{
  "metadata": {
    "last_updated": "2026-01-07 02:36:06",
    "time_filter": "week",
    "subreddit": "comfyui",
    "total_items": 33,
    "total_comments": 512,
    "file_size_bytes": 512600
  },
  "items": [
    {
      "id": "1pxzfzs",
      "title": "My first Movie generated entirely by AI.",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/ybcqsboarz9g1",
      "author": "OvenGloomy",
      "created_utc": "2025-12-28 19:04:06",
      "score": 334,
      "num_comments": 121,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1pxzfzs/my_first_movie_generated_entirely_by_ai/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwext23",
          "author": "Keyflame_",
          "text": "Alright, let me preface by saying I admire the patience, effort and time that went into this.\n\nNow this might hurt to read, but it's just okay for AI standards, and awful for actual film-making standards. There's almost no cohesion between cuts, and some editorial work is needed to make things flow together properly.\n\nYou need to research some film-making, framing, composition and such. Stuff like the dude shooting forwards, then upwards look like unrelated actions, they don't flow together, there's no need to use the entire clip every time, cut it and disperse 1-2 second of him shooting and the machine reacting.\n\nThe car scene with the shotgun and the drone blowing up look completely unrelated, you should've brought that clip in an editing software and start the cut with the drone blowing up. Right now it looks like the dude shoots in the wrong direction, and the drone blows up by itself a few seconds later, there should also be a shot of the drone approaching from afar, it feels like it just spawns behind the car like a videogame.\n\nDo not randomly use cross-dissolves or fades to black, those type of transitions have meaning, their purpose is to distance cuts, creating the feeling of time passing or location changes, not blending cuts together, actual cuts work better for that.\n\nUse LoRAs for actions the AI doesn't know how to work with, the dude putting his entire mouth around the neck of the bottle looks really weird.\n\nLastly, everything looks like it's in slow motion, use an editing software to accelerate the movement if needed.\n\nI know it may seem harsh and it's unpleasant to read this, but if I just say that it's good when it isn't, you aren't gonna get any better.",
          "score": 154,
          "created_utc": "2025-12-28 19:36:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwezu46",
              "author": "smeepydreams",
              "text": "Someone could make a mint creating mini filmmaking tutorials specifically for people making AI movies. One of the first things I realized when I started making AI videos was how little I knew about the mechanics of filmmaking and cinematography.",
              "score": 37,
              "created_utc": "2025-12-28 19:46:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwf13g1",
                  "author": "Keyflame_",
                  "text": "That's actually a great idea, hopefully it inspires someone to do so.\n\nI might work on doing that myself when I have some time, it sounds like something that would actually help the community grow and improve.\n\nAs much as AI keeps improving, at the end of the day it's a tool, and while we have a ton of tutorials on how to generate, we have almost none on how to actually use those results for creative work. No matter how good models get at generating, it's a human who has to do the editorial work, at least for the near future.",
                  "score": 14,
                  "created_utc": "2025-12-28 19:52:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwfbw5h",
                  "author": "RootaBagel",
                  "text": "I was just thinking I need to learn more about the film making craft and went looking.  User u/Wnet_wtem  on r/Filmmakers put together a huge set of resources for people to learn from:\n\n[https://www.reddit.com/r/Filmmakers/comments/k60tve/i\\_made\\_a\\_huge\\_list\\_of\\_resources\\_to\\_learn/](https://www.reddit.com/r/Filmmakers/comments/k60tve/i_made_a_huge_list_of_resources_to_learn/)",
                  "score": 9,
                  "created_utc": "2025-12-28 20:45:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwggzl5",
                  "author": "lewdroid1",
                  "text": "There's already tutorials... It's just called filmmaking. AI is just one of the many tools that can be used in the process.",
                  "score": 5,
                  "created_utc": "2025-12-29 00:15:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwg7jkk",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 3,
                  "created_utc": "2025-12-28 23:25:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwf9l7e",
                  "author": "lordpuddingcup",
                  "text": "This someone who takes post processing and film making with ai and does a clean GOOD course will make a bundle",
                  "score": -1,
                  "created_utc": "2025-12-28 20:34:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwfnnpy",
              "author": "whoisurhero",
              "text": "If only the op hadn't mentioned in the description that the video was only a test for his rig and had nothing to do with creating a masterpiece.",
              "score": 14,
              "created_utc": "2025-12-28 21:42:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwfvrho",
                  "author": "Keyflame_",
                  "text": "OP edited the post. The description was different when I replied, and was outright asking for opinions and criticism. Edits only show up in comments, not in threads.\n\nNone of the testing the limits part was mentioned in the original description, and frankly it doesn't make sense to edit generated clips together to test the limits of a rig, compositing the video has nothing to do with the specs of the machine, video-editing is light weight and requires minimal resources compared to AI.\n\nYou can tell the thread is edited cause it's now titled \"My first movie using AI\" and the description essentially says \"but this isn't about making a movie\", which is an open contradiction.\n\nI'm very disappointed, as I provided sincere advice for what I believed to be a sincere request for feedback.",
                  "score": 16,
                  "created_utc": "2025-12-28 22:23:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwhklhm",
                  "author": "LocoMod",
                  "text": "I‚Äôm not sure the amount of effort put into this is considered a test. OP learned the tools but that‚Äôs the easy part. The part that determines the outliers takes years to hone, even with AI. Since the way AI has raised the floor for a lot of people, it has also raised the ceiling of expectations.\n\nThe good news is OP is well on their way to getting there.",
                  "score": 0,
                  "created_utc": "2025-12-29 04:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjibww",
              "author": "Unreal_777",
              "text": "So you just create new loras anytime ai cant create a scene?",
              "score": 1,
              "created_utc": "2025-12-29 13:29:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwjqp98",
                  "author": "Keyflame_",
                  "text": "Everytime is a bit of a stretch, If necessary, yes, that's how you do it if you want good results. If the AI model simply doesn't understand a concept, and you really want to include said concept in a shot, there's really no other way around it.\n\nA lot of stuff you train during the process is stuff you'll eventually be using again, it's not as taxing as it sounds.",
                  "score": 2,
                  "created_utc": "2025-12-29 14:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwj0zgw",
              "author": "SeaTacVic",
              "text": "Completely fair criticism. Even after OP‚Äôs edit this needs to be said.",
              "score": 1,
              "created_utc": "2025-12-29 11:18:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwfzqx5",
              "author": "elswamp",
              "text": "Relax mate. its their first movie",
              "score": -8,
              "created_utc": "2025-12-28 22:43:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwg078g",
                  "author": "Keyflame_",
                  "text": "I was just trying to help them improve, the original thread asked for criticism and feedback. It's since been edited.",
                  "score": 8,
                  "created_utc": "2025-12-28 22:46:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwk718t",
              "author": "Rheumi",
              "text": "He wrote exactly that \"The goal was not to create a professional cinematic short film, but to explore the current boundaries of local hardware and the WAN 2.2 model. I am not a filmmaker. This project wasn't about cinematography, cuttin, pacing, or professional storytelling.\" Also he did not post this into r/indiemovies but in r/comfyui so I find your comment pretty needless.",
              "score": -2,
              "created_utc": "2025-12-29 15:44:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwk7wpq",
                  "author": "Keyflame_",
                  "text": "Dude I don't wanna be pedantic, but please take the time to read the replies before commenting the same thing 4 other people said.\n\nI've already explained 4 times that OP edited the post and was previously inviting criticism and feedback.\n\nSorry if I come off as aggressive, but it's getting tiresome to see the same comment every few hours, and only adds to how dishonest OP's edit was, inviting criticism and then quietly hiding the request when he didn't like receiving feedback.\n\nI took my time to watch his video, to analyze it and to leave feedback aimed at improving in the assumption that it was a sincere request, only to have people reply to me every few hours that \"read the description\" when they can't be bothered reading the replies to the comment themselves.",
                  "score": 2,
                  "created_utc": "2025-12-29 15:48:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwgbmml",
              "author": "Elegant-Radish7972",
              "text": "Did you read this? : \"This project wasn't about cinematography, cuttin, pacing, or professional storytelling. My goal was purely to see how far I could push my local setup (RTX 5090) in my very first steps of local video generating.\"\n\nI think he did an outstanding job for a new video to just see what it could do with his card.",
              "score": -9,
              "created_utc": "2025-12-28 23:47:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgdvcd",
                  "author": "Tuned3f",
                  "text": "OP was asking for criticism before editing the description, apparently",
                  "score": 7,
                  "created_utc": "2025-12-28 23:59:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwgg01t",
                  "author": "Keyflame_",
                  "text": "I did, but it wasn't there when I originally made this comment.\n\nOP edited the thread after my comment, the original description openy asked for criticism and feedback, it has since been edited saying the project wasn't about making a movie, despite the thread still being titled \"My first AI movie\".\n\nTo reinforce the fact that it wasn't like that before, it also doesn't really make sense to test the boundaries of what can be done with AI by stitching 5 seconds Wan clips together into a long video, that's just manual video editing.",
                  "score": 6,
                  "created_utc": "2025-12-29 00:10:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwf5xe1",
          "author": "funkymonkeyinheaven",
          "text": ">\"My first Movie\"\n\n>\"And no, it's not meant to be a \"movie\".¬†\n\nDon't call it that if you don't want it to be judged like that. \n\n>Promt Engineer \n\nTypo in your credits",
          "score": 24,
          "created_utc": "2025-12-28 20:15:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nweyx6r",
          "author": "The_BeatingsContinue",
          "text": "There are so many continuity mistakes, this is very hard to watch. Despite of these really annoying and grave continuity mistakes:  \n\n* you should NOT blend nearly every shot into dark. \n* you should use different field sizes, always looking at same sized objects is quite boring\n* you should not paste every generated clip just into the \"mix\". Make CUTS. Learn cutting rythms. Watch movies with good editing. Learn from it. Cause your film does not provide ANY editing skill.\n* If you have a long shot after a long shot, adding a timelapse after that is just wrong. You put timelapses after sequences of high frequent cuts to maximize their impact.\n* Your \"story\" can be told in two sentences. You're taking 3:47 for that. This is way too much. You will realize, that if editing this to a length of 1 minute using CUTS, this whole project will benefit from it.",
          "score": 9,
          "created_utc": "2025-12-28 19:42:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwez3vq",
          "author": "kek0815",
          "text": "Technically it's really well made, though you could look into some film making rules like the 180 degree rule of posing subjects. Some shots like the robot appearing are weirdly posed: protagonist looks from right to left, robot looks from left to right, then when we see both the protagonist is on the left and robot on the right looking left. It makes if difficult for the viewer to stay oriented in the scene. [https://www.youtube.com/watch?v=Bba7raSvvRo](https://www.youtube.com/watch?v=Bba7raSvvRo)  \nAlso, same scene: You cut from a medium long shot (robot appears) into another medium long shot (protagonist faces robot), which is not commonly done to make for a more engaging viewing experience.  \nNot meaning to shit on your film at all, it's quite good but just some tips about things most people get a bit wrong when first making films.",
          "score": 15,
          "created_utc": "2025-12-28 19:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwff75i",
              "author": "msixtwofive",
              "text": "\"technically it's really well made\" \n\nwhat? In what way? Nothing about this comes across as well made in the context OP is aiming for.",
              "score": 9,
              "created_utc": "2025-12-28 21:01:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwfi4ke",
                  "author": "kek0815",
                  "text": "I mean, I was trying to be encouraging, OP took a lot of time to make this. Constructive criticism, you know?",
                  "score": 7,
                  "created_utc": "2025-12-28 21:15:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfai1w",
          "author": "ANR2ME",
          "text": "I feels that the train shouldn't stopped there ü§î need to go forwards a bit more.",
          "score": 3,
          "created_utc": "2025-12-28 20:38:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfr7ui",
          "author": "GrungeWerX",
          "text": "Visuals are there but the pacing, story flow, connectivity of the shots‚Ä¶that‚Äôs all bad. Very bad. Not a personal jab but you should watch videos on directing stories. \n\nAt the very least, work from storyboards. \n\nThere are too many errors for me to pick out just one to improve on, BUT‚Ä¶you need to learn how to make shots flow in a continuous direction‚Ä¶left to right, etc.  and maintain that consistency between shots before introducing another direction.\n\nI‚Äôm not in front of PC so I gotta make this brief. \n\nAll that said, your work is not a wasted, lots of great money shots and good quality and with a little directing and editing work, your next project will look great.\n\nKeep it up!",
          "score": 3,
          "created_utc": "2025-12-28 22:00:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlfrpp",
          "author": "Fun-Village-9043",
          "text": "Keep making more, you'll get better. Honestly, this is a great time for experimentation. Eventually, the truly good stuff will stand out.\n\nI did a similar experiment to test what I could do on my 3080 locally, but leaned into the slop. Character inconsistency abound, but we're getting better tools for that now: [https://www.youtube.com/watch?v=Ukt2T-s4deI](https://www.youtube.com/watch?v=Ukt2T-s4deI)",
          "score": 3,
          "created_utc": "2025-12-29 19:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfjrly",
          "author": "Clasyc",
          "text": "Sorry, but I puked.",
          "score": 8,
          "created_utc": "2025-12-28 21:23:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf19bu",
          "author": "PeachScary413",
          "text": "Bro I'm really sorry.. but it looks ass tbh ü•≤\nAnyone saying anything else is just gassing you up, you need to hear this and actually take some classes and learn about film making.. it's really bad.",
          "score": 13,
          "created_utc": "2025-12-28 19:53:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfim17",
              "author": "3PI-G3N3TIC",
              "text": "I agree, I am tired of all this AI slop. The edit and the physics are awful. I hope the hype settles once and for all. Everyone is acting like a James Cameron clone because AI. There is more to a short movie than access to a generative model.\n\nThe best use of this technology is to create/explore drafts for potential storylines. All else is a glorified wannabe art crap.",
              "score": 10,
              "created_utc": "2025-12-28 21:18:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwfrq6i",
                  "author": "Puttanas",
                  "text": "It‚Äôs not even because it‚Äôs AI that‚Äôs the issue. The issue is that there‚Äôs more to making a good movie than damn pretty visuals lol.",
                  "score": 8,
                  "created_utc": "2025-12-28 22:02:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwkyint",
          "author": "thermocoffee",
          "text": "Man you're brave putting this on here. This sub is full of people who don't know what they're talking about and don't work for the industry. Congrats! You should be proud of what you made. Keep going. Cheers!",
          "score": 4,
          "created_utc": "2025-12-29 17:54:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm3zq3",
              "author": "Rheumi",
              "text": "right? So many entitled brats who think only a hollywood masterpiece deserves their attention. If OP is happy with it, I'm happy for OP.",
              "score": 3,
              "created_utc": "2025-12-29 21:11:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwflqla",
          "author": "3DNZ",
          "text": "All this effort and its still a lousy, uninteresting story.  The motion is awful - its truly abysmal motion - and it took me out of the whole thing.\n\nThe editing isn't good, the beats are clunky, the blocking and staging are non-sensical.\n\nI suggest you learn how to tell a story and how to edit before putting in such a tremendous (and respectable) effort into a project. Write several drafts.  Have friends you trust read it to give their opinions.\n\nFilmmaking isnt in the final product.  Real filmmaking happens in preproduction planning.  This screams you had \"a rough idea\" but started slapping stuff together.",
          "score": 5,
          "created_utc": "2025-12-28 21:33:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf0se7",
          "author": "BroManDudeLegend",
          "text": "First of all if you can‚Äôt handle criticism for which you deemed it yourself as a proud achievement. You need to run man, run far away. \n\nThis was utter trash bro, I got bored watching him pull his gun up to shoot ROFLMAO! The only good thing I will say is the consistency of the characters.",
          "score": 9,
          "created_utc": "2025-12-28 19:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjbuys",
              "author": "TekaiGuy",
              "text": "\"Dad, look what I drew!\"\n\n\"Son, I need to be 100% real, your drawing is certified pure landfill and the only thing I can think to do with it is wipe my ass. I'm just doing you a favor by giving my raw feedback, be grateful I took the time.\"",
              "score": 4,
              "created_utc": "2025-12-29 12:46:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwetmax",
          "author": "IndividualAttitude63",
          "text": "I can see the pain while creating each frame while keeping the fingers crossed. Best quality you reached 80 percent of realism. You need to pull more frames to it will be of normal moview like speed. Its kind a slow framed. \n\nYou used wan?",
          "score": 2,
          "created_utc": "2025-12-28 19:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgh9hw",
          "author": "venpuravi",
          "text": "Scene consistency is not 100% good, but it is better than in most cases. How did you set the visual anchor here? What is the workflow? I would like to try with Wan rapid aio with the first frame.",
          "score": 2,
          "created_utc": "2025-12-29 00:17:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi81ae",
          "author": "dr_laggis",
          "text": "Love it but in my opinion, you need to upscale your final wan clips to geht a bit better resolutions. the  clips are a little bit to long on a few scenes, you can try to cut it a bit faster next time but it is very good work for your first project",
          "score": 2,
          "created_utc": "2025-12-29 06:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi9bdx",
          "author": "FernDiggy",
          "text": "Why is is slow motion? \n\nThe only thing good here is the character consistency. Nothing else.",
          "score": 2,
          "created_utc": "2025-12-29 07:03:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwipahw",
          "author": "James_Reeb",
          "text": "Why is it slow ?",
          "score": 2,
          "created_utc": "2025-12-29 09:31:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn5ir2",
          "author": "Altruistic-Elephant1",
          "text": "Bravo! Looks like some intriguing intro for a niche gay porn.",
          "score": 2,
          "created_utc": "2025-12-30 00:26:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwey1on",
          "author": "Remmnever",
          "text": "I love arc raiders and this is awesome. Man I need a 5090! My 3090 isn‚Äôt cutting it",
          "score": 2,
          "created_utc": "2025-12-28 19:37:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf3gqt",
          "author": "Scandinavian-Viking-",
          "text": "It was ok. I got a little bored after one minute, and you break some editing rules. But well made.",
          "score": 2,
          "created_utc": "2025-12-28 20:03:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf4ekr",
              "author": "OvenGloomy",
              "text": "Its not about \"film making\" ?",
              "score": -9,
              "created_utc": "2025-12-28 20:08:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfesae",
                  "author": "Scandinavian-Viking-",
                  "text": "Its not?",
                  "score": 4,
                  "created_utc": "2025-12-28 20:59:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwid3l5",
          "author": "Historical-Role358",
          "text": "theme is great. way more exciting than the video lol hollywood is safe for another 5 years i think",
          "score": 2,
          "created_utc": "2025-12-29 07:37:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfpn42",
          "author": "samijanetheplain",
          "text": "This was horrible to watch. It really fit the definition of slop.",
          "score": 2,
          "created_utc": "2025-12-28 21:52:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwet9xj",
          "author": "K0owa",
          "text": "Using which models?",
          "score": 1,
          "created_utc": "2025-12-28 19:15:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nweupef",
              "author": "OvenGloomy",
              "text": "See the end of the video",
              "score": 3,
              "created_utc": "2025-12-28 19:21:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwex8cb",
          "author": "CryptographerCrazy61",
          "text": "Pretty cool I‚Äôm making a sci fi series for a micro streaming platform, my characters are visually complex too I feel your pain at having to make sure there is consistency shot to shot. My take is you have the tools now work on the directing / story telling part of it. The dialogue. Those will elevate your game a hundred fold",
          "score": 1,
          "created_utc": "2025-12-28 19:33:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf1hm1",
          "author": "RepresentativeRude63",
          "text": "Instead of a random music for ambient, a voice over commentary or story telling will provide much more impact. We don‚Äôt get the feelings, movie is not connecting to the viewer. Just try this, lower that music, keep sound effects min too, add a story voice over. You will see the difference without changing any scene",
          "score": 1,
          "created_utc": "2025-12-28 19:54:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf7jzi",
          "author": "nihnuhname",
          "text": "How can I use LoRA to put two different characters in the same frame?",
          "score": 1,
          "created_utc": "2025-12-28 20:23:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfdohi",
          "author": "yobigd20",
          "text": "We need in game vehicles",
          "score": 1,
          "created_utc": "2025-12-28 20:54:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfopgq",
          "author": "ifonze",
          "text": "It‚Äôs impressive what technology is capable of nowadays. I‚Äôve been wanting these capabilities to come into fruition 2 decades ago but I thought it would be just a fantasy in my lifetime. I‚Äôm glad you stated in your oc that the intention wasn‚Äôt to pass this off as an actual short film even tho it is an amateur one at that I commend the time and effort you spent in making this as it motivates me to do something of this scale as I personally just bought a 3090fe. I‚Äôm slowly building up to a full build. I have tried wan 2.2 and it‚Äôs impressive. I see commenters who are giving it harsh criticism and it‚Äôs well deserved, but I also think is better than what amateurs can do atm. I‚Äôm hoping this makes its way to skilled storytellers and someone can step up and give us a proper film made with ai.  But thanks for sharing. It‚Äôs very motivating for me to look forward to using these tools and also learn how to tell good stories with these tools. Keep going and keep sharing take the constructive criticism you get and make some adjustments along the way.",
          "score": 1,
          "created_utc": "2025-12-28 21:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfs3qy",
          "author": "gallito_pro",
          "text": "Beautiful",
          "score": 1,
          "created_utc": "2025-12-28 22:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfsg15",
          "author": "InevitableVehicle_",
          "text": "Great visuals! Was not expecting the cameo from Dr. Andrew Huberman üòÅ",
          "score": 1,
          "created_utc": "2025-12-28 22:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwft2ma",
          "author": "goodluckcoins",
          "text": "I love it! üëèüèªüëèüèª",
          "score": 1,
          "created_utc": "2025-12-28 22:09:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfyr2u",
          "author": "Anxious-Program-1940",
          "text": "Someone played ArcRaiders and now has major PTSD üò≠. Also fantastic worküëèüèª",
          "score": 1,
          "created_utc": "2025-12-28 22:38:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg3b4v",
          "author": "testdrive93",
          "text": "It‚Äôs ok for an ads but needs more improvement for a full focus moment",
          "score": 1,
          "created_utc": "2025-12-28 23:02:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg3jns",
          "author": "Efficient_Band_3045",
          "text": "I can‚Äôt run wan 2.2 on my 5090. Segmentation error killing me and wondering about ur cuda and torch versions",
          "score": 1,
          "created_utc": "2025-12-28 23:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgi4ye",
          "author": "criticalcrypt",
          "text": "Well done! üëç",
          "score": 1,
          "created_utc": "2025-12-29 00:21:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgu7ho",
          "author": "Santhanam_",
          "text": "Whole film is in 0.5x, is it wan limitations or intentional ?",
          "score": 1,
          "created_utc": "2025-12-29 01:28:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgytvq",
          "author": "reicaden",
          "text": "Better romance than broke back mountain",
          "score": 1,
          "created_utc": "2025-12-29 01:55:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwh6gh1",
          "author": "asciimo",
          "text": "The blue glowing thing reminded me of  a short story I wrote in 4th grade. In my story, the protagonist found a chest at the bottom of a lake early on. I never mentioned it again.",
          "score": 1,
          "created_utc": "2025-12-29 02:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhtx8h",
          "author": "osiris316",
          "text": "Nice job raider!",
          "score": 1,
          "created_utc": "2025-12-29 05:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj20vc",
          "author": "littlegreenfish",
          "text": "Redo this, but in an animated art style. Trying for realism just .... does not seem to work.",
          "score": 1,
          "created_utc": "2025-12-29 11:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkb2of",
          "author": "Cautious_Scholar_191",
          "text": "Cool, great work",
          "score": 1,
          "created_utc": "2025-12-29 16:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmip7k",
          "author": "PixieRoar",
          "text": "What workflow and model did you use?",
          "score": 1,
          "created_utc": "2025-12-29 22:24:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmnmbg",
          "author": "CryptoCatatonic",
          "text": "I love how it turns into a car commercial mid video üòÜ",
          "score": 1,
          "created_utc": "2025-12-29 22:49:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6fibk",
          "author": "SufficientOwl871",
          "text": "what was the workflow to create something so long? I strongly with consistency after I do the first 6-10 second video. I've been looking for working workflows that make sense, any leads?",
          "score": 1,
          "created_utc": "2026-01-02 01:32:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx94azz",
          "author": "AffectionateBox7649",
          "text": "The quality of the video is exceptionally high, the storyline is particularly coherent, and the clarity and consistency of the characters are strong. In short, you are an enviable person with excellent skills and screenwriting abilities.",
          "score": 1,
          "created_utc": "2026-01-02 13:52:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfd7a2",
          "author": "Noeyiax",
          "text": "For an amateur movie, it's great! \n\n80% of people would enjoy it, the feedback in other comments is good too and I agree with most of them\n\nTy for sharing, see you topside o7\n\nBut come on 1 heavy fuze grenade cannot take down a leaper? Or is that a queen lol.. should have used a wolf pack, that would been sick animation too",
          "score": 1,
          "created_utc": "2025-12-28 20:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf0lmy",
          "author": "Pretend-Park6473",
          "text": "I chuckled than regular slow-mo turned to slow slow-mo than the robot shot it's weapon. Anyway, keep it up!",
          "score": 1,
          "created_utc": "2025-12-28 19:50:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf6yrr",
          "author": "barepixels",
          "text": "Congrats on your first effort.  The more you do it, the better you will be.  Thanks to the people who gave harsh feedback.  We all learn from this.  It would be great if someone could point to a short film and break it down scene by scene, explaining why it works.  As a complete noob, I would love to learn the art of cinema.",
          "score": 1,
          "created_utc": "2025-12-28 20:20:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf820f",
          "author": "thisiztrash02",
          "text": "this is extremely well put together ..the only thing that hinders it a little is wan slow movements particularly in the battle scene but great work  overall",
          "score": 1,
          "created_utc": "2025-12-28 20:26:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf7m55",
          "author": "bsensikimori",
          "text": "THIS IS THE FUTURE! Excellent work :)\n\nLove the creativity and consistent look and feel\n\nWhat kind of Lora do you use to keep him consistent? Or is that just by first frame?\n\nReally impressive result, well done",
          "score": -2,
          "created_utc": "2025-12-28 20:24:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwesc8q",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -13,
          "created_utc": "2025-12-28 19:10:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwet882",
              "author": "K0owa",
              "text": "Why are you in this subreddit then?",
              "score": 9,
              "created_utc": "2025-12-28 19:14:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwetn5y",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -7,
                  "created_utc": "2025-12-28 19:16:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwevhki",
              "author": "OvenGloomy",
              "text": "That's such an unnecessary comment that I almost fall off my chair laughing.",
              "score": 4,
              "created_utc": "2025-12-28 19:25:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwevqkw",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": -4,
                  "created_utc": "2025-12-28 19:26:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nweykrw",
              "author": "Better-Interview-793",
              "text": "It‚Äôs about creativity, not the tool. We‚Äôre almost in 2026, hating AI is kinda pointless tbh",
              "score": 0,
              "created_utc": "2025-12-28 19:40:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwfzhnz",
          "author": "queenkasa",
          "text": "ts is so ass ü•Ä",
          "score": 0,
          "created_utc": "2025-12-28 22:42:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgvwg1",
          "author": "Sir_McDouche",
          "text": "Well, good job on testing your hardware but this video is just a drop in the ocean of AI slop. Will be forgotten in 2 minutes.",
          "score": 0,
          "created_utc": "2025-12-29 01:38:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwew6xi",
          "author": "Fast-Cash1522",
          "text": "Simply fantastic! Thanks for sharing",
          "score": -6,
          "created_utc": "2025-12-28 19:28:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfoki3",
          "author": "Honest_Time_7758",
          "text": "Very nice! These haters cant make this!",
          "score": -4,
          "created_utc": "2025-12-28 21:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nweu9ys",
          "author": "LookAnOwl",
          "text": "Honestly, this is very good. I wouldn‚Äôt pay to see something like this at this moment in time because it still has the somewhat cold, lifeless AI feel, but compare this to the original Will Smith eating spaghetti videos. Shit is moving fast.",
          "score": -6,
          "created_utc": "2025-12-28 19:19:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nweummx",
              "author": "OvenGloomy",
              "text": "It was never my intention to create a Movie for the masses. It was a private project on my part.",
              "score": -4,
              "created_utc": "2025-12-28 19:21:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nweuxwz",
                  "author": "LookAnOwl",
                  "text": "No, I understand that - I‚Äôm just looking at it through a bigger lens. For a private project, this is better than most of the things I‚Äôve seen posted on subreddits like this.",
                  "score": 1,
                  "created_utc": "2025-12-28 19:22:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwf3m91",
          "author": "elvinjoker",
          "text": "You sound like you also create movie before AI exists",
          "score": -1,
          "created_utc": "2025-12-28 20:04:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf4ksh",
              "author": "OvenGloomy",
              "text": "Never. I did it purely from a technical standpoint, not from a ‚Äúfilmmaking‚Äù perspective.",
              "score": 3,
              "created_utc": "2025-12-28 20:09:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwiuy3a",
          "author": "ThexDream",
          "text": "Does anyone ever make something with AI (or anything else for that matter) and not post it somewhere? Is there a new law that says you must post your learning tests? Your sketches? Anything and everything you do during the day? \nSo you learned how to prompt and do first image last image. We‚Äôre at a date in time where 3rd graders can do this.",
          "score": -1,
          "created_utc": "2025-12-29 10:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnty7a",
              "author": "CheezeFPV",
              "text": "To be fair, I find it inspiring",
              "score": 1,
              "created_utc": "2025-12-30 02:41:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q2z02m",
      "title": "Update: I figured out how to completely bypass Nano Banana Pro's SynthID watermark, and here's how you can try it for free:",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1q2z02m",
      "author": "LiteratureAcademic34",
      "created_utc": "2026-01-03 16:32:57",
      "score": 304,
      "num_comments": 61,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q2z02m/update_i_figured_out_how_to_completely_bypass/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxgo8cy",
          "author": "additionalpylon2",
          "text": "This is why they won't let consumers have GPUs anymore. We are too powerful lol. Keep up the good work my friend.",
          "score": 61,
          "created_utc": "2026-01-03 16:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxh69d2",
              "author": "PaysForWinrar",
              "text": "I'd consider myself a healthy skeptic that doesn't pay much attention to most conspiracy theories, but I absolutely believe the market is moving towards subscription based models to milk us dry and control the future of generative AI. \n\nThey know if we get consumer gear with hundreds of GB of VRAM, we'll be able to run a little appliance at home instead of relying on them. \n\nData scientists I used to work with were calling this move back in 2020, and the recent move affecting RAM prices is like I'm seeing the prophecy fulfilled.",
              "score": 27,
              "created_utc": "2026-01-03 18:00:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxh9d1d",
                  "author": "LiteratureAcademic34",
                  "text": "Im betting on China to come out with 96gb gpus for 1k",
                  "score": 21,
                  "created_utc": "2026-01-03 18:14:50",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nxh9hew",
                  "author": "additionalpylon2",
                  "text": "I fully agree. There is no other reason they would invest so much money and not expect a return.\n\nIt is all short sighted but unfortunately will work for a little while.  The only power we have is to not pay for the subscription services since how we spend our money is the only vote that actually counts. Unfortunately people will buy it and they will get rich.",
                  "score": 3,
                  "created_utc": "2026-01-03 18:15:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxj0rrq",
                  "author": "Green-Ad-3964",
                  "text": "The cloud paradigm is like ‚Äúthe Nothing‚Äù in *The NeverEnding Story*: human apathy, cynicism, and the loss of imagination consuming the world of Fantasia, where Fantasia is the community made up of open-source developers and enthusiasts.",
                  "score": 1,
                  "created_utc": "2026-01-03 23:23:08",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxsxmnu",
                  "author": "justmypointofviewtoo",
                  "text": "This is why I have my 5090 and 128 GB of Ram. Zero chance EVERYTHING isn‚Äôt becoming a subscription model to do anything viable. It‚Äôll all be a big bait and switch like all of the streaming services were.",
                  "score": 1,
                  "created_utc": "2026-01-05 11:56:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3r7lu",
                  "author": "imlitterallygru",
                  "text": "Brother we *already live* in the subscription apocalypse",
                  "score": 1,
                  "created_utc": "2026-01-06 23:47:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxgpfmb",
              "author": "LiteratureAcademic34",
              "text": "Yup!! Thanks!",
              "score": 8,
              "created_utc": "2026-01-03 16:43:18",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxk0fti",
              "author": "chum_is-fum",
              "text": "Just wait a few years until a new wave of hardware comes out, we'll have an ocean of second hand datacenter GPUs.",
              "score": 2,
              "created_utc": "2026-01-04 02:35:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxgqs9i",
          "author": "nok01101011a",
          "text": "Thank you, that‚Äôs an interesting approach. Does solely upscaling not do the magic already?",
          "score": 8,
          "created_utc": "2026-01-03 16:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgqygv",
              "author": "LiteratureAcademic34",
              "text": "Nope, in fact upscaling makes it even harder to remove the watermark because it bakes it in even further.",
              "score": 10,
              "created_utc": "2026-01-03 16:50:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxgwymn",
                  "author": "Sn34kyMofo",
                  "text": "Interesting.\n\nI was going to try something like recursively reading each pixel of an image and altering its value randomly, but only slightly, to be higher or lower such that it's imperceptible to the human eye but possibly screws up SynthID.\n\nThen, depending on how that goes, divide the approach into partial quadrants or even numerous random spots throughout an image to see if it's at all effective. Have you seen or tried something to that effect yet?",
                  "score": 9,
                  "created_utc": "2026-01-03 17:18:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxgrlsw",
                  "author": "nok01101011a",
                  "text": "Thank you for the insight, makes sense, I guess. Hence there is also noise involved in upscaling, I wonder how the synthID gets even more baked in.",
                  "score": 1,
                  "created_utc": "2026-01-03 16:53:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxhjrv2",
                  "author": "garlic-silo-fanta",
                  "text": "There‚Äôs your answer then. lol. \n\nCheck. Your move.",
                  "score": 1,
                  "created_utc": "2026-01-03 19:01:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxhepzo",
          "author": "T_D_R_",
          "text": "Is there any way to bypass Nano Banana Pro into NSFW zone ?‚Äã ‚ÄãI mean I want to generate an image for a crime scene but there's blood on it and they are rejecting!",
          "score": 5,
          "created_utc": "2026-01-03 18:39:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhkptx",
              "author": "AlphabetDebacle",
              "text": "Try to bypass the filter by changing the words you choose but will give a similar visual result. For instance, ‚Äòfake blood, prop blood, dark cherry syrup.‚Äô\n\nI find the content censorship is stronger when accessing Nano Banana through API instead of directly through Google. Google Flow or AI studio is more lax compared to accessing Nano Banana through a 3rd party.",
              "score": 5,
              "created_utc": "2026-01-03 19:06:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkcx8l",
                  "author": "T_D_R_",
                  "text": "Yeah, It takes so much time and retry to get the result BTW I am already using red sauce/water!",
                  "score": 2,
                  "created_utc": "2026-01-04 03:46:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxj7wt3",
          "author": "m_tao07",
          "text": "I would wish that this isn‚Äôt possible. I believe that the SynthID is important, making it possible to identify AI content and real content. I hope that the big companies will learn of this and improve, so we don‚Äôt end with believing something is true because of no prof and having fake information spreading.",
          "score": 3,
          "created_utc": "2026-01-04 00:00:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny17pgy",
              "author": "Z3ROCOOL22",
              "text": "https://i.redd.it/q91cai1ecrbg1.gif",
              "score": 1,
              "created_utc": "2026-01-06 16:42:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhlqvu",
          "author": "roxoholic",
          "text": "> build truly robust watermarking that can't be scrubbed away by simple re-diffusion\n\nMy intuition tells me this is probably impossible.",
          "score": 2,
          "created_utc": "2026-01-03 19:10:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhqmma",
              "author": "LiteratureAcademic34",
              "text": "It is not 100% possible because you can always rediffuse the image until it is unregnisable. I have had a few ideas of training something into the actual diffusion model, kind of like a \"quirk\" that works completely differently from the SynthID",
              "score": 3,
              "created_utc": "2026-01-03 19:33:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxgorip",
          "author": "BoredHobbes",
          "text": "i just screenshot my google banna photos and upscale...........",
          "score": 3,
          "created_utc": "2026-01-03 16:40:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgqgen",
              "author": "nok01101011a",
              "text": "I would also think that upscaling with some noise would bypass it already. You use SeedVR2 right?",
              "score": 6,
              "created_utc": "2026-01-03 16:48:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkrjxw",
                  "author": "BoredHobbes",
                  "text": "topaz but just installed seed cause topaz changed subscription style while back",
                  "score": 2,
                  "created_utc": "2026-01-04 05:21:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxh9324",
          "author": "RepresentativeRude63",
          "text": "Do a 0.01 denoise refine with any model after that use standart upscale node (even keep same resolution) test if it still fails ai detection add effects (LuTs) with an app like Lightroom etc. you will get %90 human made in most ai detectors",
          "score": 1,
          "created_utc": "2026-01-03 18:13:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm4l9d",
              "author": "DeMischi",
              "text": "Does it pass the SynthID check?",
              "score": 1,
              "created_utc": "2026-01-04 12:21:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhna67",
          "author": "TheArchivist314",
          "text": "I've done the same thing except I did it by turning on a single detailing Lora at 0.2",
          "score": 1,
          "created_utc": "2026-01-03 19:18:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhnvvf",
          "author": "TheArchivist314",
          "text": "Your SeedVR2 Models (optional)\tseedvr2/\tSeedVR2 Repository\n\nleads to a 404 page",
          "score": 1,
          "created_utc": "2026-01-03 19:20:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxho4gz",
              "author": "LiteratureAcademic34",
              "text": "Thanks for letting me know, ill update this when I have time",
              "score": 1,
              "created_utc": "2026-01-03 19:21:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxj2czl",
          "author": "YMIR_THE_FROSTY",
          "text": "Everything can be scrubbed. Only somewhat usable solution would be poisoning image on output. Altho I can right now imagine couple ways around it too.\n\nIts generative AI, it wont stop being generative.\n\nBeside while current nano-banana seems impressive, Im pretty sure we will continue forward. Much like last years models or year before that (which is middle ages in terms of generative AI), this year models might just be as good or way better. And smaller, I hope. :D",
          "score": 1,
          "created_utc": "2026-01-03 23:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3ss3u",
          "author": "quebec00",
          "text": "Heres a new discord link: https://discord.gg/k9CpXpqJt",
          "score": 1,
          "created_utc": "2026-01-06 23:55:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhggnn",
          "author": "LiteratureAcademic34",
          "text": "Updated discord link: https://discord.gg/k9CpXpqJt",
          "score": 1,
          "created_utc": "2026-01-03 18:46:57",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny3n1rh",
              "author": "terrorspace",
              "text": "The link seems to be broken. \"Unable to accept invite\"",
              "score": 1,
              "created_utc": "2026-01-06 23:25:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhynkg",
          "author": "Affectionate_Wash104",
          "text": "What is the difference between this workflow and the one you from a week ago?",
          "score": 1,
          "created_utc": "2026-01-03 20:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxi8x6n",
              "author": "LiteratureAcademic34",
              "text": "I optimized it for lower VRAM",
              "score": 5,
              "created_utc": "2026-01-03 21:03:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxifod5",
          "author": "Robotic_People",
          "text": "Wait are normal exif strippers not enough",
          "score": 0,
          "created_utc": "2026-01-03 21:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxk7wrb",
              "author": "Carnildo",
              "text": "The watermark isn't stored in the EXIF data, it's embedded into the image data itself.",
              "score": 3,
              "created_utc": "2026-01-04 03:17:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxpsm8w",
              "author": "Badbullet",
              "text": "As an analogy, think of how modern printers print a little code in yellow that you can‚Äôt see, but it can be used to identify the exact printer used to make that particular print. If I understand what is being done here, it‚Äôs a pattern in the pixels that identifies the image. Resampling it removes or modifies those pixels where they can‚Äôt be read.",
              "score": 1,
              "created_utc": "2026-01-04 23:15:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxh4ox6",
          "author": "3deal",
          "text": "What is the purpose of this ? Spreading fake content on internet ?",
          "score": -6,
          "created_utc": "2026-01-03 17:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhg48d",
              "author": "phloppy_phellatio",
              "text": "Other way around. It's like penetration testing, in order to make hardened watermarking you need a method of testing breaking the watermarking.\n\nThere are many useful reasons for all AI content to have an unremovable watermark. Especially if that watermark could contain a significant amount of data like a QR code.",
              "score": 17,
              "created_utc": "2026-01-03 18:45:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhpb19",
              "author": "ThenExtension9196",
              "text": "It‚Äôs to show that watermarks are pointless to prove something is real or not. It‚Äôs far more dangerous to think there is some way to prove an image is real.",
              "score": 5,
              "created_utc": "2026-01-03 19:27:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhpy2o",
          "author": "CryptographerCrazy61",
          "text": "Why do you need to bypass the watermark? Just curious",
          "score": -2,
          "created_utc": "2026-01-03 19:30:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhqony",
              "author": "LiteratureAcademic34",
              "text": "It's a research project.",
              "score": 7,
              "created_utc": "2026-01-03 19:33:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxgzph8",
          "author": "mudasmudas",
          "text": "The what?",
          "score": -2,
          "created_utc": "2026-01-03 17:31:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhly4i",
              "author": "Infallible_Ibex",
              "text": "It's a largely academic concept, if a picture is posted online as real, people will believe it. It won't matter if some tech comes in later with a forensic analysis to say the picture is AI, nobody pays attention to those people (no offense OP).",
              "score": 1,
              "created_utc": "2026-01-03 19:11:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxgyw8p",
          "author": "waferselamat",
          "text": "https://preview.redd.it/fw2n02no56bg1.jpeg?width=830&format=pjpg&auto=webp&s=3f3c4e92ea9ee1bbbfbb19efa74bd8f32f2514e0\n\nwhere is the watermark?",
          "score": -6,
          "created_utc": "2026-01-03 17:27:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxh3yq2",
              "author": "LiteratureAcademic34",
              "text": "It's imbedded into the image. It is not visible to the naked eye.",
              "score": 10,
              "created_utc": "2026-01-03 17:50:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxm4ja6",
              "author": "DeMischi",
              "text": "Dude, read the GitHub readme. It is on a subpixel level. He even made them visible in extra examples for peeps like you and me to understand how that watermark actually looks like.",
              "score": 1,
              "created_utc": "2026-01-04 12:21:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyvmcy",
      "title": "I finally managed to generate a video with my potato PC",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/tn926b0027ag1",
      "author": "Good_Avocado_7133",
      "created_utc": "2025-12-29 19:29:10",
      "score": 265,
      "num_comments": 44,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1pyvmcy/i_finally_managed_to_generate_a_video_with_my/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwloeq9",
          "author": "Geritas",
          "text": "One of the better attempts at big fish go jump and splash I‚Äôve seen yet, impressive on your hardware especially! What quant did you use?\n\nEDIT: sorry whale is not a fish‚Ä¶",
          "score": 19,
          "created_utc": "2025-12-29 19:55:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlq9q4",
              "author": "Good_Avocado_7133",
              "text": "Thank you very much! Q3\\_K\\_S is the one I am using. I really want to try at least Q5, but it's giving me OOMs. I just waiting for the ram prices to go down. lol!",
              "score": 9,
              "created_utc": "2025-12-29 20:04:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwlqgsf",
                  "author": "Geritas",
                  "text": "Ain‚Äôt we all..",
                  "score": 4,
                  "created_utc": "2025-12-29 20:05:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwm7xop",
                  "author": "EmphasisNew9374",
                  "text": "I  can run Q6 and Q8 easy on a same specked pc as yours, i do it by activating pagefile on multiple drives, each drive can do 32gb, so setting multiple ones can give you the ability to run much bigger models.",
                  "score": 1,
                  "created_utc": "2025-12-29 21:30:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnxdyf",
          "author": "Street_North9286",
          "text": "could you please share the workflow",
          "score": 2,
          "created_utc": "2025-12-30 02:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwljsrl",
          "author": "masterlafontaine",
          "text": "Great! What did you use?",
          "score": 1,
          "created_utc": "2025-12-29 19:33:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlk2yp",
              "author": "Good_Avocado_7133",
              "text": "Wan 2.2 + lightx2v loras. For the upscaler, its nmkdSiaxCX\\_200k.",
              "score": 11,
              "created_utc": "2025-12-29 19:34:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwlkbf2",
                  "author": "mudasmudas",
                  "text": "Could you share the workflow? Please",
                  "score": 4,
                  "created_utc": "2025-12-29 19:35:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwniclr",
                  "author": "ANR2ME",
                  "text": "This is my first time hearing that upscaler ü§î which node did you use it on? SeedVR2/UltimateSD/FlashVSR/something else?",
                  "score": 2,
                  "created_utc": "2025-12-30 01:37:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlk6a2",
          "author": "KILO-XO",
          "text": "Great job dude! The pain and suffering was finally worth it! Lol",
          "score": 1,
          "created_utc": "2025-12-29 19:34:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlp25n",
              "author": "Good_Avocado_7133",
              "text": "Thanks dude! Absolutely! I have spent at least days for me to be able to find the best settings for my system. Now I can generate 5 second videos <400 seconds.",
              "score": 1,
              "created_utc": "2025-12-29 19:58:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwlr31m",
                  "author": "Joker_Jrock",
                  "text": "Post settings?",
                  "score": 1,
                  "created_utc": "2025-12-29 20:08:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwll2mh",
          "author": "Delicious-Impact-397",
          "text": "I‚Äôm thinking you used text to video since there‚Äôs no whale in the first or last image. That‚Äôs really nice! ¬†I kept trying for a similar result and never got it because I always fed in a reference photo. I‚Äôll try that. Thanks for sharing and you should be proud of your potato PC. üòÜ",
          "score": 1,
          "created_utc": "2025-12-29 19:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlmvn5",
              "author": "Good_Avocado_7133",
              "text": "It's an i2v workflow, and I just fed an EmptyImage node instead, that's why it started with a black image. Haha! You can also use a transparent image.",
              "score": 1,
              "created_utc": "2025-12-29 19:47:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwlnkfn",
                  "author": "Delicious-Impact-397",
                  "text": "Would you mind sharing your prompts because I have never been able to do a breaching whale as well as as yours and I tried for a few days. ¬†üò¨",
                  "score": 1,
                  "created_utc": "2025-12-29 19:51:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlpy5r",
          "author": "psyclik",
          "text": "Now I can see the whales",
          "score": 1,
          "created_utc": "2025-12-29 20:02:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwlqfo4",
              "author": "Good_Avocado_7133",
              "text": "Haha!",
              "score": 1,
              "created_utc": "2025-12-29 20:05:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlzd0b",
          "author": "iandigaming",
          "text": "Beautiful. \n\nTried posting mine, not up to par, deleted it quick. \n\nSorry about that guys.",
          "score": 1,
          "created_utc": "2025-12-29 20:49:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm0ca8",
              "author": "Good_Avocado_7133",
              "text": "Thanks! I'm pretty sure it looks fine!",
              "score": 2,
              "created_utc": "2025-12-29 20:54:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwmrnff",
                  "author": "iandigaming",
                  "text": "Actually...no. \n\nI edited results I didn't want to throw away into a sequence best defined as slop.\n\nHad a blast making it tho...",
                  "score": 1,
                  "created_utc": "2025-12-29 23:11:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmr5ug",
          "author": "Cesar55142",
          "text": "Whale fart",
          "score": 1,
          "created_utc": "2025-12-29 23:08:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnht8f",
          "author": "ANR2ME",
          "text": "I'm surprised that you can upscale to that resolution on your potato üòØ which upscaler did you use?",
          "score": 1,
          "created_utc": "2025-12-30 01:34:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp6iw8",
          "author": "lorenzo1384",
          "text": "No it's the first one you are sharing",
          "score": 1,
          "created_utc": "2025-12-30 08:29:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq8bfj",
          "author": "razzer069",
          "text": "Wow man this is epic! I actually upgraded my system thinking it's not going to work with 8gb vram. Kudos to you! I'm going to try this out soon.",
          "score": 1,
          "created_utc": "2025-12-30 13:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq8f4j",
          "author": "Hrmerder",
          "text": "Damn that's actually pretty nice!",
          "score": 1,
          "created_utc": "2025-12-30 13:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqznqp",
          "author": "ifonze",
          "text": "It‚Äôll take a while for Ram prices to go down. I had to get ddr4 & even that was high. Spent $300 on eBay used For 2x 32gb. And that‚Äôs impressive for your computer. How long did that take to generate?",
          "score": 1,
          "created_utc": "2025-12-30 16:03:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwre2qe",
          "author": "Different-Toe-955",
          "text": "boobs too small. great gen",
          "score": 1,
          "created_utc": "2025-12-30 17:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww4gyx",
          "author": "cake_men",
          "text": "Is it i2v or t2v? And can u plsssss give me the workflow?my pc is potatoe too!",
          "score": 1,
          "created_utc": "2025-12-31 10:10:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx97tcz",
          "author": "Sl33py_4est",
          "text": "sick video",
          "score": 1,
          "created_utc": "2026-01-02 14:13:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxprwq",
      "title": "Qwen Image Edit 2511 Limit Tests (5 Image Inputs, Consistency and Shift Fix)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1pxprwq",
      "author": "Ecstatic_Following68",
      "created_utc": "2025-12-28 12:02:21",
      "score": 249,
      "num_comments": 24,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1pxprwq/qwen_image_edit_2511_limit_tests_5_image_inputs/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwddewi",
          "author": "sukebe7",
          "text": "sorry, why would you put more clothes on?",
          "score": 29,
          "created_utc": "2025-12-28 14:58:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdodmp",
              "author": "Ecstatic_Following68",
              "text": "hahahahaha, you got me.",
              "score": 13,
              "created_utc": "2025-12-28 15:57:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwhtv2y",
                  "author": "aar550",
                  "text": "I was actually looking for a clothes on !",
                  "score": 3,
                  "created_utc": "2025-12-29 05:01:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwcwn13",
          "author": "janosibaja",
          "text": "Good job! Thank you!",
          "score": 3,
          "created_utc": "2025-12-28 13:11:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdii4n",
          "author": "Byzem",
          "text": "How much ram/vram you need for this?",
          "score": 3,
          "created_utc": "2025-12-28 15:26:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdve3x",
              "author": "Mountain-One-811",
              "text": "roughly all of it",
              "score": 12,
              "created_utc": "2025-12-28 16:32:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwkrclu",
              "author": "knoll_gallagher",
              "text": "actual answer lol: I've got a 12gb 3090, 64gb sys RAM, & it takes a while to load & get cranked up, but once it starts individual gens are fine.",
              "score": 2,
              "created_utc": "2025-12-29 17:20:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf89vx",
          "author": "JustA3DGuys",
          "text": "Sorry, new user here. What shift fix and what's the difference between custom and native?",
          "score": 3,
          "created_utc": "2025-12-28 20:27:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgtpuo",
              "author": "Ecstatic_Following68",
              "text": "just different ways to fix the same issue, one uses custom nodes, another uses antive nodes.",
              "score": 3,
              "created_utc": "2025-12-29 01:25:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwcyui3",
          "author": "eidrag",
          "text": "can it do character swap?",
          "score": 2,
          "created_utc": "2025-12-28 13:27:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwczp6z",
              "author": "Ecstatic_Following68",
              "text": "Yes, tested.",
              "score": 2,
              "created_utc": "2025-12-28 13:32:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwe3mup",
          "author": "InternationalOne2449",
          "text": "I tried implementing these shift fixed and it messed up everything.",
          "score": 2,
          "created_utc": "2025-12-28 17:13:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgtkpn",
              "author": "Ecstatic_Following68",
              "text": "Why?...curious...",
              "score": 1,
              "created_utc": "2025-12-29 01:24:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwd2qss",
          "author": "scsonicshadow",
          "text": "Does this work like groks edit where if I prompt a pose for example it will edit accordingly? Or does it always need a second reference image?",
          "score": 1,
          "created_utc": "2025-12-28 13:52:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwd3311",
              "author": "EmphasisNew9374",
              "text": "It can",
              "score": 1,
              "created_utc": "2025-12-28 13:55:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwe62vz",
          "author": "SkirtSpare4175",
          "text": "Looks awesome",
          "score": 1,
          "created_utc": "2025-12-28 17:25:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiiafc",
          "author": "Past_Ad6251",
          "text": "This does not work for me , not sure why...",
          "score": 1,
          "created_utc": "2025-12-29 08:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiiuax",
          "author": "Kaantr",
          "text": "I tried to inpainting yesterday but only able to enhance the fabric's quality rather than changing its color.¬†",
          "score": 1,
          "created_utc": "2025-12-29 08:30:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjsw9g",
          "author": "latentbroadcasting",
          "text": "This is super cool! Thanks for sharing. I'm gonna try it for sure",
          "score": 1,
          "created_utc": "2025-12-29 14:31:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwof8eg",
          "author": "cdxcdxcomputer",
          "text": "Áúü‰∏çÈîô",
          "score": 1,
          "created_utc": "2025-12-30 04:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz76x6",
          "author": "MelodicFuntasy",
          "text": "Looks great, thank you for posting this! Do you think it can pose multiple characters? Let's say I have a character and want to add another one to the image and I want both of them to have different poses.",
          "score": 1,
          "created_utc": "2025-12-31 21:01:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwd3exz",
          "author": "Toni_Vaca",
          "text": "Perdona pero s√≥lo veo tres entradas",
          "score": 1,
          "created_utc": "2025-12-28 13:57:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwddsit",
              "author": "-chaotic_randomness-",
              "text": "En la primera imagen: mujer, bolso, vestido, pose y fondo",
              "score": 0,
              "created_utc": "2025-12-28 15:00:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwj07yk",
                  "author": "Toni_Vaca",
                  "text": "S√≠, pero los WF que facilita en YouTube solo admiten 3 entradas",
                  "score": 1,
                  "created_utc": "2025-12-29 11:11:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q217sc",
      "title": "SVI Pro 2.0 WOW",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/eusuhw6adyag1",
      "author": "New_Physics_2741",
      "created_utc": "2026-01-02 15:17:46",
      "score": 245,
      "num_comments": 67,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1q217sc/svi_pro_20_wow/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxa15hs",
          "author": "Nokai77",
          "text": "In all of SVI's videos, I see slow motion or fading. Unless someone changes my mind, my opinion is that I don't like the result of these types of videos.",
          "score": 33,
          "created_utc": "2026-01-02 16:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxab5nq",
              "author": "_half_real_",
              "text": "The slow motion might be because of the 4-step lora, it's used here. The fading is probably SVI though.",
              "score": 4,
              "created_utc": "2026-01-02 17:28:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxawmst",
              "author": "wemreina",
              "text": "you could try this node https://github.com/princepainter/ComfyUI-PainterI2V",
              "score": 4,
              "created_utc": "2026-01-02 19:07:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxex1v9",
                  "author": "Nokai77",
                  "text": "That node is for the first and/or last frame; as far as I know, it's not valid for svipro, which uses the wanimagetovideosvipro node.",
                  "score": 0,
                  "created_utc": "2026-01-03 09:56:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxewtyj",
              "author": "Nokai77",
              "text": "I'm also going to add something else.... The prompt often ignores you.\n\nPerhaps there's an expert who can tell me. I'm using gguf, and I've tried the 1030/moe/high lightxv2 loras, but none of them seem to work.",
              "score": 2,
              "created_utc": "2026-01-03 09:54:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxi7ks9",
                  "author": "vibrantLLM",
                  "text": "I had the same problem using fp8, I guess it's a problem with  svi itself.",
                  "score": 2,
                  "created_utc": "2026-01-03 20:57:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxm6mqx",
                  "author": "kemb0",
                  "text": "I believe it‚Äôs because svi uses an anchor image so the video will always have a tendency to match the input image where as regular WAN is free to follow your prompt without visual restrictions",
                  "score": 1,
                  "created_utc": "2026-01-04 12:37:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxdpnrl",
              "author": "jonnytracker2020",
              "text": "Check painter long video in this workflow it‚Äôs better I guess SVI is overhyped Realtime Motion in ComfyUI\nhttps://youtu.be/2YMkxUpEKfw",
              "score": 1,
              "created_utc": "2026-01-03 04:09:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxehw9o",
                  "author": "ronbere13",
                  "text": "patreon ....",
                  "score": 5,
                  "created_utc": "2026-01-03 07:44:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxex5uh",
                  "author": "Nokai77",
                  "text": "I'll tell you the same thing as the person above, that node, as far as I know, isn't for SVI PRO",
                  "score": 1,
                  "created_utc": "2026-01-03 09:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxme1xo",
              "author": "BombardierComfy",
              "text": "What amazes me is the fact it would take 2m to just open a video editor and speed it up\n\nI‚Äôd rather have too many frames than not enough",
              "score": -1,
              "created_utc": "2026-01-04 13:28:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxarhue",
          "author": "James_Reeb",
          "text": "Why is it slow ?",
          "score": 7,
          "created_utc": "2026-01-02 18:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdcmzr",
          "author": "-AwhWah-",
          "text": "omg!!!!1 Is that.... Is that.... Slow-mo 1girl?!??! WHOOOAOAOAOOAAOO WHAT THE FUKKKKKKCKKCKCK HOW??!?!??!",
          "score": 8,
          "created_utc": "2026-01-03 02:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0w9cy",
              "author": "Z3ROCOOL22",
              "text": "ü§£",
              "score": 1,
              "created_utc": "2026-01-06 15:49:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx9tk9p",
          "author": "SnooOnions2625",
          "text": "Messed around with it last night and yeah that‚Äôs my reaction.. just wow. It has its kinks if you bump up resolution. But it is amazing",
          "score": 6,
          "created_utc": "2026-01-02 16:05:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxag3mr",
              "author": "willjoke4food",
              "text": "Share your gens",
              "score": 2,
              "created_utc": "2026-01-02 17:51:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbiq26",
                  "author": "SnooOnions2625",
                  "text": "made a quick one, 24 secs long, like I said only been messing aroudn withit so far. but so far.. it is not bad at all. [https://www.reddit.com/r/comfyui/comments/1q2aa1v/svi\\_v2\\_test\\_requested/](https://www.reddit.com/r/comfyui/comments/1q2aa1v/svi_v2_test_requested/)",
                  "score": 3,
                  "created_utc": "2026-01-02 20:54:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxak6f8",
          "author": "FaceDeer",
          "text": "Incredible. I'm now in the process of turning all the character thumbnails for my roleplaying campaigns into animated clips, it makes them feel so much more \"real.\"\n\nI'm hoping it'll be possible to eventually do a \"last frame\" input into a workflow like this too, to allow for a seamlessly looping video to be generated. It'd be great for avatars and video background generation.",
          "score": 3,
          "created_utc": "2026-01-02 18:10:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxapib2",
          "author": "tomakorea",
          "text": "The clavicle is something like coming from a nightmare",
          "score": 3,
          "created_utc": "2026-01-02 18:34:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcjsko",
          "author": "Emergency-Row3957",
          "text": "https://preview.redd.it/c7r04cfqz0bg1.png?width=512&format=png&auto=webp&s=768b28f6ac20bd727b2dd330272b3dd9bf6c39ff\n\nOn a GTX 1080 and a thousnad year old Xeon, the videos are stunning.",
          "score": 3,
          "created_utc": "2026-01-03 00:05:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9kiax",
          "author": "fmnpromo",
          "text": "VRAM?",
          "score": 2,
          "created_utc": "2026-01-02 15:22:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9xo2g",
              "author": "intLeon",
              "text": "Ive shared the continious video workflow on civit. Its just wan2.2 i2v with an extra lora so runs fine on 12gb vram.",
              "score": 10,
              "created_utc": "2026-01-02 16:25:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxaciyq",
                  "author": "9elpi8",
                  "text": "Could you please post a link?",
                  "score": 3,
                  "created_utc": "2026-01-02 17:34:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx9lfvt",
              "author": "New_Physics_2741",
              "text": "5060Ti 16GB 64GB DDR4 ComfyUI/Linux Box.",
              "score": 5,
              "created_utc": "2026-01-02 15:26:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxakqkp",
          "author": "Etsu_Riot",
          "text": "You can make 19 second videos in one go, depending on your hardware. I even made a couple 27 seconds videos once. We need minute long videos without degradation in order to prove this is useful.",
          "score": 2,
          "created_utc": "2026-01-02 18:12:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxcice8",
              "author": "New_Physics_2741",
              "text": "It can be done~",
              "score": 1,
              "created_utc": "2026-01-02 23:57:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxcisan",
                  "author": "Etsu_Riot",
                  "text": "Without visual quality or speed loss?",
                  "score": 1,
                  "created_utc": "2026-01-02 23:59:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxaz8g1",
          "author": "Other-Policy-7530",
          "text": "Having issues getting this to work in general. The workflow here with the ~~same model(s)~~ just devolves into random noise.\n\nNevermind, had the wrong SVI lora I guess.",
          "score": 2,
          "created_utc": "2026-01-02 19:19:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxdpkok",
          "author": "aeroumbria",
          "text": "How are you supposed to prompt this? I tried similar methods as iterative WAN i2v (describing motion only and avoiding describing what's obvious from the first frame) but it does not seem to work very well, with little motion and altered character looks. Are you supposed to describe the whole scene at each stage?",
          "score": 2,
          "created_utc": "2026-01-03 04:09:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxds3fb",
              "author": "New_Physics_2741",
              "text": "I am not sure how strong the text string really plays into the overall picture. I let 50 image to video things run last night, and they all came out a bit different - I used a vague prompt: wild movement in all three prompts. Trying Florence2Run now and getting similar results...tweak and test til I come to some conclusion - on the fence, but it seems the text string plays a weak part in the equation at the moment.",
              "score": 1,
              "created_utc": "2026-01-03 04:25:47",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxerhga",
              "author": "L-xtreme",
              "text": "With a workflow I found you just prompt for 5 seconds. The cool thing is that you don't need to do everything in one run. Just make 5 seconds, look at the result, then do 5 more. If the last 5 are not what you want you can just only change that without needing to render the whole video again, just the last 5 secs.",
              "score": 1,
              "created_utc": "2026-01-03 09:07:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlbjm5",
          "author": "WarmKnowledge6820",
          "text": "I keep noodling with SVI and a few different workflows I keep getting weird generations. Either the characters start ghosting into each other or for some reason I end up with these weird raindrops on the screen.",
          "score": 2,
          "created_utc": "2026-01-04 08:04:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlfd2x",
              "author": "New_Physics_2741",
              "text": "I gave up using the light lora - and sure it takes a bit longer - but the output is much better\\~",
              "score": 1,
              "created_utc": "2026-01-04 08:38:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx9ys94",
          "author": "Lower-Cap7381",
          "text": "Is it wan smooth mix?",
          "score": 1,
          "created_utc": "2026-01-02 16:30:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxa0ia3",
              "author": "New_Physics_2741",
              "text": "Not the smooth mix, using the 4 step loras and svi loras. And a SEEDVR2 image to start it up.",
              "score": 3,
              "created_utc": "2026-01-02 16:38:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxaj840",
                  "author": "heyholmes",
                  "text": "I‚Äôve been trying to get it to work with the smoothMix model, but not great results thus far",
                  "score": 2,
                  "created_utc": "2026-01-02 18:05:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxfmaw0",
          "author": "BoredHobbes",
          "text": "now all we need is a better lip sync",
          "score": 1,
          "created_utc": "2026-01-03 13:15:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxpw964",
          "author": "Amelia_Amour",
          "text": "It's strange, but with each subsequent step my video starts to speed up. And already by step 4-5 everything happens too fast.",
          "score": 1,
          "created_utc": "2026-01-04 23:33:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3k8ja",
          "author": "olvastam74",
          "text": "could this be used for single frame (image) generation on a mac studio M2 ultra 64GB RAM? I can run Wan 2.2 successfully (about 3 minutes for one frame at 14 steps)",
          "score": 1,
          "created_utc": "2026-01-06 23:10:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxafy73",
          "author": "Juana_Dela_Cruz",
          "text": "Links for all GGUFs for this please.",
          "score": -1,
          "created_utc": "2026-01-02 17:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9vjvw",
          "author": "Low-Connection5599",
          "text": "Meu comfyui portable n√£o permite abrir workflows, e quando abre, n√£o me permite baixar os nodes faltantes. Sempre d√° erro de conex√£o.\n\n  \nMy comfyui portable doesn't allow me to open workflows, and when it does, it doesn't allow me to download the missing nodes. Always gives connection error.",
          "score": -2,
          "created_utc": "2026-01-02 16:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa3v2f",
          "author": "nylaeth",
          "text": "my bih so bad she cant even go online",
          "score": -2,
          "created_utc": "2026-01-02 16:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa1nog",
          "author": "InternationalOne2449",
          "text": "I'm never gonna have good and fast videos on my 12 gigs...",
          "score": -5,
          "created_utc": "2026-01-02 16:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxal0ry",
              "author": "Etsu_Riot",
              "text": "I have 10 gigs. My videos may not be the best, but they are not that terrible. You are fine.",
              "score": 3,
              "created_utc": "2026-01-02 18:13:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxauq5z",
                  "author": "Ok_Barber_1827",
                  "text": "Dis you manage to run this on 10gb vram ? I lost Connection while trying another svi one",
                  "score": 1,
                  "created_utc": "2026-01-02 18:58:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxamtnw",
                  "author": "InternationalOne2449",
                  "text": "It takes too long.",
                  "score": -1,
                  "created_utc": "2026-01-02 18:22:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pz00rd",
      "title": "ComfyUI repo will moved to Comfy Org account by Jan 6",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1pz00rd/comfyui_repo_will_moved_to_comfy_org_account_by/",
      "author": "crystal_alpine",
      "created_utc": "2025-12-29 22:18:17",
      "score": 225,
      "num_comments": 43,
      "upvote_ratio": 0.98,
      "text": "Hi everyone,\n\nTo better support the continued growth of the project and improve our internal workflows, we are going to officially moved the **ComfyUI** repository from the u/comfyanonymous account to its new home at the [Comfy-Org](https://github.com/comfy-org) organization. We want to let you know early to set clear expectations, maintain transparency, and make sure the transition is smooth for users and contributors alike.\n\n# What does this mean for you?\n\n* **Redirects:** No need to worry, **GitHub will automatically redirect all existing links, stars, and forks to the new location**.\n* **Action Recommended:** While redirects are in place, we recommend updating your local git remotes to point to the new URL: [`https://github.com/comfy-org/ComfyUI.git`](https://github.com/comfy-org/ComfyUI.git)\n   * Command:\n      * `git remote set-url origin https://github.com/Comfy-Org/ComfyUI.git`\n   * You can do this already as we already set up the current mirror repo in the proper location.\n* **Continuity:** This is an organizational change to help us manage the project more effectively.\n\n# Why we‚Äôre making this change?\n\nAs ComfyUI has grown from a personal project into a cornerstone of the generative AI ecosystem, we want to ensure the infrastructure behind it is as robust. Moving to **Comfy Org** allows us to:\n\n* **Improve Collaboration:** An organization account allows us to manage permissions for our growing core team and community contributors more effectively. This will allow us to transfer individual issues between different repos\n* **Better Security:** The organization structure gives us access to better security tools, fine-grained access control, and improved project management features to keep the repo healthy and secure.\n* **AI and Tooling:** Makes it easier for us to integrate internal automation, CI/CD, and AI-assisted tooling to improve testing, releases, and contributor change review over time.\n\n# Does this mean it‚Äôs easier to be a contributor for ComfyUI?\n\nIn a way, yes. For the longest time, the repo only had a single person (comfyanonymous) to review and guarantee code quality. While this list of people is still small now as we bring more people onto the project, we are going to do better overtime to accept more community input to the codebase itself and **eventually setup longterm open governance structure for the ownership of the project**.\n\n\n\nOur commitment to open source remains the same, this change will push us to further enable even more community collaboration, faster iteration, and a healthier PR and review process as the project continues to scale.\n\n\n\nThank you for being part of this journey!",
      "is_original_content": false,
      "link_flair_text": "Comfy Org",
      "permalink": "https://reddit.com/r/comfyui/comments/1pz00rd/comfyui_repo_will_moved_to_comfy_org_account_by/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nwmla4s",
          "author": "crystal_alpine",
          "text": "For anyone who is worried that this will break your setup, we previously did this for ComfyUI Manager (from `https://github.com/ltdrdata/ComfyUI-Manager.git` to `https://github.com/Comfy-Org/ComfyUI-Manager`), there wasn't any issue with that process. Eveyrthing will work as intended.",
          "score": 50,
          "created_utc": "2025-12-29 22:37:20",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwo161h",
              "author": "howardhus",
              "text": "this comment has full potential to get famous",
              "score": 36,
              "created_utc": "2025-12-30 03:21:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwop832",
                  "author": "crystal_alpine",
                  "text": "[r/agedlikemilk](https://reddit.com/r/agedlikemilk)",
                  "score": 18,
                  "created_utc": "2025-12-30 05:57:58",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmilfa",
          "author": "emplo_yee",
          "text": "as long as it's still comfy!",
          "score": 47,
          "created_utc": "2025-12-29 22:23:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmnvmo",
              "author": "crystal_alpine",
              "text": "More Comfy than ever ü´°",
              "score": 31,
              "created_utc": "2025-12-29 22:50:55",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nws5slo",
              "author": "Different-Toe-955",
              "text": "**gets dragged into the abyss with wires**",
              "score": 1,
              "created_utc": "2025-12-30 19:19:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmykso",
          "author": "lazyspock",
          "text": "Just to say a big thank you for Comfy. It's certainly hard work to maintain the repo and sometimes we forget to let you know how grateful we are.",
          "score": 47,
          "created_utc": "2025-12-29 23:48:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmqiu3",
          "author": "FugueSegue",
          "text": "Will you update the portable installer so that it points to the new location?",
          "score": 5,
          "created_utc": "2025-12-29 23:05:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmrz69",
              "author": "crystal_alpine",
              "text": "Yes, and you don‚Äôt need to do anything",
              "score": 8,
              "created_utc": "2025-12-29 23:12:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwno265",
          "author": "jingtianli",
          "text": "HiÔºÅ where I should type in this command? Under comfyui main folder? Or the update folder in portable version? \t‚Å†git remote set-url origin https://github.com/Comfy-Org/ComfyUI.git",
          "score": 3,
          "created_utc": "2025-12-30 02:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtu1bv",
              "author": "crystal_alpine",
              "text": "You don't have to do anything. If you are not super familiar with cmdline and git, it's better to just let automatic redirecting do the work here üôè",
              "score": 2,
              "created_utc": "2025-12-31 00:20:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwut4fb",
                  "author": "jingtianli",
                  "text": "Thank you very much and i got it working",
                  "score": 1,
                  "created_utc": "2025-12-31 03:43:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmitqv",
          "author": "alisitskii",
          "text": "Should I update anything in my local ComfyUI portable to keep downloading updates from correct source? I use update.bat in the update folder. If so can you please provide a little more info. Thank you.",
          "score": 6,
          "created_utc": "2025-12-29 22:24:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmix8d",
              "author": "crystal_alpine",
              "text": "No need to update anything, Github will help auto redirect everything.",
              "score": 8,
              "created_utc": "2025-12-29 22:25:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwmmsvg",
                  "author": "noyart",
                  "text": "github the real hero <3",
                  "score": 7,
                  "created_utc": "2025-12-29 22:45:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwmqj3y",
          "author": "Some_Artichoke_8148",
          "text": "Does this affect running comfy in runpod ?",
          "score": 2,
          "created_utc": "2025-12-29 23:05:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwms0dv",
              "author": "crystal_alpine",
              "text": "Nope",
              "score": 2,
              "created_utc": "2025-12-29 23:13:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwmsg4r",
                  "author": "Some_Artichoke_8148",
                  "text": "Ok thanks. Good luck !",
                  "score": 1,
                  "created_utc": "2025-12-29 23:15:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrq8zj",
          "author": "TekaiGuy",
          "text": "ComfyUI is one of the best things since sliced bread, thanks for making this diamond.",
          "score": 2,
          "created_utc": "2025-12-30 18:07:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmjwdm",
          "author": "coastisthemost",
          "text": "Will updating comfy ui through the manager still work?",
          "score": 2,
          "created_utc": "2025-12-29 22:30:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmkyxy",
              "author": "crystal_alpine",
              "text": "Yes, everything wil work as usually, no need to change anything, but if you want no redirect, you can update your local git remote to `https://github.com/Comfy-Org/ComfyUI.git`",
              "score": 9,
              "created_utc": "2025-12-29 22:35:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwn7xwg",
          "author": "Lil_Twist",
          "text": "It‚Äôs amazing to me I even understand what you said at the very beginning and what anyone in the IT space would be most concerned about. \n\nThe part I clearly understood the most was the need from a financial and risk management perspective due to exponential company resource and user demand. That‚Äôs when I was very pleasantly surprised how proactive and transparent y‚Äôall are in the upcoming change.\n\nI may not be dependent on your service and platform, but I‚Äôm having fun learning new skills I never thought I would be capable of. But most importantly, thankful for you and your teams stewardship and community driven support!",
          "score": 2,
          "created_utc": "2025-12-30 00:39:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo44q9",
          "author": "OkBill2025",
          "text": "How would I do it for Stability Matrix? I'm confused üòî",
          "score": 2,
          "created_utc": "2025-12-30 03:38:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwohiwz",
              "author": "SpaceNinjaDino",
              "text": "Pretty sure you don't have to do anything and updating Stability Matrix itself will work this change in as well.",
              "score": 3,
              "created_utc": "2025-12-30 05:02:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmwwz8",
          "author": "Imagineer_NL",
          "text": "Do all the (open and closed) issues get moved as well?",
          "score": 1,
          "created_utc": "2025-12-29 23:39:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwn7w53",
              "author": "crystal_alpine",
              "text": "Issues and PRs will also get moved",
              "score": 4,
              "created_utc": "2025-12-30 00:39:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwngi67",
          "author": "DigThatData",
          "text": "fancy",
          "score": 1,
          "created_utc": "2025-12-30 01:27:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnkcso",
          "author": "Green-Ad-3964",
          "text": "Any fork staying on GitHub?",
          "score": 1,
          "created_utc": "2025-12-30 01:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwoky3v",
          "author": "Afraid_Relationship9",
          "text": "This is a smart move!, excited to see ComfyUI maturing into production grade infrastructure. Proud to be witness of this evolution!",
          "score": 1,
          "created_utc": "2025-12-30 05:26:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwopm1t",
          "author": "Snoo20140",
          "text": "Do we need to update custom nodes that we have made?",
          "score": 1,
          "created_utc": "2025-12-30 06:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrn4zt",
          "author": "iWhacko",
          "text": "Isn't this something that should be featured heavilty on the github page? I mean, I'm sure this account is verified, but this is exactly how hostile takeovers work. Asking people to update links before an official move.",
          "score": 1,
          "created_utc": "2025-12-30 17:53:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrujrm",
          "author": "lookatthisbaby",
          "text": "End of an era!",
          "score": 1,
          "created_utc": "2025-12-30 18:27:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9szy6",
          "author": "Low-Connection5599",
          "text": "Me pergunto por que a vers√£o port√°til do comfyui √© t√£o sensivel que se quebra f√°cilmente ao adicionar custom nodes ou apenas instalar o suporte a nvidia e sagge?\n\nI wonder why the portable version of comfyui is so sensitive that it breaks easily when adding custom nodes or just installing nvidia and sagge support?",
          "score": 1,
          "created_utc": "2026-01-02 16:03:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb2w8f",
          "author": "Minimum-Let5766",
          "text": "I noticed the tags are completely different.  For example, as of this moment, the latest tag for comfyanonymous is 'v0.7.0', but for Comfy-Org, the latest tag is 'v0.1.1114'.",
          "score": 1,
          "created_utc": "2026-01-02 19:37:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnakm7",
          "author": "PixWizardry",
          "text": "I always git clone, will this feature remain? And I always review the commits, will that remain?\n\nAnd most importantly what happened to ‚ÄúComfy anonymous‚Äù? ????\n\nAlso , are you planning to make it close source?",
          "score": 1,
          "created_utc": "2025-12-30 00:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr4ehp",
              "author": "crystal_alpine",
              "text": "No, I don‚Äôt know how many times I have to re-iterate, we will always be open source",
              "score": 3,
              "created_utc": "2025-12-30 16:26:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr4t5r",
                  "author": "PixWizardry",
                  "text": "Thank you!",
                  "score": 1,
                  "created_utc": "2025-12-30 16:28:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwou38w",
              "author": "LindaSawzRH",
              "text": "Of course. Slippery slope not today, not tomorrow, but definitely coming. Meanwhile, \"open source champion\" Comfy (the actual developer) is hiding behind tough guy.",
              "score": -3,
              "created_utc": "2025-12-30 06:37:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwo03hm",
          "author": "SackManFamilyFriend",
          "text": "Sell outs.",
          "score": -6,
          "created_utc": "2025-12-30 03:15:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmqx5c",
          "author": "bradjones6942069",
          "text": "Dead project. What's next?",
          "score": -25,
          "created_utc": "2025-12-29 23:07:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmrqw7",
              "author": "_CreationIsFinished_",
              "text": "Ragebait? What kind of a silly (and objectively \\*very\\* erroneous) thing is that to say?",
              "score": 12,
              "created_utc": "2025-12-29 23:11:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q06s82",
      "title": "THE BEST ANIME2REAL/ANYTHING2REAL WORKFLOW!",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1q06s82",
      "author": "OneTrueTreasure",
      "created_utc": "2025-12-31 07:09:50",
      "score": 218,
      "num_comments": 92,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1q06s82/the_best_anime2realanything2real_workflow/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nx3uc4h",
          "author": "Kurokage_Black",
          "text": "Just in case it helps people find the models and lora and such used here, I think I found:\n \n**Models:**\n\n*  Qwen: [Qwen-image Edit Anything to Real CharactersÂä®Êº´ËΩ¨Áúü‰∫∫.safetensors](https://huggingface.co/WarmBloodAban/Anything_to_Real_Characters/tree/main)\n* SDXL: [majicMIX realistic È∫¶Ê©òÂÜôÂÆû_v7_250803.safetensors](https://civitai.com/models/43331/majicmix-realistic)\n* Z-Image: [moodyPornMix_zitV3.safetensors](https://civitai.com/models/620406/moody-porn-mix) (NSFW)\n* Qwen Image Edit: [qwen_image_edit_2511_fp8mixed.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI/blob/main/split_files/diffusion_models/qwen_image_edit_2511_fp8mixed.safetensors)\n\n**LORA:**\n\n* **Qwen**\n * [Qwen_Snorfs_1_2.safetensors](https://huggingface.co/Mattimus1/SNOFS/tree/main)\n * [Korean_qwen.safetensors](https://civitai.com/models/2233187?modelVersionId=2528874)\n * [Skin_Fix_rank64.safetensors](https://civitai.com/models/2031296/skin-fix-qwen)\n * [Kook_Qwen_V3ÊûÅËá¥ÁúüÂÆû.safetensors](https://modelscope.cn/models/KookYan/Kook_Qwen_JIZHIZHENSHI/summary?version=20250905153225)\n * [yky_000032000.safetensors](https://civitai.com/models/2130705/qwen-image-nsfw-anime-and-realistic) (NSFW)\n * [Qwen-Image-Lightning-8steps-V2.0 bf16.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/blob/main/Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors)\n* **Qwen Image Edit**\n * [qwen_image_edit_2511_upscale.safetensors](https://huggingface.co/valiantcat/Qwen-Image-Edit-2511-Upscale2K/tree/main)\n * [Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Edit-2511-Lightning/blob/main/Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors)\n\n\n**Controlnet:**\n\n* [Z-Image-Turbo-Fun-Controlnet-Tile-2.1-8steps.safetensors](https://civitai.com/models/2186383?modelVersionId=2461802)\n\n**CLIP:**\n\n* [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/blob/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)",
          "score": 7,
          "created_utc": "2026-01-01 17:19:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx4na5p",
              "author": "g_nautilus",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-01-01 19:44:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx7qkc0",
              "author": "OneTrueTreasure",
              "text": "Thanks for linking them :) You can also use this as it is the same model\n\n [https://civitai.com/models/2146265/the-strongest-anything-to-real-charactersqwen-image-edit-2509](https://civitai.com/models/2146265/the-strongest-anything-to-real-charactersqwen-image-edit-2509)",
              "score": 1,
              "created_utc": "2026-01-02 06:50:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvt3kd",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/ef7ssx6d1iag1.png?width=2048&format=png&auto=webp&s=c75dc8c80cae908b197fdce259207421f411eb6b\n\nFULL PNG\n\nedit: nvm downloading this won't work as the workflow because of Reddit ig",
          "score": 8,
          "created_utc": "2025-12-31 08:22:00",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwvtuz0",
              "author": "UndoubtedlyAColor",
              "text": "Tried it and seems like it stripped meta data from the image.\n\nIf you want to save it as .JSON you can go to File->Export\n\nThe pastebin site is probably the easiest way to share the text workflow üôÇ",
              "score": 3,
              "created_utc": "2025-12-31 08:29:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvuhra",
                  "author": "OneTrueTreasure",
                  "text": "I just tried it and it says \n\nPastebin‚Äôs SMART filters have detected potentially offensive or questionable content in your Paste. The content you are trying to publish has been deemed potentially offensive or questionable by our filters, because of this you‚Äôre receiving this warning. This Paste can only be published with the visibility set to \"Private\".\n\nwhat should I do?",
                  "score": 4,
                  "created_utc": "2025-12-31 08:35:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwxj51c",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2025-12-31 15:54:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx1k5pj",
                  "author": "OneTrueTreasure",
                  "text": "The best is subjective bro, like someone in my other post commented a picture of a girl cosplaying from some Anime Convention. I have been to Anime Cons and this is not a cosplay kind of workflow. There are loras specifically for that use case. This was to my own taste really, I wanted Anime girls turned into  unrealistically attractive women. And plus this is my first ever workflow I legit just started using ComfyUI a couple days ago",
                  "score": 1,
                  "created_utc": "2026-01-01 06:19:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx0cgm1",
          "author": "Electronic-Metal2391",
          "text": "Thanks for sharing this. As you requested, I cleaned up the workflow. I added another upscale method (QWEN Edit 2511) which I think better than SeedVR. SeedVR is still there just bypassed. The workflow is horizontal rather than cramped over each other. It is divided into sections as per the developer (QWEN, SDXL, Detailers, zimage, controlnet, upscale by QIE 2511 and then optional upscale by seedvr. I did not alter settings or lines wiring. This is the original workflow just untangled so you know how it flows by looking at it. I did not run it after cleaning it, because I don't have the models and some nodes are missing (tagger and seedvr2) and since I don't have use for this concept, I didn't feel like downloading everything. Again, the workflow should work as if it was the original. I didn't alter or change anything in the original workflow. Kudos to the author, he/she put thinking into his/her workflow.\n\n[https://drive.google.com/file/d/18ttI8\\_32ytCjg0XecuHPrXJ4E3gYCw\\_W/view?usp=sharing](https://drive.google.com/file/d/18ttI8_32ytCjg0XecuHPrXJ4E3gYCw_W/view?usp=sharing)\n\nhttps://preview.redd.it/qh0hiyba0nag1.jpeg?width=1908&format=pjpg&auto=webp&s=5a1a30dc29e4b2c2a71e7cde88cc31cf2462a4ca",
          "score": 6,
          "created_utc": "2026-01-01 01:03:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1llzj",
              "author": "OneTrueTreasure",
              "text": "holy shit thank you bro! I legit just started using ComfyUI a couple days ago so I'm still learning alot! Happy New Year!",
              "score": 3,
              "created_utc": "2026-01-01 06:32:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx1lqnx",
                  "author": "OneTrueTreasure",
                  "text": "I will put this in the post since I am very grateful!",
                  "score": 2,
                  "created_utc": "2026-01-01 06:34:02",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx1x3vi",
              "author": "OneTrueTreasure",
              "text": "the get\\_nodes for the models are not working for some reason, I manually connected them and it worked, any idea why? I haven' really used the get and set nodes before. All the other ones work perfectly :)",
              "score": 1,
              "created_utc": "2026-01-01 08:28:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx392f9",
                  "author": "Electronic-Metal2391",
                  "text": "This should work now.\n\n[https://drive.google.com/file/d/19GJe7VIImNjwsHQtSKQua12-Dp8emgfe/view?usp=sharing](https://drive.google.com/file/d/19GJe7VIImNjwsHQtSKQua12-Dp8emgfe/view?usp=sharing)",
                  "score": 1,
                  "created_utc": "2026-01-01 15:25:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx3sc5e",
              "author": "Kurokage_Black",
              "text": "When I load this I get:\n\n>**Error:**\n\n>No link found in parent graph for id [292] slot [0] image\n\n>**Workflow Validation**\n\n>678 is funky... target(292).inputs[0].link is NOT correct (is 446), but origin(243).outputs[0].links contains it\n\n> \\> [PATCH] target(292).inputs[0].link is defined, removing 678 from origin(243).outputs[0].links.\n678 is def invalid; BOTH origin node 243 doesn't have 678 and 243 target node doesn't have 678.\nDeleting link #678.\nsplicing 65 from links\nMade 1 node link patches, and 1 stale link removals.\n\nNot sure if it will matter in the end (I'm still looking for models and lora and such), but just thought I'd bring it up in case it warrants attention. (Or maybe it's just me?)",
              "score": 1,
              "created_utc": "2026-01-01 17:09:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx41dla",
                  "author": "Electronic-Metal2391",
                  "text": "Link the image to the tagger node in the first group. I think I forgot to link it.\n\nUse the updated workflow:\n\n[https://drive.google.com/file/d/19GJe7VIImNjwsHQtSKQua12-Dp8emgfe/view?usp=sharing](https://drive.google.com/file/d/19GJe7VIImNjwsHQtSKQua12-Dp8emgfe/view?usp=sharing)",
                  "score": 1,
                  "created_utc": "2026-01-01 17:55:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvsh3v",
          "author": "anydezx",
          "text": "Now yt's going to be flooded with those anime character transformation videos. It would be hilarious if they saturated that market; it gets tons of views! Seriously!üëå",
          "score": 8,
          "created_utc": "2025-12-31 08:16:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvspj6",
              "author": "OneTrueTreasure",
              "text": "No need for nanobanana when you have this workflow ;)",
              "score": 5,
              "created_utc": "2025-12-31 08:18:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvtnkb",
                  "author": "anydezx",
                  "text": "You don't really need anything; Flux Kontext dev, Qwen Edit, and their variants already did it natively. Keep in mind that there're now LoRas and you get better results; this workflow's a good example. Just yesterday, I was surprised to see one of those transformation videos on yt with millions of views, and I thought, \"Why didn't I do it myself?\" But it's an opportunity for many new CC to generate income, since these videos're monetizable. As long as they don't use characters brands like Marvel and similar ones, there's no problem!üëå",
                  "score": 2,
                  "created_utc": "2025-12-31 08:27:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwxl53i",
              "author": "ptwonline",
              "text": "A few years back and it would have been nothing but \"realistic\" Bioshiock Elizabeths running around doing who knows what lol.",
              "score": 2,
              "created_utc": "2025-12-31 16:04:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvt883",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/0l8hucju1iag1.png?width=2048&format=png&auto=webp&s=840d3141909278b2d12b0d0f1d2e885c7b87a0d2\n\nFULL PNG EXAMPLE",
          "score": 5,
          "created_utc": "2025-12-31 08:23:14",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwvwmak",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/0e48ra6m7iag1.jpeg?width=2048&format=pjpg&auto=webp&s=fe2a956397c643fef30ae46a1f3e3f0d2363a06e",
          "score": 3,
          "created_utc": "2025-12-31 08:55:22",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nww89rk",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/bydrddtariag1.png?width=2048&format=png&auto=webp&s=8df8abed94b521fd4f834241fb3c51e382faeb13",
          "score": 2,
          "created_utc": "2025-12-31 10:45:49",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nww8rni",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/a7vy4dm4siag1.png?width=2048&format=png&auto=webp&s=3731c1dcb0778b32f3aa33ef9da50af9cbf7c0fb",
          "score": 2,
          "created_utc": "2025-12-31 10:50:27",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nww4jvq",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/tuzd03i3liag1.png?width=2048&format=png&auto=webp&s=a2ebbec94fce3ed3badca7a5c020bbc0f44552de",
          "score": 1,
          "created_utc": "2025-12-31 10:11:04",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nww72sc",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/k4epmgebpiag1.png?width=2048&format=png&auto=webp&s=336d939b80aac1c2d2dfcd6876a6ad3dee44bb87",
          "score": 1,
          "created_utc": "2025-12-31 10:34:44",
          "is_submitter": true,
          "replies": [
            {
              "id": "nww78qc",
              "author": "OneTrueTreasure",
              "text": "![gif](giphy|8UdbDVaUtYNhK)",
              "score": 0,
              "created_utc": "2025-12-31 10:36:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwd0a2",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/8v1ioil0ziag1.png?width=2048&format=png&auto=webp&s=6357ad9b6931ec2ca8bc5f1a86808a9ff5318840",
          "score": 1,
          "created_utc": "2025-12-31 11:29:04",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwwec3v",
          "author": "OneTrueTreasure",
          "text": "Just by changing the Z-Image diffusion model to \"BeyondRealityZ\" and the SD1.5 face detailer checkpoint to \"Cyberrealisticv6\" you will get this kinda image!\n\nhttps://preview.redd.it/use9n2241jag1.png?width=2048&format=png&auto=webp&s=fb8a49cbb870bccdd3159943a695677c4a64778d",
          "score": 1,
          "created_utc": "2025-12-31 11:40:51",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwwvegw",
          "author": "SwingNinja",
          "text": "Looks like it captures almost everything, including the background. Can it also capture the face expression (like the mouth)?",
          "score": 1,
          "created_utc": "2025-12-31 13:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1kc4d",
              "author": "OneTrueTreasure",
              "text": "yes, you will just have to skip the face detailer, you can also prompt for it multiple ways (with the QwenImage part and the Z-Image part. I have added Text Boxes to both so it is customizable.",
              "score": 1,
              "created_utc": "2026-01-01 06:21:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxjkdk",
          "author": "Other_b1lly",
          "text": "Which is better?\nAnything or a pony?",
          "score": 1,
          "created_utc": "2025-12-31 15:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyvc1f",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2025-12-31 19:57:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzpv1g",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2025-12-31 22:45:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx0vbuw",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-01 03:08:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx063bs",
          "author": "nikgrid",
          "text": "OP I've installed the Seedvr2 custom nodes from the git, updated comfyui...but cannot find the SEEDVR2BLOCKSWAP, SEEDVR2EXTRAARGS, SEEDVR2 nodes at all. Any ideas?",
          "score": 1,
          "created_utc": "2026-01-01 00:24:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1klur",
              "author": "OneTrueTreasure",
              "text": "the one I am using is the old SEEDVR2 version from a couple weeks ago or so. The new version is on ComfyUI Manager. The new node has DIT and VAE as the inputs, and it is only 4 nodes in the folder. They both do the same exact thing, so you do not need SEEDVR2ExtraArgs or SEEDVR2BlockSwap",
              "score": 2,
              "created_utc": "2026-01-01 06:23:36",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx0y7r9",
              "author": "Practical_Support126",
              "text": "You need to fix that path in the environment. You can ask Co-pilot on how to install it.",
              "score": 1,
              "created_utc": "2026-01-01 03:27:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx1l5ik",
              "author": "OneTrueTreasure",
              "text": "https://preview.redd.it/mb1p6777moag1.png?width=1476&format=png&auto=webp&s=27bcc0621e7b140d1a57526dda87dd240d0b1fc3\n\nthe new SEEDVR2 version looks something like this, you can play around with the input noise and all the other stuff since idk the right settings for this either",
              "score": 1,
              "created_utc": "2026-01-01 06:28:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx1lg8b",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/acd0zlbemoag1.png?width=1476&format=png&auto=webp&s=11b38405d61c1d36ab16b178ef24fd0ef5e6bc02\n\nFor people having trouble with SEEDVR2, it seems like I was using the version from a couple weeks or a month ago or something. The new one looks something like this. You just need to connect it exactly like this (Only dit and vae)",
          "score": 1,
          "created_utc": "2026-01-01 06:31:22",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nx2k0gk",
          "author": "Reasonable-Card-2632",
          "text": "Hey bro I don't like runninghub. What about your opinion on this. About speed, price",
          "score": 1,
          "created_utc": "2026-01-01 12:26:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2og2t",
              "author": "OneTrueTreasure",
              "text": "I'm pretty new to Runninghub too just started using it a few days ago, I think compared to Runpod or VastAI it is way cheaper and seems less complicated. There are also ways to generate NSFW on Runninghub so dm me if you wanna know how. As for speed it's definitely way faster than my 4070 Super, I think the $15 a month thing lets you use a 4090 which is more than plenty for my needs at least. I'm gonna look into Runninghub though since it seems way more customizable and powerful albeit pricier haha",
              "score": 1,
              "created_utc": "2026-01-01 13:05:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx4yww2",
          "author": "Kurokage_Black",
          "text": "https://preview.redd.it/8rc8wz0gusag1.png?width=1121&format=png&auto=webp&s=9d65da70ec62ef182d26bd691e5f8e3463e69e16\n\nGot it working!  I was getting blotchy repeating patterns with the Qwen upscaler, so I rebuilt the SeedVR one from the latest version as reccomended elsewhere here.  The workflow does a really good job!  Obviously the right is way downscaled to match the original on the left. But it did quite a lot with some old anime art.",
          "score": 1,
          "created_utc": "2026-01-01 20:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7qs4b",
              "author": "OneTrueTreasure",
              "text": "Glad you like it bro! Happy New Year :)",
              "score": 1,
              "created_utc": "2026-01-02 06:52:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx7r8sv",
              "author": "OneTrueTreasure",
              "text": "how fast are your gen times locally?",
              "score": 1,
              "created_utc": "2026-01-02 06:56:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx7vh0t",
                  "author": "Kurokage_Black",
                  "text": "Depends on how it's tweaked, but as I have it currently, about 3-4 minutes on a RTX4090.\n\nThe TextEncodeQwenImageEditPlus node often seems to take a fair amount of time on it's own, and from the console it seems like it's running on CPU for some reason, I don't see a way to change that to GPU. (changing from \"CPU\" to \"default\" still makes it run on CPU in the console it seems.\n\nThe SeedVR2 Upscaler probably takes up the biggest chunk of the time, but upscalers tend to be slow.",
                  "score": 1,
                  "created_utc": "2026-01-02 07:34:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx5i8d8",
          "author": "JohnnyLeven",
          "text": "Just curious. Is TextEncodeQwenImageEditPlus supposed to be the slowest part of the workflow, or do I have something set up wrong?\n\nEDIT: Nevermind. I figured it out. Load CLIP for QWEN was set to CPU instead of default for device.",
          "score": 1,
          "created_utc": "2026-01-01 22:24:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7r5zc",
              "author": "OneTrueTreasure",
              "text": "I see, hope you got it working :)",
              "score": 1,
              "created_utc": "2026-01-02 06:55:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx80uao",
                  "author": "OneTrueTreasure",
                  "text": "https://preview.redd.it/rnlihk3sbwag1.png?width=1650&format=png&auto=webp&s=3ab1c71412b98aae5909b0bedaad373b086bbd45\n\ntry this node out, might fix the issue :)  with this node you can remove the vae encode node since it is built-in on this one",
                  "score": 1,
                  "created_utc": "2026-01-02 08:25:06",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx7ybbi",
              "author": "OneTrueTreasure",
              "text": "https://preview.redd.it/x4gniifo7wag1.png?width=1727&format=png&auto=webp&s=2f13613eafc94efd9efb7420cdbae0fd4dba03a6\n\nPlease try these three nodes to see if it fixes the issue. I would also love to know what your generation times are for testing :)",
              "score": 1,
              "created_utc": "2026-01-02 08:01:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8dlsi",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/ibm5b2nnxwag1.png?width=2048&format=png&auto=webp&s=5437a8ee38bca44e432d04120badb106563ede02\n\nIt can do non-Asian btw",
          "score": 1,
          "created_utc": "2026-01-02 10:26:35",
          "is_submitter": true,
          "replies": [
            {
              "id": "nxakim3",
              "author": "This-Article9741",
              "text": "Hi!\n\nFirst of all, thank you so much for this amazing workflow and thread.\n\nHow can you generate non-Asian? Could you share the exact workflow and source image for this one?",
              "score": 1,
              "created_utc": "2026-01-02 18:11:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxe735y",
                  "author": "OneTrueTreasure",
                  "text": "Just switch the UNET/CHECKPOINTS/LOAD DIFFUSION MODELS around\n\nlike I had mine set to P\\*rnmaster for the Z-Image part and PureRealismMixXL for the face detailer part. You can use the face detailer with any SD1.5 or SDXL checkpoint so start there I'd say. You can also prompt for it",
                  "score": 1,
                  "created_utc": "2026-01-03 06:14:08",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx8el9u",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/ddn21o36zwag1.png?width=2048&format=png&auto=webp&s=7f700a8142df699e5722aaa092a129f40b27b9c2",
          "score": 1,
          "created_utc": "2026-01-02 10:35:49",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxlfwie",
          "author": "Martzafoi",
          "text": "Would this work on a multipanel hentai comic?",
          "score": 1,
          "created_utc": "2026-01-04 08:43:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlgskw",
              "author": "OneTrueTreasure",
              "text": "yeah it should, haven't tried it yet so let me know how it goes :) probably need to make them colored first",
              "score": 1,
              "created_utc": "2026-01-04 08:51:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvpl2s",
          "author": "inb4Collapse",
          "text": "The fidelity of the apparel is impressive in your examples",
          "score": 1,
          "created_utc": "2025-12-31 07:49:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvpvpr",
              "author": "OneTrueTreasure",
              "text": "Thank you! I spent all day cooking this up haha",
              "score": 1,
              "created_utc": "2025-12-31 07:51:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvsktb",
          "author": "UndoubtedlyAColor",
          "text": "Dude, why does the workflow download as a .bin file? Share it via something like pastebin instead..",
          "score": 1,
          "created_utc": "2025-12-31 08:17:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvswaj",
              "author": "OneTrueTreasure",
              "text": "ngl I have never made a workflow bro before this one so I wasn't sure on the sharing etiquette. I am also new to Comfy but I think if I post the full .PNG it should work as the .Jsonfile right?",
              "score": 3,
              "created_utc": "2025-12-31 08:20:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvteko",
                  "author": "UndoubtedlyAColor",
                  "text": "Fair enough. Usually these sites tries to hide the underlying workflows to lure users.\n\nA full .PNG file might work. Many image hosting sites strip meta data from images though so isn't guaranteed to work.",
                  "score": 2,
                  "created_utc": "2025-12-31 08:24:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvt52g",
              "author": "OneTrueTreasure",
              "text": "I have posted the full PNG file and it works as a workflow. I just tested it out :)",
              "score": 2,
              "created_utc": "2025-12-31 08:22:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvwu0n",
          "author": "Bronzeborg",
          "text": "https://preview.redd.it/qq2b00dz7iag1.png?width=1222&format=png&auto=webp&s=163d50093fca1bc67368887f0dc1dbc123080a27\n\ngee thanks.",
          "score": -1,
          "created_utc": "2025-12-31 08:57:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvx4s0",
              "author": "OneTrueTreasure",
              "text": "I am not sure what the issue is.",
              "score": 4,
              "created_utc": "2025-12-31 09:00:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvyesu",
                  "author": "Bronzeborg",
                  "text": "installing the nodes for your workflow broke my venv. had to delete it and reinstall.",
                  "score": 1,
                  "created_utc": "2025-12-31 09:12:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvvu6r",
          "author": "OneTrueTreasure",
          "text": "https://preview.redd.it/p1duqkp96iag1.png?width=2048&format=png&auto=webp&s=080440caab39f2b6e380bb0daf24fd98b312770a\n\nzoom in to see skin texture",
          "score": 0,
          "created_utc": "2025-12-31 08:48:01",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwvqrgo",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2025-12-31 08:00:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvqvik",
              "author": "OneTrueTreasure",
              "text": "![gif](giphy|UX6huwJfADuH9khCMl)",
              "score": 6,
              "created_utc": "2025-12-31 08:01:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwy715c",
          "author": "debayanmalo",
          "text": "Guys if you are looking to create and scale AI models in fanvue. I have a complete workflow setup to generate the best model in the market and all needed ai ofm courses of top agencies. Dm me on telegram - @ofmbundle if you are serious",
          "score": -1,
          "created_utc": "2025-12-31 17:53:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4h1ck",
      "title": "SVI infinite video, seamless transitions",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/1vup5i7mzhbg1",
      "author": "Advanced-Bottle-4911",
      "created_utc": "2026-01-05 09:14:41",
      "score": 217,
      "num_comments": 46,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q4h1ck/svi_infinite_video_seamless_transitions/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxswdas",
          "author": "Edenoide",
          "text": "Workflow or it didn't happen",
          "score": 33,
          "created_utc": "2026-01-05 11:46:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsx1t0",
              "author": "Advanced-Bottle-4911",
              "text": "Here are the features of this workflow:\n\nModels : smoothMixWan22i2v_HIGH.safetensors\nsmoothMixWan22i2v_LOW.safetensors\nhttps://civitai.com/models/1995784/smooth-mix-wan-22-i2vt2v-14b\n\nLightning LORas : SVI_v2_PRO_Wan2.2-I2V-A14B_LOW_lora_rank_128_fp16.safetensors\nSVI_v2_PRO_Wan2.2-I2V-A14B_HIGH_lora_rank_128_fp16.safetensors\nhttps://huggingface.co/Kijai/WanVideo_comfy/blob/main/LoRAs/Stable-Video-Infinity/v2.0/SVI_v2_PRO_Wan2.2-I2V-A14B_HIGH_lora_rank_128_fp16.safetensors\n\nModel loader node:\nDiffusion Model Loader KJ, check weight_dtype = fp8_e4m3fn and enable_fp16_accumulation = true \n\nImage To Video node:\nWanImageToVideoSVIPro edited by KJ nodes. The anchor_samples slot concerns finally one sample: the start image",
              "score": 14,
              "created_utc": "2026-01-05 11:51:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxv4u50",
                  "author": "DeepHomage",
                  "text": "What is the github link to \"WanImageToVideoSVIPro edited by JJ nodes.\"?  Would be wonderful if all workflow posters included links in the WF itself pointing to the obscure custom nodes that only 5 people on Earth know about.",
                  "score": 2,
                  "created_utc": "2026-01-05 18:49:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxv1l0z",
                  "author": "ptwonline",
                  "text": "I tried Smoothmix (GGUF) with a different SVI workflow and when I do that it completely ignores my starting image.  I wonder why it works for this workflow.\n\nFYI it was this one:  https://civitai.com/models/1866565/wan22-continuous-generation-svi-native-gguf?modelVersionId=2559451",
                  "score": 1,
                  "created_utc": "2026-01-05 18:35:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxx7pvy",
                  "author": "Spare_Ad2741",
                  "text": "thanks for posting. workflow works well enough, seems to be ignoring input image and makes chunk clips solely based on prompt chunk text boxes. no relation to input image. i created an input image similar to yours...\n\nhttps://preview.redd.it/hh303e2xmmbg1.png?width=1040&format=png&auto=webp&s=f59b591b96d6c5c80e76d8ef6ee1894b6aeea836",
                  "score": 1,
                  "created_utc": "2026-01-06 00:52:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxsxunm",
              "author": "Advanced-Bottle-4911",
              "text": "Workflow here:\n\nhttps://we.tl/t-OaYEROMbY7",
              "score": 31,
              "created_utc": "2026-01-05 11:58:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxtsyhf",
                  "author": "PaulDallas72",
                  "text": "Thanks!",
                  "score": 3,
                  "created_utc": "2026-01-05 15:08:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxvkxr1",
                  "author": "harrro",
                  "text": "This is the first SVI workflow that has worked well for me. Thank you!",
                  "score": 2,
                  "created_utc": "2026-01-05 20:03:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxsx9s8",
              "author": "Advanced-Bottle-4911",
              "text": "https://preview.redd.it/zu1n4wxzribg1.png?width=758&format=png&auto=webp&s=bf172f0a291283dbe3db7db39a2f89e59ab09f66",
              "score": 6,
              "created_utc": "2026-01-05 11:53:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxwn1ua",
                  "author": "somethingwnonumbers",
                  "text": "16 GB VRAM enough for this workflow? How many frames can it handle?",
                  "score": 1,
                  "created_utc": "2026-01-05 23:04:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxt2rbw",
          "author": "xbobos",
          "text": "In my case, the slow-motion issue with SVI is quite serious, and the prompt adherence rate is also very low. Have you used any special methods to fix this?",
          "score": 10,
          "created_utc": "2026-01-05 12:34:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtwvj7",
              "author": "grmndzr",
              "text": "some don't like this checkpoint but I find that [smoothmix](https://civitai.com/models/1995784?modelVersionId=2260110) helps with motion/speed a ton",
              "score": 2,
              "created_utc": "2026-01-05 15:27:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxthsle",
          "author": "Straight_Fish_704",
          "text": "AI people in videos always look so complacent and confused.",
          "score": 17,
          "created_utc": "2026-01-05 14:08:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxuqo7q",
              "author": "Awaythrowyouwilllll",
              "text": "You would too if someone gave you random instructions with no motivation!!¬†\n\nWe need method AiCTORS^^tm with lifetimes measured in epochs, flipping pages at sitting at desks. Jared Letto watch out...",
              "score": 11,
              "created_utc": "2026-01-05 17:46:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxvdfrp",
                  "author": "Straight_Fish_704",
                  "text": "*\"You would too if someone gave you random instructions with no motivation!!*¬†\n\nSounds like my parents. Wait, am I AI? :O",
                  "score": 5,
                  "created_utc": "2026-01-05 19:28:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxsixj4",
          "author": "GRCphotography",
          "text": "waaaaaaait a min......",
          "score": 4,
          "created_utc": "2026-01-05 09:50:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxt5rf7",
          "author": "TekaiGuy",
          "text": "When you're trying to buy time until HR gets there to pull Gerald away from your desk.",
          "score": 2,
          "created_utc": "2026-01-05 12:55:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtbk8d",
          "author": "hereforthefundoc",
          "text": "One issue I still see is that the initial character morphs and changes as you extend. If a garment, face or any other object falls of the frame is game over.\n\nDoes anyone have recommendations on how to deal with that?",
          "score": 2,
          "created_utc": "2026-01-05 13:32:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtw6ou",
              "author": "ptwonline",
              "text": "AFAIK it's the same as the previous \"generate I2V and stitch them together manually\" process: if it's important to keep consistent then you need to keep it in frame, have a lora for it, or use some kind of FLF process.\n\nSo far I'm having issues with prompt adherence and because the SVI workflow I am trying is somewhat different than what I had been using for I2V. I'm still trying to figure out some of the extra loras I often use and finding the settings to avoid getting weird movement from them, like shakiness or very fast movement.",
              "score": 4,
              "created_utc": "2026-01-05 15:24:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxdsh3",
                  "author": "ANR2ME",
                  "text": "The difference between SVI (and other similar long video models) than traditional/manually stitched 5 seconds videos, is that manually stitched videos only use 1 last frame of previous video as the start frame of next video, while these long video models are using more than 1 frames to keep the motion across videos seamless.\n\nSome long video models also played with context window and KV cache to improve the consistency.",
                  "score": 1,
                  "created_utc": "2026-01-06 01:24:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxvbvwg",
              "author": "JohnnyLeven",
              "text": "There are face replace workflows that I'm sure you could incorporate in some way. I haven't tried them out though, so I can't help more than that.",
              "score": 1,
              "created_utc": "2026-01-05 19:21:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxuzzmj",
          "author": "Beneficial_Fly_2817",
          "text": "https://preview.redd.it/yt98fb9aqkbg1.png?width=1710&format=png&auto=webp&s=f4f8a05df2ef5ab14061e7a91faf201da108d7dd\n\nHi! Do you have an idea how to fix it? Thank you.",
          "score": 2,
          "created_utc": "2026-01-05 18:28:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvxtel",
              "author": "dericn",
              "text": "I had the same issue and ended up having to reinstall KJNodes.\n\nhttps://www.youtube.com/watch?v=-3DVJu72VhE&t=1091s\n\nIf updating KJNodes doesn't fix it, delete the ComfyUI-KJNodes folder in the Custom Nodes directory and reinstall KJNodes. See the 'installation' section here:\n\nhttps://github.com/kijai/ComfyUI-KJNodes\n\nThat worked for me.",
              "score": 2,
              "created_utc": "2026-01-05 21:03:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu4h00",
          "author": "EpicNoiseFix",
          "text": "You can still where it transitions because with each generation, it‚Äôs essentially a new generation. So she goes from looking at her book to half turning the page because that was last frame but since it‚Äôs a new generation she looks at the printer. The transitions are not seamless if they look and feel disjointed",
          "score": 3,
          "created_utc": "2026-01-05 16:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtqwnj",
          "author": "Winougan",
          "text": "Thank you. I'll try out your workflow.",
          "score": 1,
          "created_utc": "2026-01-05 14:57:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu8eel",
          "author": "Silly_Goose6714",
          "text": "Is the audio mmaudio?",
          "score": 1,
          "created_utc": "2026-01-05 16:21:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxuf3n9",
              "author": "Advanced-Bottle-4911",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-01-05 16:52:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxxt6jo",
          "author": "kenrock2",
          "text": "I feel bad for the AI girl with no instruction what she going to say or to do.. And tries any random things to impress.. Lolz",
          "score": 1,
          "created_utc": "2026-01-06 02:48:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyisbp",
          "author": "Several_Honeydew_250",
          "text": "Running this on a 4070 16gb super ti, on linux os, no KDE, access from windows... 350 seconds for 728 frames... (i only did 3 boxes as a test, otherwise it'd been \\~970 frames... I added rive vfe to it to interpolate and increase output frame rate... not bad!)",
          "score": 1,
          "created_utc": "2026-01-06 05:27:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyxl12",
          "author": "Advanced-Bottle-4911",
          "text": "Hello, here are the models used :\n\nhttps://preview.redd.it/737c54ttlobg1.png?width=1332&format=png&auto=webp&s=7904e157b50977a54b295a403eaad4a8c3be3cda",
          "score": 1,
          "created_utc": "2026-01-06 07:29:45",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "ny07asl",
          "author": "shukritobi",
          "text": "Possible to use 4070super 12gb vram?",
          "score": 1,
          "created_utc": "2026-01-06 13:42:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny34buf",
              "author": "Advanced-Bottle-4911",
              "text": "In my opinion it's not enough. I used a A40 PCIe with 48 GB VRAM  and 56 GB RAM. I tried 10 X 81 frames and consistency is still present. I didn't try more.",
              "score": 1,
              "created_utc": "2026-01-06 21:54:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu14ox",
          "author": "Affectionate_Wash104",
          "text": "Not gonna lie, this is creepy as F**k.",
          "score": 0,
          "created_utc": "2026-01-05 15:47:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxt67wg",
          "author": "thisisallanqallan",
          "text": "Prompt ?",
          "score": -1,
          "created_utc": "2026-01-05 12:58:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxud4ia",
              "author": "asciimo",
              "text": "A human with considerable brain damage works hard at her first temp job.",
              "score": 12,
              "created_utc": "2026-01-05 16:43:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxum5hg",
          "author": "Anjz",
          "text": "2026 is the year of AI making long videos indistinguishable to reality. Then as videos get easier to make, AI will be able to infinitely generate realities continuously.",
          "score": -1,
          "created_utc": "2026-01-05 17:25:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q38hj2",
      "title": "Showcase All-in-One (AIO) Uncensored Qwen Model",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q38hj2/showcase_allinone_aio_uncensored_qwen_model/",
      "author": "theaccountisdeadjim",
      "created_utc": "2026-01-03 22:40:36",
      "score": 206,
      "num_comments": 33,
      "upvote_ratio": 0.97,
      "text": "I am fairly new to the AI Generation scene and have loved the Pixaroma YT channel and I have learned a ton. I like generating uncensored and stumbled across [https://huggingface.co/Phr00t/Qwen-Image-Edit-Rapid-AIO/tree/main](https://huggingface.co/Phr00t/Qwen-Image-Edit-Rapid-AIO/tree/main) which has been a huge help. I started going down the AIO/merged models on CIV and there are just so many and I don't have time to keep downloading 10-40GB files to test these out. \n\n  \nSo I wanted to share my find and also ask if others have AIO uncensored recommendation they have used. Thanks in advanced. ",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1q38hj2/showcase_allinone_aio_uncensored_qwen_model/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nxiv53s",
          "author": "The_Last_Precursor",
          "text": "The Qantas‚Äôs version https://huggingface.co/Phil2Sat/Qwen-Image-Edit-Rapid-AIO-GGUF\n\nIs a nsfw uncensored version",
          "score": 30,
          "created_utc": "2026-01-03 22:53:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxivv7j",
              "author": "aar550",
              "text": "Doesn‚Äôt the phr00t version already exist ? Which one js better ?",
              "score": 4,
              "created_utc": "2026-01-03 22:57:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxizec3",
                  "author": "The_Last_Precursor",
                  "text": "The Phr00t is a very large model. It‚Äôs the best, but takes a powerful pc to run properly. The link I provided is a smaller quantized version. It can run easily on smaller GPUs. \n\nFor the model I linked. You have to use the GGUF nodes. This is for the model, CLIP and VAE models, all of them are GGUFs. The CLIP model has a special encoded model. You must have it in your CLIP file. You don‚Äôt load it in the workflow, it just makes the clip model work correctly. If you don‚Äôt the clip model won‚Äôt properly load and have error codes. \n\nAlso this models has a lighting Lora built in. So do NOT use lighting Lora‚Äôs. This will cause the image to be garbage. Also it is sensitive to some Lora‚Äôs, this will cause the images be blurry or not fully focused. So you need to test Lora‚Äôs.",
                  "score": 7,
                  "created_utc": "2026-01-03 23:15:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxiz9af",
                  "author": "TheSlateGray",
                  "text": "Quants for people with less vram.",
                  "score": 1,
                  "created_utc": "2026-01-03 23:15:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxosrl5",
              "author": "Sgsrules2",
              "text": "I see you've quantized up to v9, but phroot is at v18 now, any plans to quantize the newer versions? Also do you have any info on how to quantize a model? I tried chatgpt, and failed. Can you do this locally on a 24gb of vram?",
              "score": 1,
              "created_utc": "2026-01-04 20:26:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjp9ir",
          "author": "No_Witness_7042",
          "text": "I can't use loras with the AIO model , anypose lora is not working which I have I checked",
          "score": 6,
          "created_utc": "2026-01-04 01:33:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxmdem",
              "author": "MelodicFuntasy",
              "text": "Does that lora actually work at all? I couldn't get good results with it.",
              "score": 1,
              "created_utc": "2026-01-06 02:11:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxmxee",
                  "author": "No_Witness_7042",
                  "text": "With which model you are using?",
                  "score": 1,
                  "created_utc": "2026-01-06 02:14:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxl6j5y",
          "author": "NewContribution2097",
          "text": "I am using AIO Models v18, with an RTX 3060 (12 GB VRAM) and 96 GB of system RAM, and the speed is acceptable.\n\nHowever, I have noticed that when I specify only certain parts of an image to be redrawn, other unspecified elements are also altered, such as the person‚Äôs face or other areas of the background.\n\nI am new to ComfyUI and am still looking for workflows that include SAM2 or SAM3. I also hope to learn how to use SAM2 or SAM3 nodes in the future to address this issue.",
          "score": 5,
          "created_utc": "2026-01-04 07:19:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxkz5y",
              "author": "HardenMuhPants",
              "text": "V5 worked really good in my experience,¬† v18 adds fake elements to the images.",
              "score": 2,
              "created_utc": "2026-01-06 02:03:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxnc6u",
                  "author": "MelodicFuntasy",
                  "text": "This is why I haven't bothered downloading any of those models. On HuggingFace people say in the comments how those models destroy consistency. So I stick with the base Qwen Image Edit.\n\nI've seen some loras that had a similar issue and I just don't get why people decide to waste other people's time this way. If you're gonna make something for an imagine editing model and it sucks at image editing, maybe mention that?",
                  "score": 1,
                  "created_utc": "2026-01-06 02:16:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxktigc",
          "author": "Rich-Waltz442",
          "text": "is there any difference for AIO models vs you know using everything differently like loading models  , text encoder , vae . other than convenience of course ?",
          "score": 1,
          "created_utc": "2026-01-04 05:35:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl3plg",
              "author": "lolxdmainkaisemaanlu",
              "text": "AIO models are faster than loading everything individually. Since it's all built into a single file.\n\nAlso the author has merged in useful loras and tweaked the base models to give much better output. Try it once. \n\nThe NSFW v18 model by Phr00t is amazing!",
              "score": 1,
              "created_utc": "2026-01-04 06:55:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxov9z",
                  "author": "MelodicFuntasy",
                  "text": ">The NSFW v18 model by Phr00t is amazing!\n\nI've seen people on HuggingFace say those models aren't good for editing, because they change the character or something else in the image too much. Do you not get such problems?",
                  "score": 1,
                  "created_utc": "2026-01-06 02:24:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxmr118",
          "author": "AcetaminophenPrime",
          "text": "Wondering if I could use it as a base model to train a lora with Onetrainer",
          "score": 1,
          "created_utc": "2026-01-04 14:45:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxmatu",
          "author": "MelodicFuntasy",
          "text": "People there often say that those NSFW models destroy character consistency. I don't know if that's true, because I haven't used them. But if it is, then it's not very usable for editing. Just like many NSFW loras for Qwen Image Edit.",
          "score": 1,
          "created_utc": "2026-01-06 02:10:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0ertt",
          "author": "ndorayaki",
          "text": "Is this available on tensorhub (Lora)?",
          "score": 1,
          "created_utc": "2026-01-06 14:23:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjp1jd",
          "author": "2legsRises",
          "text": "looks great but a little large for 12gb vram.",
          "score": 0,
          "created_utc": "2026-01-04 01:32:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl3izf",
              "author": "lolxdmainkaisemaanlu",
              "text": "Bro I have a 3060 12GB vram and 32 GB system RAM and it works just fine!",
              "score": 10,
              "created_utc": "2026-01-04 06:53:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxzar4",
      "title": "Z Image Turbo Stress Test - without any LoRA",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1pxzar4",
      "author": "Clear-Leadership-349",
      "created_utc": "2025-12-28 18:58:45",
      "score": 203,
      "num_comments": 44,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1pxzar4/z_image_turbo_stress_test_without_any_lora/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwet09k",
          "author": "MeetStraight1899",
          "text": "Can you share the prompts?",
          "score": 7,
          "created_utc": "2025-12-28 19:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfbdow",
              "author": "Clear-Leadership-349",
              "text": "Will include prompts + negative prompts with the workflow.",
              "score": 6,
              "created_utc": "2025-12-28 20:42:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfkzn9",
                  "author": "Clear-Leadership-349",
                  "text": "I have added the prompts in the post body. u/MeetStraight1899",
                  "score": 8,
                  "created_utc": "2025-12-28 21:29:49",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nweweyp",
          "author": "InternationalOne2449",
          "text": "What's the optimal resolution?",
          "score": 6,
          "created_utc": "2025-12-28 19:29:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwflb5q",
              "author": "Clear-Leadership-349",
              "text": "For this setup, I found **1088√ó1920 for base generation** to be a good balance. It preserves facial structure and skin cues reliably.\n\nFinal resolution is reached via **SeedVR refinement (target 2560px, capped at 4096px)**. Going much higher at base didn‚Äôt add meaningful structural benefit in this test.",
              "score": 9,
              "created_utc": "2025-12-28 21:31:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwersey",
          "author": "Current-Row-159",
          "text": "no workflow ?",
          "score": 9,
          "created_utc": "2025-12-28 19:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwes7l3",
              "author": "Clear-Leadership-349",
              "text": "I'll add one soon.",
              "score": 17,
              "created_utc": "2025-12-28 19:10:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfhmof",
                  "author": "Clear-Leadership-349",
                  "text": "https://preview.redd.it/yyqfhqhig0ag1.png?width=1926&format=png&auto=webp&s=34250fcfd35431840169deb16aa4c1933306252f\n\nSeedVR upscale",
                  "score": 22,
                  "created_utc": "2025-12-28 21:13:16",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwfhjy0",
                  "author": "Clear-Leadership-349",
                  "text": "https://preview.redd.it/5l0zjnodg0ag1.png?width=2135&format=png&auto=webp&s=36188df5d5c3169f1ea41e8ede8c2028ea06b225\n\ntxt2img workflow",
                  "score": 15,
                  "created_utc": "2025-12-28 21:12:54",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwex7ky",
          "author": "ArchAngelAries",
          "text": "I can never get my Z Image generations to come out this good. Idk if it's because I'm using the Q8\\_0 gguf,  or if it's because my workflow/prompting isn't good, but they always come out looking mid and not very realistic.",
          "score": 3,
          "created_utc": "2025-12-28 19:33:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf1j3k",
              "author": "Seyi_Ogunde",
              "text": "I find that the sampler matters a lot. Euler ancestral vs euler for example",
              "score": 4,
              "created_utc": "2025-12-28 19:54:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgs2nc",
                  "author": "ArchAngelAries",
                  "text": "I've been using Euler ancestral with linear quadratic, I did lots of testing and Euler with Simple just kinda resulted in SDXL/Pony looking generations",
                  "score": 3,
                  "created_utc": "2025-12-29 01:16:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwi0l4a",
              "author": "nymical23",
              "text": "What are your hardware specs?",
              "score": 2,
              "created_utc": "2025-12-29 05:51:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwf06yd",
              "author": "hayashi_kenta",
              "text": "why use gguf at 18 when there is an fp8 model that consumes same vram.",
              "score": -6,
              "created_utc": "2025-12-28 19:48:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwf22yw",
                  "author": "Silly_Goose6714",
                  "text": "GGUF 8 is closer to fp16 than fp8",
                  "score": 15,
                  "created_utc": "2025-12-28 19:57:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwf78ey",
                  "author": "Full_Way_868",
                  "text": "actually why quantize such a small model at all beyond 16bit",
                  "score": 4,
                  "created_utc": "2025-12-28 20:22:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwf80su",
              "author": "MelodicFuntasy",
              "text": "Yeah, this looks upscaled. Z-Image doesn't look like this. Wan 2.2 or Jib Mix Qwen produce more detailed images. In reality, Z-Image is an overhyped model. It's good, but not that great compared to other modern models.\n\nThe OP is lying here, not sure why, maybe they want to sell you something. They have an empty profile with no activity.",
              "score": -6,
              "created_utc": "2025-12-28 20:26:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwiesbq",
                  "author": "Neurovault",
                  "text": "hey just an FYI you can hide your post activity now in reddit's privacy settings.",
                  "score": 2,
                  "created_utc": "2025-12-29 07:52:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwf7l30",
          "author": "Fast-Mathematician39",
          "text": "Does it allow img2img?",
          "score": 2,
          "created_utc": "2025-12-28 20:24:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwfllzp",
              "author": "Clear-Leadership-349",
              "text": "Yes. It supports img2img and ControlNets",
              "score": 3,
              "created_utc": "2025-12-28 21:32:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwgi1nk",
          "author": "venpuravi",
          "text": "Ooh, too much of a stereotype. It looks like their demo reel. Try cross-styling.",
          "score": 2,
          "created_utc": "2025-12-29 00:21:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi4x8u",
          "author": "UndoubtedlyAColor",
          "text": "https://i.ibb.co/x8s2RRLW/Screenshot-20251229-152429-Red-Reader.jpg",
          "score": 2,
          "created_utc": "2025-12-29 06:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi95z9",
          "author": "StuccoGecko",
          "text": "Anyone have any tips on how to minimize the SeedVR Upscale process from changing the image too much?",
          "score": 1,
          "created_utc": "2025-12-29 07:02:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwinsi1",
              "author": "TheRealAncientBeing",
              "text": "The settings shown here in the workflow actually dont change the image in any noticeable way, at least from my personal tests with portraits comparable to the ones of the OP.",
              "score": 2,
              "created_utc": "2025-12-29 09:16:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwiiih1",
          "author": "FernDiggy",
          "text": "How well does it perform with hand drawn generations?",
          "score": 1,
          "created_utc": "2025-12-29 08:27:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwix4wh",
          "author": "iriarsham",
          "text": "can you share img2img side also?",
          "score": 1,
          "created_utc": "2025-12-29 10:44:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwk9rvk",
          "author": "ganbrood",
          "text": "It looks like this model creates almost the same image on different seeds of a particular prompt. Am I doing something wrong here or is Z-Image Turbo pretty limited?",
          "score": 1,
          "created_utc": "2025-12-29 15:57:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkaexs",
              "author": "Clear-Leadership-349",
              "text": "You are right; that is one of its limitations. As a workaround, I generate a base image using Flux and then perform an img2img with Z-image. This allows us to produce different faces and structures while retaining control over the seed.",
              "score": 3,
              "created_utc": "2025-12-29 16:00:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwkwuhs",
              "author": "Nextil",
              "text": "All the DiT-based models tend to have this \"issue\". I imagine it's because the more recent language models like Qwen are just better models, so they're more likely to extract a given semantic vector from a prompt, regardless of how it's worded.\n\nIt's probably more of a sampling problem that a training one. LLMs have sampling controls like Temperature, but for some reason image model equivalents haven't taken off yet (probably because they weren't necessary before).",
              "score": 2,
              "created_utc": "2025-12-29 17:46:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwmz44f",
              "author": "Etsu_Riot",
              "text": "You are not doing anything wrong and it's not a limitation. If you want more variety but for some reason don't want to prompt for it, use a lower denoising value (0.75 works great for me) or use a pre-existing image (any image, doesn't really matter), as input; changing the input image will allow you to get a different outpost even when using the same seed.",
              "score": 2,
              "created_utc": "2025-12-29 23:51:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx0nkgu",
              "author": "jonesaid",
              "text": "You could try the SeedVarianceEnhancer node:\n\nhttps://github.com/ChangeTheConstants/SeedVarianceEnhancer",
              "score": 1,
              "created_utc": "2026-01-01 02:15:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwinaza",
          "author": "HotelInteresting3693",
          "text": "can someone shar Workflow bec doesnt load when dragging or saving it and drag it",
          "score": 0,
          "created_utc": "2025-12-29 09:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmntse",
          "author": "_Erilaz",
          "text": "I'm sorry, I HAD TO \n\nhttps://preview.redd.it/9vzb41rt28ag1.png?width=570&format=png&auto=webp&s=0a18d14d472b763de1628ba2c5ccba7fc04d4256",
          "score": 0,
          "created_utc": "2025-12-29 22:50:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q45wpg",
      "title": "Wan 2.2 NSFW Simple Workflow for People with only 8GB of VRAM",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q45wpg/wan_22_nsfw_simple_workflow_for_people_with_only/",
      "author": "Yiggity69",
      "created_utc": "2026-01-04 23:59:22",
      "score": 187,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "Hi everyone, I wrote this article over on CivitAI because I felt like I had a really hard time getting decent NSFW AI I2V workflows working. I started with SVD and went to AnimateDiff, but they just didn't work for what I wanted. I finally found Wan 2.2 AIO NSFW V10, and it's been night and day. It's not fast by any means if you're only rocking 8 GB of VRAM, but it's much, much better than SVD and AnimateDiff on the same specs. If you're having a hard time with 8 GB VRAM, I'd recommend giving it a read.\n\n  \n[NSFW Image to Video with Wan 2.2 - The Idiot's Guide | Civitai](https://civitai.com/articles/24518)\n\n  \nLet me know if you have any questions or comments.\n\n  \nThanks!",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q45wpg/wan_22_nsfw_simple_workflow_for_people_with_only/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nxqth9k",
          "author": "Own-Biscotti4740",
          "text": "How much system RAM do you have?",
          "score": 7,
          "created_utc": "2026-01-05 02:24:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxr8wm3",
              "author": "Yiggity69",
              "text": "16, with like 8.2 vram",
              "score": 7,
              "created_utc": "2026-01-05 03:49:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxrbswd",
                  "author": "Own-Biscotti4740",
                  "text": "Oh I ask because models that size don't usually work for me so I use gguf instead. Will try your method at some point, thanks for posting!",
                  "score": 1,
                  "created_utc": "2026-01-05 04:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxy2wlt",
          "author": "talaigoII",
          "text": "what the average time for 113/16(FPS) video ? lets said on 832x480p ?   \ni have my spare rig with the same spec and kinda want to try it out.",
          "score": 2,
          "created_utc": "2026-01-06 03:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxy7zmg",
              "author": "Yiggity69",
              "text": "113 frames? It would take a long time. It takes about 35-40 minutes for me to make 61 frames, so easily over an hour",
              "score": 1,
              "created_utc": "2026-01-06 04:14:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3ngvo",
          "author": "CorrectOpinions0nly",
          "text": "If I have 6GB DDR6 VRAM, a 3060, 16GB memory, and a Ryzen 9 is this worth trying?",
          "score": 2,
          "created_utc": "2026-01-06 23:27:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3owpg",
              "author": "Yiggity69",
              "text": "It probably won't work on 6GB of VRAM, but if you're interested in local generation it can't hurt to try, just so you're more familiar with the process (if you aren't already). But yeah, it's more than likely gonna keep throwing memory errors with only 6 GB of VRAM.",
              "score": 1,
              "created_utc": "2026-01-06 23:35:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny3pjas",
                  "author": "CorrectOpinions0nly",
                  "text": "Ah damn. Yeah didn't really want to go down the rabbit whole if there wasn't really a point. Thanks for the insight though!",
                  "score": 2,
                  "created_utc": "2026-01-06 23:38:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxqshwr",
          "author": "aar550",
          "text": "Is this better than wan remix nsfw model",
          "score": 1,
          "created_utc": "2026-01-05 02:18:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxr8y9v",
              "author": "Yiggity69",
              "text": "I don't know, I haven't tried it. All I know is this one worked for me",
              "score": 2,
              "created_utc": "2026-01-05 03:49:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzanam",
          "author": "conkikhon",
          "text": "37 frames of 512x512? 20-40min of waiting? I don't think the quality worth it",
          "score": 1,
          "created_utc": "2026-01-06 09:33:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzx519",
              "author": "Yiggity69",
              "text": "37 frames is closer to 10-15 minutes. To the best of my knowledge, this is about the best you can squeeze out of 8 gb vram",
              "score": 1,
              "created_utc": "2026-01-06 12:40:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxrk5gq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -29,
          "created_utc": "2026-01-05 04:54:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxrz4n4",
              "author": "singfx",
              "text": "Literally ALL of your comments are promoting Runpod. I have used, it is a pretty great service, but how about some transparency? Just say you‚Äôre affiliated with them.",
              "score": 19,
              "created_utc": "2026-01-05 06:47:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxshbp5",
                  "author": "boobkake22",
                  "text": "The same questions get asked *all the time* because people don't read other people's versions of the same question. It's my advice when people says they have a memory/power poor GPU. I'm not trying to be coy about using an affliate link, that's what \"we'll both get credit\" means. But I don't work for them, and that's the extent of my relationship with them.\n\nI give plenty of \"real answers\" to real questions as well.",
                  "score": -10,
                  "created_utc": "2026-01-05 09:35:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2y7bk",
      "title": "Go Slowly - [ft. Sara Silkin]",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/9bqt8yjcq5bg1",
      "author": "d3mian_3",
      "created_utc": "2026-01-03 16:01:58",
      "score": 163,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q2y7bk/go_slowly_ft_sara_silkin/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxh0jru",
          "author": "_half_real_",
          "text": "This is Wan-SCAIL?",
          "score": 11,
          "created_utc": "2026-01-03 17:35:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nximvf6",
              "author": "Unreal_Sniper",
              "text": "OP posted it in the kling sub as well, so it's safe to assume it's not.",
              "score": 9,
              "created_utc": "2026-01-03 22:11:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxhsmiu",
              "author": "budwik",
              "text": "Second this, can you give any detail about what method you used?",
              "score": 4,
              "created_utc": "2026-01-03 19:43:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxi1peo",
          "author": "Andrzej1987",
          "text": "Tutorial please :D",
          "score": 4,
          "created_utc": "2026-01-03 20:27:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxim5px",
          "author": "Zounasss",
          "text": "Would love to see the workflow! This would work pretty well with sign language videos",
          "score": 3,
          "created_utc": "2026-01-03 22:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxk8rub",
          "author": "FernDiggy",
          "text": "Workflow?",
          "score": 3,
          "created_utc": "2026-01-04 03:22:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgh9ne",
          "author": "ManDanLostInDam",
          "text": "Super clean! Does it work well with camera movement? I'd love to play with a workflow or tutorial if that's possible? Nice work üëç",
          "score": 2,
          "created_utc": "2026-01-03 16:04:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgtqbw",
              "author": "d3mian_3",
              "text": "It works with camera movement, if its not too aggressive. Thank you!",
              "score": -1,
              "created_utc": "2026-01-03 17:03:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhoq73",
          "author": "Hefty_Development813",
          "text": "This length of clip is a single run or a bunch stitched together?",
          "score": 2,
          "created_utc": "2026-01-03 19:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhudl6",
          "author": "Professional_Diver71",
          "text": "Would really love to know how this was made",
          "score": 2,
          "created_utc": "2026-01-03 19:51:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxibldf",
          "author": "Kauko_Buk",
          "text": "You should try medium pace (ft. Adam Sandler) next",
          "score": 2,
          "created_utc": "2026-01-03 21:16:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxh64z0",
          "author": "joseph_jojo_shabadoo",
          "text": "Is this wavey hands sitting thing a trend or something? What is even going on here",
          "score": 1,
          "created_utc": "2026-01-03 18:00:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxh9nx4",
              "author": "arthropal",
              "text": "Dance. Sara Silkin is a choreographer and dance performer. I'm sure this piece, in the proper context, makes more sense than as its own thing.",
              "score": 1,
              "created_utc": "2026-01-03 18:16:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxhngqn",
          "author": "neuroform",
          "text": "very nice",
          "score": 1,
          "created_utc": "2026-01-03 19:18:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxn98x1",
          "author": "BoredHobbes",
          "text": "u got the og video by itself i wanna test somethign",
          "score": 1,
          "created_utc": "2026-01-04 16:16:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5a8ta",
      "title": "Goodbye, wan 2.2? LTX-2 is a DiT-based audio-video foundation model designed to generate synchronized video and audio within a single model.",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q5a8ta/goodbye_wan_22_ltx2_is_a_ditbased_audiovideo/",
      "author": "One_Yogurtcloset4083",
      "created_utc": "2026-01-06 05:39:47",
      "score": 145,
      "num_comments": 85,
      "upvote_ratio": 0.89,
      "text": "[https://github.com/Lightricks/LTX-2](https://github.com/Lightricks/LTX-2)  \n[https://huggingface.co/Lightricks/LTX-2](https://huggingface.co/Lightricks/LTX-2)\n\n20 seconds videos with audio!",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1q5a8ta/goodbye_wan_22_ltx2_is_a_ditbased_audiovideo/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nxz4xpb",
          "author": "Electronic-Beyond162",
          "text": "I'm fed up, my PC is completely full of gguf, tensor, and ckpt files.",
          "score": 54,
          "created_utc": "2026-01-06 08:38:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny07792",
              "author": "xKronkx",
              "text": "You mean it‚Äôs not normal to completely jack up your workspace, delete everything, and reinstall from scratch weekly? Damn.",
              "score": 13,
              "created_utc": "2026-01-06 13:41:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1l5z9",
                  "author": "chuckaholic",
                  "text": "This is the way. Click update. Restart Comfy. Nothing works. Delete and reinstall.",
                  "score": 6,
                  "created_utc": "2026-01-06 17:43:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxz61ky",
              "author": "Zueuk",
              "text": "> ckpt files\n\nthese must be really old, I'd say you can safely delete them :)",
              "score": 18,
              "created_utc": "2026-01-06 08:49:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzioup",
              "author": "Winougan",
              "text": "I have over 40TB of AI checkpoints, diffusers, LORAs, LLMs, etc. Recently, I've just culled everything I don't touch. A lot of finetunes are really unnecessary. Just keep the best ones and get rid of the rest. I'm waiting for the big ZIT-NoobAI merge so I can purge everything related to Illustrious and NAI. I've deleted all Flux related models in lieu of ZIT. Just pare everything down and you'll be fine.",
              "score": 9,
              "created_utc": "2026-01-06 10:47:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1smjv",
                  "author": "Artistic_Okra7288",
                  "text": "Considering some things are purged, you might consider uploading them somewhere like archive.org. This is history in the making!",
                  "score": 5,
                  "created_utc": "2026-01-06 18:16:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny1sh3z",
                  "author": "favorited",
                  "text": "> I have over 40TB of AI checkpoints\n\n> Just pare everything down and you'll be fine.",
                  "score": 2,
                  "created_utc": "2026-01-06 18:15:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxys9lg",
          "author": "boobkake22",
          "text": "I hate these kinds of silly statements, but I'll be curious to see more examples from people using it.   \n  \nWan has really good LoRA support at this point, and the sound in the example video doesn't impress me yet. Will be curious to see if it's worth consideration.",
          "score": 55,
          "created_utc": "2026-01-06 06:42:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyzxqr",
              "author": "ANR2ME",
              "text": "As long they provided the training code, i'm sure there will be lora trainers available too, and then loras will be spreading like WAN too. Just let them cook first üòÅ",
              "score": 8,
              "created_utc": "2026-01-06 07:51:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzc8xj",
                  "author": "vaosenny",
                  "text": "> i‚Äôm sure there will be lora trainers available too, and then loras will be spreading like WAN too.\n\nThey sure will, because everyone and their mother has access to 24+GB GPU.",
                  "score": 7,
                  "created_utc": "2026-01-06 09:48:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxzg3jj",
              "author": "crinklypaper",
              "text": "when wan came out everyone said the same thing because hun had been around a while. The thing holding this back is the min requirements are quite high. I hope this pushes wan team to push out 2.5 to open source",
              "score": 9,
              "created_utc": "2026-01-06 10:24:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzhyw2",
                  "author": "boobkake22",
                  "text": "I agree with that sentiment, but it is a bit different now. Wan 2.2 works with both 2.2 and 2.1 LoRA's. So it's actually a pretty big bed of support. I was also using Hun. We'll see how it goes.",
                  "score": 5,
                  "created_utc": "2026-01-06 10:41:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz01ch",
          "author": "No_Comment_Acc",
          "text": "I am testing this model right now. 48 gigs of VRAM, 64 gigs of RAM. Basic text to video workflow:\n\nFirst run: 145 seconds to generate 5 second video.\n\nSecond run: 93 seconds to generate 5 second video.\n\nLove it more than Wan 2.2 from the first try. Lipsync is quite good.",
          "score": 15,
          "created_utc": "2026-01-06 07:52:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzbq8c",
              "author": "Confusion_Senior",
              "text": "Which gpu",
              "score": 4,
              "created_utc": "2026-01-06 09:44:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxzby6x",
                  "author": "No_Comment_Acc",
                  "text": "Chinese 4090 48 gigs",
                  "score": 14,
                  "created_utc": "2026-01-06 09:46:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzer23",
          "author": "thebaker66",
          "text": "Goodbye WAN? Unlikely, assuming it's still censored it's not killing WAN. I think they can be complimentary. \n\nStill seems to have that flux/plastic look to it but otherwise it looks good and seems to be far faster.",
          "score": 8,
          "created_utc": "2026-01-06 10:12:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1b9mq",
              "author": "WordSaladDressing_",
              "text": "This. Any censored model is a nonstarter. Period. End of story.",
              "score": 4,
              "created_utc": "2026-01-06 16:58:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2scp7",
                  "author": "Different-Toe-955",
                  "text": "Long term I bet nsfw wan loras will be ported over somehow.",
                  "score": 1,
                  "created_utc": "2026-01-06 20:59:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzmab4",
          "author": "darkshark9",
          "text": "Has anyone gotten this working on ComfyUI Desktop version yet? Been trying for a while now and it is just not cooperating.",
          "score": 4,
          "created_utc": "2026-01-06 11:18:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzmw0u",
              "author": "Dnumasen",
              "text": "Same. :(",
              "score": 1,
              "created_utc": "2026-01-06 11:23:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3gost",
              "author": "picassoble",
              "text": "Not released on desktop yet! Will be released along with stable ComfyUI",
              "score": 1,
              "created_utc": "2026-01-06 22:53:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyoqzf",
          "author": "protector111",
          "text": "20 sec ? You need 256 vram to generate 20 sec?",
          "score": 6,
          "created_utc": "2026-01-06 06:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyunvw",
              "author": "goddess_peeler",
              "text": "From the [nvidia quickstart guide](https://www.nvidia.com/en-us/geforce/news/rtx-ai-video-generation-guide/):\n\n> For example, GeForce RTX 5090 GPUs have 32GB of VRAM, and can generate a 720p 24fps 4-second clip within GPU memory in about 25 seconds. However, if a user wants a longer 8-second video, the generation time will increase to three minutes because it will require more than 32GB of VRAM and automatically engage weight streaming.",
              "score": 9,
              "created_utc": "2026-01-06 07:03:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzsfb3",
          "author": "hum_ma",
          "text": "19B plus 12B text encoder... with my GPU more like goodbye LTX.",
          "score": 3,
          "created_utc": "2026-01-06 12:06:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny05hxp",
          "author": "Striking-Long-2960",
          "text": "It's like nobody learned anything from the success of  Z-image turbo.",
          "score": 4,
          "created_utc": "2026-01-06 13:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzrbzi",
          "author": "Hopeful-Junket-7990",
          "text": "Heads up. The licensing makes this mearly a toy at most. They keep permanent control over derivatives, competition, enforcement and shutdown rights. You'll either pay to comply or be shut down and lose everything.\n\n\nWan 2.2 isn't going anywhere for the time being.",
          "score": 5,
          "created_utc": "2026-01-06 11:58:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzw8eb",
              "author": "laurenblackfox",
              "text": "What makes you say that? Section 1 Paragraph 5 states they claim no ownership of output ...\n\nIf you host the model for others, make finetunes, or otherwise derive from the model itself, then yeah. They reserve the right to enforce their usage restrictions as set out in Appendix A.",
              "score": 4,
              "created_utc": "2026-01-06 12:34:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny007gl",
              "author": "TomatoInternational4",
              "text": "AI licensing is a joke anyways. Just make sure there is no watermark and you can do whatever you want and they'll have no way of knowing it's their model. \n\nThe watermarks out currently are easily removed with a bit of technical know how and a Google search.",
              "score": 1,
              "created_utc": "2026-01-06 13:00:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2siay",
              "author": "Different-Toe-955",
              "text": "OOF this should be top comment.",
              "score": 1,
              "created_utc": "2026-01-06 20:59:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzt8wx",
              "author": "GreyScope",
              "text": "If you‚Äôre not selling anything who cares ? Ppl on this and others waffle on about this like it‚Äôs a holy grail",
              "score": 1,
              "created_utc": "2026-01-06 12:12:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny09gow",
                  "author": "hornynnerdy69",
                  "text": "Because many people with the hardware to train loras are at least hoping to recover training costs. This will severely limit the number of people who make loras for LTX2, which will severely limit its potential",
                  "score": 2,
                  "created_utc": "2026-01-06 13:54:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny00nka",
                  "author": "AssistBorn4589",
                  "text": "I do.",
                  "score": -1,
                  "created_utc": "2026-01-06 13:03:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzkvus",
          "author": "Hauven",
          "text": "Looks nice, can't get it to work on ComfyUI Desktop though. I guess it's a bit too early to test it.",
          "score": 2,
          "created_utc": "2026-01-06 11:06:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0anzz",
          "author": "Pase4nik_Fedot",
          "text": "I just tried generating a few videos on the FP8 model, and the quality was terrible. Is this the case for everyone? Or is there a problem with comfyui adapting the model?",
          "score": 2,
          "created_utc": "2026-01-06 14:00:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3ydsi",
              "author": "AngelofKris",
              "text": "Ran the fp8 model on a 5090 and i2v was cooked. No consistency whatsoever so ever. T2v was also surprisingly bad. The community needs to save this model. Wan2.2 with mmaudio is significant better at this point regardless if it takes longer to render. However they did an amazing job on the workflow for ltx",
              "score": 2,
              "created_utc": "2026-01-07 00:24:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1cxjz",
              "author": "squired",
              "text": "Their sample videos even look jank. I'm not going to give it my time until I see some more promise. I've been burned by hype far too many times to be chasing some new hotness that doesn't even appear to be SOTA. If they were dev focused, it might worth the time to bang on it, but it does not appear to be at first blush. That was the key to Wan. It was an open box that we could extend for them.",
              "score": 1,
              "created_utc": "2026-01-06 17:05:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2x2ro",
          "author": "Mysterious-String420",
          "text": "Ugh, 16gb VRAM and 32 GB RAM here. I'm not even gonna try it. I know how this goes.\n\nSpend all night trying to make it work, and it's not even got loras and stuff ?   \nJust here to salute the courageous pioneers who bother with this before we get some GGUFs.",
          "score": 2,
          "created_utc": "2026-01-06 21:20:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyr127",
          "author": "DanzeluS",
          "text": "Optimization Tips\n\nUse DistilledPipeline - Fastest inference with only 8 predefined sigmas (8 steps stage 1, 4 steps stage 2)\n\nEnable FP8 transformer - Enables lower memory footprint: --enable-fp8 (CLI) or fp8transformer=True (Python)\nInstall attention optimizations - Use xFormers (uv sync --extra xformers) or Flash Attention 3 for Hopper GPUs\n\nUse gradient estimation - Reduce inference steps from 40 to 20-30 while maintaining quality (see pipeline documentation)\nSkip memory cleanup - If you have sufficient VRAM, disable automatic memory cleanup between stages for faster processing\n\nChoose single-stage pipeline - Use TI2VidOneStagePipeline for faster generation when high resolution isn't required",
          "score": 7,
          "created_utc": "2026-01-06 06:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyz4do",
              "author": "BeautyxArt",
              "text": "Optimization Tips for (what..??)",
              "score": 13,
              "created_utc": "2026-01-06 07:43:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxz6xct",
              "author": "kaotec",
              "text": "tried on my 4090 using latest Comfui, worflow from templates.  \n\\--enable-fp8 does not exist as a startup optioon to my ComfyUI...  \nI tried --supports-fp8-compute but I still get OOM\n\nI tried --fp8\\_e4m3fn-text-enc --fp8\\_e4m3fn-unet but I still get OOM\n\nany ideas? I did install xformers / flash2\n\nI'm guessing, you're here writing about the python inference code? not the ComfyUI workflow?",
              "score": 5,
              "created_utc": "2026-01-06 08:57:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1nzxn",
                  "author": "Samuelec81",
                  "text": "im with the 4090 like u, unable to run it",
                  "score": 1,
                  "created_utc": "2026-01-06 17:56:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3xe9r",
                  "author": "AngelofKris",
                  "text": "I tried those text encoders too on a 5090 and it‚Äôs created a black image with no audio.",
                  "score": 1,
                  "created_utc": "2026-01-07 00:19:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2to2m",
              "author": "unarmedsandwich",
              "text": "I don't think even you know what that means.",
              "score": 2,
              "created_utc": "2026-01-06 21:05:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxylpxj",
          "author": "RowIndependent3142",
          "text": "Because you post this in ComfyUI sub, can you provide a workflow template (JSON) and can you say if the workflow generates audio or if you need to import audio (wav, mp3). Thanks.",
          "score": 5,
          "created_utc": "2026-01-06 05:49:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxym2wr",
              "author": "One_Yogurtcloset4083",
              "text": "it can generate without import. you can found workflow here  \n[https://github.com/Lightricks/ComfyUI-LTXVideo/](https://github.com/Lightricks/ComfyUI-LTXVideo/)  \n[https://docs.ltx.video/open-source-model/integration-tools/comfy-ui](https://docs.ltx.video/open-source-model/integration-tools/comfy-ui)\n\nedit: they havent updated workflows for the ltx-2?",
              "score": 5,
              "created_utc": "2026-01-06 05:52:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxynq8o",
                  "author": "RowIndependent3142",
                  "text": "I see. You install everything through the manager. But it would also be easy just to have the JSON to drop into a blank ComfyUi and install the nodes. I‚Äôd rather do it that way. You didn‚Äôt answer about how the audio is generated",
                  "score": 2,
                  "created_utc": "2026-01-06 06:05:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzehzq",
          "author": "vaosenny",
          "text": "> Goodbye, wan 2.2?\n\nMore like bye LTX-2 and hello Wan 2.2 until an equivalent of Z Image for video will be released",
          "score": 2,
          "created_utc": "2026-01-06 10:09:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzxr8j",
          "author": "Brahianv",
          "text": "Goobye wan?? sorry but this at best matching an 6 months old model wan 2.2",
          "score": 2,
          "created_utc": "2026-01-06 12:44:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyqdxl",
          "author": "Ill_Ease_6749",
          "text": "wan is still better than ltx 2, coz even on their web its look low than wan 2.2",
          "score": 3,
          "created_utc": "2026-01-06 06:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyrq8s",
              "author": "exomniac",
              "text": "Well said",
              "score": 11,
              "created_utc": "2026-01-06 06:38:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxznskd",
          "author": "is_this_the_restroom",
          "text": "Can it do portrait resolutions? Or only landscape?",
          "score": 1,
          "created_utc": "2026-01-06 11:30:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny07pch",
          "author": "Raandomu",
          "text": "Does it have easy multi-frame support like the older version?",
          "score": 1,
          "created_utc": "2026-01-06 13:44:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0y46j",
          "author": "SysPsych",
          "text": "I am admittedly using this with some more serious hardware, so I'm minimizing the need to lean on distills. But so far -- damn, this is pretty impressive, just for the lip sync capabilities alone.\n\nIf there's anyway to have some consistency with the voice, this really is one of those situations where \"game changer\" make apply. There's limitations to it all, it screws up on some things (I notice in particular, animated characters + camera close up, it chokes so far) but out of the gate for a just released model.. damn. This is great.",
          "score": 1,
          "created_utc": "2026-01-06 15:58:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1k7hg",
          "author": "InternationalOne2449",
          "text": "I can barely run Wan 2.2 on my 12 gigs.",
          "score": 1,
          "created_utc": "2026-01-06 17:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1po7e",
          "author": "Mylaptopisburningme",
          "text": "This wont work on a 12 gb 4070 I assume?",
          "score": 1,
          "created_utc": "2026-01-06 18:03:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny257ez",
              "author": "Nybio",
              "text": "Works for me. I have 4070 and 96 RAM. Fp8 distilled, official workflow, 416x544, 121 frames takes about just a minute. Quality though... I better stick with wan for now¬†",
              "score": 1,
              "created_utc": "2026-01-06 19:12:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1rvw2",
          "author": "lacaille59",
          "text": "Free template?",
          "score": 1,
          "created_utc": "2026-01-06 18:13:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny29nt5",
          "author": "SweatyNovel2356",
          "text": "The Enhance node (for Gemma 3 that comes in their LTX-2 workflow) is giving me errors saying certain json files aren't where they're supposed to be. ANy ideas? (I can bypass the node and it generates.... but, I'd rather not if I didn't have to).",
          "score": 1,
          "created_utc": "2026-01-06 19:33:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2g4lf",
          "author": "drowpro",
          "text": "I have not worked with either one. What would be the best platform for someone that makes original audio/songs and I just want my characters to be able to lip sync? Would I still need a RAM & VRAM heavy pc to use wan 2.2 or LTX-2 for  what I‚Äôm trying to do?",
          "score": 1,
          "created_utc": "2026-01-06 20:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2qz3z",
          "author": "boobkake22",
          "text": "Gave this a shot for a few hours testing T2V and I2V on an H100 SXM at 5 and 10 seconds \\~720p. \n\nIt's not a \"Wan killer\" or whatever. It \\*is\\* faster and memory hungry. It's *not great* at anything tho - maybe character coherence when there isn't much motion? Talking heads with wonky AI voice pacing works pretty well? The sound is okay. The character consistency *is* good until it isn't. It doesn't understand a ton of concepts, and the results are often cartoonish and weird like earlier AI videos but at higher fidelity. Doesn't do text. I found prompt following was worse than Wan; in many ways it feels like it has a lot of the lightx flaws baked in? It's a bit hard to articulate what doesn't work for LTX-2.\n\nOverall, I still like what Wan is doing over this. Maybe with a ton of LoRA support it would be better, but I remain skeptical.",
          "score": 1,
          "created_utc": "2026-01-06 20:53:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2s4nq",
          "author": "Different-Toe-955",
          "text": "does it require CUDA?",
          "score": 1,
          "created_utc": "2026-01-06 20:58:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2t9ab",
          "author": "Majestic-Menu5063",
          "text": "fun",
          "score": 1,
          "created_utc": "2026-01-06 21:03:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3run5",
          "author": "Less_Consequence_633",
          "text": "Just in case anyone else is running with \"--fast fp16\\_accumulation\" in their ComfyUI startup, it'll put a crazy grid pattern all over your LTX-2 T2V and even worse on the I2V workflows, so I've taken that out of mine.",
          "score": 1,
          "created_utc": "2026-01-06 23:50:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3wgx0",
              "author": "One_Yogurtcloset4083",
              "text": "what pattern?",
              "score": 1,
              "created_utc": "2026-01-07 00:14:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny4b3qg",
                  "author": "Less_Consequence_633",
                  "text": "https://preview.redd.it/ao2f91xtytbg1.png?width=1280&format=png&auto=webp&s=6b88952580993c7d0f9a6dacd3a5ae2eb34066b3\n\nLike, that pattern.",
                  "score": 2,
                  "created_utc": "2026-01-07 01:31:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny3zaf2",
          "author": "AngelofKris",
          "text": "The open source community has 2 weeks at best to fix this model before it‚Äôs forgotten. The fp8 model they released is cheeks, even on a 5090. I‚Äôm going to try the larger distilled model on a bigger GPU and see how it handles but my confidence is low. It cuts the image resolution in half before it processes it, then upscales it 2x before it‚Äôs done. What I am interested in doing however is using this upscaler in my Wan 2.2 setup because it‚Äôs fast AF.",
          "score": 1,
          "created_utc": "2026-01-07 00:28:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4aa2u",
          "author": "mrImTheGod",
          "text": "Not bad, a 3090 w/ 64gb ram and can do  5s 1280x720 25fps in 125seconds with the gemma fp8 and the distilled fp8 ltx model, not great with quality on cartoons, solid lines get pretty blurry, will have to try the non distill and see how that goes still",
          "score": 1,
          "created_utc": "2026-01-07 01:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyz4vf",
          "author": "SDuser12345",
          "text": "Then you test it, and it's SD3 all over again, full of promises and fails to deliver. Sigh, so much hope crushed so fast...",
          "score": 2,
          "created_utc": "2026-01-06 07:44:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyx6d2",
          "author": "Head-Leopard9090",
          "text": "They finally released it ? Ohh",
          "score": 1,
          "created_utc": "2026-01-06 07:26:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxywin0",
          "author": "superstarbootlegs",
          "text": "give it a week",
          "score": 0,
          "created_utc": "2026-01-06 07:19:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxywopm",
          "author": "JoelMahon",
          "text": "I know probably very cherry picked but pretty impressed by the voices.\n\ndoes it currently support chaining generation with the last ~4 frames of video 1 being fed into the start of video 2? to make e.g. 39.8s clips. I appreciate audio/visual consistency will not be as good.",
          "score": 0,
          "created_utc": "2026-01-06 07:21:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz6taa",
          "author": "Electronic-Beyond162",
          "text": "Exactly. In my first video, the girl was a redhead with her hair down. Her head went out of frame and she came back with her hair tied in a ponytail. In the end, she looked more like a Chinese girl than my redhead. That was with WF WAN 2.2. And LoRa at each stage. Super practical for adapting the job she has to do at each stage. https://civitai.com/models/1924597?modelVersionId=2178322\nThen SDI WAN is great because it manages the personality better from beginning to end.\n\nhttps://youtu.be/PJnTcVOqJCM?si=HiLT1uSedNjFheEh\n\nOkay, so I'm experimenting with prompts on a 5-second stage. If it works, I'll send several stages.\n\nWith the 4060 Ti 8GB, everything goes straight into the RAM.\n\nI understand why, RAM is so expensive now.",
          "score": 0,
          "created_utc": "2026-01-06 08:56:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzvrkr",
      "title": "YES A RE-UP FULL FP32 full actual 22gb weights YOU HEARD IT!! WITH PROOF My Final Z-Image-Turbo LoRA Training Setup ‚Äì Full Precision + Adapter v2 (Massive Quality Jump)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1pzvrkr/yes_a_reup_full_fp32_full_actual_22gb_weights_you/",
      "author": "Capitan01R-",
      "created_utc": "2025-12-30 22:28:18",
      "score": 142,
      "num_comments": 109,
      "upvote_ratio": 0.84,
      "text": "After weeks of testing, hundreds of LoRAs, and one burnt PSU üòÇ, I've finally settled on the LoRA training setup that gives me the¬†**sharpest, most detailed, and most flexible**¬†results with¬†**Tongyi-MAI/Z-Image-Turbo**.\n\nThis brings together everything from my previous posts:\n\n* Training at¬†**512 pixels**¬†is overpowered and still delivers crisp 2K+ native outputs¬†**((meaning the bucket size not the dataset)**)\n* Running¬†**full precision**¬†(no quantization on transformer or text encoder) eliminates hallucinations and hugely boosts quality ‚Äì even at 5000+ steps\n* The¬†**ostris zimage\\_turbo\\_training\\_adapter\\_v2**¬†is absolutely essential\n\nTraining time with 20‚Äì60 images:\n\n* \\~15‚Äì22 mins on RunPod on¬†**RTX5090**¬†costs¬†**$0.89/hr (( you will not be spending that amount since it will take 20 mins or less))**\n\nTemplate on runpod¬†**‚ÄúAI Toolkit - ostris - ui - official‚Äù**\n\n* \\~1 hour on RTX 3090¬†***((if you sample 1 image instead of 10 samples per 250 steps))***\n\n**Key settings that made the biggest difference**\n\n* ostris/zimage\\_turbo\\_training\\_adapter\\_v2\n* saves (dtype: fp32) ***note when we train the model on AiToolKit we utilize the full fp32 model not bf16, and if you want to merge in your on fp32 native weights model you may use this*** [***repo*** ](https://github.com/PixWizardry/ComfyUI_Z-Image_FP32)***credit to*** [***PixWizardry***](https://github.com/PixWizardry) ***for assembling it. also this was the reason your LoRA looked different and slightly off in comfyui,*** [fp32 model](https://civitai.com/models/2266472/z-image-turbo-native-fp32-model)***.***\n\n[running the model at fp32 to utilize my LoRA trained at fp32, no missing unet layers or flags üòâ](https://preview.redd.it/fu4tqbne3fag1.png?width=1718&format=png&auto=webp&s=851e22234f8715832edde5cecd0fb94488badf65)\n\nNo quantization anywhere\n\nLoRA rank/alpha 16 (linear + conv)\n\nsigmoid timestep\n\nBalanced content/style\n\nAdamW8bit optimizer, LR 0.00025 **or** 0.0002, weight decay (0.0001).¬†**Note :** **~~I'm currently~~**¬†***~~in process of testing Prodigy¬†optimizer~~*** ***- still under process.***\n\nsteps 3000 sweet spot >> can be pushed to 5000 if careful with dataset and captions.\n\n* ***configs***:\n* 1.[Full ai-toolkit config.yaml](https://pastebin.com/G9LcSitA)¬†***^(optimized fast)***\n* 2.[Heavy training config](https://pastebin.com/CGaNjE88) **(use this if you don't mind renting a heavy gpu or own one, minimum 42Gb of Vram, I'm talking 1hr for 3000 steps on H200üòÇ)** *^(perks= no rounding errors, full on beast mode.)*\n\n*\\*\\*Note: this applies to all configs if you're character or* ***style locked in at earlier step eg. 750-1500***\\*, there could be still fine-tuning needs to be done, so if you feel like it looks good, lower your learning rate from the\\* ***0.00025*** *to* ***0.00015***\\*,\\* ***0.0001*** *or* ***0.00009*** *to avoid overfitting and continue training at your intended steps eg 3000 steps or even higher with the lowered learning rate.*\n\n[1.to copy the config follow the arrow and click on the Show Advanced Tab](https://preview.redd.it/b12gb7vgsiag1.png?width=3540&format=png&auto=webp&s=583e0a4107b9a559ad4e585e99b5fb13f759f727)\n\n[2.paste in the config file info in here, after pasting do not back out instead follow the arrow and click Show simple then when inside of the main page add select your dataset.](https://preview.redd.it/bv405hzlsiag1.png?width=3533&format=png&auto=webp&s=7743daf3744308889497d06cd1e52f926a4fd901)\n\n# \n\n**ComfyUI workflow (use exact settings for testing/ test with**¬†*bong\\_tangent also it works decently*)  \n[workflow](https://pastebin.com/CAufsJG7)\n\n[fp32 workflow](https://pastebin.com/jKP0gaMd) (***same as testing workflow but with proper loader for fp32)***\n\n[flowmatch scheduler¬†](https://github.com/erosDiffusion/ComfyUI-EulerDiscreteScheduler)**(( the magic trick is here/ can also test on**¬†*bong\\_tangent*))\n\n[RES4LYF](https://github.com/ClownsharkBatwing/RES4LYF)\n\n[UltraFluxVAE¬†](https://huggingface.co/Owen777/UltraFlux-v1/blob/main/vae/diffusion_pytorch_model.safetensors)**( this is a must!!! provides much better results than the regular VAE)**\n\n**Pro tips**\n\n1.Always preprocess your dataset with¬†**SEEDVR2**¬†‚Äì gets rid of hidden blur even in high-res images\n\n1A-[SeedVR2 Nightly Workflow](https://pastebin.com/gZbAq4vC)\n\n[SeedVR2 slightly updated workflow with blending original image for color and structure.](https://pastebin.com/K7QtCEfr)¬†\n\n***((please be mindful and install this in a separate comfyui, as it may cause dependencies conflicts))***\n\n1B-¬†[Downscaling py script](https://pastebin.com/UJfugSaJ)¬†**( a simple python script I created, I use this to downscale large photos that contain artifacts and blurs. then upscale them via SeedVR2 eg. 2316x3088 that has artifacts or blur technically not easy to use but with this I downscale it to 60% then upscaling it with SeedVR2 with fantastic results. works better for me than the regular resize node in comfyui \\*\\*note this is local script, you only need to replace input and output folders paths in the scripts as it does bulk resizing or individual, takes split of seconds to finish as well even for Bulk resizing)**\n\n* **2.Keep captions simple, don't over do it!**\n\nPrevious posts for more context:\n\n* [512 res post](https://www.reddit.com/r/comfyui/comments/1pmijxo/zimage_training/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) *-deleted but discussion still there*\n* [Full precision post](https://www.reddit.com/r/comfyui/comments/1pp49vc/another_zimage_tip/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) *-deleted but discussion still there*\n\nTry it out and show me what you get ‚Äì excited to see your results! üöÄ\n\n**PSA: this training method guaranteed to maintain all the styles that come with the model, for example :y*****ou can literally have your character in in the style of sponge bob show chilling at the crusty crab with sponge bob and have sponge bob intact alongside of your character who will transform to the style of the show!!***¬†**just thought to throw this out there.. and no this will not break a 6b parameter model and I'm talking at strength 1.00 lora as well. remember guys you have the ability to change the strength of your lora as well. Cheers!!**\n\n**üö® IMPORTANT UPDATE ‚ö° Why Simple Captioning Is Essential**\n\nI‚Äôve seen some users struggling with distorted features or ‚Äúmushy‚Äù results. If your character isn‚Äôt coming out clean, you are likely over-captioning your dataset.\n\nz-image handles training differently than what you might be used to with SDXL or other models.\n\n**üßº The ‚ÄúClean Label‚Äù Method**\n\nMy method relies on a minimalist caption.\n\nIf I am training a character who is a man, my caption is simply:\n\nman\n\n**üß† Why This Works (The Science) ‚Ä¢ The Sigmoid Factor**\n\nThis training process utilizes a Sigmoid schedule with a high initial noise floor. This noise does not ‚Äúsettle‚Äù well when you try to cram long, descriptive prompts into the dataset.\n\n**‚Ä¢ Avoiding Semantic Noise**\n\nHeavy captions introduce unnecessary noise into the training tokens. When the model tries to resolve that high initial noise against a wall of text, it often leads to:\n\nDisfigured faces\n\nLoss of fine detail\n\n**‚Ä¢ Leveraging Latent Knowledge**\n\nYou aren‚Äôt teaching the model what clothes or backgrounds are, it already knows. By keeping the caption to a single word, you focus 100% of the training energy on aligning your subject‚Äôs unique features with the model‚Äôs existing 6B-parameter intelligence.\n\n**‚Ä¢ Style Versatility**\n\nThis is how you keep the model flexible.\n\nBecause you haven‚Äôt ‚Äúbaked‚Äù specific descriptions into the character, you can drop them into any style, even a cartoon. and the model will adapt the character perfectly without breaking.\n\n[original post with discussion](https://www.reddit.com/r/comfyui/comments/1ppy4t0/my_final_zimageturbo_lora_training_setup_full/) \\-*deleted but discussion still there*, **this is the same exact post btw just with adding few things and not removing anything from previous one**\n\n***Additionally, here is full fp32 model merge:***\n\n***Full fp32 model here :*** [***https://civitai.com/models/2266472?modelVersionId=2551132***](https://civitai.com/models/2266472?modelVersionId=2551132)\n\n**Credit for:**\n\n[**Tongyi-MAI For the ABSOLUTE UNIT OF A MODEL**](https://github.com/Tongyi-MAI)\n\n[**Ostris And his Absolute legend of A training tool and Adapter**](https://github.com/ostris)\n\n[**ClownsharkBatwing For the amazing RES4LYFE SAMPLERS**](https://github.com/ClownsharkBatwing)\n\n[**erosDiffusion For Revealing Flowmatch Scheduler**](https://github.com/erosDiffusion)",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1pzvrkr/yes_a_reup_full_fp32_full_actual_22gb_weights_you/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nwunp13",
          "author": "Wallye_Wonder",
          "text": "i tried your caption method but the resault turn all \"woman\" or \"man\" into my dataset.",
          "score": 9,
          "created_utc": "2025-12-31 03:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwup025",
              "author": "Capitan01R-",
              "text": "try to describe the other character in more depth. meaning give more details to the secondary character such as age, hair color, gender, etc.. this should resolve the issue, if that fails lower the lora strength, it will still maintain your trained character at highest level but will not bleed into others.",
              "score": 2,
              "created_utc": "2025-12-31 03:18:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nww6q8b",
          "author": "alb5357",
          "text": "Single word captions? Really??",
          "score": 6,
          "created_utc": "2025-12-31 10:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx11u5",
              "author": "Capitan01R-",
              "text": "That‚Äôs what I do for my LoRA‚Äôs I only use one word, others do it differently which I completely respect that. but just be cautious with the wording to avoid model misinterpretation :)",
              "score": 2,
              "created_utc": "2025-12-31 14:18:57",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwyfrx7",
              "author": "MeikaLeak",
              "text": "thats pretty normal",
              "score": 1,
              "created_utc": "2025-12-31 18:36:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2a9g0",
                  "author": "alb5357",
                  "text": "I know it's normal, but does it actually work better than long captions?\n\nAnd has no one tried alternating captions? Actually I'd better make a post about that.",
                  "score": 1,
                  "created_utc": "2026-01-01 10:48:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtpuzo",
          "author": "xcdesz",
          "text": "Last time you wrote this you said that you didn't test this with \"style loras\".  Has that changed?  Is this a guide for mostly character Lora training?",
          "score": 4,
          "created_utc": "2025-12-30 23:57:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtup7l",
              "author": "Capitan01R-",
              "text": "I still haven't done anything new recently, this is mainly for characters due to the high initial noise by Sigmoid Timestep.",
              "score": -2,
              "created_utc": "2025-12-31 00:23:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwu36i",
          "author": "Any_Reading_5090",
          "text": "thx for sharing but only 512px will logically delete/ignor all the fine details of a hi res dataset and for hyper body proportions my test results with simple captions \"leads to a win\" of the z image model bias like \"hey thats a woman with strange proportions I have to fit it into my knowledge how a woman looks like\". Furthermore as we all have to use the v2adapter even with the same dataset and captions etc the lora turns out always different. A real mystery..z imgae training is very special.",
          "score": 4,
          "created_utc": "2025-12-31 13:37:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwzh0j",
              "author": "Capitan01R-",
              "text": "It never did that for me, I tried on probably many different datasets with various resolutions, and they turned out good. But if you prefer 1024 you can absolutely do that it‚Äôs just going to be slower during training. But I would be more than glad if you dm me and discuss this further as there could be a different underlying problem. Bc during training I noticed that z-image interpret some words entirely differently, i tested that with the model without LoRA‚Äôs to check which words are interpreted differently and there was a big chunk of at least what I tested, reason I‚Äôm saying this is if the model interpreted a word differently it could potentially have initial noise of wrong colors or parts and that would go into your training which is bad thing. And since we are using Sigmoid Timestep that‚Äôs a quick initial high noise basically which could cause a blend of chaos if we choose the wrong words as a caption.",
              "score": 2,
              "created_utc": "2025-12-31 14:09:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwzd5h7",
                  "author": "Any_Reading_5090",
                  "text": "thats 1 key point testing the caption wothout lora. But as mentioned z image lora training is very inconsistent the base model absorbs somehow all extreme shapes but with the right trigger in a \"magic moment\" they are back again. the tendency for this \"behavior\" I recognized when I accidently trained a lora without any caption or trigger word.  but when I promted blonde woman my lora character appeared so the z image or the adapter put the weights in the \"correct pocket\". Also u can try same dataset every run the trained lora is different.",
                  "score": 1,
                  "created_utc": "2025-12-31 21:33:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nww0mt5",
          "author": "SvenVargHimmel",
          "text": "I'll try this but I'm going to put this through an LLM to summarise it first :)",
          "score": 3,
          "created_utc": "2025-12-31 09:34:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww59mm",
          "author": "Nepharios",
          "text": "One question: this works extremely well for me local if I use quant in both. The lora is pretty good too. If I try with no quant, after around 500 steps it becomes very slow, just feels like a vram overflow. 4090 with 24 gigs. How could you run with no quant on a 3090? Any tips?",
          "score": 3,
          "created_utc": "2025-12-31 10:17:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww5u8g",
              "author": "Capitan01R-",
              "text": "i remove the low-vram flag, and I reduce sampling to 1 sample instead of 10 samples, I do not run anything else on my pc during the run I just leave it alone entirely, not even one single tab or open folders. But worse case try renting an rtx5090 on any platform that does training. I only mention runpod bc it has a ready to go template and relatively cheap. But generally speaking this is doable on rtx3090, it might be a bit slower depending on your dataset size if you followed all parameters from the config, that would be the only difference.",
              "score": 1,
              "created_utc": "2025-12-31 10:23:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx0bp0w",
                  "author": "Nepharios",
                  "text": "Thank you! Was able to try after getting my dataset ready. deactivated low-vram, but I think what made the difference is that I did not uncheck the higher resolutions (other than 512). Went through butter smooth after that, exceptional quality. Nice work! Hope to hear from you after base drops.",
                  "score": 1,
                  "created_utc": "2026-01-01 00:58:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwu7b0p",
          "author": "Cautious_Scholar_191",
          "text": "One PSU burned... Those models must be AAA SUPER CRISP results. It takes cracking some eggs to make an omelette.",
          "score": 5,
          "created_utc": "2025-12-31 01:35:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwudvku",
              "author": "Capitan01R-",
              "text": "Haha true that üòÜ",
              "score": 1,
              "created_utc": "2025-12-31 02:12:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwti1hm",
          "author": "haragon",
          "text": "What is the difference between using 512x images vs 512 bucket size?",
          "score": 2,
          "created_utc": "2025-12-30 23:14:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtknie",
              "author": "Capitan01R-",
              "text": "if you're image is 512x512 it's just a resolution, is totally different than a bucket size of 512 pixels as its calculated like this for bucket size 512x512= 262,144 and from these pixels you get variation of resolutions. but with how toned the model is we don't need the hassle of 1024 unless you want to go above and beyond as the model performs well when training the 512 buckets and able to throw out crisp results at even higher resolution like 2k res",
              "score": 2,
              "created_utc": "2025-12-30 23:28:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtqsmn",
                  "author": "haragon",
                  "text": "Would that mean it's taking random crops of the image? Or resizes? Or is it doing some kind of tiling?",
                  "score": 2,
                  "created_utc": "2025-12-31 00:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtuj2p",
          "author": "Segaiai",
          "text": "1. Regarding what you said about simple captioning, what about art styles? There are many that give such unique representations of the world that the model likely doesn't recognize a lot of what's going on in the image. Qwen Edit, for instance, had little concept of anything in a western comic panel from the 80s that I gave it. This tells me that I actually do need to describe the scene and people.\n\n2. Also, if you're training a character, what if you want to allow for clothing changes, when the only data you have is their standard costume? Then should you describe their clothing? Or maybe just say \"action outfit\" to imply that it can be changed?\n\n3. Finally, does this method of using a new checkpoint mean that the lora will be less compatible with the standard checkpoint that everyone is using?",
          "score": 2,
          "created_utc": "2025-12-31 00:22:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtvsry",
              "author": "Capitan01R-",
              "text": "1. yes that's true, also z-image has unique interpretations of some of the wordings, so for style I haven't gotten deep there as of yet.\n\n2.when you want flexible changes in the outfits, what I do is just prompt in the character without extra stuff or clothing specifications and that allowed me to have all outfits the model was trained on, some have other opinions though on that.\n\n3. this method works great on all base checkpoint, de-stilled ones. as I noticed some tried to train some of custom made z-image that were created with de-distilled model, sure you can do that just do not use the adapter as the adapter is only meant for the distilled version. but generally speaking yes this works with all float types.",
              "score": 2,
              "created_utc": "2025-12-31 00:29:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvhne7",
          "author": "infinity_bagel",
          "text": "What is the repo for the SeedVR2 nodes in the workflows you shared? For some reason the manager does not recognize them. I installed https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler thinking it was the same one, but the nodes provided by this repo are different than the ones in your workflow for me",
          "score": 2,
          "created_utc": "2025-12-31 06:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvi1z7",
              "author": "Capitan01R-",
              "text": "sent you the link for the exact custom node folder I have for now, since it's an older version",
              "score": 1,
              "created_utc": "2025-12-31 06:42:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nww6kkh",
          "author": "alb5357",
          "text": "Seedvr2 to sharpen all images? Won't that make your dataset look kinda fake?\n\nWhat if you doubled the dataset, one sharpened and one natural?",
          "score": 2,
          "created_utc": "2025-12-31 10:29:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww76mh",
              "author": "Capitan01R-",
              "text": "You don't need to overly upscale everything, and actually seedvr doesn't sharpen everything with the right parameters and resolution, you gotta treat each photo you upscale with it's own unique needs. as long as you have clear faces you should be golden.",
              "score": 2,
              "created_utc": "2025-12-31 10:35:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwaa31",
                  "author": "alb5357",
                  "text": "I *do* often have blurry loras. I go through my dataset and images all seem high quality...",
                  "score": 2,
                  "created_utc": "2025-12-31 11:04:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtmwxd",
          "author": "TechnologyGrouchy679",
          "text": "this again. your post is riddled with chatgpt emoji bullet points",
          "score": 9,
          "created_utc": "2025-12-30 23:41:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvn1l5",
              "author": "Shartiark",
              "text": "You seem to be completely fucking nuts. \nOP brought a ton of materials, shared his knowledge, collected structured information in one place, and you're whining that he used AI to format it.\n\n\"Please don't just hand us all the information on a silver platter, but take the time to format it by hand to please our eyes.\" \n\nWHAT? \n\nIt makes absolutely no difference whether he lied about using AI or not. The question of whether it was AI shouldn't have been asked in the first place.",
              "score": 28,
              "created_utc": "2025-12-31 07:25:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx049ke",
                  "author": "TechnologyGrouchy679",
                  "text": "shared knowledge that was already known by many...  you sound angry. Your must be a Furkan fan",
                  "score": 3,
                  "created_utc": "2026-01-01 00:12:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwvqg18",
              "author": "Doctor-Wojack",
              "text": "He is doing his best to share a protective knowledge for free not like Patreon paywall shit, stop being ingrateful crying baby.",
              "score": 5,
              "created_utc": "2025-12-31 07:57:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx04mdk",
                  "author": "TechnologyGrouchy679",
                  "text": "there is nothing new here. this is not protective knowledge.",
                  "score": 1,
                  "created_utc": "2026-01-01 00:15:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwto7aj",
              "author": "Capitan01R-",
              "text": "Hahah not really. I don‚Äôt like chatgpt. üòÇüòÇ\n\n\nEdit: Guys I‚Äôm going downhill for this that negative downvote feels like a credit card debt, I said Grok did the formatting part but the idea and rough draft is completely my ideaüòÜü•≤",
              "score": -12,
              "created_utc": "2025-12-30 23:48:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtyw5h",
                  "author": "UncleZoomy",
                  "text": "At least be honest, the second half of your post is AI enhanced at the very least. We all know ChatGPT does that emoji bulleted/bold format. We‚Äôre literally in an AI subreddit bro come on.",
                  "score": 14,
                  "created_utc": "2025-12-31 00:46:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtl43m",
          "author": "n9neteen83",
          "text": "is there a runpod template?",
          "score": 3,
          "created_utc": "2025-12-30 23:31:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtlbkt",
              "author": "Capitan01R-",
              "text": "yes Template on runpod¬†**‚ÄúAI Toolkit - ostris - ui - official‚Äù**",
              "score": 5,
              "created_utc": "2025-12-30 23:32:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtmlnr",
                  "author": "n9neteen83",
                  "text": "Can I ask you about the simple caption?  I have a set of 30 images that I want to train as a characters face.  They are vertical 9:16 now.  Its a woman w long hair wearing a white button up shirt w white background\n\n\nDo I crop her face only like a passport photo and caption all of them \"a young woman wearing a white button up shirt\"?",
                  "score": 2,
                  "created_utc": "2025-12-30 23:39:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtmo6z",
          "author": "xoxavaraexox",
          "text": "Are you going to make a video for those of us who like see how it's done?",
          "score": 3,
          "created_utc": "2025-12-30 23:39:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtnhzl",
              "author": "TechnologyGrouchy679",
              "text": "That be Furkan's job and he will charge you for it",
              "score": 20,
              "created_utc": "2025-12-30 23:44:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwtp7n2",
                  "author": "lostlooter24",
                  "text": "Peak comment",
                  "score": 5,
                  "created_utc": "2025-12-30 23:53:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwufnrb",
                  "author": "ReasonablePossum_",
                  "text": "And create a completely useless ecosystem with random propietary scripts doing the same as what OP posted so it's not copied by the community he stole it from.",
                  "score": 4,
                  "created_utc": "2025-12-31 02:23:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwuoaxv",
          "author": "baalm4",
          "text": "THIS IS HISTORY OF AI, HELLO MOM!!!!",
          "score": 2,
          "created_utc": "2025-12-31 03:14:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwuyje",
          "author": "Electronic_Resist_65",
          "text": "Thanx so much OP! There was already a comment asking for the right SeedVR2 repo. Can you please share this? I only found the regular Version and also have other Workflows that seem to use older SeedVR2 Nodes",
          "score": 1,
          "created_utc": "2025-12-31 13:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwxk6p",
              "author": "Capitan01R-",
              "text": "Sorry yes here is the link for the [older version](https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/tree/1fa603899f2a5329287d5c51a05e1ae166b3f6f1)  , download it as zip, extract it into your custom nodes folder.  then go into your python_embed folder and use this command with your path of course : python.exe -m pip install -r \"C:\\Users\\youruser\\path-to-your-requirements file\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\seedvr2_videoupscaler\\requirements.txt\"",
              "score": 1,
              "created_utc": "2025-12-31 13:58:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwxfdwn",
          "author": "SuddenInitial890",
          "text": "I'm trying to make sure I understand.. \n\nIs the FP32 model used for training, or is it needed to get proper generations with the finished loras?",
          "score": 1,
          "created_utc": "2025-12-31 15:36:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyssyv",
              "author": "Capitan01R-",
              "text": "Essentially when you train on AiToolKit and you use these configs by setting the quantizations to NONE, you are training at full precision since AiToolKit use the full 3 model shards already from the huggingface,So it is all along fp32 training. Now the second part which is using your lora inside of comfyui at its full capacity, what I did for that was merging these 3 shards using the repo I mentioned to have the actual full fp32 weights since the model we previously used inside of comfyui and most famous one that we downloaded was bf16 model, meaning earlier before having the fp32 model we trained on fp32 since AiToolKit was capable of doing that but used bf16 inside of comfyui because we did not have the fp32, which is okay for most people and even me, but since I wanted the full potential of the LoRA and the [missing unet weights] was bugging me I wanted to run it on what I actually trained the LoRA on which is FP32.",
              "score": 1,
              "created_utc": "2025-12-31 19:43:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyu5mz",
          "author": "MikirahMuse",
          "text": "Training adapter is better than de distilled?",
          "score": 1,
          "created_utc": "2025-12-31 19:50:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyuxra",
              "author": "Capitan01R-",
              "text": "You do not use the adapter with the \nde-distilled ‚Äúde-turbo‚Äù. the adapter is only used on the distilled model",
              "score": 1,
              "created_utc": "2025-12-31 19:55:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwyv7jo",
                  "author": "MikirahMuse",
                  "text": "Yes but I'm asking if de turbo was a part of your testing?",
                  "score": 1,
                  "created_utc": "2025-12-31 19:56:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx0xplt",
          "author": "Top-Simple-2235",
          "text": "https://preview.redd.it/cfv44zibpnag1.png?width=2324&format=png&auto=webp&s=d8c2ebe4325953ab78938882e0381af77c5736e0\n\nIt didn't work for me. It gets stuck generating the first images and won't go any further.\"",
          "score": 1,
          "created_utc": "2026-01-01 03:23:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx10xft",
              "author": "Capitan01R-",
              "text": "try to use low vram, your psu has 350w (mine goes up during training to 410w, I have 420w total), and clock is already at 1950 MHz. you're most likely gonna throttle. could you please dm me your main config page ? I already sent you a dm\n\nEDIT: Fixed now.",
              "score": 1,
              "created_utc": "2026-01-01 03:45:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx1et33",
          "author": "Past_Ad6251",
          "text": "To train charactor LoraÔºå1500-steps with 20-30 images is enough for me, more steps means overfitting. 3000-steps is TOO much",
          "score": 1,
          "created_utc": "2026-01-01 05:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx21xki",
          "author": "DJSpadge",
          "text": "Dont mind me, just a bookmark ;)",
          "score": 1,
          "created_utc": "2026-01-01 09:20:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx21zho",
          "author": "Born-Caterpillar-814",
          "text": "I am willing to test your training settings, thank you for the research and detailed post! However I am not sure how to run on 3090 without going oom? \n\nIf I use the RAM offloading at 50% for both TE and model I can start the job with almost maxed out vram, but the job will take several hours. I have sampling prompts set to only one prompt. Otherwise the settings are direct copy paste from your provided config. Vram before job start sits at 15mb / 24 Gb. The low vram setting doesnt seem to have any effect either.",
          "score": 1,
          "created_utc": "2026-01-01 09:20:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx24lto",
              "author": "Born-Caterpillar-814",
              "text": "The solution to fix the issue was a little odd. I rebooted my linux environment and configured the OPs settings by hand in the AI Toolkit gui instead of copying those over from the provided link. Now 21.1 Gb / 24 Gb VRAM utilization during training.",
              "score": 1,
              "created_utc": "2026-01-01 09:48:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2ysia",
                  "author": "Capitan01R-",
                  "text": "Yeah I must‚Äôve done something to the pastebin I will adjust it once I‚Äôm on my pc.",
                  "score": 1,
                  "created_utc": "2026-01-01 14:20:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx2k7u7",
          "author": "DontCallMeLarry",
          "text": "Tried your template on RunPod with a 5090, but i'm getting OOM. what settings could i change that wouldn't appreciably degrade quality? Using Low Vram option is not solving the issue.",
          "score": 1,
          "created_utc": "2026-01-01 12:28:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2ymba",
              "author": "Capitan01R-",
              "text": "That should never happen at all especially with a 5090, try to follow what‚Äôs in the screenshot I uploaded but adjust the saving type from Bf16 to fp32, I will update the config once I get back on my pc.",
              "score": 1,
              "created_utc": "2026-01-01 14:19:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx32h3g",
                  "author": "DontCallMeLarry",
                  "text": "i used the settings you linked: https://pastebin.com/G9LcSitA. I just compared against the screenshot as well and what i have is exactly the same. I'll give it another try later.\nMaybe the issue is that i'm using PNG files that are like 5mb a piece?",
                  "score": 1,
                  "created_utc": "2026-01-01 14:45:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx2uxwl",
          "author": "bdsqlsz",
          "text": "I suspect this might be an issue introduced by BF16.\n\nYou could try switching to FP16 or experimenting with an optimizer that supports random rounding.\n\n[https://github.com/kohya-ss/musubi-tuner/pull/795](https://github.com/kohya-ss/musubi-tuner/pull/795)",
          "score": 1,
          "created_utc": "2026-01-01 13:54:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx4442y",
          "author": "Born-Caterpillar-814",
          "text": "Thanks for the reply, it could also be just my env acting up.\n\nBtw your work is impressive. With these settings and a dataset of my beloved one, this is the first time I get resemblance of her in nearly all generated pictures if I gen with 2k res. Nice!\n\nFor some reason lower res doesn't work so well, but I'll take the higher res likeliness any day over low res. üòä",
          "score": 1,
          "created_utc": "2026-01-01 18:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx79rf5",
          "author": "DaffyDuck",
          "text": "Thanks for trying to contribute something to the community.  Unfortunate that there are unappreciative doofuses here.",
          "score": 1,
          "created_utc": "2026-01-02 04:42:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7age5",
              "author": "Capitan01R-",
              "text": "not a problem at all, honestly all love to everyone. without the community I would not have known and discovered a lot of things!!",
              "score": 1,
              "created_utc": "2026-01-02 04:46:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlhzvx",
          "author": "protector111",
          "text": "Hey OP thanks for the info. WHere can i get this Thinking TE? i",
          "score": 1,
          "created_utc": "2026-01-04 09:02:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlvvgj",
              "author": "Capitan01R-",
              "text": "Np, [here](https://civitai.com/models/2277954?modelVersionId=2563867)",
              "score": 1,
              "created_utc": "2026-01-04 11:07:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxlwmyi",
                  "author": "protector111",
                  "text": "thanks! i was searching civitai by didnt find it... ty again",
                  "score": 1,
                  "created_utc": "2026-01-04 11:14:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwj9xc",
          "author": "razortapes",
          "text": "A post promising great results without showing a single example image ‚Äî that‚Äôs peak comedy üòÇ. Careful, or they‚Äôll delete your account again.",
          "score": 1,
          "created_utc": "2025-12-31 12:21:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwkeju",
              "author": "Capitan01R-",
              "text": "says the one who was constantly asking me for advice then copied my entire config and posted it as OP after my account was hacked, made a post.. took it down after I called him out for stealing. the shameless is peak! your comments are still in my previous post btw... ü•Äü•Ä\n\nhttps://preview.redd.it/d8p3f75vbjag1.png?width=1156&format=png&auto=webp&s=ce034a74893421b099d5c98d6cbf61372f74c2e4",
              "score": 4,
              "created_utc": "2025-12-31 12:30:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwuj7nx",
          "author": "lookwatchlistenplay",
          "text": "Gorilla bark.",
          "score": 1,
          "created_utc": "2025-12-31 02:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww7llx",
          "author": "Omrbig",
          "text": "Thank you for all your work!\n\nThe default template on Runpod alredy has all the correct settings out of the box? I'm most tutorials I've seen they always suggest to change some settings before running üèÉ",
          "score": 1,
          "created_utc": "2025-12-31 10:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww7ulg",
              "author": "Capitan01R-",
              "text": "The template has the default settings not these settings in this post, but if you copy the config file into the config tab you will get these settings",
              "score": 2,
              "created_utc": "2025-12-31 10:41:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nww8ane",
                  "author": "Omrbig",
                  "text": "Oh I didn't know it's possible on Runpod! I'll take a look, thanks a million üôÜ",
                  "score": 2,
                  "created_utc": "2025-12-31 10:46:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtg1od",
          "author": "grovesoteric",
          "text": "Thank you for your service!",
          "score": 0,
          "created_utc": "2025-12-30 23:03:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtgvzt",
              "author": "Capitan01R-",
              "text": "Np, also I will be uploading the fp32 model to my civitai soon and will post the link.",
              "score": 1,
              "created_utc": "2025-12-30 23:08:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwth0wb",
                  "author": "grovesoteric",
                  "text": "Heck yeah!  I'll have to check it out.",
                  "score": 2,
                  "created_utc": "2025-12-30 23:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtsrfr",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2025-12-31 00:13:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtsxnq",
              "author": "Capitan01R-",
              "text": "Np, and no it cannot work on SDXL. Sdxl needs its own training.",
              "score": 3,
              "created_utc": "2025-12-31 00:14:19",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwuqcp9",
              "author": "metafilmarchive",
              "text": "u are idiot?",
              "score": 4,
              "created_utc": "2025-12-31 03:26:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q116sz",
      "title": "Can somebody explain how can I achieve this colour skin?",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/04b2z5dospag1.jpeg",
      "author": "Novarastudio",
      "created_utc": "2026-01-01 10:25:49",
      "score": 136,
      "num_comments": 61,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1q116sz/can_somebody_explain_how_can_i_achieve_this/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nx29pzs",
          "author": "JoelMahon",
          "text": "this was my 2nd try, I'm sure you can get better results with some effort https://chat.qwen.ai/s/eda9020e-cd29-4a0e-81b1-0bfc4ca5d86b?fev=0.1.30",
          "score": 42,
          "created_utc": "2026-01-01 10:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2ea69",
              "author": "obliviate__Niskala",
              "text": "I think it‚Äôll be perfect if you add race too, cause right now it looks like asian woman painted in black",
              "score": 21,
              "created_utc": "2026-01-01 11:30:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2eqai",
                  "author": "JoelMahon",
                  "text": "OP didn't specify a race, given the lack of eyes I genuinely thought that wanted a more almost super natural type vibe rather than a real real person. and yes I am aware people with jet black skin do exist and it's obviously not super natural, it just didn't feel like that's what OP wanted if that makes sense.",
                  "score": 2,
                  "created_utc": "2026-01-01 11:35:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2apxe",
              "author": "Legitimate-Pumpkin",
              "text": "Qwen makes images too? I guess it uses qwen, right?",
              "score": 2,
              "created_utc": "2026-01-01 10:53:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2buld",
                  "author": "JoelMahon",
                  "text": " I confidently **assume** chat.qwen.ai use qwen, haven't actually checked FWIW üòÖ",
                  "score": 4,
                  "created_utc": "2026-01-01 11:05:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx39u7e",
              "author": "blastcat4",
              "text": "I started with your prompt and used \"Vantablack\" as the colour, but the results are pretty similar to yours. \n\n[Imagen 4](https://labs.google/fx/tools/image-fx/56ssvgt68g000)",
              "score": 2,
              "created_utc": "2026-01-01 15:29:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx2awag",
              "author": "Novarastudio",
              "text": "BruhüíÄ",
              "score": -13,
              "created_utc": "2026-01-01 10:55:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx28x50",
          "author": "BeyondRealityFW",
          "text": "Vantablack girl?",
          "score": 20,
          "created_utc": "2026-01-01 10:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2bi2z",
              "author": "Corrupt_file32",
              "text": "actually this one seemed to work to get a final push towards darkest possible skintone, Z-image.\n\nJust added \" , vantablack,\" while describing the skintone\n\nhttps://preview.redd.it/ouded8yfypag1.png?width=1280&format=png&auto=webp&s=439e68d06758da8284b63c1e64648df3a73c8d56",
              "score": 34,
              "created_utc": "2026-01-01 11:01:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2jpef",
                  "author": "LatentDimension",
                  "text": "Damn she's good.",
                  "score": 10,
                  "created_utc": "2026-01-01 12:23:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2loae",
              "author": "Tramagust",
              "text": "Khoudia Diop and Nyakim Gatwech are models that actually have this skin tone. They're not dark brown they're black skinned.",
              "score": 4,
              "created_utc": "2026-01-01 12:41:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxcwcuh",
              "author": "Local-External4193",
              "text": "was just gonna say, the image is vantablack paint, ie no color as it absorbs 99+ or something. so did qwen actually understand what paint that was...amazing",
              "score": 1,
              "created_utc": "2026-01-03 01:15:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx2ayl4",
              "author": "Novarastudio",
              "text": "Will that works?",
              "score": -3,
              "created_utc": "2026-01-01 10:56:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2v5qw",
          "author": "Downtown-Bat-5493",
          "text": "https://preview.redd.it/35aa99w1uqag1.jpeg?width=1024&format=pjpg&auto=webp&s=0b014f42da5def59e34f0f8d7ec3f470d761a906\n\nIs this black enough?\n\nPrompt: Generate portrait photo of a young ebony woman with \"black #000000\" skin tone. She is relaxing on a beach with white sand and blue water at afternoon time.",
          "score": 12,
          "created_utc": "2026-01-01 13:55:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3e1du",
              "author": "Downtown-Bat-5493",
              "text": "https://preview.redd.it/by82s5f3frag1.jpeg?width=967&format=pjpg&auto=webp&s=0e818ddd4db2e9c7f46a9020d347abdffcbbee45",
              "score": 7,
              "created_utc": "2026-01-01 15:53:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx37hka",
              "author": "Novarastudio",
              "text": "Literally helpfulüò≠",
              "score": 3,
              "created_utc": "2026-01-01 15:16:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2c62r",
          "author": "Lonely-Jicama5888",
          "text": "I did some chatgpt prompting and after some back and forward this is the result\n\nhttps://preview.redd.it/c9zkauh20qag1.jpeg?width=1536&format=pjpg&auto=webp&s=9c38637c6390b3e0a4a32b0ce0d1a66e2f6de559\n\n# 000 girl sunbathing on a beach\n\nHer skin color has to be #000\n\nRest of the beach has to be white white like super white sand and super white bathtowel and she has to be ventablack black like 100% taking the light black\n\nNow make the picture landscape so she is whole in the picture and change the bathing suite to black black\n\nI know it aint comfyui prompt but you can see the process hope it helps :)",
          "score": 28,
          "created_utc": "2026-01-01 11:08:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2j4du",
              "author": "TheXyDro",
              "text": "6 toes .. nice üòÅ",
              "score": 3,
              "created_utc": "2026-01-01 12:18:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx2eyvv",
              "author": "JoelMahon",
              "text": "nice, definitely much better than mine, sometimes AI just needs to be talked down to in a condescending and infantilising way fr üòÖ",
              "score": 1,
              "created_utc": "2026-01-01 11:37:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx44gug",
              "author": "Keyflame_",
              "text": "This is such a cool effect, it's not exactly what OP asked, but you made her so black that she legitimately absorbs light like a black hole.\n\nThere might be a lot of uses for this to be cute and artsy.",
              "score": 1,
              "created_utc": "2026-01-01 18:11:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx28vzy",
          "author": "JoelMahon",
          "text": "have you tried prompting with \"#000 colour skin\"? just so the AI is clear that you mean black the colour not black the cultural/ethnicity term.\n\nalso you could say \"pitch black full body and face paint\" maybe? or layer of crude oil üòÖ",
          "score": 19,
          "created_utc": "2026-01-01 10:34:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2au3g",
              "author": "Novarastudio",
              "text": "Not yet but thanks for this üòÇ will ping ya once it works",
              "score": 6,
              "created_utc": "2026-01-01 10:54:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2ioxn",
          "author": "Kastila1",
          "text": "\"Locked character\" \n\nLet me know if it works.",
          "score": 9,
          "created_utc": "2026-01-01 12:14:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2l9w8",
              "author": "Icy-Faithlessness239",
              "text": "That's what I thought.  You need to complete the entire campaign first before you can unlock these characters.",
              "score": 3,
              "created_utc": "2026-01-01 12:38:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx2p99d",
              "author": "Novarastudio",
              "text": "Sure thing!! But it wasn‚Äôt üíÄ",
              "score": 0,
              "created_utc": "2026-01-01 13:11:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3nr5l",
          "author": "Xerminator13",
          "text": "I was able to prompt chatgpt to produce the following image using an initial prompt then an edit:\n\nhttps://preview.redd.it/isee1jxcorag1.jpeg?width=1024&format=pjpg&auto=webp&s=1651612a029c32c5b625664cdb7ff383b2f6c5f2\n\nPrompt:\n\nA statue of a traditionally beautiful woman reclining on a plastic white resort beach chair. The statue is made of smooth matte black marble, creating a striking contrast between the impossibly black woman and the white beach chair. The statue appears to absorb light rather than reflect it due to the nature of the matte black marble. The statue lacks fine details, instead depicting an impressionist silhouette of a woman. The statue sits outside on a beach with pure white sand, on a background of calm desaturated teal sea water and a pale baby blue sky on a cloudy day in the late afternoon. The photograph captures the statue at a side profile on a long shot and centers the subject in the frame.\n\nEdit:\n\nThe statue should be wearing a black bikini. The statue should be b the color black (#000) to attempt to obscure specific details of the woman, instead highlighting her silhouette.",
          "score": 3,
          "created_utc": "2026-01-01 16:45:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2b8wi",
          "author": "pioo84",
          "text": "You have to go to the solarium a lot.",
          "score": 7,
          "created_utc": "2026-01-01 10:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3ef9p",
          "author": "No_Mind7198",
          "text": "90 minutes at 450",
          "score": 3,
          "created_utc": "2026-01-01 15:55:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2gpyj",
          "author": "Kauko_Buk",
          "text": "Try \"vanta black\" üòÅ",
          "score": 2,
          "created_utc": "2026-01-01 11:55:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2nkww",
              "author": "XonikzD",
              "text": "It's hard with modern image gen models as they've locked out a lot of celebrity and fashion model names for image referencing, but the OP could reference Nyakim Gatwech in the prompt and likely get the look without weird #000 or \"vantablack\" skin tone prompting that reduces skin tone and shaping in the final result.",
              "score": 1,
              "created_utc": "2026-01-01 12:58:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2pb4c",
          "author": "phocuser",
          "text": "Try using the words  vantablack, black 3.0. see if that works",
          "score": 2,
          "created_utc": "2026-01-01 13:12:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx39f9b",
          "author": "Digital-Ego",
          "text": "Increase contrast",
          "score": 2,
          "created_utc": "2026-01-01 15:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx54ykc",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-01-01 21:15:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx57ddp",
              "author": "Spare_Ad2741",
              "text": "nice...",
              "score": 2,
              "created_utc": "2026-01-01 21:28:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3bna8",
          "author": "Any-Scar765",
          "text": "A woman reclining on a white sun lounger on a sandy beach by the sea, side view.\nSkin tone: extremely deep, uniform dark skin with very low reflectance, near-absolute black tone,\nmatte surface, minimal specular highlights, no visible color cast, no brown or warm undertones,\nsmooth continuous shading with correct light falloff.\nNatural daylight, soft coastal lighting, high dynamic range, realistic anatomy, clean silhouette.\nMinimalist composition, pale sand, light blue sky, calm ocean horizon.\nPhotorealistic, high detail, accurate skin luminance, physically correct lighting.",
          "score": 1,
          "created_utc": "2026-01-01 15:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx549il",
          "author": "GraftingRayman",
          "text": "Try this, works pretty good, though comes up different on different monitors.\n\nhumanoid female figure, wearing a vibrant red floral dress, holding a green glass bottle,\nskin made of absolute light-absorbing black material, zero reflectance, void-like surface,\nno visible skin texture, no pores, no highlights, no subsurface scattering,\nskin darker than shadows, darker than hair,\nlong black hair blending into shadow with no edge light,\nflat neutral lighting, no rim light, no backlight,\nindoor laboratory setting, metal work surfaces, shallow depth of field",
          "score": 1,
          "created_utc": "2026-01-01 21:11:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5atto",
          "author": "Green-Ad-3964",
          "text": "https://preview.redd.it/bf80iudp5tag1.jpeg?width=1800&format=pjpg&auto=webp&s=054479ab8b588d39fd8d92795b653e5cec66e9ea\n\nNot exactly the same‚Ä¶ but I asked a friend of mine to paint her body and pose for me.\n\nJust kidding, though maybe someone had imagined it. I made it with Z-Image Turbo, using the same prompt used by a contributor above.",
          "score": 1,
          "created_utc": "2026-01-01 21:45:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5sahp",
          "author": "BoulderRivers",
          "text": "I believe this level of control is where previous generation tools would be better for the granular control of results",
          "score": 1,
          "created_utc": "2026-01-01 23:19:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx73vl0",
          "author": "suresh_deora_seducer",
          "text": "You've to wait for summer üåûüòÅ",
          "score": 1,
          "created_utc": "2026-01-02 04:03:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx78v2d",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-02 04:36:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7ls5n",
          "author": "Bozhark",
          "text": "Glossy vanta black¬†",
          "score": 1,
          "created_utc": "2026-01-02 06:10:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8tquv",
          "author": "CapitanM",
          "text": "Ask for just the shilouette",
          "score": 1,
          "created_utc": "2026-01-02 12:43:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaf7q2",
          "author": "tostane",
          "text": "You may be looking for the looks of Nyakim Gatwech a South Sudanese model   \n\nhttps://preview.redd.it/5mfr4z2a4zag1.png?width=320&format=png&auto=webp&s=e84e45f1857e62f17f128ea0d9b2c25ee1adddf2\n\nThis is here real photo  do not use it for ai.",
          "score": 1,
          "created_utc": "2026-01-02 17:47:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb9u67",
              "author": "Novarastudio",
              "text": "Appreciate that finding stuff like thisü•∑üèø but still people gonna use her to train as their model",
              "score": 1,
              "created_utc": "2026-01-02 20:10:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxdkb8v",
                  "author": "tostane",
                  "text": "I tried to get open ai to make a prompt to recreate her look as standing but just could not get her essence to shine the same.",
                  "score": 1,
                  "created_utc": "2026-01-03 03:36:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx2d2tz",
          "author": "leftonredd33",
          "text": "Photoshop!",
          "score": 1,
          "created_utc": "2026-01-01 11:18:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2but1",
          "author": "seppe0815",
          "text": "??? i can see nothing realy ... oled screen",
          "score": 1,
          "created_utc": "2026-01-01 11:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2cilw",
          "author": "tyrwlive",
          "text": "Damn this shit blood diamond black",
          "score": 1,
          "created_utc": "2026-01-01 11:12:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2gdch",
          "author": "Sir_McDouche",
          "text": "African coal mine girl.",
          "score": 0,
          "created_utc": "2026-01-01 11:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3p9rz",
          "author": "Special_DJK10",
          "text": "Mudflap Lora",
          "score": 0,
          "created_utc": "2026-01-01 16:53:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2pcm3",
          "author": "Massive_Passion_7368",
          "text": "What color is her ()?",
          "score": -3,
          "created_utc": "2026-01-01 13:12:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2nkeq",
          "author": "Sioluishere",
          "text": "Ah, the great -redacted- skin lora",
          "score": -2,
          "created_utc": "2026-01-01 12:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5sdh5",
          "author": "shivdbz",
          "text": "I don‚Äôt think human come with this skin color. They never made with this color",
          "score": -2,
          "created_utc": "2026-01-01 23:19:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx73rs2",
              "author": "OldTrapper87",
              "text": "Its called \"blue black\" and its real.",
              "score": 2,
              "created_utc": "2026-01-02 04:03:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1k0iu",
      "title": "SugarCubes Preview - Reusable, Shareable Workflow Segments",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/crrasm5hytag1",
      "author": "ArtificialSweetener-",
      "created_utc": "2026-01-02 00:32:13",
      "score": 128,
      "num_comments": 26,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q1k0iu/sugarcubes_preview_reusable_shareable_workflow/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nx6dyyn",
          "author": "sci032",
          "text": "You can also save things as a template(built in). The node on the left is a subgraph I built and saved as a template, on the right is some of the templates I have saved(blocks like the ZIT+External\\_Inputs node or even full workflows). I can just drop in whatever I need when I need them.\n\nhttps://preview.redd.it/zv7rei2g8uag1.png?width=1828&format=png&auto=webp&s=4c59e98d4e249497ceaadeec771da1860df72d72",
          "score": 11,
          "created_utc": "2026-01-02 01:22:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6iz21",
              "author": "ArtificialSweetener-",
              "text": "Here's my notes on that. Let me know if I say something that's wrong, please:  \n \\- Templates load the whole graph, they don't load on top of the workspace you have opened.  \n \\- So the only way to use templates like how I am proposing SugarCubes is to copy the workflow segment you have saved as a template and paste it into the workflow you're actually working on  \n \\- Comfy DOES have a built in feature called \"Template Packs\" but there is no way to create them in modern ComfyUI. Template Packs actually can be loaded in on top of workflows rather than opening a new one, and this is very similar to if not the same path that copy/paste uses\n\nUltimately I want a more organized and sharable way to create these kinds of workflow segments. Saving your segments in separate template files is clever, but it's not a full solution like Cubes will be, at least not for the problem I have.\n\nI should note, subgraphs are very very close to what I want. My main problem with subgraphs is really just the way the abstraction was implemented. Subgraphs can be \"published\" which saves them for later and makes them nodes in the node lookup. That's great!\n\nBut I find myself using them primarily for smaller workflow sections rather than larger steps in the workflow because a subgraph can make things harder to reason about when used for larger sections - at least for me. Seeing one node with a big stack of inputs is unwieldy, though it's excellent that we can zoom into subgraphs when we need to reason about those sections more deeply.\n\nSubgraphs often have many inputs and outputs just like a normal node. Cubes are best when they only have one input and one output. It involves a more compartmentalized style of graph building. There is nothing stopping you from doing it with subgraphs, though!",
              "score": 4,
              "created_utc": "2026-01-02 01:53:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx75jsc",
                  "author": "sci032",
                  "text": "*Here's my notes on that. Let me know if I say something that's wrong, please:*  \n*- Templates load the whole graph, they don't load on top of the workspace you have opened.*\n\nThat's not the way they work. They only load what you saved in the template and and can be added to any workflow. There is no copy/pasting involved.\n\nThe workflow in the image:\n\nEvery group is a template that I have saved and I just added them in. No, I wouldn't use all of this like this, but, I could. It flows. If there is a group in there that I decide that I don't want to use, I can bypass or delete it.\n\nSearge: I enter a prompt and it enhances it and then sends it to the Prompt from filesx3 node.\n\nPrompt From Filesx3: It lets you load up to 3 simple text files that contain prompts. It works similar to wildcards. The 2 text boxes: the top one is added to the beginning of the prompt, the 2nd one is added to the end. Both are optional. This contains clip text encode nodes which get their clip model from the SDXL subgraph.\n\nControlnet: the created prompt is sent to the Controlnet which processes it and sends it through the heart of the workflow, the SDXL subgraph.\n\nFaceID: it uses the model from the SDXL subgraph, processes it, and then sends it back to be sent through the SDXL subgraph to the ksampler.\n\nThe output of the XL subgraph is sent through an outpaint subgraph(a full outpaint workflow that only needs input and output image nodes) and is outpainted. I could easily make the outpaint node use the same model that is in the XL subgraph. The output of that is sent to the Wan 1st/last subgraph(a full wan workflow that just needs image inputs) and is used as the 1st image. The loose load image node is for the final image for the wan subgraph.\n\nI started this with the SDXL subgraph group and dropped all of the other templates in. No copy/pasting, I just opened the template menu and selected the one that I wanted and clicked on it. The SDXL subgraph is a full workflow that can work with only an output image node connected to it. The other connections do not have to be connected. The switches control the inputs. The ouput connections are just there so it can be used for other things like I did here.\n\nI only show items on the faces of the subgraphs that I may want to change. Everything else is hidden inside.\n\nI'm not saying what you are doing is bad, I'm just showing an alternative that is built in to Comfy. :)\n\nhttps://preview.redd.it/d47bvzln3vag1.png?width=3695&format=png&auto=webp&s=03ec1c2e2b822409c9311b505ea97c43bcdf0c91",
                  "score": 4,
                  "created_utc": "2026-01-02 04:14:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx92z2h",
          "author": "janosibaja",
          "text": "I like it, thank you, I'm following you",
          "score": 2,
          "created_utc": "2026-01-02 13:44:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx954jh",
          "author": "inb4Collapse",
          "text": "FFS, yes!",
          "score": 2,
          "created_utc": "2026-01-02 13:57:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx9yr3t",
          "author": "Dogluvr2905",
          "text": "Very cool contribution to the community - nice job! thx",
          "score": 2,
          "created_utc": "2026-01-02 16:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa877v",
          "author": "muteki1982",
          "text": "what's the github link?",
          "score": 2,
          "created_utc": "2026-01-02 17:14:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q40d6b",
      "title": "Simple yet Powerful Face Swap Pipeline: ReActor + FaceDetailer (Fixing the 128px limitation)",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/vuo0ad1l0ebg1.png",
      "author": "Otherwise_Ad1725",
      "created_utc": "2026-01-04 20:17:21",
      "score": 120,
      "num_comments": 22,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/comfyui/comments/1q40d6b/simple_yet_powerful_face_swap_pipeline_reactor/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxp12zu",
          "author": "Otherwise_Ad1725",
          "text": "Workflow: [https://drive.google.com/file/d/1r2D0YiAGprGRpoQllzuAg5LGeFsIGDPo/view?usp=drive\\_link](https://drive.google.com/file/d/1r2D0YiAGprGRpoQllzuAg5LGeFsIGDPo/view?usp=drive_link)",
          "score": 17,
          "created_utc": "2026-01-04 21:04:54",
          "is_submitter": true,
          "replies": [
            {
              "id": "nxsp7ht",
              "author": "skyrimer3d",
              "text": "Thanks!, i'll check it out asap",
              "score": 1,
              "created_utc": "2026-01-05 10:46:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxotgos",
          "author": "Spare_Ad2741",
          "text": "https://preview.redd.it/odpxpwy37ebg1.png?width=1900&format=png&auto=webp&s=4f14d0b06ad0d442b7948add99c1577c8718bd0e",
          "score": 10,
          "created_utc": "2026-01-04 20:29:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxqxkso",
              "author": "theloneillustrator",
              "text": "How do I get reactor node?\n\nhttps://preview.redd.it/uazwfcoa2gbg1.png?width=531&format=png&auto=webp&s=fdad438ebb8d92b1e7b7445cfe75989e43923966",
              "score": 3,
              "created_utc": "2026-01-05 02:46:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxqyajt",
                  "author": "Spare_Ad2741",
                  "text": "bastards!.... try here \n\n[https://codeberg.org/Gourieff/comfyui-reactor-node](https://codeberg.org/Gourieff/comfyui-reactor-node)",
                  "score": 5,
                  "created_utc": "2026-01-05 02:49:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxtmpev",
                  "author": "Otherwise_Ad1725",
                  "text": "https://preview.redd.it/1l6id23vkjbg1.png?width=2948&format=png&auto=webp&s=4a0d950b4bfaed7e3fd962c83f6e5be9c803168b",
                  "score": 1,
                  "created_utc": "2026-01-05 14:35:37",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxot7he",
          "author": "Spare_Ad2741",
          "text": "try this model with comfyui [https://huggingface.co/datasets/Gourieff/ReActor/blob/main/models/reswapper\\_256.onnx](https://huggingface.co/datasets/Gourieff/ReActor/blob/main/models/reswapper_256.onnx) \n\nand GFPGANv1.4\n\nhttps://preview.redd.it/qxf0kfuv6ebg1.png?width=458&format=png&auto=webp&s=9b592194f66db855c5c88ac4f95e6f43aec8c690",
          "score": 7,
          "created_utc": "2026-01-04 20:28:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxs9kvn",
          "author": "Bitter-Pen-3389",
          "text": "this is like two year old node",
          "score": 5,
          "created_utc": "2026-01-05 08:21:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxu8vyc",
              "author": "Spare_Ad2741",
              "text": "so...? i get good results with reswapper\\_256. that's all i care about.",
              "score": 3,
              "created_utc": "2026-01-05 16:24:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxq3lmq",
          "author": "Lightningstormz",
          "text": "Thanks for the workflow bolt on.",
          "score": 1,
          "created_utc": "2026-01-05 00:09:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrzp1p",
          "author": "Arcival_2",
          "text": "Does anyone know if Reactor has implemented the method for splitting the image into multiple images based on different pixels to increase ending resolution? Or does it still need to be done previously?",
          "score": 1,
          "created_utc": "2026-01-05 06:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxvhaxw",
          "author": "Rootsking",
          "text": "It works but I had to get some help from Chatgpt for positive and negative inputs on facedetailer.",
          "score": 1,
          "created_utc": "2026-01-05 19:46:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwsqxf",
          "author": "seifai",
          "text": "I can see 3 faces not a face swap!",
          "score": 1,
          "created_utc": "2026-01-05 23:34:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxoyivv",
          "author": "skyrimer3d",
          "text": "Worflow?¬†",
          "score": 0,
          "created_utc": "2026-01-04 20:52:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxozs9k",
              "author": "Otherwise_Ad1725",
              "text": "Do you want the Workflow?",
              "score": 0,
              "created_utc": "2026-01-04 20:58:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxp0cwj",
                  "author": "skyrimer3d",
                  "text": "Sure¬†",
                  "score": 2,
                  "created_utc": "2026-01-04 21:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q3saec",
      "title": "Really good results - SVI Pro 2.0 with Upscaling - 20 Sec Video on RTX 3070 8GB",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/8p0qrm93kcbg1",
      "author": "TheMagic2311",
      "created_utc": "2026-01-04 15:11:33",
      "score": 117,
      "num_comments": 46,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q3saec/really_good_results_svi_pro_20_with_upscaling_20/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxn4apk",
          "author": "Training_Fail8960",
          "text": "looks good but how to avoid the slowmotion?",
          "score": 12,
          "created_utc": "2026-01-04 15:52:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxo0uie",
              "author": "TheMagic2311",
              "text": "like [Successful\\_Round9742](https://www.reddit.com/user/Successful_Round9742/) said, you can use 24 fps to get rid of the slow motion, but If I did want to do it, the generation time would take over an hour, I will generate one but only for 10 seconds to show the results",
              "score": 8,
              "created_utc": "2026-01-04 18:22:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxnwqr0",
              "author": "Better-Interview-793",
              "text": "Use wan 2.2 smooth mix",
              "score": 9,
              "created_utc": "2026-01-04 18:04:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxol0qv",
              "author": "Segaiai",
              "text": "I like to use Wan Enhanced Cam V2 (not NSFW). It has great motion and camera control. The prompt adherence is the best I know of.",
              "score": 3,
              "created_utc": "2026-01-04 19:50:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxne4be",
              "author": "Successful_Round9742",
              "text": "Most workflows default to 16 fps, but Wan 2.2 generates motion for ~30 fps.",
              "score": -5,
              "created_utc": "2026-01-04 16:38:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxo24sq",
                  "author": "WalkSuccessful",
                  "text": "This is bs.",
                  "score": 9,
                  "created_utc": "2026-01-04 18:27:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxng1my",
                  "author": "Eshinio",
                  "text": "Are you saying the slowmotion can be removed, by setting the fps to something higher like 24? I have yet to see an SVI Pro 2.0 workflow that does not have slowmotion output.",
                  "score": 4,
                  "created_utc": "2026-01-04 16:47:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxoxciq",
                  "author": "Scriabinical",
                  "text": "this is not true at all. wan 2.2 was trained for 16fps.",
                  "score": 4,
                  "created_utc": "2026-01-04 20:47:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxq6izm",
                  "author": "superstarbootlegs",
                  "text": "its a 16fps model. you can put whatever you want, but it outputs 16fps.",
                  "score": 2,
                  "created_utc": "2026-01-05 00:23:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxncacu",
          "author": "KS-Wolf-1978",
          "text": "Except the morphing face, looks good.",
          "score": 5,
          "created_utc": "2026-01-04 16:30:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxnyce5",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-01-04 18:11:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxnslma",
          "author": "serendipity777321",
          "text": "Eyes are glitchy",
          "score": 5,
          "created_utc": "2026-01-04 17:45:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxoq1vk",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 4,
          "created_utc": "2026-01-04 20:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxp2bl6",
              "author": "TheMagic2311",
              "text": "True, I realised somthing, the more complicated is the prompt, the slower the video is, very weird behaviour.",
              "score": 1,
              "created_utc": "2026-01-04 21:10:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxnh44g",
          "author": "chAzR89",
          "text": "37 minutes is rough but still looks promising. How do these 37 minutes compare to a workflow that generates multiple short clips with ff2lf or the recently posted \"wan long video\" workflow?\n\nI know chunking generation isn't the same as one long video gen, I'm simply curious since I haven't tested SVI yet myself due to limited time. \n\nWill definitely give this a try as soon as I get some spare time.",
          "score": 3,
          "created_utc": "2026-01-04 16:52:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxnt101",
              "author": "TheMagic2311",
              "text": "believe me, 37 minutes for Laptop RTX 3070 is amazing.",
              "score": 6,
              "created_utc": "2026-01-04 17:47:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxo1vn7",
                  "author": "chAzR89",
                  "text": "Sorry if it came across so negative, wasn't intentional. I think it's amazing something like this even works with 8 or 12gb vram in the first place.\nIt's always nice how some wizards of the community can reduce the required resources for amazing tech like this.",
                  "score": 7,
                  "created_utc": "2026-01-04 18:26:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxnyb4p",
                  "author": "Green-Ad-3964",
                  "text": "how is it compared to a desktop 5090? like...5 minutes?",
                  "score": 1,
                  "created_utc": "2026-01-04 18:11:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxnzq85",
          "author": "countjj",
          "text": "How are you upscaling without running out of DRAM? Every time I try to comfyUI eats all my DRAM and shuts itself down",
          "score": 3,
          "created_utc": "2026-01-04 18:17:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxs5w52",
              "author": "TheMagic2311",
              "text": "I did set 48GB Page file (Windows Virtual memory)",
              "score": 1,
              "created_utc": "2026-01-05 07:46:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxs7ld1",
                  "author": "countjj",
                  "text": "Oof I‚Äôm not on windows",
                  "score": 1,
                  "created_utc": "2026-01-05 08:02:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxn1gsq",
          "author": "fmnpromo",
          "text": "Im getting errors using sageattention",
          "score": 2,
          "created_utc": "2026-01-04 15:39:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxn4d0v",
              "author": "Permitty",
              "text": "Lots of people get sageattention errors. Not even sure how to fix it myself.",
              "score": 3,
              "created_utc": "2026-01-04 15:53:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxn5dct",
                  "author": "fmnpromo",
                  "text": "yeah",
                  "score": 2,
                  "created_utc": "2026-01-04 15:58:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxngcjt",
              "author": "vibrantLLM",
              "text": "Are you using a workflow with \"WAN Wrapper\" nodes? I was getting CUDA and sage errors with them, so I tried another workflow that doesn't use it and everything worked.",
              "score": 3,
              "created_utc": "2026-01-04 16:49:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxnsmh1",
              "author": "TheMagic2311",
              "text": "auto cause error for me too, use sageattn\\_qk\\_int8\\_pv\\_fp16\\_triton option.",
              "score": 3,
              "created_utc": "2026-01-04 17:45:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxo55ga",
          "author": "VirusCharacter",
          "text": "Another slowmo video by WAN ü§î",
          "score": 2,
          "created_utc": "2026-01-04 18:40:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxpqug7",
          "author": "Green-Ad-3964",
          "text": "Care to share your modded wf? Thanks in advance.",
          "score": 2,
          "created_utc": "2026-01-04 23:06:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxs66gy",
              "author": "TheMagic2311",
              "text": "[https://civitai.com/models/2280989?modelVersionId=2567220](https://civitai.com/models/2280989?modelVersionId=2567220)",
              "score": 2,
              "created_utc": "2026-01-05 07:49:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxng6gn",
          "author": "Eshinio",
          "text": "If just we could get rid of the damn slowmotion output for SVI Pro 2.0, it would be amazing...",
          "score": 1,
          "created_utc": "2026-01-04 16:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnw00y",
          "author": "Better-Interview-793",
          "text": "Slow motion, just use the smoothmix wan2.2",
          "score": 1,
          "created_utc": "2026-01-04 18:00:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxo7ueq",
          "author": "alitadrakes",
          "text": "I was out for a whilw, what is SvI Pro 2.0? Lora?",
          "score": 1,
          "created_utc": "2026-01-04 18:52:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxp1ymo",
              "author": "TheMagic2311",
              "text": "It is lora for stable and smooth transition between video samples for infinite extensions",
              "score": 3,
              "created_utc": "2026-01-04 21:09:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxq74ud",
          "author": "GRCphotography",
          "text": "cool",
          "score": 1,
          "created_utc": "2026-01-05 00:26:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxs3sru",
          "author": "nadhari12",
          "text": "Almost there! But face consistency is a hit or miss for me! Especially if they get obstructed, like for example, someone eats a popsicle and in the second or 3rd generation when done eating the popsicle, the face is someone else.",
          "score": 1,
          "created_utc": "2026-01-05 07:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxs5ybp",
          "author": "TheMagic2311",
          "text": "I have posted my Workflow: [https://www.reddit.com/r/comfyui/comments/1q4flqw/my\\_svi\\_pro\\_20\\_for\\_low\\_vram\\_8gb\\_workflow\\_included/](https://www.reddit.com/r/comfyui/comments/1q4flqw/my_svi_pro_20_for_low_vram_8gb_workflow_included/)",
          "score": 1,
          "created_utc": "2026-01-05 07:47:25",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxs8h54",
          "author": "roxas4sora",
          "text": "di u use GGUF or default ?",
          "score": 1,
          "created_utc": "2026-01-05 08:10:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxs8jsd",
              "author": "TheMagic2311",
              "text": "GGUF",
              "score": 2,
              "created_utc": "2026-01-05 08:11:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyxgr9",
          "author": "Cool_Reserve_9250",
          "text": "I hate the slo mo. How many seconds a normal speed?",
          "score": 1,
          "created_utc": "2026-01-06 07:28:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny05ak2",
          "author": "Conscious-Citzen",
          "text": "Am I wrong to assume I'd get closer results using a 3060ti?",
          "score": 1,
          "created_utc": "2026-01-06 13:30:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2sq25",
      "title": "Please bring back the old ‚ÄúCancel queue‚Äù button and the queue list layout",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/xnify2m5c4bg1.png",
      "author": "Ok-Page5607",
      "created_utc": "2026-01-03 11:48:08",
      "score": 113,
      "num_comments": 31,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1q2sq25/please_bring_back_the_old_cancel_queue_button_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxfima2",
          "author": "Yasstronaut",
          "text": "They focused on UI and neglected UX unfortunately. The number of clicks is higher - there are no designated areas , so everything requires searching in multiple spaces or memorization .",
          "score": 35,
          "created_utc": "2026-01-03 12:51:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxic3fz",
              "author": "slpreme",
              "text": "and using keyboard shortcuts",
              "score": 1,
              "created_utc": "2026-01-03 21:19:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxfp9wa",
          "author": "michael-65536",
          "text": "The amount of dev time being wasted is disappointing.\n\nAdding some sorting, multi-select and display type options to the interface from a year ago would have made more sense than repeatedly re-hashing the interface, half-finishing it and then starting again before it barely reaches the level of function of what it replaces.\n\nThe hundreds of dev hours spent on musical chairs with the interface could have been used to do things **which actually needed doing and are still an issue now** to varying degrees. Such as dependency hell, making custom node installation process stricter and more reliable, proper versioning correspondence between core and custom, enforcing datatyping properly, creating a more granular node installation scheme (so users don't need to install 200 nodes for the one they actually use),  adding equivalents to the most popular custom nodes into core, fixing the horribly inefficient code for adding tasks to the queue (which gets slower the more things you add in one go).\n\nHow many pointless interface tweaks have there been in the time it took to add a mask preview node? How many more will there be before there's a gaussian blur mask node in core?\n\nHonestly don't know what's going on over there.",
          "score": 19,
          "created_utc": "2026-01-03 13:34:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgf7ww",
              "author": "1filipis",
              "text": "+1 for essential custom nodes into core. Primitive stuff has been missing for years. Image comparing, cropping, adjustments, compositing, working with masks - all the stuff that people install 1000s of custom nodes for could have been integrated into the base in minutes. Yet all we get is UI from Figma designers that have lost touch with reality",
              "score": 9,
              "created_utc": "2026-01-03 15:54:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxicbmt",
                  "author": "slpreme",
                  "text": "figma comment üò≠",
                  "score": 2,
                  "created_utc": "2026-01-03 21:20:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxg7g1o",
          "author": "Phuckers6",
          "text": "Also, why can't we use the cancel button to cancel the job before it has started? Why must I use the \"...\" dropdown to do it? Sometimes I have made a mistake in a set of prompts, but I only want to remove the recently added jobs, instead of clearing the entire queue. Removing them would go much faster if I didn't have to open up the \"...\" menu for every instance.  \n  \nCan't you allow me to do it by pressing shift or something when I use the red cancel button?  \n\n\nhttps://preview.redd.it/5ygjor5kh5bg1.png?width=334&format=png&auto=webp&s=1968dc8a2e5b3822c66dd477bf99dc6084e91f6b\n\nError: \"\\[...\\] not currently running, skipping interrupt\"",
          "score": 7,
          "created_utc": "2026-01-03 15:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhd0cm",
              "author": "hum_ma",
              "text": "Yep, that bug was annoying and it was just fixed a few days ago:\nhttps://github.com/Comfy-Org/ComfyUI_frontend/issues/7758",
              "score": 9,
              "created_utc": "2026-01-03 18:31:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxhhp0o",
                  "author": "Phuckers6",
                  "text": "Oh, okay, thanks for the info!",
                  "score": 4,
                  "created_utc": "2026-01-03 18:52:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxhan5h",
          "author": "hum_ma",
          "text": "There is this PR: https://github.com/Comfy-Org/ComfyUI_frontend/pull/7617\n\nAdd a thumb up to get it merged?",
          "score": 7,
          "created_utc": "2026-01-03 18:20:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhtk52",
          "author": "uniquelyavailable",
          "text": "The constantly changing UI is annoying.",
          "score": 6,
          "created_utc": "2026-01-03 19:47:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2jakf",
              "author": "nomuse22",
              "text": "They are trying to be Windows.",
              "score": 2,
              "created_utc": "2026-01-06 20:17:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxg52mi",
          "author": "Green-Ad-3964",
          "text": "I lost that bar completely...how to bring it back? I'm using CTRL+enter to start jobs, currently...",
          "score": 3,
          "created_utc": "2026-01-03 15:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxk3787",
          "author": "RavioliMeatBall",
          "text": "I always use the old original UI, the newer UI don't make sense to me.",
          "score": 3,
          "created_utc": "2026-01-04 02:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfgzuc",
          "author": "KS-Wolf-1978",
          "text": "Dear Devs ! :)\n\nLet there be options for every new UI idea.\n\nPlease don't assume you know better what is more comfortable for users and how they prefer to work. :)\n\nBTW The fewer clicks, mouse movements, keystrokes to do anything, the better.",
          "score": 14,
          "created_utc": "2026-01-03 12:39:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxg5tkl",
              "author": "Old_System7203",
              "text": "\nOptions for every UI idea - so that the options themselves become unmanageable, and every possible combination (exponentially scaling) has to be tested for every release.\n\nGreat idea.",
              "score": 2,
              "created_utc": "2026-01-03 15:07:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxg9900",
                  "author": "KS-Wolf-1978",
                  "text": "\"unmanageable\"\n\nJust categorize them logically and add a search box, no problem in for example Reaper DAW.",
                  "score": 0,
                  "created_utc": "2026-01-03 15:25:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxfp4da",
          "author": "Ill_Ease_6749",
          "text": "bro their focus is on api and just developing not needed shit",
          "score": 2,
          "created_utc": "2026-01-03 13:33:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfbqtw",
          "author": "noyart",
          "text": "Tho i have now gotten used to the new UI, i do think the earlier UI was simpler. The new UI feels and looks like something i would imagine a cloud service would use as its front end. The layout and the texts reads more like if i was using a service or something like that.¬†",
          "score": 3,
          "created_utc": "2026-01-03 11:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxffldw",
              "author": "protector111",
              "text": "It was much simpler. You need to click 2x more buttons and open windows to so same things that could be sone with 1 button. When u do this 1000 times a day it turns in to hours wasted",
              "score": 9,
              "created_utc": "2026-01-03 12:29:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjkmni",
          "author": "DigThatData",
          "text": "given that they've separated the frontend and backend, it feels like there ought to be an easy way to revert to the old look, right? you probably just need to pin the frontend to a particular commit.",
          "score": 1,
          "created_utc": "2026-01-04 01:08:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlg8cu",
          "author": "rngesius",
          "text": "Comfy: fuck you & subscribe to our cl$$d.",
          "score": 1,
          "created_utc": "2026-01-04 08:46:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlyh1u",
          "author": "yoomiii",
          "text": "And what is up with the image preview node, where I now have to click on the individual tiny dots below the picture to view the results (with batch size > 1) instead of clicking a much larger button a few times, without having to avert my attention from the thing that I'm actually interested in, being the images.",
          "score": 1,
          "created_utc": "2026-01-04 11:30:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxn1jgc",
          "author": "Eriane",
          "text": "Would appreciate if the cancel queue feature would still work. So far, you have to restart the server. Huge pain.",
          "score": 1,
          "created_utc": "2026-01-04 15:39:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxoavrm",
          "author": "Generic_Name_Here",
          "text": "I hate hate hate the new setup.\n\nWhat we‚Äôve lost:\n- A unified queue where we can see past and pending results\n\n- The ability to load workflows from the queue and have the images load with it.  Right now it loads the workflow without loading any results.  Want to check the workflow and make tweaks while looking at the results?  Have a complex workflow with multiple outputs you need to compare when you crash and have to re-open the workflow?  Well fuck you I guess.\n\n- The ability to see all workflows run, even if they failed or didn‚Äôt produce an image result.\n\nNow it‚Äôs spread out over three different menus, none of which work nearly as well. And is missing half the functionality.\n\nLove comfy, hate this particular thing.",
          "score": 1,
          "created_utc": "2026-01-04 19:05:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgky9d",
          "author": "BeautyxArt",
          "text": "\\*please bring back legacy comfyui we used to know.",
          "score": 1,
          "created_utc": "2026-01-03 16:22:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxis2yq",
          "author": "TheDownvotesFarmer",
          "text": "Guys it is because we all have wrong workflows! ü§¶üèª‚Äç‚ôÇÔ∏è I will publish one in few hours that will help everyone's hardware",
          "score": -1,
          "created_utc": "2026-01-03 22:38:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxge6q2",
          "author": "1filipis",
          "text": "I don't appreciate the work that goes into these updates. When there's no respect from dev to community, why should I have any respect in return? They have $17M reasons to ignore your complaints and still do just fine",
          "score": -2,
          "created_utc": "2026-01-03 15:49:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxmzw8",
      "title": "[Release] ComfyUI-Doctor: Stop guessing why your workflow failed.",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1pxmzw8",
      "author": "rayfreeman1",
      "created_utc": "2025-12-28 09:08:52",
      "score": 108,
      "num_comments": 12,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1pxmzw8/release_comfyuidoctor_stop_guessing_why_your/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwcnmfj",
          "author": "knselektor",
          "text": "nice work, last week this was released and maybe you can use it:\n\n[https://github.com/calebevans/cordon](https://github.com/calebevans/cordon)\n\n\"Cordon uses transformer embeddings and density scoring to identify semantically unusual patterns in large log files, reducing massive logs to the most anomalous sections for analysis. Repetitive patterns (even errors) are considered \"normal background.\" Cordon surfaces unusual, rare, or clustered events that stand out semantically from the bulk of the logs.\"",
          "score": 6,
          "created_utc": "2025-12-28 11:59:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwc78di",
          "author": "Lil_Twist",
          "text": "I don‚Äôt know if the inspiration came from Claude Code and using the /doctor command, but it sure does make a shit load of sense to have something like this.",
          "score": 5,
          "created_utc": "2025-12-28 09:23:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc86sz",
              "author": "lebrandmanager",
              "text": "I would not care in the slightest as long as this thing was actually helping me. As you said: it makes sense to have this.",
              "score": 3,
              "created_utc": "2025-12-28 09:33:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwum2h6",
          "author": "Rythameen",
          "text": "Thank you for this, I just start down the ComfyUI rabbit hole 2 months ago and this is absolutely appreciated. I‚Äôve been using ChatGPT to try and track down problems but it‚Äôs been touch and go. Will install tonight. And I like the Ableton analogy too, except for me it was 14 years of Pro Tools and then dumping it for Cubase.",
          "score": 2,
          "created_utc": "2025-12-31 03:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwuo0w5",
              "author": "rayfreeman1",
              "text": "Thank you! The 'rabbit hole' is deep, but that's the fun part.\n\nI think you'll find the Doctor much faster than the manual ChatGPT method since it automatically captures the node context for you.\n\n**But the Doctor is just getting started!** I'll be continuously updating its diagnostic capabilities, so please feel free to share any feedback or suggestions for optimization. Enjoy the ride :)",
              "score": 1,
              "created_utc": "2025-12-31 03:12:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx0v508",
                  "author": "Rythameen",
                  "text": "You bet! It‚Äôs already solved one problem today.",
                  "score": 2,
                  "created_utc": "2026-01-01 03:06:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdh03v",
          "author": "uxl",
          "text": "More like this, please! Learning and using ComfyUI gives me the exact same vibes as learning Ableton Live (a DAW) in the early 2000‚Äôs. Tons of tutorials and workflows, most of which are overwhelming and at odds with each other on node and layout preferences, and so many customizations and downloads that cause conflicts - and then you find something that works and just lean all the way into it lol. Any apps/plugins/extensions that can assist with analyzing and diagnosing the workflow is appreciated. \n\nWhat would be awesome is if there was an app that examined your full startup log (which inevitably displays countless little errors or extra load times after extended use and tons of custom nodes have been installed) and provided remediation steps to speed up the local server loading process.\n\nEven better - imagine if you dragged a workflow *into an app* that analyzed *every* component ‚Äî not just nodes, but models, LoRAs, etc. ‚Äî and automatically found, downloaded, *and placed* everything where it should go. Such that any workflow you see is guaranteed to work without you having to *make* it work. \n\nAs long as we‚Äôre daydreaming, add a toggle to ‚Äúoptimize workflow for your system‚Äù where total size of the workflow will never exceed your VRAM threshold and trigger offloading (meaning the app would swap out a workflow‚Äôs model variant for a GGUF that is best for your system, for example).\n\nIf such an app existed, I would happily drop cash for it, and I‚Äôm sure I‚Äôm not the only one!\n\nAnyway, thanks for your work on this üëçüèª",
          "score": 3,
          "created_utc": "2025-12-28 15:18:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgg0vt",
              "author": "rayfreeman1",
              "text": "This is amazing feedback, thanks! The Ableton analogy is perfect‚Äîit's chaotic but powerful.\n\nI really like the idea of analyzing startup logs for speed optimization. Since ComfyUI-Doctor already captures the full log, adding an analysis layer for 'slow loading nodes' is definitely something I can explore. Your 'dream features' gave me a lot of inspiration for v2.0.\n\nAlso, thanks for the appreciation! It really gives me the motivation to keep maintaining this project and making it even more practical for everyone. Making a profit isn't my intention here‚Äîand I believe the core ComfyUI developers feel the same way. We're all just driven by that shared passion. Thanks for the support! üëç",
              "score": 4,
              "created_utc": "2025-12-29 00:10:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwv8dml",
          "author": "rayfreeman1",
          "text": "**Update: Now available on ComfyUI Manager! Just search for \"ComfyUI Doctor\" and click Install.**\n\nhttps://preview.redd.it/z62nkq6b6hag1.png?width=1189&format=png&auto=webp&s=50adf81e23a562bf6350f2455e584eefb6dcae45",
          "score": 1,
          "created_utc": "2025-12-31 05:26:13",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzv43f",
      "title": "Best workflows for NSFW in ComfyUI?",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1pzv43f/best_workflows_for_nsfw_in_comfyui/",
      "author": "eda4bla",
      "created_utc": "2025-12-30 22:01:08",
      "score": 99,
      "num_comments": 78,
      "upvote_ratio": 0.8,
      "text": "Hey, been into creating adult contents in ComfyUI but i'm a newbie so as i search for tutorials on YouTube it's getting more complicated plus there are lots of fake videos. Can you suggest me some workflows to create adult contents? \n\nI'm not creating hardcore NSFW also i'm looking for something ultra-realistic. Would be great if you guys also recommend some good tutorials about how to run these workflows. \n\nThanks in advance! ",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1pzv43f/best_workflows_for_nsfw_in_comfyui/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nwtcuty",
          "author": "Kratos__GOW",
          "text": "Try this one. It works wonders\n\nhttps://civitai.com/models/1651835/gonzalomo-flux-refiner-workflow",
          "score": 29,
          "created_utc": "2025-12-30 22:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxrpshe",
              "author": "__MichaelBluth__",
              "text": "I downloaded this but the nipple.pt and pussy.pt are marked as suspicious/unsafe on huggingface. Is that true or false-positive?",
              "score": 1,
              "created_utc": "2026-01-05 05:33:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxrt2qt",
                  "author": "Kratos__GOW",
                  "text": "When you download the workflow it should come with it. \n\nIf not, its safe to add them.",
                  "score": 1,
                  "created_utc": "2026-01-05 05:58:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxrtiqj",
                  "author": "Kratos__GOW",
                  "text": "Did you download all the missing custom nodes?\nWhen you download load it its should create a Ultralytics folder that should have nipple.pt and pussy.pt",
                  "score": 1,
                  "created_utc": "2026-01-05 06:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwtlq2u",
              "author": "eda4bla",
              "text": "thanks but the thing is these are crazy complicated so i also need a tutorial thanks tho!",
              "score": 2,
              "created_utc": "2025-12-30 23:34:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtpciu",
                  "author": "Kratos__GOW",
                  "text": "I use runpod. This video and youtube channel should help you. \n\nhttps://youtu.be/V8YGDzE5XuY?si=SzqRUergkj33k55F",
                  "score": 10,
                  "created_utc": "2025-12-30 23:54:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwt4qva",
          "author": "LyriWinters",
          "text": "Just go to civitAI and download the videos images that are already created. The workflows are embedded in like 1/3 of them.",
          "score": 39,
          "created_utc": "2025-12-30 22:06:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt94wg",
              "author": "xKronkx",
              "text": "Just be prepared to download 345 different custom nodes if you download 5 different images",
              "score": 76,
              "created_utc": "2025-12-30 22:27:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwti651",
                  "author": "AppleBottmBeans",
                  "text": "Dude it‚Äôs unreal and so unnecessary.",
                  "score": 32,
                  "created_utc": "2025-12-30 23:15:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtapx2",
          "author": "unfilteredforms",
          "text": "Just go to the template section in ComfyUI and start with their templates. Wan 2.2 has been my go to.",
          "score": 9,
          "created_utc": "2025-12-30 22:35:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtijeu",
              "author": "stuartlucas",
              "text": "Problem is WAN 2.2 is HUNGRY!",
              "score": 5,
              "created_utc": "2025-12-30 23:17:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwyh9bj",
                  "author": "MaximilianPs",
                  "text": "I'm using it with my 3080 with 10 gigs and it's working just a couple of seconds but it's quite fast, a couple of minutes for 60frames",
                  "score": 1,
                  "created_utc": "2025-12-31 18:44:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwtlsbg",
                  "author": "eda4bla",
                  "text": "wdym by hungry?",
                  "score": 1,
                  "created_utc": "2025-12-30 23:34:58",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwukrux",
          "author": "aholeinthetable",
          "text": "Watch pixaroma on YouTube. He has the best tutorials I‚Äôd say and all of the workflows he uses are free on his discord. I would start at the beginning if you‚Äôre new but he is gonna start a new beginners series this January so it should teach you new and relevant information about comfyui.",
          "score": 9,
          "created_utc": "2025-12-31 02:53:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt800y",
          "author": "KILO-XO",
          "text": "I have like 1000s workflows on my desktop. I got so many I dint even know what the fuck i have üò≠",
          "score": 23,
          "created_utc": "2025-12-30 22:22:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt9dj3",
              "author": "eda4bla",
              "text": "Same here and still didn't get a proper result since there is a proper tutorial video about these workflows...",
              "score": 4,
              "created_utc": "2025-12-30 22:29:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwv8igz",
          "author": "IAvar_496",
          "text": "watch [this video](https://m.youtube.com/watch?v=rXQh1dHZSAo)\nand [check this](https://huggingface.co/Phr00t)",
          "score": 7,
          "created_utc": "2025-12-31 05:27:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwui5qd",
          "author": "hstracker90",
          "text": "You should get yourself familiar with ComfyUI first. Then later you add loras from Civitai for the content. \n\nThe latest models (Z-Image Turbo, QwenEdit2511) are all the rage right now, but SDXL / Pony are still the king of NSFW images. They have the largest user base and most content (uncensored checkpoints and loras).",
          "score": 6,
          "created_utc": "2025-12-31 02:38:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwt9zf2",
          "author": "Specialist-Team9262",
          "text": "[u/Hearmeman98](https://www.reddit.com/user/Hearmeman98/submitted/) does great work",
          "score": 7,
          "created_utc": "2025-12-30 22:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvqatl",
              "author": "Hearmeman98",
              "text": "Thanks for the shoutout",
              "score": 6,
              "created_utc": "2025-12-31 07:55:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3s81n",
                  "author": "eda4bla",
                  "text": "do you have any workflow recommend?",
                  "score": 0,
                  "created_utc": "2026-01-01 17:08:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtm4tu",
          "author": "Pazerniusz",
          "text": "The answer is self-made, to be honest, it not objective difference between using but if you don't know what is going you are likely to always get low quality outputs as you cannot do fine tunning.  \nDo it yourself. Watch the generic Wan 2.2 (video model) tutorial at the start. I would suggest Image to Video.   \nAs an Image model, Chroma or Z-image.   \nPick one from Civic you can understand and tweak it to suit your needs, play with lora nail proportions.",
          "score": 3,
          "created_utc": "2025-12-30 23:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtmukz",
          "author": "Conor074",
          "text": "Try BigLove Photo 4, it's great",
          "score": 2,
          "created_utc": "2025-12-30 23:40:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvkt47",
          "author": "boobkake22",
          "text": "I'll suggest¬†[my workflow](https://civitai.com/models/2008892?modelVersionId=2315383)¬†for Wan 2.2, Yet Another Workflow, if you want video. I designed it to be well labeled and color coded with important controls in breakout boxes. (I also have a Wan[¬†Runpod template](https://console.runpod.io/deploy?template=pw6ztkvhcd&ref=lb2fte4g) if you do cloud, and¬†I have a step by step¬†[guide available here](https://civitai.com/articles/21844/yet-another-workflow-step-by-step-with-runpod-template-v035). You'll get good performance with a 5090, if your local GPU struggles with video.)",
          "score": 2,
          "created_utc": "2025-12-31 07:05:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0ipt0",
          "author": "laseracid",
          "text": "Can any of this be done on a AMD GPU or is Nvidia the only option?",
          "score": 2,
          "created_utc": "2026-01-01 01:43:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1yesc",
              "author": "zincmartini",
              "text": "I have used both a 7900xtx and now a R9700. The 7900xtx was definitely great value for how fast it is.\n\nThey were both a huge pain in the ass to get up and running, but of the two, the 7900xtx was easier. After the initial setup headaches though, they're decent.\n\nThere is a ROCm subreddit for us masochists that is a good reference.",
              "score": 2,
              "created_utc": "2026-01-01 08:42:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx38gu0",
                  "author": "laseracid",
                  "text": "Awesome thank you I'll take a look!",
                  "score": 1,
                  "created_utc": "2026-01-01 15:22:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtstel",
          "author": "SenseiBonsai",
          "text": "Cant atm, but tomorrow i can help you for sure if you want. I can teach you a bit about the basics of comfyui and how to set it up and make ur own workflow without hundereds of bullshit nodes.",
          "score": 4,
          "created_utc": "2025-12-31 00:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwttbxq",
              "author": "eda4bla",
              "text": "that would be amazing. maybe you can post here so people who also struggles like me can benefit of your knowledge. Thanks!",
              "score": 1,
              "created_utc": "2025-12-31 00:16:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwttob9",
                  "author": "SenseiBonsai",
                  "text": "I ment more like with a discord call xd, cant do that for the whole sub, but feel free to share with the sub after tomorrow tho.",
                  "score": 1,
                  "created_utc": "2025-12-31 00:18:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwuvrwc",
          "author": "Southern-Chain-6485",
          "text": "Start with the comfyui templates for chroma and sdxl (which also apply to illustrious)",
          "score": 1,
          "created_utc": "2025-12-31 04:00:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwtxut",
          "author": "Fast-Cash1522",
          "text": "You can easily use any capable model and workflow combo. Good place to start is the Comfy templates. I assume you already have your models and LoRAs picked up and running. If not, Civitai is your place.\n\nFinal details, realism and quality comes from upscaling. First generate your base image, then do upscaling of your choise. I‚Äôm using simple cascading Ultimade SD Upscale method, (two ultimate sd upscale nodes in serial, each doing 1.5x upscale with low denoise 0.2-0.3 or so).",
          "score": 1,
          "created_utc": "2025-12-31 13:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwz914y",
          "author": "MelodicFuntasy",
          "text": "Assuming you want to generate simple nudes:  \nDownload Jib Mix Qwen form Civitai. Download the clip model and VAE. Start ComfyUI, go to Templates, search for \"qwen-image text to image\". Open that workflow. In the \"Load Diffusion Model\" node change the model to Jib Mix Qwen model file that you just downloaded.",
          "score": 1,
          "created_utc": "2025-12-31 21:11:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3stva",
              "author": "eda4bla",
              "text": "i'm allowed to do this with my own trained LoRA right?",
              "score": 1,
              "created_utc": "2026-01-01 17:12:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx47fol",
                  "author": "MelodicFuntasy",
                  "text": "What do you mean? You can train your own loras for Qwen Image.",
                  "score": 1,
                  "created_utc": "2026-01-01 18:25:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz94q2",
          "author": "RL1775",
          "text": "I see this question a lot, mainly by people who think there‚Äôs a right answer. My advice, which isn‚Äôt exclusive to NSFW, is to download one or two of the most popular workflows (I personally started out using UmeiArt because his workflows cover just about every discipline, not to mention they don‚Äôt require a ton of unnecessary custom nodes to run). Play around with them until you‚Äôre comfortable with what every node does in the workflow, then experiment. Pretty soon you‚Äôll be building your own custom workflows that are tailored to what you want.\n\nOh, and when in doubt, consult with Google AI. My search history is full of queries starting with ‚ÄúComfyui how do I‚Ä¶?‚Äù.",
          "score": 1,
          "created_utc": "2025-12-31 21:12:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzduph",
          "author": "zombie_pig_bloke",
          "text": "My take would be focus on the images, as others are saying. The Wan workflow I use now has simplified a lot since I started, as I've moved all my effort into good images, then upscale them, then Wan to animate. So Flux, Chroma and ZIT/Qwen for the images. ZIT will give you pretty instant results although take time to fully understand Comfy over time it really pays off. Problem is now there is SO much coming out, models loras, workflows etc. \nCode Crafters Corner YT I found useful, straightforward. I'm using his latest Wan long video example although I immediately customised it. Good luck",
          "score": 1,
          "created_utc": "2025-12-31 21:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx20on2",
          "author": "zincmartini",
          "text": "This shit is the deepest fucking rabbit hole. Everyone must find their own way, so you'll never get a final answer other than \"learn by doing.\" It's time consuming.\n\nWith that said, the brightest lamp posts on my journey so far have been as follows: \n\n-pixaroma comfy UI tutorial series. Start with ep. 1 and watch the first few to get up and running, then you can jump around to whichever topic is most relevant once you have the basics.\n\n-use the comfy UI \"templates\" to get started. Any workflow that's embedded in a civitai image or video will almost certainly not be beginner friendly.\n\n-images first, then video. Images are way easier and faster to get up and running. Idk why but I struggled to get my first video gen for days. Just couldn't figure it out, until I went back and tried the built in template.\n\n-chatGPT \n\n-browse civitai to find what you like, then look at the information on the right to see what models of other settings they used. \n\nNote: you asked about NSFW, but it's all the same. Pretty much all of them will do \"softcore\" images and videos out of the gate, especially without nudity, so you don't really need an NSFW model to get up and running. In fact it's probably better to get familiar with the base models capabilities beforehand. The base models are generally very well done and more beginner friendly.  The NSFW specific stuff is usually more focused, which in turn makes them harder to use, and if they're poorly trained they can degrade the output, as well.\n\nMy starting point was a simple Qwen text-to-image template built into comfy UI. It can do topless ladies out of the box. Easy peasy.",
          "score": 1,
          "created_utc": "2026-01-01 09:06:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3grgy",
              "author": "eda4bla",
              "text": "Thanks a lot as you say this shit is impossible to learn without putting too much time and effort. I'll follow your instructions!",
              "score": 1,
              "created_utc": "2026-01-01 16:07:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtp6kd",
          "author": "eda4bla",
          "text": "Do you see? Everyone in the comments say different things lol. That AI stuff is getting more and more complicated every single day",
          "score": 0,
          "created_utc": "2025-12-30 23:53:45",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwt6nem",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -20,
          "created_utc": "2025-12-30 22:15:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt7u51",
              "author": "eda4bla",
              "text": "As i told you there are too much false information about these. Don't worry i've been searching about it for days. Isn't this subreddit for helping eachother?",
              "score": 13,
              "created_utc": "2025-12-30 22:21:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtdqmw",
                  "author": "Cool-War635",
                  "text": "I don't think they're fake, just outdated.",
                  "score": 2,
                  "created_utc": "2025-12-30 22:51:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2ds50",
      "title": "Pimp your ComfyUI !!",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/h5tiyq9pp0bg1",
      "author": "neofuturist",
      "created_utc": "2026-01-02 23:11:02",
      "score": 93,
      "num_comments": 22,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1q2ds50/pimp_your_comfyui/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxcbo5y",
          "author": "Abject-Recognition-9",
          "text": "can images be added to fill nodes or as a background? i want to build a sort of audio rack style\n\nlike eg: \n\nhttps://preview.redd.it/a60r5qcsr0bg1.png?width=322&format=png&auto=webp&s=493acf2296ab6848266257363cedd7f4cb1ba12f",
          "score": 13,
          "created_utc": "2026-01-02 23:20:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxcckzu",
              "author": "neofuturist",
              "text": "I wanted to Winamp the hell out it, it should be possible, I'll give it a go",
              "score": 7,
              "created_utc": "2026-01-02 23:25:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxeoxbk",
              "author": "ELECTRICAT0M369",
              "text": "I believe owning Reason back in the day helped me learn the atrocity that is Comfy.. <3",
              "score": 3,
              "created_utc": "2026-01-03 08:45:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxep7ro",
                  "author": "Abject-Recognition-9",
                  "text": "üòÜ damn making Comfy looks like Reason was my first desire since Comfy is out",
                  "score": 2,
                  "created_utc": "2026-01-03 08:48:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxcc4kl",
          "author": "sci032",
          "text": "Looks awesome! It doesn't look like you are using Nodes 2.0? If not, you may want to test this with that turned on so you can be prepared for the people who are using it. :)",
          "score": 6,
          "created_utc": "2026-01-02 23:22:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxccsu9",
              "author": "neofuturist",
              "text": "I know I will be hated for saying it, but I reverted to oldschool look, the new UI just wasn't for me",
              "score": 4,
              "created_utc": "2026-01-02 23:26:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxcfe1i",
                  "author": "sci032",
                  "text": "I don't think that you will get a lot of grief for that choice. :) I turned Nodes 2.0 off the day it showed up. Rgthree put a disclaimer in when Comfy starts up saying that they won't be converting to it.",
                  "score": 8,
                  "created_utc": "2026-01-02 23:41:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxdr27t",
                  "author": "luciferianism666",
                  "text": "Nah, 2.0/ the new UI is dog shit.",
                  "score": 3,
                  "created_utc": "2026-01-03 04:18:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxdsqhc",
          "author": "luciferianism666",
          "text": "Tell me something do such customization anyway affect the performance ? \n\nhttps://i.redd.it/mnh2zzosa2bg1.gif\n\nI remember installing this  thing in the past, someone told me it would affect the performance, so I ended up uninstalling it, forgot the name of the node, so I can't find it. Your node however looks a whole lot lighter when compared to this one.",
          "score": 3,
          "created_utc": "2026-01-03 04:30:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfizqo",
              "author": "neofuturist",
              "text": "I have a 4060ti, and so far I haven't seen any performance drops, let me know if it happens",
              "score": 2,
              "created_utc": "2026-01-03 12:53:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxgbk13",
                  "author": "luciferianism666",
                  "text": "I did install the node but even after reverting to the older frontend I'm unable to see the effects like you've displayed on the video. I do see the option to switch between the different themes when I right click, however not much is happening, I see only a subtle line around the nodes during execution.",
                  "score": 2,
                  "created_utc": "2026-01-03 15:36:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxe0ckb",
              "author": "proderis",
              "text": "yea even the resource monitor affects performance by increasing ram, vram and gpu usage too if you have HW accel enabled",
              "score": 1,
              "created_utc": "2026-01-03 05:22:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxepglw",
              "author": "Abject-Recognition-9",
              "text": "i would love to have it as an option anyway, even if affect performance.  \nJust for the sake of OCD and showing my madness cable in a stylish way to some random friends",
              "score": 1,
              "created_utc": "2026-01-03 08:50:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxlrulm",
          "author": "ReflectionNovel7018",
          "text": "Is there a option to just use the shadow/glow effect?",
          "score": 3,
          "created_utc": "2026-01-04 10:32:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny33wpu",
              "author": "neofuturist",
              "text": "Please update, I have created a customized to make it easy to create themes",
              "score": 1,
              "created_utc": "2026-01-06 21:52:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxec0td",
          "author": "fauni-7",
          "text": "How to enable preview in the sampler?",
          "score": 2,
          "created_utc": "2026-01-03 06:54:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfjcpz",
              "author": "neofuturist",
              "text": "I'm not at my comp, but you need to open the comfui manager, then look on the left side drop-down, there you will find some drop-down with a preview mode, set it to taes or other, Sorry I am going by memory, but it should be there",
              "score": 2,
              "created_utc": "2026-01-03 12:56:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxhih2k",
              "author": "ELECTRICAT0M369",
              "text": "open your run_nvidia_gpu.bat or similar and add this line \n--preview-method latent2rgb",
              "score": 2,
              "created_utc": "2026-01-03 18:56:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxcgj1r",
          "author": "SearchTricky7875",
          "text": "damn, I need this.",
          "score": 1,
          "created_utc": "2026-01-02 23:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxl0l2b",
          "author": "_tarZ3N",
          "text": "Cool",
          "score": 1,
          "created_utc": "2026-01-04 06:29:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxpc5sf",
          "author": "MrSmith2019",
          "text": "u/neofuturist The glow effect is not showing up. Any hints or suggestions?  \nEverything else is also not working. No effect! Only the inside border of the single settings and the background color of the node is changing. hmmm",
          "score": 1,
          "created_utc": "2026-01-04 21:56:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny33q7i",
              "author": "neofuturist",
              "text": "This is weird, can you update to the latest version and try the customized, you can play with the glow intensity, let me know if it shows up, also try another browser just in case",
              "score": 1,
              "created_utc": "2026-01-06 21:51:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q3k5q6",
      "title": "How to solve EVERYTHING FOREVER! - broken installation after updates or custom nodes",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q3k5q6/how_to_solve_everything_forever_broken/",
      "author": "GeroldMeisinger",
      "created_utc": "2026-01-04 07:54:13",
      "score": 90,
      "num_comments": 44,
      "upvote_ratio": 0.96,
      "text": "# tl;dr\n\n1. Use the popular `uv` tool to quickly recreate python environments\n2. Use the official `comfy-cli` to quickly restore node dependencies\n3. Install ComfyUI on a separat Linux system for maximum compatibility (`triton`, `sage-attention`)\n\n# Why?\n\nSo many times in this forum I read about:\n\n* my ComfyUI installation got bricked\n* a custom node broke ComfyUI\n* ComfyUI Portable doesn't work anymore after an update\n* ComfyUI Desktop doesn't start after the update\n* Use this freak tool to check what's wrong!\n* How to install triton on Windows?\n* Does sage-attention need a blood sacrifice to work?\n\nAll of these can be prevented or mitigated by learning and using these 3 common, popular and standardized tools:\n\n1. uv\n2. comfy-cli\n3. Linux\n\nThink about all the headaches and time lost by sticking to any other esoteric solutions. If you don't want to learn these few commands, then just bookmark this thread.\n\n# UV\n\nThe `uv` tool is a layer on top of python and pip. It makes handling environments easier and most importantly:\n\n**IT'S FASTER!!!**\n\nIf your ComfyUI installation got bricked, just purge the enviroment and start anew in 1 minute.\n\n[Installation](https://docs.astral.sh/uv/getting-started/installation)\n\n# ComfyUI\n\n**Installation**\n\n    git clone https://github.com/comfyanonymous/ComfyUI\n    cd ComfyUI\n    uv venv\n    uv pip install -r requirements.txt -r manager_requirements.txt\n    uv pip install comfy-cli\n\n**Update**\n\n    git pull\n    uv pip install -r requirements.txt -r manager_requirements.txt\n    source .venv/bin/activate\n    comfy node update all\n    comfy node restore-dependencies\n\n**Run**\n\n    uv run main.py\n\n**Purge**\n\nIf something happened, just purge the environment. With `uv` and `comfy-cli` it only takes 1min.\n\n    rm -fR .venv\n    uv venv\n    uv pip install -r requirements.txt -r manager_requirements.txt\n    uv pip install comfy-cli\n    source .venv/bin/activate\n    comfy node restore-dependencies\n\n**Downgrade**\n\nFind your tagged version here [https://github.com/comfyanonymous/ComfyUI/releases](https://github.com/comfyanonymous/ComfyUI/releases)\n\n    git checkout tags/v0.7.0\n    uv pip install -r requirements.txt -r manager_requirements.txt\n\nIf that didn't work -> purge.\n\n# Linux\n\nYou don't need Linux per se, but everything is more compatible, faster and easier to install, especially `triton` (for speedups!), `sage-attention` (for speedups!) and `deep-speed` (for speed-ups!). You don't even have to abandon Windows, everything is fine, just buy another harddisk (\\~30‚Ç¨, see it as an investment in your sanity!) and setup a dualboot, just for ComfyUI. Your Photoshop and games can stay on Windows (\\*cough\\* \\*cough\\* Steam Proton).\n\nBut which distribution? Here, use [Ubuntu](https://ubuntu.com)! Don't ask any questions!\n\nInstall Python3: `sudo apt update && sudo apt install python3`\n\nInstall [CUDA](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Debian&target_version=12&target_type=deb_local)\n\nGood times!\n\n# Questions & Answers\n\n**Q: Why doesn't** [**Comfy.org**](http://Comfy.org) **care more?**\n\nA: They do care, it's just that time and resources are limited. It started as a free, voluntary, open-source project. It's an organization now, but far from a multimillion dollar company. One of ComfyUI's unique selling propositions is: new models immediately. Everything else is secondary.\n\n**Q: Why does ComfyUI break in the first place?**\n\nA: ComfyUI relies heavily on high-performance instructions of your GPU, which need to have up-to-date drivers (*CUDA*), whichs need to be compatible with *PyTorch* (the programming library for computations), which needs to be compatible with your *Python* version (the programming language runtime), which needs to be compatible with your operating system. If any combination of `Python x Pytorch x CUDA x OS` isn't available or incompatible, it breaks. And of course any update and new features need to be bug free and compatible with every package installed in the environment. And all of this should ideally be tested, everytime, for every update, with every combination.. which simply doesn't happen. We are basically crossing fingers that in some edge case it doesn't call a function which isn't actually available. That's why you should stick to the [recommended versions](https://github.com/comfyanonymous/ComfyUI#manual-install-windows-linux).\n\n**Q: Why do custom nodes break ComfyUI?**\n\nA: Another one of ComfyUI's unique selling propositions is its' flexibility and extensibility. It achieves this by simply loading any code within `custom_nodes` and allowing them to install anything. Easy.. but fragile (and highly insecure!). If a custom node developer wasn't careful (\"Let's install a different Pillow version YOLO!\") it's bricked. Even if you uninstall the node, the different package version is already installed. There are only a few - weak - safeguards in place, like \"Prohibit installation of a different pytorch version\", \"Install named versions from registry (*latest*) instead of current code in repo (*nightly*)\" and \"Fingers crossed\".\n\n**Q: Why does ComfyUI Desktop and ComfyUI Portable break so many times?**\n\nA: I have never used them myself, but I guess they are treated as secondary citizens by [comfy.org](http://comfy.org) which means even less testing than the manual version. And they need to make smart assumptions about your environment, which are probably not that smart in practice.\n\n**Q: Why is triton and sage-attention so hard to install?**\n\nA: For fast iteration the developers mainly work on Linux, and neglect Windows. Another notable example is [DeepSpeed](https://github.com/microsoft/DeepSpeed/issues/2427) developed by Microsoft, who have a long standing history of neglecting the Windows platform.",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/comfyui/comments/1q3k5q6/how_to_solve_everything_forever_broken/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nxls1qc",
          "author": "TheSlateGray",
          "text": "UV really is the best change, imo.\n\nJust make sure Comfyui-Manager uses it too.\n\nI use \\`uv venv --python 3.12 --seed\\` personally, as it will set the python to 3.12 (broad compatibility) and \\`--seed\\` adds \\`pip\\` which is missing by default.\n\nYou can also use \\`uv add\\` instead of \\`uv pip\\` as then you're not relying on \\`pip\\` as much, but it doesn't seem to work for everything.\n\nI merge this into Comfy's \\`pyproject.toml\\` after every update to keep my source for torch on Cuda13:\n\n    [[tool.uv.index]]\n    name = \"pytorch\"\n    url = \"https://download.pytorch.org/whl/cu130\"\n    explicit = true\n    \n    [tool.uv.sources]\n    torch = { index = \"pytorch\" }\n    torchvision = { index = \"pytorch\" }\n    torchaudio = { index = \"pytorch\" }\n    triton = { index = \"pytorch\" }",
          "score": 8,
          "created_utc": "2026-01-04 10:33:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlt3wt",
              "author": "GeroldMeisinger",
              "text": "Interesting infos, I didn't know that, thanks!\n\nyou should be able to set \\`git skip-worktree\\` (or \\`assume-unchanged\\`?) so you don't have to merge everytime",
              "score": 3,
              "created_utc": "2026-01-04 10:43:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxmgujr",
                  "author": "TheSlateGray",
                  "text": "I also change a few other sections, and using \\`uv add -r requirements.txt\\` modifies the pyproject further with the list of requirements.txt and versions into it. I'm noticing now that UV has more flags so I might be able to skip some things, and then just update everything to 3.13 and simplify.\n\nBut, I don't want to risk messing up my 3 day old install to test 3.13 and the new flags for UV just yet.",
                  "score": 1,
                  "created_utc": "2026-01-04 13:46:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxme9nz",
              "author": "Lesale-Ika",
              "text": "\\> I use \\`uv venv --python 3.12 --seed\\` personally, as it will set the python to 3.12 (broad compatibility) and \\`--seed\\` adds \\`pip\\` which is missing by default.\n\nWhy this strange behavior, I literally pulled my hair out trying to get the Manager to work with UV. Which is very strange, because when configured to use uv it will invoke uv like a python module? (\\`python -m uv pip install....\\`) I ended up creating some sort of shim to please it.",
              "score": 2,
              "created_utc": "2026-01-04 13:30:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxmgc1c",
                  "author": "TheSlateGray",
                  "text": "What do you mean by strange behavior?\n\nIf you don't set it to 3.12, it will use the system/latest version. Not all my custom nodes were compatible with 3.13, but they might be now, so I could test and stop...but not today haha.\n\n\\`--seed\\` is because UV doesn't need pip, so it doesn't install it into a venv by default. [https://docs.astral.sh/uv/reference/environment/#uv\\_venv\\_seed](https://docs.astral.sh/uv/reference/environment/#uv_venv_seed)\n\nI just noticed UV has a [\\--torch-backend](https://docs.astral.sh/uv/guides/integration/pytorch/#the-uv-pip-interface) flag I'll have to look into asap, because then I wouldn't need to modify the pyproject anymore.\n\nAs for the Manager, yes it runs uv pip install commands, I'm not the dev, but I'd guess it has to do with compatibility. It still works fine though after setting \\`use\\_uv = True\\` so I'm not sure what you mean.",
                  "score": 2,
                  "created_utc": "2026-01-04 13:43:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxnlgkr",
          "author": "AboveAFC",
          "text": "Why doesn't people get their Python, Cuda, Pytorch, Sage, Windows-Triton installed and then use a contraints.txt file to keep if from updating? You can put it right into the venv when you activate or update and it won't touch those packages:\n\nconstraints.txt:\n\ntorch==2.9.1+cu128\n\ntorchvision==0.24.1+cu128\n\ntorchaudio==2.9.1+cu128\n\nxformers==0.0.33.post2\n\ntriton-windows==3.5.1.post22\n\nsageattention==2.2.0+cu128torch2.9.0andhigher.post4\n\nflash-attn==2.8.3\n\nThen just update using:\n\npip install -r requirements.txt -c constraints.txt\n\nOr better yet, start your comfyui with constraints.\n\ncall .\\venv\\Scripts\\activate\n\nset PIP_CONSTRAINT=%~dp0constraints.txt\n\npython main.py\n\n\nThen, even comfyui manager won't mess up the constrained files.",
          "score": 7,
          "created_utc": "2026-01-04 17:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmo6p7",
          "author": "Free_Scene_4790",
          "text": "I use the portable version of Windows, so none of this is relevant to me, I suppose.\n\n\n\nAlthough I like having several portable versions in different folders, and I only really use one for experimenting when I install something new or \"risky.\"",
          "score": 6,
          "created_utc": "2026-01-04 14:29:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmozrc",
              "author": "GeroldMeisinger",
              "text": "If you never broke your portable version, then no. Otherwise I think it's very relevant, as my point is literally: use manual installation!",
              "score": 3,
              "created_utc": "2026-01-04 14:33:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxn4vpr",
          "author": "ItsAMeUsernamio",
          "text": "Linux gets me better s/it plus I can boot headless and get a GB extra VRAM. But on my 16GB VRAM 32GB RAM I rely on swap alot and that seems much slower on Linux to compared Windows. Chained Wan 2.2 workloads end up taking longer and even with ‚Äîcache-none Comfy wants to keep piling up my Wan models in RAM which go to Swap which loads slower than it would directly from my NVMe. Plus if you rely on Nvidia offloading, that‚Äôs missing from Linux for some reason. If I ever get Turbodiffusion running that will take more time loading models than inference and it already does that with 33 frame videos.\n\nAlso I notice Wan models loading says something like ‚Äú3GB loaded 12GB offloaded‚Äù while it‚Äôs not like that on Windows.",
          "score": 3,
          "created_utc": "2026-01-04 15:55:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnleyp",
          "author": "73tada",
          "text": "Will this work through WSL?\n\n- Open Terminal and type \"WSL\" (assuming it's already installed)\n- Then continue with uv install process?",
          "score": 2,
          "created_utc": "2026-01-04 17:12:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxoj3mq",
              "author": "Hear_N_Their",
              "text": "Thanks for asking, I was wondering the same.",
              "score": 1,
              "created_utc": "2026-01-04 19:42:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxouhy7",
              "author": "_CreationIsFinished_",
              "text": "WSL2 presents itself as a normal Linux environment, and uv is OS-agnostic at the layer that matters - though if you target a python interpreter that lives in /mnt/\\*somewhere\\*, or mixing Windows python with WSL uv, etc. you would be very likely to see some issues.",
              "score": 1,
              "created_utc": "2026-01-04 20:34:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxp2qij",
                  "author": "73tada",
                  "text": "Thanks!\n\nGenerally, I use the portable versions as I can \"lock\" a working system for particular workflows.\n\nHowever having a live, linux based install with all the \"fancy options\" (triton, sage) available and activated.",
                  "score": 1,
                  "created_utc": "2026-01-04 21:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxnuks1",
          "author": "helto4real",
          "text": "This is a great post. Thanks for sharing. Personally I made a docker container that I run nvidia image and nvidia container runtime. Works great. If something is screwed up I just recreate the container.",
          "score": 2,
          "created_utc": "2026-01-04 17:54:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmdnsy",
          "author": "Lesale-Ika",
          "text": "Comfyanonymous once bashed A1111 extension system, saying their implementation of extension (custom nodes) being more contained and limited, reducing extension conflicting each other.\n\nOf course the extensions still conflict with each other, because it's still fucking python and the dependency nightmare.",
          "score": 4,
          "created_utc": "2026-01-04 13:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlfzg9",
          "author": "New_Physics_2741",
          "text": "Great post, thanks\\~",
          "score": 2,
          "created_utc": "2026-01-04 08:44:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm5i0u",
          "author": "Lucaspittol",
          "text": "Something worth noticing is that installing Comfyui in Linux is hell. I got every possible error imaginable installing it on Linux Mint and still can't get it to run. \n\nMaybe I should try Ubuntu?",
          "score": 2,
          "created_utc": "2026-01-04 12:28:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm9tw0",
              "author": "TechnologyGrouchy679",
              "text": "linux has been smooth sailing for me.  Make sure you are using an isolated virtual environment and not installing dependencies system-wide",
              "score": 3,
              "created_utc": "2026-01-04 13:00:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxow7b8",
              "author": "_CreationIsFinished_",
              "text": "Interesting. Outside of initial release when I was still new to Linux, I've had little in the way of issues getting it to install and run.   \nHave you tried asking ChatGPT to walk you through the process, and telling it what errors you're getting? Most of my problems have been solved with the help of LLM's and I've been using Comfy since 2023.",
              "score": 2,
              "created_utc": "2026-01-04 20:42:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxm6fxj",
              "author": "GeroldMeisinger",
              "text": "Really? I had the opposite experience but as stated: it's optional, only try if you fail to install triton and sage-attention on Windows. Last week I had to setup a Comfy installation on Windows since a long time and I found the amount manual work staggering.\n\nLinux Mint is based on Ubuntu, so I don't think it will change anything.",
              "score": 3,
              "created_utc": "2026-01-04 12:35:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxm7j1l",
                  "author": "Lucaspittol",
                  "text": "I set up a fresh Linux Mint install on a separate drive because I wanted to use Diffusion-pipe, and it needs DeepSpeed. I tried to install Comfyui first, but there were so many errors. Probably a skill issue since I'm fairly new to Linux.",
                  "score": 2,
                  "created_utc": "2026-01-04 12:44:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxlgfy4",
          "author": "GreyScope",
          "text": "I have these as a batch file as part of a ‚Äúfix it in 15mins or it goes in the bin‚Äù strategy , my variance is installing a lower version than the latest PyTorch . \nThe triton / sage issue is mostly ppl unable/unwanting to follow instructions and not wanting to deal with technical stuff, the classic installing them to the system Python .",
          "score": 1,
          "created_utc": "2026-01-04 08:48:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm1gwe",
          "author": "gallito_pro",
          "text": "Thanks but don't you entered to the environment to install dependencies? Correct if I'm wrong please, but you need run .venv\\scripts\\active before installing dependencies.",
          "score": 1,
          "created_utc": "2026-01-04 11:55:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxm2xeh",
              "author": "GeroldMeisinger",
              "text": "perks of uv, it automatically searchs in current dir and up\n\nit's only required for comfy-cli restore-dependencies because of the following issue: [https://github.com/Comfy-Org/comfy-cli/issues/263#issuecomment-3641030055](https://github.com/Comfy-Org/comfy-cli/issues/263#issuecomment-3641030055)",
              "score": 4,
              "created_utc": "2026-01-04 12:07:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxm3s2w",
                  "author": "gallito_pro",
                  "text": "I think I got it.",
                  "score": 1,
                  "created_utc": "2026-01-04 12:14:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxmlk9j",
          "author": "ectoblob",
          "text": "I've never had any need for it (comfy-cli)... based on github page, it seems to be installing into C-drive, in some horrible user folder? If that is the case, then this is probably something most people don't want to do, as C-drive is usually the drive (at least for me) that doesn't have too much free space.\n\nedit: \"the standalone version\" - there is no such version, the github repo based version is only called \"Manual Install\" - AFAIK, the other two being Desktop Application and Windows Portable Package.\n\nhttps://preview.redd.it/qyyosdqwbcbg1.png?width=911&format=png&auto=webp&s=f2b38359e04a173744c50b18d207aa90e2c7b457",
          "score": 1,
          "created_utc": "2026-01-04 14:14:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmm5z9",
              "author": "GeroldMeisinger",
              "text": "yeah, me neither. don't use it for that. only use it for restore-dependencies.",
              "score": 1,
              "created_utc": "2026-01-04 14:17:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxoourx",
          "author": "Sgsrules2",
          "text": "Thanks for sharing this. I recently switched to Linux for comfyui. I've been using portable installs. What's the benefit in switching to UV? And can I convert my portable install to UV?",
          "score": 1,
          "created_utc": "2026-01-04 20:08:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxp4z9s",
              "author": "GeroldMeisinger",
              "text": "if everything runs fine for you, don't change it. with manual installs you have more control, and uv allows to recreate the env fast. you should be able to convert by transferring the directories input, models, outputs and user, yes.",
              "score": 3,
              "created_utc": "2026-01-04 21:23:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxqnvmg",
          "author": "Interesting8547",
          "text": "Why bother... I just use the easy install... every time Comfy brakes... 1 click and next comfy is ready to go after a few mins... without thinking which version of which I have to install...",
          "score": 1,
          "created_utc": "2026-01-05 01:54:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxlt0h9",
          "author": "LyriWinters",
          "text": "Pass. \n\nMost people brick it by not being able to install the correct CUDA... As such uv is useless, which is why I really see no point in using it ever.\n\nWhy would I use it when conda solves the issue and also solves CUDA / C++ libraries etc...?",
          "score": 0,
          "created_utc": "2026-01-04 10:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxlu1t7",
              "author": "GeroldMeisinger",
              "text": "I usually create more venvs than installing new cuda versions, and found uv faster, light-weight and more comfortable to use.\n\nApart from that, I don't think you fit the target audience for this tutorial :) but feel free to provide your version with Conda.",
              "score": 4,
              "created_utc": "2026-01-04 10:51:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxlwwq8",
                  "author": "LyriWinters",
                  "text": "It's fast enough. The only difference between conda and uv is how fast it is at installing packages... And conda has been around the block and back and it's fast enough. uv is slightly faster but it is also only for python packages.\n\nHere you go: [https://github.com/maximilianwicen/anaconda\\_comfy](https://github.com/maximilianwicen/anaconda_comfy)\n\n  \nTook all of 3 minutes.",
                  "score": 1,
                  "created_utc": "2026-01-04 11:16:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxmbx6k",
              "author": "aeroumbria",
              "text": "It's not useless. You can simply do `uv pip install torch torchvision --torch-backend=cu126` and it will forever stay on matching library versions as long as you don't rawdog pip install without uv. Comfy is smart enough now that all custom node updates will also be run through uv if it is a uv environment, so you will be safe if there are no custom nodes that go out of their way to bypass it. Even works with rocm. And it will try to match stuff like triton and sage attention as well, and will gracefully fail instead of breaking environment if it cannot satisfy the version constraints. \n\nI will probably still go conda though if you absolutely need xformers, flash attention, sage attention and some random compile-only library from a custom node...",
              "score": 3,
              "created_utc": "2026-01-04 13:14:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxmof1h",
          "author": "PestBoss",
          "text": "All great. But a lot of the time the issue isn't the install getting bricked per se, it's the install getting borked by ComfyUI pushing unfinished updates.\n\nAnd as far as I can see your approach isn't telling me how to roll back to an earlier version.\n\nIf UV can easily pull a previous version then that might be really useful.\n\nYou're half way to a 'rollback' button.",
          "score": 0,
          "created_utc": "2026-01-04 14:30:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmpszy",
              "author": "GeroldMeisinger",
              "text": "added **Downgrade** section",
              "score": 5,
              "created_utc": "2026-01-04 14:38:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzgyzm",
      "title": "[ComfyUI Workflow] Qwen Image Edit 2511: Fast 4-Step Editing with High Consistency",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/qzwr6i7i5cag1.png",
      "author": "Abject_Wrap6275",
      "created_utc": "2025-12-30 12:32:49",
      "score": 80,
      "num_comments": 29,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1pzgyzm/comfyui_workflow_qwen_image_edit_2511_fast_4step/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwqy8qe",
          "author": "Wonderful_Mushroom34",
          "text": "Not to be that guy but when you say ‚Äúhigh consistency‚Äù use a human face to test. See if it preserves the skin texture of the load image. I would say you don‚Äôt need to fire up comfyUI to make images like that in your example. You can use any Web UI image gen wrapper ‚Ä¶ easy and fast",
          "score": 3,
          "created_utc": "2025-12-30 15:57:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr7wde",
              "author": "Abject_Wrap6275",
              "text": "I understand that I didn't specify, but my workflow takes an image and then takes a prompt from the JSON, to make several images, or rather to modify the input images in various styles. Most importantly, you can add custom workflows so you always have them at your fingertips. If you see, in the list on the left, I have already put 11 prompts that do various things, so infinitely expandable by the user. By exploiting Qwen, it is like having, almost, Google's nano banana. \nYou download it and try to try it, you will realize that it is not important what I put as an image, but the mechanism behind it. It's like having a lot of workflows doing different things, just select the number that corresponds to a workflow. Do you want to color a drawing? Use the number 1. Do you want to restore an antique photo? Use 3. Want to do more? You use the correct prompt. \nI hope you have understood that he does not just color a drawing, it would have been trivial.",
              "score": 2,
              "created_utc": "2025-12-30 16:42:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr862e",
                  "author": "Wonderful_Mushroom34",
                  "text": "Okay I understand it now. Sorry about the critique and being a dick haha",
                  "score": 1,
                  "created_utc": "2025-12-30 16:43:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwsu3so",
          "author": "chuckaholic",
          "text": "Everything seems good except My ComfyUI refused to run Bjornulf node pack. Maybe it's because I'm using portable on Windows. IDK. The main one that was a deal breaker was the loop integer one. I would replace it with an alternative but I don't know what it's doing.",
          "score": 2,
          "created_utc": "2025-12-30 21:16:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt2ldu",
              "author": "Abject_Wrap6275",
              "text": "Most likely, I notice that there is an incompatibility in some nodes between the portable version and the Desktop version (which I use). The loop basically iterates through all the JSON indexes and then extracts the titles to compose the menu and all the custom prompts, and then extracts what is selected via the selector.\n\nUnfortunately, I don't know if there is an alternative to this node for the comfyui portable, sorry.",
              "score": 1,
              "created_utc": "2025-12-30 21:56:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrjfyh",
          "author": "Railander",
          "text": "im new to local gen, any way to tweak it to use way less vram?",
          "score": 1,
          "created_utc": "2025-12-30 17:36:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrt18s",
              "author": "Abject_Wrap6275",
              "text": "you can download it from here  \n[https://huggingface.co/unsloth/Qwen-Image-Edit-2511-GGUF/tree/main](https://huggingface.co/unsloth/Qwen-Image-Edit-2511-GGUF/tree/main)  \nTry Q6, and if that still doesn't work, try Q5. Honestly, I don't recommend anything below Q5.\n\nI use an RTX 3060 12GB.",
              "score": 3,
              "created_utc": "2025-12-30 18:20:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwv6l4y",
                  "author": "NickCanCode",
                  "text": "How do you use Q8 with 3060 12GB? The file size is almost 22g.",
                  "score": 1,
                  "created_utc": "2025-12-31 05:13:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwrmppo",
              "author": "NessLeonhart",
              "text": "GGUF‚Äôs. They‚Äôre smaller quantized versions of the original file. The smaller the quant, the worse it is, but you can find a quant that fits your vram and see how it performs. \n\nFile size of the model = amount of vram it needs. So if you have a 12gb card, find a quant that‚Äôs less than 12gb in download size.\n\nIdk where the qwen edit gguf repo is, I don‚Äôt use them personally, but some googling should find it.",
              "score": 2,
              "created_utc": "2025-12-30 17:51:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwryrl4",
              "author": "IndividualAttitude63",
              "text": "Use JollyAI then",
              "score": 1,
              "created_utc": "2025-12-30 18:46:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwtc6kx",
                  "author": "Railander",
                  "text": "trying to use their image-to-image but i click to upload my image and nothing happens.",
                  "score": 1,
                  "created_utc": "2025-12-30 22:43:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrzmde",
          "author": "pred314",
          "text": "do i just download picture for workflow?",
          "score": 1,
          "created_utc": "2025-12-30 18:50:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwsg8ip",
              "author": "Abject_Wrap6275",
              "text": "No, unfortunately I think Reddit removes all metadata. You have to go to the link I posted in the first post.",
              "score": 1,
              "created_utc": "2025-12-30 20:09:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx4vnjm",
                  "author": "Mindless-Clock5115",
                  "text": "there‚Äôs no link? can you put them here ? it‚Äôs not in the top post.",
                  "score": 1,
                  "created_utc": "2026-01-01 20:26:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwt295n",
          "author": "Anthusrnam",
          "text": "Is he holding a maraca in his right hand?",
          "score": 1,
          "created_utc": "2025-12-30 21:54:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtcsyb",
              "author": "Abject_Wrap6275",
              "text": "Observation not particularly relevant to the functioning of the workflow.\n\nI deliberately deleted the sword from the right hand and left the hilt. My test was to check whether the model actually followed the drawing or invented things that weren't really there but could be probable, such as a sword.\n\nThen I don't want to know if you have a particular interest in maracas or the reasons that make you see maracas everywhere.",
              "score": 1,
              "created_utc": "2025-12-30 22:46:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxk015l",
                  "author": "Anthusrnam",
                  "text": "I was just really hoping you made a character that fought with a maraca.  That's something I would do.",
                  "score": 1,
                  "created_utc": "2026-01-04 02:33:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxtfvgv",
          "author": "edwios",
          "text": "I am curious, what optimisation was done to make your workflow fast and consistent compared to the official workflow from ComfyUI, especially on the consistent part?",
          "score": 1,
          "created_utc": "2026-01-05 13:57:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0by5k",
      "title": "ZiT Studio - Generate, Inpaint, Detailer, Upscale (Latent + Tiled + SeedVR2)",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1q0by5k",
      "author": "pixllvr",
      "created_utc": "2025-12-31 12:31:32",
      "score": 79,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1q0by5k/zit_studio_generate_inpaint_detailer_upscale/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nx0fvxk",
          "author": "Windy_Hunter",
          "text": "Thank you for sharing, very useful. üëçü•Ç",
          "score": 4,
          "created_utc": "2026-01-01 01:25:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1dkd8",
          "author": "aar550",
          "text": "Is there a way to do image to image using prompts. The main purpose is to change clothes/position but keeping the body proportions and face intact.\nI know open pose exists but it‚Äôs not as simple as saying ‚Äúman in the uploaded image is sitting on a chair wearing a jacket‚Äô",
          "score": 1,
          "created_utc": "2026-01-01 05:22:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1pmig",
          "author": "barepixels",
          "text": "image to image, outpaint?",
          "score": 1,
          "created_utc": "2026-01-01 07:11:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxo6n31",
              "author": "pixllvr",
              "text": "I meant to release an img2img version, I‚Äôll do that today. There is a way to do outpainting with the inpaint crop and stitch node, but results are mixed. You‚Äôll get better results by doing one side at a time, you‚Äôll have to play around with the ‚ÄúInt‚Äù node to avoid having seams as well as the extend for context setting.",
              "score": 1,
              "created_utc": "2026-01-04 18:47:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx4o0j9",
          "author": "Vektast",
          "text": "Most broken hot mess spaghetti workflow I ever tried... Damn your custom nodes! [ComfyUI-NAG](https://github.com/scottmudge/ComfyUI-NAG) is broken on the latest Comfy and I lost 1 hr to figure that out.",
          "score": 0,
          "created_utc": "2026-01-01 19:47:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb3xcv",
              "author": "scorpiov2",
              "text": "yeah. Comfy-Nag doesnt install. I think it might be related to the migration (with is in a couple of days). Hopefully it'll be fixed after that.",
              "score": 1,
              "created_utc": "2026-01-02 19:42:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyz36u",
      "title": "[Update] ComfyUI-SAM3DBody: Multi-person support + depth-based size correction",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/g5ak86nlp7ag1.png",
      "author": "ant_drinker",
      "created_utc": "2025-12-29 21:41:41",
      "score": 79,
      "num_comments": 3,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1pyz36u/update_comfyuisam3dbody_multiperson_support/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwnxq8t",
          "author": "QikoG35",
          "text": "Thx! Your Sam3 node is awesome, want to try this next. But so many requirements, hate to break my environment.",
          "score": 5,
          "created_utc": "2025-12-30 03:01:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwt4az0",
              "author": "DoughtCom",
              "text": "Yeah this nuked my perfectly fine setup last time I tried installing. Maybe I‚Äôll setup a separate comfy portable to give it a go again.",
              "score": 1,
              "created_utc": "2025-12-30 22:04:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwrtof8",
          "author": "_half_real_",
          "text": "I see the 3D preview is mirrored relative to the image? Is is because of the different coordinate systems used by SAM3D and the 3D preview?",
          "score": 2,
          "created_utc": "2025-12-30 18:23:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2rvkr",
      "title": "I've created an SVI Pro workflow that can easily extended to generate longer videos using Subgraphs",
      "subreddit": "comfyui",
      "url": "https://i.redd.it/5dtutqs084bg1.png",
      "author": "Hearmeman98",
      "created_utc": "2026-01-03 10:58:27",
      "score": 78,
      "num_comments": 28,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1q2rvkr/ive_created_an_svi_pro_workflow_that_can_easily/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxgb3tq",
          "author": "jiml78",
          "text": "Something I recommend, I use lora loaders that allow multiple loras easily without having to rewire things.  \n\nAdditionally, assuming you aren't passing the models directly through each subgraph and directly from the primary loader section, it is really nice to add a lora manager for each Video Scene.  That allows you to do things without having a bunch of loras loaded for the entire run.  \n\nI setup my workflow where I have my character and style loras for all segments but specific action loras on specific video segments.  \n\nThis also works with the hard cut lora so you can easily shift the scene in the middle of one of the segments.",
          "score": 6,
          "created_utc": "2026-01-03 15:34:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxuihgw",
              "author": "wasd0109",
              "text": "How do you apply specific lora to specific segments?\n\nWhen I try to apply specific lora only to the specific segment (by connecting the get model and load lora model before connecting it to the sampler) that specific segment quality would drop\n\nDo I have to change stuff such as steps to accommodate the new lora?",
              "score": 1,
              "created_utc": "2026-01-05 17:08:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxh60sc",
          "author": "smileandwatch",
          "text": "At the start of each next video, it jumps back a few frames. I have a feeling it has to do with the \"Image batch extend with overlap\" nodes. In your workflow, is it supposed to have a completely smooth transition? Out of the box, the workflow you linked in Pastebin does not appear to do so.",
          "score": 7,
          "created_utc": "2026-01-03 17:59:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxi7mks",
              "author": "vortex19609",
              "text": "Same here, definite jump in the transitions.",
              "score": 4,
              "created_utc": "2026-01-03 20:57:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxiaadz",
                  "author": "GoofAckYoorsElf",
                  "text": "Yepp, same... And a weird contrast glitch too.",
                  "score": 3,
                  "created_utc": "2026-01-03 21:10:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxfyr6j",
          "author": "SuspiciousGuidance31",
          "text": "I get the following error running a 1280x720 image through  \nprompt outputs failed validation: WanAdvancedI2V: - Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost WanAdvancedI2V: - Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost WanAdvancedI2V: - Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost WanAdvancedI2V: - Value 0.0 smaller than min of 1.0: structural\\_repulsion\\_boost",
          "score": 4,
          "created_utc": "2026-01-03 14:29:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxge3dc",
              "author": "Permitty",
              "text": "i get this error as well., just expand the work flow @ video 1, video 2,.... and change structural\\_repulsion\\_boot from 0.0 to 1.0",
              "score": 4,
              "created_utc": "2026-01-03 15:49:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxg68y4",
              "author": "dzalikkk",
              "text": "same here",
              "score": 1,
              "created_utc": "2026-01-03 15:10:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxgdxv1",
                  "author": "JezPiquel",
                  "text": "Soooo you set structural repulsion boost in the wan advanced i2v nodes to 1 like the error says‚Ä¶.\n\nIf you don‚Äôt have that setting you need to update the nodes which adds that and svi support",
                  "score": 2,
                  "created_utc": "2026-01-03 15:48:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxfa6wx",
          "author": "remizca",
          "text": "what node pack is that set and get from?",
          "score": 3,
          "created_utc": "2026-01-03 11:46:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfk782",
          "author": "Green-Ad-3964",
          "text": "This is interesting and could be converted into a a standalone app (gui) in which you define the length amd automatically the app implements the underneath logic.",
          "score": 2,
          "created_utc": "2026-01-03 13:02:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfpod4",
              "author": "Hearmeman98",
              "text": "Yes, I've created multiple GUIs around ComfyUI",
              "score": 3,
              "created_utc": "2026-01-03 13:36:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxg6wm4",
          "author": "New_Physics_2741",
          "text": "structural\\_repulsion needs to set to a higher value in this WF - 1.5 works. Just slide the thing...",
          "score": 2,
          "created_utc": "2026-01-03 15:13:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgsqmj",
          "author": "bigman11",
          "text": "set up different loras for different phases",
          "score": 2,
          "created_utc": "2026-01-03 16:58:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxfpuxf",
          "author": "Woisek",
          "text": "How is image degradation handled and what do subgraphs have to do with this task? ü§î",
          "score": 1,
          "created_utc": "2026-01-03 13:37:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgc2nr",
          "author": "HAL_9_0_0_0",
          "text": "Which comfyUI do you use? I tried earlier to get SVI up and running after update. I had to reset the system because it smashed my ComfyUI config.",
          "score": 1,
          "created_utc": "2026-01-03 15:39:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxgfkpa",
          "author": "PestBoss",
          "text": "What does the \"image batch extend with overlap\" node do?\n\nDoes the first/last 5 frames of each part get mashed together with a linear blend? I assume these frames must be almost totally identical for this to work?\n\nGonna have to export per section and whole run and then check it out in After Effects or something so I can figure out what it's doing (the tooltip tells you basically what the name of the node is, but in different words, lol)",
          "score": 1,
          "created_utc": "2026-01-03 15:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjjhqb",
          "author": "peejay0812",
          "text": "Hey man, amazing work! I saw your runpod wan-template  got updated to v11. But this broke the WAN animate one. Also, it took more vram that vae decode falls back to tile. Maybe you're already aware of it but just letting you know üëå",
          "score": 1,
          "created_utc": "2026-01-04 01:01:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmt73e",
          "author": "Life_Relationship618",
          "text": "Hey. great Thing  but searching for the right model was'nt that easy. \n\nI have an Prob. From Video clip to another the Picture is going more and more contrastless. could you help?",
          "score": 1,
          "created_utc": "2026-01-04 14:57:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnef9a",
          "author": "JahJedi",
          "text": "Tryed SVI pro (diffrent work flow) and it did not worked weill whit not human character, even lora did not helped. Used wan 2.2 14b waights and all but still bad results.\n\nThis is my character i working on\n\nhttps://preview.redd.it/n8qeg9c82dbg1.png?width=2160&format=png&auto=webp&s=a0b91210adc6e3d1d0e88eab4c7afa423bf457bf",
          "score": 1,
          "created_utc": "2026-01-04 16:40:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q524o4",
      "title": "Trying to achieve this specific \"Raw\" realism aesthetic. Any guesses on the base model or workflow?",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1q524o4",
      "author": "Aggressive_Voice_790",
      "created_utc": "2026-01-05 23:40:24",
      "score": 77,
      "num_comments": 88,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Needed",
      "permalink": "https://reddit.com/r/comfyui/comments/1q524o4/trying_to_achieve_this_specific_raw_realism/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxwyp39",
          "author": "abnormal_human",
          "text": "If I were interested in making stuff like this I would start with Qwen 2512 and train a Lora to the aesthetic I was looking for. Using other people‚Äôs Lora‚Äôs is a shortcut that rarely pays off IMO.",
          "score": 25,
          "created_utc": "2026-01-06 00:05:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx7k42",
              "author": "xoxavaraexox",
              "text": "Have you trained a lora? How did it turn out? What workflow would you recommend?",
              "score": 2,
              "created_utc": "2026-01-06 00:51:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxztrry",
                  "author": "Mountain-Grade-1365",
                  "text": "ai-toolkit",
                  "score": 3,
                  "created_utc": "2026-01-06 12:16:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0bv5y",
                  "author": "abnormal_human",
                  "text": "Hundreds of training runs at this point.\n\nLike others have said, ai-toolkit it a good place to start.",
                  "score": 2,
                  "created_utc": "2026-01-06 14:07:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxy8w6p",
              "author": "scoobasteve813",
              "text": "Do you know if the older qwen loras work with 2512?",
              "score": 1,
              "created_utc": "2026-01-06 04:20:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxydszn",
                  "author": "PsychoLogicAu",
                  "text": "I tested a single one of mine, it worked but had banding artefacts, though YMMV",
                  "score": 3,
                  "created_utc": "2026-01-06 04:52:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny0c1a3",
                  "author": "abnormal_human",
                  "text": "They do something, but you really should retrain for decent results.",
                  "score": 1,
                  "created_utc": "2026-01-06 14:08:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxyew2q",
                  "author": "luciferianism666",
                  "text": "Do you know all it takes is a few minutes to test this on your own ?",
                  "score": -7,
                  "created_utc": "2026-01-06 04:59:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxwys5w",
          "author": "vernchoong",
          "text": "Scroll as far back through the influencers post and note the date this style /quality starts appearing. It may coincide with the release of milestone models that will give you a hint",
          "score": 17,
          "created_utc": "2026-01-06 00:05:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxwzio1",
              "author": "Aggressive_Voice_790",
              "text": "Nov 29 , 2025\nMajor upgrade in her photos quality. Thats tell you something maybe?",
              "score": 8,
              "created_utc": "2026-01-06 00:09:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxx5xsl",
                  "author": "b4ldur",
                  "text": "Synthid was positive. It's tracks with the nov 20 release of nano banana pro",
                  "score": 11,
                  "created_utc": "2026-01-06 00:42:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxx1klm",
                  "author": "noyart",
                  "text": "Z Turbo maybe¬†",
                  "score": 12,
                  "created_utc": "2026-01-06 00:20:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxx74c3",
                  "author": "Aggressive_Voice_790",
                  "text": "Edit: Nov 23 -> Nov 29",
                  "score": 0,
                  "created_utc": "2026-01-06 00:49:11",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxy3cni",
          "author": "Crypto_Loco_8675",
          "text": "https://preview.redd.it/aeelay8xhnbg1.jpeg?width=1290&format=pjpg&auto=webp&s=3e419ccbea9aef9911a3eb5555042ab8682f31f9\n\nNano Banana",
          "score": 25,
          "created_utc": "2026-01-06 03:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx4rlw",
          "author": "kaboomtheory",
          "text": "Why does everyone assume this is an open model? To me it screams nano banana pro especially because of the very good knowledge it has of designer items.",
          "score": 14,
          "created_utc": "2026-01-06 00:36:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx6qdy",
              "author": "Aggressive_Voice_790",
              "text": "But it‚Äôs possible to create a consistent character with nano banana pro? It‚Äôs a closed model right?",
              "score": 3,
              "created_utc": "2026-01-06 00:47:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxx7tvq",
                  "author": "kaboomtheory",
                  "text": "Consistently? I'd say yes and no. But it's not impossible, every few generations you'll get one that looks very consistent, especially if it's close up photos like these. It needs good photos to reference and I'd say you get pretty close most of the time. \n\nIt could also be a two step process with nano being the base and then running it through something else to get the face likeness.",
                  "score": 6,
                  "created_utc": "2026-01-06 00:52:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzk9ki",
                  "author": "four_clover_leaves",
                  "text": "You can just put a reference picture of the person and then use character LoRa via facedetailer node",
                  "score": 2,
                  "created_utc": "2026-01-06 11:01:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxy6xoh",
                  "author": "UncleZoomy",
                  "text": "Yes. Make your person. Make a reference sheet. (With body and face) then put the reference sheet in NBP when you want to generate your photo.",
                  "score": 1,
                  "created_utc": "2026-01-06 04:07:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny13fke",
                  "author": "Crypto_Loco_8675",
                  "text": "100% doable. I do it.",
                  "score": 1,
                  "created_utc": "2026-01-06 16:22:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxzyv0g",
                  "author": "voltisvolt",
                  "text": "it's incredibly easy. nano banana pro is a next gen model. it makes all the comfy ones obsolete except for making straight up porn",
                  "score": 1,
                  "created_utc": "2026-01-06 12:51:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxwvpji",
          "author": "LittlePantsOnFire",
          "text": "Ah you've used my girlfriend as the model obviously",
          "score": 14,
          "created_utc": "2026-01-05 23:49:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0rshp",
              "author": "robertpro01",
              "text": "What do you mean with \"girlfriend\"? She is my wife dude.",
              "score": 2,
              "created_utc": "2026-01-06 15:29:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxxq26f",
              "author": "RowIndependent3142",
              "text": "She‚Äôs cheating on me with you? Oh man. There goes my ego. But I‚Äôm working on making her younger sister with Dreamshaper7 LoRa",
              "score": 2,
              "created_utc": "2026-01-06 02:31:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxx3ddh",
          "author": "AI-Make-NSFW-Stuff",
          "text": "Z image, Qwen or Chroma with any of the dozens of realism/amateur/iphone/lenovo loras out there on civitai",
          "score": 4,
          "created_utc": "2026-01-06 00:29:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx3yp2",
              "author": "Aggressive_Voice_790",
              "text": "Thanks üôèüèª, Can you add character Lora to z image and get good results?",
              "score": 1,
              "created_utc": "2026-01-06 00:32:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxybsi2",
                  "author": "pixllvr",
                  "text": "Short answer but yes! I've trained several character/celebrity LoRAs using [this method that I found from a now-deleted thread](https://www.reddit.com/r/comfyui/comments/1put7gs/reup_best_zimage_training_lora_training_settings/) and am very happy with the results. I've trained with datasets as small as 15 images and as high as 100 and the likeness is pretty great either way. Usually I'll train for 3,000... maybe 5,000 steps if my dataset is huge, but usually step 2,000 ends up being the sweet spot. If you want to try some already trained celebrity loras, this guy singlehandedly trained around 1,000 of them [(see here)](https://huggingface.co/spaces/malcolmrey/browser) which you can try for yourself (Note that not all the example images are from Z Image).",
                  "score": 2,
                  "created_utc": "2026-01-06 04:39:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxx7yrh",
                  "author": "AI-Make-NSFW-Stuff",
                  "text": "At low strengths you'll get decent results but stacking loras on Zimage Turbo is still tricky.",
                  "score": 1,
                  "created_utc": "2026-01-06 00:53:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz4fba",
          "author": "-JProject-",
          "text": "This is 100% Nano Banana Pro, you can tell by the hair. Look at every realistic influencer NB pro image and the hair will always have this ultra sharpness about it where you can see literaly every single tiny strand. Also a green / purple hue patchyness in the compression when you zoom in on dark areas",
          "score": 2,
          "created_utc": "2026-01-06 08:33:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz8pw0",
          "author": "SvenVargHimmel",
          "text": "Can't you just got to CivitaAI, look for images the closest to this and then iterate on top of that?",
          "score": 2,
          "created_utc": "2026-01-06 09:14:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzd660",
          "author": "TwistedBrother",
          "text": "If you got patience the res_5s_ode sampler is unfuckingbelievable for Flux. Like I had no idea how much more realism one could squeeze out of that model. Only problem is it‚Äôs about 3x slower than res_multistep.",
          "score": 2,
          "created_utc": "2026-01-06 09:57:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2f37p",
              "author": "Aggravating-Mix-8663",
              "text": "Cool, can you show us an example?",
              "score": 1,
              "created_utc": "2026-01-06 19:57:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1el8q",
          "author": "bakker_be",
          "text": "https://preview.redd.it/wo52jt9hhrbg1.png?width=2224&format=png&auto=webp&s=e28506df639b8bf1949bd63a78ca95ea510e0dc4\n\nI get this locally, using just my own workflow (https://civitai.com/models/2282703/z-image-turbo-wildcards-to-ollama-structured-prompt-system) and the Z-Turbo-CreartUltimate model (https://civitai.com/models/2243087/z-turbo-creart-ultimate?modelVersionId=2525138). No LoRa, upscaling with SeedVR2",
          "score": 2,
          "created_utc": "2026-01-06 17:13:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx6h2g",
          "author": "RevolutionaryTurn59",
          "text": "This looks like Nano Banana Pro",
          "score": 4,
          "created_utc": "2026-01-06 00:45:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy7rlk",
          "author": "No_Engineer_2690",
          "text": "There are soooo many cool things to do with ai.\n¬†And you thirsty mofos only can think of generating digital hoes ffs. It‚Äôs all that y'all post here all day.",
          "score": 3,
          "created_utc": "2026-01-06 04:13:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwywiq",
          "author": "Straight_Fish_704",
          "text": "For what monetary purpose I ask?",
          "score": 2,
          "created_utc": "2026-01-06 00:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxgc13",
          "author": "icchansan",
          "text": "Lora training, zimage, WAN or qwen",
          "score": 1,
          "created_utc": "2026-01-06 01:38:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxkncb",
          "author": "AbbreviationsAny9759",
          "text": "If I had to guess, z-image turbo or nbp, or both. The quality looks very z-image like, but I don't think it handles branded stuff well like the Chanel purse and the watch, could've been edited in with nbp though.\n\nBut either way, you'd definitely be able to get this type of quality with z-image turbo, and it helps to use a lora.",
          "score": 1,
          "created_utc": "2026-01-06 02:01:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxsn1f",
          "author": "coolsimon123",
          "text": "Wan2.2 T2V got me pretty close, this was my fire workflow before realising you can't train loras locally\n\nhttps://preview.redd.it/i2roirifzsbg1.png?width=960&format=png&auto=webp&s=aef6bdd558c0f7700c959ea28659ba9eccd43534\n\n[https://pastebin.com/4egX0Gdq](https://pastebin.com/4egX0Gdq) Workflow there.\n\nIt uses [https://civitai.com/models/1822984?modelVersionId=2115311](https://civitai.com/models/1822984?modelVersionId=2115311) LORA v2.3 but I've not tried 2.5 it will probably be better.\n\nThat was attempt 1 of 1 by the way! Skin is maybe a touch waxy but you could quite happily process that image with a filter to give it that \"raw\" asthetic.",
          "score": 1,
          "created_utc": "2026-01-06 02:45:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxw7gu",
              "author": "coolsimon123",
              "text": "https://preview.redd.it/03qshi3tanbg1.png?width=960&format=png&auto=webp&s=32252294667b94a7bfae6ccb36e8a6de2ee598c4\n\nAttempt like 7 of the ski photo, this is more down to prompting than anything. Once you've nailed the prompt, you just run like 60 jobs and come back to it an hour later to find something that is bang on what you want. The helmet is a tricky one, they've probably used some kind of clothing LORA to get the helmet to look like the once you've pictured.",
              "score": 2,
              "created_utc": "2026-01-06 03:05:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2etcs",
                  "author": "Crypto_Loco_8675",
                  "text": "https://preview.redd.it/0jdfmpi2bsbg1.png?width=848&format=png&auto=webp&s=e53846e8f3a0a9aa5b716a4589b36cf9b322e330",
                  "score": 1,
                  "created_utc": "2026-01-06 19:56:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxxxer5",
              "author": "coolsimon123",
              "text": "https://preview.redd.it/notm8pisbnbg1.jpeg?width=1170&format=pjpg&auto=webp&s=4a39e5999b2a46fbc3cbe5f08ef87301502a601c\n\nMess with some filters a bit and you've got the added \"realism\".\n\n  \nBeautiful, Instagirl, green eyes, young adult woman, tanned woman, amateur photo, perfect face, wearing a black long sleeved top, pretty face, hyperdetailed photo of a woman, black hair, outdoor setting, bright lighting, sat in ski lift, wearing a silver reflective ski mask on her head, away from camera, wide shot, duck face, pouting",
              "score": 1,
              "created_utc": "2026-01-06 03:12:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxz7ps",
                  "author": "coolsimon123",
                  "text": "https://preview.redd.it/b42adi6mdnbg1.png?width=766&format=png&auto=webp&s=653310d4d50904016744085a49849878072ea360\n\nAdd some noise in photoshop to reduce the plastic effect, you're basically there imo",
                  "score": 1,
                  "created_utc": "2026-01-06 03:22:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxxupds",
          "author": "EpicNoiseFix",
          "text": "No one‚Äôs skin is that soft or smooth. Skin looks like AI",
          "score": 1,
          "created_utc": "2026-01-06 02:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxygt2e",
          "author": "Own-Biscotti4740",
          "text": "I found that using Qwen-style prompts from civitai with z-image gave me pretty good results with a character lora. Most realism loras seem to change the face too much or have little effect on the outcome.\n\nI want to try Qwen VQA for generating prompts from images but still considering whether its worth it.",
          "score": 1,
          "created_utc": "2026-01-06 05:13:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz0fgp",
          "author": "Time-Salt44",
          "text": "Guys, any tips on how to create your own lora? Been struggling with it for several weeks, getting poor results",
          "score": 1,
          "created_utc": "2026-01-06 07:55:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzzaz2",
          "author": "X72-9",
          "text": "This is def a Stable Diffusion ecosystem. I would say it's more like Flux and LoRA. Definitely not Nano Banana. I am almost certain I can obtain similar quality using Flux and LoRA. Flux 2 is the better guess.",
          "score": 1,
          "created_utc": "2026-01-06 12:54:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny12xvh",
              "author": "Crypto_Loco_8675",
              "text": "I proved it was nano banana with the synthid.",
              "score": 2,
              "created_utc": "2026-01-06 16:20:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1bfjm",
                  "author": "X72-9",
                  "text": "Ah ok, thanks for updating me. how do you use Synthid? is it Gemini or sperate thing?",
                  "score": 1,
                  "created_utc": "2026-01-06 16:59:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny08zs5",
          "author": "Nocoder24",
          "text": "Nano banana pro‚Ä¶.",
          "score": 1,
          "created_utc": "2026-01-06 13:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1jiqh",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-06 17:35:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1jsl8",
          "author": "Puzzled-Valuable-985",
          "text": "https://preview.redd.it/onil5u47mrbg1.png?width=1088&format=png&auto=webp&s=90cf12f17ef3c9383e376edc5c80d3e1080c181f\n\nI'll post some examples of Z Image Turbo, specifying the models with and without LoRa, changing only the workflow of each.",
          "score": 1,
          "created_utc": "2026-01-06 17:37:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1ju82",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/wsi0zu68mrbg1.png?width=1536&format=png&auto=webp&s=3564b2cd1aee520bfd53d1be9159cd7a9c8cb7f1",
              "score": 1,
              "created_utc": "2026-01-06 17:37:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny1jw9e",
                  "author": "Puzzled-Valuable-985",
                  "text": "https://preview.redd.it/zkdvrvu9mrbg1.png?width=832&format=png&auto=webp&s=86acebdf3db50c3e9cec431e94ab5a6f2d410e3d\n\nlora on",
                  "score": 1,
                  "created_utc": "2026-01-06 17:37:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny1jytc",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/51pnxm2cmrbg1.png?width=1232&format=png&auto=webp&s=fb9e14e9d5ce673f797b77e96d6069a22939c3ef\n\nlora on",
              "score": 1,
              "created_utc": "2026-01-06 17:38:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1k5re",
              "author": "Puzzled-Valuable-985",
              "text": "https://preview.redd.it/7kf7u14emrbg1.png?width=832&format=png&auto=webp&s=5d394d5512a649f8da480c7b6e18f1e78a64c6e6\n\nThis is the only one I made in Flux 2 Dev with Turbo LoRa from FAL.",
              "score": 1,
              "created_utc": "2026-01-06 17:38:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2fjz4",
          "author": "Crypto_Loco_8675",
          "text": "It is nano banana pro. Took her 2nd image with the selfie. Took my custom workflow and node. Made a half body image. Then I used another custom workflow to extract the prompt. Took the half body image I made real quick and used it as a reference image with the prompt and a coupe of prompts later it is almost the same image, except both arms are taking the selfie and she's looking out the opposite side.. but it is just a simple test.\n\nhttps://preview.redd.it/zl2ntwsnbsbg1.png?width=848&format=png&auto=webp&s=a14a8e1c38de37cef9edcaf25506cdb07475a42d",
          "score": 1,
          "created_utc": "2026-01-06 20:00:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2fnhm",
              "author": "Crypto_Loco_8675",
              "text": "https://preview.redd.it/7ubk54npbsbg1.png?width=848&format=png&auto=webp&s=8439e8a80d1ef6e2ad180bc07da7f1dd7fe33f78\n\nQuick reference image I used.",
              "score": 1,
              "created_utc": "2026-01-06 20:00:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3mvfh",
          "author": "osxdocc",
          "text": "https://preview.redd.it/cbzicuw0ctbg1.png?width=1536&format=png&auto=webp&s=bad2bf99d4c2ef1754a51fbf0dd291d25125ca68\n\nQwen Image 2512 via DrawThings (iOS/ipados/macos)",
          "score": 1,
          "created_utc": "2026-01-06 23:24:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3nbet",
              "author": "osxdocc",
              "text": "https://preview.redd.it/vnwo1ytjctbg1.png?width=1536&format=png&auto=webp&s=d16cb8e44137c4661875bb2fff71ebd33da6714c",
              "score": 1,
              "created_utc": "2026-01-06 23:26:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny3nroa",
              "author": "osxdocc",
              "text": "https://preview.redd.it/fvio0qyyctbg1.png?width=1536&format=png&auto=webp&s=5252150afb82e845297e1b0beef42410e835e59f",
              "score": 1,
              "created_utc": "2026-01-06 23:29:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxx9x1t",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -7,
          "created_utc": "2026-01-06 01:04:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxemsp",
              "author": "_kelsy",
              "text": "this looks terrible",
              "score": 8,
              "created_utc": "2026-01-06 01:29:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxkfiq",
                  "author": "IvoryDynamite",
                  "text": "Agreed. Legs and abdomen look airbrushed, disproportionate man hands, etc.",
                  "score": 1,
                  "created_utc": "2026-01-06 02:00:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q06hza",
      "title": "are there alternative sites to CivitAI for wan 2.2 loras",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q06hza/are_there_alternative_sites_to_civitai_for_wan_22/",
      "author": "jigholeman",
      "created_utc": "2025-12-31 06:53:03",
      "score": 74,
      "num_comments": 20,
      "upvote_ratio": 0.94,
      "text": "I like civitai, it's a good site that has had a lot of work put into it, but there are some things you can't post on civitai (like that one water shooting lora that got deleted because peeing isn't allowed).\n\ni was curious because im now wondering what loras i'm missing out on, because of civitai's content policy.",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/comfyui/comments/1q06hza/are_there_alternative_sites_to_civitai_for_wan_22/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nwvky2l",
          "author": "Direct-Vehicle2653",
          "text": "[https://civarchive.com](https://civarchive.com)\n\n[https://huggingface.co/ApacheOne/WAN\\_loRAs/tree/main?not-for-all-audiences=true](https://huggingface.co/ApacheOne/WAN_loRAs/tree/main?not-for-all-audiences=true)",
          "score": 44,
          "created_utc": "2025-12-31 07:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvlcj5",
              "author": "jigholeman",
              "text": "Thank you",
              "score": 6,
              "created_utc": "2025-12-31 07:10:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwvu34f",
              "author": "plus-minus",
              "text": "Thank you!\n\nI wish someone had re-uploaded these [Real Princesses LoRAs](https://civarchive.com/models/2074663?modelVersionId=2347556) somewhere.",
              "score": 6,
              "created_utc": "2025-12-31 08:31:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nww78x1",
                  "author": "AI-Make-NSFW-Stuff",
                  "text": "Most authors have a Discord link that you can join and get their deleted Loras from 3rd party download sites",
                  "score": 3,
                  "created_utc": "2025-12-31 10:36:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwy3dga",
                  "author": "q5sys",
                  "text": "Why does it say its deleted from civitai? [https://civitai.com/models/2074663?modelVersionId=2347556](https://civitai.com/models/2074663?modelVersionId=2347556)",
                  "score": 2,
                  "created_utc": "2025-12-31 17:35:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx6s86q",
              "author": "Terrible_Credit8306",
              "text": "Do you have a link for images, similar concepts",
              "score": 1,
              "created_utc": "2026-01-02 02:49:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx0txh9",
          "author": "boobkake22",
          "text": "HuggingFace is definitely a \"for now\", because, while there are people uploading them there, it's against their rules. They are funded by business activities, so their infrastructure is very very good.\n\nCivArchive mostly points at HuggingFace, but because the folks using HF are being sneaky, it's the only good way to find things people have archived there. They \\*will\\* notice eventually.\n\nIf HuggingFace goes after these files, it's going to get weird, since the only alternatives will become the old school file sharing sites like Mega, which are akward to use at best.\n\nCivitAI is the main site. An alternative is unlikely due to the high cost of storing and quickly transfering a large set of models and LoRA's.\n\nPeople have a poor understanding of the financial reasons why Civ is having to do the agressive moderation they are doing - these are largely determined by payment processing companies, and why there are unlikely to be alternatives under current conditions. A site like Civ has a large operating cost, and with very few options for collecting revenue, it's a difficult business proposition, under the best of circumstances.",
          "score": 8,
          "created_utc": "2026-01-01 02:58:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2dhke",
              "author": "alb5357",
              "text": "Maybe a torrent site?",
              "score": 1,
              "created_utc": "2026-01-01 11:22:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7npav",
                  "author": "boobkake22",
                  "text": "Could work, but makes keeping stuff around a challenge. It would also take a long time to build up enough network effect to creat a de-facto, \"Obviously use CivitAI, because it's got everything\". And still has a lot of overhead, much less, but still time demanding.",
                  "score": 2,
                  "created_utc": "2026-01-02 06:26:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwz4dk9",
          "author": "MelodicFuntasy",
          "text": "We need a community owned alternative.",
          "score": 6,
          "created_utc": "2025-12-31 20:46:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0jizh",
          "author": "minimalcation",
          "text": "Wow or just use the focus of the subreddit for free",
          "score": 2,
          "created_utc": "2026-01-01 01:48:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxach3j",
          "author": "Witty_Side8702",
          "text": "For a live video experience play [dmwithme](https://dmwithme.com/?ref=xmas5), it has great RP no ads\n\nhttps://i.redd.it/3yp21t412zag1.gif",
          "score": 0,
          "created_utc": "2026-01-02 17:34:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxamoua",
          "author": "Robertkr1986",
          "text": "I like and use [soulkyn](https://soulkyn.app/?_go=robert85) \n\nIt‚Äôs a nsfw site that has a chatbot and an image generator. You can create 1 character or pick them from the huge and growing library and the first few pictures are free. After that you have to decide if you want premium and the better model with memory and more features like narration mode, voice chat and group chat. You can make 10 second videos as well.",
          "score": 0,
          "created_utc": "2026-01-02 18:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5h3o6",
          "author": "CHAN-MAn_",
          "text": "Pers‚Å§onally I use DarL‚Å§ink AI for my NSFW videos and it's incr‚Å§edible. Top qual‚Å§ity, fully uncens‚Å§ored, no restric‚Å§tions at all.",
          "score": -2,
          "created_utc": "2026-01-01 22:18:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx79c00",
              "author": "jigholeman",
              "text": "just looked it up, Darlink is an \"ai girlfriend\" website, i was looking for WAN 2.2 Loras.",
              "score": 1,
              "created_utc": "2026-01-02 04:39:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxap8uh",
                  "author": "VacationVegetable121",
                  "text": "there is video generation... they probably use wan",
                  "score": 1,
                  "created_utc": "2026-01-02 18:33:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q57tmo",
      "title": "Official AMD ROCm‚Ñ¢ Support Arrives on Windows for ComfyUI Desktop",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q57tmo/official_amd_rocm_support_arrives_on_windows_for/",
      "author": "PurzBeats",
      "created_utc": "2026-01-06 03:42:01",
      "score": 72,
      "num_comments": 23,
      "upvote_ratio": 0.95,
      "text": "We‚Äôre excited to announce that official¬†[AMD ROCm‚Ñ¢ support](https://www.amd.com/en/blogs/2026/amd-comfyui-advancing-professional-quality-generative-ai-ryzen-radeon.html)¬†is now available on the Windows ComfyUI Desktop app, starting with version v0.7.0.\n\nWith this release, Windows users can finally tap into the full power of supported AMD Radeon‚Ñ¢ GPUs and Ryzen‚Ñ¢ AI processors, unlocking faster performance and a smoother experience across ComfyUI workflows.\n\nGoing forward, users will continuously be able to run ComfyUI on AMD ROCm‚Ñ¢ GPUs with:\n\n* [Windows Desktop version](https://www.comfy.org/download)\n* [Windows Git version](https://github.com/comfyanonymous/ComfyUI)\n* [Windows Portable version](https://github.com/comfyanonymous/ComfyUI)\n\n# How to get started:\n\n1. Download ComfyUI¬†[desktop](https://www.comfy.org/download)\n2. During installation, AMD ROCm‚Ñ¢ should be automatically selected\n3. Finish installation and boot ComfyUI!\n\n[During installation, AMD ROCm‚Ñ¢ should be automatically selected](https://preview.redd.it/z3meu131hnbg1.png?width=2022&format=png&auto=webp&s=d7df531b02831844c215b42eae47617c37081663)\n\n[](https://substackcdn.com/image/fetch/$s_!TRuH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13baea85-3203-4740-b165-47e8ce9bb2ad_2022x1324.png)\n\nThis release of the ComfyUI Desktop app and Portable is based on ROCm 7.1.1. Additional performance, feature improvements, expanded support, and bug fixes are expected in future releases.\n\n[The AMD ROCm‚Ñ¢ 7.1.1 Preview driver](https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-LINUX-ROCM-7-1-PREVIEW.html)¬†is recommended for this release and supports the use of --use-pytorch-cross-attention flag. This support is expected to be merged into the mainline branch in an upcoming AMD Software: Adrenalin‚Ñ¢ Edition driver release. Please visit the¬†[AMD blog](https://www.amd.com/en/blogs/2026/amd-comfyui-advancing-professional-quality-generative-ai-ryzen-radeon.html)¬†for more details on the benchmark.\n\nIn addition to desktop, AMD ROCm‚Ñ¢ is also supported on the portable and git versions of¬†[ComfyUI](https://github.com/comfyanonymous/ComfyUI).\n\nHappy building!",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/comfyui/comments/1q57tmo/official_amd_rocm_support_arrives_on_windows_for/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nxyifjg",
          "author": "2legsRises",
          "text": "so nice, hope to see a lot more competition for nvidia.",
          "score": 17,
          "created_utc": "2026-01-06 05:24:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxygi5l",
          "author": "kirmm3la",
          "text": "That‚Äôs nice. I would love to see some comparisons or side to side benchmarks of Nvidia and AMD GPUs rendering stuff in ComfyUI.",
          "score": 13,
          "created_utc": "2026-01-06 05:11:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz39t5",
              "author": "Bask82",
              "text": "I would too!",
              "score": 2,
              "created_utc": "2026-01-06 08:22:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxzjo8r",
              "author": "Winougan",
              "text": "Here's the main takeaway - although Intel Arc and AMD Radeon GPUs are fully supported in Windows and Pytorch and in Comfyui - you won't get any benefits from Sageattention nor Flashattention. Both of those speed boosts require cudas. But, at least you can snap up a cheaper GPU and render - just not with that cushy 20% speed boost. I have my eyes on 2 24GB Intel Arc GPUs coming out soon. They're each $500 MSRP.",
              "score": 2,
              "created_utc": "2026-01-06 10:56:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny258fr",
                  "author": "Bask82",
                  "text": "Can you run with two GPUs? How is that done?",
                  "score": 1,
                  "created_utc": "2026-01-06 19:12:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz4bjn",
          "author": "alex_godspeed",
          "text": "Thks, but I've moved to ubuntu :)",
          "score": 4,
          "created_utc": "2026-01-06 08:32:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxyuems",
          "author": "Frogy_mcfrogyface",
          "text": "I might have to dust off the old rx6800 if it's compatible :D curious to see what it would do against my 5060ti since they are pretty similar with local LLM.¬†",
          "score": 2,
          "created_utc": "2026-01-06 07:01:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxynin6",
          "author": "Sad-Chemist7118",
          "text": "Benchmarks! Benchmarks! Benchmarks!\n\nWell, I at least hope they come pouring in soon as far more AMD users gain access now. Also a lit more crash reports and people seeking assistance.",
          "score": 4,
          "created_utc": "2026-01-06 06:03:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz3d7m",
              "author": "Bask82",
              "text": "I have never tried out Comfyui, but I do have an AMD card. How do I benchmark, when I get going, so I can report back?",
              "score": 1,
              "created_utc": "2026-01-06 08:23:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyxnb3",
          "author": "mrkokkinos",
          "text": "So I have a RTX 5090 and a 9800X3D, could i theoretically offload some of the workload to the 9800X3D iGPU?",
          "score": 1,
          "created_utc": "2026-01-06 07:30:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz7xc8",
              "author": "arthropal",
              "text": "While theoretically possible it's prohibitively difficult to mix cards in one system for comfy like that because comfy runs in one python environment and you can generally only have one torch install per environment and it has to be either the rocm fork or the cuda fork. \n\nI'm sure there's ways to do it if you want to get creative but no simple path",
              "score": 3,
              "created_utc": "2026-01-06 09:07:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxz869h",
                  "author": "mrkokkinos",
                  "text": "Ah, that sounds like a nope for me üòÖ",
                  "score": 2,
                  "created_utc": "2026-01-06 09:09:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny01zni",
                  "author": "Icy_Concentrate9182",
                  "text": "There is a comfy fork, i believe which let's you offload some things,\nBut they have to be discrete tasks.\n\nSorry, can't remember the name.",
                  "score": 1,
                  "created_utc": "2026-01-06 13:11:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2bo94",
                  "author": "ZenEngineer",
                  "text": "I wonder if there's some API nodes that would allow you to do some work in a separate process.\n\nLike if you have some sort of LLM nodes you could load the LLM on a local sever (Comfy or something else) and call out there. \n\nIn theory you could have a second ComfyUI instance as it provides an API anyway (like Krita uses) but you'd need a node in the main process to call out. Is there something like that with the whole push for their cloud API? You could have a simple workflow that just loads the text encoder or the VAE or something.",
                  "score": 1,
                  "created_utc": "2026-01-06 19:42:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzhp2c",
          "author": "IordanouGiannis",
          "text": "I have installed comfyui on windows through git, would be better to uninstall it and use the new desktop amd version ?",
          "score": 1,
          "created_utc": "2026-01-06 10:38:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny30n7a",
              "author": "Beulpower87",
              "text": "i used the portable version and will switch back, image generation is faster for me but wan2.2 is 3-4 times the length.\n\nedit:  \nnvm found out why its taking so long, somehow i got multiple python processes and my vram never got empty.",
              "score": 1,
              "created_utc": "2026-01-06 21:37:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzxgh6",
          "author": "quendae",
          "text": "That's cool, but i've got issue on 6950XT, not sure if this is the driver issue or what, but it crashes when loading z\\_image\\_turbo workload from comfyui\n\n    [2026-01-06 13:37:19.654] [PRE] ComfyUI-Manager\n    [2026-01-06 13:37:20.723] Checkpoint files will always be loaded safely.\n    [2026-01-06 13:37:20.937] Total VRAM 16368 MB, total RAM 32581 MB\n    [2026-01-06 13:37:20.937] pytorch version: 2.9.0+rocmsdk20251116\n    [2026-01-06 13:37:20.937] AMD arch: gfx1030\n    [2026-01-06 13:37:20.937] ROCm version: (7, 1)\n    [2026-01-06 13:37:20.938] Set vram state to: NORMAL_VRAM\n    [2026-01-06 13:37:20.938] Device: cuda:0 AMD Radeon RX 6950 XT : native\n    [2026-01-06 13:37:20.949] Using async weight offloading with 2 streams\n    [2026-01-06 13:37:20.949] Enabled pinned memory 14661.0\n    [2026-01-06 13:37:21.694] Using sub quadratic optimization for attention, if you have memory or speed issues try using: --use-split-cross-attention\n    [2026-01-06 13:37:23.070] Python version: 3.12.11 (main, Aug 18 2025, 19:17:54) [MSC v.1944 64 bit (AMD64)]\n    [2026-01-06 13:37:23.070] ComfyUI version: 0.7.0\n    [2026-01-06 13:37:23.087] [Prompt Server] web root: I:\\ComfyUI\\resources\\ComfyUI\\web_custom_versions\\desktop_app\n    [2026-01-06 13:37:23.087] [START] ComfyUI-Manager\n    [2026-01-06 13:37:23.243] [ComfyUI-Manager] network_mode: public\n    [2026-01-06 13:37:23.248] [ComfyUI-Manager] The matrix sharing feature has been disabled because the \\matrix-nio` dependency is not installed.`\n    `To use this feature, please run the following command:`\n    \n    `C:\\ComfyUI\\.venv\\Scripts\\python.exe -m pip install matrix-nio`\n    [2026-01-06 13:37:23.639] Total VRAM 16368 MB, total RAM 32581 MB\n    [2026-01-06 13:37:23.639] pytorch version: 2.9.0+rocmsdk20251116\n    [2026-01-06 13:37:23.639] AMD arch: gfx1030\n    [2026-01-06 13:37:23.639] ROCm version: (7, 1)\n    [2026-01-06 13:37:23.640] Set vram state to: NORMAL_VRAM\n    [2026-01-06 13:37:23.640] Device: cuda:0 AMD Radeon RX 6950 XT : native\n    [2026-01-06 13:37:23.654] Using async weight offloading with 2 streams\n    [2026-01-06 13:37:23.654] Enabled pinned memory 14661.0\n    [2026-01-06 13:37:24.148]\n    Import times for custom nodes:\n    [2026-01-06 13:37:24.148] 0.0 seconds: I:\\ComfyUI\\resources\\ComfyUI\\custom_nodes\\websocket_image_save.py\n    [2026-01-06 13:37:24.148]\n    [2026-01-06 13:37:24.354] Failed to initialize database. Please ensure you have installed the latest requirements. If the error persists, please report this as in future the database will be required: (sqlite3.OperationalError) unable to open database file\n    (Background on this error at: https://sqlalche.me/e/20/e3q8)\n    [2026-01-06 13:37:24.393] Starting server\n    [2026-01-06 13:37:24.394] To see the GUI go to: http://127.0.0.1:8000\n    [2026-01-06 13:37:25.297] comfyui-frontend-package not found in requirements.txt\n    [2026-01-06 13:37:32.067] got prompt\n    [2026-01-06 13:37:32.098] Using split attention in VAE\n    [2026-01-06 13:37:32.099] Using split attention in VAE\n    [2026-01-06 13:37:32.166] VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n    [2026-01-06 13:37:36.837] Requested to load ZImageTEModel_\n    [2026-01-06 13:37:36.849] loaded completely; 95367431640625005117571072.00 MB usable, 7672.25 MB loaded, full load: True\n    [2026-01-06 13:37:36.851] CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n\nCurrently using AMD Pro Edition, 25.10.16.01.",
          "score": 1,
          "created_utc": "2026-01-06 12:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2077g",
              "author": "BigDannyPt",
              "text": "Looking at the drivers, they seem to only be for RDNA 3 and later. RX6000 series aren't listed in it.\n\n\nI know that it might work even if it is not listed, but it is also a way of them saying that it isn't compatible and call it a day.¬†",
              "score": 1,
              "created_utc": "2026-01-06 18:50:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny23j1o",
              "author": "manBEARpigBEARman",
              "text": "Not supported: [https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-7-1-1.html](https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-7-1-1.html)",
              "score": 1,
              "created_utc": "2026-01-06 19:04:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny04y86",
          "author": "jj4379",
          "text": "So I run nvidia and I have a question because I have tons of newbie friends whomst I am DEFINITELY going to have to help.\n\nDoes this only require that preview driver or are there extra steps like prior where you have to add some paths and stuff?\n\n  \nEdit: Yes I saw the 1,2,3 steps but I am just curious if there is an additional thing. I'd love for AMD users to be able to get in on this as painlessly as possible",
          "score": 1,
          "created_utc": "2026-01-06 13:28:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny22v0t",
              "author": "manBEARpigBEARman",
              "text": "one-click install with the desktop version. I have never run comfyUI locally but was generating images on a 9070 XT with the default z-image workflow in less than 15 minutes after clicking download. Just update the driver (link is wrong in the blog, goes to linux--the whole point is that this is for windows).\n\n  \nedit: to clarify, the link is wrong in the comfy blog. The AMD update blog has the correct link to the windows driver: [https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-7-1-1.html](https://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-7-1-1.html)",
              "score": 1,
              "created_utc": "2026-01-06 19:01:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2h5h9",
          "author": "peyloride",
          "text": "Can someone with 7900XTX try the z-image? I got 10 seconds for 1024x1024 9 steps",
          "score": 1,
          "created_utc": "2026-01-06 20:07:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny30ujl",
          "author": "Geekn4sty",
          "text": "You're linking to a linux driver, which is not applicable for the windows only desktop app version of ComfyUI.\n\nIt would be a good idea to include this link in your blog and this post, so people can check their hardware compatibility.\n\nhttps://www.amd.com/en/resources/support-articles/release-notes/RN-AMDGPU-WINDOWS-PYTORCH-7-1-1.html",
          "score": 1,
          "created_utc": "2026-01-06 21:38:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxp26p",
      "title": "WAN2.1 SCAIL post control test",
      "subreddit": "comfyui",
      "url": "https://v.redd.it/8bzqmx7dix9g1",
      "author": "Aneel-Ramanath",
      "created_utc": "2025-12-28 11:19:36",
      "score": 62,
      "num_comments": 7,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Show and Tell",
      "permalink": "https://reddit.com/r/comfyui/comments/1pxp26p/wan21_scail_post_control_test/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwcq4xq",
          "author": "ver0cious",
          "text": "Being out of the loop on the whole video gen:\nWan 2.1 still has advantages over 2.2? If someone where to try video generation out, where to begin? It looks like there are so many different paths",
          "score": 5,
          "created_utc": "2025-12-28 12:20:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwd2fs4",
              "author": "_half_real_",
              "text": "This is a Wan 2.1 finetune, so it's weights are trained using Wan 2.1 as a starting point, but they aren't the same weights. This is meant specifically for following pose skeletons from a starting image, not just simple image-to-video or text-to-video like the official Wan 2.1 and 2.2 weights. Wan SCAIL is really good at following poses but doesn't have good facial emotion/animation like Wan Animate.\n\nThese kinds of Wan finetunes take time to research, design and train, which is likely why it's based on 2.1 (also, it's probably easier to train a single-model finetune than a two-model (high+low) finetune).\n\nI started with image-to-video with the normal Wan variants, but where you start depends on what you want to do.",
              "score": 6,
              "created_utc": "2025-12-28 13:50:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwd36cf",
          "author": "_half_real_",
          "text": "I watched this with the sound off at first and [Lone Digger by Caravan Palace](https://www.youtube.com/watch?v=UbQgXeY_zi4) started playing in my head.",
          "score": 2,
          "created_utc": "2025-12-28 13:55:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfbea5",
          "author": "M_4342",
          "text": "looks great. what gpu did you use and what were your generation times?",
          "score": 2,
          "created_utc": "2025-12-28 20:42:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh5qjh",
              "author": "Aneel-Ramanath",
              "text": "5090, render time is 1hr:10min for 512x896 resolution for about 800 frames.",
              "score": 3,
              "created_utc": "2025-12-29 02:34:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwftwkr",
          "author": "emplo_yee",
          "text": "if you want face and hands with multiple characters, use DW POSE for the face and hands and ViTPose for the body to create the NLF.",
          "score": 1,
          "created_utc": "2025-12-28 22:13:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgsjda",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2025-12-29 01:18:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh5kcg",
              "author": "Aneel-Ramanath",
              "text": "Sorry, no WF for you lazy a\\*\\* \\*F, make an effort to read the post fully and search",
              "score": 1,
              "created_utc": "2025-12-29 02:33:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q14sre",
      "title": "[Custom Node] I built a geometric \"Auto-Tuner\" to stop guessing Steps & CFG. Does \"Mathematically Stable\" actually equal \"Better Image\"? I need your help to verify.",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/r/comfyui/comments/1q14sre/custom_node_i_built_a_geometric_autotuner_to_stop/",
      "author": "JB_King1919",
      "created_utc": "2026-01-01 13:58:43",
      "score": 57,
      "num_comments": 10,
      "upvote_ratio": 0.91,
      "text": "Hi everyone,\n\nI'm an engineer coming from the RF (Radio Frequency) field. In my day job, I use oscilloscopes to tune signals until they are clean.\n\nWhen I started with Stable Diffusion, I **had no idea** how to tune those parameters (Steps, CFG, Sampler). I didn't want to waste time guessing and checking. So, I built a custom node suite called **MAP (Manifold Alignment Protocol)** to try and automate this using math, mostly just for my own mental comfort (haha).\n\nInstead of judging \"vibes,\" my node calculates a **\"Q-Score\" (Geometric Stability)** based on the latent trajectory. It rewards **convergence** (the image settling down) and **clarity** (sharp edges in latent space).\n\n**But here is my dilemma:** I am optimizing for **Clarity/Stability**, not necessarily \"Artistic Beauty.\" I need the community's help to see if these two things actually correlate.\n\nHere is what the tool does:\n\n# 1. The Result: Does Math Match Your Eyes?\n\nHere is a comparison using the **SAME SEED** and **SAME PROMPT**.\n\nhttps://preview.redd.it/2ofhntsytqag1.png?width=3087&format=png&auto=webp&s=b445429389e884ae3b08b39c2db1ed8caa24e859\n\n* **Left:** Default sampling (20 steps, 8 CFG, simple scheduler)\n* **Center:** MAP-optimized sampling (25 steps, 8 CFG, exponential scheduler) \n* **Right:** Over-cooked sampling (60 steps, 12 CFG, simple scheduler)\n\n**My Question to You:** To my eyes, the Center image has better object definition and edge clarity without the \"fried\" artifacts on the Right. **Do you agree? Or do you prefer the softer version on the Left?**\n\n# 2. How it Works: The Auto-Tuner\n\nI included a \"Hill Climbing\" script that automatically adjusts Steps/CFG/Scheduler to find that sweet spot.\n\nhttps://preview.redd.it/qpydc8e0uqag1.png?width=989&format=png&auto=webp&s=2281b8e7e888c97aeae18abf6129508d322cfa4e\n\n* It runs small batches, measures the trajectory curvature, and \"climbs\" towards the peak Q-Score.\n* It stops when the image is \"fully baked\" but before it starts \"burning\" (diverging).\n* *Alternatively, you can use the Manual Mode. Feel free to change the search range for different results.*\n\n# 3. Usage\n\nIt works like a normal KSampler. You just need to connect the `analysis_plot` output to an image preview to check the optimization result. The scheduler and CFG tuning have dedicated toggles‚Äîyou can turn them off if not needed to save time.\n\nhttps://preview.redd.it/1gxt9xi4uqag1.png?width=684&format=png&auto=webp&s=86283fef952bc396043e189e7499996dbc0e61df\n\n# üß™ Help Me Test This (The Beta Request)\n\nI've packaged this into a ComfyUI node. I need feedback on:\n\n1. **Does high Q-Score = Better Image for YOU?** Or does it kill the artistic \"softness\" you wanted?\n2. **Does it work on SDXL / Pony?** I mostly tested on SD1.5/Anime models (WAI).\n\n**üì• Download & Install:**\n\n* **Repo:** [MAP-ComfyUI](https://github.com/JBKing514/map_comfyui)\n* **Requirement:** You need `matplotlib` installed in your ComfyUI Python environment (`pip install matplotlib`).\n\nIf you run into bugs or have theoretical questions about the \"Manifold\" math behind this, feel free to drop a comment or check the repo.\n\n>\n\nHappy tuning!",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1q14sre/custom_node_i_built_a_geometric_autotuner_to_stop/",
      "domain": "self.comfyui",
      "is_self": true,
      "comments": [
        {
          "id": "nx3i5fd",
          "author": "PestBoss",
          "text": "I'm a bit confused because any non-ancestral sampler will 'settle down' depending on the noise the sampler is asked to remove at each step, and that 'settling down' is a function of the scheduler.\n\nAnd in your (only?) example the model preferred exponential?\n\nExponential settles down nicely because it's an exp curve.\n\n\nIf the Q score is scoring higher for images that settle down nicely, then it's just going to score exponential schedulers highest isn't it?\n\nBut things like WAN 2.2 for example, converge and denoise very quickly over the last few steps, (inv exp) but also have amazing quality.\n\n\nTo clarify, exponential scheduler in ComfyUI is exponential decay.\n\nWAN2.2 on the other hand uses a curve more like a parabolic decay curve with 'simple' scheduler (remember the shift value also pushes the simple scheduler values around too)\n\n\nSurely to find the best Q needs to look at the actual Image Quality somehow and how it changes over time at various settings.\n\n\n\nBut also worth noting that the pure quality of the pixels may not always be the priority depending on the purpose.\n\nIe, I've used some models in a really rough first pass, with really oddly shaped scheduling over not many steps, and then pass this for a second pass with another model for refining.",
          "score": 11,
          "created_utc": "2026-01-01 16:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3mwb1",
              "author": "JB_King1919",
              "text": "Incredibly sharp insight. You are absolutely right.\n‚ÄãMy current Q-Score measures absolute velocity, so it naturally biases towards Exponential schedulers simply because they physically force smaller steps at the end. I am essentially conflating \"scheduler-induced deceleration\" with \"semantic convergence.\"\n‚ÄãAs you noted, this will definitely unfairly penalize linear flow models like Wan/Flux.\n‚ÄãTo fix this, I consider to normalize the velocity by the noise step size to decouple the scheduler's influence from the actual image refinement.\n‚ÄãThanks for this bug report‚Äîthis is exactly the kind of structural flaw I needed to identify for v0.3!",
              "score": 6,
              "created_utc": "2026-01-01 16:40:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx4h58d",
                  "author": "PestBoss",
                  "text": "Yes it's probably worth doing something that compensates for the scheduler Y steps.\n\nAh ok it makes more sense now I think about it. So you just watch the change in the image (latent to pixels at each step) and get a curve of rate of change vs steps.\nThen you bias the curve based on the requested noise removal rate (schedule), to 'normalise' it.\n\nThus you start to get an idea when you're over-stepping for no gain.\n\nThis could also be really useful to find good combos, ie, scheduler X with sampler Y is best with Z steps.\nOr U V W, etc.\nAlso worth being able to plot with a shift parameter to change the curve shape of the schedule?\n\n\nProbably also worth having a look at the other variables because I'm familiar with schedulers but less so with stuff like CFG etc. It may be that other such things are going to impact those.",
                  "score": 4,
                  "created_utc": "2026-01-01 19:13:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx2y1en",
          "author": "No_Damage_8420",
          "text": "Thanks for sharing info, this is pretty deep dive, reminds me of - GRID SEARCH and/or auto tuning for normal Neural Networks hyper parameters.  \nWell done, will test it with photo real things.\n\nI have question, this is tuning for specific FIXED SEED ? or once \"tuned\" - can be re-used? (parameters)",
          "score": 3,
          "created_utc": "2026-01-01 14:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2zhxl",
              "author": "JB_King1919",
              "text": "Thanks! You nailed it‚Äîit‚Äôs basically \"Automated Hyperparameter Tuning\" but using geometric feedback instead of loss validation.\n\nTo answer your question about re-usability:\n\n* **Schedulers: Highly Re-usable.** In my testing, the optimal scheduler tends to be consistent for a specific Checkpoint. For example, my model (WAI) consistently scores highest with `Exponential`, regardless of the seed. Once you find the best scheduler for your model, you can usually lock it in.\n* **Steps & CFG: Partially Re-usable.** These are more sensitive to the specific noise pattern (Seed) and prompt complexity. The tuned values serve as a **great baseline**, but for the absolute best result, I recommend running the tuner again if you change the seed significantly.\n\n**My Workflow:** I mostly use it for **\"Precision Polishing\"**‚Äîonce I find a seed/composition I like, I run the tuner to squeeze out the best clarity.\n\nI'm super curious to see if your Photo-real tests pick a different scheduler than my Anime models. Let me know what you find!",
              "score": 3,
              "created_utc": "2026-01-01 14:25:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2x2zx",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-01 14:09:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2yj0n",
              "author": "JB_King1919",
              "text": "Great question! I realized I was a bit too abstract in the post.\n\n**What to judge:** Please focus on **\"Clarity\"** and **\"Definition\"**, rather than artistic style. Since the math rewards the latent trajectory \"settling down\" into a stable state, a **High Q-Score** usually translates to Sharper, more defined edges (less \"mushy\" lines), Separation of objects from the background, Reduction of vague/dreamy artifacts.\n\n**The Test:** Compare a Low-Q vs. High-Q result. Does the High-Q one look **\"cleaner\"** and **\"more solid\"** to you? Or does it look **\"over-baked/fried\"** (too much contrast)?\n\n**A Note on Model Types:** I mostly tested on **Anime models** (where sharp lines are good). For Realism/SDXL, I suspect that for photorealistic models, a maximum Q-Score might actually look *too* sharp (like plastic skin). The math might want to remove the \"texture noise\" that makes photos look real.\n\nIf you test on realistic models, I'd love to know if the \"Sweet Spot\" implies a slightly lower Q-Score than anime!",
              "score": 1,
              "created_utc": "2026-01-01 14:18:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx4wo3a",
                  "author": "tazztone",
                  "text": "i made some prototype nodes for pyiqa (early alpha prolly) . do you think they could be handy?\nhttps://github.com/tazztone/ComfyUI-Image-Quality-Assessment\nTo test if a High Q-Score truly results in sharper edges and better object separation, maybe use the MUSIQ (Multi-scale Image Quality Assessment) or HyperIQA nodes... https://www.perplexity.ai/search/https-github-com-jbking514-map-VM4v.qY.SI6ESxu7b7A73g#2",
                  "score": 1,
                  "created_utc": "2026-01-01 20:31:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx3qovc",
          "author": "MoridinB",
          "text": "Have you looked at the PSNR and SSIM metrics? They're normally used for validating models in machine learning and are separate from the loss. Seems your geometric stability is similar in idea to these metrics.",
          "score": 1,
          "created_utc": "2026-01-01 17:00:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3rkl1",
          "author": "no_witty_username",
          "text": "I think this is a great idea if it end up working for most models and image styles. How you would make it style agnostic is the big question as such a feat seems impossible but a good start non the less. I know when i was generating images with my comfy ui workflow i was spending a lot of time with such parameters so i would have loved something like this as a starter signal for my image generations. good luck.",
          "score": 1,
          "created_utc": "2026-01-01 17:05:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8520s",
          "author": "big-boss_97",
          "text": "I prefer the right one. But if it's photo realistic I probably change my mind.",
          "score": 0,
          "created_utc": "2026-01-02 09:05:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pz37q7",
      "title": "My SeedVR2 workflow with mix of blend for original details",
      "subreddit": "comfyui",
      "url": "https://www.reddit.com/gallery/1pz37q7",
      "author": "Capitan01R-",
      "created_utc": "2025-12-30 00:30:22",
      "score": 55,
      "num_comments": 4,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Workflow Included",
      "permalink": "https://reddit.com/r/comfyui/comments/1pz37q7/my_seedvr2_workflow_with_mix_of_blend_for/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwnkjrs",
          "author": "Windy_Hunter",
          "text": "u/Capitan01R-I got \"'NoneType' object is not callable\" error and it stopped at this node.\n\nhttps://preview.redd.it/vmzxgmdry8ag1.png?width=679&format=png&auto=webp&s=bc00178cbd4055e7c772761146a37f6a45419803",
          "score": 2,
          "created_utc": "2025-12-30 01:50:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnkp6y",
              "author": "Capitan01R-",
              "text": "You‚Äôre using the 2.0 nodes, use the older nodes version you can switch it off from the settings or tap on the non and possibly it‚Äôs named false or something. What I meant is the color correction tap, try to change it and it will work as it‚Äôs probably not named ‚Äúnone‚Äù potentially named ‚Äúfalse‚Äù or some other name",
              "score": 4,
              "created_utc": "2025-12-30 01:50:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwza0sr",
          "author": "oeufp",
          "text": "seems your wf is referencing old node names that no longer exist in the current version?\n\n# ‚ùå Old node names (deprecated)\n\nThese are what your old workflow uses:\n\n* `SeedVR2`\n* `SeedVR2ExtraArgs`\n* `SeedVR2BlockSwap`\n\n# ‚úÖ New node names (current)\n\nThese replaced them:\n\n* `SeedVR2 Load Model`\n* `SeedVR2 Video Upscaler`\n* `SeedVR2 Video Decode`\n* `SeedVR2 Video Encode`",
          "score": 1,
          "created_utc": "2025-12-31 21:16:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzec6r",
              "author": "Capitan01R-",
              "text": "Sorry yes here is the link for the [older version](https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/tree/1fa603899f2a5329287d5c51a05e1ae166b3f6f1)  , download it as zip, extract it into your custom nodes folder.  then go into your python_embed folder and use this command with your path of course : python.exe -m pip install -r \"C:\\Users\\youruser\\path-to-your-requirements file\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\seedvr2_videoupscaler\\requirements.txt\"",
              "score": 1,
              "created_utc": "2025-12-31 21:40:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}