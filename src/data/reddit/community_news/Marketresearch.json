{
  "metadata": {
    "last_updated": "2026-02-26 09:09:58",
    "time_filter": "week",
    "subreddit": "Marketresearch",
    "total_items": 2,
    "total_comments": 19,
    "file_size_bytes": 23254
  },
  "items": [
    {
      "id": "1rdw2pn",
      "title": "Techniques for detecting survey fraud",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1rdw2pn/techniques_for_detecting_survey_fraud/",
      "author": "improvedataquality",
      "created_utc": "2026-02-24 23:10:40",
      "score": 7,
      "num_comments": 24,
      "upvote_ratio": 0.82,
      "text": "Over the last couple of weeks, I‚Äôve been talking with both market researchers and academic researchers about how they‚Äôre maintaining data integrity and reducing fraud in online surveys.\n\nAlmost everyone describes some version of a layered approach. Automated bot detection, device fingerprinting, manual review, time based flags, open ended response checks, cross validation of demographics, panel level monitoring, and so on. It‚Äôs rarely just one tool anymore.\n\nWhat I‚Äôve found especially interesting is how different teams define the tipping point. At what stage does a case move from ‚Äúsuspicious‚Äù to ‚Äúremove‚Äù? How many flags are enough? Are some indicators automatic disqualifiers, while others are just soft signals?\n\nFor those working in market or survey research:\n\nWhat does your current fraud detection stack actually look like in practice, and how do you decide when a case crosses the line from suspicious to removable?\n\nI‚Äôd love to hear what‚Äôs working well, what feels overly aggressive, and where you‚Äôre still experimenting.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1rdw2pn/techniques_for_detecting_survey_fraud/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o78jfhw",
          "author": "silver70seven",
          "text": "You want my honest perspective? It‚Äôs all a show. There‚Äôs only so much that can be done to prevent or scrub bad data. But at the end of the day, it‚Äôs all you can do. That PM job is on the line, passed up to the client service, and if the stamp of approval is done to say ‚Äòthe data passed all the checks‚Äô, then the client most likely will buy it, the onus is off the team, they get paid, and live to deal with another project. So many times I have dealt with clients asking for stupid intangible targets and washing data like their lives depends on it, because it does, at least their livelihood. If you think you‚Äôre honestly getting b2b ctos for 10 cpi to from a 200+ org you are delusional",
          "score": 13,
          "created_utc": "2026-02-25 00:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79q7xu",
              "author": "alexisappling",
              "text": "I once ran a segmentation study that mattered a lot. We used a well-regarded panel provider with a reputation for high-quality data. During soft launch, though, the responses were clearly fake.\n\nTo fix it, I embedded multiple attention checks and trap questions. As fieldwork continued, respondents repeatedly failed them. The incidence rate collapsed, the panel provider kept going for me though, though I agreed to a higher cost. \n\nWe eventually closed slightly under target but I was secretly quite proud because I believed we had filtered out the worst of it and got robust data.\n\nWhen analysis began, it became clear we hadn‚Äôt. The output was generic, risk-averse, and strategically useless. Despite all the controls, the data lacked depth and differentiation. It was junk.\n\nSo, what did I learn from this? People taking surveys are nearly all liars. They certainly can‚Äôt remember what they had said seconds earlier. They don‚Äôt engage their true opinions ever.",
              "score": 5,
              "created_utc": "2026-02-25 04:19:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7a2sq1",
                  "author": "improvedataquality",
                  "text": "Did you ever reach back out to the panel provider to let them know your data were of poor quality? If so, did they offer you more participants? Several market researchers have mentioned that when they return to providers with clear evidence of low-quality data, providers are often responsive and will supply replacement participants at no additional cost.",
                  "score": 1,
                  "created_utc": "2026-02-25 05:50:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7a3uta",
              "author": "improvedataquality",
              "text": "Your point about the ‚Äústamp of approval‚Äù is really interesting. I wonder how much of the fraud-detection criteria are actually driven by the client.\n\nIn your experience, do clients typically specify clear standards for what counts as a removable fraudulent response, or is that mostly left to the research team?\n\nI‚Äôve spoken with several market researchers who use very different approaches. Some say that they rely on just 1-2 checks, while others use 5+ tools directly into their surveys. I‚Äôm curious whether that variation reflects client expectations, internal standards, or just individual philosophy about risk.",
              "score": 1,
              "created_utc": "2026-02-25 05:58:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7bijen",
                  "author": "silver70seven",
                  "text": "Agencies know they can‚Äôt deliver fool proof data. Panels know the data is mostly crap.",
                  "score": 1,
                  "created_utc": "2026-02-25 13:06:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o78pd1p",
          "author": "ThePirateBee",
          "text": "In all honesty the number of flags that's \"enough\" is going to change based on the demographic. I can afford to be really strict when I'm talking to genpop about basic cpg. For lower incidence groups, I have to find the balance between data quality and sample size, and it can be a frustrating trade off.",
          "score": 7,
          "created_utc": "2026-02-25 00:46:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a33qt",
              "author": "improvedataquality",
              "text": "Completely understand that. We recently ran a study where we needed a specific demographic that wasn't readily available on the panel. Our approach was to keep the survey open for a few extra days but still ended up with a significantly smaller sample than we had anticipated. ",
              "score": 1,
              "created_utc": "2026-02-25 05:52:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o79byb1",
          "author": "Previous-Garlic4246",
          "text": "The general idea is to consider how often you, as a senior employee in a company, would fill out a survey, especially one that asks for all those demographic details before getting to the main questions??? If you think you‚Äôd do it once a month or maybe once a quarter, then you‚Äôre being pretty fair and thoughtful. Now, picture yourself in a lower ranks, swamped with work and other responsibilities‚Äîhow many surveys would you actually fill out if there was a chance to get a gift card with a decent amount? The same logic applies to the other side of things. It‚Äôs just not realistic to expect the same group of people to keep responding to surveys from all these different survey companies. So, it‚Äôs clear that the data is pretty much manipulated, altered, and dressed up in various ways!!!",
          "score": 2,
          "created_utc": "2026-02-25 02:53:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7b40ws",
          "author": "analoguefuckery",
          "text": "I've worked supply side, people would be shocked if they knew how endemic the problem is and how little you can rely on the data.\n\nEvery so often I will see something in the news that \"X% of people do Y\" and articles about how interesting it is. When it reality the data is probably just fake. ",
          "score": 2,
          "created_utc": "2026-02-25 11:23:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o78ae2z",
          "author": "WhatMeWorry22",
          "text": "There's fraud generated by bots and there's lazy responses with little consideration to the question being asked, two different things. \nYou want to eliminate 100% of the prior (difficult), and 100% of the latter (easier with traditional methods).\n\nI think we will solve the bit problem eventually via human validation but wherever there's money on offer fraud will enter that market with continuing sophistication.",
          "score": 1,
          "created_utc": "2026-02-24 23:24:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7am4zz",
          "author": "coffeeebrain",
          "text": "open ended responses catch more fraud than people expect. templated answers are a dead giveaway.\n\nbut honestly most cleaning problems start at recruitment. bad panel, no amount of flags fixes it. what sources are you working with currently?",
          "score": 1,
          "created_utc": "2026-02-25 08:39:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7dsv3q",
              "author": "improvedataquality",
              "text": "To some extent, yes. However, there are caveats. First, there are still researchers who think that only gibberish responses should be removed as they indicate bots/fraud. Second, fraudsters who generate AI responses to complete surveys are also getting smarter in that they will change a few words here and there to make it sound more human. I track all participant behavior and cannot count the number of times I have seen a response pasted, then changed slightly to make it more human sounding. ",
              "score": 2,
              "created_utc": "2026-02-25 19:40:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7dqw58",
              "author": "improvedataquality",
              "text": "I mostly work with academic panels (Connect, Prolific) and despite them claiming that their samples are of good quality, I have seen sufficient amount of fraud (15-20%). Now that may not be too bad compared to some other market research panels but it's still a substantial amount of lost data.",
              "score": 1,
              "created_utc": "2026-02-25 19:31:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7bxcb6",
          "author": "pnutbutterpirate",
          "text": "For challenging recruitment I sometimes use phone surveys (fielded by a vendor I have worked with in the past), which I assume filters out some of the worst fraud. You at least are getting actual humans responding via a phone call.\n\nAnyone disagree?",
          "score": 1,
          "created_utc": "2026-02-25 14:28:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ds2s4",
              "author": "improvedataquality",
              "text": "When I first read your comment, I thought you meant online surveys on their phones. I agree that surveys over the phone (call) are likely going to result in substantially lower fraud. However, is that really scalable? ",
              "score": 1,
              "created_utc": "2026-02-25 19:36:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7e3eaf",
                  "author": "pnutbutterpirate",
                  "text": "I pay $75-$150 per phone call response to a vendor. Cost depends on all the standard factors.",
                  "score": 1,
                  "created_utc": "2026-02-25 20:29:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7by07f",
          "author": "VyprConsumerResearch",
          "text": "Most teams seem to separate hard fails (impossible geo/device mismatches, known bot signatures, duplicate fingerprints) from soft signals (speeding, straight-lining, weak open ends), then remove only when multiple soft signals cluster together. The tipping point is often less about a fixed rule and more about whether the responses still behave coherently when you sense-check them against known distributions or adjacent questions. The hardest part right now feels like tuning that balance so you protect data quality without systematically filtering out real but ‚Äúmessy‚Äù humans.",
          "score": 1,
          "created_utc": "2026-02-25 14:31:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1re38yh",
      "title": "Cheap survey vendors (<$300 for N of 100)",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1re38yh/cheap_survey_vendors_300_for_n_of_100/",
      "author": "frieswithtrufflemayo",
      "created_utc": "2026-02-25 04:23:06",
      "score": 6,
      "num_comments": 21,
      "upvote_ratio": 0.88,
      "text": "Hi all! I'm trying to conduct a survey N of 100 to gauge public opinion. I'm targeting U.S. women age 18-40. The survey takes just 2 minutes to complete. \n\nIt's for a personal project, so I'm really trying to keep expenses low. The other vendors I'm familiar with (I'm a former consultant) are more expensive by many orders of magnitude. Does anyone have any advice? I really need some quantified gauge of interest before product launch / going to factories. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1re38yh/cheap_survey_vendors_300_for_n_of_100/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o79tit0",
          "author": "jelybely8",
          "text": "Hate to burst your bubble, but at that price the vast majority of your sample will likely be fraudulent in some manner.",
          "score": 16,
          "created_utc": "2026-02-25 04:42:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79uu42",
              "author": "frieswithtrufflemayo",
              "text": "What's a reasonable price for a 2 minute survey? And what would be other methods to gauge consumer sentiment beyond a survey? I'm a former consultant so I'm just going by the methods I'm accustomed to. I've asked friends already and a small sample, but I feel like I really need quantified measures of purchase intent before I feel comfortable going to a manufacturer (minimum order quantity of most factories is \\~300). ",
              "score": 1,
              "created_utc": "2026-02-25 04:51:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7a6psz",
          "author": "Saffa1986",
          "text": "PureSpectrum or CINT.",
          "score": 4,
          "created_utc": "2026-02-25 06:21:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o79s81m",
          "author": "cf858",
          "text": "Just use Survey Monkey, you can buy sample there cheaply.",
          "score": 2,
          "created_utc": "2026-02-25 04:33:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o79sp2c",
              "author": "frieswithtrufflemayo",
              "text": "Thank you - I'll look into Survey Money. I already have the survey programmed in Surveymars, which I really liked (it was super easy to program). I guess I had reprogram it in Survey Money pretty quickly (it was just a 2 minute survey). \n\n  \nThe other vendor I found in my research is Prolific, which would also meet my budget requirements. IDK if you or anybody else has heard of them. I'm targeting 18-40 women and want to get decent representation of current college students. \n\n",
              "score": 1,
              "created_utc": "2026-02-25 04:36:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7a8hr1",
                  "author": "improvedataquality",
                  "text": "I‚Äôm a faculty member and routinely collect data on Prolific. In my experience, they offer good gender representation. In terms of college-student participants, I know they have at least a few that identified themselves as belonging to the higher education industry. I also deploy a custom JavaScript to screen out bots and survey farms.\n\nIf you‚Äôre specifically looking for college students, your best option may be SONA; fraud there is typically low.",
                  "score": 4,
                  "created_utc": "2026-02-25 06:36:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7a3jh8",
          "author": "UptownGirl248",
          "text": "Amazon MTurk is similar quality and lower cost than survey monkey",
          "score": 1,
          "created_utc": "2026-02-25 05:56:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7a3ppl",
              "author": "frieswithtrufflemayo",
              "text": "I'll look into it. Do you think Amazon MTurk will have good representation of female U.S. college students and young adults though? That's my biggest concern ",
              "score": 1,
              "created_utc": "2026-02-25 05:57:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7a662p",
                  "author": "UptownGirl248",
                  "text": "For your price point it‚Äôll have a higher representation of legitimate quantitative responses. If you‚Äôre looking for college students specifically there are a lot of MR programs to partner with on link distribution.",
                  "score": 1,
                  "created_utc": "2026-02-25 06:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7amqg0",
          "author": "coffeeebrain",
          "text": "honestly for something that'll inform a product launch decision, the extra $100 is probably worth it. prolific participants are way more engaged than typical panel respondents and fraud rates are noticeably lower. cheap insurance when you're about to go to factories.\n\nthat said if budget is really the constraint, posting in relevant facebook groups targeting us women in that age range can work for early stage validation. less controlled but free.",
          "score": 1,
          "created_utc": "2026-02-25 08:45:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7aoi8s",
              "author": "frieswithtrufflemayo",
              "text": "I'm also leaning towards Prolific. The pricing is very reasonable, and seems to have good representation of college students and people in their 20s, which is my focus. Thank you!! ",
              "score": 2,
              "created_utc": "2026-02-25 09:02:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ariql",
          "author": "CompiledIO",
          "text": "Check out [Revuloop.com](http://Revuloop.com) for easy survey generation",
          "score": 1,
          "created_utc": "2026-02-25 09:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7atbxk",
          "author": "Jacks_Bond007",
          "text": "How do you make sure it‚Äôs accurate?",
          "score": 1,
          "created_utc": "2026-02-25 09:47:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7bs4v4",
          "author": "2manyLattes",
          "text": "No matter which company you decide to choose, make sure you add in a red herring/QA question to weed out the bots. Fraud is running rampant on every single panel (25-40% fraud respondents depending on the panel).",
          "score": 1,
          "created_utc": "2026-02-25 14:00:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bvqxc",
              "author": "pnutbutterpirate",
              "text": "FWIW, I keep seeing articles saying that trap questions are no longer reliable for bot/fraud detection. Some of those articles are written by people selling fraud prevention systems, so there's that... but in the age of AI I wouldn't be surprised to see bots pass the usual trap questions.",
              "score": 1,
              "created_utc": "2026-02-25 14:19:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7c5o14",
          "author": "pandacataract",
          "text": "Prolific",
          "score": 1,
          "created_utc": "2026-02-25 15:10:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7efvhw",
          "author": "sauldobney",
          "text": "Since the cheap options you're thinking of probably won't be 'rep', have you considered street interviewing? You can do it yourself. Probably two to three days work for a short survey and N=100. The best bit is you can see real reactions and talk to people a bit more to understand whys.",
          "score": 1,
          "created_utc": "2026-02-25 21:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7fogzs",
          "author": "1GrouchyCat",
          "text": "\nYou‚Äôre only surveying 100 people‚Ä¶ and you‚Äôve made it clear this isn‚Äôt rocket science or clinical research‚Ä¶\nWhat‚Äôs the problem?\n\nSet up a table in front of the local supermarket or go to the library and troll for people to interview.\n\nPaying a Survey vendor when this whole thing would probably take you one afternoon is a waste of money in my opinion, but you‚Äôre the consultant üôÑ‚Ä¶.",
          "score": 1,
          "created_utc": "2026-02-26 01:21:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}