{
  "metadata": {
    "last_updated": "2026-01-23 08:49:57",
    "time_filter": "week",
    "subreddit": "Marketresearch",
    "total_items": 7,
    "total_comments": 43,
    "file_size_bytes": 43443
  },
  "items": [
    {
      "id": "1qizubu",
      "title": "Market research data for Southeast Asian countries",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qizubu/market_research_data_for_southeast_asian_countries/",
      "author": "monkeybread5",
      "created_utc": "2026-01-21 14:49:04",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I‚Äôve always found that reports on SEA countries are very limited. \n\nFor industrial markets like paint, lubricants or even cleaning. Any recommendations for what type of data or research companies could be useful? \n\nI‚Äôd want to spend less than USD10k",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qizubu/market_research_data_for_southeast_asian_countries/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o10surv",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-01-22 10:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10w4ml",
              "author": "monkeybread5",
              "text": "From the sample reports, how can I know if the full report is going to be accurate? Any tips? I‚Äôm new to SEA countries :(",
              "score": 1,
              "created_utc": "2026-01-22 10:38:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qergjs",
      "title": "Open ended vs structured questions which do you actually rely on early on?",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qergjs/open_ended_vs_structured_questions_which_do_you/",
      "author": "Sufficient_Usual_857",
      "created_utc": "2026-01-16 20:37:30",
      "score": 7,
      "num_comments": 23,
      "upvote_ratio": 0.9,
      "text": "When you‚Äôre at the early research stage, how do you usually approach questions?\n\nI like open ended ones because people sometimes surprise you with things you didn‚Äôt even think to ask. But they also get messy fast and are harder to analyze.\n\nStructured questions are cleaner and easier to compare, but I sometimes worry they box people in too much.\n\nDo you start broad and then narrow down? Or do you mix both from the beginning?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qergjs/open_ended_vs_structured_questions_which_do_you/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "nzzmyy3",
          "author": "Narrow-Hall8070",
          "text": "What‚Äôs the research objective",
          "score": 11,
          "created_utc": "2026-01-16 20:46:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzn83k",
          "author": "Saffa1986",
          "text": "I try to use both. \n\n\nSome questions are only open, some are only promoted, but when it‚Äôs important I use both side by side. \n\n\nThe open gives good verbatim in their own words, but you can‚Äôt guarantee people will talk precisely about what you want. So the prompted / structured gives you a firm grip on the precise percentage.",
          "score": 6,
          "created_utc": "2026-01-16 20:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzznf5r",
          "author": "The_Scrabbler",
          "text": "This question came up earlier. If you‚Äôre doing exploratory research then you should be interviewing people with open ended questions, you can structure the answers in analysis. \n\nIf you‚Äôre trying to measure something you already know, then code frames in surveys.",
          "score": 6,
          "created_utc": "2026-01-16 20:48:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzwigk",
          "author": "Noodiler",
          "text": "Close ended all the way.  I actively try to avoid open-ended.  I usually have a max of 2 OEs. And usually don‚Äôt report them unless the insights don‚Äôt make sense",
          "score": 5,
          "created_utc": "2026-01-16 21:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04h3ck",
              "author": "ilovefunc",
              "text": "Why do you avoid open ended?",
              "score": 1,
              "created_utc": "2026-01-17 16:01:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzqh82",
          "author": "coffeeebrain",
          "text": "i almost always start open-ended early on because yeah, people surprise you. you think you know what the problem is and then someone says something totally sideways that reframes everything.\n\nthe mess is the point at that stage honestly. you're exploring, not measuring.\n\nonce i have a sense of what matters, then i get more structured. like if 8 out of 10 people mention pricing as an issue, i'll ask more specific pricing questions in the next round.\n\nmixing both from the beginning can work but it's tricky. open-ended takes longer so if you have limited time per participant, structured questions eat into exploration time.",
          "score": 3,
          "created_utc": "2026-01-16 21:02:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01c07b",
          "author": "jelybely8",
          "text": "Guessing this is a bot of some sort?  They're just reposting generic questions that were already asked a week ago.",
          "score": 2,
          "created_utc": "2026-01-17 02:18:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04b2v2",
              "author": "LeatherEconomics8604",
              "text": "Lol yes we are in their experiment - researching the researchers is smart",
              "score": 1,
              "created_utc": "2026-01-17 15:33:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04t0tr",
                  "author": "jelybely8",
                  "text": "This is just a poorly implemented AI agent trying to codify industry info.",
                  "score": 1,
                  "created_utc": "2026-01-17 16:57:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0ysl0r",
                  "author": "Charming_Code_3625",
                  "text": "Would love to participate in a focus group springyspring@icloud.com",
                  "score": 1,
                  "created_utc": "2026-01-22 01:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o01rpsf",
          "author": "Proper-Independent49",
          "text": "Closed end with other, specify option is the way",
          "score": 2,
          "created_utc": "2026-01-17 03:59:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01s7mz",
          "author": "ilovefunc",
          "text": "It really depends on how many people you want to survey and how accessible they are. For example, if it's few people (1-30), and you can follow up with them via messaging / calls, then keep things mostly open ended.\n\nIn general, the more the people you survey, or the lesser accessible they are, keep things less open ended.\n\n  \nAlso, what I do is to create one version of the survey and post it to a small set of my user pool, and see what I get back, and then refine the survey (change question wording, ordering, but NOT semantics), and post again to a different set and so on. \n\nWhat tool are you using for conducting the survey? Are you open to trying a tool where an AI conducts the survey?",
          "score": 2,
          "created_utc": "2026-01-17 04:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04h0n6",
              "author": "ilovefunc",
              "text": "For those interested in exploring an Ai agent based survey, checkout a tool I made: https://deepinterview.trythis.app",
              "score": 1,
              "created_utc": "2026-01-17 16:01:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03evis",
          "author": "Odd_Dog6616",
          "text": "Two clarifying questions:\n1. Are you talking about interviews/qual work or surveys/quant work, or is the question which to start with between those two? Asking because you could have ‚Äúopen-ended‚Äù and ‚Äústructured questions‚Äù in both qual and quant, so that influences the response here.\n\n2. When you say early on, do you mean early in the research process for a given topic, or early within any single interview? It sounds to me like you‚Äôre asking if people recommend starting with more open-ended questions early in the research PROCESS to help uncover topics and vocabulary that should be included in the overall study, but that same principle could apply to a single interview if you‚Äôre talking about Qual specifically here",
          "score": 2,
          "created_utc": "2026-01-17 12:25:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04auds",
          "author": "LeatherEconomics8604",
          "text": "I ask what I want to know  - for example: would anyone reading this thread be open to paying $65 for a 2 hour workshop that will teach you how to overcome ANY challenge you are facing in 3-weeks? \n\nIf not, what objections do you have?\n\nWhat questions do you need answered to make it feel worth it? \n\nWhat outcome would you be looking for at that price point?",
          "score": 2,
          "created_utc": "2026-01-17 15:32:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06v9jl",
          "author": "sauldobney",
          "text": "It depends on if you're exploring or measuring. The more exploratory, the more you use open questions to uncover thoughts and ideas. The more your are measuring (how many), correlating and testing you need structured questions. Open ends aren't great for measurement and remember the importance of the sample and bias and what population you are trying to represent in the research",
          "score": 2,
          "created_utc": "2026-01-17 22:59:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fops3",
          "author": "supriya_l89",
          "text": "My typical approach is to begin with a wide scope and then gradually focus on the specific. The use of broad questions at the beginning brings to light the unexpected and the vocabulary that might not be predicted. After the initial phase when the key aspects or patterns are defined, well-structured questions are then employed to confirm and estimate the significance of those insights. The combination of both methods is also effective, however, the planned arrangement of the methods prevents the issues from becoming complicated too quickly.",
          "score": 2,
          "created_utc": "2026-01-19 06:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jd0fc",
          "author": "BDizzleNizzle",
          "text": "LLMs make open-ended data much easier to work with. Pay for a basic subscription to ChatGPT or Gemini (NotebookLM) and just copy paste and start interacting.",
          "score": 2,
          "created_utc": "2026-01-19 20:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tzvwk",
          "author": "Top_Opinion9522",
          "text": "Depends - qualitative v quantitative. Horses for courses",
          "score": 2,
          "created_utc": "2026-01-21 10:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ujt86",
          "author": "_os2_",
          "text": "I have observed a love/hate relationship with open text questions. Researchers hate the cumbersome data analysis problems they create, while they love the depth of insights they could get on e.g., why things are like they are. Respondents love the ability to give their views, but hate the feeling that their long answers might be just ignored in the end.\n\nSo often there are just 1 to 3 open ended questions tacked to the end of the survey, instead of them being really utilized to dig deeper and get insights.\n\nI think AI might tilt the balance towards more open text questions. First, with AI you can soon create more intuitive interview-type open ended questions with smart follow-up. Second, advanced analysis tools using AI to surface themes help analyse qualitative data with the same rigour as quantitative data.\n\nI wrote a full blog post on [how to analyse open text responses at scale](https://skimle.com/blog/how-to-analyse-open-text-responses-at-scale-without-loosing-your-mind) (without losing your mind), hopefully interesting read!",
          "score": 2,
          "created_utc": "2026-01-21 13:06:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fzuu7",
          "author": "echochisel_memlove",
          "text": "I usually start with open-ended questions just to see what directions come up. After the first interviews, I move to more structured questions so I can actually compare answers. That mix feels the safest to me.",
          "score": 1,
          "created_utc": "2026-01-19 08:21:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhwqf0",
      "title": "AI market research tools in 2026 ??",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qhwqf0/ai_market_research_tools_in_2026/",
      "author": "maheshpatel034",
      "created_utc": "2026-01-20 09:37:32",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "Been seeing a lot of posts lately about ‚ÄúAI market research tools‚Äù and rankings and all that, including the recent analysis here. I‚Äôve been playing with a bunch of these tools over the past year, mostly because I do a lot of desk research and anything that saves time is hard to ignore.\n\nHonestly though, my experience has been pretty mixed.\n\nMost of these tools are decent at skimming large amounts of public info and giving you a quick sense of what‚Äôs going on in a market. That part actually helps, especially when you‚Äôre dropped into a new industry and need to get oriented fast. But after that first pass, you still hit the same old problems ‚Äî shaky numbers, missing context, unclear sources.\n\nI think the hype makes it sound like AI is replacing research judgment, but in reality it‚Äôs just moving the grunt work around. You still have to decide what‚Äôs credible, what‚Äôs noise, and what actually matters for the question you‚Äôre trying to answer. Otherwise you end up with insights that sound confident but don‚Äôt really hold up.\n\nI‚Äôve also noticed that chasing ‚Äúall-in-one AI research platforms‚Äù hasn‚Äôt been worth it for me. The tools I actually keep using are the ones that help early on ‚Äî quick scans, rough market framing, directional growth narratives ‚Äî and then I go back to old-school secondary research to validate things properly.\n\nFor example, I‚Äôve been using [statshub.ai](http://statshub.ai) occasionally just to get an initial market snapshot or sanity-check how a category is being framed. I don‚Äôt treat it as a source of truth, more like a starting point before digging deeper.\n\nNet takeaway for me so far: AI definitely makes desk research faster, but it doesn‚Äôt make it smarter. If anything, it forces you to be more careful because it‚Äôs very good at being confidently vague.\n\nCurious how others here are actually using these tools once the novelty wears off. Are you trusting them with numbers yet, or still keeping them at arm‚Äôs length?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qhwqf0/ai_market_research_tools_in_2026/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o0na6mk",
          "author": "_os2_",
          "text": "That seems to be the pattern with AI tools these days. The big ‚Äùagentic AI end-to-end hype tools‚Äù fail while targeted AI harnesses with real well-thought logic for a single task or tasks actually work :)",
          "score": 3,
          "created_utc": "2026-01-20 10:53:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nxtd9",
              "author": "catwithbillstopay",
              "text": "That's really interesting. Could you elaborate more? I'd love to see an example!",
              "score": 1,
              "created_utc": "2026-01-20 13:40:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n2znb",
          "author": "The_Scrabbler",
          "text": "100% agree. It‚Äôs changed my responsibilities from producing the output, to checking the output. Same amount of time and effort. \n\nI like ones that help non-researchers build surveys and discussion guides more quickly, and help them make sense of other parts of the process - but they still need expert guidance. \n\nIt seems most impactful at speeding up VOC and system analysis.",
          "score": 3,
          "created_utc": "2026-01-20 09:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n3295",
          "author": "Legitimate-Net6717",
          "text": "I‚Äôve been in the same boat‚ÄîAI tools are great for quick overviews or getting the lay of the land, but I never trust the numbers straight out of them. I treat it as a starting point, then double-check with traditional sources. Saves time, but you still need the human judgment to make it actionable.",
          "score": 3,
          "created_utc": "2026-01-20 09:48:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qegda9",
      "title": "Has anyone used Listen Labs before? I can't find information about their pricing",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qegda9/has_anyone_used_listen_labs_before_i_cant_find/",
      "author": "catwithbillstopay",
      "created_utc": "2026-01-16 13:46:44",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I'm trying to understand pricing models in the interview/research space but can't find anything other than how much they've raised and some other key \"investor\" figures. There's a rough video of how the program works but I'd like to dig a little deeper.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qegda9/has_anyone_used_listen_labs_before_i_cant_find/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "nzy5kul",
          "author": "AforAI",
          "text": "Mostly research projects are priced based on project scope. So if you just need info, platforms are unlikely to show you numbers.   \nIf you want service, you can also check out outset, biobrain, knit.. these all do qual research.. which are your interviews.",
          "score": 3,
          "created_utc": "2026-01-16 16:45:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nym6c",
              "author": "catwithbillstopay",
              "text": "Thank you for this! I really found seeing your suggestion of alternatives very helpful!",
              "score": 1,
              "created_utc": "2026-01-20 13:45:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qeu4on",
      "title": "How do you avoid biased samples in online surveys? It feels really easy to accidentally survey the wrong people.",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qeu4on/how_do_you_avoid_biased_samples_in_online_surveys/",
      "author": "Sufficient_Usual_857",
      "created_utc": "2026-01-16 22:21:42",
      "score": 5,
      "num_comments": 20,
      "upvote_ratio": 0.86,
      "text": "You share a survey, get responses quickly, and only later realize they‚Äôre all from the same type of user or channel.\n\nWhat do you actually do to reduce bias?\nDifferent distribution channels? Screening questions? Weighting responses afterward?\n\nWould love to hear what‚Äôs worked (or failed) for you.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qeu4on/how_do_you_avoid_biased_samples_in_online_surveys/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o00823a",
          "author": "The_Scrabbler",
          "text": "Quality screener section, quotas of age and gender and location, trap questions",
          "score": 11,
          "created_utc": "2026-01-16 22:26:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o008f6d",
              "author": "Hillbilly555",
              "text": "Paying for responses from a panel as well helps.... Vs putting a survey up on Reddit. We all know Redditors are not 'normal' üòâ",
              "score": 14,
              "created_utc": "2026-01-16 22:28:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o008hsr",
              "author": "Belloz22",
              "text": "Basically then. \n\nAlso, checking your data afterwards - I also report bad respondents to the panel provider and get them replaced.",
              "score": 7,
              "created_utc": "2026-01-16 22:29:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o06wcx8",
          "author": "sauldobney",
          "text": "Slow down the sample. Firstly to ensure you have sensible time-of-day coverage - you wouldn't expect working people to reply during working hours. Secondly to avoid the fraudsters who will jump in for anything new to get their points. Thirdly, so you can do proper quota control and data quality monitoring to catch issues early. \n\nOnce you have the sample, weighting is too late - it's better to control responses in field. You probably don't need responses that quickly, and definitely not if they are misleading or fake. Give yourself some time.",
          "score": 6,
          "created_utc": "2026-01-17 23:04:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a1ync",
              "author": "silver70seven",
              "text": "To top this off, when working with a panel provider, focus first (after a soft launch to ensure all is working properly) on the obvious hard demo cells (elder males, teens, high income, tough regions). Then once quota is hit within those groups as desired, fill the rest and it should be quick and easy.",
              "score": 3,
              "created_utc": "2026-01-18 12:12:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0goi7w",
                  "author": "Odd_Dog6616",
                  "text": "Additionally, depending on which panel aggregator you‚Äôre using (Cint, RepData, Purespectrum, etc) you can likely set a target mix of underlying suppliers, or at least groups of suppliers. This is a little more complex but worthwhile if you‚Äôre finding that respondents in a study are very similar to each other in ways that don‚Äôt represent reality. \n\nEvery panel recruits and incentivizes respondents a certain way. Those methods have a strong selection effect on who is in the panel. This isn‚Äôt wrong, it‚Äôs just how it works. Using a panel aggregator allows you to access lots of different underlying panels (suppliers) which allows you to reach a more psychographically (and demographically) diverse respondent pool. In reality, the panel world is dominated by like 6 very large suppliers that account for a large portion of sample on any given aggregator, but that‚Äôs 5 more than letting it fill overnight with a single supplier.\n\nAs others have noted, this approach necessarily means more time to fill your sample. This makes a normal survey take at least a week to fill if you‚Äôre balancing across demographics and enforcing diversity of suppliers.\n\nAlso, if your respondents look VERY similar (and you‚Äôve paid something to them), they‚Äôre probably just fraud from a survey farm. If the sample filled very quickly, this is almost certainly the case.",
                  "score": 1,
                  "created_utc": "2026-01-19 12:04:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0aushs",
          "author": "DataBeeGood",
          "text": "There‚Äôs a lot to it. I suggest you do some reading on ‚Äúsampling strategy‚Äù. You can also find free articles about sampling and avoiding bias on the websites for AAPOR, Pew Research, and Quirks marketing research review.",
          "score": 3,
          "created_utc": "2026-01-18 15:12:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o011o4x",
          "author": "ThePirateBee",
          "text": "Increase screening requirements and build in demo quotas, nested if they're really important. Soft launch, pausing after 10% to check data, then adjust if necessary. Pace completes to ensure representation from people available on different days/different times a day. Regularly inspect responses during sampling and remove/replace respondents who fail trap checks and put gibberish into open ends.\n\nIf after all that you still realize you messed something up, then yes, you can weight the data. But that still won't save you if the responses weren't collected well.",
          "score": 2,
          "created_utc": "2026-01-17 01:12:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n0d2s",
          "author": "VyprConsumerResearch",
          "text": "A common way to reduce bias is to control the sample *before* the survey launches rather than trying to fix it afterward. That usually means recruiting from a verified, managed panel with clear quotas across key demographics, plus ongoing quality checks to avoid duplicate, rushed, or low-intent responses.\n\nCompared to open links shared across a single channel, controlled communities tend to produce more representative data and higher-quality answers, especially when paired with engagement-focused formats instead of long, repetitive surveys.",
          "score": 2,
          "created_utc": "2026-01-20 09:22:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nfmc7",
          "author": "coffeeebrain",
          "text": "Screening questions help but they're not foolproof. People lie to qualify for incentives.\n\nWhat actually works better is being really specific about where you distribute. Don't just blast it everywhere and hope. If you need B2B users, go to industry Slack groups or LinkedIn. If you need consumers, maybe Reddit or Facebook groups where your actual users hang out.\n\nAlso sample size matters less than sample quality. I'd rather have 100 responses from the right people than 1000 from randoms who clicked through from some survey panel.\n\nThe weighting thing only works if you know what \"right\" looks like upfront. Most people don't actually know their target distribution well enough to weight accurately.\n\nHonestly though, surveys have limitations. If your question needs that much precision about who's answering, you might need interviews instead of a survey. Slower but way less sampling noise.",
          "score": 2,
          "created_utc": "2026-01-20 11:39:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04tdz3",
          "author": "dark-666777",
          "text": "quotas of age and gender and location",
          "score": 1,
          "created_utc": "2026-01-17 16:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06f47v",
          "author": "gailgolightly",
          "text": "Weighting the sample and using a good provider",
          "score": 1,
          "created_utc": "2026-01-17 21:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fzse0",
          "author": "echochisel_memlove",
          "text": "What helped me a lot was not relying on a single channel. If all responses come from one newsletter or group, bias is almost guaranteed. Fewer responses from different sources are usually better.",
          "score": 1,
          "created_utc": "2026-01-19 08:20:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h3jfr",
          "author": "Sophia-8707",
          "text": "Yeah this happens a lot. Easiest fixes are upfront: screen for who you actually need, use multiple channels (never rely on a single community/link), and cap how many completes come from any one source. If it‚Äôs still skewed, you can weight after, but weighting can‚Äôt fix a bad sample, it just makes it look cleaner on a chart.",
          "score": 1,
          "created_utc": "2026-01-19 13:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o8twr",
          "author": "Comfortable-Win-2762",
          "text": "You‚Äôre right, it‚Äôs easy to get biased samples online. To reduce this, researchers clearly define the target audience, use screening questions, diversify recruitment sources, apply quotas, and remove speeders or inconsistent responses. Proper sampling and quality checks help ensure the data reflects real-world behavior.",
          "score": 1,
          "created_utc": "2026-01-20 14:39:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeg3qk",
      "title": "Have you ever paid for market research and still felt stuck afterward?",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qeg3qk/have_you_ever_paid_for_market_research_and_still/",
      "author": "OkNeighborhood4811",
      "created_utc": "2026-01-16 13:35:27",
      "score": 4,
      "num_comments": 16,
      "upvote_ratio": 0.84,
      "text": "I‚Äôve seen cases where companies invested serious money in research, got a polished report, and then‚Ä¶ nothing really changed.\n\nNo clearer prioritization, no stronger conviction, just ‚Äúinteresting insights.‚Äù\n\nCurious how common this is, and what people felt was missing.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qeg3qk/have_you_ever_paid_for_market_research_and_still/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "nzx2lzf",
          "author": "lsuillini",
          "text": "As a researcher, I've seen this happen. Usually it's because someone in leadership believes their idea is better than what their users/customers told us.",
          "score": 19,
          "created_utc": "2026-01-16 13:41:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzdqqd",
              "author": "alexisappling",
              "text": "As a researcher I‚Äôve also seen this happen. Usually it‚Äôs because the market research agency didn‚Äôt say ‚Äúwe can‚Äôt research that, it‚Äôs impossible‚Äù, and instead went ‚Äúsure, money, sure!‚Äù  \n\nWay too often senior agency leaders are promising the earth when they don‚Äôt understand if it can be delivered. And clients end up with a disappointing ride which results in them no longer believing in research.",
              "score": 10,
              "created_utc": "2026-01-16 20:02:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxv0mu",
              "author": "jelybely8",
              "text": "100% this.",
              "score": 5,
              "created_utc": "2026-01-16 15:58:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzxnbtp",
          "author": "cf858",
          "text": "Often happens when you simply ask the wrong questions. You shouldn't be investing a lot in research if you haven't already done a lot of work to figure out what you need to know.",
          "score": 6,
          "created_utc": "2026-01-16 15:24:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxx8x8",
          "author": "toragirl",
          "text": "Insights teams (agency and within an org) need to have a clear plan for research - how does the consumer insights feed into marcom or product team planning? Have the stakeholders received the information in a format that they can create action from? \n\n  \nOR...\n\n  \nWas the research confirmatory, and didn't move the needle on changing the planning?",
          "score": 5,
          "created_utc": "2026-01-16 16:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy3yy6",
          "author": "sandysadie",
          "text": "It is the clients job to ensure the supplier is delivering actionable insights",
          "score": 4,
          "created_utc": "2026-01-16 16:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzn3q6",
          "author": "coffeeebrain",
          "text": "this happens constantly, honestly. i've been on both sides - doing research that gets ignored and also being the consultant delivering reports that probably collected dust.\n\nthe missing piece is usually that research happened too late. like the exec team already decided what they want to build, they just needed research to validate it. so when research says something else, they ignore it or cherry-pick what fits their narrative.\n\nother times it's just that the research answered the wrong question. client asks \"should we build feature x?\" but the real question was \"what problem are customers actually trying to solve?\" totally different.\n\nalso sometimes researchers (myself included) deliver too much. 40-slide deck with every finding instead of \"here are the 3 things you need to know and what to do about them.\"",
          "score": 4,
          "created_utc": "2026-01-16 20:46:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00zbjy",
          "author": "silver70seven",
          "text": "I agree with all the above but also I feel usually ego exists at the top and no action is invested in the ideas brought forth. Sometimes that can be if the scope is too broad to give good clarity on next steps, or if the the research report is somewhat vague.\n\nAlso, respect that there is always questionable data and that it‚Äôs a gamble. If it‚Äôs a decision to be made that depends on data and your gut says it‚Äôs untrustworthy, it‚Äôs sensible to withhold action and maybe do another pass at the question.",
          "score": 3,
          "created_utc": "2026-01-17 00:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0prz20",
          "author": "Previous-Garlic4246",
          "text": "Market research can often be a time-consuming and tedious task. Without regular checks and reviews, researchers may stray off course and lose alignment with business goals. Similar to a GPT or LLM model, researchers can also experience hallucinations, making it crucial for requesters to stay involved and consistently monitor the progress with researchers.",
          "score": 3,
          "created_utc": "2026-01-20 18:56:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o08ssor",
          "author": "kubrador",
          "text": "honestly this is like 80% of market research. you get a 200-page deck that confirms what the ceo already believed, costs more than a junior dev's salary, and then sits in a sharepoint folder.\n\nthe real problem is most companies do research to validate decisions they've already made, not to actually make decisions. it's security theater for the boardroom.",
          "score": 2,
          "created_utc": "2026-01-18 05:33:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04jm7z",
          "author": "OkNeighborhood4811",
          "text": "What‚Äôs interesting to me is how many of these issues show up before data collection even starts , wrong questions, late timing, unclear decision ownership. It makes me think the real leverage isn‚Äôt ‚Äúbetter research,‚Äù but better decision framing upstream.",
          "score": 1,
          "created_utc": "2026-01-17 16:13:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0gpr49",
              "author": "Odd_Dog6616",
              "text": "I think the broader theme is quality of partnership and partner. Market Research work is really hard (well, good market research work is hard). It takes a level of talent and awareness and creativity and methodological expertise that is rare to find in any one person or team. On top of that, the best researcher in the world can‚Äôt make a report or finding impactful to an org if they don‚Äôt engage their client-side stakeholders (and get good engagement back) to understand the organizational context and work with the end in mind throughout the whole project. As you mentioned in this comment, a world-class partner will ask you why you think the work would and would not be accepted and used by the org in the first one or two calls of the project. It takes ALL of those skills to consistently deliver projects that impact the org, plus being really checked-in and having the bandwidth to do great work.\n\nThe good news about our space is that this work is really needed by tons of organizations that need to understand their customer and audience. The bad news is the breadth and depth of skills it takes to do great work is very, very hard to train and develop. The result is tons of research that‚Äôs just okay. It technically answers the question but doesn‚Äôt inspire action or make a lasting impact.",
              "score": 3,
              "created_utc": "2026-01-19 12:14:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0h20ho",
                  "author": "OkNeighborhood4811",
                  "text": "I really agree with this framing. The partnership piece feels especially underrated   \n even great methodology falls flat if there‚Äôs no shared ownership of the decision and no alignment on how the work will actually be used. The part about asking why findings might or might not land early on really resonates. That seems like where a lot of projects quietly succeed or fail.",
                  "score": 1,
                  "created_utc": "2026-01-19 13:37:10",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi1gp5",
      "title": "What are some of the worse AI tools in the MR space you've seen?",
      "subreddit": "Marketresearch",
      "url": "https://www.reddit.com/r/Marketresearch/comments/1qi1gp5/what_are_some_of_the_worse_ai_tools_in_the_mr/",
      "author": "catwithbillstopay",
      "created_utc": "2026-01-20 13:44:40",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Hey folks--I'm on the tech side building survey analytics suites--mainly based on what I recall frustrated me back in grad school (from a sociology side). We're trying to improve certain design pinchpoints, but I wanted to know what to avoid. For me personally, I really hated coding in R and Python and the whole chain of creating, uploading, and cleaning really frustrated me. I doubt that there's a lot that can actually be done (especially when doing solid, in-depth work), but wanted to know what the worse tools out there were. Trying to show the engineers that spamming features is not the way forward sometimes.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/Marketresearch/comments/1qi1gp5/what_are_some_of_the_worse_ai_tools_in_the_mr/",
      "domain": "self.Marketresearch",
      "is_self": true,
      "comments": [
        {
          "id": "o0qxlj7",
          "author": "DataBeeGood",
          "text": "Actually, Alchemer is quite good. It‚Äôs got all the question types that  Qualtrics has. And far less expensive. I‚Äôm not sure they‚Äôve built in that much in AI yet though.",
          "score": 1,
          "created_utc": "2026-01-20 22:09:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o01js",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-20 13:52:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0suvxf",
              "author": "alexisappling",
              "text": "Alchemer is far more powerful than Google Forms especially when you unlock it with JavaScript. That flexibility does require more technical knowledge, but you get an amazing level customisation for a very low price compared to Qualtrics etc. \n\nHowever, this was about AI, so not really on topic!",
              "score": 2,
              "created_utc": "2026-01-21 04:41:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}