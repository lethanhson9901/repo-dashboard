{
  "metadata": {
    "last_updated": "2026-01-31 02:49:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 119,
    "file_size_bytes": 148418
  },
  "items": [
    {
      "id": "1qlhj62",
      "title": "A few of the MCPs I use on a daily basis",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qlhj62/a_few_of_the_mcps_i_use_on_a_daily_basis/",
      "author": "Eyoba_19",
      "created_utc": "2026-01-24 08:20:27",
      "score": 186,
      "num_comments": 58,
      "upvote_ratio": 0.98,
      "text": "1. **Context7**: I think this might be the most used MCP in the ecosystem, like this is how I was introduced to MCPs in general. Having to deal with codex's and claude's outdated knowledge-base was so painful. \n\n2. **Playwright**: Especially when doing frontend work, having to copy paste a screenshot of what the pages looked like made using AI for it not worth it at all.\n\n3. **Server-memory**: Helps with keeping memory across contexts and sessions, it's a knowledge graphs that stores past contexts in a `jsonl` file and refers from it.\n\n4. **Duck Duck Go Search**: DDG for the win here, honestly, I could just ask codex/claude to look up how a specific thing is made or anything on the web, was such a life-saver than having to copy paste search results to the context window every time\n\n5. **Linear**: I use linear for managing my tasks and progress, just laying out the tasks out over there, asking the AI to spec/plan out the task and only have it do it after has become an integral part of my daily work. Had to build my own MCP though, the default one wasn't good enough for the things I needed.\n\n6. **Filesystem**: This one's a bit controversial, depends on how much you trust the AI honestly to give it enough permissions to act on your FS, you want to guardrail it real good, don't want to wake up to losing all your data because the AI decided to `rm -rf ~`. But pretty cool when it comes to working with cli tools\n\n\nI only recently heard that Figma had an MCP, so excited to try it out! Any other I should try?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qlhj62/a_few_of_the_mcps_i_use_on_a_daily_basis/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o1eh9nb",
          "author": "wokkieman",
          "text": "Curious, how do you use context7 practically?\n\nEvery time you start a coding session? Anything you have a bug? Any specific prompt or instructions you can share?\n\nNote: I use it, but probably not in optimal way",
          "score": 6,
          "created_utc": "2026-01-24 09:55:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1eqo3h",
              "author": "Maasu",
              "text": "Here's my hot take in context7. Use it for everything. \n\nThe models training data is not necessarily reliable. My view is the data it's been trained on is useful to give it generalisation and abilities from this, not necessarily to use that data in it's output in my own work.\n\nHaving examples of what you want and documentation in the context window will always result in better outputs. \n\nI use context7 for external libraries, I also have my own memory mcp that I use for storing my own preferences and patterns, combining the two I have a simple context gather command that I explain the work i am going to do and then sub agents are launches to retrieve the necessary from context7, my knowledge base and code, then I go into plan mode with the big model and we work from there.\n\nHere's my plugin that i use to achieve this in Claude code https://github.com/ScottRBK/context-hub-plugin\n\nAnd here's the memory mcp https://github.com/ScottRBK/forgetful if you want to take a look.",
              "score": 4,
              "created_utc": "2026-01-24 11:20:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1gx5ho",
                  "author": "808mona",
                  "text": "Context7 is a fucking superpower!",
                  "score": 2,
                  "created_utc": "2026-01-24 18:26:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1en7yv",
              "author": "Eyoba_19",
              "text": "I just instruct it to use context7 whenever it needs to refer how to use specific frameworks, apis, functions in AGENTS.md. I saw that I was using it all the time, so I placed it in \\~/.codex/AGENTS.md so that it gets loaded on every session basically.\n\nI also do that for DDG search. Make sure to be very explicit with your instructions there, can help you out if you have problems, but putting it in either your project or root [AGENTS.md](http://AGENTS.md) should suffice",
              "score": 2,
              "created_utc": "2026-01-24 10:49:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1eo60g",
                  "author": "wokkieman",
                  "text": "Thanks!\n\nHave you considered Brave search and/or Tavily search instead of DDG? Personally using Brave, but wondering if it's considered the standard",
                  "score": 1,
                  "created_utc": "2026-01-24 10:58:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1elvrc",
              "author": "sjoti",
              "text": "Not OP, but typically you point to it when needed. Common cases are when you're working with some niche library that the model doesn't really know, or one that's too new for it to be (well) respresented in the training data of the model. Also it generally works if you notice the model struggling. You just say \"look up the docs using context7\" and off it goes.",
              "score": 1,
              "created_utc": "2026-01-24 10:37:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1f0gix",
              "author": "dvcklake_wizard",
              "text": "I refer to it's usage on the Rules and on the first chat message i prompt it to read the rules + think. Works like a charm and i've included subagents usage there too. A good detail is to make it clear that it should never rely on training data for documentation of apis, libs and so on\n\nUsing a subagent specialized in documentation retrieval with a good output format will be even better than drowning the main agent on tool calls",
              "score": 1,
              "created_utc": "2026-01-24 12:40:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1hskgd",
          "author": "richardbaxter",
          "text": "Gemini MCP¬†https://github.com/houtini-ai/gemini-mcp (my¬†version with search grounding toggle) and Desktop Commander üëå",
          "score": 3,
          "created_utc": "2026-01-24 20:47:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1kdddr",
          "author": "JTwoXX",
          "text": "I gave up on MCP‚Äôs and converted most of them into CLI commands; except for NotebookLM MCP. \n\nMost powerful tool for agents to use hands down.",
          "score": 2,
          "created_utc": "2026-01-25 05:03:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kmjeo",
              "author": "Eyoba_19",
              "text": "Why? I love MCPs, they feel like the hands AI was not born with :). But would love to know your experience, and what kind of CLI commands did you replace them with?",
              "score": 1,
              "created_utc": "2026-01-25 06:06:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1unmx6",
          "author": "pbalIII",
          "text": "Putting the Context7 instructions in your global AGENTS.md is the move. Ran the same experiment and it cuts down on the let me guess from training data drift.\\n\\nThe subagent pattern u/Maasu mentioned is worth trying if you haven't. Spawning a dedicated doc-retrieval agent keeps your main context leaner and avoids the tool-call noise mid-session. Works especially well with linear workflows where you're bouncing between specs and code.\\n\\nOn the Filesystem MCP... I keep it scoped to project dirs only. Full home access is asking for trouble, even with guardrails.",
          "score": 2,
          "created_utc": "2026-01-26 17:10:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1eajid",
          "author": "Low-Title-2148",
          "text": "What were you missing in the default Linear MCP?",
          "score": 1,
          "created_utc": "2026-01-24 08:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1eb5ry",
              "author": "Eyoba_19",
              "text": "It's quite a thin crud layer under linear, I wanted to parse and match the incoming data with my own structs so that I can invoke specific commands (like worktree, and specific codex skills)",
              "score": 1,
              "created_utc": "2026-01-24 08:58:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ekv6n",
          "author": "memetican",
          "text": "It's platform-specific, but my site runs on Webflow and madly enjoy Webflow's MCP.  Blog writing, building and designing new sections of the site, data migrations... it rocks.",
          "score": 1,
          "created_utc": "2026-01-24 10:28:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1enctw",
              "author": "Eyoba_19",
              "text": "Ooh, definitely handy for when you want to put out a landing page real quick, thanks for the pointer, I'll update the post with suggested MCPs in the comments soon so that everyone can add them to their reservoir",
              "score": 1,
              "created_utc": "2026-01-24 10:50:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1f2y2i",
          "author": "desexmachina",
          "text": "I have too many MCPs, I need an agent router that will select the MCP for the task.",
          "score": 1,
          "created_utc": "2026-01-24 12:58:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f3uae",
              "author": "Eyoba_19",
              "text": "You can use Agents.md for that. Explicitly instruct it what to do on specific tasks or keywords and it should work. It works surprisingly well for me, would love to know your experience once you‚Äôve tried it.",
              "score": 2,
              "created_utc": "2026-01-24 13:04:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1f80vx",
                  "author": "desexmachina",
                  "text": "Hmm, may fiddle with that. I‚Äôd like to have a dynamic file that has a local LLM do some inference to figure out the mix of MCP.",
                  "score": 1,
                  "created_utc": "2026-01-24 13:31:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fbkt6",
                  "author": "SalvatoreSallyJenko",
                  "text": "I‚Äôd love some ressources on that, do you know where I should look ?",
                  "score": 1,
                  "created_utc": "2026-01-24 13:52:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2h3q1g",
              "author": "iamkevincali",
              "text": "MCPHub works quite well for routing",
              "score": 1,
              "created_utc": "2026-01-29 20:19:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1g5c62",
          "author": "thegroovylitre",
          "text": "I noticed that context7 was great once I had the libraries defined but not great for planning which technologies to use for new projects. I am creating a planning tool, still in beta, (santuri.io) that help choose the right technologies and it's been useful in addition to context7 for keeping the llm in the guardrails of the technology stack.\n\nedit:  \nclickable link: [https://santuri.io/](https://santuri.io/)",
          "score": 1,
          "created_utc": "2026-01-24 16:24:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1k5nr9",
              "author": "Eyoba_19",
              "text": "Sweet, thanks! Will try it out",
              "score": 2,
              "created_utc": "2026-01-25 04:15:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1gbsmp",
          "author": "Top-Cauliflower-1808",
          "text": "Most MCPs you listed are workflow or may tools focused. What‚Äôs usually missing is a data MCP that exposes clean, queryable datasets instead of raw APIs or CSVs upload.  \n  \nIf you do any marketing or BI analysis, a normalised data layer helps a lot. Windsor MCP syncs sources into a unified schema so you can ask cross channel metrics directly in ChatGPT/Claude. You can try this.",
          "score": 1,
          "created_utc": "2026-01-24 16:53:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1k611p",
              "author": "Eyoba_19",
              "text": "Oh, I did have that problem. All the MCPs had different payload layouts so you were at the AIs mercy to understand and act how you want it, would say it‚Äôs the one shortcoming I had that led me to develop my own linear MCP, but will try out Windsor for sure, thanks",
              "score": 1,
              "created_utc": "2026-01-25 04:17:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1uat30",
                  "author": "Top-Cauliflower-1808",
                  "text": "Yeah exactly. I hit the same issue. My sources were fine but different payload formats made the AI guess fields and outputs got messy.  \nOnce I connected my normalised data through an MCP layer to Claude using Windsor, it solves my problem.",
                  "score": 1,
                  "created_utc": "2026-01-26 16:15:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1gxcr0",
          "author": "808mona",
          "text": "Love the list - checkout firecrawl",
          "score": 1,
          "created_utc": "2026-01-24 18:27:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1k63nq",
              "author": "Eyoba_19",
              "text": "Thanks, didn‚Äôt even explain what firecrawl‚Äôs about, got me hooked already :)",
              "score": 1,
              "created_utc": "2026-01-25 04:18:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1jy7kz",
          "author": "Able-Classroom7007",
          "text": "have you tried [ref.tools](http://ref.tools) for docs search? \n\n(disclaimer: I'm the developer üëã)",
          "score": 1,
          "created_utc": "2026-01-25 03:30:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1k65oa",
              "author": "Eyoba_19",
              "text": "I‚Äôll give it a try, how does it compare against context7 though?",
              "score": 1,
              "created_utc": "2026-01-25 04:18:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1mgjy4",
                  "author": "Able-Classroom7007",
                  "text": "thanks!¬†https://docs.ref.tools/comparison/context7",
                  "score": 1,
                  "created_utc": "2026-01-25 14:37:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1kgt23",
          "author": "Ok-Bedroom8901",
          "text": "For those who use context7‚Ä¶\n\nIs context7 better than simply pointing the model to the GitHub repo that has the docs and the code examples that you want to build from?",
          "score": 1,
          "created_utc": "2026-01-25 05:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kldj7",
              "author": "spenpal_dev",
              "text": "Yes. Otherwise, you risk depending on how good is the model‚Äôs ability to scrape websites like GitHub repos.",
              "score": 1,
              "created_utc": "2026-01-25 05:58:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1km92j",
              "author": "Eyoba_19",
              "text": "Absolutely! You won't realize that you've implemented 2 versions back until the AI just can't get it to work and the last answers you find online were like from 3 years ago or sth, then you have to revert everything cause there were breaking changes between versions and they're not compatible with the latest frameworks you're using.\n\nTrust me, I've been through that headache, it's not worth it. As a matter of fact, I have instructions in [Agents.md](http://Agents.md) that says to always look up the latest docs for that external library.   \n  \nIdeally frameworks and libraries would have very minimal changes and be backwards compatible, but that's not the case, so yeah you got to put in the guardrails yourself. Just try it out and if it's not what you like, you can always revert it, no?",
              "score": 1,
              "created_utc": "2026-01-25 06:04:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1m81pw",
          "author": "Upstairs_Platform561",
          "text": "Solid¬†list!¬†Context7¬†and¬†Playwright¬†are¬†essentials.\n\nOne¬†tip¬†‚Äî¬†many¬†of¬†these¬†(Filesystem,¬†DDG¬†Search)¬†require¬†local¬†setup¬†and¬†maintenance.¬†If¬†you¬†want official remote¬†that¬†just¬†work,¬†We¬†maintain¬†a¬†curated¬†directory¬†of¬†official¬†MCPs¬†here:[https://apigene.ai/mcp/official](https://apigene.ai/mcp/official)\n\nRe:¬†Figma¬†MCP¬†‚Äî¬†pairs¬†great¬†with¬†Playwright¬†for¬†frontend¬†work.",
          "score": 1,
          "created_utc": "2026-01-25 13:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nswcf",
              "author": "Eyoba_19",
              "text": "Thanks man, configuration is definitely a pain for most of us, but DDG didn't need any configs on my end, maybe that was on older versions?",
              "score": 1,
              "created_utc": "2026-01-25 18:12:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ocawh",
                  "author": "Upstairs_Platform561",
                  "text": "Can you point me to the DDG MCP server you used? As far as I know, only local versions exist, and I couldn‚Äôt find any official or remote HTTP-based one",
                  "score": 1,
                  "created_utc": "2026-01-25 19:33:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1mqurq",
          "author": "dsolo01",
          "text": "Once upon a time, file system scared me. Now, access to my entire system with Claude (mostly Claude code) is essential.",
          "score": 1,
          "created_utc": "2026-01-25 15:27:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nszzr",
              "author": "Eyoba_19",
              "text": "Haha, tell me about it ;)",
              "score": 1,
              "created_utc": "2026-01-25 18:12:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1n1xhs",
          "author": "travisliu",
          "text": "I use obsidian mcp  for both file and memory, it also provide a pretty good markdown reader to read document.\n\nI have a question. is not Chrome DevTools MCP lighter and faster than Playwright, or is Playwright more useful? I'm curious why people choose Playwright over Chrome MCP.",
          "score": 1,
          "created_utc": "2026-01-25 16:17:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nup35",
              "author": "Eyoba_19",
              "text": "Oh, I had that browser MCP thing first before playwright, not sure which is lighter, will do a test. But the couple issues I had:  \n\\- Chrome needs to be open and you needed to explicitly \"connect\" it to a tab  \n\\- Had access to your Chrome context, just like any other extension, might be wrong, please correct me\n\nPlaywright just worked, the LLM just ran it, but I would say having to run playwright every time would take a toll, so maybe there's a connect and leave option? That'd be neat",
              "score": 1,
              "created_utc": "2026-01-25 18:19:10",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1phyew",
              "author": "RobertBernstein",
              "text": "Do you mean this? [MCP-Obsidian - Universal AI Bridge for Obsidian Vaults](https://mcp-obsidian.org/)",
              "score": 1,
              "created_utc": "2026-01-25 22:36:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1psyqt",
          "author": "farastray",
          "text": "Chrome devtools; ditch playwright",
          "score": 1,
          "created_utc": "2026-01-25 23:26:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qv1tv",
              "author": "Eyoba_19",
              "text": "Second time I‚Äôm seeing this, have to give it a go",
              "score": 1,
              "created_utc": "2026-01-26 02:35:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1q7v9e",
          "author": "tom3141592",
          "text": "I have been using these MCPs:\n\n\\- Context7 is useful for pulling up-to-date library documentation\n\n[https://github.com/upstash/context7](https://github.com/upstash/context7)\n\n\\- multi-mcp has been great for asking multiple LLM providers, like Codex or Gemini, for things like code review or multi-model comparison\n\n[https://github.com/religa/multi\\_mcp](https://github.com/religa/multi_mcp)",
          "score": 1,
          "created_utc": "2026-01-26 00:38:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zd6u9",
          "author": "Relative-Flatworm-10",
          "text": "  \nI made one MCP for Indian stock market stats.   \n[https://dgmcp.com/](https://dgmcp.com/)  \nProfessional-Grade Indian Stock Market Analysis MCP For Free  \nI am looking for valuable feedback and scope to improve this MCP",
          "score": 1,
          "created_utc": "2026-01-27 08:21:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27t0bc",
          "author": "Alifaga",
          "text": "can you share your Agents.md file ?",
          "score": 1,
          "created_utc": "2026-01-28 14:10:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqf4zo",
      "title": "3 MCPs that have genuinely made me 5x better",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "author": "Warm-Snow3302",
      "created_utc": "2026-01-29 17:33:36",
      "score": 160,
      "num_comments": 54,
      "upvote_ratio": 0.88,
      "text": "I've been testing MCPs extensively for fun, so I thought I‚Äôd share some of the ones I‚Äôve found most useful. Plus I've found most of the them here only.\n\nMy main criteria were minimal setup, reliability, and whether I kept using them after the novelty wore off:\n\ngreb MCP: Greb helps makes your coding agent 30% faster by helping them find correct files faster. That too without indexing It‚Äôs especially helpful for issue + commit context grounding and repo exploration. \n\nSlack / Messaging MCP: that‚Äúwow‚Äù factor with very low effort. Once an agent can talk where humans already are, teams love it instantly. My team even used this for something as basic as ordering and tracking deliveries for team lunch, which ended up being one of the most-used workflows for us.\n\nGitHub MCP: This is what finally made Claude feel like an actual teammate instead of a smarter autocomplete. If you‚Äôre tired of copy-pasting repos into prompts, you‚Äôre gonna love it. It‚Äôs especially helpful for issue + commit context grounding and repo exploration.\n\nSuper curious to hear what MCPs all of you have found useful?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2h9avr",
          "author": "slea95",
          "text": "Not sure the GitHub MCP is any better than the already-comprehensive gh CLI tool tbh. Unless there‚Äôs something I‚Äôm missing, it seems to be able to do all the things you listed but more efficiently and without bloat?",
          "score": 38,
          "created_utc": "2026-01-29 20:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hhjgc",
              "author": "sweettuse",
              "text": "+1 to this, might be worth reconsidering with Claude lazy mcp loading, but I just use the gh cli and it's great",
              "score": 8,
              "created_utc": "2026-01-29 21:25:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2j08sj",
                  "author": "bin-c",
                  "text": "I made the switch to GitHub mcp now that the mcp cli is available and for whatever reason it just seems to work better. Absolutely unusable before lazy loading though lol",
                  "score": 2,
                  "created_utc": "2026-01-30 02:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2htqzs",
              "author": "command-shift",
              "text": "It‚Äôs much better at parsing reviewer comments and feedback than gh CLI as a user of both",
              "score": 2,
              "created_utc": "2026-01-29 22:24:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2kxxgj",
              "author": "AdResident780",
              "text": "i personally love the deepwiki mcp server as it is free (no PAT needed) , doesnt need to be self-hosted and can ask questions about literally any github repo in existence (if not indexed, you need to index the repo by going to [deepwiki.com/](http://deepwiki.com/) {owner-of-unindexed-repo} / {unindexed-repo} .",
              "score": 1,
              "created_utc": "2026-01-30 10:48:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gfmw8",
          "author": "Electronic_Boot_1598",
          "text": "Which Slack MCP do you use?",
          "score": 11,
          "created_utc": "2026-01-29 18:27:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g9eqj",
          "author": "Crab_Shark",
          "text": "I‚Äôd love to know more!\n* For greb MCP, does that speedup also come with a reduction of token usage? Have you noticed whether it‚Äôs affected search quality?\n* For GitHub MCP, how is it different than the connectors within Claude, or running Claude Code connected to specific repos?",
          "score": 10,
          "created_utc": "2026-01-29 17:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdu05",
              "author": "snix_e",
              "text": "idk of the OP but I read about greb on this reddit only and it has been great, there's a reduction in token usage plus it remembers the logic with millions of line of code \n\nGitHub is very similar to them but the transition is very smooth",
              "score": 5,
              "created_utc": "2026-01-29 18:19:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2h5pvi",
          "author": "UseHopeful8146",
          "text": "I haven‚Äôt used GitHub mcp since it like first released, but I found it to be a complete waste of context. Your basic git/gh cli tools are incredibly simple, and even scripting CI/CD stuff isn‚Äôt terribly complicated - I just don‚Äôt see the value there\n\nEven for codebase search/analysis, octocode semantic search and deepwiki have been way more beneficial. And even just browser searching a repo is faster and more efficient with browser mcp or whichever web search tool that OmO installs with\n\nBut again, I have not used it at all since like‚Ä¶ idk march?",
          "score": 5,
          "created_utc": "2026-01-29 20:29:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hlwow",
              "author": "cab938",
              "text": "My value was it was in an MCP and I wasn't having to give the agent shell access. But frankly I rarely use it just because MCPs are much more fragile it seems.",
              "score": 1,
              "created_utc": "2026-01-29 21:46:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hnbnw",
                  "author": "UseHopeful8146",
                  "text": "Yeah agreed, I use mcp for very specific purposes, usually for interacting with self hosted services. Memory functions, routine things that save me time, or in some rare cases for specific retrieval methods like pulling my project specs and related docs from any type.\n\nBut MCP isn‚Äôt saving me time on git add, git comment, git push or gh repo clone, etc. if I want to look at specific material in a codebase: octocode \n\nIf I have a theory or a particularly tricky problem, index and question with deepwiki.\n\nNeed current code examples for a given library: context7\n\nLike, MCP does really well in certain instances, but a lot of them are just context waste. Bt those, and OmO provided mcp‚Äôs I save time on the long form stuff like research, investigation, etc. and since I learn by doing - I learn a lot faster by getting to ‚Äúdo‚Äù sooner",
                  "score": 1,
                  "created_utc": "2026-01-29 21:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hekq2",
          "author": "Maasu",
          "text": "There's a plugin I created which combines context7, Serena and forgetful (my own memory mcp) \n\nhttps://github.com/ScottRBK/context-hub-plugin\n\nI basically use the context gather command before I start any work and memory save when I'm done.",
          "score": 4,
          "created_utc": "2026-01-29 21:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jjm9r",
              "author": "Impressive_Chemist59",
              "text": "What difference between Serena and forgetful?",
              "score": 1,
              "created_utc": "2026-01-30 04:03:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kjl0r",
                  "author": "Maasu",
                  "text": "Serena is more concentrated on single device and has fairly primitive memory storage/retrieval. \n\nI mainly use Serena because of its out of the box encoding capabilities, specifically the symbol mapping on a repo, I use that output in an encoding architecture doc attached to each project that an LLM can consume to get a quick understanding of the code. \n\nHandy if I in voice convo on my phone etc and I don't want an LLM trawling through loads of code during an architectural brain storming session when I'm out for a walk for example.",
                  "score": 1,
                  "created_utc": "2026-01-30 08:38:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ht4qp",
          "author": "alex__richards",
          "text": "I would avoid MCP and use CLI tools where possible. I use Claude code and have cli‚Äôs configured for GitHub, Atlassian, Sentry, NewRelic - so much faster and economical (token usage) than an MCP",
          "score": 4,
          "created_utc": "2026-01-29 22:21:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2igmqq",
              "author": "SenorTortuga",
              "text": "Agreed. Not all MCPs are bad, but if there is a CLI tool that provides equivalent functionality it is almost always a better choice.  I‚Äôve been very happy since switching to acli and glab instead of Atlassian and GitLab MCPs.",
              "score": 3,
              "created_utc": "2026-01-30 00:25:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gclfg",
          "author": "Crafty_Disk_7026",
          "text": "GitHub MCP was clunky for me.  Uses lots of tokens and effort to do simple things like comparing a diff.  Which one did you use?",
          "score": 3,
          "created_utc": "2026-01-29 18:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdy0i",
              "author": "snix_e",
              "text": "opas",
              "score": 2,
              "created_utc": "2026-01-29 18:19:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfiv8",
                  "author": "Crafty_Disk_7026",
                  "text": "Gracias",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2gen3f",
          "author": "saloni1609",
          "text": "Nice list! I‚Äôve also been experimenting with MCPs recently.\n\nGreb stood out for me too especially for repo exploration without indexing. I‚Äôve been testing it inside Cheetah AI, which uses it as part of their context engine. It‚Äôs been interesting to see how it handles issue + commit grounding across bigger repos.\n\nGitHub MCP + Greb together feels like the closest thing to having a teammate who actually read the repo.\n\nCurious if you‚Äôve tried layering in memory systems too? I‚Äôve seen setups where the agent keeps commit history context, which makes debugging way smoother.",
          "score": 3,
          "created_utc": "2026-01-29 18:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gga4d",
          "author": "infidel_tsvangison",
          "text": "What does the GitHub mcp do really?",
          "score": 3,
          "created_utc": "2026-01-29 18:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2htkpa",
              "author": "command-shift",
              "text": "It‚Äôs also useful for fetching reviewer comments/feedback into your agent of choice to make decisions or issues to address or deliberate on",
              "score": 2,
              "created_utc": "2026-01-29 22:23:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2hipdd",
              "author": "TeamCaspy",
              "text": "See pull requests easier, open pr, open issues,...",
              "score": 1,
              "created_utc": "2026-01-29 21:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gfdz8",
          "author": "Pitiful-Minute-2818",
          "text": "Nice one i tried greb mcp it was really good",
          "score": 2,
          "created_utc": "2026-01-29 18:25:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ghtbv",
          "author": "Capnjbrown",
          "text": "Good info thanks. Perhaps you might find my product I made for context archiving and context preservation (amongst other features) for coding within Claude Code CLI. I open sourced it a couple weeks ago: [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-29 18:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hl20o",
          "author": "adreportcard",
          "text": "People‚Ä¶. Copy and pasted repos into prompts?",
          "score": 2,
          "created_utc": "2026-01-29 21:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kt5bh",
              "author": "that__it_guy",
              "text": "Yeah I too didnt get this.",
              "score": 1,
              "created_utc": "2026-01-30 10:06:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ktyr7",
          "author": "that__it_guy",
          "text": "Why do people in general use so many mcps? When I have a coding task, i do research on Gemini, code on cursor/intellij and thats all. What are the manual workflows the agents have helped you in ?",
          "score": 2,
          "created_utc": "2026-01-30 10:13:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mrsly",
              "author": "vayana",
              "text": "I agree. I get by absolutely fine without an MCP. The only 2 I would consider using are a database MCP like neon or supabase and perhaps playwright, but I've so far never really needed to use these either.",
              "score": 1,
              "created_utc": "2026-01-30 16:52:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hkvb0",
          "author": "oginome",
          "text": "Check out Forgetful MCP. It's a yet another vector-based semantic memory system that allows your agents to recollect stuff between sessions. I've been using it and it's actually pretty great - we can reference conversations from weeks ago instantly. I'm a huge fan of how it organizes by project, and I have basically replaced my note-taking workflow with it.\n\nCoupled with GLM 4.7 Flash, Karakeep MCP, and Searxng I've made strides in being able to efficiently provide it context so that I don't have to burn so many tokens reaching understanding. \n\n[https://github.com/scottrbk/forgetful](https://github.com/scottrbk/forgetful)",
          "score": 3,
          "created_utc": "2026-01-29 21:41:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g61wd",
          "author": "FewChart7648",
          "text": "I have used GitHub that is amazing but will try the rest, but GitHub also sometimes have a bad memory",
          "score": 1,
          "created_utc": "2026-01-29 17:44:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gc5u0",
          "author": "anywhereblue",
          "text": "Good list.",
          "score": 1,
          "created_utc": "2026-01-29 18:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gi1ur",
          "author": "PuzzledCulture25",
          "text": "When working on frontend I use [Linear](https://linear.app/docs/mcp), [ChromeDevTools](https://github.com/ChromeDevTools/chrome-devtools-mcp) and [Capturl](https://capturl.com). It lets agents see screenshots inside of tickets and update the ticket with new screenshots when it's done.",
          "score": 1,
          "created_utc": "2026-01-29 18:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h1tr4",
              "author": "Express-One-1096",
              "text": "Why not playwright mcp?",
              "score": 1,
              "created_utc": "2026-01-29 20:10:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h5e6g",
                  "author": "PuzzledCulture25",
                  "text": "I mainly switched over to chrome dev tools because it's nice for debugging but Playwright worked great too!",
                  "score": 1,
                  "created_utc": "2026-01-29 20:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h9da7",
          "author": "martin_xs6",
          "text": "There's an obsidian one that is really great if you use that.\n\nGmail + Google drive Is great too.  With Gmail you can have it draft emails to review before sending.  It's great for making notes to send to something about changes.",
          "score": 1,
          "created_utc": "2026-01-29 20:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hd46k",
          "author": "Traditional_Cress329",
          "text": "Really love devtools by google for debugging extensions or web apps.",
          "score": 1,
          "created_utc": "2026-01-29 21:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2he2rp",
          "author": "VictorCTavernari",
          "text": "For me as Swift developer, SwiftZilla.dev is the best",
          "score": 1,
          "created_utc": "2026-01-29 21:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hgw40",
          "author": "canihelpyoubreakthat",
          "text": "Nah huh. I saw 55x improvements! Measured with the trustmebro bench and all.\n\n55x more tokens\n55x more hallucinations \n55x more markdown\n55x more code to review",
          "score": 1,
          "created_utc": "2026-01-29 21:22:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hi68n",
          "author": "aviboy2006",
          "text": "I am using AWS ECS service MCP for debugging issue so far. I heard about Figma  and playwright MCP but didn‚Äôt try yet. Soon going to try.",
          "score": 1,
          "created_utc": "2026-01-29 21:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jght4",
              "author": "Warm-Snow3302",
              "text": "playwright is actually really good",
              "score": 1,
              "created_utc": "2026-01-30 03:44:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hoz7h",
          "author": "freeformz",
          "text": "I use the local version of the GitHub MCP (to remove tools I don‚Äôt care about) and it‚Äôs pretty awesome",
          "score": 1,
          "created_utc": "2026-01-29 22:01:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hvsib",
          "author": "dxlachx",
          "text": "Sequential thinking, Serena, and Context7",
          "score": 1,
          "created_utc": "2026-01-29 22:34:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i2nik",
          "author": "trolololster",
          "text": "greb?",
          "score": 1,
          "created_utc": "2026-01-29 23:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ihaid",
          "author": "Icanteven______",
          "text": "GitHub mcp is such a context hog. I just have it use the gh cli",
          "score": 1,
          "created_utc": "2026-01-30 00:28:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jqfpy",
          "author": "sincerodemais",
          "text": "Grep or filesystem mcp?",
          "score": 1,
          "created_utc": "2026-01-30 04:46:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kxnp8",
          "author": "AdResident780",
          "text": "i use the deepwiki MCP server (for up-to-date info about any github repo)",
          "score": 1,
          "created_utc": "2026-01-30 10:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2geob1",
          "author": "DasBlueEyedDevil",
          "text": "You forgot the best one:  [https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
          "score": 0,
          "created_utc": "2026-01-29 18:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gfa0e",
              "author": "snix_e",
              "text": "you are promoting your MCP hereüòÇ",
              "score": 2,
              "created_utc": "2026-01-29 18:25:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfjt7",
                  "author": "DasBlueEyedDevil",
                  "text": "I meeeaaaaan, OP did end the post with asking which ones we've found useful ;-)",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2h8l0d",
              "author": "full_hyperion",
              "text": "Gonna try it out just because of the theme :D",
              "score": 1,
              "created_utc": "2026-01-29 20:43:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmhh5r",
      "title": "I built `mcp2skill` which converts your MCP servers into Skills with one command! ‚ú®",
      "subreddit": "mcp",
      "url": "https://github.com/fenwei-dev/mcp2skill",
      "author": "Ok_You4416",
      "created_utc": "2026-01-25 12:09:02",
      "score": 81,
      "num_comments": 39,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qmhh5r/i_built_mcp2skill_which_converts_your_mcp_servers/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1pjfld",
          "author": "Ok_Mix_2823",
          "text": "Ngl the core premise is a bit off. MCP and Skills have different purposes. MCP is for connecting AI models to external tools and data sources. Skills are essentially curated markdown instructions and context that coding agents load on demand. They‚Äôre complementary, not competing. this tool actually just wraps MCP server interactions behind a SKILL.md and a CLI binary. Which is what skills were made for essentially",
          "score": 11,
          "created_utc": "2026-01-25 22:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qiw2w",
              "author": "Ok_You4416",
              "text": "I agree! This is essentially a CLI that calls MCP servers. What I wanted to propose is this pattern could be a better approach to use MCP compared to loading all MCP tools into agent context at the same time. With MCP protocol itself going [\"state-less\"](https://blog.modelcontextprotocol.io/posts/2025-12-19-mcp-transport-future/#a-stateless-protocol), this  approach will work for more MCP servers.",
              "score": 5,
              "created_utc": "2026-01-26 01:33:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1rnmq0",
                  "author": "Successful-Raisin241",
                  "text": "I was struggling to give Claude skills to perform certain api calls with certain limitations, with clear API docs available. Claude was dumb, ignored instructions, ignored skills, and composed prompt injections to overcome limitations. So MCP is still needed and Skills can't replace it",
                  "score": 2,
                  "created_utc": "2026-01-26 05:26:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1s7p1x",
                  "author": "Ok_Mix_2823",
                  "text": "Ah I see!",
                  "score": 1,
                  "created_utc": "2026-01-26 08:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1utm1n",
              "author": "dashingsauce",
              "text": "People just need a continuous source of ‚Äúacshually‚Äù to continue reaping engagement points",
              "score": 1,
              "created_utc": "2026-01-26 17:36:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1n5pr7",
          "author": "shikima",
          "text": "I use the skills to make the LLMs understand the MCPs",
          "score": 2,
          "created_utc": "2026-01-25 16:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1oly24",
              "author": "Groveres",
              "text": "Same here. Give them more context how and when to use it.",
              "score": 2,
              "created_utc": "2026-01-25 20:16:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1mdejr",
          "author": "Possible-Benefit4569",
          "text": "Skills eating my context Window very fast, so more skills dumb ai. I have to keep them small and smart.",
          "score": 2,
          "created_utc": "2026-01-25 14:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mq448",
              "author": "One-Poet7900",
              "text": "Skills are loaded on demand, MCP tools are loaded up front. Skills should have less context bloat",
              "score": 6,
              "created_utc": "2026-01-25 15:24:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1nixxx",
                  "author": "zaphodp3",
                  "text": "Yeah I thought context size management was one of the big reasons to use skills instead of mcp only.",
                  "score": 2,
                  "created_utc": "2026-01-25 17:30:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ol5cb",
                  "author": "WealthSad4337",
                  "text": "You can choose which MCP tools your client has access to. You can just create an MCP tool to return a string and it behaves exactly as a skill would.",
                  "score": 1,
                  "created_utc": "2026-01-25 20:12:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1mi3hh",
              "author": "Crafty_Disk_7026",
              "text": "Please check out \"codemode\".  This has given me the benefits of MCP with much more reasonable token usage.  Here's a SQLite MCP I converted to codemode to prove it:  https://github.com/imran31415/codemode-sqlite-mcp/tree/main",
              "score": 1,
              "created_utc": "2026-01-25 14:45:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1mk4tr",
                  "author": "mycall",
                  "text": "> https://github.com/imran31415/codemode-sqlite-mcp/tree/main\n\nThe trade off of codemode is slower performance, yes?",
                  "score": 2,
                  "created_utc": "2026-01-25 14:55:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1pph8d",
              "author": "Specialist_Solid523",
              "text": "An inefficient skill will behave just like inefficient code. If skills are chewing up your context window and burning tokens, it might be worth reconsidering how you are writing them.\n\nThe point is, I wouldn‚Äôt be so quick to write them off. I‚Äôve seen significant token saving and reduced context rot from skills usage - they are OP.\n\nHappy to share my approach if you want!",
              "score": 1,
              "created_utc": "2026-01-25 23:09:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1rpsea",
                  "author": "Possible-Benefit4569",
                  "text": "Different approaches here. My case is like ‚Äûexcel‚Äú. Will it be code in future or not. Mostly not. In my case probably yes, because my Skills are POCs. They combine domain Knowledge with ‚Äûapi‚Äú/mcp and llm. So it creates business value but in Claude.ai / Desktop they consumes half of context but working together. \nHead of dev can decide to transfer them to code or i book another claude for other complex cases. End of day claude, custome mcp and skills are a very beneficial combination. Like a already tested and running Spec üôÇ",
                  "score": 1,
                  "created_utc": "2026-01-26 05:41:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1zc1y9",
              "author": "Possible-Benefit4569",
              "text": "Edit: Yes, as Users mentioned on demand in that chat.",
              "score": 1,
              "created_utc": "2026-01-27 08:10:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1mghm2",
          "author": "WealthSad4337",
          "text": "Cool but skills and MCP essentially do the same thing.",
          "score": 3,
          "created_utc": "2026-01-25 14:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1oqznm",
              "author": "cab938",
              "text": "No? Skills teach the LLM something, MCPs execute code based on LLM input. One is reasoning, the other is computation.",
              "score": -1,
              "created_utc": "2026-01-25 20:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p2vqf",
                  "author": "WealthSad4337",
                  "text": "Just make a tool that returns a string and it‚Äôs a skill.",
                  "score": 2,
                  "created_utc": "2026-01-25 21:29:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qu2pr",
                  "author": "sivadneb",
                  "text": "Not exactly. Both augment the context in some way. Both can do reasoning, both can do computation. It's all context in the end. \n\nThat's not to say each doesn't have their uses. I think what skills will largely replace is *local* MCP servers. Remote MCP servers will always have their place. But again, those servers could do reasoning, computation, or a mix of both.",
                  "score": 2,
                  "created_utc": "2026-01-26 02:30:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qzxhr",
                  "author": "Excited_Idiot",
                  "text": "This is a very misinformed take on what MCPs do. I have a lot of MCPs I run that are not remotely related to code execution.",
                  "score": 1,
                  "created_utc": "2026-01-26 03:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ogymg",
          "author": "vskhosa",
          "text": "Can skills 'really' replace MCP for good? Does that mean Anthropic donated a dying project to Linux Foundation?",
          "score": 1,
          "created_utc": "2026-01-25 19:54:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ooaud",
              "author": "Fafadom",
              "text": "There still needs to be guard railed non-coding AI tools for non-devs in production systems.",
              "score": 1,
              "created_utc": "2026-01-25 20:26:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1sbxqx",
          "author": "Sachka",
          "text": "MCPs aren‚Äôt meant for us, they are meant for them, if you build MCP for them you build an entry door for you, a CLI, or like in most cases, the CLI is there already and you build an MCP for them on top of it. Skills are just instructions at prompt evaluation time. These are not the same thing. This is pretty much like saying ‚ÄúI‚Äôve built a Docker Container to bash script tool‚Äù or even worse, ‚ÄúHere is a container to readme tool‚Äù. What you need to be better at or at least understand is how THEY read function description, so that you understand HOW they see the tools in their context, and what it means to add an MCP to an agent configuration or an MCP Gateway.",
          "score": 1,
          "created_utc": "2026-01-26 08:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1seejy",
          "author": "Sachka",
          "text": "You are overloading the context with redundant instructions at best, you got to understand skills are not the same thing as MCP and aren‚Äôt meant to replace them, skills are at best just instructions on how to use tools (MCP) in a specific way, think of it as guardrails for the way you develop. You may have a skill that describes how to read sdk info using an MCP tool, write the code in a particular location and then write documentation using a different MCP tool (Maybe Notion). And I could write a skill to tell the same agent in the same project to never write to Notion, and always do testing before pushing into production. Same project, different skills, different uses, BUT! you cannot replace MCP tools!",
          "score": 1,
          "created_utc": "2026-01-26 09:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1te5kc",
          "author": "ChronoFish",
          "text": "I've built my system around agents instead of skills.\n\n\nI have a routing (master) agent that simply determines \"who is going to respond to this request?\"\n\n\nEach (sub) agent has its own preamble and MCP list.\n\n\nI can see the bennift of bolt on or reusable preamble bits.. which is where skills come in.¬† But so far (in my architecture) that level of granularity is unnecessary.¬† But it's on my radar once I need consistency with instructions around tool use between agents.",
          "score": 1,
          "created_utc": "2026-01-26 13:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1uqtu7",
          "author": "kuaythrone",
          "text": "I like wrapping my mcps in sub agents instead, I find it better for context management and saving tokens using haiku and sonnet since they have the smaller task of just calling the mcp functions",
          "score": 1,
          "created_utc": "2026-01-26 17:24:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21wdqu",
              "author": "unc0nnected",
              "text": "Can you share some of your lessons learned good vs bad ways to do this and results from any benchmarks you ran?  Really curious!",
              "score": 1,
              "created_utc": "2026-01-27 17:32:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o200d74",
          "author": "maxkatz6",
          "text": "Necessity to write skills for MCP is an indicator of poorly implemented MCP server.\n\nMCP server's tool descriptions and standard server-instructions promt should do this job of explaining how to call them, in what order, and in what scenarios.\n\nSee [Server Instructions: Giving LLMs a user manual for your server](https://blog.modelcontextprotocol.io/posts/2025-11-03-using-server-instructions/) for example.",
          "score": 1,
          "created_utc": "2026-01-27 11:46:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20s0gb",
          "author": "Only_Internal_7266",
          "text": "Skill: llm does the work it discovers in the instructions  \nMCP: llm executes the work from existing context (not 'discovered')  \nSubtle, but meaning full distinction.  \n\n    {\n      \"mcpServers\": {\n        \"apifunnel\": {\n          \"url\": \"https://tool.apifunnel.ai/mcp/\",\n          \"headers\": {\n            \"Authorization\": \"Bearer YOUR_TOKEN_HERE\"\n          }\n        }\n      }\n    }\n\n[get a key.](https://app.apifunnel.ai/engineering)  \n",
          "score": 1,
          "created_utc": "2026-01-27 14:30:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qodaze",
      "title": "Sims 1 Legacy MCP",
      "subreddit": "mcp",
      "url": "https://i.redd.it/nnn207a64wfg1.png",
      "author": "pevers",
      "created_utc": "2026-01-27 13:05:39",
      "score": 69,
      "num_comments": 15,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o223p6l",
          "author": "Select-Bell-5920",
          "text": "I didn't know that I wanted nor needed this, but turns out I actually do...",
          "score": 8,
          "created_utc": "2026-01-27 18:03:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23qoaj",
              "author": "VIDGuide",
              "text": "Holy shit.. the idea of AI playing a simulation of humans.. and .. fuck it, I‚Äôm in, let‚Äôs go!",
              "score": 5,
              "created_utc": "2026-01-27 22:24:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o213kmm",
          "author": "Odd-Cardiologist1905",
          "text": "Gosh now I imagine having claude like a porn director: \"Hey Claude make them fuck! now!\"",
          "score": 3,
          "created_utc": "2026-01-27 15:26:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o277tgt",
          "author": "SecureHunter3678",
          "text": "Holy shit letting Claude work Ghydra is fucking genius... That just gave me soooo many Ideas.",
          "score": 3,
          "created_utc": "2026-01-28 12:04:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279zmv",
              "author": "pevers",
              "text": "It is a game changer. I did this in a fraction of the time it would cost me without AI. I remember painfully debugging method after method trying to figure out the flow. Now I can just let it crunch for an hour and it comes back with \\~100 renamed methods and data structures.",
              "score": 1,
              "created_utc": "2026-01-28 12:19:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27bn15",
                  "author": "SecureHunter3678",
                  "text": "Some while ago I also saw a Cheat Engine MCP Floating around. I guess i know what I'm going to do this weekend. That opens some modding doors on Retro Games, at which I had been crunching my teeth out for a while.",
                  "score": 1,
                  "created_utc": "2026-01-28 12:30:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o21cylx",
          "author": "InfraScaler",
          "text": "haahahah fcking brilliant mate! and I bet it was lots of fun working on it!",
          "score": 2,
          "created_utc": "2026-01-27 16:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o229ahz",
          "author": "cionut",
          "text": "So cool!! Planning to open source/share? Back in my days people had travian at work on a second screen - this could fit the same role",
          "score": 2,
          "created_utc": "2026-01-27 18:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22rrxn",
              "author": "pevers",
              "text": "Thanks! There is a GitHub repo with the code. It is mainly DLL injection to read values from memory but I‚Äôm working on a patch for more control.",
              "score": 2,
              "created_utc": "2026-01-27 19:47:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o22ndcg",
          "author": "Open_Resolution_1969",
          "text": "I took the liberty to cross post your message on another reddit since the idea is amazing and very appealing!",
          "score": 2,
          "created_utc": "2026-01-27 19:27:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22svvm",
              "author": "pevers",
              "text": "Thanks! In which sub-reddit? I'm not sure why but I can't see it",
              "score": 1,
              "created_utc": "2026-01-27 19:52:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o22tbgq",
                  "author": "Open_Resolution_1969",
                  "text": "https://www.reddit.com/r/impressionsgames/s/DTjC6s1P9u",
                  "score": 1,
                  "created_utc": "2026-01-27 19:54:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o22xup8",
          "author": "jotarokato",
          "text": "    hay que jder",
          "score": 1,
          "created_utc": "2026-01-27 20:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26viqx",
          "author": "msghost1989",
          "text": "Thats why i love paying so much money for ddrs üòç",
          "score": 1,
          "created_utc": "2026-01-28 10:24:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qog1wq",
      "title": "I wrote Concierge, an Open Source library to convert MCPs into tool groups, stages and workflows which are progressively discovered as agents interact with the server.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/",
      "author": "Prestigious-Play8738",
      "created_utc": "2026-01-27 14:56:15",
      "score": 67,
      "num_comments": 12,
      "upvote_ratio": 0.96,
      "text": "Hey everyone!\n\nAnyone else tired of configuring 50¬†tools into MCP and just¬†hoping¬†the¬†agent figures¬†it out? (invoking the right tools in the right order).\n\nWe keep¬†hitting same problems:\n\n* Agent¬†calls¬†\\`checkout()\\`¬†before¬†\\`add\\_to\\_cart()\\`\n* Context bloat: 50+ tools served for every conversation message.\n* Semantic loss: Agent does not know which tools are relevant for the current interaction\n* Adding¬†a system¬†prompt describing the order of tool invocation and praying that the agent follows it.\n\nSo I wrote Concierge. It converts¬†your¬†MCP into a stateful graph, where you¬†can organize tools into¬†stages and workflows, and agents only have tools¬†**visible to the¬†current stage**.\n\n    from concierge import Concierge\n    \n    app = Concierge(\"my-server\")\n    \n    \n    app.stages = {\n        \"browse\": [\"search_products\"],\n        \"cart\": [\"add_to_cart\"],\n        \"checkout\": [\"pay\"]\n    }\n    \n    \n    app.transitions = {\n        \"browse\": [\"cart\"],\n        \"cart\": [\"checkout\"]\n    }\n\nThis also supports sharded distributed state and semantic¬†search for¬†thousands of tools. (also compatible with existing MCPs)\n\nDo try it out and love to know what you think. Thanks!\n\nRepo: [https://github.com/concierge-hq/concierge](https://github.com/concierge-hq/concierge)\n\nInstall it with: `pip¬†install concierge-sdk`",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o20xlhe",
          "author": "Choice-Party4676",
          "text": "Following",
          "score": 4,
          "created_utc": "2026-01-27 14:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21bb6e",
          "author": "fizzcuber",
          "text": "very interesting. did you considering contributing this to the mcp spec? I remember seeing something about progressive disclosure for mcps tools",
          "score": 2,
          "created_utc": "2026-01-27 16:00:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21cp4t",
              "author": "Prestigious-Play8738",
              "text": "Thank you for your interest! Concierge provides constructs like distributed state, discovery, orchestration, storage etc.\n\nSuch features may not be relevant to the protocol, but very relevant to the application layer to build apps/servers.",
              "score": 2,
              "created_utc": "2026-01-27 16:06:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24l9zi",
          "author": "pbalIII",
          "text": "Stage-gated tool visibility is the part that scales best. Most teams I've seen hit a wall around 20-30 tools where the model starts confusing semantically similar actions... checkout vs complete_order vs finalize_purchase.\n\nThe semantic search mode compressing to two meta-tools (search_tools + call_tool) is clever for the long tail case. For backtracking scenarios like abandoned carts mid-checkout, the cleanest pattern I've seen is treating reverse transitions as explicit stages rather than reverse edges. Reset to a known stage, don't try to unwind.",
          "score": 2,
          "created_utc": "2026-01-28 00:58:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279jf8",
              "author": "Prestigious-Play8738",
              "text": "Reset is a really great idea! Support should be added shortly",
              "score": 1,
              "created_utc": "2026-01-28 12:16:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26u7sg",
          "author": "kduman",
          "text": "This is really cool. I like the idea.",
          "score": 2,
          "created_utc": "2026-01-28 10:13:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279eo8",
              "author": "Prestigious-Play8738",
              "text": "Thanks! Concierge makes your MCP server a first class citizen, let me know if you want to use it in the future. Can share unlimited lifetime deployment credits on the platform",
              "score": 1,
              "created_utc": "2026-01-28 12:15:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o29zza4",
                  "author": "Select-Bell-5920",
                  "text": "Would love to give it a go!",
                  "score": 2,
                  "created_utc": "2026-01-28 20:01:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2786t0",
          "author": "Childish_Ganon",
          "text": "Landed on a similar pattern for my project, an MCP server with 60+ data science tools. I split them into classes (utils, parent tools, workflow tools, and subtools), then group subtools by function (EDA, cleaning, visualization, ML, etc.). Parent tools wrap subtools via `describe_<category>` \\+ `execute_<category>`, so the agent discovers tools progressively rather than getting everything dumped into context at once. Workflow tools package related subtools together for common pipelines.\n\nGitHub: [https://github.com/oogunbiyi21/stats-compass-mcp](https://github.com/oogunbiyi21/stats-compass-mcp)",
          "score": 0,
          "created_utc": "2026-01-28 12:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279611",
              "author": "Prestigious-Play8738",
              "text": "This is awesome, happy to connect if you want to implement this with Concierge, change 4-5 lines and get superpowers! Great to see your server, starred it!",
              "score": 1,
              "created_utc": "2026-01-28 12:13:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27azix",
                  "author": "Childish_Ganon",
                  "text": "Will definitely consider it in the future! As the number of data science tools expands I'm conscious that I might need even tighter tool orchestration, and in particular I think the way I've managed workflows could be simplified.",
                  "score": 1,
                  "created_utc": "2026-01-28 12:26:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnhf18",
      "title": "finally found a stack that doesn't break my agents every 5 mins",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qnhf18/finally_found_a_stack_that_doesnt_break_my_agents/",
      "author": "Ilove_Cakez",
      "created_utc": "2026-01-26 14:25:28",
      "score": 57,
      "num_comments": 5,
      "upvote_ratio": 0.98,
      "text": "idk about you guys but i've spent way too much of 2025 just fighting with my mcp config files instead of actually building. finally feel like i‚Äôve got a stable setup that doesn't require me to babysit my terminal all day so i thought i'd drop it here.\n\nthis is what i‚Äôm using for my agentic workflow right now:\n\n1. mcp jam - local testing tool for chatgpt apps and mcp servers. lets you build locally with a widget emulator and test against any llm in the playground\n\n2. smithery - still the best place to find ready-to-go servers. i basically use it as my app store for mcp... usually grab their github and figma connectors first thing on any new project.\n\n3. ogment ai - this is my secret weapon for the \"adult\" stuff. i use it to handle the remote hosting and the nasty auth/governance bits that i don't want to hardcode into my own servers. it basically lets me select a data source (api/db/3rd party) and customise the server tools in plain english and it just stays live/secure without me touching it.\n\n4. context7 - been using this to keep the agent's docs updated. helps so much when you're working with fast-moving libraries that claude‚Äôs base training hasn‚Äôt seen yet.\n\nhonestly, once i offloaded the server hosting and auth to ogment and started using smithery for the standard stuff, my dev velocity basically tripled. it‚Äôs nice to actually have a \"production\" grade setup without needing a whole devops team to manage the backend.\n\nwhat are you guys using for your registry/governance? i'm still looking for a better way to handle long-term memory across sessions if anyone has suggestions.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qnhf18/finally_found_a_stack_that_doesnt_break_my_agents/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o1tsj9f",
          "author": "MoP342",
          "text": "Hi! I'm building Airlock ([https://www.air-lock.ai](https://www.air-lock.ai)), which acts as an MCP server, security layer and audit trail. Obviously, I'm using that as registry/governance, but it's very interesting to see what other people are using.\n\nHaven't used smithery. Where do you end up in terms of cost, monthly?\n\nFor long-term memory: since I basically live in Claude, CLAUDE.md does the trick for me...",
          "score": 2,
          "created_utc": "2026-01-26 14:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xv8d8",
              "author": "isoman",
              "text": "Governance is the future of AI: https://github.com/ariffazil/arifOS",
              "score": 2,
              "created_utc": "2026-01-27 02:09:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ylz9j",
          "author": "Honest-Antelope-2589",
          "text": "Can u share wdym by config file issues isn't the config file catching up and the tools getting used or its the ide in loading state or something else can u share it clearly .",
          "score": 2,
          "created_utc": "2026-01-27 04:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o274kmn",
          "author": "saif_shines",
          "text": "Try scalekit.com! Very lightweight OAuth 2.1 layer.",
          "score": 1,
          "created_utc": "2026-01-28 11:40:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g8pm1",
          "author": "pbalIII",
          "text": "Splitting hosting/auth from the registry layer is underrated. I've seen teams waste weeks debugging config drift when both concerns are tangled in one server.\n\nFor long-term memory: check out Mem0's OpenMemory MCP or the doobidoo/mcp-memory-service repo. Both do semantic indexing so the agent retrieves relevant context instead of dumping everything into the prompt. The key is scoped memory keys... user_id + namespace prevents contamination across sessions.\n\nOne thing I'd push back on: CLAUDE.md works for project context but doesn't scale for user-specific state across multiple projects. You end up needing a proper memory layer eventually.",
          "score": 1,
          "created_utc": "2026-01-29 17:56:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlp56s",
      "title": "Built a way to share MCP-configured skills without requiring users to set up Claude locally",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qlp56s/built_a_way_to_share_mcpconfigured_skills_without/",
      "author": "enthusiast_bob",
      "created_utc": "2026-01-24 15:00:40",
      "score": 28,
      "num_comments": 0,
      "upvote_ratio": 0.95,
      "text": "I kept seeing the same friction with clients sharing Skills based agents:  \n\n\n1. End user needs Claude Desktop or Claude Code installed\n\n2. End user also needs to also configure MCPs correctly\n\n3. If anything breaks, debugging over texts and calls.\n\n\n\nThat makes sharing agents and skills high friction, even if listed on a marketplace.\n\n\n\nSo I built Agent37 ([agent37.com](http://www.agent37.com)) - upload your Claude skills + Connect Apps (for MCP), get a shareable link. Users hit the link, skills just works. No Claude account required on their end.\n\n\n\n**Example:** Here's a YC Advisor skill that RAGs over 434 YC resources. Instead of asking users to download plugins, you just share a link: [agent37.com/yc](http://www.agent37.com/yc)\n\n  \nWould you use something like this?",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qlp56s/built_a_way_to_share_mcpconfigured_skills_without/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qnpgrl",
      "title": "MCP Apps - Bringing UI Capabilities To MCP Clients",
      "subreddit": "mcp",
      "url": "https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps/",
      "author": "beckywsss",
      "created_utc": "2026-01-26 19:05:12",
      "score": 28,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qnpgrl/mcp_apps_bringing_ui_capabilities_to_mcp_clients/",
      "domain": "blog.modelcontextprotocol.io",
      "is_self": false,
      "comments": [
        {
          "id": "o1y1ear",
          "author": "Zach543",
          "text": "Is this the same as Google's A2UI?",
          "score": 1,
          "created_utc": "2026-01-27 02:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o242ogs",
              "author": "EnvironmentSilent647",
              "text": "Not really, A2UI is generative UI where the model ‚Äòbuilds‚Äô a UI out of a component catalog. MCP Apps are fully custom interactive UI apps that the MCP server provides.",
              "score": 1,
              "created_utc": "2026-01-27 23:23:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yw1vp",
          "author": "Ok-Bedroom8901",
          "text": "I‚Äôm really glad to see Claude finally supporting MCP apps. I was getting a little worried there since ChatGPT had app support first.\n\nChatGPT has a tendency to do things slowly, poorly, and terribly.",
          "score": 1,
          "created_utc": "2026-01-27 05:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zsriu",
          "author": "jezweb",
          "text": "Awesome. Glad to see this is standardised.",
          "score": 1,
          "created_utc": "2026-01-27 10:44:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2310sw",
          "author": "mkaufman09",
          "text": "Anyone know what changes you need to make when they add chatgpt support if you built according to chatgpts app protocol originally",
          "score": 1,
          "created_utc": "2026-01-27 20:28:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qobxmj",
      "title": "MCP apps VS Apps SDK (OpenAI)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/",
      "author": "0xKoller",
      "created_utc": "2026-01-27 12:01:00",
      "score": 23,
      "num_comments": 6,
      "upvote_ratio": 0.97,
      "text": "MCP Apps is now an official extension to the Model Context Protocol (MCP), enabling tools to return interactive UI components that render directly within MCP clients. It overcomes the limitations of text-based interactions by delivering rich, sandboxed UI experiences right inside conversations, while keeping the model involved through seamless bidirectional communication.\n\nBefore this, we had OpenAI's Apps SDK, a proprietary alternative that allowed similar functionality but was limited to the ChatGPT sandbox, with exclusive runtime variables and APIs. In contrast, MCP Apps enables UI rendering in *any* MCP client that supports it, promoting a more open and portable ecosystem.\n\n# GPT Apps vs. MCP Apps\n\n* **Backbone**: GPT Apps build on MCP plus OpenAI's proprietary widget runtime, while MCP Apps use pure MCP with a standardized UI extension.\n* **UI Declaration**: GPT Apps declare UIs via `_meta.openai/outputTemplate` or similar, whereas MCP Apps use the standard `_meta.ui.resourceUri: \"ui://dashboard\"`.\n* **UI Delivery**: Both deliver bundled HTML/JS resources served by an MCP server.\n* **Host and UI**: GPT Apps rely on OpenAI-specific widget runtime and postMessage, but MCP Apps standardize it with JSON-RPC over postMessage.\n\nThe ecosystem has converged remarkably fast. MCP Apps emerges as the open, multi-platform winner going forward and with ChatGPT now supporting the official standard, you no longer have to choose between them. OpenAI may even phase out their proprietary development in the near future.\n\n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o231bsw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-01-27 20:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23722l",
              "author": "sylre",
              "text": "There is a statement on the mcp website talking about convergence of both standard",
              "score": 1,
              "created_utc": "2026-01-27 20:56:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o23lli4",
          "author": "matt8p",
          "text": "I was skeptical of ChatGPT adopting MCP apps at all. It's great for the ecosystem to have a single protocol for apps. From a business perspective, it might be better off for OpenAI to maintain their own ecosystem. They could implement add-ons like payment flows that aren't part of the MCP apps spec.",
          "score": 1,
          "created_utc": "2026-01-27 22:00:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o24lkcx",
          "author": "pbalIII",
          "text": "Portability is the real win here. Building on MCP means your server works with Claude, Cursor, VS Code, whatever supports the protocol... not just ChatGPT. That compounds over time as more clients ship support.\n\nOne thing worth watching: the spec leaves a lot of implementation details to individual hosts. Could see some fragmentation creep in between how OpenAI, Anthropic, and VS Code handle edge cases. The double iframe architecture and pre-declared resources are aligned, but the Host-to-Guest communication layer has room for drift.",
          "score": 1,
          "created_utc": "2026-01-28 00:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o255idg",
              "author": "Sad-Passage-4653",
              "text": "Reminds me of when everyone had to put custom <!-- if ie6 --> code in their HTML back in the day.  Hopefully no on makes an MCP version of internet explorer lol",
              "score": 2,
              "created_utc": "2026-01-28 02:44:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2655qy",
          "author": "Euphoric-Mark-4750",
          "text": "Has anyone had any success getting there (remote) MCP hosted in either of Anthropic / OpenAI connectors/apps directories?\n\nI submitted mine to Anthropic a week plus ago - the submission messaged involved a ‚Äòwe may not list your connector nor may we contact you‚Äô and no email acknowledgment of submission - not exactly hopeful.\n\nI got stuck with OpenAI‚Äôs business verification process. Just starting to wonder if any of it was worth the effort.",
          "score": 1,
          "created_utc": "2026-01-28 06:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28vf4f",
          "author": "Ok_Message7136",
          "text": "This is a good breakdown. The big win with MCP Apps is portability, same UI + tools across any MCP client, not locked to one runtime.\n\nFeels like the natural evolution now that MCP is becoming the shared standard instead of every platform inventing its own app model.",
          "score": 1,
          "created_utc": "2026-01-28 17:05:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqior0",
      "title": "I built a playground to test MCP + Skills Pairing",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/gallery/1qqior0",
      "author": "matt8p",
      "created_utc": "2026-01-29 19:38:23",
      "score": 21,
      "num_comments": 4,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqior0/i_built_a_playground_to_test_mcp_skills_pairing/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2gvr7y",
          "author": "matt8p",
          "text": "Skills + MCP is still a fairly new concept. I would love to hear your opinions on MCP with Skills. \n\nIf you're interested in reading more about the new features we put out, I encourage you to read the blog below!\n\n[https://www.mcpjam.com/blog/skills](https://www.mcpjam.com/blog/skills)",
          "score": 3,
          "created_utc": "2026-01-29 19:41:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2gyuq4",
              "author": "Bobification",
              "text": "This is interesting timing...we have an MCP server in front of our GraphQL api and Claude consistently fails at using the right query and params despite running a schema check first.  Instead of making an attempt to make better tools, management has (just this morning) suggested we use skills to explain to Claude how to use our MCP server.  I'm not yet convinced that we should go that route ourselves but maybe at least we can attempt to test that here.",
              "score": 3,
              "created_utc": "2026-01-29 19:56:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h2e9e",
                  "author": "matt8p",
                  "text": "I'd start off by being more descriptive in the tool descriptions / tool param descriptions, or the MCP server instructions. This could give better context to Claude on how to use the server. \n\nHaving skills is nice, but the only downside is that it's not attached / bundled with the MCP server. It's loaded separately. Try tweaking the server itself first, then if that doesn't work, use the skill.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:13:11",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o2h2nxh",
                  "author": "matt8p",
                  "text": "On a tangent, I'd wish Anthropic encourage use of MCP prompts more rather than push for MCP + Skills. You can have skills be loaded up in the prompt so they're bundled together. This would accomplish the same thing.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:14:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnqm5q",
      "title": "A practical open-source repo for learning AI agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qnqm5q/a_practical_opensource_repo_for_learning_ai_agents/",
      "author": "Creepy-Row970",
      "created_utc": "2026-01-26 19:44:19",
      "score": 14,
      "num_comments": 0,
      "upvote_ratio": 0.9,
      "text": "A practical open-source repo for learning AI agents. I‚Äôve contributed 10+ examples\n\nI‚Äôve contributed 10+ agent examples to an open-source repo that‚Äôs grown into a solid reference for building AI agents.\n\nRepo:[ https://github.com/Arindam200/awesome-ai-apps](https://github.com/Arindam200/awesome-ai-apps)\n\nWhat makes it useful:\n\n* 70+ runnable agent projects, not toy demos\n* Same ideas built across different frameworks\n* Covers starter agents, MCP, memory, RAG, and multi-stage workflows\n\nFrameworks include LangChain, LangGraph, LlamaIndex, CrewAI, Agno, Google ADK, OpenAI Agents SDK, AWS Strands, and PydanticAI.\n\nSharing in case others here prefer learning agents by reading real code instead of theory.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnqm5q/a_practical_opensource_repo_for_learning_ai_agents/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qnflkf",
      "title": "MCP and Skills: Why Not Both?",
      "subreddit": "mcp",
      "url": "https://kvg.dev/posts/20260125-skills-and-mcp/",
      "author": "kurtisvg",
      "created_utc": "2026-01-26 13:10:20",
      "score": 12,
      "num_comments": 5,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnflkf/mcp_and_skills_why_not_both/",
      "domain": "kvg.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o1tqjl7",
          "author": "Block_Parser",
          "text": "Why not make skills a special type of resource `skill://` similar to `ui://`",
          "score": 2,
          "created_utc": "2026-01-26 14:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yd3w4",
              "author": "kurtisvg",
              "text": "That's definitely one approach, but I think it's a bit of shame if skills can't call tools or read files without just copying the resource locally.",
              "score": 1,
              "created_utc": "2026-01-27 03:49:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1unyli",
          "author": "Joy_Boy_12",
          "text": "What is a skill?",
          "score": 1,
          "created_utc": "2026-01-26 17:12:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yepyl",
              "author": "kurtisvg",
              "text": "There is a TL;DR in the post, but you can find the full spec here: [https://agentskills.io/home](https://agentskills.io/home)",
              "score": 1,
              "created_utc": "2026-01-27 03:59:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2d8d9c",
          "author": "p1zzuh",
          "text": "i actually just built a skill and an mcp server this week for my product\n\ni think i prefer skills. also if you're just getting started skills have a much lower barrier to entry, it's just a [SKILL.md](http://SKILL.md) file",
          "score": 1,
          "created_utc": "2026-01-29 06:32:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnntj7",
      "title": "We built Colin, a context engine that can keep agent skills fresh",
      "subreddit": "mcp",
      "url": "/r/AI_Agents/comments/1qnns7n/we_built_colin_a_context_engine_that_can_keep/",
      "author": "jlowin123",
      "created_utc": "2026-01-26 18:10:48",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnntj7/we_built_colin_a_context_engine_that_can_keep/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qpn0d5",
      "title": "LAD-A2A: How AI agents find each other on local networks",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "author": "franzvill",
      "created_utc": "2026-01-28 20:29:18",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.85,
      "text": "AI agents are getting really good at doing things, but they're completely blind to their physical surroundings.\n\nIf you walk into a hotel and you have an AI assistant (like the Chatgpt mobile app), it has no idea there may be a concierge agent on the network that could help you book a spa, check breakfast times, or request late checkout. Same thing at offices, hospitals, cruise ships. The agents are there, but there's no way to discover them.\n\nA2A (Google's agent-to-agent protocol) handles how agents talk to each other. MCP handles how agents use tools. But neither answers a basic question: how do you find agents in the first place?\n\nSo I built LAD-A2A, a simple discovery protocol. When you connect to a Wi-Fi, your agent can automatically find what's available using mDNS (like how AirDrop finds nearby devices) or a standard HTTP endpoint.\n\nThe spec is intentionally minimal. I didn't want to reinvent A2A or create another complex standard. LAD-A2A just handles discovery, then hands off to A2A for actual communication.\n\nOpen source, Apache 2.0. Includes a working Python implementation you can run to see it in action. Repo can be found at franzvill/lad.\n\nCurious what people think!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2b0ei3",
          "author": "Upstairs_Safe2922",
          "text": "Interesting stuff! Will it automatically connect or will need human final approval? Follow up, can something that was already on the network connect to the agent unprompted?",
          "score": 1,
          "created_utc": "2026-01-28 22:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2djyd9",
              "author": "franzvill",
              "text": "Human approval always required! Discovery is passive (just shows what's available), but connecting requires explicit user consent. \n\nNothing can connect to your agent unprompted as it's client-initiated and consent-gated by design. If you are curious, you can see Section 4.3 of the spec:\n\n[https://lad-a2a.org/](https://lad-a2a.org/)\n\n[https://github.com/franzvill/lad](https://github.com/franzvill/lad)",
              "score": 2,
              "created_utc": "2026-01-29 08:12:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqk0j3",
      "title": "Have I understood MCP correctly?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "author": "DoNotBelieveHim",
      "created_utc": "2026-01-29 20:26:52",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "My understanding of MCP is that I can publish details about what my REST API does, what each end point can do (\"This is for creating new clients\", \"This gives a list of overdue tasks for the current user\") and how to use the endpoints (JSON payload looks like this. \n\nBasically a subset of whats already in my OpenAPI Spec (swagger.json) with some natural langauge explanations of whats there.\n\nThis then enables LLMs to take user input in natural language (\"Create a new client call John\", \"Whats on my plate today?\") to then take actions on my server via the REST API\n\nIs that anywhere near correct or am I missing something important?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2ha2vg",
          "author": "guyernest",
          "text": "Your swagger file and other OpenAPI specs were designed for developers to use to call the API. Each developer reviewed the schema and decided what they wanted to use for their use case. You don't expect every developer to use every API call for every application.   \nAn MCP server, such as an API, can take two extreme approaches: either implement a couple of tools or allow \"code mode\". The former is similar to human developers who know what they need from the API and use only that, while the latter allows the LLM in the MCP client the freedom to call any API in any sequence.   \nMy advice is to take the middle ground and wrap a couple of the APIs as tools, based on the Pareto principle: 80% of calls will use 20% of the API. For the long tail of requests, you should enable a \"Code mode\" that provides the API schema and allows the MCP client to generate calls as needed to answer user requests.   \nThere are many security concerns for the \"Code mode\", but we some attention, you can build it safely.   \n",
          "score": 6,
          "created_utc": "2026-01-29 20:50:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hdyxe",
              "author": "DoNotBelieveHim",
              "text": "Thanks. Useful. Then it sounds like I‚Äôve not missed anything, other than that you can choose to be selective/prescriptive in how the API should be used. \n\nRe the security concerns, if the user of the LLM is authenticating themselves and has a token which the MCP uses to call the API - what are the security concerns beyond the regular concerns you‚Äôd have if a user was posting requests directly to the API? I assume you‚Äôd just pass through the bearer header or whatever you are using so the authorisation would be the same so I don‚Äôt see how the MCP could introduce new security risks.",
              "score": 1,
              "created_utc": "2026-01-29 21:09:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2huc8s",
                  "author": "guyernest",
                  "text": "MCP is an interface to your data, and it should be protected against two main types of risks: LLM mistakes and malicious users. A simple example is the option to delete data, or, less obviously, to update it. Once the user is authenticated, the MCP client stores the access token, and the MCP client can do everything that the user can do.   \nIf you only select the listUsers and getUser APIs (read-only) as MCP tools, there is not much risk that the MCP client will do anything else. However, if you also allow updateUser, the MCP client can now update the user record and grant them an unwarranted discount, for example. The MCP client typically doesn't display the full details of each call it makes to the MCP server, making it easy for users to miss such changes. Also, users might remember to log out of a sensitive website, but they will not remember to disconnect the MCP server from their ChatGPT. Therefore, a malicious user can use the MCP client connection to the MCP server and, through it, to the API to perform harmful actions on the data system. ",
                  "score": 2,
                  "created_utc": "2026-01-29 22:27:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2lrs4a",
              "author": "Melodic-Swimmer-4155",
              "text": "Really good explanation there m8!",
              "score": 1,
              "created_utc": "2026-01-30 14:05:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hlkne",
          "author": "naseemalnaji-mcpcat",
          "text": "You're basically on the right track! MCP lets you describe your API's endpoints and expected behaviors in a way that's accessible to LLM-powered agents, often with a mix of structured data and natural language. While it overlaps with OpenAPI, MCP is more focused on making your API explorable and actionable by AI agents rather than human eyeballs. One key difference is that MCP emphasizes clarity and intent in descriptions, which helps reduce ambiguity for AI.",
          "score": 3,
          "created_utc": "2026-01-29 21:45:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2igw9o",
          "author": "laresek",
          "text": "Kinda except MCP doesn't use REST/Swagger and instead uses JSON-RPC 2.0. Instead of many endpoints like in REST there's only one endpoint that's used and the payload has a method and parameters that are passed along with it. There's some info here:\n https://modelcontextprotocol.io/specification/2025-03-26/basic",
          "score": 2,
          "created_utc": "2026-01-30 00:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jiyak",
          "author": "Sufficient_Waltz4299",
          "text": "here is a video that explains this really well - [https://youtu.be/Eq21IF54VuE](https://youtu.be/Eq21IF54VuE)",
          "score": 2,
          "created_utc": "2026-01-30 03:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2klip6",
          "author": "Ordinary-You8102",
          "text": "Yes the important thing is that its a protocol (standard) so any agent that is also a mcp client will be able to connect to any MCP throughout the world (single implementation and not 1 for each Agent) \nit solves the N * M problem",
          "score": 1,
          "created_utc": "2026-01-30 08:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lh5zv",
          "author": "BC_MARO",
          "text": "Mostly yes. MCP is basically a standard way for an agent/client to talk to ‚Äútool servers‚Äù (DB/search/files/APIs) over a defined protocol (stdio/HTTP).\n\nOne practical gotcha: auth/secrets + timeouts/retries end up being the real work.\n\n(I maintain it.) Reference/checklist (peta): [https://github.com/dunialabs/peta-core](https://github.com/dunialabs/peta-core)",
          "score": 1,
          "created_utc": "2026-01-30 13:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ovbf1",
          "author": "pbalIII",
          "text": "Wrapped an internal CRUD API with MCP a few months back. The mental shift was subtle but real: OpenAPI tells developers how to call endpoints, MCP tells agents why and when to use them.\n\nOne gotcha we hit... the model kept trying to chain writes together in ways that made sense semantically but violated business rules. Ended up having to add explicit constraints in tool descriptions, not just input schemas. The reasoning layer is powerful but it needs guardrails you wouldn't think to add for human devs.\n\nThe auth question in the comments is worth digging into. MCP clients hold tokens persistently, so the blast radius of a compromised session is bigger than a user forgetting to log out of a browser.",
          "score": 1,
          "created_utc": "2026-01-30 22:40:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr8f60",
      "title": "I build an MCP UI app for interactive text rewriting and grammar improvement visualization",
      "subreddit": "mcp",
      "url": "https://i.redd.it/zldlqi0y7igg1.png",
      "author": "arif_szn",
      "created_utc": "2026-01-30 15:24:02",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qr8f60/i_build_an_mcp_ui_app_for_interactive_text/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2o0bmo",
          "author": "Melodic-Swimmer-4155",
          "text": "This feature is available for developers in Claude? I thought this was only a thing in ChatGPT",
          "score": 1,
          "created_utc": "2026-01-30 20:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oxwxl",
          "author": "matt8p",
          "text": "Really cool work! Was able to play around with it on my inspector. Tip for building an MCP app, you can try using the `registerAppTool` and resource tool from the ext-apps SDK!",
          "score": 1,
          "created_utc": "2026-01-30 22:54:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpa84z",
      "title": "HTTP2/HTTP3 support in the future?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "author": "DorkyMcDorky",
      "created_utc": "2026-01-28 12:38:07",
      "score": 8,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "Quick question for r/mcp: has anyone considered an HTTP/2 or HTTP/3 transport option for MCP, even if HTTP/1 stays the baseline? I get the tradeoffs like HTTP/1 ubiquity, stateless infra, and simpler deployment, but I am curious how folks weigh those against streaming and long lived connections.\n\nI know HTTP/2 or HTTP/3 can be a pain in cloud environments and external facing SaaS, but for internal networks and home labs it is much easier and brings real benefits like multiplexing and true streaming. Maybe MCP is mainly targeting SaaS cloud infra, but it feels like a huge miss that there is no true streaming option for internal use cases.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o27mkvy",
          "author": "Crafty_Disk_7026",
          "text": "I have grpc mcps with streaming but they are custom integrations I created and not MCP based but does the same thing.  Also I have been experimenting with codemode mcps which is not really http difference but instead executes the agent logic as a sandboxed code execution.  Te codemode flow has made the biggest improvement difference since it eliminates api round teips",
          "score": 3,
          "created_utc": "2026-01-28 13:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27mpbm",
              "author": "Crafty_Disk_7026",
              "text": "Please check out Google ADK streaming agent development workflow.  I believe this is more what you want than MCP on http2",
              "score": 1,
              "created_utc": "2026-01-28 13:37:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27ntei",
                  "author": "DorkyMcDorky",
                  "text": "My intent is to make an MCP option that's streaming that can still work with MCP clients that are standard MCP services.  To have it so if you define this spec, you get MCP serving as well.  It would be a streaming version of the MCP service.  If both clients negotiate with each other and they're both HTTP2, then they can stay that way or else downgrade to HTTP1. \n\nI'll check it out!  Thanks for perking my ears in this direction..",
                  "score": 1,
                  "created_utc": "2026-01-28 13:43:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27fksg",
          "author": "NoAdministration6906",
          "text": "‚Å†Hey, great question! I‚Äôve also been thinking about long‚Äëlived streams for internal MCP deployments. HTTP/2 (and especially HTTP/3) can unlock true multiplexing and lower‚Äëlatency streaming, but you‚Äôre right that cloud/SaaS environments often pose challenges around proxies and certs. One approach I‚Äôve seen is experimenting with WebTransport (over HTTP/3) in a home‚Äëlab setup to validate streaming performance, then rolling back to HTTP/2 or gRPC‚ÄëWeb for external/cloud contexts.",
          "score": 1,
          "created_utc": "2026-01-28 12:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27hrbj",
              "author": "DorkyMcDorky",
              "text": "Thanks. There is a gRPC transport effort, but it is a 1:1 mapping of current MCP, so it inherits the lack of true streaming. The current proto is here: [https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/](https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/) and it mirrors the MCP spec and looks good.\n\nI plan to work on a wrapper that enables HTTP/2 streaming on top of that once the gRPC transport solidifies. The idea is to keep MCP compatibility, add HTTP/2 tunneling for true streaming, and avoid multiple server implementations. I can share details if you are interested.\n\nThat is why I asked the question. Why not define an HTTP/2 option and a tunneling spec too? My guess is it would over burden the spec, and the HTTP/1 work is leaning away from streaming to keep transports compatible. That is a reasonable direction, but it leaves a gap for internal and home lab use cases.",
              "score": 1,
              "created_utc": "2026-01-28 13:09:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27zmod",
          "author": "ToHallowMySleep",
          "text": "In the context of a streaming solution to MCP, I would favour HTTP/3 over HTTP/2, simply because HTTP/2 seems to have been slept on - it was adopted by only 50% of websites at its peak and now that is already down to 35% or so, as it just didn't resonate for full bidirectional support.\n\nBrowsers are more likely to jump to HTTP/3 support, and that's going to be a strong driver for protocol adoption.",
          "score": 1,
          "created_utc": "2026-01-28 14:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bosp0",
              "author": "DorkyMcDorky",
              "text": "100% I agree with you. However the latest spec is encouraging reeling back any streaming and staying pure stateless. \n\nThey want to focus on a common layer between transfer protocols which is a good idea but they need two implementations: one that is streaming and one that is not.  \n\nPersonally, they shouldn't even have a stateless solution. I know it would be a challenge to get this far but it's clearly the future. After all nvidia's even inventing new network interfaces to replace ethernet. The protocols are already there with http3.  So they should start that spec now. \n\nIt's worth bringing this up. My voice has been exhausted, I didn't do a good job communicating this :)",
              "score": 2,
              "created_utc": "2026-01-29 00:49:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28a02s",
          "author": "naseemalnaji-mcpcat",
          "text": "A few folks I know have experimented with custom proxies or sidecar services to enable HTTP/2 streaming on top of MCP, but nothing's standardized yet. If streaming is critical for your use case, it might be worth prototyping an internal fork or raising the discussion on the MCP repo‚Äîthere's likely more demand than the current baseline suggests.",
          "score": 1,
          "created_utc": "2026-01-28 15:32:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bnty5",
              "author": "DorkyMcDorky",
              "text": "I did that. With code examples. It was grpc and they said it belongs in grpc, missing the point. So I brought up the streaming. They likely didn't understand my communication. But I dropped it, the interest and point wasn't getting the attention it needed\n\nIf you can bring it up, it might help. Feel free to reach out to them; I'd love a chorus on this.",
              "score": 1,
              "created_utc": "2026-01-29 00:43:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2929a6",
          "author": "Creamy-And-Crowded",
          "text": "Nice catch on this gap. Right now, if an MCP server is pushing a large resource, it can effectively block the entire connection until it is done...   \nA priority lane for urgent reasoning steps while the heavy data moves in the background would be much desirable.",
          "score": 1,
          "created_utc": "2026-01-28 17:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bp4xt",
              "author": "DorkyMcDorky",
              "text": "Not only that can you imagine how much cheaper it would be? Can you imagine that you can use agents in the middle of pipeline that can observe all of your logs and even react to your prompts in the middle of an answer,? There are so many use cases.",
              "score": 1,
              "created_utc": "2026-01-29 00:50:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2cfom6",
          "author": "pbalIII",
          "text": "Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases. The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nThe rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations. For internal/homelab setups where you control the infra, gRPC custom integrations (like the other commenter mentioned) work fine. But getting that into the spec would conflict with the stateless direction they're pushing.",
          "score": 1,
          "created_utc": "2026-01-29 03:16:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dx3t6",
              "author": "DorkyMcDorky",
              "text": "You summarize the tension well (with a slight clarification on the streamable option available today).\n\nYou‚Äôve touched on the fact that the MCP spec focuses on **stateless transport**. This feels like short-term gains to help massive, stateless cloud infrastructure. I agree - and that‚Äôs exactly the point of my post. They flirt with streaming but miss the opportunity; it‚Äôs a massive resource waste simply because true bidirectional streaming is difficult to deploy in large, legacy cloud infrastructure right now.  So I completely agree....\n\n... however ...\n\nAlthough MCP‚Äôs approach is \"pragmatic\" - creating an interface that *looks* like streaming - there‚Äôs no mention of how they‚Äôd ever make the jump to a real persistent transport in the future.  In fact, they're doing the opposite - removing streaming and double downing on stateless. (you touch on this too, just reiterating it for clarity)\n\nTo work around this, I use gRPC extensively already - so totally aware that streaming protocols DO exist - I'm suggesting that MCP should do that.\n\nThe downside is that it doesn‚Äôt offer an easily consumable public API for the now-popular chat protocols. However, agentic protocols like **ADK (Agent Development Kit)** or custom gRPC setups are embracing true streaming, leaving the \"popular\" MCP behind. It‚Äôs a missing scale on the dragon that I hope gets addressed.\n\n>Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases.\n\nThe **Streamable HTTP** implementation (please correct me if I‚Äôm reading the code wrong) is not \"true\" streaming because the spec is still fundamentally **cursor-based**. The chunks are collected and yielded after the fact - making it \"polling with extra steps.\" This seems intentional, but I don‚Äôt see why they can‚Äôt offer a streaming option similar to how gRPC handles bidirectional streams.  It's streaming where you need to code like it's not.  Simulating non-streaming on a streaming transfer - blocking... \n\n>The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nYes... instead of 2026 being the year of HTTP/3, we are scaling like it‚Äôs 2001. It works, but it‚Äôs putting **rockets on roller skates**.\n\n>The rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations.\n\nI get that, and it is pragmatic. But that mainly helps Google, Amazon, and Oracle while it makes us pay more in data center costs for their ease of deployment.\n\nThe current gRPC spec in the MCP ecosystem doesn't even offer true streaming; it‚Äôs just a 1:1 mapping of the MCP JSON-RPC. Again, a miss.   \n  \nSo reeling it back to my point: **MCP is not true streaming, but should be.** I‚Äôm not arguing that \"streaming-like\" behavior doesn't exist, but MCP is literally no different than the browser polling mechanisms we‚Äôve seen for 25 years.\n\nIf getting real streaming into the spec conflicts with the \"stateless direction\" they‚Äôre pushing, then the line in the sand should be clear: **MCP is for stateless utility; ADK and custom gRPC are for agentic streaming.**",
              "score": 1,
              "created_utc": "2026-01-29 10:15:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gbwub",
                  "author": "pbalIII",
                  "text": "Stateless at the transport layer, stateful at the app layer... that's basically how HTTP has worked forever. The session-as-cookie approach they're proposing isn't regression, it's unbundling concerns that got conflated when MCP was primarily local STDIO.\n\nThe gRPC angle is interesting but the hybrid pattern emerging makes more sense to me. MCP for discovery and semantics, gRPC for the hot path when you need real streaming. Google Cloud is already shipping pluggable transports in the SDK for exactly this reason.\n\nWhere I'd push back: the June 2026 spec release is targeting stateless-first, but the Transport Working Group has multi-turn SSE as an active SEP. So it's not purely abandoning streaming... it's separating the concerns. Whether that's better or worse depends on your deployment model.",
                  "score": 1,
                  "created_utc": "2026-01-29 18:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qogxy6",
      "title": "MCP Server Security Standard (MSSS)",
      "subreddit": "mcp",
      "url": "https://github.com/mcp-security-standard/mcp-server-security-standard",
      "author": "cr0hn",
      "created_utc": "2026-01-27 15:28:45",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qogxy6/mcp_server_security_standard_msss/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o25i6j2",
          "author": "barefootsanders",
          "text": "Interesting. Ive been exploring security for mcp for a bit. My efforts are way less organized than what you have here üòÖ  what are your goals for the framework? Is thus used out in the wild anywhere?",
          "score": 1,
          "created_utc": "2026-01-28 03:55:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o289dbj",
              "author": "cr0hn",
              "text": "Hey! This proposal defines security controls that security teams can check to enforce MCP security. It‚Äôs meant to be a reference framework teams can lean on",
              "score": 1,
              "created_utc": "2026-01-28 15:29:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28x83s",
          "author": "Ok_Message7136",
          "text": "This is much needed. Having a concrete, testable security baseline for MCP servers makes conversations around trust and production readiness way more actionable.",
          "score": 1,
          "created_utc": "2026-01-28 17:13:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29seip",
              "author": "cr0hn",
              "text": "Sure! And it's essential to have a reference framework for it",
              "score": 1,
              "created_utc": "2026-01-28 19:27:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qno8lg",
      "title": "Kent Dodds has an interesting metaphor about MCP vs naked API's",
      "subreddit": "mcp",
      "url": "https://v.redd.it/xkes8tw0kqfg1",
      "author": "sean-adapt",
      "created_utc": "2026-01-26 18:24:33",
      "score": 7,
      "num_comments": 10,
      "upvote_ratio": 0.71,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qno8lg/kent_dodds_has_an_interesting_metaphor_about_mcp/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1ytcqa",
          "author": "AyeMatey",
          "text": "This is still not right. \n\nIt was never right and it isn‚Äôt right now.\n\nThink about it. How does MCP work? look at the interaction diagram on the modelcontextprotocol.io website. \n\nAn agent or tool uses MCP to talk to a server to \n- ask which tools are available \n- learn about the purpose of each of the tools and how to invoke (required params and expected responses)\n- invoke tools and get responses. \n\nAn agent.  Read that again. An agent uses MCP.  What uses MCP to talk to a server ?  An AGENT.\nDoes the agent use MCP to talk to the model? No. It does not. Check the diagram on the MCP website. \n\nOk at startup the agent calls each MCP server‚Ä¶ using the MCP protocol‚Ä¶.  and says ‚Äútell me which tools you have available‚Äù.  And the MCP server ‚Ä¶. Using the MCP protocol‚Ä¶. Returns the list of tools available, back to the agent. \n\nThen, _after the agent gets the list of tools available from the MCP server (or maybe multiple)_, the agent sends to the LLM a user query along with a list of tools available. This list of tools is a transformation of the list retrieved from the servers. It is not jsonrpc , it is not MCP (the protocol). It is json.  \n\nLet me repeat that because it‚Äôs important: The agent does not use MCP to communicate with the LLM (aka model).  The model does not know about MCP. The model does not know where the tools came from.  \n\nThere is no universe in which the model will find it ‚Äúeasier‚Äù to use a tool that was originally propagated to the agent via MCP, as compared to a tool that was originally propagated to the agent via API. IT DOES NOT MAKE SENSE. \n\n\nPeople who say ‚Äúit‚Äôs easier for a model to use tools exposed via MCP‚Äù ‚Ä¶ either do not understand, or want to fool you. \n\n2nd thing - there is a bit of truth to the idea that IN THEORY, MCP allows progressive expansion of the list of tools.  \n\nIn theory. \n\nAnd in actuality, there are approximately zero concrete implementations of MCP servers that expose different sets of tools at different times to the same agent. I have seen MCP servers that expose different sets of tools to different agents, depending on the user or agent identity. But not different over time for the same identities. \n\nSo it is true that MCP, the protocol, allows for this progressive exposure of tools.  And it is also true that there‚Äôs no practical way to implement it. The MCP server does not have the context that the agent has.  The MCP server knows only that an agent (MCP client) has or has not invoked a tool. This information is not enough to produce a high quality ‚Äúprogressive‚Äù expansion of the list of tools. \n\nImagine an MCP server: ‚ÄúOh you invoked tool A? I will now tell you about tool B!‚Äù  That‚Äôs possible but that kind of interaction will starve agents of reasoning capability. The agent solves problems with the model by assembling a plan for invoking multiple tools to arrive at a solution. If the MCP server doesn‚Äôt tell the agent about all the tools, a priori, then the agent+model cannot reason through a solution. \n\nAnd why do we want this progressive release of tools anyway? What is the benefit?  As I understand, The issue is that multiple MCP servers with multiple tools each can incur a token tax. Just telling the model about the tools can consume lots of tokens. Imagining that a progressive exposure of tools will reduce on that token tax‚Ä¶ is a fantasy. That‚Äôs not what is happening in practice. \n\nIn short. This opinion is not useful. It confuses or misleads people.",
          "score": 2,
          "created_utc": "2026-01-27 05:36:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yuiiy",
              "author": "AyeMatey",
              "text": "The one key benefit of MCP over APIs that i have seen: people produce better documentation for MCP servers. And THAT is what allows an agent+model to figure out which tools to invoke.  \n\nOpenAPI specs typically have poor documentation with few examples. And the agent cannot make sense of when to call it. Or how .\n\nIf you want agents to have a better time with tools exposed as APIs‚Ä¶. Improve the documentation in the OpenAPI spec.  Add examples.",
              "score": 3,
              "created_utc": "2026-01-27 05:45:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1z46dn",
              "author": "Darnaldt-rump",
              "text": "You said does an agent use mcp to talk to a model not usually but it can, depending on how you‚Äôre building an mcp server you can have dynamic tool lists that are exposed to the agent using the mcp server. \n\nBut all of what I said it dependent on how the mcp server is developed.",
              "score": 1,
              "created_utc": "2026-01-27 07:01:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o22j7yd",
                  "author": "AyeMatey",
                  "text": "> does an agent use mcp to talk to a model not usually but it can,  \n\nNo. Still no.  Check the diagram. Agents do not talk to models via MCP. \n\nModels have their own APIs which predate MCP. The agents use the model‚Äôs api to talk to the model. Each model has a different API. Though, due to first mover advantage, the ChatGPT api is often implemented by non-ChatGPT models. \n\nIf this is not clear, i suggest that you review the documentation at modelcontextprotocol.io.\n\n> depending on how you‚Äôre building an mcp server you can have dynamic tool lists that are exposed to the agent using the mcp server.\n\nYea. I addressed that in my comment. It‚Äôs possible and rarely (if ever) actually implemented. \n\nAnd regardless, a dynamic tool list doesn‚Äôt mean an agent communicates to a model via MCP. Those are different links in the distributed architecture.",
                  "score": 1,
                  "created_utc": "2026-01-27 19:09:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o25a9md",
              "author": "DangerousSubject",
              "text": "I made an MCP server that proxies other MCP servers. Exposes two tools, findTools, loadTools. Agent chooses when to load new tools which refreshes the tool list. Multiple tool sets swapped out by the same agent in the same session.",
              "score": 1,
              "created_utc": "2026-01-28 03:10:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o28heb6",
                  "author": "AyeMatey",
                  "text": "I understand that it‚Äôs possible for an MCP server to disclose different sets of tools at different times. \n\nNow please tell me how the agent knows when it needs to do this, to load new tools.\n\nYour layered /proxied approach doesn‚Äôt change the physics. An unlayered MCP server could do the same filtering / finding. Right?  But it doesn‚Äôt matter - dynamically loaded tools or not. \n\nThe agent+LLM is responsible for reasoning through the solution to the problem. It does so with the list of tools it has available. \n\nIt does not know, a priori, what tools it needs. It‚Äôs more of an Apollo 13 thing - you know the scene where they dump a bunch of parts and materials on a desktop and say, ‚Äúok given this stuff we have available, let‚Äôs figure out how to solve the problem.‚Äù?  That is what the agent does. \n\nAnd to do that, it wants all the possible tools in the beginning. The MCP server does not participate in this reasoning phase. It has no context beyond which tools the agent has already invoked. It cannot ‚Äúknow‚Äù when it is appropriate to dribble out more tools.\n\nGrandpa teaching his 7yr old grandkid how to make a stool, knows the solution, and the steps. Grandpa can say ‚Äúok, now that you used the saw, I think you‚Äôre going to need the drill.  Do you know why?‚Äù Leading the 7 yr old to the solution. The MCP + agent relationship is not like that. The MCP server does not know the problem. Does not know the steps or the sequence of tools necessary. And before the agent sees all the tools, it cannot know that either. \n\nI‚Äôm fairly convinced but am open to counter arguments. Explain how the MCP server ‚Äúknows‚Äù when it will need to disclose additional tools, or how the agent will ‚Äúknow‚Äù which tools to ask for, before knowing all the possible tools. \n\nYou can offer as an example a ‚Äúblank slate‚Äù agent that searches for and finds tools (MCP servers)‚Ä¶ via the equivalent of a google search. that‚Äôs a possible avenue. But to make this happen , the agent has to modify its MCP server configuration after doing the search.  \n\nIn which case, there‚Äôs no point to filtering tools. Basically the solution devolves into a ‚Äúassemble tools‚Äù phase and a ‚Äúuse tools‚Äù phase and in the ‚Äúuse tools‚Äù phase, once again, tool filtering isn‚Äôt practical or beneficial to reduce the token tax. \n\nLike legos, you can attach pieces in all sorts of ways, but not all of the connections are useful or stable or sensible. Some combinations will be a hallucinogenic Picasso architecture. No bueno.",
                  "score": 1,
                  "created_utc": "2026-01-28 16:04:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qp9c1l",
      "title": "How are you running MCP servers beyond local demos?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/",
      "author": "Sumanth_077",
      "created_utc": "2026-01-28 11:54:27",
      "score": 6,
      "num_comments": 16,
      "upvote_ratio": 0.88,
      "text": "For anyone using MCP beyond quick demos, how are you running MCP servers in practice?\n\nAre you mostly:\n\n* running them locally on a workstation when they need access to files or editors\n* containerizing them and running them somewhere managed, either one per agent or shared\n* or treating them more like remote services and just calling them over HTTP\n\nEach of these seems to come with different tradeoffs around isolation, reuse, and ops overhead.\n\nI‚Äôve been looking at managed setups on Clarifai where public MCP servers are deployed as APIs and discovered by models at inference time, instead of being bundled into every runtime.\n\nCurious what people here are doing today and what‚Äôs been annoying or unexpectedly smooth.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o28fikq",
          "author": "finance-mcp-001",
          "text": "I‚Äôve dockerized my app (Python backend using FastMCP) and call it through a JS server/front end deployed on Railway. Works okay but not super scalable. Actively looking at alternatives.",
          "score": 4,
          "created_utc": "2026-01-28 15:56:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27g7nz",
          "author": "kashishhora-mcpcat",
          "text": "We have lots of customers that deploy MCP servers in a variety of different ways. The most common we've seen:\n\n* Cloudflare Workers\n* Vercel\n* Render\n* within existing cloud infra on AWS/GCP/Azure\n\nHonestly, I wouldn't overthink it and go with the simplest that you're most familiar with. The protocol was designed such that MCP servers can be deployed easily and quickly without a lot of overhead.",
          "score": 3,
          "created_utc": "2026-01-28 13:00:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29h52s",
              "author": "Electronic_Boot_1598",
              "text": "Do any of these servers support OAuth?",
              "score": 1,
              "created_utc": "2026-01-28 18:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2bj16h",
                  "author": "kashishhora-mcpcat",
                  "text": "Oauth is based on your implementation not where you deploy it. Cloudflare has a library that makes it simpler but any Oauth library should work fine",
                  "score": 1,
                  "created_utc": "2026-01-29 00:19:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27acsv",
          "author": "anywhereblue",
          "text": "I run two MCp servers publicly.   This has been smooth I run both on Render, it‚Äôs been solid.  \n\nThe first is a demo site a MCp Gane Server call [Joshua](https://joshua.lyr3.com).  \n\nThe second is a cross person AI agent collaboration environment [AiBBS](https://artifact.Lyr3.com). \n\nBoth have good descriptions or instructions on the landing pages if you have any interest in learning more.  \n\nAdditionally we have commercially deployed several commercial MCp servers for proprietary market research data.  But those are controlled access and subscriptions.",
          "score": 1,
          "created_utc": "2026-01-28 12:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28eijj",
          "author": "kduman",
          "text": "I'm building a small startup (more like a side gig) in my spare time and I had the exact same problem with running MCP servers I implement outside of local envs somehow.\n\nTo run at scale you will need to dockerize them anyway, then the deployment... well, there are options as of today, with pros and cons and it really depends on the architecture of the exact MCP servers you're about to dockerize and serve. My main pain is auth, specifically identity-related questions, especially in the context of MCP gateways.",
          "score": 1,
          "created_utc": "2026-01-28 15:52:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28ueim",
          "author": "Ok_Message7136",
          "text": "What‚Äôs worked for us is a hybrid: local MCP servers for anything that needs filesystem/editor access, and a few containerized servers for shared tools.\n\nWe usually prototype locally first, then promote the ones that stick to managed/shared setups. Keeps ops light and avoids over-engineering early.",
          "score": 1,
          "created_utc": "2026-01-28 17:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o29czvi",
          "author": "punkpeye",
          "text": "You can deploy almost any server with one-click\n\nhttps://glama.ai/mcp/servers\n\nYou can try them in inspector before deploying",
          "score": 1,
          "created_utc": "2026-01-28 18:20:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o29l4tg",
          "author": "JohnDoeSaysHello",
          "text": "Fastmcp and fargate",
          "score": 1,
          "created_utc": "2026-01-28 18:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o29xgmn",
          "author": "SmartWeb2711",
          "text": "Who have deployed MCP server in AWS and running as production grade ?",
          "score": 1,
          "created_utc": "2026-01-28 19:50:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ah8m2",
              "author": "musketyr",
              "text": "I'm running brick.directory MCP on AWS. It is production ready but I'm still waiting for the heavy load üòÖ Sincerely, it is like any other project, you should think about how to handle the thousands of connections but it's quite possible that you won't get there any time soon.",
              "score": 2,
              "created_utc": "2026-01-28 21:17:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2b6gie",
                  "author": "SmartWeb2711",
                  "text": "hey üëã thanks for your feedback, DM you ;)",
                  "score": 1,
                  "created_utc": "2026-01-28 23:13:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2abvw1",
          "author": "Upstairs_Safe2922",
          "text": "I'm somewhat in the middle. Local MCP servers are fine for demos, but I'm pretty hesitant to trust them with anything non trivial. \n\nMy preferred option is running agents/MCP servers in a sandboxed environment. Clear execution boundaries and a contained blast radius. I've been using BlueRock's sandbox, provides visibility into the runtime so I can see what happens once tools start chaining or the agent starts acting in weird ways.",
          "score": 1,
          "created_utc": "2026-01-28 20:54:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2c1feq",
          "author": "texo_optimo",
          "text": "I run my mcp servers on cloudflare. I have a governance server, a PRD to Sprint builder, and a text2image service. All cloudflare workers",
          "score": 1,
          "created_utc": "2026-01-29 01:58:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iysds",
          "author": "hasmcp",
          "text": "I am creator of HasMCP (opensource a GUI based MCP Server framework) that serves MCP's with Streamable HTTP. I would say, running someone's code non-isolated environment is always risk. Today majority of the MCP's come with STDIO(local running) option only. If you create a MCP tools on top of your APIs, you can create MCP Server with a few clicks using UI and distribute the https url instead of asking someone to install npx/python or another library. Having auth, realtime logs and telemetry is mandatory for both Streamable HTTP and STDIO approaches.  \n\n\nThere are other ways like creating virtual ones using Docker(containerized like you mentioned) or using cloud providers that deploy's the MCP servers from given library code.  \n\n  \nI think there are other questions like how are you going to handle auth, observe errors and provide fix when things are not working. For those cases I would recommend having auth layer if you are exposing with Streamable HTTP and observability layer for any of the option.",
          "score": 1,
          "created_utc": "2026-01-30 02:04:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}