{
  "metadata": {
    "last_updated": "2026-02-15 08:59:58",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 131,
    "file_size_bytes": 155474
  },
  "items": [
    {
      "id": "1r09tpd",
      "title": "5 MCPs that genuinely made me quicker",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r09tpd/5_mcps_that_genuinely_made_me_quicker/",
      "author": "Stunning-Worth-5022",
      "created_utc": "2026-02-09 17:05:38",
      "score": 410,
      "num_comments": 64,
      "upvote_ratio": 0.97,
      "text": "I have been consistently putting MCPs to use in my daily real work, not just for showing demos. Initially, these ones ignited quite a hype, and now, they have grown on me. What mattered to me: setup should be painless, they shouldnt flake out, and I should notice when theyre gone.\n\n### **GitHub MCP** [https://github.com/github/github-mcp-server](https://github.com/github/github-mcp-server)\n\nThis was the thing that really gave the agent the feel that it was working within the repo. Issues, commits, PR context, file history, all without copy, pasting links or dumping files into prompts. Seriously cant imagine doing heavy, duty work without this feature now.\n\n### **CodeGraphContext MCP** [https://github.com/CodeGraphContext/CodeGraphContext](https://github.com/CodeGraphContext/CodeGraphContext)\n\nThis one is the quiet time-saving hero. It stores a structured graph of the codebase internally at all times, so the agent is pre-equipped with an understanding of how files, functions, and classes relate to each other. Refactors and what breaks if I change this? become pretty reliable.\n\n### **Context7 MCP** [https://github.com/upstash/context7](https://github.com/upstash/context7)\n\nThis one made my agents stop guessing APIs. Whenever I request something using a library or framework, it automatically pulls the correct docs. I open docs tabs so rarely now.\n\n### **Firecrawl MCP / Jina Reader MCP** [https://github.com/mendableai/firecrawl](https://github.com/mendableai/firecrawl) [https://github.com/jina-ai/reader](https://github.com/jina-ai/reader)\n\nBoth of these are wonderful at converting dirty web pages into spotless Markdown. Great for blogs, specs, or lengthy articles where you just want the content, not the site.\n\n### **Figma MCP** [https://github.com/GLips/Figma-Context-MCP](https://github.com/GLips/Figma-Context-MCP)\n\nDesign → code, but done properly. Instead of screenshots, the agent sees real Figma structure: layouts, components, variants, tokens. Frontend output is noticeably closer to the design.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1r09tpd/5_mcps_that_genuinely_made_me_quicker/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4gygt3",
          "author": "Desperate-Ad-9679",
          "text": "Thanks for mentioning CodeGraphContext, people are now realizing how much context window aka money can be saved by simpler tweaks!! Btw, I am the maintainer of CodeGraphContext.  ",
          "score": 66,
          "created_utc": "2026-02-09 18:00:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ieq03",
              "author": "m3kw",
              "text": "How would it save context?  Tools search for the required context, this MCP does what?",
              "score": 3,
              "created_utc": "2026-02-09 22:15:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4k3cvw",
                  "author": "Desperate-Ad-9679",
                  "text": "Imagine 3 scenarios -\nYou are changing a function and want to see the impact across the entire project, grep - read - loop over all open files - read one by one. But here you just get a function call chain and can directly use it as context.\n\nAnother scenario would be the need to find dead code and refactor it, you would need to read tonnes of files to find dead code, even then lots of hallucinations could corrupt the response, here you just call a single tool.\n\nSimilarly you can find most complex functions in a single tool call to start simplifying and refactoring them rather than opening all files to find the right function",
                  "score": 1,
                  "created_utc": "2026-02-10 04:02:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4k5nxy",
              "author": "Someoneoldbutnew",
              "text": "right on, graph based memory beats the hell out of grep",
              "score": 2,
              "created_utc": "2026-02-10 04:18:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ku3zo",
                  "author": "Desperate-Ad-9679",
                  "text": "Very true",
                  "score": 1,
                  "created_utc": "2026-02-10 07:34:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4oghyc",
              "author": "jii0",
              "text": "How have I missed this one! Will definitely give it a try right now.",
              "score": 2,
              "created_utc": "2026-02-10 20:31:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ojnqs",
                  "author": "Desperate-Ad-9679",
                  "text": "Sure, would love to get your feedback!",
                  "score": 1,
                  "created_utc": "2026-02-10 20:46:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4k1pxy",
              "author": "thepreppyhipster",
              "text": "thanks for your contribution!!",
              "score": 1,
              "created_utc": "2026-02-10 03:51:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4k3evv",
                  "author": "Desperate-Ad-9679",
                  "text": "Happy to help!",
                  "score": 1,
                  "created_utc": "2026-02-10 04:03:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4kgg5u",
              "author": "Logical_Armadillo390",
              "text": "Hey, love the idea. Did you pull this data from LSPs? Given they do a similar thing. I'm not an expert, just curious.",
              "score": 1,
              "created_utc": "2026-02-10 05:36:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ku1ra",
                  "author": "Desperate-Ad-9679",
                  "text": "Thanks for your appreciation, also this data isn't pulled by LSPs but it works by using tree sitters on each file and writing custom resolution logic for each language. This lets us have a very fast speed in exchange for a little drop of accuracy. We are now also integrating SCIP (A better version of LSP) for users who prefer accuracy over speed, Python has already been integrated.",
                  "score": 3,
                  "created_utc": "2026-02-10 07:33:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o55tj07",
              "author": "siddha911",
              "text": "Hey there! Does CodeGraphContext can be integrated into Codex app?",
              "score": 1,
              "created_utc": "2026-02-13 13:34:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o566fs2",
                  "author": "Desperate-Ad-9679",
                  "text": "Yes it can be used with codex as well",
                  "score": 1,
                  "created_utc": "2026-02-13 14:44:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4gxffy",
          "author": "OnRedditAtWorkRN",
          "text": "I find the GitHub mcp grossly over rated. Historically it crowded the context window heavily, that's less of a pain point with recent mcp changes, but I still don't feel like I get any more out of it than I do with the agent using the gh cli",
          "score": 13,
          "created_utc": "2026-02-09 17:55:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i5zik",
              "author": "phil",
              "text": "Exactly. That’s the consensus at my work too. Is there any advantage at all to the GitHub MCP server over gh command line tools?",
              "score": 3,
              "created_utc": "2026-02-09 21:31:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4voch4",
              "author": "derSchwamm11",
              "text": "I recently ditched it in favor of the CLI and it’s way better! Totally agree",
              "score": 1,
              "created_utc": "2026-02-11 22:16:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4gvi0k",
          "author": "penguinzb1",
          "text": "the GitHub and CodeGraphContext combo is solid—having repo structure awareness without manually feeding context makes refactors way less fragile.\n\none thing I've noticed with MCP integrations is they can break silently when the server flakes or returns unexpected output. the agent just keeps going with stale context and you don't catch it until the PR is already wrong. we've been working on simulating these failure modes before they hit prod—helps spot when an MCP dependency is quietly degrading your workflow.\n\nContext7 is underrated for exactly the reason you mentioned. docs drift is real and having fresh reference material automatically pulled in saves so much debug time.",
          "score": 7,
          "created_utc": "2026-02-09 17:46:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hf9tb",
              "author": "Stunning-Worth-5022",
              "text": "Exactly my point!!",
              "score": 2,
              "created_utc": "2026-02-09 19:18:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kqnnm",
          "author": "Electrical_Walrus537",
          "text": "You can also try this. When I run the browser tests using it, everything works perfectly. [Browser devtools mcp](https://www.npmjs.com/package/browser-devtools-mcp)",
          "score": 4,
          "created_utc": "2026-02-10 07:02:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h0xzd",
          "author": "BC_MARO",
          "text": "Context7 is the one I keep recommending to people. The number of times I've watched an agent hallucinate an API that doesn't exist anymore because it's working off training data from 2 years ago... Context7 basically kills that problem.\n\nI'd also throw in the sequential thinking MCP if you haven't tried it. For multi-step refactors where the agent needs to plan before executing, it keeps things way more coherent than just letting it go step by step.",
          "score": 4,
          "created_utc": "2026-02-09 18:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4l2ewj",
              "author": "cellulosa",
              "text": "Do you need to tell the agent to use it explicitly? And does it know which exact documentation to pick?",
              "score": 1,
              "created_utc": "2026-02-10 08:54:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mkjnj",
                  "author": "BC_MARO",
                  "text": "Usually yes: unless your agent has an automatic tool-selection policy, you’ll want to explicitly instruct it to use Context7 (e.g. “use Context7 for the current docs before answering / coding”).\n\nFor picking the right docs, don’t rely on it guessing. Give it an unambiguous target: package/repo name + version (or a specific URL/commit/branch). If you only say “the docs”, it may grab a close match and you’re back to stale APIs.",
                  "score": 1,
                  "created_utc": "2026-02-10 15:16:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4pm7r6",
                  "author": "BC_MARO",
                  "text": "In practice, yes: you get much more reliable behavior if you tell the agent when to call the tool (a simple rule + 1-2 examples goes a long way).\n\nOn docs: it usually won’t pick the right page on its own. I either scope a docs/search tool to the exact docs set (so retrieval does the routing), or I give it an explicit “docs index” mapping in the tool description (feature -> URL/section). If there are multiple versions, make the version rule explicit too.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:00:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4guawv",
          "author": "sorvendral",
          "text": "Nice ones thanks bro",
          "score": 2,
          "created_utc": "2026-02-09 17:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xj9ha",
          "author": "Same_Wall1200",
          "text": "Thank you for sharing. I'm going check these in [mcp-trust.com](http://mcp-trust.com) to better understand the security profiles of these servers. I've been working on my first few agents and selecting MCP servers has been a challenge. \n\n  \nDef want to check out CodeGraphContext next!",
          "score": 2,
          "created_utc": "2026-02-12 04:58:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h08o9",
          "author": "Important_Storage123",
          "text": "Which Figma MCP is better? This one or the Official from Figma itself?",
          "score": 1,
          "created_utc": "2026-02-09 18:08:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hepap",
              "author": "Stunning-Worth-5022",
              "text": "I think this one worked for me better!",
              "score": 1,
              "created_utc": "2026-02-09 19:16:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4h8pji",
          "author": "stibbons_",
          "text": "I do not see the use of codeCraphContext, Claude code or viscose copilot are both excellent at analyzing the code. And in vscode it has access to the language server.\n\nContext7: still no free equivalent for internal libraries ?",
          "score": 1,
          "created_utc": "2026-02-09 18:47:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hf76t",
              "author": "Stunning-Worth-5022",
              "text": "I have used Antigravity, claude code, and cursor for my work but had a terrible experience when working on large codebases. All of them started hallucinating and consuming tonnes of tokens just to find the right function to edit or the right file to find an implementation. This helped me find the right context across those files clutter, hence recommended.",
              "score": 1,
              "created_utc": "2026-02-09 19:18:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hcnbk",
          "author": "Maasu",
          "text": "Oh I just wrote my own version of code graph context, will check that out as it's likely done a better job. Can't remember if I looked at it or not, maybe I did but it didn't support vb.net which I have a use case for. \n\nOnly thing is add to the list is a memory mcp, I wrote my own version of that as well. Genuinely did write it as well as it was before opus 4.5 when I felt comfortable letting the models take the reigns. I do use AI to maintain it these days.",
          "score": 1,
          "created_utc": "2026-02-09 19:06:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hjdc4",
          "author": "NebulaNavigator2049",
          "text": "ChromeDevTools anyone?",
          "score": 1,
          "created_utc": "2026-02-09 19:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bx0we",
              "author": "monxas",
              "text": "There’s now playwright-cli, and you always want to go cli above mcp if you can. It’ll work faster, better and cheaper.",
              "score": 1,
              "created_utc": "2026-02-14 12:36:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4i14xz",
          "author": "GentoroAI",
          "text": "thanks! figma MCP is great",
          "score": 1,
          "created_utc": "2026-02-09 21:07:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iuqxz",
          "author": "brads0077",
          "text": "I would add Docker MCP Server",
          "score": 1,
          "created_utc": "2026-02-09 23:39:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iz32o",
          "author": "TheLostWanderer47",
          "text": "Good picks. I’d add a web access MCP for cases where agents need live data. We’ve used one ([Bright Data MCP Server](https://github.com/brightdata/brightdata-mcp)) to keep browsing and extraction consistent instead of wiring custom scrapers per project. Low effort, high reliability.",
          "score": 1,
          "created_utc": "2026-02-10 00:04:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j1v92",
          "author": "an80sPWNstar",
          "text": "I use searxng for the web search and it has been solid.",
          "score": 1,
          "created_utc": "2026-02-10 00:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j22xt",
          "author": "nooruponnoor",
          "text": "Have you compared Github CLI vs MCP?",
          "score": 1,
          "created_utc": "2026-02-10 00:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4je24y",
          "author": "TrvlMike",
          "text": "How’s token usage on them though?",
          "score": 1,
          "created_utc": "2026-02-10 01:30:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ltn6e",
              "author": "Stunning-Worth-5022",
              "text": "GitHub consumes the most, whereas codegraphcontext and context7 are comparatively on the lower end, based on the functionalities they provide",
              "score": 2,
              "created_utc": "2026-02-10 12:47:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lw3jr",
                  "author": "TrvlMike",
                  "text": "Thanks! Your post finally got me to install Context7 too",
                  "score": 1,
                  "created_utc": "2026-02-10 13:03:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4klvi9",
          "author": "Bulky_Ad738",
          "text": "Hey all,\n\nDo you think an MCP to help you save your best prompts, skill, agents, UI/UX, tech stack etc, in your own library **right from your terminal or IDE** would be useful?\n\nLike imagine you're in your project, and you came up with a great and refined prompts to format a document. You just ask the agent to save it and it's done. Or maybe you created a beautiful UI and you want to save the details. Just tell your agent to do it and it's save for future use.\n\nSame if you want to retrieve anything from the library. Just ask your agent.\n\nIs it useful?",
          "score": 1,
          "created_utc": "2026-02-10 06:20:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nd7gk",
          "author": "Pitiful-Minute-2818",
          "text": "Greb mcp really good i mean it does what code graph mcp does but without indexing overhead",
          "score": 1,
          "created_utc": "2026-02-10 17:30:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ob0q3",
          "author": "mugiltsr",
          "text": "Reg GitHub MCP,  why can't we clone the repo and analyse using AI agent locally ?",
          "score": 1,
          "created_utc": "2026-02-10 20:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4olu0v",
          "author": "NikolaiAce",
          "text": "Thank you",
          "score": 1,
          "created_utc": "2026-02-10 20:56:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uw5po",
          "author": "Horror_Turnover_7859",
          "text": "You should check out the Limelight MCP. It gives your AI full app runtime context: [limelight-mcp](https://docs.getlimelight.io/mcp/installation)",
          "score": 1,
          "created_utc": "2026-02-11 19:59:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w8n9k",
          "author": "AryanDuntley",
          "text": "Let AI do the coding for you. Just watch (Directive based MCP Server)\n\nThis is best for new projects as it forced AI to code in pure functions (Functional Procedural) with DRY principles, no OOP crap. Complete project management without contextual noise. Sqlite record of every file, every function, every type, interactions, themes, flows, completion path, milestones, task/subtask/sidequest/ and notes for logging important events.\n\nAfter aifp\\_init is used to create the full blueprint and design specs for your project, just let AI do the rest. At any new session, no need to provide context, just say \"continue\" and AI will know exactly where it left off and continue from that point.\n\nIt's directive based so the code is primarily CRUD operations. Actions and direction are just text directives telling AI how it should act and when.\n\nFor those who want to \"just let AI do the coding\" without constant babysitting. Free, open source. Welcome forkers, contributors, users, reviewers, issues, etc. \n\n[https://github.com/aryanduntley/AIFP](https://github.com/aryanduntley/AIFP)",
          "score": 1,
          "created_utc": "2026-02-12 00:05:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y83k3",
          "author": "AyushW",
          "text": "We also built: onecompiler MCP \nIt has tool: code_exec.\n\nIt can take code string and execute code against any language/db/framework.\n\nExtremely useful for grounding, where LLM can make use of code to figure out answers.\n\nFrom as simple as: mathematical reasoning to complex reporting calculations.\n\nhttps://www.reddit.com/r/mcp/comments/1r17zcp/onecompiler_apis_mcp_server_enables_code/",
          "score": 1,
          "created_utc": "2026-02-12 08:39:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yr1je",
          "author": "saberbj",
          "text": "Solid list thanks for sharing",
          "score": 1,
          "created_utc": "2026-02-12 11:38:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57uw59",
          "author": "HarjjotSinghh",
          "text": "i love that mcp's magic feels like walking into a repo treasure room",
          "score": 1,
          "created_utc": "2026-02-13 19:35:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a2532",
          "author": "upvotes2doge",
          "text": "Codegraphcontext looks promising. I’ll try",
          "score": 1,
          "created_utc": "2026-02-14 02:59:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bwb7t",
          "author": "monxas",
          "text": "GitHub mcp brings no valueeeeeeee! So frustrating. Git is dominated by llms by now. Any extra functionality exclusive for GitHub, make it use gh-cli. It’s way way better, faster and cheaper.",
          "score": 1,
          "created_utc": "2026-02-14 12:31:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2m7ev",
      "title": "Chrome’s WebMCP makes AI agents stop pretending",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r2m7ev/chromes_webmcp_makes_ai_agents_stop_pretending/",
      "author": "jpcaparas",
      "created_utc": "2026-02-12 06:31:57",
      "score": 199,
      "num_comments": 26,
      "upvote_ratio": 0.93,
      "text": "[Google Chrome 145](https://developer.chrome.com/release-notes/145) just shipped an experimental feature called [WebMCP](https://developer.chrome.com/blog/webmcp-epp).\n\nIt's probably one of the *biggest deals* of early 2026 that's been buried in the details.\n\nWebMCP basically lets websites **register tools that AI agents can discover and call directly**, instead of taking screenshots and parsing pixels.\n\nLess tooling, more precision.\n\nAI agents tools like [agent-browser](https://jpcaparas.medium.com/give-your-coding-agent-browser-superpowers-with-agent-browser-ae3df40ff579) currently browse by rendering pages, taking screenshots, sending them to vision models, deciding what to click, and repeating. Every single interaction. 51% of web traffic is already bots doing exactly this (per Imperva's latest report).\n\nEdit: I should clarify that agent-browser doesn't need to take screenshots by default but when it has to, it will (assuming the model that's steering it has a vision LLM).\n\nHalf the internet, just... screenshotting.\n\nWebMCP flips the model. Websites declare their capabilities with structured tools that agents can invoke directly, no pixel-reading required. Same shift fintech went through when Open Banking replaced screen-scraping with APIs.\n\nThe spec's still a W3C Community Group Draft with a number of open issues, **but Chrome's backing it and it's designed for progressive enhancement.**\n\nYou can add it to existing forms *with a couple of HTML attributes.*\n\nI wrote up how it works, which browsers are racing to solve the same problem differently, and when developers should start caring.\n\n[ https://extended.reading.sh/webmcp ](https://extended.reading.sh/webmcp)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r2m7ev/chromes_webmcp_makes_ai_agents_stop_pretending/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4z2kc4",
          "author": "Plastic-Ad9036",
          "text": "Pretty sure your premise is off. Playwright, for example, just interacts with the DOM of your webpage. It can take screenshots as well but that’s not what it uses to navigate…",
          "score": 15,
          "created_utc": "2026-02-12 13:01:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54qvmp",
              "author": "lambdawaves",
              "text": "That’s quite difficult when the page is mostly JavaScript.",
              "score": 2,
              "created_utc": "2026-02-13 08:25:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d3h36",
                  "author": "brandly",
                  "text": "Even if the DOM is constructed with JS, it can still interact with that DOM",
                  "score": 1,
                  "created_utc": "2026-02-14 16:42:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4z6wd3",
              "author": "Baseradio",
              "text": "Yeah, hows this different from playwright mcp",
              "score": 1,
              "created_utc": "2026-02-12 13:28:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51f4lt",
                  "author": "jpcaparas",
                  "text": "Playwright MCP uses a fuckton of tokens because it's an MCP server.\n\nI've written a bit of it here:  \n[https://blog.devgenius.io/give-your-coding-agent-browser-superpowers-with-agent-browser-ae3df40ff579?sk=97313824ffc1bbdfcded0bf5b54c1e7c](https://blog.devgenius.io/give-your-coding-agent-browser-superpowers-with-agent-browser-ae3df40ff579?sk=97313824ffc1bbdfcded0bf5b54c1e7c)\n\nTidbits:  \n`agent-browser` *claims* to use 93% less context than Playwright MCP.\n\n\\[...\\]\n\nWhen an AI assistant uses tools, each tool call consumes context (the limited memory the AI has for your conversation). Playwright MCP exposes 26+ different tools to your AI. Every time the AI considers what action to take, it has to process all those options\n\nagent-browser takes a different approach. Instead of exposing dozens of specialised tools, it provides a handful of streamlined commands that cover the same functionality. Fewer tools means less context overhead, which means your AI can focus on your actual task rather than managing browser automation complexity.",
                  "score": 0,
                  "created_utc": "2026-02-12 19:58:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o51ewf9",
              "author": "jpcaparas",
              "text": "Yep you're correct, have updated the post for clarity",
              "score": 1,
              "created_utc": "2026-02-12 19:57:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y4a7a",
          "author": "blaesten",
          "text": "Cool! It’s like CopilotKit is trying to do, but it’s directly in the browser instead of in your own code. And available to any LLM browsing the site.",
          "score": 11,
          "created_utc": "2026-02-12 08:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y8iap",
          "author": "Humasara",
          "text": "What is the difference between this and NLWeb ?\nIf i'm not mistaking, NLWeb is also a MCP server.",
          "score": 2,
          "created_utc": "2026-02-12 08:44:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51cz3c",
          "author": "constarx",
          "text": ">AI agents tools like [agent-browser](https://jpcaparas.medium.com/give-your-coding-agent-browser-superpowers-with-agent-browser-ae3df40ff579) currently browse by rendering pages, taking screenshots, sending them to vision models, deciding what to click, and repeating. Every single interaction. 51% of web traffic is already bots doing exactly this (per Imperva's latest report).\n\nThat is not at all how agent-browser works. It uses accessibility snapshots to find interactable elements, no screenshot involved.",
          "score": 2,
          "created_utc": "2026-02-12 19:48:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51dpx1",
              "author": "jpcaparas",
              "text": "It CAN take screenshots when it needs to and send to  vision LLM/s when navigation isn't straightforward. \n\nBy default it doesn't need to.\n\nEdit: Have updated the post",
              "score": 0,
              "created_utc": "2026-02-12 19:51:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zjvgd",
          "author": "kaizer1c",
          "text": "I can't read it because I am not a premium Medium member. Your link didn't work. Can you share it any other manner?",
          "score": 1,
          "created_utc": "2026-02-12 14:39:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51fad5",
              "author": "jpcaparas",
              "text": "[https://medium.com/reading-sh/chromes-webmcp-makes-ai-agents-stop-pretending-e8c7da1ba650?sk=f729fbaf4c5b2a973fef3e64bda46956](https://medium.com/reading-sh/chromes-webmcp-makes-ai-agents-stop-pretending-e8c7da1ba650?sk=f729fbaf4c5b2a973fef3e64bda46956)\n\nPlease try this out. ",
              "score": 2,
              "created_utc": "2026-02-12 19:59:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5c29hz",
                  "author": "Wlad-",
                  "text": "u/jpcaparas  vielen lieben Dank!",
                  "score": 1,
                  "created_utc": "2026-02-14 13:15:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zsh1m",
          "author": "Chemical_Raisin_7951",
          "text": "This will actually push browser-based agents a lot. I saw a demo somewhere, but it required enabling a [chrome://flags](chrome://flags) setting, so I didn’t really follow up. If this becomes default, we will start seeing proper agent workflows",
          "score": 1,
          "created_utc": "2026-02-12 15:22:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o568zo7",
          "author": "paca-vaca",
          "text": "If the website owner has to do that how's it different from exposing the API? \n\nScreenshots/accessibility parsing works independently of the website owner desire to expose it to the agent world.",
          "score": 1,
          "created_utc": "2026-02-13 14:56:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56iytj",
          "author": "GregBreak",
          "text": "What happen if website doesn't expose any tool?",
          "score": 1,
          "created_utc": "2026-02-13 15:45:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56ui97",
              "author": "Beginning-Foot-9525",
              "text": "What is when it is a bad tool, and collects all the data? \nWell what prevents phishing sites from using it?",
              "score": 1,
              "created_utc": "2026-02-13 16:40:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zc24u",
          "author": "OkLettuce338",
          "text": "How does this differ meaningfully from the llms.txt protocol? Most sights that want to be accessible to llms just post one of those",
          "score": 1,
          "created_utc": "2026-02-12 13:57:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ycn45",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-02-12 09:24:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yfd6z",
              "author": "slamdeathmetals",
              "text": "You should look up, star and fork the ImAFuckingPrick MCP server. Helps people who don't know how to socialize with other human beings to not be such assholes.",
              "score": 6,
              "created_utc": "2026-02-12 09:52:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4ydnbt",
              "author": "jpcaparas",
              "text": "I don't really mind if you don't read it. I'm not forcing anyone to read it and you can be less nasty about phrasing it too.  \n\nIt's ultimately up to discretion of the orchestrator (yourself or the agent) if agent-browser will take a screenshot and send it over for multiprocessing to a vision llm apart from the default i claude. \n\ni do. in my use case, I do send over the screenshots to minimax and zai because I want to get competing interpretations (mostly for research purposes and not for multi-turn scenarios), and it's pretty quick in doing that because of subagents. \n\n(although I admit I could have made it clearer that that my use case isn't everyone else's use case)",
              "score": 3,
              "created_utc": "2026-02-12 09:35:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r17v3k",
      "title": "We scanned over 8000+ MCP Servers... here's what we found",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r17v3k/we_scanned_over_8000_mcp_servers_heres_what_we/",
      "author": "Upstairs_Safe2922",
      "created_utc": "2026-02-10 17:55:54",
      "score": 86,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Over the past few months we’ve been running the [MCP Trust Registry](http://mcp-trust.com/), an open scanning project looking at security posture across publicly available MCP server builds.\n\nWe’ve analyzed 8,000+ servers so far using 22 rules mapped to the OWASP MCP Top 10.\n\nSome findings:\n\n* \\~36.7% exposed unbounded URI handling → SSRF risk (same class of issue we disclosed in Microsoft’s Markitdown MCP server that allowed retrieval of instance metadata credentials)\n* \\~43% had command execution paths that could potentially be abused\n* \\~9.2% included critical-severity findings\n\nWe just added private repo scanning for teams running internal MCP servers. Same analysis, same evidence depth. Most enterprise MCP adoption is internal, so this was the #1 request.\n\nInterested to know what security review processes others have for MCP servers, if any. The gap we keep seeing isn’t intent, it’s that MCP is new enough that standard security gates haven’t caught up.\n\nHappy to share methodology details or specific vuln patterns if useful.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1r17v3k/we_scanned_over_8000_mcp_servers_heres_what_we/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4o3l1f",
          "author": "kramit",
          "text": "Thanks to AI, I don't think its \"Move fast and break things\" anymore. I think we need a new phrase. \"Move so fast that you break everything to the point of massive dumpster fire\"",
          "score": 11,
          "created_utc": "2026-02-10 19:30:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oeb62",
              "author": "Upstairs_Safe2922",
              "text": "Lol we've seen a few teams adopt that mindset. At least they get to call themselves \"first adopters\"",
              "score": 1,
              "created_utc": "2026-02-10 20:20:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pp6pp",
          "author": "_blkout",
          "text": "Three prompts in and you have to wait until next Tuesday 2046",
          "score": 6,
          "created_utc": "2026-02-11 00:17:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pr591",
          "author": "Left_Fieldhitem",
          "text": "Would love to hear the methodologies",
          "score": 3,
          "created_utc": "2026-02-11 00:28:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pxugc",
              "author": "Upstairs_Safe2922",
              "text": "We built an agentic system that dynamically monitors new security issues related to MCP server implementations, using sources such as the OWASP Top 10, MAESTRO, and other MCP security standards. From those best practices, we distilled an initial set of 22 evaluation rules which we then instruct our system to evaluate each and every MCP server repository against. Multiple agents evaluate the source code against a combination of SAST and DAST tools with the specific intent of gathering sufficient evidence as to whether the repo has one or more security findings based on each evaluation rule. For each vulnerable finding, our system proposes practical fixes that the MCP repo creator can take to improve the operational security of the implementation as well as mitigations any MCP server operator can take if they choose to deploy the server themselves.\n\nOne of the biggest issues facing the MCP server ecosystem, is that there may be many different implementations of the same server -- some repos are clearly more secure than others. The goal of this trust registry is to help both MCP server owners and operators safely build and deploy MCP servers.",
              "score": 2,
              "created_utc": "2026-02-11 01:07:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5b6ex9",
                  "author": "iloos",
                  "text": "Love this.\n\nDo you mind sharing thw evaluation rules or guideline set?\n\nI would love to integrate it into my own agentic software development flows to prevent these unsafe outcomes.",
                  "score": 1,
                  "created_utc": "2026-02-14 08:27:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4qz9xp",
          "author": "NoAdministration6906",
          "text": "This is exactly the kind of infrastructure the MCP ecosystem needs. The 22-rule evaluation framework based on OWASP + MAESTRO is solid. One question: are you differentiating between server-side vulnerabilities (the MCP implementation itself) vs client-side risks (what happens when a malicious MCP server responds to a trusted client)? We've been thinking about this from the testing/CI angle — automated security gates before MCP servers get deployed to production.",
          "score": 3,
          "created_utc": "2026-02-11 05:07:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t45pa",
              "author": "Upstairs_Safe2922",
              "text": "Great question. The Trust Registry focuses strictly on server-side vulnerabilities. It covers issues with the MCP implementation itself, such as SSRF or unsafe execution paths.\n\nWhat you’re describing on the client-side is absolutely a real problem space. That’s largely why our Agentic Observability Sandbox exists. Goal is to provide visibility and containment at the execution layer rather than analyze server code.\n\nWe view these as complimentary controls addressing different failure models\n\n100% agree on CI/Testing angle. Majority of what we see are trust-boundary issues.",
              "score": 1,
              "created_utc": "2026-02-11 14:58:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o51nap9",
          "author": "Sea_Platform8134",
          "text": "Can you also scan for Env Vars, tools list and what type of server it is, if it is a local one and so on? That would create so much value.",
          "score": 3,
          "created_utc": "2026-02-12 20:37:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51wka1",
              "author": "Upstairs_Safe2922",
              "text": "We scan for tools and identify which type of server it is. Env variables depends, if it's to do with secrets detection then we support out of the box. If you had something else in mind would need more context to give you an accurate answer.",
              "score": 1,
              "created_utc": "2026-02-12 21:21:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o51xr38",
                  "author": "Sea_Platform8134",
                  "text": "Very nice is the list open? Can you write me a PM?",
                  "score": 2,
                  "created_utc": "2026-02-12 21:26:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4v0m3r",
          "author": "BC_MARO",
          "text": "nice dataset.\n\na gateway can block a lot (tool allowlists, outbound url restrictions, sandboxed exec, strict schemas), but it can’t fix everything: some ssrf/command paths live inside the server implementation, and a malicious server can still feed your client toxic prompts/data.\n\ni’ve had best results with runtime secret injection + policy/approvals for high-risk tools + ci rules that reject servers without bounded inputs. that’s basically what we built into peta (mcp vault + gateway).\n\nwould love to see the 22-rule list if you can share.",
          "score": 2,
          "created_utc": "2026-02-11 20:21:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vnpyw",
              "author": "haroldatbluerock",
              "text": "the rule list is viewable in any of the findings at mcp-trust\\[.\\]com which is free and open.\n\nFor example, the Ollama MCP Server RCE vulnerability (CVE2025-15063) is something that we detected in scans and have remediation guidance around.\n\nFrom our rule for that specific server: Multiple tools (`serve`, `create`, `show`, `pull`, `push`, `list`, `cp`, `rm`) use `execAsync` with template string interpolation, directly injecting unsanitized user inputs into shell commands. This enables arbitrary OS command execution.\n\nThere are other rules such as the following:\n\n\\- Static secrets / .env reliance  \n\\- Unrestricted Network Fetch / SSRF  \n\\- Path Traversal\n\nAgain, all viewable in the registry.",
              "score": 3,
              "created_utc": "2026-02-11 22:12:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wm6xc",
                  "author": "BC_MARO",
                  "text": "thanks. do you have an exportable json feed (or api) for the findings/rules? would be really handy to wire into CI so builds fail if a server trips a rule.",
                  "score": 1,
                  "created_utc": "2026-02-12 01:25:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4vv0gy",
              "author": "Upstairs_Safe2922",
              "text": "Great response. You are right on the money in regard to gateways. Very interesting idea with runtime secret injection. Will give peta a look. We are focused on the execution layer as well via an agentic observability sandbox. Since we live in the infrastructure we can constrain both tool calls and runtime actions in line along with alerting to any unexpected/malicious activity.\n\nWill default to u/haroldatbluerock's answer when it comes to the 22 rules.",
              "score": 3,
              "created_utc": "2026-02-11 22:50:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4wm2xz",
                  "author": "BC_MARO",
                  "text": "execution-layer sandbox is where it gets real. if you end up publishing the 22-rule list or any writeup on the observability approach, please drop a link. would love to compare it to the checks we’ve been using.",
                  "score": 1,
                  "created_utc": "2026-02-12 01:25:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o517nl1",
          "author": "BC_MARO",
          "text": "Thanks, that helps a lot. The per-scan findings + the awesome-llm-apps example make it click. Looking forward to the observability writeup.",
          "score": 2,
          "created_utc": "2026-02-12 19:22:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4shaxk",
          "author": "The_frogs_Scream",
          "text": "Zoho mcp needs love",
          "score": 1,
          "created_utc": "2026-02-11 12:50:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sq7ax",
          "author": "Nshx-",
          "text": "Couldn't security be implemented in the gateways so that even if an MCP isn't secure, the gateway still protects it?",
          "score": 1,
          "created_utc": "2026-02-11 13:43:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t1q90",
              "author": "Upstairs_Safe2922",
              "text": "That tends to be the industry standard approach but gateway's limitation is that they only see requests at the boundary. They provide no visibility into the execution layer.\n\nEven if all the tool calls an agent makes are \"approved\" they can be chained together, either unintentionally or maliciously, into unexpected outcomes. Without visibility into the runtime you’re effectively trusting that tool selection alone guarantees safe behavior, which it doesn't.\n\nFor example, we discovered a [SSRF vulnerability in Microsoft's MarkItDown MCP](https://www.bluerock.io/post/mcp-furi-microsoft-markitdown-vulnerabilities) that invoked tools, that from a gateway's perspective look valid. However, at runtime, the server could be steered into retrieving instance metadata credentials. This failure occurred inside the execution, not at the perimeter.\n\nThis is the type of problem we've been exploring with our Agentic Observability Sandbox. Focus is on execution level visibility and containment rather than perimeter controls.",
              "score": 2,
              "created_utc": "2026-02-11 14:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tft8m",
                  "author": "Nshx-",
                  "text": "thanks for explain :)",
                  "score": 2,
                  "created_utc": "2026-02-11 15:55:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4w8nsx",
          "author": "AryanDuntley",
          "text": "Let AI do the coding for you. Just watch (Directive based MCP Server)\n\nThis is best for new projects as it forced AI to code in pure functions (Functional Procedural) with DRY principles, no OOP crap. Complete project management without contextual noise. Sqlite record of every file, every function, every type, interactions, themes, flows, completion path, milestones, task/subtask/sidequest/ and notes for logging important events.\n\nAfter aifp\\_init is used to create the full blueprint and design specs for your project, just let AI do the rest. At any new session, no need to provide context, just say \"continue\" and AI will know exactly where it left off and continue from that point.\n\nIt's directive based so the code is primarily CRUD operations. Actions and direction are just text directives telling AI how it should act and when.\n\nFor those who want to \"just let AI do the coding\" without constant babysitting. Free, open source. Welcome forkers, contributors, users, reviewers, issues, etc. \n\n[https://github.com/aryanduntley/AIFP](https://github.com/aryanduntley/AIFP)",
          "score": 1,
          "created_utc": "2026-02-12 00:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bbl4r",
          "author": "Prestigious-Way-1878",
          "text": "Yes please can you share the methodology and vulnerability patterns",
          "score": 1,
          "created_utc": "2026-02-14 09:17:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r262kx",
      "title": "MCP tool discovery problem at scale - how we handle 50+ servers in Bifrost MCP gateway",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r262kx/mcp_tool_discovery_problem_at_scale_how_we_handle/",
      "author": "dinkinflika0",
      "created_utc": "2026-02-11 18:54:44",
      "score": 45,
      "num_comments": 7,
      "upvote_ratio": 0.8,
      "text": "I maintain Bifrost ([OSS](https://git.new/bifrost)). Working on MCP integration and the discovery problem gets messy past 10-15 servers.\n\n**The tool namespace collision:** Multiple MCP servers exposing tools with similar names. \"search\\_files\" from filesystem server vs \"search\\_files\" from Google Drive server. LLM picks the wrong one, user gets unexpected results.\n\nOur fix: namespaced tools. Each server gets a prefix - `filesystem.search_files` vs `gdrive.search_files`. LLM sees explicit tool sources, makes better decisions.\n\n**The schema bloat problem:** 50 MCP servers = 200+ tools. Dumping all tool schemas into every request blows up context windows. Token costs spike, latency increases.\n\nSolution: dynamic tool filtering. Virtual keys define which tools are available per agent/workflow. Agent only sees relevant tools, not the full catalog.\n\n**The connection lifecycle hell:** MCP servers crash, hang, or become unresponsive. Requests timeout waiting for dead servers.\n\nWe health-check servers before routing. Failed health checks exclude that server temporarily, retry periodically to restore when recovered.\n\n**The cross-server orchestration gap:** Agent needs data from server A to call tool on server B. No built-in way to handle this in MCP protocol.\n\nAdded \"Code Mode\" where LLM writes TypeScript to orchestrate multiple tools across servers. Cuts latency 40% vs back-and-forth tool calls.\n\nDocs: [docs.getbifrost.ai/mcp/overview](http://docs.getbifrost.ai/mcp/overview)\n\nHow are you handling tool discovery with multiple MCP servers? Namespacing or different approach?",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1r262kx/mcp_tool_discovery_problem_at_scale_how_we_handle/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4v1lh4",
          "author": "BC_MARO",
          "text": "namespacing + dynamic tool sets is exactly where we landed too.\n\na couple extra tricks that helped us once we crossed \\~50 servers:\n\n- store tool metadata in a registry and only ship \\*descriptions\\* by default; fetch full json schema on-demand for the 3-10 tools that survive routing\n- add a “capabilities” tag per tool (io, net, exec, secrets) so the router can hard-filter by policy before the model even sees them\n\nalso +1 on health checks. a gateway that can’t degrade cleanly turns into random failures fast.",
          "score": 2,
          "created_utc": "2026-02-11 20:26:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x0xv8",
          "author": "private_final_static",
          "text": "What do you mean virtual keys for dynamic tool filtering?",
          "score": 1,
          "created_utc": "2026-02-12 02:54:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yq287",
              "author": "HorrorEastern7045",
              "text": "\\+1",
              "score": 1,
              "created_utc": "2026-02-12 11:30:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o525fi8",
              "author": "DangerousSubject",
              "text": "Probably depends on a proxy layer and a refresh of the tools list on the client side.",
              "score": 1,
              "created_utc": "2026-02-12 22:03:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o528tcb",
          "author": "PutPrestigious2718",
          "text": "When all you have is a gateway…\n\nThese problems are solvable by splitting agents into delegations and domain expertise. \n\nMcp is not a silver bullet.",
          "score": 1,
          "created_utc": "2026-02-12 22:20:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vig67",
          "author": "HarjjotSinghh",
          "text": "bifrost: 50 servers = one giant namespace nightmare",
          "score": 0,
          "created_utc": "2026-02-11 21:47:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3zm5j",
      "title": "Presentation generator MCP server - turn your AI agent into a deck builder",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r3zm5j/presentation_generator_mcp_server_turn_your_ai/",
      "author": "getalai",
      "created_utc": "2026-02-13 20:06:11",
      "score": 40,
      "num_comments": 3,
      "upvote_ratio": 0.75,
      "text": "We launched Alai's MCP server a few weeks back and it's been crazy to see the workflows users and even our internal team have built from it. Wanted to share some of the common/useful ones that I feel could be helpful.\n\nIt connects to Claude Desktop, Cursor, Windsurf, VS Code, and most other MCP clients. Setup takes a couple minutes, just grab an API key from [app.getalai.com](https://app.getalai.com/) and add the config to your client. Full docs here: [docs.getalai.com/api/mcp](https://docs.getalai.com/api/mcp)\n\nThe real power is combining it with other MCP servers. Here are some workflows we've been seeing:\n\n**Research → Deck in one conversation** Ask your agent to research a topic, refine an outline together, then say \"now create this as a presentation.\" No context switching, no copy-pasting between apps.\n\n**Internal docs → Pitch deck** Pair it with Notion MCP (or similar) to pull from your product roadmap, financials, team bios, etc. and generate a polished investor deck from all of it. One prompt, multiple sources.\n\n**Live data → Weekly reports** Connect it alongside Stripe, PostHog, or whatever analytics tools you use. \"Pull this week's metrics and make me a 5-slide marketing update\" - what used to take an afternoon now takes minutes. Save the prompt as a template and rerun it next week with fresh data. Most useful for weekly marketing/sales reviews\n\n**Meeting notes → Sales proposal** Right after a discovery call, feed your notes in and have it generate a tailored proposal deck while the conversation is still fresh. Combine with your company docs MCP to pull in standard pricing and case studies automatically.\n\nIt handles generating full decks, adding/deleting individual slides, speaker notes, and exporting to PPTX, PDF, or shareable links. You can also edit decks afterwards in Alai's editor or download the PPTX and tweak in PowerPoint.\n\nA few tips for best results: be specific about slide count, specify design/tone preferences, and iterate on the outline in conversation before generating - it's much faster than regenerating entire decks.\n\nWould love to hear what workflows others come up with or any feedback on the setup experience. Also happy to learn about existing presentation MCP experiences and what can be improved in the space.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1r3zm5j/presentation_generator_mcp_server_turn_your_ai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o5842e7",
          "author": "BC_MARO",
          "text": "This is neat. Do you expose slide templates/themes via API, and can we lock fonts/colors to brand tokens? Also curious if you support citation links per slide so outputs are auditable.",
          "score": 1,
          "created_utc": "2026-02-13 20:20:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5861vl",
              "author": "getalai",
              "text": "Hey u/BC_MARO ,\n\nThanks for the reply. We currently expose only our system themes via the API. However, for enterprises we can expose custom themes as well. Once a theme is created, the fonts/colors etc will be locked in and will be used consistently across decks. You will also be able to lock in templates (slide layouts) across presentations if needed.\n\nNot sure what you mean by citation links. However, you can make API requests per slide to get the transcription of that slide for auditing. If you add citation links to your raw content and ask the AI to put it on the slide in the footer then yes, that's possible as well.\n\nWould love to discuss this further and see how we can solve this end to end for you. Please reach out to us at [founders@getalai.com](mailto:founders@getalai.com)",
              "score": 1,
              "created_utc": "2026-02-13 20:31:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o58eyks",
                  "author": "BC_MARO",
                  "text": "Thanks for the detail. We will follow up over email for enterprise themes and template locking. For citations, footer links per slide plus the per slide transcript endpoint should work for our audit flow.",
                  "score": 2,
                  "created_utc": "2026-02-13 21:15:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0elcz",
      "title": "I built an MCP server that gives Claude 60+ FFmpeg tools — trim, merge, convert, stream, stabilize, and more",
      "subreddit": "mcp",
      "url": "https://i.redd.it/urjpo9paxiig1.png",
      "author": "dubnium0",
      "created_utc": "2026-02-09 19:54:46",
      "score": 34,
      "num_comments": 6,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r0elcz/i_built_an_mcp_server_that_gives_claude_60_ffmpeg/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4jpr0d",
          "author": "Basic_Young538",
          "text": "This rocks. Thx",
          "score": 2,
          "created_utc": "2026-02-10 02:38:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hmr93",
          "author": "dubnium0",
          "text": "If you want to try it, setup takes about 2 minutes...",
          "score": 1,
          "created_utc": "2026-02-09 19:55:31",
          "is_submitter": true,
          "replies": [
            {
              "id": "o4ht36z",
              "author": "finance-mcp-001",
              "text": "What’s the rough token usage?",
              "score": 1,
              "created_utc": "2026-02-09 20:27:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4k2619",
                  "author": "Proparser",
                  "text": "Interest in this too",
                  "score": 1,
                  "created_utc": "2026-02-10 03:54:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4k41j3",
              "author": "strigov",
              "text": "You mean installing requirements?",
              "score": 1,
              "created_utc": "2026-02-10 04:07:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4n08bz",
                  "author": "dubnium0",
                  "text": "yeah",
                  "score": 1,
                  "created_utc": "2026-02-10 16:30:19",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r34ou8",
      "title": "These MCPs made my life so much easier as a marketer (I basically live on Claude)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r34ou8/these_mcps_made_my_life_so_much_easier_as_a/",
      "author": "Serious-Unit5",
      "created_utc": "2026-02-12 20:36:02",
      "score": 29,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "As a marketer, my bar was simple: can I set it up without bugging our dev team too much (at max once or twice), is it reliable, and am I still using it a month later?\n\n**Google Analytics MCP (Performance reporting)** This one quietly became part of my daily routine. Solid for when you just want to keep a regular eye on stats and not wait for weekly reviews. I just ask Claude things like \"is our new blog getting any traction\" or \"which landing pages had the highest bounce rate last week.\" I get the answer in seconds. \n\n**Notion MCP (Knowledge base)** If your team lives in Notion like mine does, this is a game-changer. I majorly use this with other MCPs - for example it uses by GA4 data to create our weekly reviews on Notion, I also use it to get a better first draft for product marketing assets since it pulls all info from our Notion repository\n\n**Alai MCP (Presentations)**: Our current sales process involves creating custom decks for each client. Earlier the hassle of pulling info from Notion (we also currently use Notion as a temp CRM) + slack threads + call recordings was such a huge pain. Now I've created a baseline template - I use that + MCPs for all these tools to create the content on claude and then use the Alai MCP to get the deck ready using my brand template within 10-15 mins - such a time saver considering how I end up making 10-15 PPTs a week\n\n**Ahrefs MCP (SEO & competitive research)** If you do any SEO or content strategy work, this one's incredibly useful. Being able to ask Claude things like \"what first-page rankings does \\[competitor\\] have that we don't\" or \"show me our top declining keywords this month\" without opening dashboards and running reports manually -  it just removes so much friction from the research phase. I use it most when planning new content or auditing existing pages. Pairs well with Notion MCP for dropping findings straight into our content calendar.\n\n  \nI'm looking for more MCPs to optimize my workflow - if I am missing on any major ones pls do share and I hope the marketers out there find this useful :)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r34ou8/these_mcps_made_my_life_so_much_easier_as_a/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o540n6s",
          "author": "Top-Cauliflower-1808",
          "text": "Really like your list. The Windsor MCP is the perfect addition to your list because it connects Claude to over 300 ad platforms like Meta and TikTok. It uses automated normalisation so you can ask Claude, Which channel had the best ROAS? without manually blending data from different apps. Btw, you can even send that same data to Looker Studio if you need a visual dashboard for your weekly reviews.",
          "score": 3,
          "created_utc": "2026-02-13 04:45:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e29t9",
              "author": "Serious-Unit5",
              "text": "nice, will definitely check it out",
              "score": 1,
              "created_utc": "2026-02-14 19:38:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5846fv",
          "author": "getalai",
          "text": "Thanks for the mention, hope you enjoyed the experience so far :)",
          "score": 2,
          "created_utc": "2026-02-13 20:21:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5atplw",
          "author": "Snickers_B",
          "text": "Have you tried Dataforseo mcp?",
          "score": 1,
          "created_utc": "2026-02-14 06:28:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e25xm",
              "author": "Serious-Unit5",
              "text": "not yet",
              "score": 1,
              "created_utc": "2026-02-14 19:37:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5efiof",
          "author": "zenspirit20",
          "text": "I agree. Relatedly, I have heard that Ahrefs MCP hallucinates data. I have no proof point besides seeing other people’s comments. Please do keep this in mind. \n\nMy approach is to validate the data I am seeing if anything looks off. In general though it does save a lot of time.",
          "score": 1,
          "created_utc": "2026-02-14 20:49:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fcntz",
          "author": "TheLostWanderer47",
          "text": "Nice stack. One category you might like (if you do competitor/content research) is a web data MCP. Not dashboard data, but live web stuff: competitor pages, SERP results, public content, etc. I’ve seen marketing teams use web MCPs (we’ve used Bright Data’s [MCP Server](https://github.com/brightdata/brightdata-mcp) in some workflows) to pull live market signals straight into Claude instead of manually checking sites. ",
          "score": 1,
          "created_utc": "2026-02-14 23:59:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3q5wr",
      "title": "CamoFox MCP: Anti-detection browser MCP server with 22 tools (TypeScript, MIT)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r3q5wr/camofox_mcp_antidetection_browser_mcp_server_with/",
      "author": "Silver_Entrance8996",
      "created_utc": "2026-02-13 14:10:47",
      "score": 25,
      "num_comments": 16,
      "upvote_ratio": 0.94,
      "text": "I was frustrated with Playwright MCP being slow and getting blocked on many sites, so I built CamoFox MCP - an MCP server that wraps the CamoFox anti-detection browser (based on Camoufox/Firefox).\n\nWhat it does:\n- 22 MCP tools for full browser automation (navigate, click, type, snapshot, screenshot, search across 14 engines, etc.)\n- Anti-detection fingerprinting - each tab gets a unique fingerprint so sites don't flag you as a bot\n- Session isolation per user with cookie import/export\n- Works with Claude Desktop, VS Code Copilot, Cursor, or any MCP client\n\nWhy I built it:\nPlaywright MCP kept getting blocked by Cloudflare, bot detection, and CAPTCHAs. CamoFox uses Camoufox (a patched Firefox fork) that passes most anti-bot checks. The MCP server is a thin TypeScript wrapper over CamoFox's REST API.\n\nQuick start:\nnpx -y camofox-mcp@latest\n\n(Requires CamoFox browser running on localhost:9377)\n\nGitHub: https://github.com/redf0x1/camofox-mcp\nnpm: https://www.npmjs.com/package/camofox-mcp\n\nWould love feedback from the community. MIT licensed, contributions welcome!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r3q5wr/camofox_mcp_antidetection_browser_mcp_server_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o563xkx",
          "author": "Silver_Entrance8996",
          "text": "Fun fact: this post was actually created and submitted using CamoFox MCP itself! The entire flow - login, navigate to subreddit, fill in the post form, select flair, and submit - was fully automated through the MCP server. Reddit didn't flag any of it as bot activity thanks to the anti-detection fingerprinting. Eating our own dogfood here!",
          "score": 10,
          "created_utc": "2026-02-13 14:31:00",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o56qmmh",
          "author": "BC_MARO",
          "text": "Nice. Do you expose a profile preset API so agents can request a specific fingerprint or locale? Also curious how you handle CAPTCHA fallbacks.",
          "score": 2,
          "created_utc": "2026-02-13 16:21:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57ed25",
              "author": "Proparser",
              "text": "I need it too.",
              "score": 1,
              "created_utc": "2026-02-13 18:15:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o577apf",
          "author": "MDSExpro",
          "text": "Pack it into container with instance of camofox and it's much more usable.",
          "score": 2,
          "created_utc": "2026-02-13 17:42:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5988w4",
          "author": "typescape_",
          "text": "The fingerprint-per-tab approach solves a real pain point - I've burned too many hours debugging why my automation suddenly starts getting 403s mid-session.\n\nCurious about the REST API architecture choice. Did you consider exposing CamoFox directly as an MCP server without the intermediate layer? Asking because I've been wrestling with similar tradeoffs when wrapping browser automation for agent workflows.\n\nOne thing that would make this even more useful: persistent session profiles. Right now I'm guessing you'd need to manually export/import cookies between runs. Having named profiles that auto-persist fingerprint + cookies would be huge for workflows that need to maintain state across multiple agent sessions.\n\nWhat's the memory footprint like when running 5-10 concurrent tabs with unique fingerprints?",
          "score": 2,
          "created_utc": "2026-02-13 23:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56p534",
          "author": "jcrowe",
          "text": "I thought it was called Camoufox?",
          "score": 1,
          "created_utc": "2026-02-13 16:14:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5b9hap",
              "author": "Silver_Entrance8996",
              "text": "Good question! Camoufox is the original Python-based anti-detection browser project. CamoFox (no 'u') is a separate fork (camofox-browser) that adds a REST API layer on top. Our MCP server wraps that REST API, making it accessible to AI agents through the Model Context Protocol.\n\n\n\nSo the chain is: Camoufox (original) → CamoFox Browser (REST API fork) → CamoFox MCP (this project).",
              "score": 1,
              "created_utc": "2026-02-14 08:56:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bz1de",
                  "author": "jcrowe",
                  "text": "Thanks for the info, I’ll check it out.",
                  "score": 1,
                  "created_utc": "2026-02-14 12:51:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o57xqgl",
          "author": "HarjjotSinghh",
          "text": "this is unreasonably cool actually!",
          "score": 1,
          "created_utc": "2026-02-13 19:49:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5b9j74",
              "author": "Silver_Entrance8996",
              "text": "*Thanks, really appreciate it! 🙏*",
              "score": 1,
              "created_utc": "2026-02-14 08:57:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4dmxh",
      "title": "Has anyone built MCP servers with code execution like Anthropic’s pattern",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r4dmxh/has_anyone_built_mcp_servers_with_code_execution/",
      "author": "Physical_Ideal_3949",
      "created_utc": "2026-02-14 06:43:15",
      "score": 18,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "I want to  convert my open api spec to mcp server and use this code execution [https://www.anthropic.com/engineering/code-execution-with-mcp](https://www.anthropic.com/engineering/code-execution-with-mcp) any ideas how to achieve this",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r4dmxh/has_anyone_built_mcp_servers_with_code_execution/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o5axnlt",
          "author": "DavidAntoon",
          "text": "We built it without requiring file system access; we chose the sandbox approach instead.\n\nhttps://docs.agentfront.dev/frontmcp/plugins/official/codecall",
          "score": 4,
          "created_utc": "2026-02-14 07:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b5rp3",
          "author": "BC_MARO",
          "text": "We’ve done similar by wrapping exec in a jailed worker (firecracker/docker + seccomp), no network, strict time/mem, and an explicit tool allowlist. Convert OpenAPI to MCP and route code runs to that sandbox, then stream logs back. If you need approvals and audit on tool calls, Peta (peta.io) is the control plane for MCP: secure vault, managed MCP runtime, tool-call audit trail, and policy approvals.",
          "score": 2,
          "created_utc": "2026-02-14 08:20:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5d57xe",
              "author": "Physical_Ideal_3949",
              "text": "Can u share any reference mcp server which is using open api spec with code execution",
              "score": 1,
              "created_utc": "2026-02-14 16:51:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bvjws",
          "author": "rtfm_pls",
          "text": "I built [puppeteer mcp](https://github.com/iatsiuk/pptr-mcp) server using the same approach.\n\nInstead of exposing dzens of browser automation tools (navigate, click, type, screenshot, etc), it has single execute tool that runs arbitrary js with direct access to puppeteer broswer instance.",
          "score": 2,
          "created_utc": "2026-02-14 12:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bgt01",
          "author": "moonshinemclanmower",
          "text": "I use this\n\n[https://github.com/AnEntrypoint/mcp-glootie](https://github.com/AnEntrypoint/mcp-glootie)\n\nWhich is part of this\n\n[https://github.com/AnEntrypoint/glootie-cc](https://github.com/AnEntrypoint/glootie-cc)\n\nMy approach is a bit more advanced than theirs cause I've been at it for longer",
          "score": 1,
          "created_utc": "2026-02-14 10:09:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bifxf",
          "author": "shipping_sideways",
          "text": "the openapi to mcp conversion part is actually pretty straightforward if you think about it as a schema transformation. each openapi operation becomes an mcp tool - path params and query strings map to tool arguments, and response schemas become your tool output format. the tricky part is handling auth flows since mcp doesn't have native oauth token refresh.\n\nfor the code execution bit, anthropic's pattern uses isolated vm contexts for the lightweight sandboxing but you can also look at webcontainer or even wasm-based isolation if you need true multi-tenant safety. key thing is separating the runtime from the filesystem - let the sandbox execute but stream stdout/stderr through a separate channel.",
          "score": 1,
          "created_utc": "2026-02-14 10:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c0k77",
          "author": "ClinchySphincter",
          "text": "https://github.com/pydantic/monty",
          "score": 1,
          "created_utc": "2026-02-14 13:03:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dq16x",
          "author": "ShagBuddy",
          "text": "I created a MCP server specifically designed for coding agents:  [GlitterKill/sdl-mcp: SDL-MCP (Symbol Delta Ledger MCP Server) is a cards-first context system for coding agents that saves tokens and improves context.](https://github.com/GlitterKill/sdl-mcp)",
          "score": 1,
          "created_utc": "2026-02-14 18:35:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ey737",
          "author": "Embarrassed_Hotel630",
          "text": "https://medium.com/@gal.liber1/agent-tool-protocol-why-ai-agents-need-to-write-code-not-call-tools-b57b65f84b37\n\nThe idea came up before anthropic :), full open source implementation",
          "score": 1,
          "created_utc": "2026-02-14 22:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fy8fr",
          "author": "HarjjotSinghh",
          "text": "this mcpc version would be next level server vibes",
          "score": 1,
          "created_utc": "2026-02-15 02:18:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cb3q4",
          "author": "Phaelon74",
          "text": "This is so silly, is basically an API server, goodness me oh my.  We've gone full circle now.",
          "score": 0,
          "created_utc": "2026-02-14 14:10:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2s4hb",
      "title": "I dont get mcp",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r2s4hb/i_dont_get_mcp/",
      "author": "Yaar-Bhak",
      "created_utc": "2026-02-12 12:27:59",
      "score": 16,
      "num_comments": 25,
      "upvote_ratio": 0.77,
      "text": "All I understood till now is - \n\nI'm calling an LLM api normally and now\nInstead of that I add something called MCP which sort of shows whatever tools i have? And then calls api \n\n\nI mean, dont AGENTS do the same thing? \n\nWhy use MCP? Apart from some standard which can call any tool or llm \n\nAnd I still dont get exactly where and how it works \n\nAnd WHY and WHEN should I be using mcp? \n\nI'm not understanding at all 😭 Can someone please help\n\n",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1r2s4hb/i_dont_get_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4yytma",
          "author": "sogo00",
          "text": "You mix up a few things.\n\nAgents are a concept on how the LLM works more independently.\n\nMCP is an interface definition that the LLM can call an application to gather certain information.\n\nFor example: you want the AI to be able to see database entries, so you create an application that gets those and tell the LLM that it can call this tool if it needs this type of information.",
          "score": 7,
          "created_utc": "2026-02-12 12:36:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fy1m4",
              "author": "coworker",
              "text": "You are also mixing up things\n\nLLMs don't call applications. Agents call tools. Agents use LLMs. MCP is an interface for agents to discover tools.\n\nAn LLM is just a model (hint it's in the name lol)",
              "score": 1,
              "created_utc": "2026-02-15 02:17:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4z1z0i",
              "author": "Yaar-Bhak",
              "text": "Okay so MCP would be used in agentic flows right?\nBecause we need agents to \"perform actions\" \n\n\nAnd to choose which action to be performed,\n we need tools. \n\nAnd to see which tool is to be used, we need MCP to list out and the LLM will see which tool to pick",
              "score": 1,
              "created_utc": "2026-02-12 12:57:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4zddpb",
                  "author": "OkLettuce338",
                  "text": "You don’t strictly “need” mcp. MCP facilitates the llms decision making with documented tool usage. So if I have an api that has a “getBalance” “getTotal” and a “getCurrentTotalBalance”, your mcp can assist the LLM in choosing which one it needs at which time and what the difference is in a way that’s optimized for agent usage",
                  "score": 2,
                  "created_utc": "2026-02-12 14:04:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o52izkt",
                  "author": "Corv9tte",
                  "text": "It's a way to streamline a process with one input - output action, which is way more reliable! Think of it like a macro for your LLM, because that's exactly what it is.",
                  "score": 1,
                  "created_utc": "2026-02-12 23:14:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z876j",
          "author": "penguinzb1",
          "text": "think of mcp as a standardized way for llms to discover and call tools. without it, every agent framework reinvents tool calling slightly differently. with mcp, you write a server once (database access, file system, api calls, whatever) and any mcp client can use it. makes agents way more composable",
          "score": 5,
          "created_utc": "2026-02-12 13:35:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yyn30",
          "author": "Technocratix902",
          "text": "MCP is basically what allows an AI to tool call outside of its current environment. Like a terminal agent tool call to web or a cloud agent tool call to file system. Stuff like that . It's not certain for tool call to be outside environment like context7 and memory mcps. They allow you to give AI extra tools without changing any code. Like MCP connection to claude allows you to add extra tools without changing its code(since you can't it's close source).",
          "score": 5,
          "created_utc": "2026-02-12 12:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zda39",
          "author": "rollerblade7",
          "text": "Imagine if you need to update something in your backend - you could add lead information, create a task, call support etc.. you can build an MCP which is essentially an API that an LLM can call in a predictable way",
          "score": 2,
          "created_utc": "2026-02-12 14:03:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52hi2d",
          "author": "Low-Efficiency-9756",
          "text": "MCP is a protocol for executable tools that:\n\n\t1. Validate inputs — Schema enforcement via JSON-RPC before execution\n\t2. Mutate state — Write to databases, filesystems, APIs\n\t3. Return structured data — Not prose, actual typed responses the LLM can parse\n\t4. Maintain invariants — The LLM proposes, the tool validates and executes",
          "score": 2,
          "created_utc": "2026-02-12 23:06:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50e4ik",
          "author": "digibath",
          "text": "you can think of the agent as the glue between llm and mcp.  the llm doesn't actually call any tools, and it’s not aware of the mcp server. \n\nthis is where there seems to be a large misconception. the llm isn’t actually calling anything. \n\nits fed available tools, and it returns a tool call (this is just a data structure saying what tool to call with what inputs), which the agent then uses to call the correct tool via mcp server, then the agent returns the result from the tool call back to the LLM.",
          "score": 1,
          "created_utc": "2026-02-12 17:03:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53p70y",
          "author": "Creepy_Bullfrog_3288",
          "text": "Agents use tools to sense and act. MCP is a popular protocol to discover and consume those tools. The agent uses a LLM to formulate a plan, which may include calling tools, and then executes that plan.\n\nMCP is just one type of tool, but is popular and many companies/products have started shipping MCP servers to integrate agents with their platforms.",
          "score": 1,
          "created_utc": "2026-02-13 03:27:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53w1me",
          "author": "saikjuan",
          "text": "This is my view up to this point: \n\nÍ didn’t understand them either and I think developing an MCP for a custom agent might not be the best in all cases. \n\nBUT what I found is that building an MCP is for others to access some information or process you have, so that they do not have to build custom code. \n\nThis way any other agent, will have those tools at their disposal and will know what to do and how to without the owner being explicit about it.  \n\nSo… build an MCP if you want others to connect to you.",
          "score": 1,
          "created_utc": "2026-02-13 04:12:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53xbhw",
          "author": "tueieo",
          "text": "MCP is a way for agents to have structured and predictable access to tools. \n\nIt is a contract like what GraphQL is for FE. Could we have used GQL instead? Maybe. \n\nBut MCP is just an interface. What you power through it is up to you. Direct database queries, creating UI, updating a todo list, etc.",
          "score": 1,
          "created_utc": "2026-02-13 04:21:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54xrhj",
          "author": "lambdawaves",
          "text": "You had to write an AGENTS to explain how to call the API and what the API methods do and the inputs and outputs. \n\nIn MCP, the server basically declares its own AGENTS message",
          "score": 1,
          "created_utc": "2026-02-13 09:30:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o553w5o",
          "author": "adreportcard",
          "text": "Welcome. Stay. Learn.",
          "score": 1,
          "created_utc": "2026-02-13 10:28:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o572clw",
          "author": "Cool_Fly_2030",
          "text": "It’s a protocol to standardize how LLMs Fetch context to ground and complete a particular task effectively. \n\nFunctionally MCP servers are APIs, and “tools” function as endpoints/routes to perform logic, retrieve data, etc. and return a response to the LLM.\n\nIt’s pretty powerful in agentic applications of LLMs because they can effectively get knowledge they need to be effective and avoid hallucinating in a fully automated loop.",
          "score": 1,
          "created_utc": "2026-02-13 17:17:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58lmxp",
          "author": "whyisthequestion",
          "text": "Concrete example:\n\nI added the Miro MCP today. Now Claude Code can read and draw system diagrams of codebases and infra directly in Miro. \n\nTomorrow i add Notion MCP and it can document anything, and read all company policies.\n\nThat could be done by rest apis but MCP makes it a five minute setup. ",
          "score": 1,
          "created_utc": "2026-02-13 21:48:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f0bgz",
          "author": "KarmelMalone",
          "text": "MCP is just integrating an API without the work of integrating an API.",
          "score": 1,
          "created_utc": "2026-02-14 22:44:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o510d8v",
          "author": "memetican",
          "text": "I like to loosely think of MCP's as API's for agents.  Your agent needs to interact with something- a database, your email inbox, your file system, and the MCP provides that access and interface. \n\nAgents can also call standard web API's directly if they have the right access tokens and documentation but MCP's give advantages;\n\n* Generally more token-efficient, you don't need piles of JSON.  \n* Generally more agentic- so things like search tools become more valuable \n* Often don't need to return JSON, for many tools MD is a more efficient response \n* Built in docs for when and how to use the MCP, and what each tool is for ( so you don't need a separate skill to use your web API ) \n* For server-based MCPs, generally easier security for integration into ChatGPT, Gemini, Claude... through OAuth.  Users can just add the MCP, login, and it knows what data that user has access to. \n\n",
          "score": 0,
          "created_utc": "2026-02-12 18:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51jz9k",
          "author": "BC_MARO",
          "text": "Think of MCP as the “plugin protocol” between a host/agent and tools. Agents are still the thing that decides what to do next. MCP is just a standardized way to *reach* tools (and get results back) across different hosts.\n\nWhen is it useful? When you want one tool server to work in Claude + OpenAI + whatever, and you don’t want to rewrite glue code each time. The other big one is ops: auth, secrets, auditing, and approvals. A control plane like Peta (peta.io) can centralize creds + policy + an audit trail if you’re running more than a toy setup.",
          "score": 0,
          "created_utc": "2026-02-12 20:21:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o549tii",
          "author": "Mediocre-Abroad6083",
          "text": "\\*) Tool calling is the core concept. It is how context and actions from external systems are made available to an LLM.  \n\\*) Agents are really a for-loop-wrapper on top of an LLM, providing a set of tools, and making tool calls when requested by the LLM. From the \"outside\", a single call to the OpenAI (or equivalent) API may do this agentic loop on the \"inside\"  \n\\*) Instead of everyone building one-off protocols for tool calling, MCP is a standard protocol. It is a syntactic protocol not a semantic one. So you can wrap some service in an MCP server and publish it. Then any AI client can choose to use it  \n\\*) \"Use it\" means both inspect it (list tools, their descriptions, parameters) which is essential for an AI agent to decide to invoke it, and actually invoke it (run a tool, using a standardized format).  \n\\*) As a practical matter, this is way better than everything having its own one-off REST API because someone who have hand-build a tool to invoke it. If you have exactly one API to call and that's it, maybe that is all  \n\\*) This has nothing to do with context windows --- tiny context window or massive context window, MCP helps standardize tool calling (discovery and actual tool invocation)\n\nSo that's the \"basic\" MCP -- and you could say, ok functionally it is the same as REST APIs, but with a standardized syntax. And in a growing number of cases, the underlying SaaS service itself hosts the MCP server (eg: Notion hosts one, Intercom hosts one, Salesforce has one in preview, etc). So it shifts the burden of integration away from the consumer and to the source.  \n  \nBut things have moved beyond that ..\n\n\\*) MCP also exposes resources  \n\\*) MCP is stateful -- this is super important. Calling one tool can cause other tools to become available  \n\\*) MCP tool calls can be long running. So workflows and sub-agents can be exposed as MCP.  \n\\*) MCP tools can return UI (in a standard form that AI clients will respect)\n\nFInally, as I noted, there is the MCP syntax and then there is the question of semantics. REST APIs tend to be low-level developer-facing interfaces. If you want agents to do well, you want MCP tools that are higher-level semantic interfaces (sort of like the buttons you'd put in an app in front of a human being). Often these might compose many lower-level API calls.  \n  \nSo I'd say syntactically, you can expose a REST API via 1:1 mapping to MCP (and that's what most MCP servers do today). That gives you some benefit with simpler integration to your AI client. But then if you use it with its richer semantics, you get very much better outcomes",
          "score": 0,
          "created_utc": "2026-02-13 05:54:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51k9ub",
          "author": "randommmoso",
          "text": "Thank god finally someone asked this question",
          "score": -1,
          "created_utc": "2026-02-12 20:23:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5338kd",
          "author": "Kitchen-Lynx-7505",
          "text": "MCP is swagger / openapi for AI agents with low context windows.\n\nNow that we have 1M token context window on leading agents it might disappear very soon, as 99% of MCP servers are just wrappers on an OpenAPI endpoint, but we will see.\n\nMostly it has better documentation so that agents can understand, paging, so that the information fits into their tiny brains, and lack of output schema since for an Agent, it doesn’t really matter as long as it’s somewhat readable.",
          "score": -1,
          "created_utc": "2026-02-13 01:11:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54fsuf",
          "author": "Old_Motor_6561",
          "text": "Im the creator of RapidMCP.com so I’m saying this from experience and direct customer feedback. \n\n1) Your intuition is correct.\n2) if you own both ends of the tool calls, don’t bother, it’s too much friction and your current setup is probably far easier to validate/enforce/secure/trust etc. \n3) it’s very much a single tenanted interface (yes there are work arounds but that’s just the point it’s a hacky work around) \n\nSo the concrete use case for MCP is:\n\nYou are a user of a platform and you personally want to use those platform APIs in your own agentic assistant chat.",
          "score": -1,
          "created_utc": "2026-02-13 06:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51nx8t",
          "author": "Doomtrain86",
          "text": "You’re right in your intuition. It’s not that great at all. Just another friction. You’d be better off just writing a tool that interacts with whatever api you need. More efficient , more control. Less noise. Don’t listen to the people who thinks this will elevate llms to some new level. No. It’s holding it back.",
          "score": -2,
          "created_utc": "2026-02-12 20:40:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2mqcn",
      "title": "Excalidraw mcp is kinda cool",
      "subreddit": "mcp",
      "url": "https://v.redd.it/kp7hxp5pi0jg1",
      "author": "shanraisshan",
      "created_utc": "2026-02-12 07:03:29",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1r2mqcn/excalidraw_mcp_is_kinda_cool/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4yi3px",
          "author": "BC_MARO",
          "text": "Nice, the SVG→diagram loop is exactly what I wanted. We routed it through Peta (peta.io) for approvals and an audit trail when agents modify shared diagrams, which made teams less nervous.",
          "score": 1,
          "created_utc": "2026-02-12 10:18:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0xsmr",
      "title": "File-Organizer-MCP v3.2.8 just dropped — Now with FINAL MCP fixes, TUI wizard, and battle-tested stability. Organize 5000+ files with one AI prompt!",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r0xsmr/fileorganizermcp_v328_just_dropped_now_with_final/",
      "author": "Technocratix902",
      "created_utc": "2026-02-10 11:01:38",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hey MCP fam (and Claude/Cursor users),\nTired of your Downloads folder looking like a digital warzone? I built File-Organizer-MCP — a hardcore local MCP server that lets your AI actually manage your files intelligently:\nAuto-categorizes into 12+ smart folders (Docs, Images, Code, Archives, etc.)\nDetects duplicates with SHA-256 (saves you GBs of space)\nBatch rename, conflict handling (rename/skip/overwrite), dry-run previews\nRollback any changes if something goes sideways\nScheduled auto-organization (cron-style)\n8 layers of security so nothing escapes your allowed dirs\nInteractive setup: just run npx file-organizer-mcp --setup — picks your clients automatically\nThe AI decides what to do — we handle the how securely and efficiently (low token burn, atomic ops).\nLatest v3.2.8 fixes the last MCP protocol gremlins — tested with Claude Desktop, Cursor, Gemini CLI, etc.\nInstall in seconds:\nnpx file-organizer-mcp --setup\nGitHub: https://github.com/kridaydave/File-Organizer-MCP\nNPM: https://www.npmjs.com/package/file-organizer-mcp\nMCP Registry: https://registry.modelcontextprotocol.io/servers/io.github.kridaydave/file-organizer\nBuilt during school break because I was tired of manual sorting lol. Feedback, stars, issues, PRs all welcome — let's make file chaos history!\nHappy organizing 🗂️✨",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r0xsmr/fileorganizermcp_v328_just_dropped_now_with_final/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4myr0o",
          "author": "astrokat79",
          "text": "Have you tested/tried this with a music folder?",
          "score": 4,
          "created_utc": "2026-02-10 16:23:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n7gez",
              "author": "Technocratix902",
              "text": "File organization by Content/Metadata is in the works and should be implemented by Sunday. It was delayed today due to an npm oversight I occured. By the time update rolls out. You will have sorting of songs according to your Favorite Artists. Currently Kendrick and Drake have to share the same folder lol.",
              "score": 1,
              "created_utc": "2026-02-10 17:03:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r4hb03",
      "title": "Google Analytics MCP is available but only locally",
      "subreddit": "mcp",
      "url": "https://github.com/googleanalytics/google-analytics-mcp",
      "author": "48K",
      "created_utc": "2026-02-14 10:25:34",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1r4hb03/google_analytics_mcp_is_available_but_only_locally/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5binau",
          "author": "shipping_sideways",
          "text": "my guess is it comes down to api quotas and data volume. the GA reporting API has pretty aggressive rate limits (10 QPS per property, 10k requests/day for free tier) and analytics queries tend to be bursty - you pull a lot of dimensions/metrics at once. running locally means you can implement your own caching layer and batch requests without fighting a remote server's rate limiting on top of google's.\n\nalso the oauth scope for analytics is pretty sensitive from a business perspective - companies are paranoid about their traffic data hitting third party servers even briefly. mail and drive are different beasts since those are user-initiated discrete operations rather than bulk data pulls.",
          "score": 3,
          "created_utc": "2026-02-14 10:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bvjn8",
          "author": "evildeadxsp",
          "text": "We have a free tool that connects to the GA4 MCP without having to set anything up. We originally built it for clients to just go to a website to connect and ask questions ...  and have since released it to the public...\n\nDM me!",
          "score": 1,
          "created_utc": "2026-02-14 12:24:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r26sr0",
      "title": "Built an MCP that lets your whole team share context across Claude Code sessions",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r26sr0/built_an_mcp_that_lets_your_whole_team_share/",
      "author": "Ray-Hernandez",
      "created_utc": "2026-02-11 19:21:02",
      "score": 11,
      "num_comments": 9,
      "upvote_ratio": 0.77,
      "text": ">Claude Code for Teams:  [recall.team](http://recall.team)\n\nBeen building AI memory and context tools for over a year. Started with personal stuff, but the real problem hit when I started working with a team.\n\nEvery Claude Code session is an island. Someone spends an hour debugging an auth issue, fixes it, session ends. A few days later another dev hits the same thing. Starts from zero. One dev fixes auth one way. Another dev doesn't know, changes it. Someone re-explains the same thing to Claude that they already covered two hours ago.\n\nThe knowledge exists. It's just trapped in sessions nobody else can access.\n\nSo we built Recall - a platform that makes Claude Code actually work for teams.\n\n* **Sessions are automatically captured and encrypted when they end**\n* **When any dev starts a new session, their Claude already has context from the whole team**\n* **Search across every session your team has ever run**\n* **Dashboard showing what your team is actually building**\n* **End-to-end encrypted, no source code stored, raw transcripts deleted immediately**\n\nNot just for devs either. A PM can connect through Claude Desktop and ask \"what's blocking the auth migration?\" without bothering anyone.\n\nLaunched today. [recall.team](http://recall.team)\n\nRip it apart, tell me what sucks, what's cool, just really want feedback from the community.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r26sr0/built_an_mcp_that_lets_your_whole_team_share/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4uz7x4",
          "author": "BC_MARO",
          "text": "This nails the session-islands problem. How are you handling secret redaction before indexing, and do you support per-repo scoping so old incidents don't bleed into unrelated work?",
          "score": 2,
          "created_utc": "2026-02-11 20:14:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4v4tv1",
              "author": "Ray-Hernandez",
              "text": "Per-repo scoping is airtight - every session, decision, and piece of knowledge is scoped at the database level. Context for repo A never includes anything from repo B. Old incidents don't bleed.\n\nFor secrets, we redact before indexing and raw transcripts are deleted after processing. We're also adding programmatic regex detection (Stripe keys, AWS creds, GitHub tokens, high-entropy strings) as a belt-and-suspenders layer on top. LLM compliance is good but I want code-level enforcement too.",
              "score": 2,
              "created_utc": "2026-02-11 20:42:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4v1cmb",
          "author": "BC_MARO",
          "text": "this is a real pain point.\n\nq on the “e2e encrypted / raw transcripts deleted” bit: where do keys live (per-user, per-team), and can you do role-based access + audit logs for who queried what?\n\nwe’ve found teams only adopt this once it looks more like a vault/gateway model (policy + approvals for sensitive stuff), otherwise it feels spooky fast.",
          "score": 2,
          "created_utc": "2026-02-11 20:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4v4phy",
              "author": "Ray-Hernandez",
              "text": "Keys are per-team, AES-256-GCM. Raw transcripts get deleted after processing - only the LLM-generated summaries persist encrypted at rest. We have owner/admin/member/viewer (pm that can use claude desktop instead of claude code to get recall sessions) roles for team management and key rotation.\n\nAudit logs - honest answer, not built yet. You're describing exactly where we need to go and I agree it's table stakes for enterprise. The vault/gateway model with policy + approvals is on the roadmap. Right now we're focused on dev teams where the auto-deletion of raw transcripts is what gets people past the \"spooky\" feeling. But the full audit trail is coming.",
              "score": 1,
              "created_utc": "2026-02-11 20:41:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xmenf",
          "author": "drivebyposter2020",
          "text": "Oh, seriously intriguing. Watching with great interest. I am not really in a position to try it myself, as a guy experimenting solo, but I can totally see this problem having legs, and solving it making someone money :) (sorry, I'm a product guy, I look it it through that lens-- \"Does this address a real problem? YES!\") ",
          "score": 2,
          "created_utc": "2026-02-12 05:22:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xr04x",
              "author": "Ray-Hernandez",
              "text": "I may have something for you even going solo.  I built a product called Goldfish before I started building Recall.   Here is the github if you wanted to save context a similar way that recall does, but just locally.  \n\n[https://github.com/raydawg88/goldfish](https://github.com/raydawg88/goldfish)\n\nAnd I also...am a product guy :) ",
              "score": 1,
              "created_utc": "2026-02-12 06:00:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xxx7p",
          "author": "stibbons_",
          "text": "All these memory mcp cannot really work unless a LLM is itself used to manage these memory. How can a llm knows which memory to retrieve and when?",
          "score": 2,
          "created_utc": "2026-02-12 07:02:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xz3lt",
              "author": "Ray-Hernandez",
              "text": "Technically our mcp’s job is encrypting and decrypting, vs handling memory. The recall services take care of the memory, but we have a multi-step process where a full transcript is processed, then the llm will document, and organize the session deciphering that you had a problem here, had a solution here, etc, then organizes the file so that it’s easily searchable and retrievable when you search for something specific. \n\nHope that makes sense.",
              "score": 1,
              "created_utc": "2026-02-12 07:13:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uo854",
          "author": "Ray-Hernandez",
          "text": "Here's a quick little demo:  [https://www.youtube.com/watch?v=ib8DAPEtsiU](https://www.youtube.com/watch?v=ib8DAPEtsiU)",
          "score": 1,
          "created_utc": "2026-02-11 19:22:02",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzcc1d",
      "title": "Built a local memory system for Claude Code, benchmarked against 5 alternatives",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qzcc1d/built_a_local_memory_system_for_claude_code/",
      "author": "_rendro",
      "created_utc": "2026-02-08 15:49:19",
      "score": 11,
      "num_comments": 21,
      "upvote_ratio": 0.87,
      "text": "I built an MCP server that gives AI agents persistent memory across sessions. 4 tools: store, recall, list, forget. That's the entire API.\n\nThe tool count is deliberate. I started with 8 tools, tags, metadata fields, expiration dates. Every parameter I added was another decision the LLM had to make on every call, and it got worse at using the system. Stripping it down to store content and recall query made the LLM actually use it well without explicit prompting.\n\nUnder the hood it does more than the simple API suggests. Vector search (all-MiniLM-L6-v2 via Candle), hybrid BM25 scoring, memory decay with a 30-day half-life, a property graph for linking related memories, and auto-consolidation that merges near-duplicates. All of that is invisible to the LLM. It just calls store and recall.\n\nI benchmarked it against 5 alternatives (1,000 memories, 200 queries):\n\n* R@1: 50% (vs 47% next best)\n* Recency@1: 100% (vs 14% for competitors)\n* Auto-dedup: 99% consolidation rate\n\nSingle Rust binary, zero external dependencies. No Docker, no cloud, no API keys. Works with any MCP client.\n\n  \n`brew install rendro/tap/sediment`\n\nThen add to your client, e.g. for Claude Code:\n\n`claude mcp add sediment -- sediment`\n\n\n\nLanding page: [https://sediment.sh](https://sediment.sh)\n\nGitHub: [https://github.com/rendro/sediment](https://github.com/rendro/sediment)\n\nBenchmark suite: [https://github.com/rendro/sediment-benchmark](https://github.com/rendro/sediment-benchmark)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qzcc1d/built_a_local_memory_system_for_claude_code/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o49pzty",
          "author": "Otherwise_Wave9374",
          "text": "Love the \"fewer tools, better usage\" point. People underestimate how much decision fatigue you introduce for the LLM when the tool surface area gets big.\n\nAlso really like the idea of keeping the fancy stuff (hybrid search, decay, dedup, graph links) invisible behind a dead simple store/recall contract. That is basically how I have seen the most reliable agent memory layers built.\n\nAny chance you have a short writeup on how you tuned the decay + consolidation thresholds? This topic comes up a lot in agent memory discussions, a good overview here too: https://www.agentixlabs.com/blog/",
          "score": 3,
          "created_utc": "2026-02-08 15:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4e5kmq",
              "author": "Dense_Gate_5193",
              "text": "that’s why the MCP server toolset for Nornic is idiomatic for memory operations. \n\nhttps://github.com/orneryd/NornicDB",
              "score": 2,
              "created_utc": "2026-02-09 06:34:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4foh16",
                  "author": "_rendro",
                  "text": "Interesting project, will check it out",
                  "score": 1,
                  "created_utc": "2026-02-09 14:12:27",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4a8o4i",
              "author": "_rendro",
              "text": "Thanks! Context rot is really what I am trying to avoid. I started with way more tools and parameters and removed anything that wasn’t necessary and improved tool call reliability in the process.\n\nThe parameters for decay and consolidation are opinionated and might need more tweaking based on benchmarks. Thanks for the link, will definitely give it a read and see if I need to make changes.\n\nFor the hybrid vector + BM25 FTS blending parameters I had a grid search running with the benchmark suite to tune it for best recall results.",
              "score": 1,
              "created_utc": "2026-02-08 17:30:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49y6d7",
          "author": "DorkyMcDorky",
          "text": "Do you think a lot of this can be offloaded if it were a persistent connection between client/server?  Do you see anything that might perform better if MCP had such a design to it?\n\nGreat job!!!",
          "score": 2,
          "created_utc": "2026-02-08 16:39:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4abrez",
              "author": "_rendro",
              "text": "Thanks! MCP's stdio transport is already persistent, the server stays running for the whole session, which is how Sediment keeps the embedding model loaded and runs background consolidation between calls. What I'd love to see though is richer server→client communication, like push notifications when background tasks complete or streaming partial results. The main bottleneck isn't really connection overhead, it's the vector/embedding ops themselves. But bidirectional streaming could make the intelligence layer stuff (consolidation, clustering) feel more real-time instead of fire-and-forget.",
              "score": 1,
              "created_utc": "2026-02-08 17:45:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4bxslm",
                  "author": "DorkyMcDorky",
                  "text": "It's not true streaming though, the results yield via cursors, making it about the same as REST :)  They will never have bidi - they don't have streaming now.  Look at the code - it is a streaming protocol but it is not streaming in action.\n\n  \nI'm trying to get real bidi going in it, they are doing the opposite.",
                  "score": 1,
                  "created_utc": "2026-02-08 22:29:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4dgcg0",
          "author": "BC_MARO",
          "text": "The deliberate tool count reduction is the right call. I've seen the same pattern where more tools means worse LLM decision-making per call. The 30-day decay half-life is interesting -- have you experimented with different curves? For coding context specifically I'd expect some memories (architectural decisions) to stay relevant much longer than others (debug sessions). The auto-consolidation at 99% dedup rate is impressive though, that's usually where naive approaches fall apart.",
          "score": 2,
          "created_utc": "2026-02-09 03:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f3o92",
              "author": "_rendro",
              "text": "Thank you!\n\nI’m currently experimenting with a usage based decay. If I don’t store memories for 30 days I probably don’t want all of it to decay, but if I hammer on the storage layer, 30 days seems too long. This is definitely an area that needs more tuning.\n\nI originally had different decay and storage parameters for different types of memory, based on this paper (https://arxiv.org/abs/2512.05470). But this required the LLM to classify memories at write time and it adds all sort of additional context and complexity (tags etc).\n\nI’ve found that recall boost via the access count does a great job while keeping the memory schema simple. Additionally it works across multiple categories. Simply put, memory recalled more often surfaces more often. Architecture decisions are likely recalled at a higher frequency than one off debug sessions. Lastly, you can opt to keep debug sessions in local context and never add to memory.",
              "score": 2,
              "created_utc": "2026-02-09 11:55:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4fjpjl",
                  "author": "BC_MARO",
                  "text": "The access count as a proxy for importance is a really clean approach. It sidesteps the classification overhead and you get natural weighting for free. I've been doing something similar with my own setup where I just let frequency of recall determine what sticks around. The paper you linked is interesting, I'll check it out. For the usage-based decay, have you considered scaling the half-life dynamically based on how many memories you're storing? Small corpus might want longer retention, large one shorter.",
                  "score": 2,
                  "created_utc": "2026-02-09 13:44:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4b9sxi",
          "author": "IversusAI",
          "text": "Sounds amazing but it seems no windows support",
          "score": 1,
          "created_utc": "2026-02-08 20:28:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bbl9d",
              "author": "_rendro",
              "text": "Yes not currently. You can compile from source for windows and I can look into adding support for windows in my CI release pipeline",
              "score": 1,
              "created_utc": "2026-02-08 20:37:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4l0uow",
          "author": "UnifiedFlow",
          "text": "Why use mcp overhead for local tools?",
          "score": 1,
          "created_utc": "2026-02-10 08:39:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4viekq",
              "author": "_rendro",
              "text": "Mainly for the simplicity of integraion. It's a simple one line setup in claude code vs local scripts you hope the LLM picks up and executes",
              "score": 1,
              "created_utc": "2026-02-11 21:47:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4srpgi",
          "author": "EvilTakesNoHostages",
          "text": "Have you tried it in Zed?",
          "score": 1,
          "created_utc": "2026-02-11 13:52:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vhzcm",
              "author": "_rendro",
              "text": "Yeah it works in Zed. You can just add a local server to your settings`.`\n\n    {\n      \"sediment-mcp\": {\n        \"command\": \"sediment\",\n        \"args\": [],\n        \"env\": {}\n      }\n    }",
              "score": 1,
              "created_utc": "2026-02-11 21:45:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3jgyt",
      "title": "Best Practices for Agentic Development - By Octocode",
      "subreddit": "mcp",
      "url": "https://octocode.ai/blog/best-practices-agentic-development",
      "author": "_bgauryy_",
      "created_utc": "2026-02-13 08:04:17",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1r3jgyt/best_practices_for_agentic_development_by_octocode/",
      "domain": "octocode.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r0cgkc",
      "title": "What trust assumptions do MCP servers make?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r0cgkc/what_trust_assumptions_do_mcp_servers_make/",
      "author": "Far_Accountant_961",
      "created_utc": "2026-02-09 18:38:53",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 0.92,
      "text": "What surprised us most while building with MCP wasn’t how powerful the ecosystem is, but how much implicit trust it assumes. Once we started connecting third-party MCP servers to real agents, a few questions kept coming up:\n\n• How do you know an MCP server is safe before connecting it?\n\n• Where does agent data actually go across servers?\n\n• Can one MCP influence model behavior or exfiltrate data meant for another?\n\n• Can an LLM be nudged into calling tools it shouldn’t?\n\nWe went looking for “trust layer” for MCP servers and couldn’t find a comprehensive catalog or standardized risk assessment. So we ended up building one internally and decided to make it public. We analyzed MCP servers across a few dimensions:\n\n• provenance (official vs community)\n\n• MCP spec conformance\n\n• OWASP-style risks applied to agentic systems\n\n• static analysis for AI-specific patterns\n\n• CVEs, dependency issues, and runtime behaviors like prompt injection or cross-server data access\n\nSome of the findings were concerning: exposed API keys, servers pulling in known malicious packages, and tools that appear to attempt context poisoning or cross-server data access.\n\nFull disclosure: [https://mcp.armor1.ai/mcp-directory](https://mcp.armor1.ai/mcp-directory)\n\nThe catalog is free, public, and doesn’t require a login. It’s still evolving, and I’d genuinely love input from people here:\n\n• How are you evaluating MCP servers today?\n\n• Are there risk categories you think we’re missing?\n\n• Would a shared trust / risk signal for MCP servers actually be useful?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1r0cgkc/what_trust_assumptions_do_mcp_servers_make/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o4hcg3q",
          "author": "owlpellet",
          "text": "I think this directory is good. Basically journalism about services. I find the liability implications of this kind of spooky, but I'm sure you've thought about that. \n \nThe next layer down is actual controls within orgs that enforce allowed lists for services and/or isolate them within networks. An example: [https://blogs.vmware.com/tanzu/building-an-enterprise-mcp-server-marketplace-with-tanzu-platform/](https://blogs.vmware.com/tanzu/building-an-enterprise-mcp-server-marketplace-with-tanzu-platform/) \n\nNone of this is specific to MCP, once you wrap your head around \"I don't really know you, man\" and zero-trust them accordingly.",
          "score": 2,
          "created_utc": "2026-02-09 19:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i1lia",
          "author": "GentoroAI",
          "text": "Two things I’d add to your scoring: network egress (where can it phone home) and data retention/logging (what it stores + for how long). A shared risk signal would be super useful if it’s versioned and opinionated.",
          "score": 1,
          "created_utc": "2026-02-09 21:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4icwtv",
              "author": "Life_Salt8186",
              "text": "As part of the Armor1 team thanks, those additional signals make sense to add. Can you elaborate a bit more on your context of shared risk signal here? We also have point in time snapshots so metrics/scores are versioned behind the scenes. ",
              "score": 1,
              "created_utc": "2026-02-09 22:06:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pu3mq",
                  "author": "GentoroAI",
                  "text": "By shared risk signal I mean a machine-readable feed (JSON/API) that registries/gateways can enforce per server version: egress + retention/logging + creds + SBOM/CVEs, plus an allow/warn/block verdict backed by evidence. Snapshots are the right foundation.",
                  "score": 2,
                  "created_utc": "2026-02-11 00:45:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4iewtf",
          "author": "BC_MARO",
          "text": "The cross-server data exfiltration risk is the one that keeps me up at night. Most people just add MCP servers without thinking about what data flows between them, and there's no sandboxing by default.\n\nI've been looking at peta.io for this - they have a managed MCP runtime with policy-based approvals and a tool-call audit trail, which at least gives you visibility into what's happening. But yeah, the spec itself needs a trust/permissions model baked in.",
          "score": 1,
          "created_utc": "2026-02-09 22:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k7jso",
              "author": "Hot_Barracuda2596",
              "text": "This is a real concern and we’re seeing it too. What we do today is detect risk before connection, not sandbox at runtime. We analyze tool metadata and schemas because that’s what the LLM actually sees, and we flag patterns that could enable cross-server data flow, like instructions that try to force the model to always call a tool. For example, we’ve seen a web search tool whose description explicitly nudged the LLM to prefer that tool over native search tools provided by IDEs like Cursor. It doesn’t solve sandboxing, but it gives teams early visibility into which MCP servers can influence model behavior before they’re blindly added. We are actively looking into better modelling and analysing cross tool/server interactions as well as runtime analysis strategies.",
              "score": 3,
              "created_utc": "2026-02-10 04:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2utaw",
      "title": "is anyone working on mcp APPS?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1r2utaw/is_anyone_working_on_mcp_apps/",
      "author": "dcsan",
      "created_utc": "2026-02-12 14:27:02",
      "score": 9,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "is anyone working on MCP Apps? eg like [https://modelcontextprotocol.io/docs/extensions/apps](https://modelcontextprotocol.io/docs/extensions/apps)\n\nIt seems to me the openAI platform doesn't install apps for the last few days, at least I haven't been able to put one up there, the same app i could before.\n\nI've learn a lot about shared state, passing messages from MCP to the chat host, triggering UX widgets to init, differences between claude and openAI as host platforms and more.\n\nBe cool to share learnings if anyone is interested.",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1r2utaw/is_anyone_working_on_mcp_apps/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o59qfdg",
          "author": "Puzzleheaded_Mine392",
          "text": "we developed a cool Remotion video MCP server to use it everywhere instead of the CLI.  \n  \nif you're grinding through the dev cycle on mcp apps (especially on claude with no refresh lol), here's what we are working on:\n\nbuild with the [mcp-use sdk](https://github.com/mcp-use/mcp-use) (9k stars and 6m+ downloads).   \ngreat docs and [skill](https://skills.sh/mcp-use/mcp-use/chatgpt-app-builder) for claude code.\n\ntest with the [MCP inspector](https://www.manufact.com/inspector). way faster than reloading inside a host every time you touch something.  \ndeploy to manufact MCP cloud when it's ready.   \nbeats running your own infra for this.\n\nhaving an actual build/test/deploy loop makes a huge difference when you're dealing with all the host quirks between claude and openai.",
          "score": 2,
          "created_utc": "2026-02-14 01:44:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59rz9c",
              "author": "Guilty-Effect-3771",
              "text": "cool! do you have the URL ?",
              "score": 1,
              "created_utc": "2026-02-14 01:54:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o59vw17",
              "author": "dcsan",
              "text": "is this an MCP app or just an mcp to help build with?",
              "score": 1,
              "created_utc": "2026-02-14 02:18:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zovjy",
          "author": "OkLettuce338",
          "text": "What’s the difference between an “mcp app” and a remote mcp server over http?",
          "score": 1,
          "created_utc": "2026-02-12 15:04:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zr12u",
              "author": "dcsan",
              "text": "basically you can have a UX for your app and openAI at least has an appstore, claude also supports it but mainly b2b. probly gemini will support it in the future\n\ncheck out [chatgpt.com/apps](http://chatgpt.com/apps)\n\n",
              "score": 3,
              "created_utc": "2026-02-12 15:15:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4zrcl7",
                  "author": "OkLettuce338",
                  "text": "Thanks interesting. I have a couple mcps I support but not ui in the agent",
                  "score": 1,
                  "created_utc": "2026-02-12 15:17:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o502mxs",
          "author": "Block_Parser",
          "text": "I am very interested in the difference between hosts and how to navigate that.\nDo they work with any transport type?",
          "score": 1,
          "created_utc": "2026-02-12 16:10:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51jtiy",
          "author": "BC_MARO",
          "text": "From what I’ve seen, “MCP apps” are mostly host-side packaging: UI widgets + lifecycle/state that run inside the client. A remote MCP server is just tools over a transport.\n\nIf you’re trying to support multiple hosts, I’d keep the server transport-agnostic (stdio + HTTP/SSE) and treat widgets as optional capabilities.\n\nFor shared state + approvals, a control plane (vault, policy, audit trail) helps. Peta (peta.io) is one option if you want a managed MCP runtime with HITL approvals.",
          "score": 1,
          "created_utc": "2026-02-12 20:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5237l4",
          "author": "Slate_eLearning",
          "text": "We were but pulled back on it after a lot of testing due to CSP limitations. Didn't work for our use case but hopefully it could in the near future.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52nk08",
              "author": "dcsan",
              "text": "can you explain a bit more?  was it the CSP settings were blocking your content, or that the setup you had to use left your content wide open to other attacks?\n\nor were you trying to do some complex nested iframe thing rather than a fresh new greenfield app?\n\nI found openAI vs Claude handled CSP completely differently. maybe b2c open-directory vs b2b scoping?",
              "score": 2,
              "created_utc": "2026-02-12 23:40:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52t5p3",
                  "author": "Slate_eLearning",
                  "text": "It was blocking content. With our setup, it's a bit of a Russian doll situation with iframes. MCP frame > our course preview frame > user content (which can include embedded iframes from various sources + other external links).  \n\nI tried making our preview layer available on the MCP server directly since it's only html, CSS, and JS with no dependencies. Figured I could just inject it on demand. The user's content was still blocked that way though, so I shelved it for now.  \n\nI was testing with MCPjam, Claude Desktop, and Claude web, didn't try OpenAI. MCPjam was the only one that worked as intended.",
                  "score": 2,
                  "created_utc": "2026-02-13 00:12:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o525s47",
          "author": "tarkaTheRotter",
          "text": "We recently added MCP apps support to our commercial (for larger corporates) Kotlin MCP SDK, along with a testing host. Personally I think it's got more legs than elicitation (at least in I tried a current form), despite the lack of quality documentation around wiring it all together.\n\nIt was very satisfying to get an app rendering inside Claude in just a few lines of code - but I worry about the design impacting the testability of the solutions (hence us introducing our test host)... We're looking at getting playwright and the host and the MCP app server running entirely inside a test case to keep the cycle time down.",
          "score": 1,
          "created_utc": "2026-02-12 22:05:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ok3w",
              "author": "dcsan",
              "text": "> it's got more legs than elicitation\n\nat least the elicited inputs would be inline to the conversation? The connection between a UX widget and the chat still seems very basic in MCP apps\n\nalso implementation varies widely eg in Claude using [App.sendMessage](https://modelcontextprotocol.github.io/ext-apps/api/classes/app.App.html#sendmessage) will just populate the chatbox where openAI sends it in the background to the server and shows the response.\n\nThe clunkiness between chat and UX leaves a lot to be improved in a 2.0 version.\n\nYour testing host seems useful. the iteration cycle is a real pain atm esp in claude where there's no 'refresh'. esp for playwright type testing a slim 'host' env would be awesome. would you do a typescript SDK?",
              "score": 1,
              "created_utc": "2026-02-12 23:45:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o545trk",
          "author": "nileshteji1",
          "text": "we just launched a mcp app",
          "score": 1,
          "created_utc": "2026-02-13 05:23:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54h0ty",
              "author": "Tobi-Random",
              "text": "Me too!",
              "score": 1,
              "created_utc": "2026-02-13 06:55:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5780k6",
                  "author": "dcsan",
                  "text": "what is it?",
                  "score": 1,
                  "created_utc": "2026-02-13 17:45:31",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56gpoy",
          "author": "GroundbreakingBed597",
          "text": "FYI - I couldnt post a sample video here so I posted it in its own post in case you still look for examples => [https://www.reddit.com/r/mcp/comments/1r3sa7b/mcp\\_app\\_example\\_observability\\_data\\_in\\_interactive/](https://www.reddit.com/r/mcp/comments/1r3sa7b/mcp_app_example_observability_data_in_interactive/) ",
          "score": 1,
          "created_utc": "2026-02-13 15:34:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qz4asy",
      "title": "🦞 When Your AI Talks to Another AI — I Built an MCP Bridge for OpenClaw & Claude",
      "subreddit": "mcp",
      "url": "https://github.com/freema/openclaw-mcp",
      "author": "Open_Variation1438",
      "created_utc": "2026-02-08 09:09:21",
      "score": 9,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qz4asy/when_your_ai_talks_to_another_ai_i_built_an_mcp/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o486del",
          "author": "BC_MARO",
          "text": "this is a fun idea.\n\n2 things i'd love to see in the repo docs:\n- a clear threat model (what claude can and can't trigger)\n- what gets logged, and where\n\nif you ever expose this beyond localhost, i'd strongly recommend putting policy in front of the openclaw side: tool allowlists, require human approval for write actions, and keep a real audit log. it’ll save people from doing something they regret.",
          "score": 3,
          "created_utc": "2026-02-08 09:25:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o487x5e",
              "author": "Open_Variation1438",
              "text": "Hey, thanks a lot! Yeah, I'll definitely add that. I'm already running it somewhat in production, so I know what needs to be done — but others mightt not. It does take quite a bit of efort to set up properly. I'll add som warnings at startup when it detects it's running outside localhost, tha should help a lot... ",
              "score": 2,
              "created_utc": "2026-02-08 09:40:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48ifgb",
          "author": "Prestigious-Yam2428",
          "text": "Sounds like an interesting experiment 😅 Good luck! 🚀",
          "score": 2,
          "created_utc": "2026-02-08 11:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4det99",
          "author": "mt-beefcake",
          "text": "I havnt looked into the details of your setup yet. But I got 2 open claw agents and 2 claude desktops talking with eachother and collaborating on things. Set up a universal memory that reads all chat logs live and adds them to a query able database. Its also great for crash recovery, but reverting back to the last message seems to happen less now. Imma have one of the boys take a look at your setup and compare it to mine. Ill let you know",
          "score": 2,
          "created_utc": "2026-02-09 03:23:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4e9fzj",
              "author": "Open_Variation1438",
              "text": "Hey, thanks for the comment. I think a multi-agent setup without orchestration is fragile. That's why I often have repetitive flows in n8n, and n8n gives OpenClaw instructions via MCP. As I wrote somewhere above, Claw mainly gives me the ability to test and prototype a flow. When I like it and it's functional, I usually convert it into some kind of automation. In my case, Claw basically just handles working with GitHub and passes instructions to Claude Code on what to do (bug fixes). This can then be taken over by a simple Golang script. Otherwise, it's definitely important for me to isolate Claw in Docker. If it crashes, I just throw away the container and start fresh. Memory is usually in an external volume. Theoretically, I've been thinking about adding some kind of memory module or something like that. I use that approach on my other online MCP tools. Anyway, thanks for the feedback! :)\n\nOh and about the Docker setup — I usually have CC, GH, or whatever else pre-installed. I don't want it installing anything on its own. That's always a road to hell...  \n",
              "score": 1,
              "created_utc": "2026-02-09 07:08:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4b3500",
          "author": "dbizzler",
          "text": "Can someone explain to me what the hubbub is about with OpenClaw? I got excited about it after watching dozens of bros on TikTok going out and buying Mac Minis to run it but when I dug in it's... an insecure version of Claude Cowork with a non-standard tools interface? I know that by having a node running on your machine it gets access to your entire filesystem, camera, location, etc. but I'm seeing influencers talk about having it code them apps and I just don't understand why you'd have OpenClaw make you an app over Claude Code?\n\n\n\nGiven its explosive growth I assume I'm the one missing something here. Is it the heartbeat? The messaging app integration? The full YOLO access to everything?",
          "score": 1,
          "created_utc": "2026-02-08 19:54:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bkfee",
              "author": "Open_Variation1438",
              "text": "Yeah, I agree the hype is nonsense. What I actually enjoy about it though is that you can run it in an isolated Docker environment where it can't go anywhere — it only has access to what you give it. For example, you give it Claude Code and GitHub, and then you send it tasks like fixing bugs. Then you realize it actually works, and you write something in Golang that can do the same thing :D So it's more like a toy you can use to prototype workflows that you do over and over again.",
              "score": 1,
              "created_utc": "2026-02-08 21:21:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qz9rrb",
      "title": "We open-sourced SBP — a protocol that lets AI agents coordinate through pheromone-like signals instead of direct messaging",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qz9rrb/we_opensourced_sbp_a_protocol_that_lets_ai_agents/",
      "author": "Brief-Feed665",
      "created_utc": "2026-02-08 14:05:46",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 0.85,
      "text": "We just released SBP (Stigmergic Blackboard Protocol), an open-source protocol for multi-agent AI coordination.\n\n**The problem:** Most multi-agent systems use orchestrators or message queues. These create bottlenecks, single points of failure, and brittle coupling between agents.\n\n**The approach:** SBP uses stigmergy — the same mechanism ants use. Agents leave signals on a shared blackboard. Those signals have intensity, decay curves, and types. Other agents sense the signals and react. No direct communication needed.\n\n**What makes it different from MCP?** MCP (Model Context Protocol) gives agents tools and context. SBP gives agents *awareness of each other*. They're complementary — use MCP for \"what can I do?\" and SBP for \"what's happening around me?\"\n\n**What's included:**\n\n* Full protocol specification (RFC 2119 compliant)\n* TypeScript reference server (`@advicenxt/sbp-server`)\n* TypeScript + Python client SDKs\n* OpenAPI 3.1 specification\n* Pluggable storage (in-memory, extensible to Redis/SQLite)\n* Docker support\n\n**Links:**\n\n* GitHub: [https://github.com/AdviceNXT/sbp](https://github.com/AdviceNXT/sbp)\n* npm: `npm install` u/advicenxt`/sbp-server`\n* PyPI: `pip install sbp-client`\n\nHappy to answer questions about the protocol design, decay mechanics, or how we're using it.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qz9rrb/we_opensourced_sbp_a_protocol_that_lets_ai_agents/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o49e41q",
          "author": "nofilmincamera",
          "text": "Concept is really cool but I am missing the so what? How does this structure operate different on output?",
          "score": 2,
          "created_utc": "2026-02-08 14:58:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a7otz",
          "author": "pbalIII",
          "text": "Stigmergy works for ants because ant tasks are stateless... forage, return, reinforce. LLM agents are making contextual decisions where the meaning of a signal depends on what the agent already knows. That analogy breaks fast.\n\nVirtual stigmergy research shows environmental traces without agent memory fail completely. Individual memory alone gets 68.7% improvement over baselines. Decay curves and signal intensity don't help if agents can't reason about why a signal was left.\n\nThe real bottleneck in multi-agent systems isn't communication topology. It's shared state corruption. One agent writes a slightly wrong signal, others build on it confidently. An orchestrator gives you a single place to audit that. A blackboard with decaying anonymous signals makes provenance harder, not easier.",
          "score": 1,
          "created_utc": "2026-02-08 17:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ggxqf",
              "author": "Brief-Feed665",
              "text": "Fair critiques, but you're arguing against vanilla ant stigmergy, we don't implement that here.\n\nSBP pheromones aren't anonymous traces. Every signal carries typed JSON payloads, source agent IDs, UUIDs, and timestamps. Downstream agents know *what* happened, *who* said it, and *how fresh* it is. The agent's internal reasoning (RAG, CoT, whatever) is its own business, SBP only handles coordination.\n\nOn \"traces without memory fail\" - agreed, if signals are unstructured. Ours aren't. We also have capped audit streams with pheromone UUIDs for full temporal reconstruction. Decay isn't a substitute for reasoning, it's a safety invariant: unreinforced signals evaporate, the system hibernates instead of acting on stale data.\n\nOn shared state corruption, thank you, your strongest point. But the tradeoff: a bad orchestrator decision persists until a human catches it. A bad SBP signal *decays away*. Plus agents gate on composite thresholds (e.g., drift > 0.6 AND VIX ≤ 25), so a single bad signal can't cascade. Orchestrators are easier to debug after the fact. Stigmergic systems fail more safely in real-time. Thanks again.",
              "score": 1,
              "created_utc": "2026-02-09 16:36:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49o3vp",
          "author": "BC_MARO",
          "text": "Love this. The \"so what\" for me is you can drop the message-passing choreography and let agents reaLove this. The \"so what\" for me is you can drop the message-passing choreography and let agents react",
          "score": 1,
          "created_utc": "2026-02-08 15:50:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}