{
  "metadata": {
    "last_updated": "2026-01-19 02:39:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 153,
    "file_size_bytes": 170321
  },
  "items": [
    {
      "id": "1qarjqm",
      "title": "5 MCPs that have genuinely made me 10x faster",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qarjqm/5_mcps_that_have_genuinely_made_me_10x_faster/",
      "author": "ScratchAshamed593",
      "created_utc": "2026-01-12 10:34:54",
      "score": 454,
      "num_comments": 73,
      "upvote_ratio": 0.95,
      "text": "Iâ€™ve been using MCPs extensively at work, so I thought Iâ€™d share some of the ones Iâ€™ve found most useful.\n\nMy main criteria were minimal setup, reliability, and whether I kept using them after the novelty wore off:\n\n1. Context7 MCP: (Documentation and knowledge)This is by far the best MCP Iâ€™ve used for coding. It helps your agents fetch the latest documentation automatically. For me, I used to ask the agent to implement a feature X from Y technology and I have never had to deal with documentation.\n2. Firecrawl MCP / Jina Reader MCP: These are good for turning URLs into clean Markdown. They strip boilerplate, nav, and ads so the agent can focus on the actual article, although very interactive apps or paywalled content may still require a manual check.\n3. Figma MCP: (Design and UI) Design-to-code is the basic necessity nowadays for frontend development. This MCP server exposes the live structure of the layer you have selected in Figma, which includes hierarchy, autoâ€‘layout, variants, text styles, and token references. Tools like Claude, Cursor, or Windsurf can use it to generate code against real designs instead of screenshots.\n4. Slack / Messaging MCP: High â€œahaâ€ factor with very low effort. Once an agent can talk where humans already are, teams love it instantly. My team even used this for something as basic as ordering and tracking deliveries for team lunch, which ended up being one of the most-used workflows for us.\n5. GitHub MCP: This is what finally made Claude feel like an actual teammate instead of a smarter autocomplete. If youâ€™re tired of copy-pasting repos into prompts, youâ€™re gonna love it. Itâ€™s especially helpful for issue + commit context grounding and repo exploration.\n\nSuper curious to hear what MCPs all of you have found useful?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qarjqm/5_mcps_that_have_genuinely_made_me_10x_faster/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nz53oph",
          "author": "Hot_Dig8208",
          "text": "\n1. [Vercel grep](https://vercel.com/blog/grep-a-million-github-repositories-via-mcp) search github repo. Its like context7 but instead of semantic search, it use fuzzy \n2. [Chunkhound](https://chunkhound.github.io) for exploring / research codebase. Really good if you donâ€™t know where to start , the search tool works well for large code base",
          "score": 36,
          "created_utc": "2026-01-12 10:46:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nza0m8y",
              "author": "ProvidenceXz",
              "text": "This is tempting but why not just clone the repo and let the sub agents read it",
              "score": 4,
              "created_utc": "2026-01-13 02:08:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nza38p8",
                  "author": "Hot_Dig8208",
                  "text": "I suppose you are referring to the vercel grep. I think its great when you donâ€™t know initially which repo that suits your needs. \n\nIf you want to search deeper to a specific repo, sure its better to clone or use context7 instead. But for broad search I think grep will be better",
                  "score": 1,
                  "created_utc": "2026-01-13 02:22:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz55uee",
              "author": "ScratchAshamed593",
              "text": "Iâ€™ve played a bit with Vercelâ€™s repo search as well; itâ€™s great when you already have a rough idea of what youâ€™re looking for. I found Context7 to be more helpful when I needed *current docs + usage patterns*, but for repo-level fuzzy search, Vercelâ€™s approach is definitely solid. Chunkhound is a good mention, too.",
              "score": 2,
              "created_utc": "2026-01-12 11:06:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz73ki9",
                  "author": "Live_Vermicelli4307",
                  "text": "Sorry, quick question: what would you say it's the key difference between Vercel and Context7?",
                  "score": 1,
                  "created_utc": "2026-01-12 17:34:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7wlci",
              "author": "UseHopeful8146",
              "text": "All the time Iâ€™ve spent looking for a free, simple indexing tool and this never came up. Sometimes I hate the internet, but I donâ€™t hate you so thatâ€™s something",
              "score": 2,
              "created_utc": "2026-01-12 19:45:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz57913",
          "author": "Maasu",
          "text": "What about memory MCPs working wit agents? I use multiple for different settings (home/work) and tasks (UI/backend)\n\nI rolled my own (that's what we do now amirite) but there are plenty of others available and few that are free. Shameless plug for my own (I've no commercial interest here I just open source it so I could share it with friends and colleagues) \n\nhttps://github.com/ScottRBK/forgetful\n\nWhen I combine it with context7 it has helped make prompting agents for implementation planning.",
          "score": 13,
          "created_utc": "2026-01-12 11:18:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz57laz",
              "author": "ScratchAshamed593",
              "text": "Good point , memory MCPs are a whole category on their own and probably the next thing most people run into once agents go beyond single-shot tasks.\n\nI havenâ€™t standardized on one yet, mainly because memory design feels very workload-dependent (personal vs work, short-term vs long-term, UI vs backend). Iâ€™ve experimented a bit, but I still find myself being cautious about *what* actually deserves to persist.\n\nThanks for sharing your MCP. I like the idea of explicit control instead of â€œeverything becomes memory by default.â€ Will take a closer look.\n\nBtw, how do you decide what gets written to memory vs staying ephemeral in your setup?",
              "score": 3,
              "created_utc": "2026-01-12 11:21:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5kmux",
                  "author": "Maasu",
                  "text": "Yeah this is a really good question and it's precisely as you called out, it depends on the workflow and indeed the agent.\n\nFor my own workflows (outside of work which I cannot share) I actually created a context hub plugin that uses context7 l, forgetful and Serena (I only use Serena to semantically encode repos, I then turn it off because of has mcp tool spam in the context window - whereas context7 and forgetful are both lean in that regard).\n\nIt covers skills/commands for saving, exploring, curating memories. Plus an encode repo command that I use a lot. It basically lets forgetful become a poor mans context7 for private repos. \n\nI worn with micro services on enterprise software services so it's honestly been a life saver.\n\nhttps://github.com/ScottRBK/context-hub-plugin",
                  "score": 2,
                  "created_utc": "2026-01-12 12:58:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz5c9f2",
          "author": "thehashimwarren",
          "text": "Nextjs MCP. Puts an MCP in your Next app so that errors can be read by an agent. Works really well.\n\nChrome MCP. Gives your agent browser control powers. Works better than the third party projects I've used that are too overwhelming for some agents.",
          "score": 9,
          "created_utc": "2026-01-12 11:58:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5g4zh",
              "author": "ScratchAshamed593",
              "text": "Next.js MCP is a great call. Iâ€™ve found it especially useful during fast iteration loops where context switching into logs is the real bottleneck.\n\nChrome MCP has been surprisingly solid for me too. I agree on the third-party tools , a lot of them try to do *everything* and end up overwhelming the agent.",
              "score": 4,
              "created_utc": "2026-01-12 12:27:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz68o56",
          "author": "Atomm",
          "text": "I stopped using github MCP with Claude Code. It can already use github cli, so this saves context space.",
          "score": 8,
          "created_utc": "2026-01-12 15:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz68vo8",
              "author": "matrixise",
              "text": "yes, I do confirm, I stopped to use the MCP, and when I have a workflow, I ask to Claude Code to write a shell script with the right commands.",
              "score": 3,
              "created_utc": "2026-01-12 15:11:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz72bsh",
              "author": "japherwocky",
              "text": "Yes, GLMs and the minimax models both also seem very comfortable using the github CLI",
              "score": 2,
              "created_utc": "2026-01-12 17:28:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzat8gw",
              "author": "jcumb3r",
              "text": "Agreed. Claude knows how to git just fine without consuming context from an MCP server.",
              "score": 1,
              "created_utc": "2026-01-13 04:49:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzt79jl",
              "author": "Illustrious_Eye_1280",
              "text": "Agree, it was getting redundant.",
              "score": 1,
              "created_utc": "2026-01-15 22:11:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz6zlu1",
          "author": "thehashimwarren",
          "text": "I really like your list. But want to ask you about two of them...\n\nContext7: when I use gpt-5.2-codex it seems able to get fresh docs for my libraries without me telling it to and without an MCP server. \n\nI feel like Context7 was a patch for a problem that may not exist anymore.\n\nGitHub MCP. I like having the agent use the Github CLI instead because I can better see what's going on. I think the CLI may also be more token efficient.",
          "score": 5,
          "created_utc": "2026-01-12 17:16:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5dfa0",
          "author": "raghav-mcpjungle",
          "text": "Special mention for time & filesystem mcp servers. Have no idea what I'd do without them!\n\nI put them along with github & deepwiki behind mcpjungle gateway and connected to it from my claude & pycharm. Gave me an instant bazooka",
          "score": 5,
          "created_utc": "2026-01-12 12:07:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6nc84",
              "author": "chadrik",
              "text": "MCP newb here: Whatâ€™s the advantage of the file system mcp server when Claude can already use bash to acquire the same information?",
              "score": 3,
              "created_utc": "2026-01-12 16:20:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz6wmii",
                  "author": "raghav-mcpjungle",
                  "text": "In my personal opinion, I'd always prefer a process that makes system calls to get structured, reliable output over bash commands that return textual output.",
                  "score": 0,
                  "created_utc": "2026-01-12 17:02:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs2qs7",
              "author": "IvanVilchesB",
              "text": "For what do you use time mcp ? Ty",
              "score": 1,
              "created_utc": "2026-01-15 19:04:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvplo2",
                  "author": "raghav-mcpjungle",
                  "text": "mainly conversions to schedule my linkedin posts more easily (when I want to target a specific timezone)",
                  "score": 1,
                  "created_utc": "2026-01-16 07:12:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz56rvl",
          "author": "baradas",
          "text": "Love it if you could give counsel (counsel.getmason.io) - a spin. It's a deep decision engine and works with any assistant (claude code, cursor, chatgpt, claude)",
          "score": 2,
          "created_utc": "2026-01-12 11:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz56xu8",
              "author": "ScratchAshamed593",
              "text": "Sure would check it out and maybe post the review here",
              "score": 2,
              "created_utc": "2026-01-12 11:15:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5mwzq",
          "author": "Marc9696",
          "text": "[https://github.com/magentic/flowlens-mcp-server](https://github.com/magentic/flowlens-mcp-server) for debugging with console output and visual debugging",
          "score": 2,
          "created_utc": "2026-01-12 13:12:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5t96g",
          "author": "Fit_Upstairs_869",
          "text": "**Cipher MCP** for Knowledge ;)\n\nIts a RAG based Docu and Knowledge backend...\n\nIf you know, how inconsistent LLMs are with searching things (they tend to often choose the exact word)\n\nits a real gamechanger!\n\n**Playwright** \n\nfor Webdev",
          "score": 2,
          "created_utc": "2026-01-12 13:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6ca0e",
          "author": "theDatron",
          "text": "I use context7, sequential-thinking, memory and fetch (similar to firecrawl) through jilebi. I sometimes use github but fetch is usually good enough. Use arxiv, Wikipedia for research.Â ",
          "score": 2,
          "created_utc": "2026-01-12 15:28:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6sov8",
          "author": "Plus_Valuable_4948",
          "text": "Google Super MCP via Composio",
          "score": 2,
          "created_utc": "2026-01-12 16:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7ibtx",
          "author": "AccurateSuggestion54",
          "text": "Does slack have official MCP? Mind share the url?",
          "score": 2,
          "created_utc": "2026-01-12 18:40:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz81rc7",
          "author": "WinProfessional4958",
          "text": "Gonna have to check out figma mcp.",
          "score": 2,
          "created_utc": "2026-01-12 20:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz84qgd",
          "author": "Nearly_Tarzan",
          "text": "What has saved me tens of hours is the PowerBI MCP.",
          "score": 2,
          "created_utc": "2026-01-12 20:23:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj46n3",
              "author": "Revolutionary-Two457",
              "text": "Really? Other than documenting DAX measures in bulk I havenâ€™t been able to get a lot out of it yet. How do you use it?",
              "score": 1,
              "created_utc": "2026-01-14 12:52:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzkan5s",
                  "author": "Nearly_Tarzan",
                  "text": "I use it to connect to my powerBI desktop and create all the measures, cards, KPIs, tables, charts, etc.  Im working in Claude code so I have a PRD and a BRD for each dashboard.  Im somewhat specific around what I want and I have it connect and do most of the heavy lifting.  Ultimately, Im just cleaning up the look and feel and ensuring the data is accurate even though i have cc spawning agents to help me validate the UX and what is displayed is accurate.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:30:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz85uk6",
          "author": "jpmc_197",
          "text": "Which GitHub MCP is everyone using?",
          "score": 2,
          "created_utc": "2026-01-12 20:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz88rts",
          "author": "Cultural_Book_400",
          "text": "is github MCP equivalent of having claude extension and have it complete access to my project in visual studio code?? \n\nI have yet to use MCP but I am just wondering if I have been secretly using it??",
          "score": 2,
          "created_utc": "2026-01-12 20:42:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza0i7t",
          "author": "erikig",
          "text": "For me itâ€™s been Chrome Dev Tools https://github.com/ChromeDevTools/chrome-devtools-mcp\n\nBeing able to ask Cursor/Claude to:Â â€œLog into the application and complete the registration as user with password and run through the xyz workflow while fixing and documenting the processâ€ has been a game changer",
          "score": 2,
          "created_utc": "2026-01-13 02:07:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza7x4r",
          "author": "ReasonUnusual4101",
          "text": "I like Ref MCP for technical documentation and Exa search for enhanced web search while coding using Claude code.\n\nAs for using MCP in my own work (marketing/advertising), Iâ€™ve created my own take of a marketing MCP that lets me connect my advertising and marketing data to just about any AI tool out there and it works wonders for analyzing and agentia workflows.",
          "score": 2,
          "created_utc": "2026-01-13 02:47:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzdawei",
              "author": "Proparser",
              "text": "Please more info",
              "score": 1,
              "created_utc": "2026-01-13 15:45:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzi1f8s",
                  "author": "ReasonUnusual4101",
                  "text": "Please see my reaction below :)",
                  "score": 1,
                  "created_utc": "2026-01-14 07:14:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzht8m0",
              "author": "Admirable-Bill-4752",
              "text": "More info please as well",
              "score": 1,
              "created_utc": "2026-01-14 06:04:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzi1d7s",
                  "author": "ReasonUnusual4101",
                  "text": "This wasnâ€™t meant to be self promotional, but itâ€™s in beta and I could use a few more beta users. Itâ€™s called adsuperpowers.ai and you can check out the website for a quick demo and my contact info if you want to get in touch.\n\nCheers, Nick",
                  "score": 1,
                  "created_utc": "2026-01-14 07:14:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzr527a",
          "author": "chiroro_jr",
          "text": "Context7 MCP \nShadcn MCP\nGoogle Chrome Devtools MCP\nTanstack MCP\n\nThat's all you need.",
          "score": 2,
          "created_utc": "2026-01-15 16:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5eudj",
          "author": "matrixise",
          "text": "Have you tried Serena ?",
          "score": 2,
          "created_utc": "2026-01-12 12:17:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5fyi3",
              "author": "ScratchAshamed593",
              "text": "Havenâ€™t tried Serena yet, itâ€™s been on my list, but I havenâ€™t had a strong enough use case to justify adding another moving part. Curious what kind of workflows it shines in for you.",
              "score": 1,
              "created_utc": "2026-01-12 12:26:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7bje7",
          "author": "dattara",
          "text": "What are some Context7 use cases you've implemented - meaning what's downstream in workflows after extracting documentation?",
          "score": 1,
          "created_utc": "2026-01-12 18:10:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7icpz",
          "author": "Capnjbrown",
          "text": "Yes this is my own project. But Iâ€™ve had a lot of quick traction and positive responses on it so far. Perhaps it might complement your suite of MCP servers/tools you are already using? [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 1,
          "created_utc": "2026-01-12 18:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdpix5",
          "author": "loganintx",
          "text": "I use Bash â€œghâ€ commands for GitHub CLI and works great. Havenâ€™t tried the MCP server yet",
          "score": 1,
          "created_utc": "2026-01-13 16:52:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdpjno",
          "author": "loganintx",
          "text": "I use Bash â€œghâ€ commands for GitHub CLI and works great. Havenâ€™t tried the MCP server yet",
          "score": 1,
          "created_utc": "2026-01-13 16:52:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfa63q",
          "author": "typescape_",
          "text": "Context7 is legitimately a game changer. The number of times I used to paste documentation into context just to have the agent forget it three turns later... that's just gone [now.One](http://now.One) I'd add to the list: a custom MCP for your own company's internal docs. Same concept as Context7 but for tribal knowledge that isn't public. We built one that indexes our internal runbooks and now the agent can answer \"how do we handle X\" without anyone having to search Notion.The GitHub MCP point resonates. Before that, codebase exploration felt like playing telephone. Now Claude can actually understand the structure and history instead of just seeing whatever I copy-paste.Slack MCP is underrated for non-engineering use cases too. We use it for approval workflows - agent drafts something, posts to Slack for human review, then acts on the response. Turns what used to be manual back-and-forth into async [handoffs.One](http://handoffs.One) thing I've noticed: the MCPs that stick are the ones that eliminate repetitive context-stuffing. Anything where you're constantly re-explaining the same background info to the model is a good candidate for an MCP.What's your setup for the Figma one? Does it handle component variants well or do you still need to specify which state you want?",
          "score": 1,
          "created_utc": "2026-01-13 21:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfnwop",
          "author": "jcheroske",
          "text": "I'm using basic-memory MCP and really loving it. Curious what others think of it.",
          "score": 1,
          "created_utc": "2026-01-13 22:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfo1zr",
          "author": "TheIncredibleWalrus",
          "text": "Can you expand on the Slack MCP? How are you using it exactly?",
          "score": 1,
          "created_utc": "2026-01-13 22:27:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuy28o",
              "author": "ChronoFish",
              "text": "I built my own slack MPC server.\n\nIt allows the agent to set reactions, DM by email or user ID, and post.\n\nI also cache users so the MCP is able to use that as well.\n\nMy multi agent platform uses slack as the base and I started it before Slack had released MCP.",
              "score": 1,
              "created_utc": "2026-01-16 03:53:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzg2o7f",
          "author": "Overall_Ad_2067",
          "text": "Why not just use github cli instead of mcp?",
          "score": 1,
          "created_utc": "2026-01-13 23:43:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzh9g7s",
          "author": "farastray",
          "text": "Chrome dev tools for verifying what you build. None of those others did much for me. Playwright is ok for e2e testing. Gh, linear, notion, all those are just convenience but donâ€™t move the needle imho.",
          "score": 1,
          "created_utc": "2026-01-14 03:45:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzha3g8",
          "author": "edjez",
          "text": "My â€œmcp spawnerâ€ McP, that codes, reviews, keeps backlog for, maintains repo of, and deploys instances of, Mcps I ask for.\nWhich quickly brought me to the issues with the design of mcp itself , vs multi-agent architectures",
          "score": 1,
          "created_utc": "2026-01-14 03:48:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi7wmn",
          "author": "bhaktatejas",
          "text": "[morphllm.com/mcp](http://morphllm.com/mcp) warpgrep for fast filesystem search - makes dev so much better with claude code",
          "score": 1,
          "created_utc": "2026-01-14 08:15:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkri3f",
          "author": "Top-Cauliflower-1808",
          "text": "ngl thats basically the sweet spot MCPs should hit. As a Data Analyst I think MCP has played a very great role recently. Engineering team was already using windsor ai and I tried their MCP that  does something similar for marketing data by exposing normalised ad and analytics datasets directly to agents, so you can analyse spend shifts, KPI drops or anomalies without dashboards or SQL. imo once agents reason over live marketing data, workflows level up fast.",
          "score": 1,
          "created_utc": "2026-01-14 17:46:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo61tp",
          "author": "pbalIII",
          "text": "Memory MCPs are underrated for multi-agent setups. Context7 handles docs lookup, but persistent memory across sessions is what lets you skip the cold-start problem every time you spin up a new agent.\n\nThe combination works well... Context7 gives you current library APIs, memory gives you project-specific patterns and decisions. One fills knowledge gaps, the other fills context gaps.",
          "score": 1,
          "created_utc": "2026-01-15 04:07:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzod8jz",
          "author": "moonshinemclanmower",
          "text": "You should try mcp-glootie, server side code execution. [https://github.com/AnEntrypoint/mcp-glootie](https://github.com/AnEntrypoint/mcp-glootie)\n\nOr [https://github.com/AnEntrypoint/code-search](https://github.com/AnEntrypoint/code-search)\n\nAfter a year of 18 our days on mcp, I dont enable any of the ones you mentioned",
          "score": 1,
          "created_utc": "2026-01-15 04:56:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrv8a2",
          "author": "InvisibleWraith",
          "text": "Playwright bro....",
          "score": 1,
          "created_utc": "2026-01-15 18:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxx84n",
          "author": "SafeMeasurement136",
          "text": "Linear mcp for me imo - although have mixed feelings about oauth only",
          "score": 1,
          "created_utc": "2026-01-16 16:08:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o005q2h",
          "author": "parachutes1987",
          "text": "Hey OP. Did you create these MCPs or downloaded from somewhere?  \nI am a newbi into MCPs and Ai agentic flow but so far I have been using JIRA for tracking my workload, I am PO. \n\nCare to share some more details? I would love to explore some options with Slack",
          "score": 1,
          "created_utc": "2026-01-16 22:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o095w76",
          "author": "McNemarra",
          "text": "what is the cost of using all these mcps? I get that cost is likely justified but just wondering how balance is achieved",
          "score": 1,
          "created_utc": "2026-01-18 07:21:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09j4s4",
          "author": "TheLostWanderer47",
          "text": "Nice list. One MCP that surprised me on the infra side was a web-access MCP. Once agents need live data, brittle scraping kills velocity. Using something like Bright Dataâ€™s [MCP server](https://github.com/brightdata/brightdata-mcp) for search/browse/extract kept context small and reliability high. Agents call tools instead of pasting pages or guessing selectors. Not flashy, but itâ€™s one of those MCPs you keep once novelty wears off.",
          "score": 1,
          "created_utc": "2026-01-18 09:23:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz75wb2",
          "author": "oronbz",
          "text": "Which Slack MCP do you use?",
          "score": 1,
          "created_utc": "2026-01-12 17:44:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7e0i7",
          "author": "FancyAd4519",
          "text": "we have https://context-engine.ai - honestly when you hit 5-10m loc, i cant live without it anymore. Everything without my context compression is jacked including augment code. Needless to say there is a huge market of these self proclaimed tools out there.. which is why we are BSL but free for personal/corporate use so long as you do not resell the toolsâ€¦ we back our shit up with verified benchmarks against cosqa/coir/swe bench as well. Anyway; want to make changes that are not a nightmare id suggest looking into it. its free; we arent making any money lol",
          "score": 0,
          "created_utc": "2026-01-12 18:21:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7eglc",
              "author": "FancyAd4519",
              "text": "works best with GLM / openai for the psuedo description tags on your vectors (codebase index) and the context answer toolâ€¦ +9% improvement on local embedding models raw dense retrieval etcâ€¦ check it out",
              "score": 1,
              "created_utc": "2026-01-12 18:23:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qb7bx7",
      "title": "Anyone else find mcp setup to be a massive pain?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qb7bx7/anyone_else_find_mcp_setup_to_be_a_massive_pain/",
      "author": "Apprehensive_Ice9370",
      "created_utc": "2026-01-12 21:09:03",
      "score": 60,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Recently introduced to MCP thinking the hard part would be getting a server running, but I was surprised that that was the easy bit.. the pain started when I tried to make it usable in practice like custom server logic, proper auth and permissions, logging and analytics.. to understand what the agent is doing, and then figuring out how to host it safely without creating a security mess\n\nWanted to connect Postgres and some internal docs to Claude Desktop, but turning that into something Iâ€™d be comfortable running for more than a demo took way longer than expected.\n\nI needed to find a tool mostly out of fatigue, and it helped with a lot of the plumbing (especially auth, logging, and hosting), but Iâ€™m curious how others are handling this (ogment ai, in case anyone else is using it). Are people rolling their own production MCP servers, or is there a better pattern Iâ€™m missing?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qb7bx7/anyone_else_find_mcp_setup_to_be_a_massive_pain/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nz8o42s",
          "author": "BallsOfStonk",
          "text": "How are these considerations remotely relevant to MCP. This is just all standard production stuff, anything you host in a production environment has these issues.",
          "score": 8,
          "created_utc": "2026-01-12 21:53:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8j3sm",
          "author": "drakgremlin",
          "text": "Would be great to run them in Docker.  Sadly most agents do not integrate with it, meaning a larger attack surface.",
          "score": 2,
          "created_utc": "2026-01-12 21:30:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8xpt6",
              "author": "coloradical5280",
              "text": "Are you talking about locally hosted servers? Cause you can absolutely get any agent to communicate with a local server in docker.",
              "score": 1,
              "created_utc": "2026-01-12 22:40:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz97xdg",
                  "author": "drakgremlin",
                  "text": "Technically, yes?\n\nPractically it gets really funky with the edge cases in the lifecycle.",
                  "score": 1,
                  "created_utc": "2026-01-12 23:33:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz8jzc8",
          "author": "clipd_dead_stop_fall",
          "text": "I'm way behind you folks. I just started this journey. \n\nI want to use the Docker MCP Toolkit version of the AWS documentation mcp server with another that I want to build. I want to use mcp gateway to have one point of contact for the custom client, and I want all of it running local on developer machines. \n\nPretty sure I can handle the custom client and server, but the plumbing is proving a challenge.",
          "score": 2,
          "created_utc": "2026-01-12 21:35:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8x2rk",
          "author": "theapidude",
          "text": "Try out [https://getgram.ai/](https://getgram.ai/) \\- its not a framework like FastMCP rather a platform to plumb data to AI applications using MCP. The \"mcp bits\" (hosting, Oauth, logging, tool curation) are abstracted away but everything is compliant with the protocol so you're not locked in.",
          "score": 2,
          "created_utc": "2026-01-12 22:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcm24q",
          "author": "0xKoller",
          "text": "Hey!  \nKoller from [xmcp.dev](http://xmcp.dev) here. I totally get your pain, this use case really *is* painful. I encourage you to try building an MCP server with xmcp. Our main focus is DX, so it doesnâ€™t have to feel like a headache.\n\nFor auth, we support Better Auth, Clerk, and WorkOS, with Auth0 coming later this week. You can host your MCP server on Vercel using our zero-config deployment.\n\nIâ€™ll put together an example for the problem you mentioned over the next few weeks.",
          "score": 2,
          "created_utc": "2026-01-13 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze65pc",
          "author": "motakuk",
          "text": "[https://github.com/archestra-ai/archestra](https://github.com/archestra-ai/archestra) addresses most of the pain points of running MCP servers yourself: auth, connecting to clients, logging, etc.",
          "score": 2,
          "created_utc": "2026-01-13 18:19:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8vz3j",
          "author": "AchillesDev",
          "text": "This is setting up any customer-facing application, nothing specific to MCP. Arcade.dev and FastMCP both are frameworks that live on top of the MCP SDK that can help with these things.",
          "score": 1,
          "created_utc": "2026-01-12 22:31:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zoj4",
          "author": "Ol010101O1Ol",
          "text": "Itâ€™s absolutely painful\n\nWorking on a real solution for that. Standby.",
          "score": 1,
          "created_utc": "2026-01-12 22:49:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzeif7a",
              "author": "Live_Vermicelli4307",
              "text": "Keep us posted!",
              "score": 1,
              "created_utc": "2026-01-13 19:14:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz93qy6",
          "author": "naseemalnaji-mcpcat",
          "text": "Yep, existing frameworks help, but most (or any basic apps) require a fundamental understanding of authorization and identity. For most usecases I think itâ€™s fine to settle for simplicity in someways, like using token based authentication. \n\nMy stack: FastMCP running in ECS with an RDS database",
          "score": 1,
          "created_utc": "2026-01-12 23:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzanqa2",
              "author": "punkpeye",
              "text": "I really need to rename FastMCP (TypeScript) to something else.\n\nEvery time someone says FastMCP, I have no clue which framework they are talking about.",
              "score": 1,
              "created_utc": "2026-01-13 04:14:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzanzh8",
                  "author": "naseemalnaji-mcpcat",
                  "text": "Haha yeaaaa and thereâ€™s two Python implementations ðŸ¤¦â€â™‚ï¸",
                  "score": 1,
                  "created_utc": "2026-01-13 04:16:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz9a490",
          "author": "lujunsan",
          "text": "Yeah, I agree with the pain. Getting an MCP server running is easy, but turning it into something you want to run long-term can get messy fast, with auth, secrets, permissions, safe hosting,  visibility... Weâ€™re building Toolhive, an open-source project that helps by running MCP servers in isolation (locally or on Kubernetes), managing secrets and permissions, and quite a lot more. If that sounds interesting, you can check it out here: https://toolhive.dev https://docs.stacklok.com/toolhive/ Iâ€™m one of the devs working on it, so I'm happy to answer any questions!",
          "score": 1,
          "created_utc": "2026-01-12 23:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaxqza",
          "author": "hasmcp",
          "text": "This was the main reason that I created HasMCP and opensource a community version. It was super painful to setup the env, find the right tool then try to figure out the setup. Now I just provide the url and token then I choose the tools that I need only and relax while seeing what is going on behind scene with realtime logs.",
          "score": 1,
          "created_utc": "2026-01-13 05:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb21nn",
          "author": "raghav-mcpjungle",
          "text": "What you're describing is not a MCP problem but rather an operational problem.\n\nA good strategy is to \"centralize\" all your MCP servers by putting them behind a mcp gateway. A gateway becomes a single MCP endpoint that all your clients (like claude, ai agents) can connect to, to access all your MCP tools.\n\nGateways can solve a lot of these problems for you - centralized observability, audit logging, auth & ACLs, discoverability and give a holistic view of all your MCPs.\n\nfor eg, I'm a core developer of [mcpjungle](https://github.com/mcpjungle/MCPJungle). It is open source and self hosted, which improves your security & privacy aspects as well.  \nYou can run it on your local machine for personal use or deploy to your server in an enterprise setting.",
          "score": 1,
          "created_utc": "2026-01-13 05:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbphnj",
          "author": "babydecocx",
          "text": "yep. running the server is the easy part. making it â€œprod-safeâ€ is the grind (auth, perms, logs, hosting, wtf did the agent do)\n\nwhat helped us:\n\n* dont expose raw apis / 100 tools. wrap a few high level intent tools\n* put a gateway in front (oauth/ss0, allowlists, rate limits, audit logs). \n* postgres: read-only user, timeouts + row limits, schema allowlist. avoid â€œrun any sqlâ€\n* docs: split search vs fetch (search -> ids, then get(id)) so you can scope + audit\n\nmcp is just the wire. you still need the platform stuff around it, or use something that already ships those rails, we have our own version, it's open-source and free to test: [decocms.com/mesh](http://decocms.com/mesh)",
          "score": 1,
          "created_utc": "2026-01-13 09:24:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbxnwi",
          "author": "jezweb",
          "text": "Yes but once I got a good starting set of components to build on it was a lot easier. Fastmcp cloud was the easiest I found to build on for learning but just use cloudflare now instead. Claude 4.5 is a way better with mcp than 3.7 era was. It used to be like force feeding and reminding constantly that mcp was not minecraft protocols lol.",
          "score": 1,
          "created_utc": "2026-01-13 10:41:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhd5dv",
          "author": "saif_shines",
          "text": "The auth parts needs to be able to expand into auth'z, rather than just usual auth'n for MCP stuff. That has been my observation.  We use MCPJam for local inspection and development, try and checkout their blog: [https://www.mcpjam.com/blog/scalekit-oauth](https://www.mcpjam.com/blog/scalekit-oauth)",
          "score": 1,
          "created_utc": "2026-01-14 04:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzodrs9",
          "author": "moonshinemclanmower",
          "text": "Try having a good starting point, here are some examples you can use for source code examples:\n\n[https://github.com/AnEntrypoint/code-search](https://github.com/AnEntrypoint/code-search)\n\n[https://github.com/anentrypoint/coolify-mcp](https://github.com/anentrypoint/coolify-mcp)",
          "score": 1,
          "created_utc": "2026-01-15 05:00:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaltgf",
          "author": "punkpeye",
          "text": "It's literally one button click (Okay, two) if you are using Glama (I am the founder).\n\nhttps://glama.ai/blog/2025-07-08-how-to-install-and-use-mcp-servers\n\nOut of the box you get:\n\n* updates\n* secret management\n* analytics\n* streamable HTTP\n* chat (https://glama.ai/chat)\n\nand can even share it with others using access tokens",
          "score": 1,
          "created_utc": "2026-01-13 04:03:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qawh8c",
      "title": "Why MCP is a dead end for AI agent development",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qawh8c/why_mcp_is_a_dead_end_for_ai_agent_development/",
      "author": "First-Line9299",
      "created_utc": "2026-01-12 14:34:54",
      "score": 41,
      "num_comments": 63,
      "upvote_ratio": 0.79,
      "text": "We started working with MCP at Anysite almost immediately after its release. Beyond that, I extensively use third-party services both for AI agents and with Claude Desktop / Code. This weekend, while developing our new agent for analyzing large data volumes and collecting datasets, I concluded that MCP (at least in its current form) is not suitable for scaling AI agent functionality. The issue is the context that tool descriptions occupy. Currently, I use several MCPs regularly: Anysite, Zoom, Gmail, Postgres, GitLab, GitHub, and several custom ones. Anysite alone takes up ~21,000 tokens of context used with every LLM call. All my MCPs occupy around 40,000 and are approaching the recommended limit of 50,000 (beyond which MCP becomes dramatically less effective because the LLM gets confused). But what if we want a universal agent with tools for every occasion? The number of tools and context they occupy will tend toward infinity.\nMCP as a protocol is unlikely to be fundamentally improved. What are the ways out?\n1. Increasing context window.Â Not a solution. Tool selection efficiency plateaus at ~100k tokens even with a 1M context window.\n2. Optimizing MCP descriptions.Â Yes. We can reduce context footprint by 2â€“3x without significant quality loss. But this can't be done indefinitely.\n3. Dynamic tool invocation.Â Don't store all tools in context but provide tools for searching necessary ones based on the task. Though officially supported, it doesn't work in practice, and effectiveness depends on developer implementation â€” not trivial.\n4. Delegate via MCP to specialized agents.Â Closer to what we're building at Anysite. Finding tools for a specific agent is an order of magnitude easier than for a universal one.\n5. Embed tool usage during LLM training and give MCP only template tools (code execution, API calls).Â Most reliable but complex/costly â€” tools appear faster than models retrain.\nI think we'll arrive at a hybrid of methods 4 and 5 â€” specialized agents using custom small LLMs tailored for specific tasks, learning on the fly. This will become infrastructure for the agentic economy. And we at Anysite will bring this closer with every release.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qawh8c/why_mcp_is_a_dead_end_for_ai_agent_development/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nz6lsx3",
          "author": "Hofi2010",
          "text": "Anthropic proposed the agent to communicate with MCP tools by writing code. Here the link\n\nhttps://www.anthropic.com/engineering/code-execution-with-mcp\n\nThey have recognized the problem and making MCP tools discoverable and then the LLM writes code, which uses the MCP endpoints, to achieve its goal. This is similar to your point 3.",
          "score": 17,
          "created_utc": "2026-01-12 16:13:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bqmhm",
              "author": "Disneyskidney",
              "text": "Wait this is very nice! Doesnâ€™t seem too hard to implement too. Also seems pretty easy to turn any MCP into one of these programmatically. OP should probably give this a shot. Seems like the best solution to me.",
              "score": 1,
              "created_utc": "2026-01-18 17:45:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzazl0w",
              "author": "paulirish",
              "text": "Wonderful, but... that's a solution for Anthropic. We need a solution for the MCP ecosystem.  \n\nThe concepts of code execution and codemode could be introduced into the MCP spec and bring those benefits to all.",
              "score": 1,
              "created_utc": "2026-01-13 05:34:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz68t6d",
          "author": "raghav-mcpjungle",
          "text": "\\> Increasing context window  \nSome good solutions have been introduced in the last 4 months.  \n  \nI'm a core dev for a [MCP gateway](https://github.com/mcpjungle/MCPJungle) and the way we solve it is by allowing users to create a group of hand-picked tools from across all the mcp servers that exist.  \nThe gateway then exposes a new MCP endpoint that only exposes those tools to your LLM's context. These work well for some use cases (when your agent has a small, well defined scope).\n\nThis is just an example, I'm seeing some creative solutions springing up so I don't think this will hinder MCP's adoption in the long run.",
          "score": 6,
          "created_utc": "2026-01-12 15:11:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzawscb",
              "author": "Bog_Boy",
              "text": "When is semantic search coming",
              "score": 1,
              "created_utc": "2026-01-13 05:14:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzb2ggd",
                  "author": "raghav-mcpjungle",
                  "text": "this has proven to be harder than I thought, we're still in technical planning phase, so perhaps 2-3 months.",
                  "score": 0,
                  "created_utc": "2026-01-13 05:56:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz70thp",
          "author": "Total_Prize4858",
          "text": "Thats mostly because mcp servers are just rest endpoints in disguise. Way too many low level APIs and  massively bloated json responses containing gazillion tokens of unrelevant metadata.\nIf you write your own mcp server with 3-4 high level tools for your actual use cases and make it return only relevant data it gets really helpful.",
          "score": 6,
          "created_utc": "2026-01-12 17:21:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz73kvw",
          "author": "Historical-Lie9697",
          "text": "https://gist.github.com/GGPrompts/50e82596b345557656df2fc8d2d54e2c enables dynamic discovery of mcp tools for Claude and Codex already works that way out of the box. You can also spawn Claude Code with the --plugin-dir flag and they have full access to mcps/skills that are installed but not enabled. I think agents are the way forward for mcps, not a dead end.",
          "score": 3,
          "created_utc": "2026-01-12 17:34:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz63pqd",
          "author": "nuno6Varnish",
          "text": "Good read. I think solutions 3 or 4 (which IMO can be the same to some extend) will probably be common in the near future. A tool is like a website for an LLM, they can't load all of them but they can quickly trigger a web search and return value",
          "score": 3,
          "created_utc": "2026-01-12 14:45:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz66idk",
              "author": "First-Line9299",
              "text": "So should we expect a â€œGoogleâ€ for MCP?",
              "score": 0,
              "created_utc": "2026-01-12 14:59:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6weoi",
                  "author": "nuno6Varnish",
                  "text": "Probably as we will never be able scale infinitely. We already have some MCP server registries, even an official one if I am correct. But those are more for humans for now.",
                  "score": 2,
                  "created_utc": "2026-01-12 17:01:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nznee9k",
                  "author": "ReasonUnusual4101",
                  "text": "Maybe you should check out Smithery, which is basically a giant database of MCPâ€™s",
                  "score": 1,
                  "created_utc": "2026-01-15 01:22:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7dp9p",
          "author": "promethe42",
          "text": ">But what if we want a universal agent with tools for every occasion?\n\nThat's the neat part: you don't!",
          "score": 3,
          "created_utc": "2026-01-12 18:19:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz85tnw",
              "author": "First-Line9299",
              "text": "Sure, my question was a bit exaggerated. But I can easily imagine an agent that needs free access to 100+ tools simultaneously",
              "score": 1,
              "created_utc": "2026-01-12 20:28:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz8hbpl",
                  "author": "promethe42",
                  "text": "Sure. But I would argue 10 agents with 10 tools will do a lot better anyway. I don't expect a chef to do my taxes.",
                  "score": 1,
                  "created_utc": "2026-01-12 21:22:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzveo9l",
                  "author": "ChronoFish",
                  "text": "Whether it's one agent or a team of agents, does it matter?\n\n\nIt might for your architecture.. but does the user interaction (if it has one) care?",
                  "score": 1,
                  "created_utc": "2026-01-16 05:44:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz64qht",
          "author": "SpareIntroduction721",
          "text": "I have an agent as the only tool exposed to my MCP server. They dude had the actual tools",
          "score": 2,
          "created_utc": "2026-01-12 14:50:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz66lst",
              "author": "First-Line9299",
              "text": "Thereâ€™s no difference from the perspective of agent tools and MCP. In both cases, itâ€™s stored in context and therefore finite.",
              "score": 2,
              "created_utc": "2026-01-12 15:00:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6yula",
                  "author": "SpareIntroduction721",
                  "text": "1 tool vs 100 tools is a big difference? All the context stays within the MCP. It only spits out one response.\n\nI guess yeah, eventually, but it doesnâ€™t take up as much tokens/context as loading up all 100 at start.",
                  "score": 2,
                  "created_utc": "2026-01-12 17:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6cs3i",
          "author": "Classic_Chemical_237",
          "text": "Isnâ€™t 4 one of the native ways to use MCP? I meant, MCP expects structured data from cmd line and API. Nothing prevents you from making an agent returning JSON.\n\nMy issue with AI in general is the cost and round trip time. Add a few agents into the mix, soon the round trip will take minutes instead of seconds and the bill will add up.",
          "score": 2,
          "created_utc": "2026-01-12 15:31:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz88lyk",
              "author": "First-Line9299",
              "text": "You're right about cost and latency â€” that's exactly why solution #5 matters. Specialized small models (fine-tuned 7B or even smaller) can handle specific tool domains at a fraction of the cost and 10x faster. The future isn't one expensive generalist doing everything, but a mesh of cheap, fast specialists with smart routing on top.",
              "score": 2,
              "created_utc": "2026-01-12 20:41:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz8z9o4",
                  "author": "Classic_Chemical_237",
                  "text": "I totally understand you. However, with specialized models, you will face different set of challenges.\n\nWith specialized models, you need to do your own hosting. No API cost, but you will incur hardware and hosting cost. Big question is how many models you can host per server? How many servers do you need?\n\nAnd with specialized models, how do you know what model to train? Your use cases become limited. And for specialized use cases, do you need to use LLM as the backbone of your app? How about mixing LLM, ML and API whenever appropriate?",
                  "score": 1,
                  "created_utc": "2026-01-12 22:47:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6dqok",
          "author": "theDatron",
          "text": "I've been playing around with the idea of running qwen 3 0.6b through llama-cpp locally and having it interact with tools for the main LLM. It's like the sub agent in claude code but just for tool calls.Â ",
          "score": 2,
          "created_utc": "2026-01-12 15:35:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6sxuy",
              "author": "angelarose210",
              "text": "Someone made a yt video about this recently. I'll see if I can find it in my history.",
              "score": 1,
              "created_utc": "2026-01-12 16:45:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nza5ujc",
                  "author": "theDatron",
                  "text": "Ah interesting, this is reassuring. Could you share the video when you find it?Â ",
                  "score": 2,
                  "created_utc": "2026-01-13 02:36:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz87p4w",
                  "author": "First-Line9299",
                  "text": "this one? [https://www.youtube.com/watch?v=rsDlu-9UP00](https://www.youtube.com/watch?v=rsDlu-9UP00)",
                  "score": 1,
                  "created_utc": "2026-01-12 20:37:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6e5hz",
          "author": "ggone20",
          "text": "Youâ€™re using it just like any other tool/API. The point isnâ€™t to just restructure APIs. Use MCP as complete workflow and context offload points so as NOT to stuff your main thread context but still get complex work done. \n\nWeâ€™re so far into this I donâ€™t understand why this isnâ€™t the default way of thinking about it. \n\nOpenAI Agents SDK, MCP, and A2A are the literal perfect agentic stack. \n\nEverything else is noise; unless payments and/or dynamic UI - but there are protocols for those also AND they should be hidden behind MCP anyway soâ€¦",
          "score": 2,
          "created_utc": "2026-01-12 15:37:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz83lp0",
              "author": "First-Line9299",
              "text": "I agree MCP should be a context offload, not context bloat â€” that's exactly my point. The current default usage pattern (all tools in context) is broken, and your workflow approach is the right direction. But your \"perfect stack\" still needs a solution for tool discovery at scale. How does an agent find the right MCP server among thousands? That's the missing piece. We need something like a registry or semantic search layer on top of MCP â€” otherwise you're just manually curating which servers to connect, which doesn't scale.",
              "score": 1,
              "created_utc": "2026-01-12 20:18:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz8fqcw",
                  "author": "Historical-Lie9697",
                  "text": "I use a conductor agent that takes tasks from my backlog and drafts prompts for them, then uses a script that checks my installed plugins and adds them to the prompts. It's a bit hacky but working well so far. You can have thousands of installed plugins all installed but disabled, then spawn workers with the --plugin-dir flag and they get full access to that plugins agents hooks skills commands and mcps",
                  "score": 2,
                  "created_utc": "2026-01-12 21:15:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz9ooy9",
                  "author": "ggone20",
                  "text": "Again your question is an architecture problem - I personally have been working with distributed agents for literal years now. If you check my comment history I was likely one of the first in the world. \n\nThat said, and back when MCP was released, I created an MCP/tool management MCP with an intelligent layer that literally spins up a customized agent JUST for whatever the current atomic task is. \n\nAgain, nothing else is needed beyond the stack above. Software development patterns were a solved thing (distributed microservices), but for some reason everyone (literally everyone even at top engineering shops) lost their heads and forgot how to do things properly. Never made sense to me. \n\nAt first I used Cerebras to get insanely fast tool selection and programmatic agent spin up. Then when the Gemma3 270m dropped I took all the logs Iâ€™d saved and fune-tuned a tool routerâ€¦ itâ€™s basically magic and so fast/efficient. \n\nNot trying to be all high and mighty but the correct way to read the MCP spec is how the ChatGPT MCP connector forces you to do it: two â€˜toolsâ€™. 1) list tools (workflows, whole actions) and 2) execute tool. MCP was never meant to be an API wrapper. Thatâ€™s why everyone was â€˜what use is MCPâ€™ for the first year+ after its release. Even before building a custom router and spinning up distributed agents each MCP should show just 2 tools. But the github server alone exposed what? 27 or 14 or something? Like I said, the biggest shops in the world are really bad at agentic development; Reddit, everyone. They donâ€™t get it either. \n\nHope this helps.",
                  "score": 2,
                  "created_utc": "2026-01-13 01:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6il5h",
          "author": "Status_Baker5861",
          "text": "4 & 5 are definitively the way forward. Smaller models will likely be sufficient too, the added cost savings will make this even more attractive.\n\nThe problem then with agentic flows becomes how to convey context from one to the other, and in particular authorization. For that you need to use additional specifications such as OAuth2 Token Exchange and OpenID AuthZEN. You can also chat with us : [https://www.indykite.ai/contact-us](https://www.indykite.ai/contact-us)",
          "score": 2,
          "created_utc": "2026-01-12 15:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6o26z",
          "author": "Empty-Employment8050",
          "text": "Very interesting and to the point convo. Love it. My guess is sub agents galore. Subs on subs on subs. Prolly forever really.",
          "score": 2,
          "created_utc": "2026-01-12 16:23:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6xzp8",
          "author": "Excited_Idiot",
          "text": "Whatâ€™s your usecase for anysite in this context? Thatâ€™s a pretty heavy token consumption for a recurring MCP response.",
          "score": 2,
          "created_utc": "2026-01-12 17:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7eh1c",
          "author": "abensur",
          "text": "last week I turned many MCPs into skills, still a good use for mcp, like \"create a new skill based on the XYZ mcp\"",
          "score": 2,
          "created_utc": "2026-01-12 18:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8885k",
              "author": "First-Line9299",
              "text": "Can you share an example of how you structure these skills?",
              "score": 1,
              "created_utc": "2026-01-12 20:39:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz8avcz",
                  "author": "abensur",
                  "text": "I have some of the skills from this repo: [https://github.com/onmax/nuxt-skills](https://github.com/onmax/nuxt-skills)  \nsome skills from this one: ([https://github.com/anthropics/skills](https://github.com/anthropics/skills)).  \nOne of my skills is a skill-creator that I've been using to create new skills from MCPs.  \nOur backend services are using [https://github.com/Vizioz/Swagger-MCP](https://github.com/Vizioz/Swagger-MCP)",
                  "score": 1,
                  "created_utc": "2026-01-12 20:52:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7tolp",
          "author": "guac-o",
          "text": "Number 4",
          "score": 2,
          "created_utc": "2026-01-12 19:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8eagt",
          "author": "itissid",
          "text": "The key idea is think in terms of workflow and select MCP call sites needed for it. Only once this is done  should you engage your CC agent to do implementation. A common work flow is:\n\n\\`/research\\` -> \\`/create\\_plan\\` -> \\`/implement\\_plan\\`\n\n1. You /research slash command + prompt can find the MCP calls needed for what you want to do and be very specific. Output should be a document with the list of selected calls from each MCP to do the job. Some MCP calls will be made for research others will just be mentioned as to which ones are needed later. \\[Here\\]([https://gist.github.com/itissid/8a3969c4d1495e44ca9391dd8849f9b5](https://gist.github.com/itissid/8a3969c4d1495e44ca9391dd8849f9b5)) is an example of how I use it, you can add your MCPs to it.\n2. IN a new CC start \\`/create\\_plan\\`\\[Here\\]([https://gist.github.com/itissid/738dd6c7f596871424e9aae98052e792](https://gist.github.com/itissid/738dd6c7f596871424e9aae98052e792)) is what I use. Give it above document and a prompt to do what you want. Use the research document and creates a plan. Here skills can have more detailed description of what each MCP does and a function to preprocess results. I would think of it this way. Another idea is to use sub agents. What should be a Skill/Subagent and what should be an MCP?\n\n* If an MCP needs custom pre-processing it should be a skill and skills can call tools locally to post process, which is more efficient than going through MCPs to do this.\n* If you can do the post processing with tool scopes then use agents(in \\`.claude/agents/\\` for example \\[here\\]([https://gist.github.com/itissid/d9c289e5aca0465eb8e09f71a374d2c2](https://gist.github.com/itissid/d9c289e5aca0465eb8e09f71a374d2c2)) is a web search agent.\n\n1. /implement\\_plan. In a new CC window you can give it the document from #2 above and ask it. An example is [Here](https://gist.github.com/itissid/940c99989d4f55d4a58a2c8a2cb105fd)\n\nSo you mentioned:\n\n>Delegate via MCP to specialized agents.Â \n\nDon't do that. Use skills/agents instead where you can.\n\nCC Skills  provide light weight \"ambient\" context and they do progressive disclosure: i.e. read only the YAML front matter of each tool and keep context usage low. This should make the context usage tiny for dozens of tools.",
          "score": 2,
          "created_utc": "2026-01-12 21:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nza4xzt",
          "author": "shottyhomes",
          "text": "Today i just ripped out the traceloop mcp by using a custom python client with a readme (a skill you could say).\n\nWorks like a charm and no random errors.",
          "score": 2,
          "created_utc": "2026-01-13 02:31:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkht8a",
          "author": "Beneficial_Ear4282",
          "text": "Something I did for a project was context aware tools, before we even add tools we analyze user intent select a subset of tools and the pass those to the agent to execute. This reduced the tile sent to the context window dramatically, and many LLM calls end up w/o any tool calls as it's not need based on context",
          "score": 2,
          "created_utc": "2026-01-14 17:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvd9sn",
              "author": "ChronoFish",
              "text": "This is how my platform works.\n\nMaster agent selects sub agent based on context.\n\nSubagent has its own preamble and (MCP) tool set.",
              "score": 1,
              "created_utc": "2026-01-16 05:34:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzommwe",
          "author": "Swimming_Internet402",
          "text": "MCPs offer no added value over a cli",
          "score": 2,
          "created_utc": "2026-01-15 06:07:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8nqi1",
          "author": "East_Relief_4729",
          "text": "We rewrote our servers for code execution and reduced from 100k tokens to 100. Like 90% token savings\n\nwww.PatchOps.ai",
          "score": 1,
          "created_utc": "2026-01-12 21:52:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz90xko",
          "author": "circamidnight",
          "text": "What you describe isn't really an mcp problem it's an agent context management problem. If the agent bloats context with \"All The Tools\" that's bad agent design not an indictment on MCP.",
          "score": 1,
          "created_utc": "2026-01-12 22:56:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzazb42",
          "author": "lszyba1",
          "text": "Wasn't it the promise of MCP that you would pass on the answer to more specialize MCP server? Where does most of the 40k token reside? Where in a pipeline?",
          "score": 1,
          "created_utc": "2026-01-13 05:32:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvdqfm",
              "author": "ChronoFish",
              "text": "That would be highly architecture specific",
              "score": 1,
              "created_utc": "2026-01-16 05:37:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzc0kh4",
          "author": "kronnix111",
          "text": "I have developed a framework where only the context you actually need gets loaded. \nLiving Doc Framework sits a layer above ralph and mpcs and can be use for many things (start&end session, versioning, dev memory that is persistent and is shared between agents!)\nLast addition I am testing are codebase semantic releations amd first result looks very interesting. I have added some snips zo my latest post.\n\nhttps://github.com/user-hash/LivingDocFramework?tab=readme-ov-file",
          "score": 1,
          "created_utc": "2026-01-13 11:07:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzciqf2",
          "author": "digit1024",
          "text": "Mcp servers tend to expose 1000 tools with low level api and think that its ok! \nThey are written with development principles in mind instead of \"human readable\" in mind- task oriented. I've seen obsidian servers with tool names and description i could not understand! \n\nIn my app im simply implementing profiles - with subset of servers , and filtering to remove unused tools. And im carefully choosing servers. Then the agent is quite universal.",
          "score": 1,
          "created_utc": "2026-01-13 13:20:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk3rqc",
          "author": "anirishafrican",
          "text": "I found the quality of the MCP experience to depend highly on the tool descriptions and self documenting / guiding tool responses\n\nThere are also a whole range of patterns such as progressive disclosure, allowing the agent to specify the level of detail, adding explain flags, ability to dry run .etc\n\nFundamentally though it seems there are only two options :\n- Front load with exactly what should happen when certain operations occur\n- Be discoverable by something like MCP\n\nMCP itself is simply an API layer wrapper. A different protocol around that isnâ€™t going to solve the problems if you want to discoverability for agents.",
          "score": 1,
          "created_utc": "2026-01-14 15:58:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzne64q",
          "author": "ReasonUnusual4101",
          "text": "Anthropic just released a new function called MCP tool search, that allows it to dynamically load MCPâ€™s when needed in the conversation to save context. Similar to â€˜lazy loadingâ€™.",
          "score": 1,
          "created_utc": "2026-01-15 01:20:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs6j1j",
          "author": "Upstairs_Safe2922",
          "text": "Context bloat feels less like an implementation issue and more a structural one. More tool definitions leads to scale breaking fast. As you said, as context grows, execution is shaped by noise even if they are operating with correct logic. Move toward specialized agents and narrower execution surfaces seems like most logical step. Next question that goes along with that though is identifying why a tool was chosen.",
          "score": 1,
          "created_utc": "2026-01-15 19:21:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsgw57",
          "author": "PV__19",
          "text": "Well, A) there are solutions/agents to interact with MCP now..B) one of the biggest issues was/is security (partially solved by guardfive.com and similar) \nC) MCP or not, agents and ai in general is gonna cost more",
          "score": 1,
          "created_utc": "2026-01-15 20:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxxpk4",
          "author": "SafeMeasurement136",
          "text": "Maybe rule files and simple text only grep is the way to go - KISS",
          "score": 1,
          "created_utc": "2026-01-16 16:10:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbzdhz",
      "title": "MCPs are a workaround",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbzdhz/mcps_are_a_workaround/",
      "author": "Accomplished-Emu8030",
      "created_utc": "2026-01-13 18:40:19",
      "score": 37,
      "num_comments": 29,
      "upvote_ratio": 0.85,
      "text": "Youâ€™ll see posts saying â€œMCPs are a fad,â€ and other posts saying â€œMCPs are amazing.â€ I think both sides are missing the point.\n\nMCPs exist because theyâ€™re solving a very real painÂ *right now*.\n\nWhen Anthropic shipped MCP, the intent was clear: make it easier for models to plug into real systems. The â€œUSB-C for AI toolsâ€ line was great marketing, but the deeper truth is simpler: MCP fit their product constraints and made integrations safer and more repeatable.\n\nThen adoption took off and a narrative formed: â€œThis is the new wave.â€\n\nBut I donâ€™t think teams adopted MCP because everyone concluded itâ€™s the One True Interface. Adoption happened because lots of teams hit the same wall at the same time: **LLMs werenâ€™t reliable enough to write integration code live without messing it up.**\n\nIn theory, if a model could generate perfect code every time, you wouldnâ€™t need MCP. The model could just generate whatever connector you need on the spot and it would work. But that wasnâ€™t the world we were living in. Models could code, sureâ€”but â€œpretty goodâ€ isnâ€™t good enough when youâ€™re dealing with production systems, permissions, and actions that move money.\n\nFast-forward to now: models are meaningfully better at code. And you can see the product direction shifting with that reality. Anthropic started talking aboutÂ *code-based tool calling*â€”roughly: â€œwhat if tools are scripts (real code) instead of only protocol-shaped endpoints?â€ That arc naturally leads into things like Skills.\n\nThatâ€™s the part I find most interesting:Â *tooling evolves with model capability.* MCP made sense when models needed tighter guardrails. Code-first approaches make more sense as models get stronger.\n\nAnd all this brings me to what weâ€™re releasing today.\n\nWeâ€™re releasingÂ a framework called [Operai](https://github.com/brwse/operai)Â (operations + AI, and yes, a nod to operads). Call it a plug if you wantâ€”it's public and we think itâ€™s the better direction for the ecosystem.\n\nOur main thesis is: Instead of orchestrating agents + a giant pile of tools,Â *orchestrate tools with policies*Â and keep the tool surface areaÂ *small, scoped, and deliberate.*\n\nWhy?\n\n* *A dedicated toolset beats a Swiss Army knife.* You can fumble around with a â€œdo-everythingâ€ MCP, or you can just program a tool that does the jobâ€”cleanly, predictably, and safely.\n* *Policy orchestration matters more than agent orchestration.* In a real org, leadership doesnâ€™t micromanage every personâ€™s steps. They define constraints: approval rules, audit requirements, budgets, access boundaries. When you â€œorchestrate agents,â€ youâ€™re implicitly trying to micromanage. You shouldnâ€™t care about the agentâ€™s personalityâ€”you should care aboutÂ **what it is allowed to do**.\n\nOperai uses anÂ *effect-based policy system*: agents can behave flexibly, but the system enforces guardrails on side effects. The policies protect the endgame.\n\nThe workflow with operai is simple:\n\n1. Create a Git repo that stores your tools.\n2. Build tools with your favorite coding assistant + the Operai CLI.\n3. Serve them with Operai.\n\nUnder the hood we made choices that are biased toward enterprise reality and how LLMs actually behave. For example, we choseÂ RustÂ because Python/JS donâ€™t give you compile-time guaranteesâ€”and when youâ€™re exposing capabilities to an agent, you want as many guarantees as you can get.\n\n**Why do we think this is where things go?**\n\nBecause programs arenâ€™t going away. Even with infinite context, weâ€™re not â€œhedging probabilityâ€ hereâ€”weâ€™re enforcing logic: access control, schemas, invariants, side effects, logging, auditing. Those arenâ€™t optional. The transport is secondary. What we need is a solid mechanism for AI to generateÂ **good** programsâ€”not ad-hoc scripts, not unaudited glue code, but real software: versioned, typed, testable, reviewable, observable. The kind of quality level youâ€™d expect from something like ripgrep.\n\nSo our bet is simple:\n\nThe future isnâ€™t picking a single protocol and arguing forever. Itâ€™s treating tools like real softwareâ€”whether it's fully authored by a human or an AIâ€”without pretending the model is perfect.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qbzdhz/mcps_are_a_workaround/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzeuk4z",
          "author": "Biruleiby",
          "text": "i like this take. for me MCP is more like a bridge than â€œthe final interfaceâ€.  \nthe real hard part is not the transport, is all the ops: who can do what, audit trail, debugging, costs etc.  \n  \nhow do you handle RBAC / approvals / audit logs / cost limits in operai when tools start to spread in a big org?",
          "score": 5,
          "created_utc": "2026-01-13 20:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzf4wxw",
              "author": "Accomplished-Emu8030",
              "text": "Thank you! And really great question :) I actually hoped someone would ask this\n\nOperai is stateless (scalable) so it scales based on IO. Also regarding audit logs, you just hook a database to operai which captures all activity. For everything else, our effects system is what drives everything.\n\nFor example, for the things you mentioned, you can use the following policies:\n\n    [[policies]]\n    name = \"rbac-policy\"\n    version = \"1.0\"\n    \n    [[policies.effects]]\n    tool = \"admin.*\" Â  Â  Â  # Pattern matching for tool names\n    stage = \"before\" Â  Â  Â  # Run before the tool executes\n    when = \"user.id != 'Fred'\"\n    fail_message = \"permission denied: Admin access required.\"\n    \n    [[policies]]\n    name = \"deploy-approval\"\n    version = \"1.0\"\n    \n    # Initialize state\n    [[policies.context]\n    approval_status = \"pending\"\n    \n    # Rule 1: Guard the sensitive tool\n    [[policies.effects]]\n    tool = \"deploy_prod\"\n    stage = \"before\"\n    when = \"context.approval_status != 'granted'\"\n    fail_message = \"Deployment requires approval. Please run 'request_approval' first.\"\n    \n    # Rule 2: Grant approval (Action)\n    # Assumes you created an 'approve_request' tool and it was called successfully\n    [[policies.effects]]\n    tool = \"approve_request\"\n    stage = \"after\"\n    when = \"result.is_ok\"\n    [policies.effects.set]\n    approval_status = \"'granted'\"\n\nI think you can probably come up with cost control example (we'll write a list of examples in the repo at some point).\n\nYou would handle policies like you would in a large scale systems. You can bundle them however you wish and deploy it to the file system (for example, ConfigMap in K8S).",
              "score": 2,
              "created_utc": "2026-01-13 20:58:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzgbv6j",
          "author": "intertubeluber",
          "text": "I stopped reading before the pitch for your product, but the first part addresses a subset of how MCPs are useful. And MCP isnâ€™t even about guardrails.Â \n\nThey provide context that the LLMs need. Â Ie my LLM needs time know my internal database schema to build queries or optimize indexes. Or connect to my task management system. Or Spotify to create a playlist.Â \n\nMCPs provide the _model_ with a _protocol_ for the needed _context_ from different resources.Â ",
          "score": 3,
          "created_utc": "2026-01-14 00:33:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzge5la",
              "author": "Accomplished-Emu8030",
              "text": "Yesâ€”MCP gives a clean protocol for context/tool access. Agreed.\n\nBut you just said you stopped reading before the pitchâ€¦ which is the part where I explain the actual problem: MCP in enterprise isnâ€™t blocked by 'can it fetch context,' itâ€™s blocked by 'can it do it safely, compliantly, and repeatedly'.",
              "score": 0,
              "created_utc": "2026-01-14 00:45:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfmcn6",
          "author": "Low-Efficiency-9756",
          "text": "MCP is a protocol for executable tools that:\n\n1. Validate inputs â€” Schema enforcement via JSON-RPC before execution\n\n2. Mutate state â€” Write to databases, filesystems, APIs\n\n3. Return structured data â€” Not prose, actual typed responses the LLM can parse\n\n4. Maintain invariants â€” The LLM proposes, the tool validates and executes",
          "score": 2,
          "created_utc": "2026-01-13 22:19:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfpue8",
              "author": "Accomplished-Emu8030",
              "text": "I don't understand what this comment is supposed to be about; I think everyone in r/mcp knows what an MCP is for, but I need to correct several things:\n\n3. This is completely wrong. LLMs do not need structured data. They actually work better with prose. Tools return structured data for the purpose of orchestration (e.g. intercepting a tool call and doing something with that data).\n\n4. This is also completely wrong. Nothing about MCPs maintains invariants. In fact, it's one of the main reasons I created Operai. To maintain invariants.",
              "score": 1,
              "created_utc": "2026-01-13 22:36:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzft48u",
                  "author": "Low-Efficiency-9756",
                  "text": "\nJust because you donâ€™t build MCPs like that doesnâ€™t mean the rest of us donâ€™t.\n\nStructured data isnâ€™t about what LLMs â€œwork better withâ€ LLMs are stateless. They donâ€™t have data, but data is prose. When a tool returns coordinates in 3D space, thatâ€™s the interface between a stateless model and actual persistent state. The structure exists for the database, the game engine, the system, not the model. However structured data is useful for the user behind the scene, we should all be designing our tool outputs for structured data so humans can easily parse it as well. \n\nAnd â€œLLM proposes, tool validates and executesâ€ is invariant maintenance. The protocol doesnâ€™t prescribe your business rules, it ensures all mutations flow through server-controlled logic where you enforce them. Thatâ€™s the architecture.\nMCP isnâ€™t a workaround. Shallow implementations are.",
                  "score": 4,
                  "created_utc": "2026-01-13 22:53:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzhwls2",
          "author": "d2000e",
          "text": "I wrote this a while back, explaining that MCP is just one of several methods to get work done with LLMs, with other interfaces like REST and CLI being great options depending on what is needed and the context of the work.\n\n[https://www.localmemory.co/blog/the-mcp-backlash-is-missing-the-point](https://www.localmemory.co/blog/the-mcp-backlash-is-missing-the-point)",
          "score": 2,
          "created_utc": "2026-01-14 06:32:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj5tyj",
              "author": "Accomplished-Emu8030",
              "text": "Really great article. Particularly \"Domain-centric operations with semantic guarantees\". This is exactly what I'm talking about. It's funny because there are some people who view this article and see this as some negative feedback to MCPs when in reality we're really just highlighting what needs actual focus.",
              "score": 2,
              "created_utc": "2026-01-14 13:02:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjgwqo",
                  "author": "d2000e",
                  "text": "Appreciate the feedback. I think people forget that they have agency. No one has to use MCP or any other protocol. We are all free to use whatever works for our needs.\n\nFor example, I frequently use plain old JSON-RPC instead of installing an MCP. However, there are times when I need to install an MCP or use bash scripts to automate CLI commands. This is the beauty of software engineering. There is no \"one right way\" for anything.",
                  "score": 2,
                  "created_utc": "2026-01-14 14:05:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzinaq6",
          "author": "actual-time-traveler",
          "text": "Iâ€™m all for opinionated ideas in tool protocols, thanks for the work. I starred your repo and would love to give it a spin, but Iâ€™m not smart enough to understand it without examples. \n\nI really like that audit and logging are first class. The fact that MCP didnâ€™t initially spin out with built in tracing is bewildering to me.\n\nEdit: forgot to ask how does the LLM discover and load the tools into context?",
          "score": 2,
          "created_utc": "2026-01-14 10:42:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjacer",
              "author": "Accomplished-Emu8030",
              "text": "We implement a search endpoint using embeddings that can be used for semantic search. We're debating about implementing a \"code mode\" which means the tools embed their source code and provide a ripgrep like endpoint, but for our use case, the search endpoint is sufficient.",
              "score": 2,
              "created_utc": "2026-01-14 13:29:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl9czn",
          "author": "promethe42",
          "text": "I agree that code mode is better and more agentic.\n\nBut (and that's a big but) Claude Code has to burn loooots of token before being able to do integration/glue code that works.\n\nIn the other hand, code mode based on MCP tools is a good middleground when the tool schemas are clean and documented. Plus progressive disclosure can easily be implemented based on the MCP tools. Not so much on an entire code base.",
          "score": 2,
          "created_utc": "2026-01-14 19:05:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn8eam",
              "author": "Accomplished-Emu8030",
              "text": "\\> But (and that's a big but) Claude Code has to burn loooots of token before being able to do integration/glue code that works.\n\nClaude creates scripts on the fly and uses those so it's not that bad.\n\n\\> In the other hand, code mode based on MCP tools is a good middleground when the tool schemas are clean and documented.\n\nDefinitely, but it's a shit show because of how MCPs work. Even if an MCP is completely stateless, MCPs are not cross-system invariant in general. Ultimately this means you are back to just coding a server that works for your use-case which is basically just API programming again. With Operai, you can code once and it will literally expand (this is a rust joke) to every use-case (API, tools, even code mode \\[but we're not convinced code mode is actually the best solution\\]).",
              "score": 1,
              "created_utc": "2026-01-15 00:48:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzp0xkp",
                  "author": "promethe42",
                  "text": "But to create integration scripts and debug them, the LLM must inspect the code base. That burns a lot of token.\n\n\nIf the client - say Claude Code - were to save said script automatically as a shareable/reusable skill for example then that would truly be the best solution.Â ",
                  "score": 1,
                  "created_utc": "2026-01-15 08:13:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzh43nj",
          "author": "socrateslee",
          "text": "\\> In theory, if a model could generate perfect code every time, you wouldnâ€™t need MCP.\n\nI just think MCP provides a standard way to prompt what tool calls are. It is mainly used for direct communicate with LLMs. And generated code is more like to build something not only for direct use of LLMs.",
          "score": 1,
          "created_utc": "2026-01-14 03:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh543x",
              "author": "socrateslee",
              "text": "And MCP are probably 'the final interface', except it evolves itself.\n\nMCP come out at right time and only get much more adoption in the future. Consider MCP like the distance between two horses in the AI age, it already get adopted(and growing), it only becomes the distance between two wheels of cars or trains as it developed.",
              "score": 1,
              "created_utc": "2026-01-14 03:18:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhrvcq",
          "author": "Big-Victory-3948",
          "text": "MCP's are an amazing fad!",
          "score": 1,
          "created_utc": "2026-01-14 05:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzldhxs",
              "author": "Live_Vermicelli4307",
              "text": "Well, let's see how far along we can make it then.",
              "score": 1,
              "created_utc": "2026-01-14 19:24:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzi1fp3",
          "author": "Virviil",
          "text": "So, why cdylib in a world where wasm is already invented?",
          "score": 1,
          "created_utc": "2026-01-14 07:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj53le",
              "author": "Accomplished-Emu8030",
              "text": "This is on our roadmap. We want to be able to plug in to the JS community but we've been using this in server-sided/client-side code that uses Rust so far.",
              "score": 1,
              "created_utc": "2026-01-14 12:58:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzj7xmy",
                  "author": "Virviil",
                  "text": "i want to work on this. Are you hiring?",
                  "score": 1,
                  "created_utc": "2026-01-14 13:15:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzj8tky",
          "author": "Accomplished-Emu8030",
          "text": "Hey everyone. I really appreciate all the comments. The ultimate goal of this article is to present how much care needs to be made when building programs and reducing the spotlight of MCPs back to classical backend programming. Also, Operai is still in its infancy so it's experimental. We recently got it working for some of our backend infra so now we're focusing pushing this upstream and making the DX impeccable :).",
          "score": 1,
          "created_utc": "2026-01-14 13:21:05",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzoqplr",
          "author": "moonshinemclanmower",
          "text": "Mcp is a protocol... its api with, but with modern consteraints applied for realtime observation during persistent compute, and yes, its here to say, we wont go back to non streaming apis again. That's because of our CAP theorem needs when it comes to internet calls that have to have state now",
          "score": 1,
          "created_utc": "2026-01-15 06:41:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0979vs",
          "author": "McNemarra",
          "text": "I mean I think I understand what you are trying to solve and the problem is real but it just seems like everyone will build their own version of this and the big boys will win out. I'm certain this idea is being done a hundred times over a leading ai companies but good luck. Great website btw",
          "score": 1,
          "created_utc": "2026-01-18 07:34:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhy0se",
          "author": "martial_fluidity",
          "text": "Except your ai generated connector code will break as soon as that service releases a breaking change.",
          "score": -1,
          "created_utc": "2026-01-14 06:45:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy6bm9",
              "author": "Illustrious_Eye_1280",
              "text": "And then it gets patched up again, so what's the issue.",
              "score": 1,
              "created_utc": "2026-01-16 16:48:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qaur6a",
      "title": "Playwright MCP - Next Gen",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qaur6a/playwright_mcp_next_gen/",
      "author": "Dry-Requirement-3049",
      "created_utc": "2026-01-12 13:23:21",
      "score": 27,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "Hey guysss\n\nCreated an improved Playwright MCP (forked from the official Microsoft one), with improvements mostly in the LLM selection and efficiency (currently, Cursor automatically chooses its built-in scrapping, and it works bad) -  I improved the tool selection by the LLM so it prioritizes Playwright over the native scraping.\n\nLMK your thoughts after trying.\n\n[https://github.com/Playwright-os/Playwright-MCP](https://github.com/Playwright-os/Playwright-MCP)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qaur6a/playwright_mcp_next_gen/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzbcm65",
          "author": "punkpeye",
          "text": "Congrats!\n\nHost it on https://glama.ai/mcp/servers if you want active users and feedback. A better Playwright MCP server is one of the most common asks I get from our users.",
          "score": 2,
          "created_utc": "2026-01-13 07:22:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzblmvk",
              "author": "Dry-Requirement-3049",
              "text": "Hosted!\n\nPlease give it a try, and if you like it - a Github repo star. Much appreciated!",
              "score": 1,
              "created_utc": "2026-01-13 08:47:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzblw35",
                  "author": "punkpeye",
                  "text": "found it https://glama.ai/mcp/servers/@Playwright-os/Playwright-MCP\n\njust installed it and tested. works like a charm!\n\nthank you. will give it a little boost in search so that more people adopt it. working on featured servers feature as we speak\n\nwe are also going to announce revenue share soon, so you will automatically earn for every paying user that uses the server",
                  "score": 1,
                  "created_utc": "2026-01-13 08:49:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzbp1es",
                  "author": "punkpeye",
                  "text": "Just noticed that while successfully starts the browser, when I actually try to navigate it, it fails with an error:\n\n> ### Result\\nError: Browser is already in use for /root/.cache/ms-playwright/mcp-chrome, use --isolated to run multiple instances of the same browser\\n\n\nI think you need to evolve your `pnpm start` to support that.",
                  "score": 1,
                  "created_utc": "2026-01-13 09:20:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzbc2ef",
          "author": "Witty_Neat_8172",
          "text": "If you ever want your MCP to read real CI data, Iâ€™ve been using the TestDino MCP to ask Cursor/Claude things like â€œwhat were the last flaky Playwright runs on main?â€ and then open those runs to inspect them.",
          "score": 1,
          "created_utc": "2026-01-13 07:17:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf9day",
      "title": "MCP Tool Lazy Loading and TypeScript Sandbox with Workspace Output, for Claude Code. Context savings: ~97% reduction (48k to 1.1k tokens) for multi-tool workflows.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "author": "milkphetamine",
      "created_utc": "2026-01-17 09:57:25",
      "score": 22,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "https://github.com/elb-pr/claudikins-tool-executor\n\nAnthropic's API users getÂ advanced tool use - Claude writes code, executes N tools in a sandbox, returns once. Claude Code users get serial execution and lazy loading. Tool Executor brings the API pattern to Claude Code..\n\nClaude will:\n1. Use `search_tools` to find relevant tools\n2. Use `get_tool_schema` to load the exact parameters\n3. Use `execute_code` to run the generation in one shot\n \nMCP tools often return large payloads. Web scrapes, code analysis, generated content - all eating context.\n\nTool Executor intercepts responses over 200 characters and saves them to workspace files. Your code receives a reference:\n\nUnlike native MCP, Tool Executor injects guidance every session. Claude knows:\n- What MCP categories exist (ai-models, code-nav, web, knowledge, reasoning, ui)\n- When to use MCP vs basic tools\n- The exact search â†’ schema â†’ execute workflow\n\nNo guessing. No forgetting.\n\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04206p",
          "author": "punkpeye",
          "text": "/u/milkphetamine this looks like theoretically something that we could provide as part our [MCP gateway](https://glama.ai/mcp) service?\n\nMy thinking is... people deploy/add their MCP servers, then we provide a single MCP that has access to all other MCPs, that utilizes your project to actually resolve and execute tools.",
          "score": 1,
          "created_utc": "2026-01-17 14:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o047iz9",
              "author": "milkphetamine",
              "text": "Yeah that could definitely work no doubt. Feel free to message me",
              "score": 1,
              "created_utc": "2026-01-17 15:15:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o047vg7",
                  "author": "punkpeye",
                  "text": "Thanks. I will dig deeper later this afternoon and message you if any questions. A version of this has been on a TODO for a long time",
                  "score": 1,
                  "created_utc": "2026-01-17 15:17:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o030fjr",
          "author": "promethe42",
          "text": "Very good idea.\n\nTo make it even more efficient, you could mimic the skill progressive disclosure and add a list of 100 char name + description of the tools in the system prompt.\n\nIt will massively reduce the number of calls to \\`search\\_tools\\` to find relevant tools.",
          "score": 1,
          "created_utc": "2026-01-17 10:18:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o030q3k",
              "author": "milkphetamine",
              "text": "Interesting! The hooks and schema seem to do okay for chaining but there's definitely a few moments of okay that's a lot of calls but the tokens are minimal so, it's just me getting too lost in it at that point aha!\n\nOne issue I need to address though, output saves to the mcp workspace. Need to adjust it to save to project workspace. Had a few hiccups thereðŸ˜…",
              "score": 2,
              "created_utc": "2026-01-17 10:21:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03o5b2",
              "author": "Hofi2010",
              "text": "That was part of the problem why Anthropic proposed code use for MCP tools because the list of all tools and description are â€žeatingâ€œ the context window.",
              "score": 2,
              "created_utc": "2026-01-17 13:29:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04xxbn",
                  "author": "promethe42",
                  "text": "The schemas are eating a lot of tokens. But tool names and descriptions are just like skill names and descriptions.Â ",
                  "score": 3,
                  "created_utc": "2026-01-17 17:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o033c8m",
          "author": "Stock-Protection-453",
          "text": "Great effort, I also walked a similar path with Natural Context Provider [https://github.com/portel-dev/ncp](https://github.com/portel-dev/ncp)",
          "score": 0,
          "created_utc": "2026-01-17 10:45:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfop2k",
      "title": "n8n MCP Server â€“ Enables Large Language Models to interact with n8n automation instances through the Model Context Protocol. Supports workflow management, execution, credentials handling, and security audits through natural language commands.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-17 21:00:06",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qfop2k/n8n_mcp_server_enables_large_language_models_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o067jp8",
          "author": "modelcontextprotocol",
          "text": "This server has 33 tools:\n\n- [activate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/activate-workflow) â€“ Enable an n8n automation workflow to run by providing its ID. Use this tool to activate workflows for automated task execution.\n- [create-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-credential) â€“ Create authentication credentials for n8n automation workflows. Specify credential type and required data to enable nodes to connect to external services and APIs.\n- [create-project](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-project) â€“ Create new projects in n8n automation platform for organizing workflows and resources, requiring Enterprise license with project management enabled.\n- [create-tag](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-tag) â€“ Add tags to organize workflows in your n8n automation instance. Use this tool to create new tags for categorizing and managing automation processes.\n- [create-users](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-users) â€“ Add users to your n8n automation instance by specifying email addresses and roles to manage access and permissions.\n- [create-variable](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-variable) â€“ Create variables in n8n to store and share data across workflows. Requires n8n Enterprise license with variable management enabled.\n- [create-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-workflow) â€“ Build automation workflows in n8n by defining nodes and connections to automate business processes and integrate applications.\n- [deactivate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/deactivate-workflow) â€“ Stop a workflow from running by deactivating it using its ID. This prevents automated processes from executing until reactivated.\n- [delete-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-credential) â€“ Remove stored credentials by ID from n8n automation instances. Securely delete authentication data you own to manage access controls.\n- [delete-execution](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-execution) â€“ Remove a specific workflow execution by ID to manage automation history and maintain system performance.",
          "score": 3,
          "created_utc": "2026-01-17 21:00:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o06up5r",
          "author": "astrokat79",
          "text": "Any chance it has clouldflared auth for n8n instances behind token or email auth?",
          "score": 1,
          "created_utc": "2026-01-17 22:56:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcyrzk",
      "title": "Follow-up from yesterday's Code Mode post - MCP setup guide",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "author": "dinkinflika0",
      "created_utc": "2026-01-14 20:41:28",
      "score": 18,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "Got a few questions in my dms after yesterday's post about Code Mode, so writing up the actual MCP setup process since the folks asked how to get started.\n\n**Basic connection is pretty simple:**\n\nConnect to any MCP server via STDIO, HTTP, or SSE. For local tools like filesystem stuff, STDIO works fine. Remote services use HTTP.\n\n`{ \"mcp\": { \"client_configs\": [{ \"name\": \"filesystem\", \"connection_type\": \"stdio\", \"stdio_config\": { \"command\": \"npx\", \"args\": [\"-y\", \"@anthropic/mcp-filesystem\"] } }] } }`\n\n**Important security detail:**\n\nTool calls from the LLM are just suggestions by default. Nothing actually executes unless you explicitly call the execution endpoint. This caught me off guard initially but it's the right design - prevents accidental API calls or data modifications.\n\nIf you want autonomous execution, enable Agent Mode and specify which tools can auto-execute via `tools_to_auto_execute`.\n\n**Code Mode setup (from yesterday):**\n\nSet `is_code_mode_client: true` on your MCP clients. LLM writes TypeScript to orchestrate tools instead of the standard iterative approach. Cuts tokens significantly when you have multiple servers.\n\n**Tool filtering:**\n\nControl which tools are available per request or per virtual key. Useful for different environments or team permissions.\n\nBifrost can also act as an MCP server - expose your tools to Claude Desktop or other MCP clients through the gateway URL.\n\nSetup docs: [https://docs.getbifrost.ai/features/mcp](https://docs.getbifrost.ai/features/mcp)  \nGithub: [https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)\n\nAnyone run into issues setting this up?",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qcwp09",
      "title": "I built the MCP inspector I always wanted â€“ no login, full spec support, state in URL",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/inspector",
      "author": "punkpeye",
      "created_utc": "2026-01-14 19:24:18",
      "score": 16,
      "num_comments": 0,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcwp09/i_built_the_mcp_inspector_i_always_wanted_no/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qbwcuq",
      "title": "Consolidated 195 tools down to 28 using action enums",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbwcuq/consolidated_195_tools_down_to_28_using_action/",
      "author": "Low-Efficiency-9756",
      "created_utc": "2026-01-13 16:44:56",
      "score": 14,
      "num_comments": 15,
      "upvote_ratio": 0.9,
      "text": "Working on an RPG MCP server, we hit a scaling problem: every CRUD operation got its own tool. Characters alone had \\`create\\_character\\`, \\`get\\_character\\`, \\`update\\_character\\`, \\`delete\\_character\\`, \\`list\\_characters\\`. Multiply that across items, quests, combat, parties, etc. and we ended up with 195 tools and \\~50k tokens of schema definitions.\n\nThe fix was simple. Instead of separate tools per operation, we made domain tools with an \\`action\\` enum:\n\nBefore\n\ncreate\\_character\n\nget\\_character\n\nupdate\\_character\n\ndelete\\_character\n\nlist\\_characters\n\nAfter\n\ncharacter\\_manage(action: \"create\" | \"get\" | \"update\" | \"delete\" | \"list\" | \"search\")\n\nApplied across the board, this dropped us to 28 tools and \\~6-8k tokens of schema. Same functionality, 85% less overhead.\n\nWe also added fuzzy matching on action values so typos get helpful suggestions instead of opaque failures.\n\nIf youâ€™re building MCP servers and your tool count is ballooning, action enums might be worth considering. Happy to answer questions about the implementation.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qbwcuq/consolidated_195_tools_down_to_28_using_action/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzeaq62",
          "author": "Crafty_Disk_7026",
          "text": "Great tip, simple APIs with very concrete types always better with llm.   \n\nFor example never use a generic dictionary in Python as an api input.  Ensure it's string: string or string:number or Cat:Dog.   Or else the llm will just put anything there",
          "score": 3,
          "created_utc": "2026-01-13 18:39:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzipeju",
              "author": "TechToolsForYourBiz",
              "text": "llms are just typescript underneath, confirmed",
              "score": 2,
              "created_utc": "2026-01-14 11:00:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzf9aad",
              "author": "Low-Efficiency-9756",
              "text": "Thanks! Totally agree on specifying types. One of the drivers behind the consolidation was to make every parameter as explicit as possible so the model canâ€™t â€œmake upâ€ keys or values. \n\nFor example, most of our actions are enums and many of the nested fields are typed (string, integer, even specific regex patterns) rather than just any. Thatâ€™s eliminated a lot of ambiguity and improved reliability and fuzzy matching helps us to ensure that llm typos or close hallucinations still can call a tool even without exact syntax.",
              "score": 1,
              "created_utc": "2026-01-13 21:18:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzexbbd",
          "author": "Biruleiby",
          "text": "love the approach. i can see this being really useful once tool counts start to blow up.  \nhave you thought about how youâ€™d do per-action rules later (like some actions being more restricted), or is that out of scope for your setup?",
          "score": 3,
          "created_utc": "2026-01-13 20:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfaoa6",
              "author": "Low-Efficiency-9756",
              "text": "We havenâ€™t implemented per-action restrictions yet, but itâ€™s definitely something weâ€™ll need.\n\nFunny enough, Iâ€™m hitting a related problem right now. We have a simple math_tools with a dice roll function, and we have combat_manage actions that handle attacks with all the context like attacker stats, target AC, spell AoE calculations, skill checks, the works. The LLM keeps reaching for the simple dice roll instead of the combat actions that would do the heavy lifting for it.\nI think the model sees â€œI need to roll diceâ€ and pattern-matches to the simpler tool, even though the domain-specific one would give it a complete resolution in one call. Been trying to steer it with prompting but itâ€™s stubborn. The math tools were meant for crazy stuff like calculating the trajectory of a cannon ball, or calculating how far an enemy is that is flying in 3d space not simple dice rolls. \n\nSo yeah, per-action rules or even just tool prioritization/hints would help a lot. Something like â€œprefer combat_manage.attack over math_tools.roll when in combatâ€ at the schema level. Havenâ€™t figured out the cleanest way to express that yet.",
              "score": 1,
              "created_utc": "2026-01-13 21:25:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjeyxq",
                  "author": "Biruleiby",
                  "text": "oh wow, yeah iâ€™ve seen that exact behavior. two small things that sometimes help:\n\n1. rename the dice tool to make it feel â€œadvanced onlyâ€ (like `math_tools.advanced_roll` / `raw_dice_roll`) and in the description say â€œnot for combatâ€.\n2. in `combat_manage.attack` description, be super explicit: â€œuse this for any combat roll, includes dice + modifiers + resolutionâ€.\n\nwhat client are you testing with (Claude Desktop / Cursor / custom)? and do you pass any â€œmodeâ€ context like `state=combat`?",
                  "score": 2,
                  "created_utc": "2026-01-14 13:55:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfiigp",
          "author": "forgotMyPrevious",
          "text": "Ahh interesting, I totally would have split operations over dedicated tools too, because traditionally that would be the â€œcleanestâ€ way to go about it..",
          "score": 2,
          "created_utc": "2026-01-13 22:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfkbw1",
              "author": "Low-Efficiency-9756",
              "text": "Yeah itâ€™s been a learning curve for me for sure. Iâ€™m transitioning from heavy equipment operator into a more developer oriented hobby and I donâ€™t have a strong idea of what best practices are.",
              "score": 1,
              "created_utc": "2026-01-13 22:09:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhj0pj",
          "author": "raghav-mcpjungle",
          "text": "Pretty wild! Great way to reduce the tokens.  \nI'm curious though - did you also notice improvement in the LLM's accuracy?  \nI mean, the LLM still sees the same number of actions it can take overall. But did it start calling the right tool+action more often just because the token count was reduced?",
          "score": 2,
          "created_utc": "2026-01-14 04:48:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzho11y",
              "author": "Low-Efficiency-9756",
              "text": "Actually Iâ€™ve initially got less coherency than I used to have in a weird way. Earlier versions the models usually had no issue with calling the right tools, just mostly in the wrong order (need to create an item before adding to inventory type errors) \n\nIn this newest release, weâ€™re having issues getting the model to use the combat suite instead of the math suite for rolling attacks. However it handles it just fine doing manual action economy instead of the automated tool for it. \n\nThe biggest plus is that I can get way longer and cheaper sessions now that context isnâ€™t stuffed so heavily.",
              "score": 2,
              "created_utc": "2026-01-14 05:24:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzi23me",
          "author": "Maasu",
          "text": "Nice, but I think you can keep going.\n\nCheck out the meta tools pattern on this repo https://github.com/ScottRBK/forgetful\n\nThe how to use pattern almost becomes lazy loading of skills for an MCP tool",
          "score": 2,
          "created_utc": "2026-01-14 07:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzipc5e",
          "author": "TechToolsForYourBiz",
          "text": "clever",
          "score": 2,
          "created_utc": "2026-01-14 11:00:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzje64f",
          "author": "0xKoller",
          "text": "Love this!\n\nHow much was the cost of migrating this? I have some friends that have some of +100 tools",
          "score": 2,
          "created_utc": "2026-01-14 13:51:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkr1p3",
              "author": "Low-Efficiency-9756",
              "text": "Thanks! Time cost for me was about 3 hours. I donâ€™t track inference costs as I use Claude code. It was done in one sitting within the 5 hour window on the $100 plan.",
              "score": 2,
              "created_utc": "2026-01-14 17:44:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qcjnc3",
      "title": "Built a YouTube MCP Server. Routed the scraping through an API so I don't have to manage proxies",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "author": "nikhonit",
      "created_utc": "2026-01-14 10:13:29",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "been building a few agent workflows that need to ingest youtube content (summarizers, sentiment analysis, etc).\n\nthe biggest bottleneck wasn't the agent logicâ€”it was the actual data fetching. local scrapers like youtube-dl or ytdlp are great but they get throttled/blocked constantly if you run them at any real volume, and managing a rotating proxy pool for a side project is overkill.\n\nso i built a dedicated YouTube MCP Server that offloads the heavy lifting.\n\nwhat it does:\n\n* exposes tools to fetch full transcripts (with timestamps). \n* grabs video metadata (views, likes, description). \n* handles the \"rate limit\" dance externally.\n\n\n\nthe stack: instead of raw-dogging the youtube html, i routed the requests through [TranscriptAPI](https://transcriptapi.com/r/reddit/mcp)  \n  \nit basically acts as the specialized layer to ensure the data actually comes back clean without the \"verify you are human\" capchas blocking the agent.\n\nallows you to plug youtube data into cursor, windsurf, or any custom mcp client without worrying about your ip getting flagged.\n\nif youâ€™re building video-aware agents, this should save you some headache.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzipztq",
          "author": "actual-time-traveler",
          "text": "Can you post a repo?",
          "score": 2,
          "created_utc": "2026-01-14 11:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzixjbq",
          "author": "0xKoller",
          "text": "this sounds cool!\n\ncan you share a video of a use case?",
          "score": 2,
          "created_utc": "2026-01-14 12:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk1o7u",
          "author": "arnaldodelisio",
          "text": "I think too much headache for something very simple. Going to share my youtube transcription mcp when I am back to the laptop.",
          "score": 2,
          "created_utc": "2026-01-14 15:49:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkosus",
          "author": "First-Line9299",
          "text": "Try this one. They have youtube endpoints for searching YT videos and scraping subtitles https://docs.anysite.io/mcp-server/unlimited-plan",
          "score": 1,
          "created_utc": "2026-01-14 17:34:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrqvsh",
          "author": "Live_Vermicelli4307",
          "text": "Would love to see it working in action!",
          "score": 1,
          "created_utc": "2026-01-15 18:11:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf3nm3",
      "title": "mcp-graph-engine - network algorithms and visualisation for your agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "author": "utilitydelta",
      "created_utc": "2026-01-17 04:34:47",
      "score": 12,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "MCP that your agents can use to build network graphs:\n\n[https://github.com/utilitydelta/mcp-graph-engine](https://github.com/utilitydelta/mcp-graph-engine)\n\nBuild a network from your problem domain and use graph algorithms like page rank and cycle detection to analyze it.\n\nYou can also visualize graphs being built in your browser, updated in real time from your agent.\n\nTool set is light and docs are small. They won't pollute your context window. Tell me what you think!\n\n[LOTR character network](https://preview.redd.it/3vokfkl38udg1.png?width=1213&format=png&auto=webp&s=d4a374431dffb5f2bb86903dd328ed05fc5869c2)\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o03tbv4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-17 14:00:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04dei2",
              "author": "Crafty_Disk_7026",
              "text": "Your better off using ast",
              "score": 1,
              "created_utc": "2026-01-17 15:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05xqy6",
          "author": "H0BB5",
          "text": "Nice! Does it have madge support?",
          "score": 1,
          "created_utc": "2026-01-17 20:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o063w3b",
              "author": "utilitydelta",
              "text": "Don't you find these kinds of tools really noisy? It's doesn't build any level of abstraction - just funcA() -> funcB(). Personally I don't find it valuable, it becomes chaos in anything but toy code bases. You gotta use the LLM at what it's good at - checking data flow, mapping out your design invariants,visualising service dependencies, all the really important stuff!",
              "score": 1,
              "created_utc": "2026-01-17 20:41:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0af6rs",
          "author": "joanmiro",
          "text": "I was looking smith like this",
          "score": 1,
          "created_utc": "2026-01-18 13:46:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpioc",
      "title": "Is anybody using MCPs with ChatGPT?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "author": "raghav-mcpjungle",
      "created_utc": "2026-01-15 17:17:33",
      "score": 11,
      "num_comments": 15,
      "upvote_ratio": 0.92,
      "text": "I use ChatGPT mostly for all the non-coding stuff (brainstorms, travel, life, etc)\n\nI recently started connecting my MCPs to chatgpt via my gateway, mainly out of curiosity about the possibilities.\n\nI quickly realized that I mostly use MCPs for tech work only.\n\nOf course, chatgpt has \"Apps\", which are essentially mcp servers only. I just don't use most of them.\n\n  \nSo is anyone a \"power user\" of mcps on gpt?\n\nAnd are you using it for personal stuff or at your org?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzwdl0g",
          "author": "pswithlove",
          "text": "Connected it to clickhouse and team is loving it. No more asks to build UIs or reports or whatever. They simply chat with the data and Itâ€™s good enough.",
          "score": 2,
          "created_utc": "2026-01-16 10:49:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrvnl4",
          "author": "0xKoller",
          "text": "Just for really dumb stuff like calendar to plan a trip, after that nothing",
          "score": 1,
          "created_utc": "2026-01-15 18:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp2k4",
              "author": "raghav-mcpjungle",
              "text": "hmm fair, I can see some of my work becomign smoother if I integrate my calendar into gpt",
              "score": 1,
              "created_utc": "2026-01-16 07:07:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwp6az",
                  "author": "0xKoller",
                  "text": "Yeah but is not the big thing for now... untill stuff like emails unlocks maybe not that usefull\n\nyou can check with the Google Drive app, that one is kind of usefull if you want to avoid the hustle to copy/paste files",
                  "score": 1,
                  "created_utc": "2026-01-16 12:19:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzshpgk",
          "author": "naseemalnaji-mcpcat",
          "text": "Based on our findings at MCPcat <5% of agents are coming through ChatGPT ðŸ˜¬",
          "score": 1,
          "created_utc": "2026-01-15 20:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp4ez",
              "author": "raghav-mcpjungle",
              "text": "wow. where's the majority coming from I wonder",
              "score": 1,
              "created_utc": "2026-01-16 07:08:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsziii",
          "author": "digit1024",
          "text": "I use my MCp with multiple providers - sometimes with openAI, yet I find open AI overpriced ( via API ) comparing to alternatives.  \nI have to admit that I don't like the company...  this is basically a company that turned into profit company from foundation at the very moment they discovered something profitable . Shame on them.  \nAnd I hate Idea of entre humanity sending money to 4 big AI companies sooooo...",
          "score": 1,
          "created_utc": "2026-01-15 21:35:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt7fww",
              "author": "xFloaty",
              "text": "Theyâ€™re asking about using MCPs on the ChatGPT website via custom connectors",
              "score": 2,
              "created_utc": "2026-01-15 22:12:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztir9g",
                  "author": "digit1024",
                  "text": "Ohhh..... Someone is using websites? :) thanks for pointing it ðŸ˜‰\nThen the answer is no",
                  "score": 1,
                  "created_utc": "2026-01-15 23:09:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt76e2",
          "author": "tinyhousefever",
          "text": "I use MCP at ChatGTP to create, edit, publish content and  iterate SEO of my WordPress website.",
          "score": 1,
          "created_utc": "2026-01-15 22:11:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvpcyl",
              "author": "raghav-mcpjungle",
              "text": "that's the first good enterprise use case I've heard of. Otherwise people mostly seem to use it for personal only. Good stuff!",
              "score": 1,
              "created_utc": "2026-01-16 07:10:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuvr5d",
          "author": "NeoMCP_AI",
          "text": "We provide MCP servers for various tools, mainly in the GTM space. Does anyone want to try it out?",
          "score": 1,
          "created_utc": "2026-01-16 03:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzri3a0",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2026-01-15 17:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzst6so",
              "author": "Ordinary-You8102",
              "text": "Why u use google?",
              "score": 1,
              "created_utc": "2026-01-15 21:06:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzstcnl",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-15 21:07:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfahkm",
      "title": "Is there a free MCP for web and documentation search? (OpenAI Codex)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "author": "jakehj5167",
      "created_utc": "2026-01-17 11:04:43",
      "score": 10,
      "num_comments": 11,
      "upvote_ratio": 0.86,
      "text": "I'm struggling to find a way for Codex to perform thorough searches without having to pay for a plan or wasting tokens. What I've tried:\n\n* Codex's built-in web search tool: can't browse JS-only sites. In my case, it's unable to browse developer.apple.com.\n* \\`microsoft/playwright-mcp\\`: It's able to perform searches and read pages, but very heavy hit on context. Burned through 10% of the context window for a single search.\n* [Exa.ai](http://Exa.ai), [context7.com](http://context7.com), Brave Search MCP: I'm strongly turned off by the pay-per-thousand model or caps on free plans. I understand they have to make money, it's just not what I want to spend money on.\n* [https://github.com/arabold/docs-mcp-server:](https://github.com/arabold/docs-mcp-server:) I didn't test this, but I was turned off by the fact you have to run the server in the background instead of allowing it to be booted by the Codex instance (via npx) like it can for other kinds of MCP servers.\n\nDoes anyone have a solution to this that hits on all marks: free, able to read websites including JS ones, thorough and high-quality?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04jhyh",
          "author": "punkpeye",
          "text": "I think it is unlikely you will find something like Exa for free. I have implemented comparable service to Exa for our internal use case (we make hundreds of thousands of requests) and it took a lot of effort and still relies on external services (ie not free)\n\nMaybe if you define the problem better, you will find better solutions.\n\nLike, maybe you just need something that can navigate sites using browser and return markdown instead of html. There are a few of those",
          "score": 1,
          "created_utc": "2026-01-17 16:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05eqze",
          "author": "Technical-Shock-7385",
          "text": "If you Only use sub-agents for playwright-mcp you got resume of results without burning context window ?",
          "score": 1,
          "created_utc": "2026-01-17 18:38:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09qx9q",
          "author": "waxyslave",
          "text": "tavily , parallel. Very generous monthly allowances. If you want something even more basic there are website -> markdown chrome extensions.",
          "score": 1,
          "created_utc": "2026-01-18 10:35:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5szf",
          "author": "phdyle",
          "text": "Ref.tools",
          "score": 1,
          "created_utc": "2026-01-18 12:43:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o037f05",
          "author": "iohans",
          "text": "Try building your own. It will not be better than you listed, but you can get better over time and solve your current need.\n\nHybrid RAG, vector DB, rerankimg, use a sentence transformer for emeddings. Put your knowledge files in a folder, index, and wrap in an MCP Server. Claude Code or Codex will get you there in an hour. Then, hours of refining. It will be fun and yours.",
          "score": 0,
          "created_utc": "2026-01-17 11:22:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038moh",
              "author": "Express-One-1096",
              "text": "Yeah man, why not just your own llm while heâ€™s at it, maybe design his own ram aswell",
              "score": 3,
              "created_utc": "2026-01-17 11:33:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o043vlj",
                  "author": "BeautifulFeature3650",
                  "text": "Damn",
                  "score": 1,
                  "created_utc": "2026-01-17 14:56:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08ikt3",
                  "author": "Doomtrain86",
                  "text": "Yeah man, why do ANYTHING yourself ! No need for that at all !",
                  "score": 1,
                  "created_utc": "2026-01-18 04:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03lyu1",
              "author": "jakehj5167",
              "text": "It's possible, and I thought about adjusting \\`playwright-mcp\\` to be a bit lighter, but it's honestly too deep of a rabbit hole for me. That's why I hoped people had found a way around this issue already.",
              "score": 1,
              "created_utc": "2026-01-17 13:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04uu8d",
                  "author": "Terrariant",
                  "text": "Itâ€™s actually way easier than you think. I started playing around with local LLMs about 4 days ago and already have a â€œcomposer model fileâ€ that runs an LLM to select one of 9 other models that is appropriate for the prompt. RAG and database stuff I am looking into next.\n\nBut yeah, really itâ€™s becoming more of a solved problem. You can have Gemini walk you through setting it up, even",
                  "score": 2,
                  "created_utc": "2026-01-17 17:06:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03sd53",
          "author": "jakehj5167",
          "text": "So far I've found [https://github.com/jae-jae/fetcher-mcp](https://github.com/jae-jae/fetcher-mcp) which mostly does what I want, but it only started working well when I asked Codex to run it with \\`disableMedia: false\\`.",
          "score": 0,
          "created_utc": "2026-01-17 13:54:38",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdr3f7",
      "title": "MCP for dev",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "author": "ProfessionNo3952",
      "created_utc": "2026-01-15 18:12:49",
      "score": 10,
      "num_comments": 26,
      "upvote_ratio": 0.81,
      "text": "I am really into AI for code. However I cannot understand why when and for what I can use MCP as software developer. I ask ChatGPT about it but nothing helpful. May be some of you have practical experience in enterprise development using MCP?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzs360p",
          "author": "circamidnight",
          "text": "I've built mcp dev servers for specific projects with tools to run tests, lint, run etc. this is nice because our team can use the agent of their choice and the agent doesn't burn tokens figuring out the way to run some bash command for what you want to do.",
          "score": 5,
          "created_utc": "2026-01-15 19:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs7t2h",
              "author": "ProfessionNo3952",
              "text": "Sound good. Is it difficult to do?",
              "score": 1,
              "created_utc": "2026-01-15 19:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsqme0",
                  "author": "circamidnight",
                  "text": "No, I've used FastMCP, it's very simple to get started with a simple server that can say run your tests. Heck Claude code or whatever coding agent can set it up easy enough.",
                  "score": 1,
                  "created_utc": "2026-01-15 20:54:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrt18w",
          "author": "0xKoller",
          "text": "When using AI for coding, tools like Cursor, CC, or Codex can really benefit from MCPs to improve output, for example, Context7, which lets the AI query up-to-date documentation, or the Figma MCP, which an agent can use to get pixel-perfect references for a UI design youâ€™re trying to nail.",
          "score": 3,
          "created_utc": "2026-01-15 18:21:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzryn29",
              "author": "ProfessionNo3952",
              "text": "Context7 is sound really cool. May be you can share how you use it and set up it? Or may be some cool article?",
              "score": 2,
              "created_utc": "2026-01-15 18:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwph2c",
                  "author": "0xKoller",
                  "text": "Here is the official GH with the tutorial for some IDEs  \n[https://github.com/upstash/context7#installation](https://github.com/upstash/context7#installation)",
                  "score": 2,
                  "created_utc": "2026-01-16 12:21:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztk1lj",
                  "author": "colsatre",
                  "text": "https://letmegooglethat.com/?q=context7",
                  "score": 1,
                  "created_utc": "2026-01-15 23:15:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs0bd5",
              "author": "Shumuu",
              "text": "> Pixel perfect \nlol! I never get it to be pixel perfect BUT it is good to get like 90% of the way",
              "score": 2,
              "created_utc": "2026-01-15 18:53:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzslmq0",
                  "author": "finance-mcp-001",
                  "text": "The problem is that the last 10% takes two months of figuring out what happened with the 90% that took an hour.",
                  "score": 3,
                  "created_utc": "2026-01-15 20:31:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs104v",
          "author": "Capnjbrown",
          "text": "Hey, perhaps you might find some interests in my project\nI recently open sourced [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-15 18:56:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztf7jg",
              "author": "DasBlueEyedDevil",
              "text": "I feel like they compliment one another...\n\n[https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
              "score": 2,
              "created_utc": "2026-01-15 22:50:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzts27y",
                  "author": "Capnjbrown",
                  "text": "Interesting. Iâ€™ll check it out.",
                  "score": 1,
                  "created_utc": "2026-01-15 23:59:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu6ilc",
          "author": "TheLostWanderer47",
          "text": "MCP starts to make sense once an agent needs to do something outside your codebase. Itâ€™s basically a standard way to expose tools to an agent without bloating context or writing custom glue for every service. For example, when an agent needs live web data, instead of hardcoding scrapers or APIs, you can put a web-access layer behind MCP. Thatâ€™s where setups like Bright Dataâ€™s [MCP server](https://github.com/brightdata/brightdata-mcp) come in: the agent calls search/browse/extract tools on demand, and the infrastructure handles access and blocking. If your agent only works on local code or static docs, MCP adds little value.",
          "score": 2,
          "created_utc": "2026-01-16 01:18:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzur46g",
          "author": "NoAdministration6906",
          "text": "I have used mcptoolgate mcp server to guardrail the github, jira, slack for junior developers who are using coding agent to code. I can easily monitor any unwanted github actions and approve or disapprove the request like directly merging to main branch. Pretty useful",
          "score": 2,
          "created_utc": "2026-01-16 03:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrs6ko",
          "author": "requisiteString",
          "text": "What are you using to code with AI? MCP servers are like APIs for your AI agent. They allow the agent to do things with other software through a standard interface. Think of MCP like USB for your agents to connect to other apps.",
          "score": 1,
          "created_utc": "2026-01-15 18:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrsjlr",
              "author": "ProfessionNo3952",
              "text": "Yep, I got it. But using AI agent with which MCP and how can help for software development?",
              "score": 1,
              "created_utc": "2026-01-15 18:19:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzrt7ja",
                  "author": "colganc",
                  "text": "Interact with a web browser to automatically verify UI behavior as it iterates in the dev process?",
                  "score": 2,
                  "created_utc": "2026-01-15 18:22:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrw7a9",
                  "author": "SociableSociopath",
                  "text": "Youâ€™re looking for an answer that no one has because it completely depends on what youâ€™re doing and what your use cases are. There is no one magic MCP server to use itâ€™s just another name for an API",
                  "score": 2,
                  "created_utc": "2026-01-15 18:35:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvp76",
          "author": "texo_optimo",
          "text": "I have a txt2img mcp server that I connect can connect to from within any repo to gen image assets on demand. Mainly browser game image assets for my kids but works well for FE\n\nI have a governance mcp server I connect all my repos to. Guardrails \"vibecoding\" with blessed stack patterns, knowledge gained from prior ADRs, kind of a kanban board for me to either review via UI or programmatically from within the repo.",
          "score": 1,
          "created_utc": "2026-01-15 18:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzspy0d",
          "author": "naseemalnaji-mcpcat",
          "text": "I've found MCP can be really useful for integrating AI into your development workflows. For instance, you can use MCP to automate making changes to code reviews or generate test cases by connecting it with GitHub or JIRA. It's especially powerful in CI/CD pipelines for debugging based on logs.",
          "score": 1,
          "created_utc": "2026-01-15 20:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfnte",
          "author": "Prismshadow_AI",
          "text": "Think of it this way: Without MCP, your AI is like a genius stuck in a room with no internet and no windows. You have to copy-paste everying to it. With MCP, you are giving that genius a 'key' to your local dev environment.\n\nOne practical example: Yesterday I was debugging a legacy repo. Instead of pasting 10 files, I just used an MCP server to let Claude 'read' the whole folder. It found a naming conflict in a config file I didn't even tell it about. Thatâ€™s the 'aha' moment.\n\nIf you're using Claude Desktop or Cursor, just try the basic 'Google Search' or 'Filesystem' MCP first. Itâ€™s a game changer for keeping the AI in sync with what you're actually doing.",
          "score": 1,
          "created_utc": "2026-01-16 05:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyyo5e",
          "author": "Jealous_Document2508",
          "text": "MCP servers are really helpful. On a baseline, web search is a must as your agent will not have all the context needed, and will sometimes need to search the web.\n\nOn a side note, we're building an [SDK ](https://github.com/dedalus-labs/dedalus-sdk-python)at Dedalus that will allow you to use trusted MCP servers that are hosted on our marketplace. Check us out!",
          "score": 1,
          "created_utc": "2026-01-16 18:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0tgn",
          "author": "Classic_Chemical_237",
          "text": "Think of MCP as a wrapper over traditional API.\n\nIn text centric world, everything is done through chat and voice. So when you say â€œdo this for meâ€ and it needs to call some API to execute, a MCP is a reusable module which you delegate the responsibility to call the API. It can be used to run command line on local machine too.\n\nBasically itâ€™s a wrapper to call structured actions in an unstructured world",
          "score": 1,
          "created_utc": "2026-01-15 18:55:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzso3zv",
          "author": "Low-Efficiency-9756",
          "text": "Hi! Iâ€™m an mcp developer. I have a framework for LLMs that uses prompt engineering to guide agents into TDD development flows\n\nThe framework has some bolt ons mcp tools\n\nOODA mcp - full computer control for your agent (yes itâ€™s the type of server researchers would be scared of) \n\nSynch mcp - persistent memory bank for agents across workspaces (Claude code, to antigravity, to Roo code, etc.\n\nTrace mcp - consumer/ producer schema validation and bidirectional scaffolding for over 10 languages and model context protocol servers. \n\nIndex foundry mcp - Deterministic RAG pipeline  for deployed chatbots in less than an hour, while also adding to your local agents RAG capabilities. \n\nThese four tools give your agents most of the tools to fix the â€œbrain in a jarâ€ problem. \n\nIntegrate with GitHub cli, railway cli, supabase etc and you have yourself an agent that is capable of writing and deploying software on its own.",
          "score": 1,
          "created_utc": "2026-01-15 20:42:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzspkcy",
              "author": "Low-Efficiency-9756",
              "text": "Also did like to add mcp is way more than api for your agents. Any cli capable agent can use api services. \n\nMCP servers are executable tools that validate inputs (JSON-RPC), mutate state, return typed data, maintain invariants. LLM proposes, tool executes.\n\nLLMs are the hands, the database is the intelligence. MCPs allow agents to reason over state in ways that raw APIs canâ€™t. The tool enforces contracts, state persists across sessions, and the LLM doesnâ€™t have to remember, it just has to ask.",
              "score": 0,
              "created_utc": "2026-01-15 20:49:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qaq5n7",
      "title": "MCP servers aren't just another API to load test",
      "subreddit": "mcp",
      "url": "https://share.google/v1Z3q5Dq86e42z685",
      "author": "TypicalComma",
      "created_utc": "2026-01-12 09:07:29",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qaq5n7/mcp_servers_arent_just_another_api_to_load_test/",
      "domain": "share.google",
      "is_self": false,
      "comments": [
        {
          "id": "nzwd6oh",
          "author": "TypicalComma",
          "text": "Hiya All, the same brilliant colleague of mine wrote up a more hands-on follow-up on how to set up Grafana k6 to load test MCP servers. He shares his scripts, results, honest opinions and assumptions he followed. Hope it's helpful!\n\n[Implementing MCP load tests with Grafana k6](https://infobip.com/developers/blog/implementing-mcp-load-tests-with-grafana-k6)",
          "score": 1,
          "created_utc": "2026-01-16 10:46:00",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qerxaw",
      "title": "Following MCP & RAG questions: A self-hosted agent with LightRAG and MCP",
      "subreddit": "mcp",
      "url": "https://i.redd.it/7v0km08kyrdg1.png",
      "author": "motakuk",
      "created_utc": "2026-01-16 20:55:19",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qerxaw/following_mcp_rag_questions_a_selfhosted_agent/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qbmn6p",
      "title": "Jira MCP - Better than ever",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbmn6p/jira_mcp_better_than_ever/",
      "author": "EcstaticDiscussion32",
      "created_utc": "2026-01-13 09:07:41",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "Hey all!\n\nSaw the emerging wave of improving official MCPs, and wanted to give it a try.\n\nI've developed a Jira MCP - more efficient, less tools, focuses only on what matters.\n\nThe most important part is the local hosting. I don't trust remote servers.\n\nGive it a try, and don't hesitate to give the repo a star!\n\n[https://github.com/Jira-MCP/Jira-MCP](https://github.com/Jira-MCP/Jira-MCP)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qbmn6p/jira_mcp_better_than_ever/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzi681o",
          "author": "chadrik",
          "text": "404",
          "score": 1,
          "created_utc": "2026-01-14 07:59:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi8tll",
          "author": "SafetySouthern6397",
          "text": "404 error",
          "score": 1,
          "created_utc": "2026-01-14 08:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzij262",
          "author": "GuaranteeCurrent8084",
          "text": "404",
          "score": 1,
          "created_utc": "2026-01-14 10:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzovqq4",
          "author": "EcstaticDiscussion32",
          "text": "    ### Via npm (recommended)\n    \n    npm install -g jira-mcp-server\n    \n    ### From Source\n    \n    \n    1. Install dependencies: `npm install`\n    2. Build the project: `npm run build`\n    3. Configure your MCP client (see below)\n    \n    \n    ## Configuration\n    \n    \n    ### For Cursor Users\n    \n    \n    Add this to your Cursor MCP configuration (`~/.cursor/mcp.json`):\n    \n    \n    ```json\n    {\n      \"mcpServers\": {\n        \"Jira MCP\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"/path/to/mcp-server-atlassian-jira/dist/index.js\"\n          ],\n          \"env\": {\n            \"ATLASSIAN_SITE_NAME\": \"your-company\",\n            \"ATLASSIAN_USER_EMAIL\": \"your.email@company.com\",\n            \"ATLASSIAN_API_TOKEN\": \"your_api_token\"\n          }\n        }\n      }\n    }",
          "score": 1,
          "created_utc": "2026-01-15 07:25:58",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc1obq",
      "title": "Postman V3 MCP server",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qc1obq/postman_v3_mcp_server/",
      "author": "The_Post_Man_V3",
      "created_utc": "2026-01-13 20:02:57",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.91,
      "text": "easy install:\n\n    npm iÂ @postmanv3/postman-mcp-server\n\n[Git](https://github.com/PostmanV3/postman-mcp-server)\n\n[GLama](https://glama.ai/mcp/servers/@PostmanV3/mcp-PostmanV3)\n\nHope this helps! and if it does, please leave a star!\n\n  \nFull disclosure - I made this MCP server for myself because I didnt like the official one - made my cursor glitch and use wrong tools\n\nThis is not an official release by any means - just a good release that has all the tools that im using on a day to day basis",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qc1obq/postman_v3_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbpofz",
      "title": "Mapped the agent infrastructure stack - where MCP fits relative to A2A, ACP, UCP, and the payment protocols",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbpofz/mapped_the_agent_infrastructure_stack_where_mcp/",
      "author": "PutPurple844",
      "created_utc": "2026-01-13 12:09:59",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.82,
      "text": "Notion Doc: [https://agentic-ecosystem-daily.notion.site/Agentic-Ecosystem-Research-2e4ff2f808c381fab03adbe8d4b168f1](https://agentic-ecosystem-daily.notion.site/Agentic-Ecosystem-Research-2e4ff2f808c381fab03adbe8d4b168f1)  \n  \nBeen tracking how the ecosystem around MCP is evolving. Here's how I'm seeing the layers:\n\n    Commerce:      ACP (OpenAI) / UCP (Google)\n    Payments:      Visa TAP / Mastercard Agent Pay / x402\n    Agent-Agent:   A2A (Google)\n    Agent-Tool:    MCP (Anthropic)\n\nKey recent stuff:\n\n* **AAIF launched** \\- MCP, A2A, ACP now under Linux Foundation governance. Anthropic, OpenAI, Google, and Microsoft are all involved.\n* **A2A explicitly \"complements MCP\"** \\- agent-to-agent vs agent-to-tool. Boundary still fuzzy.\n* **Identity unsolved** \\- Microsoft, AWS, startups all taking different approaches. No standard for MCP server auth yet.\n* **OWASP Agentic Top 10** shipped in December â€” an actual security framework now exists.\n\nPut together a research hub covering all the protocols, payment rails, identity approaches, and security frameworks.\n\nKeeping it updated. Curious what others are seeing - especially around MCP auth patterns and how A2A/MCP will interact in practice.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qbpofz/mapped_the_agent_infrastructure_stack_where_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzouq4e",
          "author": "Prestigious-Play8738",
          "text": "Agent-Service: [UAIP](https://github.com/concierge-hq/uaip)",
          "score": 1,
          "created_utc": "2026-01-15 07:16:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpakn6",
              "author": "PutPurple844",
              "text": "UAIP looks small compared to global players, but I will add it to the page, though.",
              "score": 1,
              "created_utc": "2026-01-15 09:47:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}