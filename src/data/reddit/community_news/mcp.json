{
  "metadata": {
    "last_updated": "2026-01-04 16:46:37",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 55,
    "file_size_bytes": 82507
  },
  "items": [
    {
      "id": "1pynehb",
      "title": "MCP for a coffee machine.. Worked!",
      "subreddit": "mcp",
      "url": "https://i.redd.it/t50uyzldj5ag1.jpeg",
      "author": "Any-Way-2765",
      "created_utc": "2025-12-29 14:18:02",
      "score": 160,
      "num_comments": 19,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pynehb/mcp_for_a_coffee_machine_worked/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwll7sj",
          "author": "livecodelife",
          "text": "As a fellow weird coffee person and engineer I love this. I also love seeing someone use AI tools for fun life things as a respite from the constant â€œmillion dollar ideasâ€ everywhere. Well done, I may give this a try!",
          "score": 14,
          "created_utc": "2025-12-29 19:39:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm9ron",
              "author": "WantDollarsPlease",
              "text": "I love it as well. Especially since it's not slop",
              "score": 2,
              "created_utc": "2025-12-29 21:39:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpt9ni",
              "author": "TheAtlasMonkey",
              "text": "You cannot get million dollar ideas if you are sleepy. you need coffee.\n\nAnd now you can use just ask : Claude brew me some coffee.",
              "score": 2,
              "created_utc": "2025-12-30 11:55:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvxpbp",
              "author": "Electrical-Taro-4058",
              "text": "Fellow weird coffee engineer unite! Finally, AI being used for something that matters: nailing the perfect shot instead of drafting a 20-slide pitch deck for a \"disruptive\" coffee subscription SaaS bro scam. That $0 machine hack is the crema on top of this perfect project.",
              "score": 1,
              "created_utc": "2025-12-31 09:05:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwltsqj",
          "author": "Ok-Bedroom8901",
          "text": "Dude, you should submit this writeup for Make magazine. This is right up their alley",
          "score": 12,
          "created_utc": "2025-12-29 20:21:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnyav7",
          "author": "ParamedicAble225",
          "text": "If anyone is curious, itâ€™s basically a $1500 coffee machine that has smart features.\n\nItâ€™s a simple mcp server that connects and calls those features.Â ",
          "score": 5,
          "created_utc": "2025-12-30 03:04:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrewh5",
              "author": "Any-Way-2765",
              "text": "It's actually a $0 coffee machine ðŸ˜",
              "score": 3,
              "created_utc": "2025-12-30 17:15:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvqwcw",
                  "author": "ParamedicAble225",
                  "text": "send one over",
                  "score": 1,
                  "created_utc": "2025-12-31 08:01:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpke08",
          "author": "0MEGALUL-",
          "text": "Iâ€™m not fully grasping what AI is adding to the proces, arenâ€™t they predefined rules? \n\nVery cool project!",
          "score": 2,
          "created_utc": "2025-12-30 10:37:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpn4or",
              "author": "Any-Way-2765",
              "text": "Just brings \"3rd opinion\" if you get stuck and don't know how to tune",
              "score": 1,
              "created_utc": "2025-12-30 11:02:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwpq5uj",
                  "author": "0MEGALUL-",
                  "text": "How does it generate the 3rd option?\n\nAs I understand now, it is based on predefined rules or am i missing something",
                  "score": 2,
                  "created_utc": "2025-12-30 11:29:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpkf8z",
          "author": "Kulitorum2",
          "text": "Implemented this in Decenza|DE1:\n\n  \n[https://github.com/Kulitorum/de1-qt/releases](https://github.com/Kulitorum/de1-qt/releases)",
          "score": 2,
          "created_utc": "2025-12-30 10:38:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnc0rz",
          "author": "TurmoilX",
          "text": "This is super cool, thanks for sharing.",
          "score": 1,
          "created_utc": "2025-12-30 01:02:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwplgx6",
          "author": "Psychological_Cry920",
          "text": "OMG",
          "score": 1,
          "created_utc": "2025-12-30 10:47:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvvb7h",
          "author": "Electrical-Taro-4058",
          "text": "Finally, AI being used for the actual important work: perfecting my morning espresso instead of pitching another \"disruptive SaaS bro\" idea. That $0 coffee machine flex just makes this even better. Chefâ€™s kiss.",
          "score": 1,
          "created_utc": "2025-12-31 08:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx02nln",
          "author": "keinsaas-navigator",
          "text": "Achestra + keinsaas Navigator looks like the ultimate open source Ai implementation solution for companies!",
          "score": 1,
          "created_utc": "2026-01-01 00:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6nw1j",
          "author": "TwoOk866",
          "text": "love it! I tuned my Rocket to my espresso beans struggling with a google sheets table of data to get the right extraction. Great job!",
          "score": 1,
          "created_utc": "2026-01-02 02:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo3avp",
          "author": "some1else42",
          "text": "I have read a lot today, and this was hands down my favorite thing I have read. Well done!",
          "score": 1,
          "created_utc": "2025-12-30 03:33:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2p343",
      "title": "Run Claude Code with ollama without losing any single feature offered by Anthropic backend",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q2p343/run_claude_code_with_ollama_without_losing_any/",
      "author": "Dangerous-Dingo-5169",
      "created_utc": "2026-01-03 08:07:14",
      "score": 56,
      "num_comments": 16,
      "upvote_ratio": 0.95,
      "text": "Hey folks! Sharing an open-source project that might be useful:\n\nLynkr connects AI coding tools (like Claude Code) to multiple LLM providers with intelligent routing.  \nKey features:\n\n\\- Route between multiple providers: Databricks, Azure Ai Foundry, OpenRouter, Ollama,llama.cpp, OpenAi\n\n\\- Cost optimization through hierarchical routing, heavy prompt caching\n\n\\- Production-ready: circuit breakers, load shedding, monitoring\n\n\\- It supports all the features offered by claude code like sub agents, skills , mcp , plugins etc unlike other proxies which only supports basic tool callings and chat completions.\n\nGreat for:\n\n\\- Reducing API costs as it supports hierarchical routing where you can route requstes to smaller local models and later switch to cloud LLMs automatically.\n\n\\- Using enterprise infrastructure (Azure)\n\n\\-Â  Local LLM experimentation\n\n\\`\\`\\`bash\n\nnpm install -g lynkr\n\n\\`\\`\\`\n\nGitHub: [https://github.com/Fast-Editor/Lynkr](https://github.com/Fast-Editor/Lynkr) (Apache 2.0)\n\nWould love to get your feedback on this one. Please drop a star on the repo if you found it helpful",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1q2p343/run_claude_code_with_ollama_without_losing_any/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nxh5y9i",
          "author": "wtgserpant",
          "text": "any plan on adding bedrock as model provider?",
          "score": 2,
          "created_utc": "2026-01-03 17:59:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxiqueh",
              "author": "extra_specticles",
              "text": "Yes, please, that would be massive. /u/Dangerous-Dingo-5169",
              "score": 1,
              "created_utc": "2026-01-03 22:31:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxj0igd",
                  "author": "Dangerous-Dingo-5169",
                  "text": "Sure ðŸ‘ the next changes would be to support bedrock and LM studio",
                  "score": 2,
                  "created_utc": "2026-01-03 23:21:45",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxhw906",
          "author": "Scary-Difference630",
          "text": "Why do these projects usually not support LM Studio?",
          "score": 1,
          "created_utc": "2026-01-03 20:00:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhwsar",
              "author": "Dangerous-Dingo-5169",
              "text": "Hi thanks for the feedback \nI have nothing against LM studio and will integrate it in the near future. \nI integrated ollama and llama.cpp for supporting local models \nFrankly speaking I integrated ollama after I got a feedback asking the same \nBecause ollama was damn slow on mac m1 with 16 gb",
              "score": 2,
              "created_utc": "2026-01-03 20:03:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxidhx6",
          "author": "Nshx-",
          "text": "but i still need a subscription tu enter claude code haha. mmm",
          "score": 1,
          "created_utc": "2026-01-03 21:26:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxj0p4k",
              "author": "Dangerous-Dingo-5169",
              "text": "No \nYou would just need to connect your claude account with 0 credits",
              "score": 1,
              "created_utc": "2026-01-03 23:22:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxj5kec",
                  "author": "Nshx-",
                  "text": "**Claude Code can be used with your Claude subscription or billed based on API usage through your Console account.**\n\nSelect login method:\n\nÂ â¯ 1. Claude account with subscription Â· Pro, Max, Team, or Enterprise\n\nÂ Â  2. Anthropic Console account Â· API usage billing",
                  "score": 1,
                  "created_utc": "2026-01-03 23:48:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxektxi",
          "author": "macromind",
          "text": "This is cool, especially the \"donâ€™t lose Claude Code features\" part, most proxies break on the weird edge cases (agents, plugins, MCP, etc). How are you deciding routing by default, is it rules-based (model A for tool calls, model B for long context) or do you score requests dynamically?\n\nAlso, do you have any benchmarks on latency overhead from the proxy layer?\n\nSide note, I have been collecting examples of agent routing patterns and guardrails lately, a few notes here if useful: https://blog.promarkia.com/",
          "score": 1,
          "created_utc": "2026-01-03 08:09:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxeldv3",
              "author": "Dangerous-Dingo-5169",
              "text": "Thank you u/macromind I will definitely check the blog  \nTo answer your question on routing  \nFor now  \nits kinda rule based if you configure all 3 levels models. I have divided the models into 3 categories\n\n1. Local LLM's\n2. OpenRouter\n3. All the other cloud LLMs\n4. The reason why I did this is because for a free user local llms are not so efficient in tool use as most machines can only host smaller models. OpenRouter as well gives strict limits for free tier but its good with moderate tool calls and context length.\n5. Although you can configure individuals ones as well. Like if you only want to use local llms you can do so\n6. I hope this answers your question. Open for feedback for any of this\n7. Please drop a star on the repo if you found it helpful\n8. Thanks",
              "score": 1,
              "created_utc": "2026-01-03 08:14:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxemzkq",
          "author": "Nshx-",
          "text": "im interested... where is the proyect?",
          "score": 0,
          "created_utc": "2026-01-03 08:28:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxen5o2",
              "author": "Dangerous-Dingo-5169",
              "text": "https://github.com/Fast-Editor/Lynkr",
              "score": 2,
              "created_utc": "2026-01-03 08:30:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0onvr",
      "title": "Built a MCP server that bridges WhatsApp and AI assistants. Messages stay local, Claude/AI assistant gets real context.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q0onvr/built_a_mcp_server_that_bridges_whatsapp_and_ai/",
      "author": "felipe-adeildo",
      "created_utc": "2025-12-31 22:05:35",
      "score": 30,
      "num_comments": 12,
      "upvote_ratio": 0.95,
      "text": "Built a MCP server that bridges WhatsApp and AI assistants. Messages stay local, Claude gets real context.\n\n**What it does??**\n\n* Cross-chat search: \"Find everything Arthur said about budget\" -> searches DMs, groups, everywhere\n* Context analysis: \"Summarize my Tech Team group this week\"\n* Send messages: \"Tell Maria I'll be 10 minutes late\" ->  finds chat, sends contextually\n* Reply with context: Claude reads conversation history before responding\n* Person lookup: See all messages from someone across all chats\n* On-demand history: Load older messages from WhatsApp servers when needed\n\n**Stack:**\n\n* Go + whatsmeow (WhatsApp Web reverse engineering)\n* SQLite with full-text search indexes\n* 6 tools, 4 prompts, 4 resource guides\n* Docker deployment\n* Streamable HTTP (not SSE, neither STDIO)\n\n**Why?**\n\nTired of copy-pasting messages manually. Now Claude searches my full WhatsApp history, understands relationships, and sends contextual replies.\n\n**Repo:** [https://github.com/felipeadeildo/whatsapp-mcp](https://github.com/felipeadeildo/whatsapp-mcp)\n\n[claude.ai using the whatsapp-mcp server](https://preview.redd.it/46o3udzi9mag1.png?width=1918&format=png&auto=webp&s=5c48fc66329d19c1245d3a14fa0b5bcf123b1ac9)\n\n**Roadmap:** Voice transcription, image OCR, GraphRAG integration.",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0onvr/built_a_mcp_server_that_bridges_whatsapp_and_ai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nx1xqxt",
          "author": "Revolutionary_Sir140",
          "text": "Use both mcp and utcp",
          "score": 3,
          "created_utc": "2026-01-01 08:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx377y0",
              "author": "felipe-adeildo",
              "text": "I could be a good feature request on the repository!\n\nI really don't know utcp (until now), i can't test for now. But i'll keep it in mind!\n\nThanks",
              "score": 1,
              "created_utc": "2026-01-01 15:14:47",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx7hazl",
              "author": "Special-Click-7607",
              "text": "what is utcp?",
              "score": 1,
              "created_utc": "2026-01-02 05:35:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7ib5l",
                  "author": "Revolutionary_Sir140",
                  "text": "Universal Tool Calling Protocol, alternative to Model Context Protocol, an ai tooling that enables ai agent to call any API.",
                  "score": 2,
                  "created_utc": "2026-01-02 05:42:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzkfac",
          "author": "qwer1627",
          "text": "Good work! I built a thing like that for Reddit/Threads/GroupMe, didnt release it though because I fear the privacy implications. Innit wild how easy it is to exfil data out of these messaging apps??",
          "score": 2,
          "created_utc": "2025-12-31 22:14:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzll5v",
              "author": "felipe-adeildo",
              "text": "Yeah, WhatsApp is actually well-designed from a security architecture perspective.\n\nMost messaging apps are way easier to reverse engineer. WhatsApp has proper E2E encryption, session management, and complex sync protocols.\n\nThat's why there are so few libraries that do this ***well***. Most WhatsApp automation tools rely on browser automation (Puppeteer/Selenium) which is fragile and breaks constantly (ok, i know it occurs on bare requests too, but less...)\n\nwhatsmeow is one of the rare libraries that properly reverse-engineered the protocol and maintains compatibility. That's why this project works, and why whatsapp-mcp is written in go :p",
              "score": 6,
              "created_utc": "2025-12-31 22:21:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx17iu5",
                  "author": "admiller07",
                  "text": "Love this!  How does your mcp differ from others for WhatsApp already out there?",
                  "score": 2,
                  "created_utc": "2026-01-01 04:32:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7h846",
          "author": "Special-Click-7607",
          "text": "good one. built a personal WhatsApp scheduler using Go + whatsmeow too.  \nI was sending WhatsApp messages at 3am and I just wished something to schedule WhatsApp messages like you can do with email.",
          "score": 2,
          "created_utc": "2026-01-02 05:34:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py1t6z",
      "title": "[Release] Skill Seekers v2.5.0 - Multi-Platform Support: Convert docs to skills for Claude, Gemini, ChatGPT, or any LLM",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1py1t6z/release_skill_seekers_v250_multiplatform_support/",
      "author": "Critical-Pea-8782",
      "created_utc": "2025-12-28 20:38:35",
      "score": 30,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "Hey ðŸ‘‹\n\n  Released **Skill Seekers v2.5.0** with universal LLM support - convert any documentation into structured markdown skills.\n\n  ## What It Does\n\n  Automatically scrapes documentation websites and converts them into organized, categorized reference files with extracted code examples. Works with any LLM (local or remote).\n\n  ## New in v2.5.0: Universal Format Support\n\n  - âœ… **Generic Markdown export** - works with ANY LLM\n  - âœ… **Claude AI** format (if you use Claude)\n  - âœ… **Google Gemini** format (with grounding)\n  - âœ… **OpenAI ChatGPT** format (with vector search)\n\n  ## Why This Matters for Local LLMs\n\n  Instead of context-dumping entire docs, you get:\n  - **Organized structure**: Categorized by topic (getting-started, API, examples, etc.)\n  - **Extracted patterns**: Code examples pulled from docs with syntax highlighting\n  - **Portable format**: Pure markdown ZIP - use with Ollama, llama.cpp, or any local model\n  - **Reusable**: Build once, use with any LLM\n\n  ## Quick Example\n\n  ```bash\n  # Install\n  pip install skill-seekers\n\n  # Scrape any documentation\n  skill-seekers scrape --config configs/react.json\n\n  # Export as universal markdown\n  skill-seekers package output/react/ --target markdown\n\n  # Result: react-markdown.zip with organized .md files\n```\n\n  The output is just structured markdown files - perfect for feeding to local models or adding to your RAG pipeline.\n\n  Features\n\n  - ðŸ“„ Documentation scraping with smart categorization\n  - ðŸ™ GitHub repository analysis\n  - ðŸ“• PDF extraction (for PDF-based docs)\n  - ðŸ”€ Multi-source unified (docs + code + PDFs in one skill)\n  - ðŸŽ¯ 24 preset configs (React, Vue, Django, Godot, etc.)\n\n  Links\n\n  - GitHub: https://github.com/yusufkaraaslan/Skill_Seekers\n  - PyPI: https://pypi.org/project/skill-seekers/\n  - Release: https://github.com/yusufkaraaslan/Skill_Seekers/releases/tag/v2.5.0\n\n  MIT licensed, contributions welcome! Would love to hear what documentation you'd like to see supported.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1py1t6z/release_skill_seekers_v250_multiplatform_support/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwigyk0",
          "author": "Stock-Protection-453",
          "text": "Nice",
          "score": 2,
          "created_utc": "2025-12-29 08:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwineu8",
              "author": "Critical-Pea-8782",
              "text": "Thanks ðŸ˜Ž",
              "score": 1,
              "created_utc": "2025-12-29 09:13:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwijiqn",
          "author": "UnderstandingOwn4448",
          "text": "Nice! I have used this for 3 libraries now and it seems to work great",
          "score": 2,
          "created_utc": "2025-12-29 08:36:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwinip4",
              "author": "Critical-Pea-8782",
              "text": "Good to hear that if there are any problems or improvements you can think always happy to hear them ðŸ™‚",
              "score": 1,
              "created_utc": "2025-12-29 09:14:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzh09o",
      "title": "Six Patterns for Connecting LLM Agents to Stateful Tools",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pzh09o/six_patterns_for_connecting_llm_agents_to/",
      "author": "Low-Efficiency-9756",
      "created_utc": "2025-12-30 12:34:40",
      "score": 21,
      "num_comments": 10,
      "upvote_ratio": 0.96,
      "text": "LLMs are stateless. Your database isn't. After building several MCP servers, I distilled six patterns that make the bridge work:\n\n1. **Externalize all state**Â â€” The agent isn't smart; the database is\n2. **Rich query tools**Â â€” Let the LLM reconstruct context on demand\n3. **Composite operations**Â â€” Batch actions to reduce coordination overhead\n4. **Fuzzy input validation**Â â€” Levenshtein matching for LLM tolerance\n5. **Explicit synchronization**Â â€” Fork/snapshot models for complex state\n6. **Chat-first output**Â â€” ASCII art, visual hierarchy, fits in a chat window\n\nFull write-up with code examples in comments.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pzh09o/six_patterns_for_connecting_llm_agents_to/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwpyh6i",
          "author": "Low-Efficiency-9756",
          "text": "check out the full writeup here, no paywall: [https://mnehmos.github.io/Mnehmos/blog/stateful-mcp-architecture/](https://mnehmos.github.io/Mnehmos/blog/stateful-mcp-architecture/)",
          "score": 4,
          "created_utc": "2025-12-30 12:35:15",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwuibk3",
          "author": "jovial1991",
          "text": "Nice article!\n\nI was also wondering about the high token usage when an agent needs to call several tools, and I started writing down some of my thoughts and experiments. I came here to talk with more experienced people and check if Iâ€™m on the right path.\n\nIf you have some time, could you take a look at this draft?  \n\nhttps://gist.github.com/josealmada/27060317da5fc858d0d2efa2d3a16511\n\nThis is one way of composing operations, similar to your third pattern.\n\nIâ€™ve never written anything like this before, so any feedback is appreciated.",
          "score": 2,
          "created_utc": "2025-12-31 02:38:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0e8h",
              "author": "Low-Efficiency-9756",
              "text": "Hi, id love to review the draft, however its 404ing for me! idk if its public or not lmk!\n\nAs per your question, high token usage can be an issue. You have to be very careful at times and build safe guards into your tools. For example in my mcp server I had a read\\_file tool. simple except for the fact it read a file much larger than it should have, the context immediately jumped to 800k tokens and the chat was unrecoverable.\n\nfrom there i started to build in hard coded limits like limiting the max lines readable to 500 for read\\_file. Then when we build composite tools, we can think of different ways to do them. My favorite is enum menus where tools can be more modular and one tool can serve many different functions.\n\nThen we can also add in batch tools.  \nbatch\\_read\\_files  \nbatch\\_string\\_replace  \nbatch\\_read\\_lines  \netc\n\nthis allow us to turn 20 calls into 1. A time saver and a context saver for the misc info we get from tool outputs.",
              "score": 2,
              "created_utc": "2025-12-31 04:30:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwv0xnt",
                  "author": "jovial1991",
                  "text": "Just fixed the link!",
                  "score": 1,
                  "created_utc": "2025-12-31 04:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwv37fl",
              "author": "Low-Efficiency-9756",
              "text": "worrying about ingredient not found is a bit of design smell imo  \nThe server should validate plausibility not exact match, we can treat unknown ingredients with confidence scores rather than failures. \n\n    // Bad: Rigid lookup\n    ingredient(\"KRAFT Smooth Peanut Butter\") // Fails if not in DB\n    \n    // Your pattern: Flexible with validation\n    ingredient({\n      name: \"peanut butter\",\n      brand: \"KRAFT\",  // Optional refinement\n      fallback: \"generic_peanut_butter\",\n      nutritional_override: { /* user-provided if unknown */ }\n    })\n\nErrors as guidance is non negotiable in our loop. \n\n    // Don't negotiate. Educate.\n    {\n      error: \"INGREDIENT_AMBIGUOUS\",\n      message: \"Multiple matches for 'peanut butter'\",\n      suggestions: [\n        { id: \"pb_001\", name: \"Generic Peanut Butter\", confidence: 0.95 },\n        { id: \"pb_kraft\", name: \"KRAFT Smooth\", confidence: 0.87 }\n      ],\n      hint: \"Re-call with specific id, or provide nutritional_override for custom entry\"\n    }\n\nthe error should tell the model exactly how to fix it.",
              "score": 1,
              "created_utc": "2025-12-31 04:49:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwutohl",
          "author": "RoboCopsGoneMad",
          "text": "very interesting that you chose an RPG domain, Im working on something similar, but am focused more on RAG for rules reference and generating examples",
          "score": 2,
          "created_utc": "2025-12-31 03:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0zrg",
              "author": "Low-Efficiency-9756",
              "text": "I think rpgs are a great culmination between the stochastic nature of LLM's (telling stories and narratives) \n\nand ensuring the game is a game that follows rules (the determistic nature of tooling) \n\nI'm currently working on translating SRD 5.2 and The World's Largest Dungeon Book 1 into a RAG rules and reference server. I'm thinking a dual approach. One traditional RAG, and one an SQL mcp server. \n\nMaybe those tools in combination can give both a broad and a granular level of control for models to use Rules and Reference material.",
              "score": 1,
              "created_utc": "2025-12-31 04:34:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwq0lnj",
          "author": "JohnLebleu",
          "text": "Batching operations was the biggest game changer for my mcp servers. Speeds up the interaction a lot and it was very simple to implement. All mcp servers should have that as a feature.\n\n\nBut I do prefer sending back information in json format and instead guiding the llm on how to display the information. This way I can create a custom mcp client that doesn't use llm but can still interact with a mcp server. This can be very useful for testing.Â ",
          "score": 1,
          "created_utc": "2025-12-30 12:50:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq2wui",
              "author": "Low-Efficiency-9756",
              "text": "You can absolutely have both! I do this with a layered approach:\nThe tool returns structured JSON internally, but the final response includes a pre-formatted display string alongside the raw data or just a reformatting.",
              "score": 3,
              "created_utc": "2025-12-30 13:06:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pya8yo",
      "title": "Why I'm building my own CLIs for agents",
      "subreddit": "mcp",
      "url": "https://martinalderson.com/posts/why-im-building-my-own-clis-for-agents/",
      "author": "malderson",
      "created_utc": "2025-12-29 02:38:18",
      "score": 19,
      "num_comments": 5,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/mcp/comments/1pya8yo/why_im_building_my_own_clis_for_agents/",
      "domain": "martinalderson.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwhyzdl",
          "author": "KeithLeague",
          "text": "Hey, me too! https://enact.tools. This is a demonstration of it using playwright:  \n[https://enact.tools/blog/claude-code-superpowers](https://enact.tools/blog/claude-code-superpowers)\n\nEnact uses the \"skills\" standard but also defines a command to be executed as proposed here: https://github.com/anthropics/skills/issues/157 \n\nBasically you can define any tools `user/my-tools/playwright` or whatever and publish them so they can be searched semantically and executed via cli.\n\nI still believe MCP is the future regarding interfacing with agents, but the main tools in your context window will be for searching, registering and executing tools.",
          "score": 10,
          "created_utc": "2025-12-29 05:38:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkhsx9",
              "author": "malderson",
              "text": "Very interesting - DMed you!",
              "score": 2,
              "created_utc": "2025-12-29 16:35:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwhn34u",
          "author": "Orpheusly",
          "text": "I've also been eyeballing the MCP world recently and.. yeah it just seems like a horizontal abstraction that really isn't necessary except in certain cases.",
          "score": 3,
          "created_utc": "2025-12-29 04:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiwvdn",
          "author": "Cumak_",
          "text": "Yeah, this is the way",
          "score": 1,
          "created_utc": "2025-12-29 10:41:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkkdl6",
          "author": "circamidnight",
          "text": "Isn't it more of a problem with MCP clients though. They can, and sometimes do, allow you to assign mcp tools to certain subagents using skills or similiar mechanisms to optionaly add to context. This is more of an agent context managment problem more than something innate about MCP.\n\nI do agree that in some usecases, a simple cli tool is better than a full MCP server. But it is limited to mostly coding or technical usecases. There are many agents that we don't want to have access to a bash tool to execute our cli's.",
          "score": 1,
          "created_utc": "2025-12-29 16:47:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1yupu",
      "title": "Built a tool to make MCP execution visible, shipping v1.1.0",
      "subreddit": "mcp",
      "url": "https://v.redd.it/gsatfx60wxag1",
      "author": "hack_the_developer",
      "created_utc": "2026-01-02 13:39:40",
      "score": 19,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1q1yupu/built_a_tool_to_make_mcp_execution_visible/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q2py06",
      "title": "Claude Team MCP â€“ Enables collaboration between multiple AI models (GPT, Claude, Gemini) to work together on complex tasks, with intelligent task distribution and role-based expert assignment for code development, review, and optimization.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@7836246/claude-team-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-03 09:00:05",
      "score": 18,
      "num_comments": 3,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q2py06/claude_team_mcp_enables_collaboration_between/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nxeqlg1",
          "author": "modelcontextprotocol",
          "text": "This server has 18 tools:\n\n- [analyze_project_structure](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/analyze_project_structure) â€“ Analyze project structure to identify technology stacks and architecture patterns for development planning and optimization.\n- [ask_expert](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/ask_expert) â€“ Consult specialized experts (frontend, backend, or QA) to get targeted answers for technical questions within the Claude Team MCP collaborative environment.\n- [code_review](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/code_review) â€“ Get expert code reviews from frontend, backend, or QA specialists to improve code quality and identify issues before deployment.\n- [cost_estimate](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/cost_estimate) â€“ Estimate token usage and execution time for AI tasks to help plan resources before running complex operations.\n- [explain_plan](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/explain_plan) â€“ Analyze how a Tech Lead would distribute tasks for a given project requirement to optimize team workflow and resource allocation.\n- [fix_bug](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/fix_bug) â€“ Fix bugs in code by analyzing problematic code snippets and error descriptions to provide corrected solutions.\n- [generate_commit_message](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/generate_commit_message) â€“ Generate Git commit messages from code changes using conventional, simple, or detailed styles to document version history.\n- [history_context](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/history_context) â€“ Retrieve recent collaboration context to continue previous work by accessing the last few interactions between AI models.\n- [history_get](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/history_get) â€“ Retrieve detailed records of specific AI collaboration sessions to review task distribution, expert assignments, and workflow outcomes for analysis and optimization.\n- [history_list](https://glama.ai/mcp/servers/@7836246/claude-team-mcp/tools/history_list) â€“ Retrieve team collaboration history records to track project progress and review past interactions between AI models.",
          "score": 3,
          "created_utc": "2026-01-03 09:00:05",
          "is_submitter": true,
          "replies": [
            {
              "id": "nxfeqn3",
              "author": "volcanotnt",
              "text": "Hey man! Nice, nice! I have a questionâ€”maybe you know a solution. I want a single window where different agents can log in and collaborate between multiple AI models like GPT, Claude, Gemini, and ChatGPT to have long discussions and debates. Iâ€™d prefer a setup with login and password for the agents, but I canâ€™t seem to find one. Maybe an IDE window could work. Iâ€™ve been looking for this for a long time :D Iâ€™m willing to pay for a working version!",
              "score": 1,
              "created_utc": "2026-01-03 12:22:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxi5jce",
                  "author": "punkpeye",
                  "text": "So you have a single window, and each agent is a persona representing a different model? Who is driving the conversation?",
                  "score": 1,
                  "created_utc": "2026-01-03 20:46:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q2b0i6",
      "title": "MCP works great â€” until you actually ship.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q2b0i6/mcp_works_great_until_you_actually_ship/",
      "author": "_dremnik",
      "created_utc": "2026-01-02 21:21:23",
      "score": 16,
      "num_comments": 21,
      "upvote_ratio": 0.75,
      "text": "I wrote a blog post discussing some of the limitations of MCP.\n\nI'd love to get your guys' thoughts.\n\n* What has been your experience building apps with MCP?\n* Have you experienced the problems I discuss? How did you solve them, if so?\n\n[https://dremnik.substack.com/p/mcp-works-great-until-you-actually](https://dremnik.substack.com/p/mcp-works-great-until-you-actually)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1q2b0i6/mcp_works_great_until_you_actually_ship/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nxcebxb",
          "author": "anirishafrican",
          "text": "Honestly, I've had an incredible experience building MCP.\n\nThe thing that makes it so useful is that you can use the MCP directly from Claude code or from any other instance. And when anything goes wrong, it's got full context of what it requested and what it expected.  \n  \nYou can get an effortless stack trace and full suggestion of what to fix straight away. (Particularly powerful from Claude Code ofc)",
          "score": 3,
          "created_utc": "2026-01-02 23:35:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxceunt",
              "author": "_dremnik",
              "text": "totally agreed on the usage in Claude Code. the protocol was definitely catered towards those use cases like i mentioned in the post \n\n\\> It works well for the use cases around which it was designed (Claude Code, Cursor â€” local, single-tenant clients with a clear user scope)\n\nthe criticisms that i laid out are more geared towards a builders perspective, for people who are building agents in production systems :)",
              "score": 1,
              "created_utc": "2026-01-02 23:38:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxcfygw",
                  "author": "anirishafrican",
                  "text": "So as a consumer of the MCP server as well, it's a fair point that it's an LLM, contractless best effort approach. I've been accepting that as a given, and creating skills (playbooks in my platform - [xtended.ai](https://xtended.ai) if curious)\n\nIt has allowed consistent usage of many MCP integrations across a range of AI clients. I've baked that in now into a recommended system prompt I suggest for any users of the platform (a strange new world)\n\nHow does your tool marketplace fit into who ecosystem? e.g. Claude Web / Mobile / ChatGPT",
                  "score": 2,
                  "created_utc": "2026-01-02 23:44:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxcojsv",
          "author": "lexxwern",
          "text": "* MCP is glorified APIs for all intents and purposes\n* There's nothing an agent can't do with OpenAPI documented services vs. MCPs\n* For non-read-only agents, both APIs and MCPs need to figure out transactions a d rollback mechanisms.",
          "score": 2,
          "created_utc": "2026-01-03 00:31:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxcqh43",
              "author": "JohnLebleu",
              "text": "The big advantge of MCP is offering a \"bring your own AI\" interface to a software.Â ",
              "score": 3,
              "created_utc": "2026-01-03 00:41:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxdydze",
          "author": "[deleted]",
          "text": "Are you looking for an LSP?",
          "score": 1,
          "created_utc": "2026-01-03 05:08:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxff77v",
          "author": "Hofi2010",
          "text": "None of the problems you are citing in your article are MCP problems. MCP is, as people noted, a standardized tool interface. Very similar to rest apiâ€™s. Anything else is up to the architect and/or developer. Your REST API also has no clue about your schema, but the developer has. In the context of MCP you need to give that information either to the LLM and it will create queries based on the schema or you need to define an interface that (parameters) that are implicitly including your schema fields and tables, eg save_sale(company, thing_to_order, amount , delivery_date)",
          "score": 1,
          "created_utc": "2026-01-03 12:26:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfgqa4",
              "author": "_dremnik",
              "text": "iâ€™d love to hear how you would solve the code sandbox problem deterministically :) \n\ni donâ€™t consider passing prompts to the LLM without runtime schema checks a good solution personally..\n\nif we are supposed to build reliable agents on this then i think its reasonable to expect to be able to eliminate non-determinism as much as possible, seeing that its already so hard to build production systems reliably.",
              "score": 1,
              "created_utc": "2026-01-03 12:37:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxfhdj1",
                  "author": "Hofi2010",
                  "text": "No they are not. You are mis-understanding what MCP is trying to solve imo.",
                  "score": 1,
                  "created_utc": "2026-01-03 12:42:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxbxcib",
          "author": "Automatic-Step-9756",
          "text": "To answer your questions:\n\n1. Experience has been very exhausting with rapidly changing MCP spec, but I think now spec has been mostly stable. My servers is HTTP transport and generated from user DB schema.\n2. But having MCP server gave advantage of being able to perform CRUD operations on database using AI powered chat.\n3. We are using OAuth flow for user authentication and backed MCP server is supported with RBAC to check user's authorizations for perform activities.\n\nCheckout how we use MCP. It has simplified a user interaction a lot -Â [https://medium.com/@crudler/stop-clicking-forms-start-talking-mcp-in-crudler-45d2624fd06f](https://medium.com/@crudler/stop-clicking-forms-start-talking-mcp-in-crudler-45d2624fd06f)",
          "score": 1,
          "created_utc": "2026-01-02 22:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxby6r1",
              "author": "_dremnik",
              "text": "hmm what kind of MCP server did you implement? and what do you think about some of the issues around schema variability + context propagation that I discussed? \n\nyou can have CRUD operations against a database without MCP, and my argument is that in a lot of cases its a lot simpler to do this instead of fighting the protocol's limitations",
              "score": 1,
              "created_utc": "2026-01-02 22:09:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxc2p1i",
                  "author": "Automatic-Step-9756",
                  "text": "We do handle tool schema variability in CRUD list operation(where user is able to provide any filter condition on table columns in plain english), through instructing LLM in tool description. For context propagation have you explored around MCP sessions(mcp-session-id)?\n\nBy the way - dont want to self promote, but would recommend to try [crudler.com](http://crudler.com) to see how it takes CRUD beyond simple db operations to complicated transaction.",
                  "score": 2,
                  "created_utc": "2026-01-02 22:32:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxcfw7u",
                  "author": "JohnLebleu",
                  "text": "You can't do crud without mcp if you aren't controlling the AI agent that makes the call, that's the real advantage of mcp.Â ",
                  "score": 2,
                  "created_utc": "2026-01-02 23:43:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q3cb3r",
      "title": "PlanoA3B - fast, predictable multi-agent orchestration LLM for agentic apps",
      "subreddit": "mcp",
      "url": "https://i.redd.it/qcvp6fjfi8bg1.png",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-04 01:22:38",
      "score": 16,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1q3cb3r/planoa3b_fast_predictable_multiagent/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nxjr4ks",
          "author": "mt-beefcake",
          "text": "Ha im literally building this now, but for my home llm and agents. Im assuming it isnt free...\n\nIt is, omg thank you, saved me days to make a shittier version",
          "score": 2,
          "created_utc": "2026-01-04 01:43:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjrqzv",
              "author": "AdditionalWeb107",
              "text": "it is absolutely free of use (just not packaged in a proxy/gateway like framework that is being distributed for commercial adoption). That's the only catch, else would love for you to build and explore with this LLM\n\nAnd of course Iâ€™d love for you to try Plano the substrate . And if you like what you see drop us a star",
              "score": 4,
              "created_utc": "2026-01-04 01:47:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxk3dex",
                  "author": "mt-beefcake",
                  "text": "Hell yes dude, I will!",
                  "score": 3,
                  "created_utc": "2026-01-04 02:51:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxl1brn",
          "author": "ExtentOdd",
          "text": "great work!",
          "score": 2,
          "created_utc": "2026-01-04 06:35:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl2477",
              "author": "AdditionalWeb107",
              "text": "ðŸ™",
              "score": 1,
              "created_utc": "2026-01-04 06:42:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxm7lkl",
          "author": "SatoshiNotMe",
          "text": "Sounds very useful. What metric are you comparing, in the table shown?\nMaybe that part got cutoff",
          "score": 1,
          "created_utc": "2026-01-04 12:44:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q01twd",
      "title": "Built a leaner Microsoft Graph MCP - 7 tools instead of 37, with direct multi-tenant access",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q01twd/built_a_leaner_microsoft_graph_mcp_7_tools/",
      "author": "BTForIT",
      "created_utc": "2025-12-31 02:53:27",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "Been using Claude with Microsoft 365 via MCP and hit two frustrations:\n\n**Problem 1: Context bloat**\n\nThe popular MS Graph MCPs expose 30-40 specialized tools like `list-mail-messages`, `create-calendar-event`, `get-user`, etc. That's ~12KB of context eaten up before you even start talking. Claude already knows the Graph API - it doesn't need 37 hand-holding tools.\n\n**Problem 2: Multi-tenant switching sucks**\n\nI manage multiple M365 tenants (work, clients, personal). Every time I wanted to query a different tenant, I had to call `select-account`, wait, then make my request. Constantly switching context.\n\n**The fix:**\n\nForked the Softeria MCP and stripped it down to 7 tools:\n- `login`, `logout`, `verify-login` (auth)\n- `list-accounts`, `select-account`, `remove-account` (account management)\n- `graph-request` (one tool for ALL Graph API calls)\n\nThe `graph-request` tool takes an `accountId` parameter, so you can query any tenant directly without switching:\n\n```json\n{\n  \"endpoint\": \"/me/messages\",\n  \"accountId\": \"client-tenant-abc123\"\n}\n```\n\nQuery work and personal calendars in the same conversation. No switching dance.\n\n~1KB context instead of ~12KB. Same capabilities.\n\n**Repo:** https://github.com/ForITLLC/forit-microsoft-graph\n\nMIT licensed, fork of Softeria's work. Just a different philosophy - less is more.\n\nAnyone else running into context bloat issues with MCPs?\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q01twd/built_a_leaner_microsoft_graph_mcp_7_tools/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nxekw6n",
          "author": "FancyConversation555",
          "text": "Thanks for sharing. I did a similar thing with Databricks MCP. It was easy to write a â€œproxyâ€ mcp with limited  set of tools by combining tool calls into one.",
          "score": 1,
          "created_utc": "2026-01-03 08:10:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0eyfc",
      "title": "Homework Grading MCP â€“ Enables automated grading of student homework images using Qwen3-VL multimodal model, supporting multiple subjects and question types with detailed feedback and batch processing capabilities.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@pickstar-2002/homework-grading-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 15:00:07",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0eyfc/homework_grading_mcp_enables_automated_grading_of/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwx8fdi",
          "author": "modelcontextprotocol",
          "text": "This server has 1 tool:\n\n- [grade_homework](https://glama.ai/mcp/servers/@pickstar-2002/homework-grading-mcp/tools/grade_homework) â€“ Grade student homework by analyzing images to automatically score answers and provide detailed feedback using AI-powered assessment.",
          "score": 1,
          "created_utc": "2025-12-31 15:00:07",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0befz",
      "title": "ForIT Microsoft Graph â€“ Provides direct access to Microsoft Graph API with multi-tenant account management, allowing users to interact with Microsoft 365 services across multiple tenants through a single flexible graph-request tool.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 12:00:09",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0befz/forit_microsoft_graph_provides_direct_access_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwwglvt",
          "author": "modelcontextprotocol",
          "text": "This server has 7 tools:\n\n- [graph-request](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/graph-request) â€“ Execute Microsoft Graph API requests to access Microsoft 365 services. Target specific accounts without switching and use any Graph endpoint with query parameters.\n- [list-accounts](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/list-accounts) â€“ Retrieve all available Microsoft accounts for managing Microsoft 365 services across multiple tenants.\n- [login](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/login) â€“ Authenticate with Microsoft Graph API using device code flow to access Microsoft 365 services across multiple tenants. Manage multi-tenant accounts through a single flexible interface.\n- [logout](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/logout) â€“ Terminate active Microsoft account sessions to end access to Microsoft 365 services and protect account security.\n- [remove-account](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/remove-account) â€“ Remove cached Microsoft accounts from the ForIT Microsoft Graph server to manage multi-tenant access and maintain account security.\n- [select-account](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/select-account) â€“ Choose a specific Microsoft account to access Microsoft Graph API services across multiple tenants, enabling interaction with Microsoft 365 resources.\n- [verify-login](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/verify-login) â€“ Check current Microsoft authentication status to verify login validity before accessing Microsoft 365 services across multiple tenants.",
          "score": 3,
          "created_utc": "2025-12-31 12:00:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q11aqv",
      "title": "Protecting Your Privacy_ RedactAI MCP server",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q11aqv/protecting_your_privacy_redactai_mcp_server/",
      "author": "Gullible-Relief-5463",
      "created_utc": "2026-01-01 10:32:58",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 0.91,
      "text": "Do you send confidential documents directly to LLMs?\n\nThat means sensitive information often gets shared unfiltered by default.\n\nI built **RedactAI**, an MCP server that acts as a privacy firewall for PDFs. It detects and permanently redacts sensitive data before the document ever reaches the LLM, while preserving layout and providing an audit-friendly preview.\n\nEverything runs locally using Ollama. No cloud calls.\n\nBuilt using MCP (Anthropic) to explore how privacy can be enforced at the tool layer instead of being an afterthought.\n\nRepo: [https://github.com/AtharvSabde/RedactAI]()  \nDemo/context: [https://www.linkedin.com/posts/atharv-sabde](https://www.linkedin.com/posts/atharv-sabde-4aa272222_%F0%9D%97%97%F0%9D%97%BC-%F0%9D%98%86%F0%9D%97%BC%F0%9D%98%82-%F0%9D%98%80%F0%9D%97%B2%F0%9D%97%BB%F0%9D%97%B1-%F0%9D%97%BF%F0%9D%97%AE%F0%9D%98%84-%F0%9D%97%A3%F0%9D%97%97%F0%9D%97%99%F0%9D%98%80-%F0%9D%98%84%F0%9D%97%B6-activity-7412434987058130945-nAvk)\n\nCurious how others are handling privacy in LLM-based document workflows.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1q11aqv/protecting_your_privacy_redactai_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nx2wkzi",
          "author": "Afraid-Today98",
          "text": "Local redaction before LLM access is smart. Way better than trusting cloud providers with sensitive docs.",
          "score": 2,
          "created_utc": "2026-01-01 14:05:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx34az8",
              "author": "Gullible-Relief-5463",
              "text": "Thanks, that was exactly the goal, enforce privacy before the document ever reaches an LLM.\nIf you like the approach, a star on the repo would really help, and feel free to share it with anyone working on LLM document workflows.",
              "score": 1,
              "created_utc": "2026-01-01 14:56:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx37s0u",
          "author": "DavidAntoon",
          "text": "This is really solid work ðŸ‘\nRedacting before the document ever touches the LLM is exactly the right layer to enforce privacy.\n\nIf youâ€™re open to it, this feels like a great fit as a FrontMCP plugin.\nFrontMCP is an open-source MCP runtime with a plugin system designed specifically for tool-layer guardrails like this, so RedactAI could be easily reused across LLM document workflows without re-implementing the logic.\n\nPlugin docs: https://docs.agentfront.dev/docs/plugins/overview\n\nFrontMCP: https://github.com/agentfront/frontmcp\n\nHappy to help wire this up and contribute it back as an open-source plugin if youâ€™re interested.\n\nLove the local-only + audit-friendly approach â€” privacy by default, not by policy ðŸ‘",
          "score": 2,
          "created_utc": "2026-01-01 15:18:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx38qhd",
              "author": "Gullible-Relief-5463",
              "text": "Yes, what not!\nLet's connect and work together..also don't forget to star the repo",
              "score": 2,
              "created_utc": "2026-01-01 15:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx3ba3k",
                  "author": "DavidAntoon",
                  "text": "Starred,  you are more than welcome to star our frontmcp repo ðŸ™",
                  "score": 1,
                  "created_utc": "2026-01-01 15:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx37mif",
          "author": "chill-botulism",
          "text": "Do you plan to add support for other file types?",
          "score": 1,
          "created_utc": "2026-01-01 15:17:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx38icl",
              "author": "Gullible-Relief-5463",
              "text": "Yes ofc.\nFor now thinking of deepseek OCR for scanned docs",
              "score": 1,
              "created_utc": "2026-01-01 15:22:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3h0yb",
          "author": "General-Ear-8056",
          "text": "Looks quite interesting. Do u know the minimum hardware requirements?",
          "score": 1,
          "created_utc": "2026-01-01 16:09:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3koeu",
              "author": "Gullible-Relief-5463",
              "text": "I have noted the minimum setup in the repo. I have tested it with a 1B parameter model, which works fine even on modest hardware.\nThe exact requirements mainly depend on which Ollama model you choose, smaller models run comfortably on CPU, larger ones benefit from more RAM or a GPU.\nIf you find it useful, feel free to check out the repo and drop a star.",
              "score": 2,
              "created_utc": "2026-01-01 16:28:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6yaea",
          "author": "CaptainMalikk",
          "text": "awesome will try it boss",
          "score": 1,
          "created_utc": "2026-01-02 03:27:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx766cn",
              "author": "Gullible-Relief-5463",
              "text": "Thanks ðŸ˜Ž",
              "score": 1,
              "created_utc": "2026-01-02 04:18:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx75bm5",
          "author": "Long-Chemistry-5525",
          "text": "Curious on how this would work, do you upload the document to the mcp directly outside of the llm then reference them frm Claude? As if you are telling Claude to upload to the mcp you are already exposed",
          "score": 1,
          "created_utc": "2026-01-02 04:13:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7628o",
              "author": "Gullible-Relief-5463",
              "text": "You pass a file path to the MCP server through claude, the document is processed locally, and Claude only issues the tool call. The raw document is never exposed. You should check the repo, I have added some examples in readme..give a star on the repo if you liked it.",
              "score": 1,
              "created_utc": "2026-01-02 04:17:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzscgg",
      "title": "Best MCP servers for AI Agents",
      "subreddit": "mcp",
      "url": "https://i.redd.it/u25442aqeeag1.png",
      "author": "Worldly_Ad_2410",
      "created_utc": "2025-12-30 20:08:54",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pzscgg/best_mcp_servers_for_ai_agents/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q1przm",
      "title": "[Feedback] Counsel MCP Server: a new \"deep research\" workflow via MCP (research + synthesis with structured debates)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q1przm/feedback_counsel_mcp_server_a_new_deep_research/",
      "author": "baradas",
      "created_utc": "2026-01-02 05:04:55",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.9,
      "text": "Hey folks,\n\nKept looking for aÂ **deep research**Â workflow that acts like a good analyst team aka : gather sources, generate hypotheses, challenges/critiques, and stitch a crisp answer.Â \n\nMost DR products (or modes) end up with 1-shot DR.   \n  \nNot to forget :   \n(a) single model hallucinations (made up links anyone?)  \norÂ   \n(b) a pile of unstructured notes with lil accountability\n\nI often keep running the output copy pasting from one model to another to validate the hypothesis and synthesis.Â \n\nthe current work is inspired a ton by Karpathyâ€™s work on the LLM-council repo - over the holidays, builtÂ **Counsel MCP Server**: an MCP server that runsÂ **structured debates**Â across aÂ **family of LLM agents**Â toÂ **research + synthesize**Â with fewer silent errors. The council emphasizes: a debuggable artifact trail and a MCP integration surface that can be plugged in into any assistant.\n\nIf you want to try it, thereâ€™s aÂ **playground assistant**Â with Counsel MCP already wired up:Â [**https://counsel.getmason.io**](https://counsel.getmason.io/)\n\n# What it does ?\n\n* You submit a research question or task.\n* The server runs a structured loop with multiple LLM agents (examples: propose, critique, synthesize, optional judge).\n* You get back artifacts that make it inspectable:\n   * **final**Â synthesis (answer or plan)\n   * **critiques**Â (what got challenged and why)\n   * **decision record**Â (assumptions, key risks, what changed)\n   * **trace**Â (run timeline, optional per-agent messages, cost/latency)\n\nThis is not just \"N models voting.â€ in a round robin pattern - the council will do structured arguments and critique aimed at better research outcomes.\n\n# Have 3 top of mind questions - any feedback here would be great?\n\n1. Whatâ€™s a useful API variant here ?\n   * A singleÂ `counsel.research()`Â orÂ `counsel.debate()`Â tool plus resources?\n   * Or multiple tools (run, stream, explain, get)?\n2. Whatâ€™s the right pattern for research runs that take 10â€“60 seconds?\n   * streaming events\n   * polling resources\n   * returning everything inline\n3. What should the final artifact contain?\n   * final output only\n   * final + critiques\n   * full trace + decision record\n   * whatâ€™s the minimum that still makes this debuggable and trustworthy?\n\nGive it a spin & tell me what gives\n\nPlayground:Â [**https://counsel.getmason.io**](https://counsel.getmason.io/)\n\nIf you try it, Iâ€™d love to hear any feedback good, blahhhh, meh?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1q1przm/feedback_counsel_mcp_server_a_new_deep_research/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nx8shvk",
          "author": "baradas",
          "text": "Got asked this in a comment   \n=======================  \nReally interesting setup with the research council workflow! The \"debuggable artifact trail\" requirement resonated. Interestingly, we're seeing this a lot as critical for multi-agent MCP systems.  \n  \nHow are you currently validating that the debate structure produces reliable results, and what's been your approach to debugging when the council output is unexpected?\n\n  \nthought of throwing in some views in here  \n===================================  \n  \nOur approach has 3 layers:\n\n\\#1 - Validation: Strict JSON schemas per phase, mandatory evidence citations (no unsourced claims), and a locked Crux Registry after the Attack phase to prevent semantic drift. We validate at the structure level (schema compliant) and semantic level (crux stability, agreement thresholds per tension).\n\n\\#2 - Debugging: Every debate produces an append-only artifact trail - transcripts per role/round, the exact context each role saw (including argument shuffle order), schema repair attempts, and crux evolution. When output is out of bounds (unexpected), we trace back through - which role drove the conclusion   \nâ†’ what evidence was cited   \nâ†’ whether the crux positions shifted unexpectedly   \nâ†’ whether validation repair led to loss in nuance.\n\n\\#3 - We also support human-in-the-loop intervention (pause, steer, modify\\_tensions) for real-time course correction when you see the debate heading somewhere wrong. the \"debuggable artifact trail\" you talk abt is what this is optimized for - a multi-agent debate synthesis is only trustworthy if you can audit the reasoning chain.",
          "score": 2,
          "created_utc": "2026-01-02 12:34:19",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nx7jo32",
          "author": "Agreeable-Gur-7525",
          "text": "I'd be interested in trying it out but I'm currently working on an app. Would it be able to help with architecture and code evaluation/decisions as well?",
          "score": 1,
          "created_utc": "2026-01-02 05:53:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7k0ug",
              "author": "baradas",
              "text": "Absolutely give it a spin for this. Right now am still working on enabling direct code context via Github integrations - but if you give it a spec (e.g. markdown or PDF docs) it should work just fine.",
              "score": 2,
              "created_utc": "2026-01-02 05:56:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx7rzmd",
          "author": "akhil_agrawal08",
          "text": "This looks pretty awesome. Thanks for sharing.",
          "score": 1,
          "created_utc": "2026-01-02 07:02:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxbk6qx",
          "author": "beepdarpledoo",
          "text": "Hi. Very interesting. What debate model are you using for structured debates? Are they just prompts?",
          "score": 1,
          "created_utc": "2026-01-02 21:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbmw5i",
              "author": "baradas",
              "text": "This is derived off the DACI framework - am getting the protocol reviewed, it's an open counsel protoocl. You can go ahead and configure your own protocol btw with the admin and APIs",
              "score": 1,
              "created_utc": "2026-01-02 21:14:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pz76u0",
      "title": "I made this MCP server to cover almost any cybersecurity topic in a VPS.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pz76u0/i_made_this_mcp_server_to_cover_almost_any/",
      "author": "exitcactus",
      "created_utc": "2025-12-30 03:27:54",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.9,
      "text": "For the ones into ai stuff, I made this MCP all about cybersecurity when you self host something.\n\nhttps://github.com/girste/mcp-cybersec-watchdog\n\nEdit- if you know what to do, it's literally the same you do everyday, in hours.\n\nIf you know how to make ai (CLI) do it for you, it takes time, tokens and sometimes results \"may vary\"...\n\nWith this, in 5 seconds you have an almost complete checkup of your VPS.\n\nPlanning to expand to SSL certs and more \"corporate\" CS stuff.",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pz76u0/i_made_this_mcp_server_to_cover_almost_any/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q1qtxf",
      "title": "Swiss Health MCP Server â€“ Provides AI assistants access to 1.6 million Swiss health insurance premium records from 55 insurers across 11 years (2016-2026), enabling price comparisons, historical analysis, and finding the cheapest insurance options based on location, age, and coverage preferences.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@remoprinz/swiss-health-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-02 06:00:04",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q1qtxf/swiss_health_mcp_server_provides_ai_assistants/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx7khpc",
          "author": "modelcontextprotocol",
          "text": "This server has 4 tools:\n\n- [compare_insurers](https://glama.ai/mcp/servers/@remoprinz/swiss-health-mcp/tools/compare_insurers) â€“ Compare health insurance premiums from multiple Swiss insurers based on canton, year, age group, and franchise to identify cost-effective options.\n- [get_cheapest_insurers](https://glama.ai/mcp/servers/@remoprinz/swiss-health-mcp/tools/get_cheapest_insurers) â€“ Compare Swiss health insurance premiums to find the most affordable options based on canton, age group, deductible amount, and coverage preferences.\n- [get_database_stats](https://glama.ai/mcp/servers/@remoprinz/swiss-health-mcp/tools/get_database_stats) â€“ Retrieve database statistics including entry counts, available years, and insurers to understand the scope of Swiss health insurance premium data for analysis.\n- [get_price_history](https://glama.ai/mcp/servers/@remoprinz/swiss-health-mcp/tools/get_price_history) â€“ Track Swiss health insurance premium changes over time by insurer, canton, age group, and franchise amount to analyze cost trends and make informed coverage decisions.",
          "score": 1,
          "created_utc": "2026-01-02 06:00:04",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2thef",
      "title": "Built an MCP that replicates the exact animations from real websites",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q2thef/built_an_mcp_that_replicates_the_exact_animations/",
      "author": "TrickAd9980",
      "created_utc": "2026-01-03 12:30:43",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 0.88,
      "text": "Iâ€™ve been developing an MCP tool that lets agentic coding AI agents pull rich UI context from a single URL. It captures pixel-accurate sizing, spacing, typography, and layout, then generates Tailwind configuration, identifies animation libraries in use, and extracts the exact animations and keyframes needed to recreate the experience. It also produces screenshots for every section and component, plus additional structured metadata to make replication and iteration fast and reliable.\n\nIâ€™m planning to open-source it and I want blunt feedback from people who would actually use it. Iâ€™m especially interested in the hard problems and real-world failure cases you hit when trying to clone or modernize production UIs, and what would make this tool genuinely indispensable. Thanks.\n\nhttps://reddit.com/link/1q2thef/video/i7dl7gdno4bg1/player\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1q2thef/built_an_mcp_that_replicates_the_exact_animations/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nxhk6n5",
          "author": "TrickAd9980",
          "text": "Really curios u might find this helpfull:)",
          "score": 1,
          "created_utc": "2026-01-03 19:03:45",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxhxx69",
          "author": "EveryoneForever",
          "text": "I would. I tried to build something by similar for animations that use web gl but it didnâ€™t quiet work. Would love to give this a try",
          "score": 1,
          "created_utc": "2026-01-03 20:08:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxid2oa",
              "author": "Old-Beginning-8892",
              "text": "Really curious what was ur approach and why it didnâ€™t work? I tried too",
              "score": 1,
              "created_utc": "2026-01-03 21:24:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0t31y",
      "title": "Google Cloud Docs MCP Server â€“ Enables AI assistants to search and access Google Cloud Platform documentation in real-time, supporting 20+ GCP services with natural language queries and smart content extraction.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-01 02:00:06",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0t31y/google_cloud_docs_mcp_server_enables_ai/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx0l98t",
          "author": "modelcontextprotocol",
          "text": "This server has 4 tools:\n\n- [fetch_google_cloud_doc](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/fetch_google_cloud_doc) â€“ Extract content from specific Google Cloud documentation pages by providing the exact path to retrieve detailed technical information in structured format.\n- [get_api_reference](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/get_api_reference) â€“ Retrieve REST API documentation for Google Cloud services to access endpoints, methods, and parameters for integration development.\n- [list_google_cloud_products](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/list_google_cloud_products) â€“ Discover available Google Cloud products and their documentation paths to explore services or find correct product IDs for further research.\n- [search_google_cloud_docs](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/search_google_cloud_docs) â€“ Search Google Cloud documentation to find configuration guides, best practices, and troubleshooting steps for GCP services like Compute Engine, Cloud Storage, BigQuery, and Kubernetes.",
          "score": 2,
          "created_utc": "2026-01-01 02:00:06",
          "is_submitter": true,
          "replies": []
        }
      ]
    }
  ]
}