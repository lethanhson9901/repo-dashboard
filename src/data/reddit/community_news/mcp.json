{
  "metadata": {
    "last_updated": "2026-01-02 16:25:50",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 46,
    "total_comments": 99,
    "file_size_bytes": 176420
  },
  "items": [
    {
      "id": "1pynehb",
      "title": "MCP for a coffee machine.. Worked!",
      "subreddit": "mcp",
      "url": "https://i.redd.it/t50uyzldj5ag1.jpeg",
      "author": "Any-Way-2765",
      "created_utc": "2025-12-29 14:18:02",
      "score": 156,
      "num_comments": 19,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pynehb/mcp_for_a_coffee_machine_worked/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwll7sj",
          "author": "livecodelife",
          "text": "As a fellow weird coffee person and engineer I love this. I also love seeing someone use AI tools for fun life things as a respite from the constant ‚Äúmillion dollar ideas‚Äù everywhere. Well done, I may give this a try!",
          "score": 14,
          "created_utc": "2025-12-29 19:39:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm9ron",
              "author": "WantDollarsPlease",
              "text": "I love it as well. Especially since it's not slop",
              "score": 2,
              "created_utc": "2025-12-29 21:39:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwpt9ni",
              "author": "TheAtlasMonkey",
              "text": "You cannot get million dollar ideas if you are sleepy. you need coffee.\n\nAnd now you can use just ask : Claude brew me some coffee.",
              "score": 2,
              "created_utc": "2025-12-30 11:55:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvxpbp",
              "author": "Electrical-Taro-4058",
              "text": "Fellow weird coffee engineer unite! Finally, AI being used for something that matters: nailing the perfect shot instead of drafting a 20-slide pitch deck for a \"disruptive\" coffee subscription SaaS bro scam. That $0 machine hack is the crema on top of this perfect project.",
              "score": 1,
              "created_utc": "2025-12-31 09:05:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwltsqj",
          "author": "Ok-Bedroom8901",
          "text": "Dude, you should submit this writeup for Make magazine. This is right up their alley",
          "score": 11,
          "created_utc": "2025-12-29 20:21:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnyav7",
          "author": "ParamedicAble225",
          "text": "If anyone is curious, it‚Äôs basically a $1500 coffee machine that has smart features.\n\nIt‚Äôs a simple mcp server that connects and calls those features.¬†",
          "score": 5,
          "created_utc": "2025-12-30 03:04:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrewh5",
              "author": "Any-Way-2765",
              "text": "It's actually a $0 coffee machine üòÅ",
              "score": 3,
              "created_utc": "2025-12-30 17:15:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwvqwcw",
                  "author": "ParamedicAble225",
                  "text": "send one over",
                  "score": 1,
                  "created_utc": "2025-12-31 08:01:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpke08",
          "author": "0MEGALUL-",
          "text": "I‚Äôm not fully grasping what AI is adding to the proces, aren‚Äôt they predefined rules? \n\nVery cool project!",
          "score": 2,
          "created_utc": "2025-12-30 10:37:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpn4or",
              "author": "Any-Way-2765",
              "text": "Just brings \"3rd opinion\" if you get stuck and don't know how to tune",
              "score": 1,
              "created_utc": "2025-12-30 11:02:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwpq5uj",
                  "author": "0MEGALUL-",
                  "text": "How does it generate the 3rd option?\n\nAs I understand now, it is based on predefined rules or am i missing something",
                  "score": 2,
                  "created_utc": "2025-12-30 11:29:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpkf8z",
          "author": "Kulitorum2",
          "text": "Implemented this in Decenza|DE1:\n\n  \n[https://github.com/Kulitorum/de1-qt/releases](https://github.com/Kulitorum/de1-qt/releases)",
          "score": 2,
          "created_utc": "2025-12-30 10:38:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnc0rz",
          "author": "TurmoilX",
          "text": "This is super cool, thanks for sharing.",
          "score": 1,
          "created_utc": "2025-12-30 01:02:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwplgx6",
          "author": "Psychological_Cry920",
          "text": "OMG",
          "score": 1,
          "created_utc": "2025-12-30 10:47:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvvb7h",
          "author": "Electrical-Taro-4058",
          "text": "Finally, AI being used for the actual important work: perfecting my morning espresso instead of pitching another \"disruptive SaaS bro\" idea. That $0 coffee machine flex just makes this even better. Chef‚Äôs kiss.",
          "score": 1,
          "created_utc": "2025-12-31 08:43:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx02nln",
          "author": "keinsaas-navigator",
          "text": "Achestra + keinsaas Navigator looks like the ultimate open source Ai implementation solution for companies!",
          "score": 1,
          "created_utc": "2026-01-01 00:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6nw1j",
          "author": "TwoOk866",
          "text": "love it! I tuned my Rocket to my espresso beans struggling with a google sheets table of data to get the right extraction. Great job!",
          "score": 1,
          "created_utc": "2026-01-02 02:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo3avp",
          "author": "some1else42",
          "text": "I have read a lot today, and this was hands down my favorite thing I have read. Well done!",
          "score": 1,
          "created_utc": "2025-12-30 03:33:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1px5ty7",
      "title": "3 months update: CodeGraphContext is now real, shipped, and used!",
      "subreddit": "mcp",
      "url": "https://i.redd.it/eoki975dps9g1.png",
      "author": "Desperate-Ad-9679",
      "created_utc": "2025-12-27 19:09:03",
      "score": 119,
      "num_comments": 21,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1px5ty7/3_months_update_codegraphcontext_is_now_real/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw9bcpe",
          "author": "ubiquae",
          "text": "Great work. Is this graphrag? Storing embeddings in the graph as well? Was your stack built from scratch or are you relying on any graphrag solution out there?",
          "score": 2,
          "created_utc": "2025-12-27 21:44:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbt38w",
              "author": "Desperate-Ad-9679",
              "text": "Yes this is graphrag but the retrieval isn't done using embeddings but by algorithmic graph traversal. The entire product's retrieval has been built from scratch.",
              "score": 2,
              "created_utc": "2025-12-28 07:08:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwc0s7f",
                  "author": "DeathShot7777",
                  "text": "I am facing the issue of Graph RAG exhausting model context size especially for monorepos. So thinking of combining with RAG for jumping into nodes and then using the graph relations for further retrieval. So skipping the entire node by node relation jumping process and context size limitation. How r u handling this?",
                  "score": 1,
                  "created_utc": "2025-12-28 08:21:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwerogc",
          "author": "Jakedismo",
          "text": "I built something very similar started before you did but finished later :D Threw in a Agent to reduce cognitive load from too many tools exposed to agents! What do you think! [https://github.com/Jakedismo/codegraph-rust](https://github.com/Jakedismo/codegraph-rust)",
          "score": 2,
          "created_utc": "2025-12-28 19:07:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwff4xg",
              "author": "Desperate-Ad-9679",
              "text": "That's great !",
              "score": 1,
              "created_utc": "2025-12-28 21:00:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9pzhx",
          "author": "MDSExpro",
          "text": "> production-grade\n\n> no streamable-http\n\nWell...",
          "score": 2,
          "created_utc": "2025-12-27 23:03:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbsy75",
              "author": "Desperate-Ad-9679",
              "text": "Hey, this tool has been developed to be installed on individual laptops. I am trying to make a streaming http, but that needs a lot of time and skills for a single developer, hence blocking some time. Thanks for your suggestion!",
              "score": 2,
              "created_utc": "2025-12-28 07:07:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwc0ei3",
          "author": "DeathShot7777",
          "text": "I m working on this. Had the similar thought. Please check. https://github.com/abhigyanpatwari/GitNexus\n\nIts works fully in browser with webassembly, including the graph db (kuzudb-wasm). \n\nCurrently working on embedings pipeline testing snowflake/arctic-xs for the embedings, hoping vector tool will help quickly point the LLM to the correct nodes after which it can use graph tool for further relation based retrieval ( graph rag + vector rag approach). Arctic xs being 22M model should rolun in browser easily\n\nAny advice will help. Working on it as a student ( my unique take on DSA practice, AI systems engineering, optimizations, etc )",
          "score": 1,
          "created_utc": "2025-12-28 08:17:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc280p",
              "author": "ubiquae",
              "text": "Kuzu has been discontinued, fyi",
              "score": 2,
              "created_utc": "2025-12-28 08:35:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwc52bd",
                  "author": "DeathShot7777",
                  "text": "Well idk any db that has a webassembly version and supports both graph data and embedings support. ü•≤",
                  "score": 1,
                  "created_utc": "2025-12-28 09:02:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwcs4fn",
                  "author": "DeathShot7777",
                  "text": "Someone forked kuzu and made ladybug db, if they maintain it maybe this will save itü•π",
                  "score": 1,
                  "created_utc": "2025-12-28 12:37:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfeu6n",
          "author": "noctrex",
          "text": "Seems interesting, will you also release docker images on github ?",
          "score": 1,
          "created_utc": "2025-12-28 20:59:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwffgwn",
              "author": "Desperate-Ad-9679",
              "text": "We already have a Docker-image published by one of our contributors, but if you need the latest version, I would request you to check out the Github page exactly after 24 hrs. I have made a lot of changes in the older version.",
              "score": 1,
              "created_utc": "2025-12-28 21:02:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwk2387",
          "author": "cromand3r",
          "text": "niiiiice.",
          "score": 1,
          "created_utc": "2025-12-29 15:20:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkkrm9",
              "author": "Desperate-Ad-9679",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2025-12-29 16:49:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pulvsb",
      "title": "Introducing Narsil MCP: The Blazing-Fast, Reforged Code Intelligence Server for AI Assistants (Built in Rust!)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pulvsb/introducing_narsil_mcp_the_blazingfast_reforged/",
      "author": "lpostrv",
      "created_utc": "2025-12-24 12:05:32",
      "score": 62,
      "num_comments": 41,
      "upvote_ratio": 0.92,
      "text": "Hey r/mcp r/MCPservers r/rust r/programming r/opensource consider this my Christmas present to the opensource community.   \n  \nAs a security guy/dev chasing that \"one tool to rule them all\" vibe, I'm excited to share Narsil MCP - my open-source code intelligence server. Named after the legendary sword from LotR (Anduril was taken üòÖ).\n\n**What Is It?**\n\nA privacy-first, Rust-powered MCP server that supercharges AI assistants (Claude, Cursor, VS Code Copilot). Point it at your repos, get deep code insights via **76 specialized tools** \\- from neural semantic search to taint analysis and SBOM generation.\n\nNo cloud. Everything local. Blazingly fast **(\\~2 GiB/s parsing, sub-microsecond lookups).**\n\n**Why I Built This:**\n\nTired of fragmented tools that leak data or crawl at snail pace. **Narsil is:**\n\n* **14 Languages** \\- Rust, Python, JS/TS, Go, C/C++, Java, C#, Bash, Ruby, Kotlin, PHP with Tree-sitter precision\n* **Neural Search** \\- Voyage/OpenAI embeddings or local ONNX - find similar code even when names differ\n* **Security Fortress** \\- 111 rules for OWASP Top 10/CWE Top 25, taint tracking, fix suggestions\n* **Supply Chain** \\- SBOM generation (CycloneDX/SPDX), dependency vulns via OSV, license compliance\n* **Advanced Analysis** \\- Call graphs, CFG/DFG, type inference (Python/JS/TS without mypy/tsc), dead code detection\n* **WebAssembly** \\- Run in-browser for code playgrounds (\\~2-3MB gzipped)\n* **Visualisation Frontend** \\- Embedded web UI for interactive graphs (call flows, import graphs, complexity overlays)\n\n**Benchmarks**\n\n* Parsing throughput - **1.98 GiB/s**\n* Symbol lookup  - **483 ns**\n* BM25 full-text - **80 ¬µs**\n* Linux kernel (78K files) - **45 seconds**\n\n*All offline-first, parallelised via Rayon, fully MCP-compliant.*\n\n**v1.0.0 Highlights**\n\n* **359 passing tests,** Criterion benchmarks\n* **Security hardening** (secret redaction, file size limits, path traversal fixes)\n* **Built-in type inference** for Python/JS/TS\n* **Neural embeddings** with semantic clone detection\n* **One-click installer script**\n* **Dual-licensed** MIT OR Apache-2.0\n\n**Try it out:**\n\n**One-liner install:**\n\n  `curl -fsSL` [`https://raw.githubusercontent.com/postrv/narsil-mcp/main/install.sh`](https://raw.githubusercontent.com/postrv/narsil-mcp/main/install.sh) `| bash`\n\n**Or via Cargo:**\n\n  `cargo install narsil-mcp`\n\n* Repo: [https://github.com/postrv/narsil-mcp](https://github.com/postrv/narsil-mcp)\n* Crates.io: [https://crates.io/crates/narsil-mcp](https://crates.io/crates/narsil-mcp) \n* Awesome MCP Servers: [https://mcpservers.org/servers/postrv/narsil-mcp](https://mcpservers.org/servers/postrv/narsil-mcp)\n\nStar if you like it, fork/contribute if you spot issues, or give me \\*polite feedback\\* in the comments - let's reforge code intelligence together!\n\nPlease let me know what features you would like to see next!\n\nCheers,\n\npostrv\n\nP.S. \"And in the darkness bind them... with unbreakable code graphs.\" üó°Ô∏è",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pulvsb/introducing_narsil_mcp_the_blazingfast_reforged/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nvplh09",
          "author": "Odaven",
          "text": "Awesome, thanks a lot for your work I'll give it try. \n\nHappy Xmas",
          "score": 2,
          "created_utc": "2025-12-24 12:58:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq3ryv",
              "author": "lpostrv",
              "text": "Thank you! Let me know what you think! Merry Xmas!",
              "score": 1,
              "created_utc": "2025-12-24 14:53:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvxyc19",
          "author": "Bitflight",
          "text": "Can you demonstrate it being used? Are you wrapping it with a plugin? An agent. A skill. A set of scenarios it should be called on by Claude?",
          "score": 2,
          "created_utc": "2025-12-25 23:39:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgy8n0",
              "author": "lpostrv",
              "text": "Yes. I added a whole batch of playbooks: [https://github.com/postrv/narsil-mcp?tab=readme-ov-file#playbooks--tutorials](https://github.com/postrv/narsil-mcp?tab=readme-ov-file#playbooks--tutorials) let me know if that helps. I'll add some gifs and videos when I get a chance but those playbooks should get you started.",
              "score": 2,
              "created_utc": "2025-12-29 01:51:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgycda",
                  "author": "Bitflight",
                  "text": "Thanks a lot :)",
                  "score": 1,
                  "created_utc": "2025-12-29 01:52:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvy15j8",
          "author": "IPv6Address",
          "text": "76 tools? Isn‚Äôt that much too many? About how many tokens does Narsil add to the context window with this many tools enabled?",
          "score": 2,
          "created_utc": "2025-12-25 23:57:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy9pmj",
              "author": "Cremeduchocolat",
              "text": "Is there any way to disable some tools with the options ? or should we clone the project, then do for exemple this ? \n\n    cargo build --release --features neural",
              "score": 1,
              "created_utc": "2025-12-26 00:51:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwdz1sn",
                  "author": "lpostrv",
                  "text": "Good point - see also my comments about new functionality to improve this here: [https://www.reddit.com/r/mcp/comments/1pulvsb/comment/nwdyw0l/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/mcp/comments/1pulvsb/comment/nwdyw0l/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
                  "score": 1,
                  "created_utc": "2025-12-28 16:50:35",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwdyw0l",
              "author": "lpostrv",
              "text": "Hey that's a good point - I just shipped v1.1.0 and added presets for subsets of the tools so you don't burn unnecessary context if you don't need to (in addition to the comment re: feature flaggin below). There are some figures in the README. In general, the tradeoff re: token use is that you want to know that you're spending tokens to get good context. So, like any MCP server, yes Narsil burns tokens, but it should be able to give you context that no other tool can. Think of it as high return on investment for context tokens.   \nGive the presets a try and let me know what you think.",
              "score": 1,
              "created_utc": "2025-12-28 16:49:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3r44y",
          "author": "Jakedismo",
          "text": "I built something similar earlier but didn't want to explode the clients with cognitive load from multiple tools so I embedded an Agent into the MCP-server [https://github.com/Jakedismo/codegraph-rust](https://github.com/Jakedismo/codegraph-rust)",
          "score": 2,
          "created_utc": "2025-12-26 23:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw3w08q",
              "author": "IPv6Address",
              "text": "Any plans for windows OS support?",
              "score": 1,
              "created_utc": "2025-12-26 23:59:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwdz8yg",
                  "author": "lpostrv",
                  "text": "Not sure if aimed at me or jakedismo, but have improved Windows OS support in Narsil in v1.1.0",
                  "score": 1,
                  "created_utc": "2025-12-28 16:51:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwdz52b",
              "author": "lpostrv",
              "text": "This looks dope! Great work.",
              "score": 1,
              "created_utc": "2025-12-28 16:51:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvplmip",
          "author": "nanor000",
          "text": "Impressive! How difficult is adding a new language? I saw mentions about tree sitter, but I guess there is some plumbing required ?",
          "score": 1,
          "created_utc": "2025-12-24 12:59:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq63j8",
              "author": "lpostrv",
              "text": "Thank you! It's reasonably easy - as you say, gotta wire it in via Tree Sitter - something like:  \n  1. Add tree-sitter-<lang> to Cargo.toml\n\n  2. Add the LanguageConfig in [parser.rs](http://parser.rs) (symbol\\_query uses tree-sitter's query syntax) \\~15-20 lines of code\n\n  3. Update 4-5 helper functions that have extension lists (is\\_source\\_file, detect\\_language\\_from\\_path, etc.)\n\nThen optionally:  \n  \n  4. Add security rules in rules/\n\n  5. Type stubs in type\\_inference.rs for type awareness (where applicable)\n\nIs there one you'd like me to add?",
              "score": 1,
              "created_utc": "2025-12-24 15:06:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvsi272",
                  "author": "nanor000",
                  "text": "Thank you for the detailed answer. I was thinking about verilog/system verilog",
                  "score": 1,
                  "created_utc": "2025-12-24 23:04:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvpukn4",
          "author": "FigZestyclose7787",
          "text": "Impressive! And useful.",
          "score": 1,
          "created_utc": "2025-12-24 13:58:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvq659u",
              "author": "lpostrv",
              "text": "Thank you! Merry Christmas!",
              "score": 1,
              "created_utc": "2025-12-24 15:07:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvr9kr4",
                  "author": "FigZestyclose7787",
                  "text": "Merry Christmas!",
                  "score": 1,
                  "created_utc": "2025-12-24 18:39:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvqhadu",
          "author": "Stock-Protection-453",
          "text": "Wow!",
          "score": 1,
          "created_utc": "2025-12-24 16:07:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqj07g",
              "author": "lpostrv",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2025-12-24 16:16:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqjh5g",
          "author": "ekim4ds",
          "text": "This is exactly what I have been looking for! I was actually starting to build something similar myself, but this is even better than what I had imagined so you just saved me so much time! \n\nThank you so much for sharing this and your hard work! I‚Äôll be sure to share and get the word out to other‚Äôs that might benefit from it.",
          "score": 1,
          "created_utc": "2025-12-24 16:18:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqvj6z",
              "author": "lpostrv",
              "text": "Thank you!! Let me know any feedback once you've tried it and I'll do my best to make it even better over the Christmas break.",
              "score": 1,
              "created_utc": "2025-12-24 17:23:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqquu6",
          "author": "smothered-onion",
          "text": "Sweet‚Äî will try!",
          "score": 1,
          "created_utc": "2025-12-24 16:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqvlqa",
              "author": "lpostrv",
              "text": "Thanks! Let me know any feedback/improvements and I'll do my best to ship 'em",
              "score": 1,
              "created_utc": "2025-12-24 17:24:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvqu8u9",
          "author": "bytejuggler",
          "text": "How does this relate/compare to Serena?",
          "score": 1,
          "created_utc": "2025-12-24 17:16:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvr2suj",
              "author": "lpostrv",
              "text": "Hopefully it's better in at least some ways - Serena is definitely the nearest analogue I'm aware of, has similar semantic capabilities and supports 30+ languages via LSP whereas I'm currently at 14 - will aim for parity soon. They also offer a JetBrains plugin that I don't have. Where Narsil is stronger is in the extent and capabilities of tools, and in speed. Here are the things that I have, which are lacking in Serena (to the best of my knowledge):\n\n* **Neural/semantic search** (with Voyage AI, OpenAI embeddings, or local ONNX models; hybrid BM25 + TF-IDF + neural) - Serena has exact semantic/symbol search but doesn't offer embeddings support\n* **Call graph analysis** (get\\_call\\_graph, callers/callees, call paths, complexity metrics, hotspots)\n* **Control flow graphs (CFG)** and data flow analysis (DFG, reaching definitions, dead code/stores)\n* **Type inference** for dynamic languages (Python, JS/TS) without external tools + type error checking\n* **Security scanning & taint tracking** (injection vulnerabilities, OWASP Top 10, CWE Top 25, crypto/secrets rules, taint sources/flows)\n* **Supply chain security** (SBOM generation in CycloneDX/SPDX, dependency vulnerability checks via OSV, license compliance, upgrade paths)\n* **Git integration tools** (blame, file/commit/symbol history, recent changes, hotspots, contributors)\n* **Import/dependency graph analysis** (circular imports detection)\n* **Embedded interactive visualisation frontend** (Cytoscape.js graphs for calls, imports, structure)\n* **WASM/browser support** for client-side/offline use\n* **Much broader toolset** (76 specialized tools vs. Serena's core \\~7: symbol finding, references, and targeted insertion)\n* **Built-in high-performance full-text/hybrid search** (Tantivy-based, streaming results)\n* **Remote repository indexing** support (though writing this out has made me realise I need to test this last one!)\n\nWorth noting that Narsil is built in Rust for a reason - it's genuinely very fast (even if I did get roasted on r/rust for using the word \"Blazing\" without due irony disclaimers) - whereas Serena is Python which is only medium fast :)   \nLet me know if you have any other questions.",
              "score": 4,
              "created_utc": "2025-12-24 18:03:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvv1oaw",
                  "author": "bytejuggler",
                  "text": "Thank you. There is definitely room for something better, Serena's context usage is kind of terrible IME. Anything that is context efficient and fast is welcome. I will check it out. üí™",
                  "score": 1,
                  "created_utc": "2025-12-25 12:30:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvr28g7",
              "author": "jboulhous",
              "text": "There is a comparison table on the repo's readme, i didn't try it though",
              "score": 1,
              "created_utc": "2025-12-24 18:00:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvw8ood",
                  "author": "lpostrv",
                  "text": "Yep comparison table here if anyone needs it: [https://github.com/postrv/narsil-mcp?tab=readme-ov-file#why-narsil-mcp](https://github.com/postrv/narsil-mcp?tab=readme-ov-file#why-narsil-mcp)",
                  "score": 1,
                  "created_utc": "2025-12-25 17:24:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvucame",
          "author": "mrfreez44",
          "text": "What are the use-cases? I understand how to use it, but not why!\nThanks",
          "score": 1,
          "created_utc": "2025-12-25 07:59:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw2miw",
              "author": "lpostrv",
              "text": "It's designed to help the LLM get much more granular and useful intelligence against your codebase. A normal AI agent may arbitrarily query the codebase with bash commands, but this gives it a package of much more useful functions such as \"find me all the path traversal vulnerabilities in this repo\", or \"find me the highest complexity files that need refactoring\" or even \"find me the exact function name that retrieves code graph for the frontend\" and it would be able to answer these, rather than say grepping through the codebase and using bash and sampling. The fact that it indexes the codebase practically instantly and can turn that rapidly into complete understanding is a real blessing. I anticipate it could be used as an onboarding assistant, a security review tool, a refactoring accomplice, and more. But to be honest, its true value will only be know when people start adopting it.  \nThanks for checking it out and I hope you're having a great Christmas (with a name like Mr Freez, I imagine you are!) - let me know if you have any further questions when you've had a chance to try it.",
              "score": 2,
              "created_utc": "2025-12-25 16:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvi349",
          "author": "_Sworld_",
          "text": "nice! I'll give it try",
          "score": 1,
          "created_utc": "2025-12-25 14:39:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw2o45",
              "author": "lpostrv",
              "text": "Thanks let me know any feedback so I can improve it!",
              "score": 1,
              "created_utc": "2025-12-25 16:48:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvvkqxj",
          "author": "Otherwise-Way1316",
          "text": "Nice work. How does this compare to Claude‚Äôs new LSP?",
          "score": 1,
          "created_utc": "2025-12-25 14:57:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvw5bwz",
              "author": "lpostrv",
              "text": "Thanks! Yeah, Claude adding native LSP support is hopefully validation that deep symbolic code intelligence is the way forward. It basically brings Claude Code up to roughly Serena-level basics (precise go-to-definition, find references, hover docs/types, diagnostics, etc)\n\nBut Narsil goes much further: Claude offers no neural/embedding-based semantic search, no advanced call/control/data flow graphs, no built-in security/taint scanning (OWASP/CWE, secrets, injections), no supply chain tools (SBOM, vuln checks), no deep Git analysis, and none of the interactive visualisation or super-fast Rust performance that Narsil has.\n\nI'm aiming to keep pushing the envelope with more depth and speed. If you give Narsil a spin and have feedback (features, bugs, whatever), hit me up-I'll prioritise fixes/additions quickly.\n\nHave a great Christmas!",
              "score": 1,
              "created_utc": "2025-12-25 17:04:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0onvr",
      "title": "Built a MCP server that bridges WhatsApp and AI assistants. Messages stay local, Claude/AI assistant gets real context.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q0onvr/built_a_mcp_server_that_bridges_whatsapp_and_ai/",
      "author": "felipe-adeildo",
      "created_utc": "2025-12-31 22:05:35",
      "score": 29,
      "num_comments": 12,
      "upvote_ratio": 0.95,
      "text": "Built a MCP server that bridges WhatsApp and AI assistants. Messages stay local, Claude gets real context.\n\n**What it does??**\n\n* Cross-chat search: \"Find everything Arthur said about budget\" -> searches DMs, groups, everywhere\n* Context analysis: \"Summarize my Tech Team group this week\"\n* Send messages: \"Tell Maria I'll be 10 minutes late\" ->  finds chat, sends contextually\n* Reply with context: Claude reads conversation history before responding\n* Person lookup: See all messages from someone across all chats\n* On-demand history: Load older messages from WhatsApp servers when needed\n\n**Stack:**\n\n* Go + whatsmeow (WhatsApp Web reverse engineering)\n* SQLite with full-text search indexes\n* 6 tools, 4 prompts, 4 resource guides\n* Docker deployment\n* Streamable HTTP (not SSE, neither STDIO)\n\n**Why?**\n\nTired of copy-pasting messages manually. Now Claude searches my full WhatsApp history, understands relationships, and sends contextual replies.\n\n**Repo:** [https://github.com/felipeadeildo/whatsapp-mcp](https://github.com/felipeadeildo/whatsapp-mcp)\n\n[claude.ai using the whatsapp-mcp server](https://preview.redd.it/46o3udzi9mag1.png?width=1918&format=png&auto=webp&s=5c48fc66329d19c1245d3a14fa0b5bcf123b1ac9)\n\n**Roadmap:** Voice transcription, image OCR, GraphRAG integration.",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0onvr/built_a_mcp_server_that_bridges_whatsapp_and_ai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nx1xqxt",
          "author": "Revolutionary_Sir140",
          "text": "Use both mcp and utcp",
          "score": 3,
          "created_utc": "2026-01-01 08:35:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx377y0",
              "author": "felipe-adeildo",
              "text": "I could be a good feature request on the repository!\n\nI really don't know utcp (until now), i can't test for now. But i'll keep it in mind!\n\nThanks",
              "score": 1,
              "created_utc": "2026-01-01 15:14:47",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx7hazl",
              "author": "Special-Click-7607",
              "text": "what is utcp?",
              "score": 1,
              "created_utc": "2026-01-02 05:35:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7ib5l",
                  "author": "Revolutionary_Sir140",
                  "text": "Universal Tool Calling Protocol, alternative to Model Context Protocol, an ai tooling that enables ai agent to call any API.",
                  "score": 2,
                  "created_utc": "2026-01-02 05:42:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzkfac",
          "author": "qwer1627",
          "text": "Good work! I built a thing like that for Reddit/Threads/GroupMe, didnt release it though because I fear the privacy implications. Innit wild how easy it is to exfil data out of these messaging apps??",
          "score": 2,
          "created_utc": "2025-12-31 22:14:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzll5v",
              "author": "felipe-adeildo",
              "text": "Yeah, WhatsApp is actually well-designed from a security architecture perspective.\n\nMost messaging apps are way easier to reverse engineer. WhatsApp has proper E2E encryption, session management, and complex sync protocols.\n\nThat's why there are so few libraries that do this ***well***. Most WhatsApp automation tools rely on browser automation (Puppeteer/Selenium) which is fragile and breaks constantly (ok, i know it occurs on bare requests too, but less...)\n\nwhatsmeow is one of the rare libraries that properly reverse-engineered the protocol and maintains compatibility. That's why this project works, and why whatsapp-mcp is written in go :p",
              "score": 5,
              "created_utc": "2025-12-31 22:21:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx17iu5",
                  "author": "admiller07",
                  "text": "Love this!  How does your mcp differ from others for WhatsApp already out there?",
                  "score": 2,
                  "created_utc": "2026-01-01 04:32:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7h846",
          "author": "Special-Click-7607",
          "text": "good one. built a personal WhatsApp scheduler using Go + whatsmeow too.  \nI was sending WhatsApp messages at 3am and I just wished something to schedule WhatsApp messages like you can do with email.",
          "score": 2,
          "created_utc": "2026-01-02 05:34:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py1t6z",
      "title": "[Release] Skill Seekers v2.5.0 - Multi-Platform Support: Convert docs to skills for Claude, Gemini, ChatGPT, or any LLM",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1py1t6z/release_skill_seekers_v250_multiplatform_support/",
      "author": "Critical-Pea-8782",
      "created_utc": "2025-12-28 20:38:35",
      "score": 29,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "Hey üëã\n\n  Released **Skill Seekers v2.5.0** with universal LLM support - convert any documentation into structured markdown skills.\n\n  ## What It Does\n\n  Automatically scrapes documentation websites and converts them into organized, categorized reference files with extracted code examples. Works with any LLM (local or remote).\n\n  ## New in v2.5.0: Universal Format Support\n\n  - ‚úÖ **Generic Markdown export** - works with ANY LLM\n  - ‚úÖ **Claude AI** format (if you use Claude)\n  - ‚úÖ **Google Gemini** format (with grounding)\n  - ‚úÖ **OpenAI ChatGPT** format (with vector search)\n\n  ## Why This Matters for Local LLMs\n\n  Instead of context-dumping entire docs, you get:\n  - **Organized structure**: Categorized by topic (getting-started, API, examples, etc.)\n  - **Extracted patterns**: Code examples pulled from docs with syntax highlighting\n  - **Portable format**: Pure markdown ZIP - use with Ollama, llama.cpp, or any local model\n  - **Reusable**: Build once, use with any LLM\n\n  ## Quick Example\n\n  ```bash\n  # Install\n  pip install skill-seekers\n\n  # Scrape any documentation\n  skill-seekers scrape --config configs/react.json\n\n  # Export as universal markdown\n  skill-seekers package output/react/ --target markdown\n\n  # Result: react-markdown.zip with organized .md files\n```\n\n  The output is just structured markdown files - perfect for feeding to local models or adding to your RAG pipeline.\n\n  Features\n\n  - üìÑ Documentation scraping with smart categorization\n  - üêô GitHub repository analysis\n  - üìï PDF extraction (for PDF-based docs)\n  - üîÄ Multi-source unified (docs + code + PDFs in one skill)\n  - üéØ 24 preset configs (React, Vue, Django, Godot, etc.)\n\n  Links\n\n  - GitHub: https://github.com/yusufkaraaslan/Skill_Seekers\n  - PyPI: https://pypi.org/project/skill-seekers/\n  - Release: https://github.com/yusufkaraaslan/Skill_Seekers/releases/tag/v2.5.0\n\n  MIT licensed, contributions welcome! Would love to hear what documentation you'd like to see supported.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1py1t6z/release_skill_seekers_v250_multiplatform_support/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwigyk0",
          "author": "Stock-Protection-453",
          "text": "Nice",
          "score": 2,
          "created_utc": "2025-12-29 08:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwineu8",
              "author": "Critical-Pea-8782",
              "text": "Thanks üòé",
              "score": 1,
              "created_utc": "2025-12-29 09:13:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwijiqn",
          "author": "UnderstandingOwn4448",
          "text": "Nice! I have used this for 3 libraries now and it seems to work great",
          "score": 2,
          "created_utc": "2025-12-29 08:36:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwinip4",
              "author": "Critical-Pea-8782",
              "text": "Good to hear that if there are any problems or improvements you can think always happy to hear them üôÇ",
              "score": 1,
              "created_utc": "2025-12-29 09:14:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pya8yo",
      "title": "Why I'm building my own CLIs for agents",
      "subreddit": "mcp",
      "url": "https://martinalderson.com/posts/why-im-building-my-own-clis-for-agents/",
      "author": "malderson",
      "created_utc": "2025-12-29 02:38:18",
      "score": 20,
      "num_comments": 5,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/mcp/comments/1pya8yo/why_im_building_my_own_clis_for_agents/",
      "domain": "martinalderson.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwhyzdl",
          "author": "KeithLeague",
          "text": "Hey, me too! https://enact.tools. This is a demonstration of it using playwright:  \n[https://enact.tools/blog/claude-code-superpowers](https://enact.tools/blog/claude-code-superpowers)\n\nEnact uses the \"skills\" standard but also defines a command to be executed as proposed here: https://github.com/anthropics/skills/issues/157 \n\nBasically you can define any tools `user/my-tools/playwright` or whatever and publish them so they can be searched semantically and executed via cli.\n\nI still believe MCP is the future regarding interfacing with agents, but the main tools in your context window will be for searching, registering and executing tools.",
          "score": 10,
          "created_utc": "2025-12-29 05:38:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkhsx9",
              "author": "malderson",
              "text": "Very interesting - DMed you!",
              "score": 2,
              "created_utc": "2025-12-29 16:35:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwhn34u",
          "author": "Orpheusly",
          "text": "I've also been eyeballing the MCP world recently and.. yeah it just seems like a horizontal abstraction that really isn't necessary except in certain cases.",
          "score": 3,
          "created_utc": "2025-12-29 04:17:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiwvdn",
          "author": "Cumak_",
          "text": "Yeah, this is the way",
          "score": 1,
          "created_utc": "2025-12-29 10:41:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkkdl6",
          "author": "circamidnight",
          "text": "Isn't it more of a problem with MCP clients though. They can, and sometimes do, allow you to assign mcp tools to certain subagents using skills or similiar mechanisms to optionaly add to context. This is more of an agent context managment problem more than something innate about MCP.\n\nI do agree that in some usecases, a simple cli tool is better than a full MCP server. But it is limited to mostly coding or technical usecases. There are many agents that we don't want to have access to a bash tool to execute our cli's.",
          "score": 1,
          "created_utc": "2025-12-29 16:47:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzh09o",
      "title": "Six Patterns for Connecting LLM Agents to Stateful Tools",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pzh09o/six_patterns_for_connecting_llm_agents_to/",
      "author": "Low-Efficiency-9756",
      "created_utc": "2025-12-30 12:34:40",
      "score": 20,
      "num_comments": 10,
      "upvote_ratio": 0.95,
      "text": "LLMs are stateless. Your database isn't. After building several MCP servers, I distilled six patterns that make the bridge work:\n\n1. **Externalize all state**¬†‚Äî The agent isn't smart; the database is\n2. **Rich query tools**¬†‚Äî Let the LLM reconstruct context on demand\n3. **Composite operations**¬†‚Äî Batch actions to reduce coordination overhead\n4. **Fuzzy input validation**¬†‚Äî Levenshtein matching for LLM tolerance\n5. **Explicit synchronization**¬†‚Äî Fork/snapshot models for complex state\n6. **Chat-first output**¬†‚Äî ASCII art, visual hierarchy, fits in a chat window\n\nFull write-up with code examples in comments.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pzh09o/six_patterns_for_connecting_llm_agents_to/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwpyh6i",
          "author": "Low-Efficiency-9756",
          "text": "check out the full writeup here, no paywall: [https://mnehmos.github.io/Mnehmos/blog/stateful-mcp-architecture/](https://mnehmos.github.io/Mnehmos/blog/stateful-mcp-architecture/)",
          "score": 3,
          "created_utc": "2025-12-30 12:35:15",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nwuibk3",
          "author": "jovial1991",
          "text": "Nice article!\n\nI was also wondering about the high token usage when an agent needs to call several tools, and I started writing down some of my thoughts and experiments. I came here to talk with more experienced people and check if I‚Äôm on the right path.\n\nIf you have some time, could you take a look at this draft?  \n\nhttps://gist.github.com/josealmada/27060317da5fc858d0d2efa2d3a16511\n\nThis is one way of composing operations, similar to your third pattern.\n\nI‚Äôve never written anything like this before, so any feedback is appreciated.",
          "score": 2,
          "created_utc": "2025-12-31 02:38:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0e8h",
              "author": "Low-Efficiency-9756",
              "text": "Hi, id love to review the draft, however its 404ing for me! idk if its public or not lmk!\n\nAs per your question, high token usage can be an issue. You have to be very careful at times and build safe guards into your tools. For example in my mcp server I had a read\\_file tool. simple except for the fact it read a file much larger than it should have, the context immediately jumped to 800k tokens and the chat was unrecoverable.\n\nfrom there i started to build in hard coded limits like limiting the max lines readable to 500 for read\\_file. Then when we build composite tools, we can think of different ways to do them. My favorite is enum menus where tools can be more modular and one tool can serve many different functions.\n\nThen we can also add in batch tools.  \nbatch\\_read\\_files  \nbatch\\_string\\_replace  \nbatch\\_read\\_lines  \netc\n\nthis allow us to turn 20 calls into 1. A time saver and a context saver for the misc info we get from tool outputs.",
              "score": 2,
              "created_utc": "2025-12-31 04:30:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwv0xnt",
                  "author": "jovial1991",
                  "text": "Just fixed the link!",
                  "score": 1,
                  "created_utc": "2025-12-31 04:34:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwv37fl",
              "author": "Low-Efficiency-9756",
              "text": "worrying about ingredient not found is a bit of design smell imo  \nThe server should validate plausibility not exact match, we can treat unknown ingredients with confidence scores rather than failures. \n\n    // Bad: Rigid lookup\n    ingredient(\"KRAFT Smooth Peanut Butter\") // Fails if not in DB\n    \n    // Your pattern: Flexible with validation\n    ingredient({\n      name: \"peanut butter\",\n      brand: \"KRAFT\",  // Optional refinement\n      fallback: \"generic_peanut_butter\",\n      nutritional_override: { /* user-provided if unknown */ }\n    })\n\nErrors as guidance is non negotiable in our loop. \n\n    // Don't negotiate. Educate.\n    {\n      error: \"INGREDIENT_AMBIGUOUS\",\n      message: \"Multiple matches for 'peanut butter'\",\n      suggestions: [\n        { id: \"pb_001\", name: \"Generic Peanut Butter\", confidence: 0.95 },\n        { id: \"pb_kraft\", name: \"KRAFT Smooth\", confidence: 0.87 }\n      ],\n      hint: \"Re-call with specific id, or provide nutritional_override for custom entry\"\n    }\n\nthe error should tell the model exactly how to fix it.",
              "score": 1,
              "created_utc": "2025-12-31 04:49:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwutohl",
          "author": "RoboCopsGoneMad",
          "text": "very interesting that you chose an RPG domain, Im working on something similar, but am focused more on RAG for rules reference and generating examples",
          "score": 2,
          "created_utc": "2025-12-31 03:47:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0zrg",
              "author": "Low-Efficiency-9756",
              "text": "I think rpgs are a great culmination between the stochastic nature of LLM's (telling stories and narratives) \n\nand ensuring the game is a game that follows rules (the determistic nature of tooling) \n\nI'm currently working on translating SRD 5.2 and The World's Largest Dungeon Book 1 into a RAG rules and reference server. I'm thinking a dual approach. One traditional RAG, and one an SQL mcp server. \n\nMaybe those tools in combination can give both a broad and a granular level of control for models to use Rules and Reference material.",
              "score": 1,
              "created_utc": "2025-12-31 04:34:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwq0lnj",
          "author": "JohnLebleu",
          "text": "Batching operations was the biggest game changer for my mcp servers. Speeds up the interaction a lot and it was very simple to implement. All mcp servers should have that as a feature.\n\n\nBut I do prefer sending back information in json format and instead guiding the llm on how to display the information. This way I can create a custom mcp client that doesn't use llm but can still interact with a mcp server. This can be very useful for testing.¬†",
          "score": 1,
          "created_utc": "2025-12-30 12:50:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq2wui",
              "author": "Low-Efficiency-9756",
              "text": "You can absolutely have both! I do this with a layered approach:\nThe tool returns structured JSON internally, but the final response includes a pre-formatted display string alongside the raw data or just a reformatting.",
              "score": 3,
              "created_utc": "2025-12-30 13:06:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1px0h44",
      "title": "Dataviewr - Universal MCP Connector to Databases with GUI for AI Agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1px0h44/dataviewr_universal_mcp_connector_to_databases/",
      "author": "deno_by",
      "created_utc": "2025-12-27 15:30:25",
      "score": 16,
      "num_comments": 11,
      "upvote_ratio": 0.94,
      "text": "Hey everyone,\n\nI've been using Claude/Cursor with databases and got frustrated with the config situation:\n\n*   Separate MCP server for each database type (mysql-mcp, postgres-mcp, etc.)\n*   JSON config files for every single project\n*   No way to see what queries the AI actually ran\n\nSo I built Dataviewr - a desktop app that runs ONE MCP server for all databases.\n\n**How it works:**\n\n1.   Add your database connections in the GUI (MySQL, Postgres, MongoDB, Redis, etc. - 11 total)\n2. Enable MCP server\n3. Point your AI agent to it\n4. Done. Works across all your projects.\n\n  **Key features:**\n\n*  Read-only mode per connection (AI can SELECT but can't DROP your prod tables)\n*  Query history - see exactly what queries were executed\n*  SSH tunnel support\n*  macOS, Windows, Linux\n\nLooking for feedback - is this something you'd actually use? What's missing?\n\nhttps://preview.redd.it/p8cg2o8xlr9g1.png?width=2400&format=png&auto=webp&s=8e6a80f748179be97a2fedffac9a3c37ab927d74\n\nhttps://preview.redd.it/mcqido8xlr9g1.png?width=2400&format=png&auto=webp&s=00f16742fedbee368cf3fe1f943e549cf0231daa\n\nhttps://preview.redd.it/cqwszo8xlr9g1.png?width=2400&format=png&auto=webp&s=148c199cc19291503745b452223800b5702db557",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1px0h44/dataviewr_universal_mcp_connector_to_databases/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nw8q0ng",
          "author": "jezweb",
          "text": "Could be useful for some people but I don‚Äôt think I would use it. When I need something like this I ask Claude code to build what I need and don‚Äôt find a clickable interface my preferred ui.",
          "score": 1,
          "created_utc": "2025-12-27 19:48:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8zvm9",
              "author": "deno_by",
              "text": "UI exists mainly so you can track requests, quickly switch between projects, and have everything connected in one place instead of manually configuring JSON configs. When Claude makes database queries on its own, it‚Äôs often not entirely clear what it‚Äôs trying to do.\n\nThe interface acts as a manager for MCP, providing unified control over different databases.\n\nWhen you have more than one project and more than one database, a large number of MCPs and JSON-based connections create additional complexity.",
              "score": 2,
              "created_utc": "2025-12-27 20:42:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwaadow",
          "author": "drfritz2",
          "text": "I've seen others MCP like that. I would use to help troubleshooting with vibe coding",
          "score": 1,
          "created_utc": "2025-12-28 00:59:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwbz0wq",
          "author": "wokkieman",
          "text": "Thanks, this does resolve 1 challenge I had with MCP for postgres and various projects.\n\nThe key one remains, what is the benefit of MCP for this? I get better results when using terminal (by LLM)?",
          "score": 1,
          "created_utc": "2025-12-28 08:04:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwclqut",
              "author": "deno_by",
              "text": "I may not have understood you correctly. This application solves a number of problems, such as:\n\n\\- connection setup (we don‚Äôt need JSON)  \n\\- a single place to store connections and the ability to use them across different projects  \n\\- one MCP instead of a separate one for each database  \n\\- transparent queries where the query history can be viewed\n\nMy main pain point is that in projects of varying complexity there is often more than one database, and usually more than one project as well. I needed a single entry point and a unified connection configuration system so that I wouldn‚Äôt have to manually configure everything each time via JSON. I also want to be able to see the history of queries executed by the agent.",
              "score": 1,
              "created_utc": "2025-12-28 11:42:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwknscq",
          "author": "pieroit",
          "text": "quite the piece I'll try it out",
          "score": 1,
          "created_utc": "2025-12-29 17:03:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwys6h5",
          "author": "hurtener",
          "text": "Is this going to be released? I would definetly try it out.",
          "score": 1,
          "created_utc": "2025-12-31 19:40:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx5b9iw",
              "author": "deno_by",
              "text": "Yes, once I have time to finish it, I‚Äôll make it available for testing.",
              "score": 1,
              "created_utc": "2026-01-01 21:48:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw7idf8",
          "author": "bertyboy69",
          "text": "Lmao people really will do anything but learn extremely basic skills like querying a DB ü•≤",
          "score": 1,
          "created_utc": "2025-12-27 16:07:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdhv6l",
              "author": "drumnation",
              "text": "Nah this looks like a very useful tool. I too dislike needing a separate mcp for every database type. AI should be empowered to take on the work for us. We humans cannot split into 80 agents, I‚Äôd rather the agent know how to do this before I myself become the bottleneck.",
              "score": 1,
              "created_utc": "2025-12-28 15:23:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nw867j3",
              "author": "deno_by",
              "text": "I know SQL just fine. The value isn't in writing queries - it's in the analysis.\n\nExample: Incident investigation with activity logs.\n\nUser reports their subscription was cancelled but they didn't do it. I need to find all activity log entries for this user's subscription - who changed what field, when, from which IP, full audit timeline for the last 30 days.\n\nThat's joining activity\\_logs with users and subscriptions, filtering by polymorphic subject\\_type/subject\\_id, parsing JSON properties to extract old‚Üínew values, ordering by timestamps...\n\nManually: 10-15 min while jumping between schema docs and remembering if it's \\`properties->old\\` or \\`properties.old\\` in your DB.\n\nWith AI: \"Show me everything that happened to user #4521's subscription last month\" ‚Üí full timeline in 30 seconds.\n\nMultiply by 20 debug sessions per week = hours saved. Zero cognitive load on SQL syntax. I focus on finding the root cause, not on crafting the perfect JOIN.\n\nThat's the point.",
              "score": 1,
              "created_utc": "2025-12-27 18:07:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q01twd",
      "title": "Built a leaner Microsoft Graph MCP - 7 tools instead of 37, with direct multi-tenant access",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q01twd/built_a_leaner_microsoft_graph_mcp_7_tools/",
      "author": "BTForIT",
      "created_utc": "2025-12-31 02:53:27",
      "score": 14,
      "num_comments": 0,
      "upvote_ratio": 0.85,
      "text": "Been using Claude with Microsoft 365 via MCP and hit two frustrations:\n\n**Problem 1: Context bloat**\n\nThe popular MS Graph MCPs expose 30-40 specialized tools like `list-mail-messages`, `create-calendar-event`, `get-user`, etc. That's ~12KB of context eaten up before you even start talking. Claude already knows the Graph API - it doesn't need 37 hand-holding tools.\n\n**Problem 2: Multi-tenant switching sucks**\n\nI manage multiple M365 tenants (work, clients, personal). Every time I wanted to query a different tenant, I had to call `select-account`, wait, then make my request. Constantly switching context.\n\n**The fix:**\n\nForked the Softeria MCP and stripped it down to 7 tools:\n- `login`, `logout`, `verify-login` (auth)\n- `list-accounts`, `select-account`, `remove-account` (account management)\n- `graph-request` (one tool for ALL Graph API calls)\n\nThe `graph-request` tool takes an `accountId` parameter, so you can query any tenant directly without switching:\n\n```json\n{\n  \"endpoint\": \"/me/messages\",\n  \"accountId\": \"client-tenant-abc123\"\n}\n```\n\nQuery work and personal calendars in the same conversation. No switching dance.\n\n~1KB context instead of ~12KB. Same capabilities.\n\n**Repo:** https://github.com/ForITLLC/forit-microsoft-graph\n\nMIT licensed, fork of Softeria's work. Just a different philosophy - less is more.\n\nAnyone else running into context bloat issues with MCPs?\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q01twd/built_a_leaner_microsoft_graph_mcp_7_tools/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q0eyfc",
      "title": "Homework Grading MCP ‚Äì Enables automated grading of student homework images using Qwen3-VL multimodal model, supporting multiple subjects and question types with detailed feedback and batch processing capabilities.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@pickstar-2002/homework-grading-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 15:00:07",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0eyfc/homework_grading_mcp_enables_automated_grading_of/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwx8fdi",
          "author": "modelcontextprotocol",
          "text": "This server has 1 tool:\n\n- [grade_homework](https://glama.ai/mcp/servers/@pickstar-2002/homework-grading-mcp/tools/grade_homework) ‚Äì Grade student homework by analyzing images to automatically score answers and provide detailed feedback using AI-powered assessment.",
          "score": 1,
          "created_utc": "2025-12-31 15:00:07",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pw4vuj",
      "title": "I implemented Anthropic‚Äôs tool search in Agentor",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pw4vuj/i_implemented_anthropics_tool_search_in_agentor/",
      "author": "aniketmaurya",
      "created_utc": "2025-12-26 13:57:08",
      "score": 10,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "AI agent with 30+ tools is going to get slower and pick the wrong one more often.\n\nNot because the model is ‚Äúbad‚Äù.\n\nBecause we‚Äôre forcing it to read a tool encyclopedia before it even starts.\n\nThe problem:\n\nEvery tool ships with a schema + descriptions + args + examples.\n\nWith a few common integrations, tool definitions alone can blow past \\~50K tokens before the agent does any work üí•\n\nAnd as the tool list grows, tool selection gets harder:\n\nsimilar names, overlapping capabilities, more chances to call the wrong thing.\n\nThe solution: \n\nTool Search (dynamic tool loading) üîç\n\nInstead of loading every tool upfront, expose one small ‚Äútool search‚Äù capability.\n\nThe agent uses it to fetch the 3‚Äì5 relevant tools for the task ‚Äî and only those get loaded.\n\n‚úÖ Lower token spend + faster responses\n\n‚úÖ Better tool selection accuracy\n\n‚úÖ Scales to lots of integrations without context overload\n\nhttps://docs.celesto.ai/agentor/tools/tool-search",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pw4vuj/i_implemented_anthropics_tool_search_in_agentor/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nw1mowc",
          "author": "amansingh4u98",
          "text": "Interesting!",
          "score": 2,
          "created_utc": "2025-12-26 16:35:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5xuef",
          "author": "ming0308",
          "text": "Do you mind sharing, at a high level, how the tool search tool is implemented?\n\nI‚Äôve read a blog post about having such a tool search tool, but I don‚Äôt fully understand how it can be implemented in practice.\n\nSearching for the relevant tools requires intelligence, so it can‚Äôt rely solely on keyword matching.\n\nRAG could be an option. It avoids the long-context issue, but its reasoning capability is still inferior to directly prompting an LLM.\n\nAlternatively, we could still prompt an LLM but run it as a sub-agent, so the long tool-searching prompt doesn‚Äôt consume the main context window. But that sub-agent itself is still subject to the context too long issue. \n\nThanks",
          "score": 2,
          "created_utc": "2025-12-27 09:05:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6r076",
              "author": "aniketmaurya",
              "text": "At a high level -- you register the tools you want to be dynamically loaded, [Agentor](https://github.com/CelestoAI/agentor) creates a search index in the background based on the tool metadata. Agents are exposed to a single tool which is the `\"search tool\"`, which find the right tool given the context. \n\nHope it helps!\n\nAlso, we have written a detailed documentation on the working principle [here](https://docs.celesto.ai/agentor/tools/tool-search)",
              "score": 2,
              "created_utc": "2025-12-27 13:27:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw6rdjx",
                  "author": "ming0308",
                  "text": "Haha, this is more like how to use it rather than how your search index works :)",
                  "score": 1,
                  "created_utc": "2025-12-27 13:29:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw8biwr",
          "author": "tinyGiant421",
          "text": "This looks like a solid way to deal with tool sprawl , the dynamic loading and searchable tool layer make a lot of sense.\n\nQuick question: have you considered adding a thin capability layer above tools?\n\nSo the agent first decides what it needs to do, and the runtime later picks which tool actually does it, making tools interchangeable backends.\nDo you see that kind of separation making sense as MCP-style ecosystems evolve?",
          "score": 2,
          "created_utc": "2025-12-27 18:34:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw554o3",
          "author": "SmartWeb2711",
          "text": "Can it be integrated with Cursor ?",
          "score": 1,
          "created_utc": "2025-12-27 04:52:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw6qjem",
              "author": "aniketmaurya",
              "text": "yes, Celesto auto creates MCP endpoints which can be natively connected with Cursor or any AI code editor.",
              "score": 1,
              "created_utc": "2025-12-27 13:24:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q11aqv",
      "title": "Protecting Your Privacy_ RedactAI MCP server",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q11aqv/protecting_your_privacy_redactai_mcp_server/",
      "author": "Gullible-Relief-5463",
      "created_utc": "2026-01-01 10:32:58",
      "score": 10,
      "num_comments": 14,
      "upvote_ratio": 1.0,
      "text": "Do you send confidential documents directly to LLMs?\n\nThat means sensitive information often gets shared unfiltered by default.\n\nI built **RedactAI**, an MCP server that acts as a privacy firewall for PDFs. It detects and permanently redacts sensitive data before the document ever reaches the LLM, while preserving layout and providing an audit-friendly preview.\n\nEverything runs locally using Ollama. No cloud calls.\n\nBuilt using MCP (Anthropic) to explore how privacy can be enforced at the tool layer instead of being an afterthought.\n\nRepo: [https://github.com/AtharvSabde/RedactAI]()  \nDemo/context: [https://www.linkedin.com/posts/atharv-sabde](https://www.linkedin.com/posts/atharv-sabde-4aa272222_%F0%9D%97%97%F0%9D%97%BC-%F0%9D%98%86%F0%9D%97%BC%F0%9D%98%82-%F0%9D%98%80%F0%9D%97%B2%F0%9D%97%BB%F0%9D%97%B1-%F0%9D%97%BF%F0%9D%97%AE%F0%9D%98%84-%F0%9D%97%A3%F0%9D%97%97%F0%9D%97%99%F0%9D%98%80-%F0%9D%98%84%F0%9D%97%B6-activity-7412434987058130945-nAvk)\n\nCurious how others are handling privacy in LLM-based document workflows.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1q11aqv/protecting_your_privacy_redactai_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nx2wkzi",
          "author": "Afraid-Today98",
          "text": "Local redaction before LLM access is smart. Way better than trusting cloud providers with sensitive docs.",
          "score": 2,
          "created_utc": "2026-01-01 14:05:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx34az8",
              "author": "Gullible-Relief-5463",
              "text": "Thanks, that was exactly the goal, enforce privacy before the document ever reaches an LLM.\nIf you like the approach, a star on the repo would really help, and feel free to share it with anyone working on LLM document workflows.",
              "score": 1,
              "created_utc": "2026-01-01 14:56:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx37s0u",
          "author": "DavidAntoon",
          "text": "This is really solid work üëè\nRedacting before the document ever touches the LLM is exactly the right layer to enforce privacy.\n\nIf you‚Äôre open to it, this feels like a great fit as a FrontMCP plugin.\nFrontMCP is an open-source MCP runtime with a plugin system designed specifically for tool-layer guardrails like this, so RedactAI could be easily reused across LLM document workflows without re-implementing the logic.\n\nPlugin docs: https://docs.agentfront.dev/docs/plugins/overview\n\nFrontMCP: https://github.com/agentfront/frontmcp\n\nHappy to help wire this up and contribute it back as an open-source plugin if you‚Äôre interested.\n\nLove the local-only + audit-friendly approach ‚Äî privacy by default, not by policy üëç",
          "score": 2,
          "created_utc": "2026-01-01 15:18:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx38qhd",
              "author": "Gullible-Relief-5463",
              "text": "Yes, what not!\nLet's connect and work together..also don't forget to star the repo",
              "score": 2,
              "created_utc": "2026-01-01 15:23:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx3ba3k",
                  "author": "DavidAntoon",
                  "text": "Starred,  you are more than welcome to star our frontmcp repo üôè",
                  "score": 1,
                  "created_utc": "2026-01-01 15:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx37mif",
          "author": "chill-botulism",
          "text": "Do you plan to add support for other file types?",
          "score": 1,
          "created_utc": "2026-01-01 15:17:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx38icl",
              "author": "Gullible-Relief-5463",
              "text": "Yes ofc.\nFor now thinking of deepseek OCR for scanned docs",
              "score": 1,
              "created_utc": "2026-01-01 15:22:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3h0yb",
          "author": "General-Ear-8056",
          "text": "Looks quite interesting. Do u know the minimum hardware requirements?",
          "score": 1,
          "created_utc": "2026-01-01 16:09:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3koeu",
              "author": "Gullible-Relief-5463",
              "text": "I have noted the minimum setup in the repo. I have tested it with a 1B parameter model, which works fine even on modest hardware.\nThe exact requirements mainly depend on which Ollama model you choose, smaller models run comfortably on CPU, larger ones benefit from more RAM or a GPU.\nIf you find it useful, feel free to check out the repo and drop a star.",
              "score": 2,
              "created_utc": "2026-01-01 16:28:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6yaea",
          "author": "CaptainMalikk",
          "text": "awesome will try it boss",
          "score": 1,
          "created_utc": "2026-01-02 03:27:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx766cn",
              "author": "Gullible-Relief-5463",
              "text": "Thanks üòé",
              "score": 1,
              "created_utc": "2026-01-02 04:18:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx75bm5",
          "author": "Long-Chemistry-5525",
          "text": "Curious on how this would work, do you upload the document to the mcp directly outside of the llm then reference them frm Claude? As if you are telling Claude to upload to the mcp you are already exposed",
          "score": 1,
          "created_utc": "2026-01-02 04:13:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7628o",
              "author": "Gullible-Relief-5463",
              "text": "You pass a file path to the MCP server through claude, the document is processed locally, and Claude only issues the tool call. The raw document is never exposed. You should check the repo, I have added some examples in readme..give a star on the repo if you liked it.",
              "score": 1,
              "created_utc": "2026-01-02 04:17:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pvhl9c",
      "title": "Anyone using a MCP for SQLite?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pvhl9c/anyone_using_a_mcp_for_sqlite/",
      "author": "Crafty_Disk_7026",
      "created_utc": "2025-12-25 17:01:16",
      "score": 9,
      "num_comments": 9,
      "upvote_ratio": 0.85,
      "text": "I was playing with some SQLite MCP servers and found they do not work well.  Mainly tons of token and context waste.\n\nI wrote my own SQLite MCP in Go using Codemode and the benchmarks are way better than existing SQLite MCP.\n\nHere's the repo if you want to try it, should be a drop in replacements. Should be benchmarks there too.\n\n[ https://github.com/imran31415/codemode-sqlite-mcp ](https://github.com/imran31415/codemode-sqlite-mcp)\n\nIf you like it plz star :)\n\nAlso it you don't know what \"codemode\" is I wrote a much more comprehensive thing on that topic here:   [ https://godemode.scalebase.io ](https://godemode.scalebase.io)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pvhl9c/anyone_using_a_mcp_for_sqlite/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nvwsgld",
          "author": "FalloutGhoulS2",
          "text": "I am waiting to try this, will do tomorrow.. can‚Äôt login in today a lot of fam about .. thank you OP. Will send you feedback.",
          "score": 2,
          "created_utc": "2025-12-25 19:19:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx1ttn",
              "author": "Crafty_Disk_7026",
              "text": "Thank you, I just wrote a bench mark to compare it to existing go and python SQLite mcps if your curious https://github.com/imran31415/sqlit-mcp-benchmark",
              "score": 2,
              "created_utc": "2025-12-25 20:15:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvxex2p",
                  "author": "FalloutGhoulS2",
                  "text": "Thank you! I will most certainly give it a go.",
                  "score": 1,
                  "created_utc": "2025-12-25 21:36:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvx4fqm",
          "author": "Afraid-Today98",
          "text": "Nice approach with Go. Most SQLite MCPs I've tried choke on larger databases. How's the memory footprint compared to the Python ones?",
          "score": 2,
          "created_utc": "2025-12-25 20:31:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx8ft7",
              "author": "Crafty_Disk_7026",
              "text": "GOs footprint for memory in general is always going to be magnitudes smaller than Python.  To answer your question though the memory should be be smaller as codemode should take fewer iteration/tool calls.  Please see the benchmark here where I do some complex scenarios  https://github.com/imran31415/sqlit-mcp-benchmark\n\nYou can see the codemode test generate model efficient inserts than the tool calling MCP approach",
              "score": 1,
              "created_utc": "2025-12-25 20:56:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwcx34u",
          "author": "vincentdesmet",
          "text": "this looks great but your website is not highlighting the ideas behind this very well.\nmaybe point to the Anthropic article explaining how having LLMs generate a program to run in a sandbox is much more effective than MCP. \nthe examples deep dive is a bit confusing \n\n1. do i install godemode as an MCP server that exposes a tool/sandbox for the LLM to generate the script? \n2. does the SQLite MCP based on godemode just provide a sandbox with SQLite SDK and is THAT the MVP i install (so I need to build custom MCP servers with specific SDKs for every Use case and not directly GoDemode?)\n3. Can‚Äôt i just write a SKILL that progressively explains how to use godemode as a sandbox? \n\nyour website is just focused on explaining the concept which to me is better explained in the Anthropic post and doesn‚Äôt show exactly how or what godemode role is in this whole thing..",
          "score": 1,
          "created_utc": "2025-12-28 13:14:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcxmto",
              "author": "Crafty_Disk_7026",
              "text": "I think you are overthinking it a bit.  You can use the SQLite MCP as you would any other MCP server. The sandbox logic is built in. Just folow the instructions in this repo to get started https://github.com/imran31415/codemode-sqlite-mcp\n\nRegarding the other questions about skills, etc. again this is \"just\" and MCP server so whatever you can do with other MCP servers should be possible here.  So you should be able to turn it into a skill or whatever. \n\nHope this helps.\n\nAlso I really like this article by cloudflare to explain codemode it may help https://blog.cloudflare.com/code-mode/.  The Godemode website I linked is just explaining how I implemented this in Go.  I also did one in [Python](https://github.com/imran31415/codemode_python_benchmark?tab=readme-ov-file) if curious",
              "score": 1,
              "created_utc": "2025-12-28 13:18:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvx2v78",
          "author": "turtleisinnocent",
          "text": "I don‚Äôt think anything could go wrong running arbitrary code after all sandboxes are always perfect.",
          "score": 0,
          "created_utc": "2025-12-25 20:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvx32qj",
              "author": "Crafty_Disk_7026",
              "text": "This post isn't really about arguing the safety of sandboxing, as this is a well established approach... see https://blog.cloudflare.com/code-mode/",
              "score": 0,
              "created_utc": "2025-12-25 20:23:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pu4916",
      "title": "Now MCP supports Tailwind???",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pu4916/now_mcp_supports_tailwind/",
      "author": "ConfusionAlone721",
      "created_utc": "2025-12-23 20:30:01",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.76,
      "text": "https://reddit.com/link/1pu4916/video/768o0h5zj09g1/player\n\nIn the next version of [xmcp.dev](http://xmcp.dev)  \n  \nTools that return React components will be able to use Tailwind with just a few tweaks  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pu4916/now_mcp_supports_tailwind/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q0befz",
      "title": "ForIT Microsoft Graph ‚Äì Provides direct access to Microsoft Graph API with multi-tenant account management, allowing users to interact with Microsoft 365 services across multiple tenants through a single flexible graph-request tool.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 12:00:09",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0befz/forit_microsoft_graph_provides_direct_access_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwwglvt",
          "author": "modelcontextprotocol",
          "text": "This server has 7 tools:\n\n- [graph-request](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/graph-request) ‚Äì Execute Microsoft Graph API requests to access Microsoft 365 services. Target specific accounts without switching and use any Graph endpoint with query parameters.\n- [list-accounts](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/list-accounts) ‚Äì Retrieve all available Microsoft accounts for managing Microsoft 365 services across multiple tenants.\n- [login](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/login) ‚Äì Authenticate with Microsoft Graph API using device code flow to access Microsoft 365 services across multiple tenants. Manage multi-tenant accounts through a single flexible interface.\n- [logout](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/logout) ‚Äì Terminate active Microsoft account sessions to end access to Microsoft 365 services and protect account security.\n- [remove-account](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/remove-account) ‚Äì Remove cached Microsoft accounts from the ForIT Microsoft Graph server to manage multi-tenant access and maintain account security.\n- [select-account](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/select-account) ‚Äì Choose a specific Microsoft account to access Microsoft Graph API services across multiple tenants, enabling interaction with Microsoft 365 resources.\n- [verify-login](https://glama.ai/mcp/servers/@ForITLLC/forit-microsoft-graph/tools/verify-login) ‚Äì Check current Microsoft authentication status to verify login validity before accessing Microsoft 365 services across multiple tenants.",
          "score": 3,
          "created_utc": "2025-12-31 12:00:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzscgg",
      "title": "Best MCP servers for AI Agents",
      "subreddit": "mcp",
      "url": "https://i.redd.it/u25442aqeeag1.png",
      "author": "Worldly_Ad_2410",
      "created_utc": "2025-12-30 20:08:54",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pzscgg/best_mcp_servers_for_ai_agents/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pz76u0",
      "title": "I made this MCP server to cover almost any cybersecurity topic in a VPS.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pz76u0/i_made_this_mcp_server_to_cover_almost_any/",
      "author": "exitcactus",
      "created_utc": "2025-12-30 03:27:54",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "For the ones into ai stuff, I made this MCP all about cybersecurity when you self host something.\n\nhttps://github.com/girste/mcp-cybersec-watchdog\n\nEdit- if you know what to do, it's literally the same you do everyday, in hours.\n\nIf you know how to make ai (CLI) do it for you, it takes time, tokens and sometimes results \"may vary\"...\n\nWith this, in 5 seconds you have an almost complete checkup of your VPS.\n\nPlanning to expand to SSL certs and more \"corporate\" CS stuff.",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pz76u0/i_made_this_mcp_server_to_cover_almost_any/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1puu4qn",
      "title": "ChatGPT App Template",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1puu4qn/chatgpt_app_template/",
      "author": "nickytonline",
      "created_utc": "2025-12-24 18:35:37",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Built this because I needed a decent ChatGPT app template. TypeScript,\n\nMCP server, React widgets care of vite, Vitest, Storybook, Pino‚Ä¶ all the proper tooling. Feedback welcome.\n\n[ https://github.com/pomerium/chatgpt-app-typescript-template ](https://github.com/pomerium/chatgpt-app-typescript-template)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1puu4qn/chatgpt_app_template/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwbz6xa",
          "author": "iamjoseangel",
          "text": "Really useful, thanks!!",
          "score": 2,
          "created_utc": "2025-12-28 08:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc4r3q",
              "author": "nickytonline",
              "text": "Thanks! Any feedback is welcome. üòé",
              "score": 2,
              "created_utc": "2025-12-28 08:59:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwc0sly",
          "author": "qchuret",
          "text": "If you are also interested we have done one at Alpic : https://github.com/alpic-ai/apps-sdk-template\n\nPowered by our abstracted framework Skybridge that provides you hooks & an eased development experience : https://github.com/alpic-ai/skybridge",
          "score": 2,
          "created_utc": "2025-12-28 08:21:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pubagw",
      "title": "Enterprise AI in 2025: $37B spent, 79% adoption, and the shift to multi-agent architectures",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pubagw/enterprise_ai_in_2025_37b_spent_79_adoption_and/",
      "author": "Classic-Ad-8318",
      "created_utc": "2025-12-24 01:46:28",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Year-end recap for enterprise AI:\n\n* $37B spent on GenAI (3.2x increase)\n* 79% of companies adopting AI agents (PwC)\n* MCP and Agent Skills now open standards\n\nThe emerging architecture: not one super-agent, but teams of specialized skills. Governance and orchestration are the 2026 challenges.\n\nFull breakdown with sources: [https://subramanya.ai/2025/12/23/2025-the-year-agentic-ai-got-real-and-what-comes-next/](https://subramanya.ai/2025/12/23/2025-the-year-agentic-ai-got-real-and-what-comes-next/)",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/mcp/comments/1pubagw/enterprise_ai_in_2025_37b_spent_79_adoption_and/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pyo6v0",
      "title": "A look at Gemini Function Calling architecture and connecting it to an MCP Tool Router",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pyo6v0/a_look_at_gemini_function_calling_architecture/",
      "author": "cyber_harsh",
      "created_utc": "2025-12-29 14:51:23",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hey everyone üëã,\n\nI‚Äôve been experimenting with the new Gemini SDKs and Google‚Äôs Agent Development Kit (ADK) recently. Particularly Function Calling differences.  \n  \nI wanted to break down exactly how the function calling loop works under the hood and share a workflow for connecting it to a Model Context Protocol (MCP) Tool Router.\n\nI figured this might be useful for anyone trying to bridge Gemini‚Äôs native tooling with MCP servers, so sharing here.\n\n\n\n**The Core Loop: How Gemini handles tools (earlier)**\n\nIf you're coming from other ecosystems, the Gemini loop is standard but strict on data structures. It essentially works like this:\n\n1. ***Declaration*****:** You pass `FunctionDeclaration` objects (*OpenAPI*\\-like schemas) in the `GenerateContentConfig`.\n2. **The Prompt:** Gemini ingests the prompt + tool schemas.\n3. **The Stop:** Instead of text, the model halts and returns a `functionCall` object in `content.parts`.\n4. **Execution (The Missing Link):** The generic SDK *doesn't* execute code for you. You have to parse the `functionCall`, execute your local code/API, and wrap the result.\n5. **The Return:** You send a new message with `role=\"tool\"` and the structured result.\n\nThe interesting part (and often the pain point) is handling the routing logic when you have dozens of tools.\n\n**Integrating an MCP Router (new flow)**\n\nWriting manual handlers for every tool gets messy fast. This is where using an MCP (Model Context Protocol) Tool Router helps abstract the execution layer.\n\nHere is a pattern for using Google ADK with an MCP Toolset. \n\n    from google.adk.agents.llm_agent import Agent\n    from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n    from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams\n    \n    # ... (Standard Auth Setup) ...\n    \n    # 1. Create the MCP Session\n    # In this example, we use a router that aggregates search tools\n    composio_session = composio_client.experimental.tool_router.create_session(\n        user_id=COMPOSIO_USER_ID,\n        toolkits=[\"duckduckgo\", \"google_search\"] \n    )\n    \n    # 2. Connect ADK to the MCP URL\n    composio_mcp_url = composio_session.url\n    composio_toolset = McpToolset(\n        connection_params=StreamableHTTPConnectionParams(url=composio_mcp_url)\n    )\n    \n    # 3. Inject into the Agent\n    root_agent = Agent(\n        model=\"gemini-2.5-pro\",\n        name=\"research_agent\",\n        # Instruction is critical for ADK to trust the tool output\n        instruction=(\n            \"You are a helpful assistant. \"\n            \"Use the available tools to answer user queries. \"\n            \"Execute the tools directly.\"\n        ),\n        tools=[composio_toolset], # <--- The MCP Toolset\n    )\n    \n\nThis example uses a router (via Composio in this instance, but the logic applies to other   \nMCP clients) to let the agent search/plan across available tools dynamically.\n\n**Why these matters?**\n\nUsing the `McpToolset` class in Google ADK allows the agent to treat the MCP server as a unified tool interface. \n\nYou don't need to manually define the schema for every single search function; the MCP handshake handles the capability discovery.\n\n  \n**Common Pitfalls**\n\nIf you are building this out, here are a few things that tripped me up:\n\n* **Schema Strictness:** Gemini is very sensitive to parameter types. If your MCP server returns a loose schema, Gemini might hallucinate arguments. Use Enums where possible.\n* **Error Propagation:** If the MCP tool fails, *return the error as a string* in the function response. Don't crash the app. Gemini can often read the error message (\"Error: 404 not found\") and self-correct or ask the user for clarification.\n* **Routing Latency:** Passing everything through a router adds a hop. For critical, low-latency tools, native function calling might still be faster than MCP.\n\nIf you want to grab the full source code for the agent setup or see a more detailed walkthrough of the environment configuration, I wrote up a guide here: [Function Calling & MCP using Google ADK](https://medium.com/composiohq/function-calling-mcp-using-google-adk-bf861421638e?postPublishedType=repub).\n\nHas anyone else here played with Google ADK's `McpToolset` yet? I'm curious how it compares to using the standard `sse`transport with other clients like Claude Desktop.\n\n",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pyo6v0/a_look_at_gemini_function_calling_architecture/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pwnsbx",
      "title": "Scrap your agents memory - Lessons from building an AI workflow builder",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pwnsbx/scrap_your_agents_memory_lessons_from_building_an/",
      "author": "PerformanceFine1228",
      "created_utc": "2025-12-27 03:43:18",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.7,
      "text": "We launched Seer and I‚Äôve spent the last week deleting code that I thought was my \"secret sauce.\"\n\nI‚Äôve realized that selling \"infra\" to devs is a losing battle. We can all build a sandbox. The real gap is the \"Plumbing\" (Auth, Time-traveling state, Interruptibility).\n\n**I have a few \"hot takes\" from our dev process, and I‚Äôd love to know if you agree:**\n\n1. **Delegation > Memory:** Giving a sub-agent a huge artifact and then killing it is 10x more reliable than \"remembering\" past mistakes via a prompt.\n2. **Freshness is the #1 Failure:** If your agent isn't using tools like Context7 to get *today's* docs, it's useless for enterprise.\n3. **Plan First:** If the agent doesn't outline its logic before it hits an API, it's just vibing.\n\n**What‚Äôs the most \"understated\" lesson you‚Äôve learned building agents?** What‚Äôs the thing that no one talks about on the landing pages but keeps you up at night?\n\nFull breakdown of our architecture shifts and references here: [https://www.getseer.dev/blogs/lessons-dec-2025](https://www.getseer.dev/blogs/lessons-dec-2025)",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pwnsbx/scrap_your_agents_memory_lessons_from_building_an/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q0t31y",
      "title": "Google Cloud Docs MCP Server ‚Äì Enables AI assistants to search and access Google Cloud Platform documentation in real-time, supporting 20+ GCP services with natural language queries and smart content extraction.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-01 02:00:06",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0t31y/google_cloud_docs_mcp_server_enables_ai/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx0l98t",
          "author": "modelcontextprotocol",
          "text": "This server has 4 tools:\n\n- [fetch_google_cloud_doc](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/fetch_google_cloud_doc) ‚Äì Extract content from specific Google Cloud documentation pages by providing the exact path to retrieve detailed technical information in structured format.\n- [get_api_reference](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/get_api_reference) ‚Äì Retrieve REST API documentation for Google Cloud services to access endpoints, methods, and parameters for integration development.\n- [list_google_cloud_products](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/list_google_cloud_products) ‚Äì Discover available Google Cloud products and their documentation paths to explore services or find correct product IDs for further research.\n- [search_google_cloud_docs](https://glama.ai/mcp/servers/@longngo192/gcpdoc-mcp/tools/search_google_cloud_docs) ‚Äì Search Google Cloud documentation to find configuration guides, best practices, and troubleshooting steps for GCP services like Compute Engine, Cloud Storage, BigQuery, and Kubernetes.",
          "score": 2,
          "created_utc": "2026-01-01 02:00:06",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1puvzon",
      "title": "Happy Holidays! I've built a lil' text-based adventure game played over MCP (or browser)",
      "subreddit": "mcp",
      "url": "https://gricha.dev/happyholidays",
      "author": "gricha91",
      "created_utc": "2025-12-24 20:00:49",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1puvzon/happy_holidays_ive_built_a_lil_textbased/",
      "domain": "gricha.dev",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pv8bo8",
      "title": "Building MCP-Powered Agents with AWS Strands",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pv8bo8/building_mcppowered_agents_with_aws_strands/",
      "author": "Arindam_200",
      "created_utc": "2025-12-25 07:49:33",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.78,
      "text": "Most MCP examples stop at ‚Äúhere‚Äôs a server‚Äù and never show how it fits into real agents.\n\nIn Part 4 of my Strands series, I walk through building¬†**MCP-powered agents**¬†in AWS Strands, starting with a single MCP server and then scaling to agents that work with multiple MCP servers.\n\nHere‚Äôs what I cover:\n\n* What MCP is and how it fits into the Strands agent model\n* How to build agents backed by¬†**one MCP server**\n* How to build agents that coordinate across¬†**multiple MCP servers**\n* When to use single-MCP vs multi-MCP agent designs\n* Real use cases for each pattern in production-style workflows\n\nIf you‚Äôve used tool-driven agents in frameworks like LangGraph, this should feel familiar, but the focus here is on how Strands makes MCP integration more modular and explicit. Here's the¬†[Full Tutorial](https://www.youtube.com/watch?v=glR4XwuqfYY).\n\nAlso, You can find all code snippets here:¬†[Github Repo](https://github.com/Arindam200/awesome-ai-apps/tree/main/course/aws_strands)\n\nWould love feedback from anyone building MCP-based or multi-agent systems in Strands.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pv8bo8/building_mcppowered_agents_with_aws_strands/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pvw37e",
      "title": "üõ°Ô∏è Built MCP Guard - a security proxy for Cursor/Claude agents (I'm the dev)",
      "subreddit": "mcp",
      "url": "https://i.redd.it/0q9d2eukdh9g1.png",
      "author": "Capital-Job-3592",
      "created_utc": "2025-12-26 05:02:48",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.73,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pvw37e/built_mcp_guard_a_security_proxy_for_cursorclaude/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q0dnoe",
      "title": "Councly MCP Server ‚Äì Enables AI assistants to create council hearings where multiple LLMs (Claude, GPT, Gemini, Grok) debate topics and synthesize verdicts with trust scores and diverse perspectives.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@slmnsrf/councly-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 14:00:08",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0dnoe/councly_mcp_server_enables_ai_assistants_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwwxuo5",
          "author": "modelcontextprotocol",
          "text": "This server has 2 tools:\n\n- [councly_hearing](https://glama.ai/mcp/servers/@slmnsrf/councly-mcp/tools/councly_hearing) ‚Äì Debate topics using multiple AI models (Claude, GPT, Gemini, Grok) to synthesize verdicts with diverse perspectives for code review, technical decisions, and problem solving.\n- [councly_status](https://glama.ai/mcp/servers/@slmnsrf/councly-mcp/tools/councly_status) ‚Äì Check council hearing status to get current phase, progress, verdict, trust scores, and counsel summaries for AI-debated topics.",
          "score": 3,
          "created_utc": "2025-12-31 14:00:08",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxv76w",
      "title": "Using Chat GPT App Sdk for distribution in 2026",
      "subreddit": "mcp",
      "url": "https://v.redd.it/fnvm7p1mzy9g1",
      "author": "Numerous_Singer_4631",
      "created_utc": "2025-12-28 16:17:32",
      "score": 5,
      "num_comments": 14,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1pxv76w/using_chat_gpt_app_sdk_for_distribution_in_2026/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwibmv2",
          "author": "Ok-Bedroom8901",
          "text": "This looks really awesome!\n\nDo you have any tips on how to get a basic UI rendered in ChatGPT in developer mode? All my MCP servers and their tools can be called, but the UI is not rendered in the iframe.\n\nI built their kitchen sink demo and I get the same results. I have a plus subscription",
          "score": 2,
          "created_utc": "2025-12-29 07:24:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwj1lj1",
              "author": "Numerous_Singer_4631",
              "text": "Hello,\n\nI'll write a tiny blog post about it soon. \n\nFrom my personnal experience, I had to downgrade few libraries to make it work with NextJs 16.1.1. Right now, I'm using : \n\n    \"modelcontextprotocol/sdk\": \"^1.20.0\"\n\n    \"mcp-handler\": \"^1.0.2\"\n\nI'm using those CORS Headers for those routes:   \n\n    '/mcp',\n    '/_next/:path*',\n    '/ANY_WIDGET_ROUTE/',\n    '/ANY_WIDGET_ROUTE/:path*'\n\n    headers: [\n    ¬† ¬† ¬† ¬† ¬† { key: 'Access-Control-Allow-Origin', value: '*' },\n    ¬† ¬† ¬† ¬† ¬† { key: 'Access-Control-Allow-Methods', value: 'GET,POST,PUT,DELETE,OPTIONS' },\n    ¬† ¬† ¬† ¬† ¬† { key: 'Access-Control-Allow-Headers', value: '*' },\n    ¬† ¬† ¬† ¬† ¬† { key: 'X-Frame-Options', value: 'ALLOWALL' },\n    ¬† ¬† ¬† ¬† ¬† { key: 'Content-Security-Policy', value: \"frame-ancestors 'self' https://*.openai.com https://*.oaiusercontent.com https://*.web-sandbox.oaiusercontent.com\" },\n    ¬† ¬† ¬† ¬† ],\n\nThen parts of my mcp route : \n\n    const generateDiagramWidget: ContentWidget = {\n    ¬† id: \"create_data_architecture_diagram\",\n    ¬† title: \"Create Data Architecture Diagram\",\n    ¬† templateUri: \"ui://widget/datadef.html\", // Same widget, reads prompt from toolOutput\n    ¬† invoking: \"Creating data architecture diagram...\",\n    ¬† invoked: \"Diagram ready\",\n    ¬† description: \"Create professional data architecture diagrams, data pipeline flowcharts, ETL diagrams, and data platform visualizations\",\n    ¬† widgetDomain: baseURL,\n    };\n\n    function widgetMeta(widget: ContentWidget) {\n    ¬† return {\n    ¬† ¬† \"openai/outputTemplate\": widget.templateUri,\n    ¬† ¬† \"openai/toolInvocation/invoking\": widget.invoking,\n    ¬† ¬† \"openai/toolInvocation/invoked\": widget.invoked,\n    ¬† ¬† \"openai/widgetAccessible\": false,\n    ¬† ¬† \"openai/resultCanProduceWidget\": true,\n    ¬† } as const;\n    }\n\nIf you managed everything correctly based on the few snippet I gave and the Vercel Boilerplate, you should see in the Chat GPT \"Application adder\" the following : \n\nModel\n\n* ui://widget/datadef.html\n   * openai/widgetDescription\"Opens Datadef - the data architecture diagramming tool\"\n   * openai/widgetPrefersBorder\n\nIf you dont have this, you will never have an iframe rendering. \n\n  \nNote : I add to manually do a tunnel forwarding to my developer machine from a domain name & server I own to be able to make it work. Ngrok free tier block interstitial requests, and it makes the iframe rendering imposible times to times (90% of the time)",
              "score": 2,
              "created_utc": "2025-12-29 11:24:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwj22t4",
                  "author": "Numerous_Singer_4631",
                  "text": "If it can helps as well :\n\n    // Create an iframe wrapper that loads a page and reads prompt from window.openai.toolOutput\n    function createIframeWrapper(pageUrl: string): string {\n    ¬† return `<!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n    ¬† <meta charset=\"UTF-8\">\n    ¬† <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    ¬† <title>Datadef</title>\n    ¬† <style>\n    ¬† ¬† * { margin: 0; padding: 0; box-sizing: border-box; }\n    ¬† ¬† html, body { width: 100%; height: 100%; overflow: hidden; }\n    ¬† ¬† iframe {\n    ¬† ¬† ¬† width: 100%;\n    ¬† ¬† ¬† height: 100%;\n    ¬† ¬† ¬† border: none;\n    ¬† ¬† }\n    ¬† </style>\n    </head>\n    <body>\n    ¬† <iframe \n    ¬† ¬† id=\"datadef-frame\"\n    ¬† ¬† allow=\"clipboard-read; clipboard-write\"\n    ¬† ¬† sandbox=\"allow-scripts allow-same-origin allow-forms allow-popups allow-modals\"\n    ¬† ></iframe>\n    ¬† <script>\n    ¬† ¬† // Read prompt from OpenAI toolOutput (set by ChatGPT Apps SDK)\n    ¬† ¬† // Try multiple paths since the structure may vary\n    ¬† ¬† var toolOutput = window.openai?.toolOutput || {};\n    ¬† ¬† var prompt = toolOutput.prompt || toolOutput.structuredContent?.prompt || '';\n    ¬† ¬† \n    ¬† ¬† var baseUrl = '${pageUrl}';\n    ¬† ¬† var url = prompt ? baseUrl + '?prompt=' + encodeURIComponent(prompt) : baseUrl;\n    ¬† ¬† document.getElementById('datadef-frame').src = url;\n    ¬† ¬† \n    ¬† ¬† // Listen for toolOutput updates\n    ¬† ¬† window.addEventListener('openai:set_globals', function(event) {\n    ¬† ¬† ¬† var globals = event.detail?.globals || {};\n    ¬† ¬† ¬† var newToolOutput = globals.toolOutput || {};\n    ¬† ¬† ¬† var newPrompt = newToolOutput.prompt || newToolOutput.structuredContent?.prompt || '';\n    ¬† ¬† ¬† if (newPrompt) {\n    ¬† ¬† ¬† ¬† var newUrl = baseUrl + '?prompt=' + encodeURIComponent(newPrompt);\n    ¬† ¬† ¬† ¬† document.getElementById('datadef-frame').src = newUrl;\n    ¬† ¬† ¬† }\n    ¬† ¬† });\n    ¬† </script>\n    </body>\n    </html>`;\n    }",
                  "score": 2,
                  "created_utc": "2025-12-29 11:28:14",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwikcql",
              "author": "UnderstandingOwn4448",
              "text": "Took me 2 or 3 days to debug, by far the most difficult part their app development.",
              "score": 1,
              "created_utc": "2025-12-29 08:44:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwio7il",
                  "author": "Ok-Bedroom8901",
                  "text": "Please blog (or make a writeup here) about what is needed to get the UI rendered",
                  "score": 1,
                  "created_utc": "2025-12-29 09:20:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwezz1n",
          "author": "Ast4rius",
          "text": "i have a question, is app review and publish in chatgpt apps free?",
          "score": 1,
          "created_utc": "2025-12-28 19:47:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf9ymh",
              "author": "Numerous_Singer_4631",
              "text": "As far as I know yes. But development needs a subscription (at least Go)",
              "score": 1,
              "created_utc": "2025-12-28 20:35:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwfalvf",
                  "author": "Ast4rius",
                  "text": "Sorry i don't understand what you mean by development needs subscription can you elaborate",
                  "score": 1,
                  "created_utc": "2025-12-28 20:39:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwwg29v",
                  "author": "ExpensiveFunny334",
                  "text": "Need a pro account",
                  "score": 1,
                  "created_utc": "2025-12-31 11:55:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwhuclu",
          "author": "zkittism",
          "text": "Is this just MCP or App? Can you please tell me how to submit your ChatGPT app? And how long does it take?",
          "score": 1,
          "created_utc": "2025-12-29 05:04:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwizwvq",
              "author": "Numerous_Singer_4631",
              "text": "It's.. both. App needs an MCP and defined tools to work. \nSubmission is ongoing, so I'll update you whenever it's done (or not and reasons it got rejected)\n\nFor submission, you need to do it through the developer platform : https://developers.openai.com/apps-sdk/deploy/submission\n\nBut you can enable your app in the developer mode as soon as you have a pro subscription, directly within the chatgpt chat.",
              "score": 1,
              "created_utc": "2025-12-29 11:09:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0af08",
      "title": "Calorie-Tracking ‚Äì A MCP server that tracks daily calorie intake through natural language interaction, providing meal recording, daily summary, weekly report generation, and food search functions.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@xiaobenyang-com/Calorie-Tracking",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 11:00:05",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0af08/calorietracking_a_mcp_server_that_tracks_daily/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nww9ti6",
          "author": "modelcontextprotocol",
          "text": "This server has 4 tools:\n\n- [add_meal](https://glama.ai/mcp/servers/@xiaobenyang-com/Calorie-Tracking/tools/add_meal) ‚Äì Log meals with food items and calories to track daily intake. Record descriptions and meal types for accurate calorie monitoring.\n- [get_daily_summary](https://glama.ai/mcp/servers/@xiaobenyang-com/Calorie-Tracking/tools/get_daily_summary) ‚Äì Retrieve today's calorie intake summary to monitor daily nutritional goals and track progress in your diet plan.\n- [get_weekly_report](https://glama.ai/mcp/servers/@xiaobenyang-com/Calorie-Tracking/tools/get_weekly_report) ‚Äì Generate a weekly calorie consumption report to track nutritional intake patterns and monitor progress toward health goals.\n- [search_food](https://glama.ai/mcp/servers/@xiaobenyang-com/Calorie-Tracking/tools/search_food) ‚Äì Find calorie information for specific foods to support dietary tracking and nutrition management.",
          "score": 2,
          "created_utc": "2025-12-31 11:00:05",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxvujj",
      "title": "stooq-mcp - Free stock data MCP server in Rust (no API key required)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pxvujj/stooqmcp_free_stock_data_mcp_server_in_rust_no/",
      "author": "Mammoth-Fail-5007",
      "created_utc": "2025-12-28 16:43:42",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,  \n  \nI just released a simple MCP server that fetches stock prices from Stooq.  \n  \nIf you just need quick stock prices without API key hassle, this might be useful.  \n  \n\\*\\*Features:\\*\\*  \n\\- No API key required  \n\\- Global markets: US (.US), Japan (.JP), UK (.UK), Germany (.DE)  \n\\- Lightweight Rust implementation  \n\\- STDIO transport\n\n\\*\\*GitHub:\\*\\* [https://github.com/hoqqun/stooq-mcp](https://github.com/hoqqun/stooq-mcp)  \n  \nThis is my first MCP server - feedback welcome!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pxvujj/stooqmcp_free_stock_data_mcp_server_in_rust_no/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q06035",
      "title": "[Dev Help] Best practices for an MCP Gateway with SSO/SAML and Dynamic Tool Routing?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q06035/dev_help_best_practices_for_an_mcp_gateway_with/",
      "author": "go-naruto",
      "created_utc": "2025-12-31 06:24:45",
      "score": 4,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I am building a custom chat-based client (independent of Claude/ChatGPT) and a **Unified MCP Gateway** to connect to multiple internal MCP services.\n\n**The Setup:**\n\n* **Client:** A custom UI that needs to provide a conversational experience.\n* **Gateway:** A central hub that aggregates tools from 5+ specialised MCP servers.\n* **Auth:** Needs to support SSO/SAML.\n\n**I'm looking for advice on these specific architecture hurdles:**\n\n1. **Auth Propagation:** Since I'm building my own client, should the client handle SSO and just pass a Bearer token to the Gateway, or should I implement the official MCP \"401/WWW-Authenticate\" flow to keep it \"spec-compliant\" for future third-party clients?\n2. **Unified Discovery:** Is it better for the Gateway to maintain a live registry of all tools from sub-servers, or should it fetch them on-demand? How do you handle name collisions (e.g., two servers having a `get_user` tool)?\n3. **Conversational Loop:** For those building custom clients, are you running the \"decide which tool to call\" logic inside the client app, or are you pushing that logic into the Gateway to keep the client \"thin\"?\n4. **Transport:** Since this is a custom client-to-gateway setup, is **SSE (Server-Sent Events)** the preferred transport for remote connections, or are people finding better success with **WebSockets** for bidirectional tool streaming?\n\nI'd love to hear from anyone building their own MCP ecosystem. What pitfalls should I avoid in the Gateway-to-Sub-Server communication?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1q06035/dev_help_best_practices_for_an_mcp_gateway_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwvjlxc",
          "author": "MycologistWhich7953",
          "text": "the new Maps Grounding Lite MCP from google passes credentials in the header iiuc .",
          "score": 1,
          "created_utc": "2025-12-31 06:55:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nww68hn",
          "author": "iamjoseangel",
          "text": "Hi!\n\nFind my implementation here:\n\nhttps://medium.com/@imjoseangel/ai-agents-for-engineers-part-ii-172b4037e941\n\nLet me know if you want more details",
          "score": 1,
          "created_utc": "2025-12-31 10:26:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pu1p49",
      "title": "all you need to know for your GPT App submission",
      "subreddit": "mcp",
      "url": "https://i.redd.it/us34pilozz8g1.png",
      "author": "0xKoller",
      "created_utc": "2025-12-23 18:45:38",
      "score": 4,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pu1p49/all_you_need_to_know_for_your_gpt_app_submission/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvl7a40",
          "author": "cinekson",
          "text": "Where is the guide so ?",
          "score": 2,
          "created_utc": "2025-12-23 18:47:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvl8g0z",
              "author": "0xKoller",
              "text": "Here is the link!\n\n[https://xmcp.dev/blog/build-and-submit-gpt-apps](https://xmcp.dev/blog/build-and-submit-gpt-apps)",
              "score": 1,
              "created_utc": "2025-12-23 18:52:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pwtk1k",
      "title": "Released: MCP server that lets Claude manage your Msty Studio installation",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pwtk1k/released_mcp_server_that_lets_claude_manage_your/",
      "author": "CryptBay",
      "created_utc": "2025-12-27 09:13:41",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "Hey everyone,\n\nI've been using Msty Studio for local AI and wanted a way to manage it through Claude. So I built¬†**Msty Admin MCP**¬†\\- a Model Context Protocol server with 24 tools for administering Msty Studio Desktop.\n\n**What it does:**\n\n* **Database insights**¬†\\- Query conversations, personas, prompts, and MCP tool configs directly from Msty's SQLite database\n* **Config sync**¬†\\- Export/import MCP tool configurations between Claude Desktop and Msty\n* **Local model orchestration**¬†\\- Chat with local models via Sidecar, compare responses across models, get performance metrics\n* **Health monitoring**¬†\\- Analyse installation health, storage usage, and get optimisation recommendations\n* **Calibration testing**¬†\\- Run quality tests on local models and identify when to escalate to Claude\n\n**Installation:**\n\nbash\n\n    pip install msty-admin-mcp\n\nOr clone from GitHub and configure in Claude Desktop.\n\n**Requirements:**\n\n* macOS (Msty Studio Desktop installed)\n* Python 3.10+\n* MCP-compatible client (Claude Desktop, Cursor, etc.)\n\n**GitHub:**¬†[https://github.com/M-Pineapple/msty-admin-mcp](https://github.com/M-Pineapple/msty-admin-mcp)\n\nThis is my first public MCP release. Would love feedback from anyone using Msty or building MCP tools!",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pwtk1k/released_mcp_server_that_lets_claude_manage_your/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pzavm8",
      "title": "Opensource No-code MCP Builder (works well with vscode, cursor, gemini, claude, chatgpt pro)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pzavm8/opensource_nocode_mcp_builder_works_well_with/",
      "author": "mtrnx",
      "created_utc": "2025-12-30 06:34:57",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 0.75,
      "text": "I just published the opensource community edition of HasMCP: No-code, no-deployment API to MCP-Server converter.¬†[https://github.com/hasmcp/hasmcp-ce](https://github.com/hasmcp/hasmcp-ce)¬†. Deploy a single server with docker and then generate 100s in the same host using API endpoints. Built-in support for OAuth2, MCP Tool Changed events and streamable HTTP.",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pzavm8/opensource_nocode_mcp_builder_works_well_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q1exxh",
      "title": "MCP Mailtrap Server ‚Äì Enables sending transactional emails and managing email templates through Mailtrap's API. Supports both production email delivery and sandbox testing with comprehensive template management capabilities.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-01 21:00:08",
      "score": 4,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q1exxh/mcp_mailtrap_server_enables_sending_transactional/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx521cr",
          "author": "modelcontextprotocol",
          "text": "This server has 6 tools:\n\n- [create-template](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/create-template) ‚Äì Create email templates with subject lines and optional HTML/text content for transactional emails and testing workflows.\n- [delete-template](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/delete-template) ‚Äì Remove unwanted email templates from your Mailtrap account to maintain clean template management and eliminate clutter from your email testing environment.\n- [list-templates](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/list-templates) ‚Äì Retrieve all available email templates from the Mailtrap server for managing transactional emails and testing scenarios.\n- [send-email](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/send-email) ‚Äì Send transactional emails to recipients with support for CC/BCC, text/HTML content, and category-based tracking using Mailtrap's email delivery service.\n- [send-sandbox-email](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/send-sandbox-email) ‚Äì Send test emails to a sandbox environment for safe email testing and validation without delivering to real recipients.\n- [update-template](https://glama.ai/mcp/servers/@mailtrap/mailtrap-mcp/tools/update-template) ‚Äì Modify existing email templates by updating name, subject, HTML content, text version, or category for transactional emails and testing.",
          "score": 1,
          "created_utc": "2026-01-01 21:00:09",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nx8eekm",
          "author": "Classic-Sherbert3244",
          "text": "Mailtrap is great for sending transactional email, and they recently bumped up their free tier to 4k emails/mo.",
          "score": 1,
          "created_utc": "2026-01-02 10:34:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pwx968",
      "title": "Anyone built a custom WordPress plugin + MCP server to automate client work via Claude Desktop?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pwx968/anyone_built_a_custom_wordpress_plugin_mcp_server/",
      "author": "Programminginmymind",
      "created_utc": "2025-12-27 12:58:46",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 0.8,
      "text": "Hey all - I built a custom MCP server that lets me manage WordPress client sites through Claude Desktop. Things like updating content, uploading media, managing posts - all via natural language instead of clicking through wp-admin.\n\nMy setup:\n\n\\\\- Custom WordPress plugin (using ACF Pro for structured content)\n\n\\\\- MCP server (Python) with tools that interact via REST API\n\n\\\\- Claude Desktop as the interface\n\nExample: Instead of logging into wp-admin, I just tell Claude \"Update next week's menu\" or \"Upload this PDF and create a post from it\" and it handles everything.\n\nAnyone else experimenting with MCP + WordPress? Curious what tasks you're automating and how your setup looks. Happy to share more details about my implementation if there's interest.\n\n\\\\-Programminginmymind",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pwx968/anyone_built_a_custom_wordpress_plugin_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nw6nc1e",
          "author": "lifeisgoodlabs",
          "text": "I am building the agent skill to do posts on the wordpress site. with their new release it should become easier to do ai integrations",
          "score": 3,
          "created_utc": "2025-12-27 13:01:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw8z2jp",
          "author": "Atomm",
          "text": "Wordpress has a MCP framework you can build on. I was trying to get Claude Code to programmatically make updates to the theme and it wasn't working. CC starts using the API and it does everything I wanted.\n\n\nI never realized just how powerful the WP API was until CC showed me.\n\n\nI don't think you even need a MCP. Just set up an application password and have Claude use the API.",
          "score": 1,
          "created_utc": "2025-12-27 20:37:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9nzhl",
              "author": "Programminginmymind",
              "text": "Yeah i also already built my own REST API Points into my custom Wordpress plugin which i will run on my customers Website and let Claude use this API and for sure the general power of WP API is insane :D",
              "score": 1,
              "created_utc": "2025-12-27 22:53:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdbdhw",
          "author": "UnityDever",
          "text": "just did [https://github.com/Johnny2x2/lombda-wordpress-abilities-pack](https://github.com/Johnny2x2/lombda-wordpress-abilities-pack)",
          "score": 1,
          "created_utc": "2025-12-28 14:46:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvbjml",
      "title": "MCP examples I‚Äôve tested locally ( Figma, Postman, Google Ads) - sharing notes",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pvbjml/mcp_examples_ive_tested_locally_figma_postman/",
      "author": "Silver-Photo2198",
      "created_utc": "2025-12-25 11:32:29",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 0.81,
      "text": "I‚Äôve been working with MCPs across different environments and noticed that most examples are scattered across GitHub repos, Discord threads, and gists, often without clear install steps or notes on what actually works in practice.\n\nTo keep track of things I‚Äôve personally tested, I started organizing:\n\n* MCP servers (Figma, Postman, Google Ads MCP)\n* install and setup steps\n* notes on where they work well (Cursor, Claude, GitHub Copilot, Windsurf, Replit)\n* basic compatibility observations\n\nThis is **not a future service or waitlist** \\- it‚Äôs a live reference I‚Äôm using myself while experimenting with MCP tooling.\n\nFor transparency: I put the examples here:  \nüëâ [https://ai-stack.dev/mcps](https://ai-stack.dev/mcps)\n\nSharing mainly to:\n\n* compare notes with others using MCPs\n* learn which MCPs people here actually rely on\n* understand what breaks or behaves differently across tools\n\nIf you‚Äôre using MCPs in your workflow, I‚Äôd be interested to hear:\n\n* which servers you use most\n* any gotchas you‚Äôve run into\n* MCPs you think are worth documenting next",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pvbjml/mcp_examples_ive_tested_locally_figma_postman/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nvx6dkk",
          "author": "Afraid-Today98",
          "text": "Firecrawl and Playwright are solid for web automation. The Context7 MCP is worth adding too, pulls live docs for any library.",
          "score": 2,
          "created_utc": "2025-12-25 20:44:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzn4pm",
              "author": "Silver-Photo2198",
              "text": "Yes, I concur with that statement. These are all quite useful MCPs to employ.",
              "score": 1,
              "created_utc": "2025-12-26 07:02:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzj0lw",
      "title": "LLM says it did an action‚Ä¶ but never actually used the tool ü§¶‚Äç‚ôÇÔ∏è",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pzj0lw/llm_says_it_did_an_action_but_never_actually_used/",
      "author": "marcocello",
      "created_utc": "2025-12-30 14:07:59",
      "score": 3,
      "num_comments": 10,
      "upvote_ratio": 0.71,
      "text": "I‚Äôm building an LLM agent with access to a fixed set of tools that perform real actions (create/update records, etc.).\n\nProblem: The model sometimes **claims it did something** (‚ÄúDone, I've done what you asked‚Äù) **without ever calling the tool** that would actually do it.\n\nSo:\n\n* If it *can‚Äôt* do something, I want it to say so\n* If no tool exists, I want a refusal\n* If no tool was called, it shouldn‚Äôt claim success\n\nStronger prompts help a bit, but don‚Äôt fully solve it.\n\n\n\nHow do you enforce *‚Äúno tool call = no claim of success‚Äù* in agent systems?\n\nPrompting? Execution contracts? Validation layers? Planning + verification loops?\n\nCurious what actually works in practice",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1pzj0lw/llm_says_it_did_an_action_but_never_actually_used/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwqeeyf",
          "author": "justanemptyvoice",
          "text": "An approach (there are many). \n\nAdversarial validation - ‚Äúmust cite evidence like <format>‚Äù. 2nd agent sees evidence and has prompt to validate evidence exists. \n\nMessage array validation- message array must have ro call and results or agent is reprompted with omission.\n\nBut really, something else is going on.  Like maybe the tool is not the obvious choice to use. Maybe you need better description, or need to include examples, etc‚Ä¶. There‚Äôs not a lot to go on here other than vague situation.",
          "score": 4,
          "created_utc": "2025-12-30 14:14:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqfohc",
              "author": "marcocello",
              "text": "Thanks for the hints!",
              "score": 1,
              "created_utc": "2025-12-30 14:22:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqgunh",
          "author": "rams_16",
          "text": "- Check the ability of model to pick tool( this happened with oss models)\n- try few shot examples \n- may be use simple classifier to determine model usage\n\nMost probably issue can be resolved with 1 or 2",
          "score": 3,
          "created_utc": "2025-12-30 14:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqeocv",
          "author": "nashkara",
          "text": "Out of curiosity, which model did this? Asking because I've personally experienced this as well, but only on Gemini.",
          "score": 2,
          "created_utc": "2025-12-30 14:16:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqffb5",
              "author": "marcocello",
              "text": "I am currently using grok-4.1-fast (no reasoning) mainly because of cost and speed. I was using Sonnet 4.5 with the same settings, and was \"tools-allucinating\" a lot less. But impractical for costs",
              "score": 1,
              "created_utc": "2025-12-30 14:20:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqvfrc",
                  "author": "nashkara",
                  "text": "We were having the issue with Gemini for a while and needed a few tweaks to our system prompts to correct things. Can't speak to Grok, but we never experienced the same issue with OpenAI or Anthropic models.",
                  "score": 1,
                  "created_utc": "2025-12-30 15:43:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwqeklp",
          "author": "proxiblue",
          "text": "Not an expert, but potentially you are hitting context window size. So LLM is loosing track of what it is doing, so hallucinating that it all worked.\n\nInvestigate content rot as a topic.\n\nMaybe a sequencial thinking mcp can help or a better pre action plan broken down into even smaller bits.",
          "score": 1,
          "created_utc": "2025-12-30 14:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqipob",
          "author": "Nalmyth",
          "text": "Happens all the time recently with Claude, they keep putting more and more bugs into the codebase.\n\nThe only workaround I've found is saying something like: \"Show me the XML you would use to call that tool\"\n\nWhich then... calls the tool lol.\n\nI've even had Claude being absolutely insistent that he does not have access to a tool, and then I ask him to show the XML, and \"wow it worked!\"",
          "score": 1,
          "created_utc": "2025-12-30 14:39:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrpzva",
          "author": "Low-Efficiency-9756",
          "text": "ChatGPT is so guilty of this. \n\nI give it a link as it to analyze the contents. It reads the url, guesses at the content, but never fetches the site. \n\nI have to go in and tell it to use a fetch tool. When you control the prompts and the workflows that makes it easier to control the behavior and when you give them better documented tools. \n\nIt‚Äôs a bit of a fight cause when they train the models the usually don‚Äôt have tools so it‚Äôs a bit of a fight against their nature currently to use tools instead of relying on their knowledge base.",
          "score": 1,
          "created_utc": "2025-12-30 18:06:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrzi2j",
          "author": "makinggrace",
          "text": "I think you're trying to enforce the wrong condition. LLM's are trained to use tools as a means to an end. If they are convinced that they have achieved the goal, it's nearly impossible to go back them to go back and try again because they skipped a tooling step (at least not efficiently and certainly not automatically).\n\nBut...check the API. Read it. Every model has good hints in the API especially about tool calling. If you're square there....\n\nWhat I would recommend instead is steeling against hallucinations (always lol). Then gin up some test data and figure out what condition is enforceable and how. You'll need to test each condition and run many trials. Enforceable might be was the data created? (So a comparison of the prior and current state should be not null. Whenever you can create this kind of check.)\n\nAlso make sure that the work you're asking the llm to do actually requires a llm and isn't deterministic. If you can do it in code only, do it in code.",
          "score": 1,
          "created_utc": "2025-12-30 18:50:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1puo3kg",
      "title": "Is anyone using extensible MCP servers/runtimes like wassette, hyper-mcp or jilebi?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1puo3kg/is_anyone_using_extensible_mcp_serversruntimes/",
      "author": "theDatron",
      "created_utc": "2025-12-24 14:03:42",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 0.8,
      "text": "I wanted to know if folks here are using extensible MCP servers that sandbox MCPs into plugins?  \n  \n\\- if you are not using extensible MCPs, why?   \n\\- if you are using extensible MCPs, how is the experience?\n\ndisclosure: I am the dev behind jilebi",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1puo3kg/is_anyone_using_extensible_mcp_serversruntimes/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nvqerch",
          "author": "jboulhous",
          "text": "Can you share a link to your project",
          "score": 1,
          "created_utc": "2025-12-24 15:54:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvt5mqa",
              "author": "theDatron",
              "text": "Here you go: https://jilebi.ai\n\n\nEditing to add the plugins directory:\nhttps://github.com/datron/jilebi-plugins",
              "score": 2,
              "created_utc": "2025-12-25 01:54:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvt6dpf",
                  "author": "jboulhous",
                  "text": "Awesome, i still don't understand what is jilebi to understand why would we create/use plugins for it!?",
                  "score": 1,
                  "created_utc": "2025-12-25 02:00:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyrchk",
      "title": "üöÄ FrontMCP ‚Äî TypeScript-First Open-Source MCP Server Framework",
      "subreddit": "mcp",
      "url": "https://docs.agentfront.dev",
      "author": "Crafty-Annual1024",
      "created_utc": "2025-12-29 16:52:40",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1pyrchk/frontmcp_typescriptfirst_opensource_mcp_server/",
      "domain": "docs.agentfront.dev",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pwmcsl",
      "title": "Building an Outbound VAPI AI Agent with MCP",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pwmcsl/building_an_outbound_vapi_ai_agent_with_mcp/",
      "author": "EigenAtom",
      "created_utc": "2025-12-27 02:34:07",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Had fun putting together an outbound call agent to help my real estate friend manage leads while he is at his second job. \n\nThe build uses Vapi for tts/stt as well as transferring calls directly to him if the lead is ‚Äúhot‚Äù. However, one issue I came across when putting this together was an inability to manage time zones with the native Vapi functions. So, I put together an MCP server and accessed it with ngrok. \n\nCheck out this video I put together for the demo:\n\nOutbound AI Calls with VAPI + MCP Tools (Full Demo)\nhttps://youtu.be/0x-Fh1D4wzI ",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1pwmcsl/building_an_outbound_vapi_ai_agent_with_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pw5gxe",
      "title": "Foundry MCP server -  An experimental MCP Server for foundry built for Solidity devs",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1pw5gxe/foundry_mcp_server_an_experimental_mcp_server_for/",
      "author": "General_County_8067",
      "created_utc": "2025-12-26 14:24:34",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Built a simple, lightweight and fast MCP (Model Context Protocol) server that provides Solidity development capabilities using the Foundry toolchain (Forge, Cast, and Anvil) and Heimdall-rs for bytecode analysis.\n\nCheck it out: [https://github.com/PraneshASP/foundry-mcp-server](https://github.com/PraneshASP/foundry-mcp-server)\n\nIn a nutshell, it allows you to\n\n* Interact with nodes (local Anvil instances or remote RPC endpoints)\n* Analyze transactions and onchain data\n* Perform common EVM operations using Cast\n* Advanced bytecode analysis using Heimdall-rs\n* Manage, deploy, and execute Solidity code and scripts\n* Work with a persistent Forge workspace\n\nhttps://reddit.com/link/1pw5gxe/video/ayeyasvq6k9g1/player\n\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1pw5gxe/foundry_mcp_server_an_experimental_mcp_server_for/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q0u4fa",
      "title": "Domain MCP ‚Äì Enables natural language domain management through Dynadot, supporting domain registration, DNS configuration, transfers, WHOIS contacts, and bulk operations across 106 API actions.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-01 03:00:05",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0u4fa/domain_mcp_enables_natural_language_domain/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx0u73c",
          "author": "modelcontextprotocol",
          "text": "This server has 10 tools:\n\n- [dynadot_account](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_account) ‚Äì Manage Dynadot account settings, check balances, and configure default domain preferences like WHOIS contacts, nameservers, and DNS records through the Domain MCP server.\n- [dynadot_aftermarket](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_aftermarket) ‚Äì Manage domain aftermarket activities including auctions, backorders, expired domains, and marketplace listings through Dynadot's platform.\n- [dynadot_contact](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_contact) ‚Äì Manage WHOIS contact information for domains: create, edit, delete contacts, and configure regional settings for compliance.\n- [dynadot_dns](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_dns) ‚Äì Manage DNS records and DNSSEC configuration for domains through the Domain MCP server. Get, set, or modify DNS settings to control domain routing and security.\n- [dynadot_domain](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_domain) ‚Äì Manage domain names through Dynadot: search availability, register new domains, renew existing ones, and perform bulk operations.\n- [dynadot_domain_settings](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_domain_settings) ‚Äì Configure domain settings including nameservers, WHOIS privacy, auto-renewal, URL forwarding, and parking pages for domains managed through Dynadot.\n- [dynadot_folder](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_folder) ‚Äì Manage domain folders in Dynadot by creating, deleting, listing, and configuring settings like WHOIS, DNS, nameservers, forwarding, and renewal options.\n- [dynadot_nameserver](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_nameserver) ‚Äì Manage custom nameservers (glue records) for domains: register new nameservers, update IP addresses, delete existing ones, or list all configured nameservers.\n- [dynadot_order](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_order) ‚Äì Manage domain orders and related operations through Dynadot, including checking order status, listing available coupons, and handling reseller verification.\n- [dynadot_transfer](https://glama.ai/mcp/servers/@joachimBrindeau/domain-mcp/tools/dynadot_transfer) ‚Äì Manage domain transfers through Dynadot: initiate transfers, check status, handle authorization codes, and process push requests between registrars.",
          "score": 2,
          "created_utc": "2026-01-01 03:00:05",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0quzx",
      "title": "Examplary MCP Server ‚Äì Provides AI assistants with access to Examplary's exam management platform, enabling users to create and manage exams, generate questions from materials, grade student responses, and collaborate in workspaces through 60+ API endpoints.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@examplary-ai/mcp",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-01 00:00:09",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0quzx/examplary_mcp_server_provides_ai_assistants_with/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nx027x9",
          "author": "modelcontextprotocol",
          "text": "This server has 62 tools:\n\n- [deleteExamsid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteExamsid) ‚Äì Remove exams from the management platform by specifying their unique identifiers to maintain organized exam records.\n- [deleteExamsidSessionssessionId](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteExamsidSessionssessionId) ‚Äì Remove a specific exam session by providing the exam ID and session ID to delete it from the exam management platform.\n- [deleteFoldersid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteFoldersid) ‚Äì Remove folders from exam management workspaces while automatically preserving exam content by moving it outside the folder before deletion.\n- [deleteOrg](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteOrg) ‚Äì Remove organizations from the Examplary exam management platform to maintain accurate workspace structures and data organization.\n- [deleteQuestion_bankid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteQuestion_bankid) ‚Äì Remove a question bank item from your workspace by specifying its ID to manage exam content effectively.\n- [deleteQuestion_typesid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteQuestion_typesid) ‚Äì Remove a question type by ID when it's unused in exams and owned by your organization.\n- [deleteSource_materialsid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteSource_materialsid) ‚Äì Remove source materials from exam management platform by specifying ID to maintain organized content libraries.\n- [deleteTaxonomiesid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteTaxonomiesid) ‚Äì Remove a taxonomy from your workspace when no exams are linked to it, ensuring clean exam management by deleting unused categories.\n- [deleteUsersid](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/deleteUsersid) ‚Äì Remove a user from the workspace by specifying their unique ID to manage team access and permissions.\n- [getExams](https://glama.ai/mcp/servers/@examplary-ai/mcp/tools/getExams) ‚Äì Retrieve a list of all exams available in your workspace for management and review.",
          "score": 2,
          "created_utc": "2026-01-01 00:00:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0m07a",
      "title": "MCP-Discord ‚Äì A Discord Model Context Protocol server that enables AI assistants to interact with Discord by sending messages, managing channels, handling forum posts, managing webhooks, and processing reactions.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@IQAIcom/mcp-discord",
      "author": "modelcontextprotocol",
      "created_utc": "2025-12-31 20:00:05",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1q0m07a/mcpdiscord_a_discord_model_context_protocol/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q05f38",
      "title": "Criteria for an MCP server",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q05f38/criteria_for_an_mcp_server/",
      "author": "Snickers_B",
      "created_utc": "2025-12-31 05:52:41",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Simple question, what criteria do you use when evaluating an mcp server? I see a lot of great advi e here on what mcps to use but I'm still struggling with how to choose one for any given project.\n\nThere is the programming language of course, and there is the primary use case as well but beyond that how do you choose the one that fits your project?\n\nThanks",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1q05f38/criteria_for_an_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwvj8ie",
          "author": "MycologistWhich7953",
          "text": "depends if your running locally you can use stdio as most MCP are stdio iiuc. the alternative would be an over https like the new google maps grounding lite mcp",
          "score": 1,
          "created_utc": "2025-12-31 06:51:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nww9zkg",
              "author": "Cyclr_Systems",
              "text": "Yeah transport/deployment first. After that, look for actively maintained and decent docs, tools that are well-scoped with predictable inputs/outputs, and a sane security story for secrets/permissions (especially if it can write)",
              "score": 1,
              "created_utc": "2025-12-31 11:01:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx11qw7",
          "author": "Automatic-Step-9756",
          "text": "Few things to consider for MCP server:  \n\\- stdio(best for personal/local use) OR HTTP(easy for none technical users to setup)  \n\\- Programming language(choose one which has MCP library available)  \n\\- MCP protocol version support from LLM client",
          "score": 1,
          "created_utc": "2026-01-01 03:51:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0lboj",
      "title": "Can someone explain the current state of the MCP specs?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1q0lboj/can_someone_explain_the_current_state_of_the_mcp/",
      "author": "Party-Cartographer11",
      "created_utc": "2025-12-31 19:29:18",
      "score": 1,
      "num_comments": 28,
      "upvote_ratio": 0.55,
      "text": "Hi all,\n\nI am confused about the current state and future direction of the MCP protocol.  Here are my current understanding and questions ..\n\n\\- MCP specs were defined by and Open a sourced by Anthropic and were originally focused on local development,\n\n\\- JSON RPC was chosen as the transport.\n\n\\- There have been discussions to use HTTP Rest and even a proposed Spec by Microsoft in the GitHub repo.  But it looks like it was retracted by Microsoft.\n\n\\- Google obviously prefers gRPC.\n\n\\- There seems to be an overloading of transport and API structure and/or idempotency/session management in the scope of the spec.\n\nIs this an accurate understanding?  Is JSON RPC scalable and is the direction stable?  Or is this tech debt due to Anthropic's current install base? Is HTTP/REST the likely future direction?\n\nThanks for any insight/corrections...",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1q0lboj/can_someone_explain_the_current_state_of_the_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nwytspu",
          "author": "cab938",
          "text": "Payload is JSON RPC, transport can be through stdio, http, or sse. Sadly I've seen nothing suggesting payload will switch away from JSON.",
          "score": 1,
          "created_utc": "2025-12-31 19:48:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzhk5w",
              "author": "qwer1627",
              "text": "payload can be absolutely anything, the spec only defines the means by which to auth, provide tools, and explains to you, the one implementing the spec, how an LLM will interface with the concept of MCP provided tooling\n\nIt's like USB , in that it's minimal by design",
              "score": 2,
              "created_utc": "2025-12-31 21:58:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx0bftl",
                  "author": "AyeMatey",
                  "text": "\\> how an LLM will interface with the concept of MCP provided tooling\n\nPeople keep saying this.  It's never been true, and it's still not true.  The only way this can be true is if you conflate \"LLM\" with \"Chatbot\"/\"Agent\", and I think that's either dishonest, or irresponsible, or confused.\n\nLLMs do not directly use MCP, do not \"support\" MCP.  It's chatbots or agent tools that act as MCP clients talking to MCP Servers.   Things like Claude Code, Gemini CLI, VSCode, or a variety of others. Those are not LLMs. An MCP conversation exists without involving any LLM at all.  Look at the diagrams on the [modelcontextprotocol.io](http://modelcontextprotocol.io) website - it's very clear.\n\nThe way an LLM interfaces with tooling is prescribed by each LLM - Anthropic calls it \"tool calling\" and Gemini calls it \"function calling\" and I'm not sure about the others. That interface is not standardized, not at this point anyway.  And it has nothing to do with MCP.",
                  "score": 2,
                  "created_utc": "2026-01-01 00:56:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwziwa1",
                  "author": "cab938",
                  "text": "That's not true. You must use json-rpc for at least negotiation and handshaking.\n\nWhether it is minimalist or not depends on your definition of minimalist.",
                  "score": 1,
                  "created_utc": "2025-12-31 22:05:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx4q07c",
                  "author": "danja",
                  "text": "USB A, B, C, mini, micro...",
                  "score": 1,
                  "created_utc": "2026-01-01 19:57:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwz894b",
              "author": "Party-Cartographer11",
              "text": "Thanks!\n\n\nYes, I think that is part of the discussion as HTTP is really an application protocol( TCP is transport), and overlaps with the JSON RPC features (REST methods are remote procedure calls).¬† It also provides a Framework with authN (headers, cookies).\n¬†\nAnd gRPC is similarly overlapping.\n\n\nCurrently I use Flask as a web services server, Oauth for authN, and make direct calls to Python scripts.¬† I am trying to figure out my roadmap and what to use where.¬† Do I move to MCP now or wait for more clarity? HTTP REST would be a smoother transition if that is supported in the future.",
              "score": 1,
              "created_utc": "2025-12-31 21:07:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwzgp48",
                  "author": "cab938",
                  "text": "Philosophically let me just call out that you should consider what is using your API, whether flask-based http or mcp-based (eg fastmcp). For the former, even if rest style, it's usually a deterministic process like a web front end. This is different than an llm-based agent in a few ways, but primarily you should be thinking of small simple apis and data structures for agents, more complex ones are fine for deterministic processes.\n\nSo \"scrape page x\" which takes a url for scraping a page is a fine MCP. For a rest service you might have dozens or more parameters which control the scraping. Putting those parameters in your MCP service will lead to the agent model improperly calling the service more often.\n\nLots of continuing challenges with MCP -- auth, async, etc. I expect there will be many changes over the next year, though sadly I don't think it will be moving away from JSON.\n\nAlso, MCP has some affordances rest doesn't -- for instance, with MCP you have the ability to put documentation right in the service explaining how to use it (resources), and you have the ability to have your service signal a human user needs to do something (elicitation). I expect over the next year this will continue to diverge from REST.",
                  "score": 1,
                  "created_utc": "2025-12-31 21:53:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzxfg4",
          "author": "Automatic-Step-9756",
          "text": "IMHO - MCP is created to standardize tool(function call) usage with various LLMs. Since LLMs are mainly trained to process natural language, JSON is more suitable and closer to natural language and model training to produce dynamic schema based output. Also most LLMs have their own function call specs and mostly JSON schema based. So MCP is very mature and on correct path, also gaining fast adoption across LLM clients.",
          "score": 1,
          "created_utc": "2025-12-31 23:31:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx0086f",
              "author": "Party-Cartographer11",
              "text": "My use case has natural language input (system prompt, human readable data which I include in the prompt and happens to be in JSON from the database) and asks for JSON output, so the MCP doesn't need to support JSON in that case.¬† In fact JSON gets in the way.¬† But it works.\n\n\nLet's take this sample use case.¬† An LLM wants user information to identify possible hackers.¬† The information is stored in a Postgres database, that has a feed from a Threat Intelligence feed (or the LLM can directly source the TI feed), and other data collected by the user.¬† Sources: Company directory (for insider threats), TI feed, Mitre Att&ck (for TTPs that attackers might be associated with) all chuncked and vector embedded, and some system logs (firewalls, suthN, net flow).\n\n\nThe system prompt has instructions on what indicators to look for, how to structure risk, and asks for a JSON output to feed a front end/alert UI.\n\n\nWe want the model to run all the time for the user and update the UI and maybe send some emails (likely would use Alert platform for that).¬† And of course there is a feedback loop.\n\n\nWhat role does MCP play here?¬† Is it purely a vendor role, and I wait for the TI feed vendor, the Enterprise directory vendor, and Postgres to implement MCP?¬† Do I role my own in front of the Postgres database?¬† If so,¬†does a JSON payload help any over a barebones protocol and natural language?¬† For example an HTTP/POST with the data from the sources in a document?\n\n\nSorry if I am going of topic...",
              "score": 1,
              "created_utc": "2025-12-31 23:48:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx04hix",
                  "author": "Automatic-Step-9756",
                  "text": "I think, MCP fits perfectly for your need and may simplify your work and also make it portable to switch models.... do you want to make something similar to [https://www.reddit.com/r/mcp/comments/1pqa9iq/claude\\_performing\\_crud\\_using\\_mcp/](https://www.reddit.com/r/mcp/comments/1pqa9iq/claude_performing_crud_using_mcp/)",
                  "score": 1,
                  "created_utc": "2026-01-01 00:14:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx18hu9",
          "author": "caj152",
          "text": "MCP has overreached as a spec IMO. And we‚Äôre adding more and more and more.\n\nWorse, it‚Äôs encouraging the enspecification of everything in the space. We need less specs to conform to and more experimentat",
          "score": 1,
          "created_utc": "2026-01-01 04:40:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwyzana",
          "author": "AyeMatey",
          "text": "> Is JSON RPC scalable and is the direction stable?  Or is this tech debt due to Anthropic's current install base? Is HTTP/REST the likely future direction?\n\nWhat is the point of these questions? What would you change if you had confidence in the answers, one way or the other?\n\nJsonrpc was chosen , probably , because MCP was philosophically inspired by LSP.  But it‚Äôs just a data format. Why is it so important? ‚ÄúGoogle prefers gRPC‚Äù is irrelevant for this discussion. There is no evidence that Google is making a gRPC-based MCP.",
          "score": 0,
          "created_utc": "2025-12-31 20:18:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwz3dl0",
              "author": "Party-Cartographer11",
              "text": "The point of the questions is for me to better understand the current state and roadmap so I know how best to invest in MCP for my services.\n\n\ngRPC is relevant as Google has used that in the past as a replacement for other JSON RPC services.¬† There is also a proposal in the MCP repo discussing using gRPC.¬†¬†\nhttps://github.com/modelcontextprotocol/modelcontextprotocol/discussions/1144\n\n\nOf course there is no evidence as not everything is public yet.¬† Just trying to get folks' POV and have a discussion about where things might go.",
              "score": 1,
              "created_utc": "2025-12-31 20:40:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwz58qt",
                  "author": "coloradical5280",
                  "text": "That is now a question for the Linux Foundation. Known to be light on their feet, with an agreeable board, and speedy turnaround times /s\n\nSeriously though, with the lack of resources anthropic dedicated to this, that‚Äôs probably where it belongs. Good move by anthropic to hand it over",
                  "score": 2,
                  "created_utc": "2025-12-31 20:51:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwzhaja",
          "author": "qwer1627",
          "text": "The spec is flawless, easy to grok, and very simple to implement - it's in the state of near perfection.",
          "score": 0,
          "created_utc": "2025-12-31 21:56:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwzj39e",
              "author": "cab938",
              "text": "Dang, I hope you're in a European time zone given you seem to be hitting that champagne already! Not sure anyone would call it \"flawless\"...",
              "score": 3,
              "created_utc": "2025-12-31 22:06:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx0jo2c",
                  "author": "qwer1627",
                  "text": "Fighting fire of 'itS So BroKeN' with fire of 'It Is Perfect'\n\nMajority of issues and PEPs hitting that spec are implementation details, and contribute nothing to the spec itself, which I feel a particular way about\n\nTell me - what do you think you cannot do with MCP as it is today?",
                  "score": 1,
                  "created_utc": "2026-01-01 01:49:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwzjkt9",
              "author": "Party-Cartographer11",
              "text": "üôÑ",
              "score": 2,
              "created_utc": "2025-12-31 22:09:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nx0bipn",
              "author": "AyeMatey",
              "text": "I upvoted this because I thought it was sweet sarcasm, but I think you're serious!  Yikes!",
              "score": 2,
              "created_utc": "2026-01-01 00:57:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx17r7s",
                  "author": "perryhopeless",
                  "text": "Same here. Do I take my upvote back???",
                  "score": 1,
                  "created_utc": "2026-01-01 04:34:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}