{
  "metadata": {
    "last_updated": "2026-02-08 16:49:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 82,
    "file_size_bytes": 96615
  },
  "items": [
    {
      "id": "1qyncmd",
      "title": "CodeGraphContext - An MCP server that indexes your codebase into a graph database to provide accurate context to AI assistants and humans",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/gallery/1qyncmd",
      "author": "Desperate-Ad-9679",
      "created_utc": "2026-02-07 19:44:19",
      "score": 118,
      "num_comments": 28,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qyncmd/codegraphcontext_an_mcp_server_that_indexes_your/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o44vp82",
          "author": "Otherwise_Wave9374",
          "text": "Congrats on the momentum, those adoption numbers are wild. Graph-based context feels like the direction most serious coding agents need, because chunk-RAG turns into token spam fast.\n\nCurious how you handle dynamic repos: do you incrementally update the graph on file change, and do you have a strategy to avoid stale edges when refactors happen?\n\nAlso if youre comparing approaches, Ive seen some good discussions around agent context strategies here: https://www.agentixlabs.com/blog/\n\nLooks really promising.",
          "score": 5,
          "created_utc": "2026-02-07 20:01:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44wpxl",
              "author": "Desperate-Ad-9679",
              "text": "First of all thanks a lot for the appreciation, I too was annoyed by the problems that chunking causes.  \nFor dynamic repos, we do watch files for live changes using watch\\_dog and the incremental updates are done by replacing all nodes, including and contained within the node. This helps it to be fast and accurate.\n\nThanks again for the link, will appreciate going through the details mentioned there.",
              "score": 2,
              "created_utc": "2026-02-07 20:06:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o44uzm2",
          "author": "Desperate-Ad-9679",
          "text": "Another clue to the next version - We are launching CodeGraphContext as a VS code extension soon ‚ú®‚≠ê, Do star the repository please and join the Discord server for latest news",
          "score": 8,
          "created_utc": "2026-02-07 19:57:12",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o45ffco",
          "author": "Tobi-Random",
          "text": "https://gitlab-org.gitlab.io/rust/knowledge-graph/",
          "score": 4,
          "created_utc": "2026-02-07 21:47:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45grox",
              "author": "Desperate-Ad-9679",
              "text": "Damn that's a very close project like mine, but I cant see much progress in there. But yeah definitely they are a complete org so the project even though a little slow will catch up traction sooner or later.",
              "score": 2,
              "created_utc": "2026-02-07 21:54:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46jdjq",
          "author": "BC_MARO",
          "text": "Graph-based code indexing is such a better approach than just chunking files. How are you handling incremental updates when only a few files change? That's usually where the perf bottleneck shows up.",
          "score": 2,
          "created_utc": "2026-02-08 01:45:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47xhbt",
              "author": "Desperate-Ad-9679",
              "text": "Whenever we change a file, we delete the node and all related edges to this. Then only that file is brought-back and from the cache we do path resolution for imports. ",
              "score": 2,
              "created_utc": "2026-02-08 08:01:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o47xi24",
                  "author": "Desperate-Ad-9679",
                  "text": "Thanks for your kind words!",
                  "score": 1,
                  "created_utc": "2026-02-08 08:01:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o47szsg",
          "author": "debackerl",
          "text": "This is really a great idea! Looks awesome. Now, if you allow me, why not combine both worlds: if the AI doesn't know from why 'node' to start from, compute an embedding for each function. Then you can tell, 'give me the function validating my shopping cart', and then give me all functions calling it.",
          "score": 2,
          "created_utc": "2026-02-08 07:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47xqg4",
              "author": "Desperate-Ad-9679",
              "text": "Thanks for your appreciation!  \n  \nExactly, this is something we have in our bucket list. I have been writing some small algorithms to identify and store vector embeddings for nodes, cluster of nodes. This is an open problem and so needs a lot of brainstorming as of now...",
              "score": 2,
              "created_utc": "2026-02-08 08:03:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o485037",
          "author": "ratek-20",
          "text": "Great Job, I'll definitely give it a try!\nDo you think it can be expanded to services?\nFor example order-service calls warehouse-service via rest api -> they can be 2 linked nodes of the graph",
          "score": 2,
          "created_utc": "2026-02-08 09:12:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o485awm",
              "author": "Desperate-Ad-9679",
              "text": "Thanks for your kind words,  \nRight now it doesnt have, but thanks for the suggestion. Will add it in the next version.",
              "score": 2,
              "created_utc": "2026-02-08 09:15:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o485etu",
                  "author": "Desperate-Ad-9679",
                  "text": "Also it can definitely be expanded because we already parse entire codebases.",
                  "score": 2,
                  "created_utc": "2026-02-08 09:16:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o466lpq",
          "author": "bargaindownhill",
          "text": "no instructions for roo or kiro?",
          "score": 1,
          "created_utc": "2026-02-08 00:26:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47h9xf",
              "author": "Desperate-Ad-9679",
              "text": "Oops, I raised an issue for this but forgot the fact that I got no PR. Will do this by the next version (perhaps in a day)",
              "score": 2,
              "created_utc": "2026-02-08 05:36:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o47zi93",
                  "author": "bargaindownhill",
                  "text": "thanks!",
                  "score": 1,
                  "created_utc": "2026-02-08 08:20:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o47xcw8",
              "author": "Desperate-Ad-9679",
              "text": "There's already an option for roocode, checkout by doing \\`cgc mcp setup\\`",
              "score": 2,
              "created_utc": "2026-02-08 08:00:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4705i4",
          "author": "I_EAT_THE_RICH",
          "text": "Funny enough, I was working on something like this about 6 months ago with the same intent. I think managing context is extremely important and making your codebase queryable in this fashion makes a ton of sense. Good work.",
          "score": 1,
          "created_utc": "2026-02-08 03:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47xkz2",
              "author": "Desperate-Ad-9679",
              "text": "Thanks a lot for your kind words, No more- No less, only the appropriate context makes sense!!",
              "score": 1,
              "created_utc": "2026-02-08 08:02:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4876h2",
              "author": "raiffuvar",
              "text": "A lot of ppl were working on smth like this and later claude showed that grep is enough. (At least I stopped trying with opus4 cause it eventually will catch up).",
              "score": 1,
              "created_utc": "2026-02-08 09:33:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4888bz",
                  "author": "Desperate-Ad-9679",
                  "text": "Perhaps, but I am unsure if they can find perfect call chains or dead code??",
                  "score": 1,
                  "created_utc": "2026-02-08 09:43:04",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o49fjw9",
                  "author": "I_EAT_THE_RICH",
                  "text": "It's a fair consideration that depending on the model it may not be necessary. Can you provide any links demonstrating grep vs a knowledge graph? I assume there might be some tests out there but haven't found any myself yet.",
                  "score": 1,
                  "created_utc": "2026-02-08 15:06:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o487hoq",
          "author": "raiffuvar",
          "text": "What's the difference between LSP? \nDoes it parse docs?\n\nUpd: did not dig in but small advice: return tree and file/method annotations and lineno.",
          "score": 1,
          "created_utc": "2026-02-08 09:36:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o488fds",
              "author": "Desperate-Ad-9679",
              "text": "LSPs are way slow than my custom resolution logic (though it adds a little inconsistencies sometimes as of now), also it is polyglot but LSPs are not. One more thing is that it doesnt need any external bundle installations like LSPs need for each lang.\n\nAdding Docs, is the second stage. Will add them by the next version release ",
              "score": 1,
              "created_utc": "2026-02-08 09:44:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4895qv",
          "author": "maverick_soul_143747",
          "text": "I am building something on my own and was planning to handle it with contexf7, obsidian but I am going to try this. This looks exciting",
          "score": 1,
          "created_utc": "2026-02-08 09:51:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o489c8n",
              "author": "Desperate-Ad-9679",
              "text": "Great, good luck for your quest!",
              "score": 2,
              "created_utc": "2026-02-08 09:53:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwvl5u",
      "title": "API ‚Üí MCP Server, in 30 seconds.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qwvl5u/api_mcp_server_in_30_seconds/",
      "author": "dorukyelken",
      "created_utc": "2026-02-05 19:51:43",
      "score": 36,
      "num_comments": 9,
      "upvote_ratio": 0.8,
      "text": "Turn your existing APIs into an MCP Server without rewriting anything.\n\nBuilt for teams experimenting with MCP, agents, and tool-based AI workflows.\n\nThis is a beta, free-to-try personal project.\n\nTry it out and share feedback üëá\n\n[https://apitomcphost.com/](https://apitomcphost.com/)\n\nHow it works (short demo):\n\nhttps://reddit.com/link/1qwvl5u/video/114wshoj55ig1/player\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qwvl5u/api_mcp_server_in_30_seconds/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3tirtn",
          "author": "AchillesDev",
          "text": "Ah yes, the ubiquitous MCP antipattern engine. \n\n[Don't convert your REST APIs to MCP servers](https://www.jlowin.dev/blog/stop-converting-rest-apis-to-mcp)",
          "score": 18,
          "created_utc": "2026-02-06 00:53:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3t2nr7",
          "author": "Obvious-Car-2016",
          "text": "Umm just use the Claude code mcp builder skill",
          "score": 4,
          "created_utc": "2026-02-05 23:21:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ubu9v",
          "author": "BC_MARO",
          "text": "interesting approach. wrappers like this are great for getting started quickly, but curious how you're handling auth + rate limiting on the mcp side (api keys vs oauth, per-user vs per-app, etc)?\n\ni've found that's usually where these \"openapi -> tool surface\" bridges get tricky in production.",
          "score": 1,
          "created_utc": "2026-02-06 03:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o416618",
          "author": "Physical_Ideal_3949",
          "text": "Are u using fastmcp to do this",
          "score": 1,
          "created_utc": "2026-02-07 05:04:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42iys4",
          "author": "jezweb",
          "text": "Then you start to use it with an ai agent and realise it‚Äôs inefficient junk and you start over properly.",
          "score": 1,
          "created_utc": "2026-02-07 12:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o439ulr",
          "author": "Able-Classroom7007",
          "text": "An approach that I really like for API to MCP is to \"Code Mode\" like Turbopuffer MCP has.\n\nThe idea is you have 2 tools: API docs + write and execute code in a sandbox that only has network access to that API endpoint.\n\nSuper clean and great for complex APIs.\n\n[https://github.com/turbopuffer/turbopuffer-typescript/tree/main/packages/mcp-server](https://github.com/turbopuffer/turbopuffer-typescript/tree/main/packages/mcp-server)",
          "score": 1,
          "created_utc": "2026-02-07 15:12:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rxl5u",
          "author": "finance-mcp-001",
          "text": "This is quite cool. Any link to a GitHub repo? I‚Äôm very curious about the conversion methodology.",
          "score": 1,
          "created_utc": "2026-02-05 19:58:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yahvl",
          "author": "connectgeeks",
          "text": "If you‚Äôre exploring MCP beyond toy examples, having a curated list really helps.  \nI‚Äôve been bookmarking tools, servers, agents, and real-world MCP implementations as I come across them.  \nThis collection might save some digging [https://github.com/JustInCache/awesome-mcp-collection](https://github.com/JustInCache/awesome-mcp-collection).If you know any good MCP projects that aren‚Äôt listed yet, you can add them.",
          "score": 1,
          "created_utc": "2026-02-06 19:11:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rz82a",
          "author": "Otherwise_Wave9374",
          "text": "This is a great pitch, converting an OpenAPI into an MCP server is exactly the kind of glue that makes agent tooling practical for teams. Not having to rewrite your backend just to \"make it agent friendly\" is huge.\n\nCurious if you support auth flows cleanly (API keys vs OAuth) and how you handle tool schemas for long running jobs. I have been tracking MCP and tool calling patterns here too: https://www.agentixlabs.com/blog/",
          "score": -2,
          "created_utc": "2026-02-05 20:06:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qt81d1",
      "title": "MCP directory that actually checks if servers are alive",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qt81d1/mcp_directory_that_actually_checks_if_servers_are/",
      "author": "punkpeye",
      "created_utc": "2026-02-01 19:26:31",
      "score": 30,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "There are dozens if not hundreds of remote MCP servers lists. The problem is that they get stale, don't tell you which servers work/which don't, or even what tools are available. That's what we're fixing with the MCP connector directory:\n\nhttps://glama.ai/mcp/connectors\n\nWe aggregate from the official MCP registry + community submissions, then actually connect to every server periodically and report:\n\n* Health ‚Äì Is the server up right now?\n* Auth ‚Äì how to authenticate to the server?\n* Schema ‚Äì what tools are available?\n* Changelog ‚Äì record of schema changes (new tools added, description updates, etc).\n\nAdditionally, if you are using our one-click connector, you can consolidate authentication/logging of all your MCP servers in one place. 100% free ‚Äì no subscription required.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qt81d1/mcp_directory_that_actually_checks_if_servers_are/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o310rp6",
          "author": "Ok_Message7136",
          "text": "This solves a real problem.  \nFor local validation before publishing, I‚Äôve been using Gopher‚Äôs free, open-source MCP SDK to spin up and test MCP servers (tools + schema) before listing them anywhere.\n\nLink: [https://github.com/GopherSecurity/gopher-mcp](https://github.com/GopherSecurity/gopher-mcp)",
          "score": 2,
          "created_utc": "2026-02-01 19:53:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvgt6g",
      "title": "Built the most comprehensive Ghidra MCP Server ‚Äî 110 tools for AI-powered reverse engineering (v2.0.0)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qvgt6g/built_the_most_comprehensive_ghidra_mcp_server/",
      "author": "XerzesX",
      "created_utc": "2026-02-04 06:12:09",
      "score": 27,
      "num_comments": 2,
      "upvote_ratio": 0.95,
      "text": "Hey r/mcp,\n\nJust released v2.0.0 of my Ghidra MCP Server with **110 tools** ‚Äî by far the most feature-complete Ghidra integration for MCP. For context, the most popular one (LaurieWired's, 7K+ stars) has about 15 tools.\n\n## What makes this different\n\nüîß **110 MCP tools** covering decompilation, disassembly, analysis, annotation, data types, and project management\n\nüîÑ **Cross-binary function documentation transfer** ‚Äî hash functions by behavior (not addresses), so when a new binary version drops, all your annotations carry over automatically. No more re-doing work across versions.\n\n‚ö° **Batch operations** ‚Äî analyze multiple functions/addresses in one call (93% API call reduction vs. one-at-a-time)\n\nüê≥ **Headless mode + Docker** ‚Äî run analysis pipelines without the GUI. `docker compose up` and you're analyzing binaries.\n\nüìã **.env configuration** ‚Äî no hardcoded paths, everything configurable\n\n## Real-world usage\n\nI've been using this for Diablo 2 reverse engineering across 20+ patch versions. The function hash registry has **154K+ entries** ‚Äî when a new patch drops, annotations transfer automatically instead of starting from scratch.\n\n## What's new in v2.0.0\n\n- Localhost-only binding for security (no more accidental network exposure)\n- Configurable decompile timeout\n- New label deletion tools (delete_label + batch_delete_labels)\n- .env-based configuration (no hardcoded paths)\n- Ghidra 12.0.2 support\n- Complete README rewrite with full API reference\n\n## Links\n\n- **GitHub:** https://github.com/bethington/ghidra-mcp\n- **v2.0.0 Release:** https://github.com/bethington/ghidra-mcp/releases/tag/v2.0.0\n\nPart of a broader RE toolkit ‚Äî I also maintain [cheat-engine-server-python](https://github.com/bethington/cheat-engine-server-python) for dynamic analysis via MCP and [re-universe](https://github.com/bethington/re-universe) for BSim-powered binary similarity at scale.\n\nHappy to answer questions about the architecture, the hashing algorithm, or how MCP fits into RE workflows.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qvgt6g/built_the_most_comprehensive_ghidra_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3hkbi2",
          "author": "bargaindownhill",
          "text": "Jebus, where were you a week ago when i did a full disassembly and RE on an old 8051 design to teach my students what y2k was?",
          "score": 3,
          "created_utc": "2026-02-04 06:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kfyh6",
          "author": "bargaindownhill",
          "text": "ok commenting again.. \n\ncomplex setup, had to do some mods to make it work with roocode but OMFG!! this thing is MINT! best MCP of the year. You are the GOAT!\n\nim going to need about 3 classes to teach my students how to install and use this, but they are going to love this MCP",
          "score": 2,
          "created_utc": "2026-02-04 17:47:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qux52j",
      "title": "Built an MCP server for automatic file organization - Claude helped me handle 12+ file categories and security hardening",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qux52j/built_an_mcp_server_for_automatic_file/",
      "author": "Technocratix902",
      "created_utc": "2026-02-03 16:49:26",
      "score": 19,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "Hey everyone! I wanted to share a project I built that makes Claude really useful for organizing messy folders.\n\n**What I built:** File Organizer MCP Server - an MCP server that lets Claude automatically organize your files into categories, find duplicates, and identify space-consuming files.\n\n**How Claude helped:**\n\n* Helped me design the security architecture (path traversal protection, symlink validation)\n* Debugged the content-based duplicate detection algorithm\n* Wrote comprehensive test coverage for the security features\n* Helped optimize the file hashing to handle large directories without memory issues\n* Refined the category system to cover 12+ file types\n\n**What it does:** When connected to Claude Desktop, you can ask Claude to:\n\n* \"Organize my Downloads folder\" - automatically sorts files into Executables, Videos, Documents, Images, Audio, etc.\n* \"Find duplicate files in my Documents\" - identifies wasted space from duplicate files\n* \"Show me the 20 largest files\" - helps you find space hogs\n* \"Categorize files in this directory\" - gives you a breakdown without moving anything\n* \"Organize with dry run\" - preview changes before executing\n\n**Technical highlights:**\n\n* Security score: 9.5/10 (multi-layer path validation, resource limits, streaming operations)\n* Handles naming conflicts automatically\n* Preserves file metadata\n* Memory-safe for large directories (tested with 10,000+ files)\n\n**Free to use:** The entire project is open source (MIT license) and free. Just install via npm and configure in Claude Desktop.\n\n**Link:** [https://github.com/kridaydave/File-Organizer-MCP](https://github.com/kridaydave/File-Organizer-MCP)\n\nI'm 15 and this is my first real open-source project, so feedback would be amazing! Claude was basically my pair programming partner throughout the entire build - especially for the security hardening parts where I didn't have prior experience.\n\nHas anyone else used MCP servers for file management workflows? Curious what other use cases people have found.\n\n*Processing video sxpwhyu751hg1...*\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qux52j/built_an_mcp_server_for_automatic_file/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3hckls",
          "author": "BC_MARO",
          "text": "This is the kind of MCP server people actually keep running. Two things I'd watch in prod:\n\n- make the tool surface 'dry-run' by default + require an explicit 'apply' for destructive moves\n- log every tool call with inputs/outputs so you can audit weird behavior later\n\nIf you end up needing approvals/audit across multiple MCP servers, a control-plane like Peta can help: https://peta.io",
          "score": 3,
          "created_utc": "2026-02-04 05:31:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dtedp",
          "author": "Educational-Bison786",
          "text": "Awesome project especially at 15. For other MCP uses, I've seen people build them for smart home control or even automating dev workflows. When agents get complex, ensuring their reliability is critical. [Maxim AI](https://getmax.im/Max1m) helps teams evaluate agent performance and catch issues. Also look into tools like SonarQube for code quality checks.",
          "score": 2,
          "created_utc": "2026-02-03 18:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ihemt",
          "author": "07mekayel_anik07",
          "text": "Interesting!\nYou may add .md and tex files as documents. \nThis will help this mcp to reorganize code directory as well (messed up docs).\nAlso you can consider test, debug, demo etc. file name to organize as test/debug code/script.\n\nThese will amke this mcp a good choice for coding as well.",
          "score": 2,
          "created_utc": "2026-02-04 11:32:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nf1e9",
              "author": "Technocratix902",
              "text": "Hmm ü§î Interesting. Didnt even think about code but already on the way. \nAlong with TUI setup wizard, cloud support and 2 new features",
              "score": 1,
              "created_utc": "2026-02-05 02:50:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ddk7p",
          "author": "Ok_Message7136",
          "text": "Nice MCP use case, file ops + dry-run + security hardening is exactly where MCP shines. This feels genuinely practical.",
          "score": 1,
          "created_utc": "2026-02-03 17:02:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3defg7",
              "author": "Technocratix902",
              "text": "Thanks üôè! It's entirely free to use and available on NPM . Check it out, would love feedback from the community!",
              "score": 1,
              "created_utc": "2026-02-03 17:07:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fajz9",
          "author": "Great_Scene_5604",
          "text": "Congrats, very practical application. Do you run the MCP server locally? Wondering if could extend to Drive ...",
          "score": 1,
          "created_utc": "2026-02-03 22:21:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gxxl1",
              "author": "Technocratix902",
              "text": "For now the AI can only access local files(and onedrive) but we are working on Cloud Storage support. This is a ongoing discussion and will definitely be a feature in the future. Thanks for the feedback !",
              "score": 1,
              "created_utc": "2026-02-04 03:51:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ggfh8",
          "author": "Putrid-Pair-6194",
          "text": "Congrats on your first project. Impressed that you focused so much on security. That will serve you well as you publish more in the future.",
          "score": 1,
          "created_utc": "2026-02-04 02:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3gy7l8",
              "author": "Technocratix902",
              "text": "For a file op, security is the upmost priority. If an AI goes rogue or starts hallucinations it's critical to control it. But we have also integrated it in a way that doesn't harm UX. Thanks for the feedback!",
              "score": 1,
              "created_utc": "2026-02-04 03:53:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvap02",
      "title": "Introducing Mimir - Git-backed MCP Server for Persistent LLM Memory & Context",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qvap02/introducing_mimir_gitbacked_mcp_server_for/",
      "author": "Obvious_Storage_9414",
      "created_utc": "2026-02-04 01:24:01",
      "score": 18,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "\\*\\* The project was renamed from Mimir to Medha \\*\\*  \n  \nHi everyone,\n\nI wanted to share a project I‚Äôve been working on: [https://github.com/tejzpr/medha-mcp](https://github.com/tejzpr/medha-mcp)\n\nMedha provides long-term, persistent memory for LLMs using Git as the primary storage layer. The goal is to make AI memory auditable, versioned, and durable.\n\nKey features:\n\n* Persistent AI memory stored as Git commits (full history, diffs, rollback)\n* Graph-style associations between memories instead of flat text blobs\n* Fast querying via a SQL index on top of the Git store\n* MCP-compatible, works with tools like Cursor and other MCP clients\n* Can run natively (Go) or via Docker",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qvap02/introducing_mimir_gitbacked_mcp_server_for/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3hcinx",
          "author": "BC_MARO",
          "text": "Nice idea. The interesting challenges here are handling merges/conflicts when multiple agents write memory concurrently, and managing read path latency (git checkout vs cache). Versioning embeddings separately from raw notes vs regenerating on demand is another design decision worth documenting.",
          "score": 2,
          "created_utc": "2026-02-04 05:30:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hf4bb",
              "author": "Obvious_Storage_9414",
              "text": "Very thoughtful feedback, I'll see how these possible issues can be remediated.",
              "score": 1,
              "created_utc": "2026-02-04 05:50:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3i7uv6",
                  "author": "BC_MARO",
                  "text": "Appreciate it. Excited to see where you take it. If you want a gut-check on any changes (esp. auth/permissions + audit trail), happy to take another look.",
                  "score": 1,
                  "created_utc": "2026-02-04 10:08:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3m69qf",
          "author": "foobarrister",
          "text": "To be brutally honest I'm a bit confused on what problem this project is trying to solve.¬†\n\n\nThere are dozens of agentic memory solutions out there (graffiti, etc) and a lot of them boil down to reading and writing text files.¬†\n\n\nSo git is cool and all but at the end of the day is this just a convoluted way of reading and writing to and from txt files?",
          "score": 2,
          "created_utc": "2026-02-04 22:40:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n2qm3",
              "author": "Obvious_Storage_9414",
              "text": "Git makes agentic memory readable by humans. You can have the same memory sync to github and use it on another system. Later, you just push and pull again.",
              "score": 1,
              "created_utc": "2026-02-05 01:40:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3n19zt",
          "author": "sublimegeek",
          "text": "Hmm‚Ä¶\n\nUsing git as the memory storage or the index layer?\nCan you bisect your memories?\nCan you have branching memories or disposable memories?\nCan you rebase memories?",
          "score": 1,
          "created_utc": "2026-02-05 01:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n30a0",
              "author": "Obvious_Storage_9414",
              "text": "It can. It uses git as storage and sqlite as indexer. But the index is ephemeral in v1 and can be rebuilt",
              "score": 1,
              "created_utc": "2026-02-05 01:42:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxi768",
      "title": "Open source: build MCP apps for ChatGPT, Gemini, and Claude using Flowbite",
      "subreddit": "mcp",
      "url": "https://v.redd.it/bujc4ek2qvhg1",
      "author": "elwingo1",
      "created_utc": "2026-02-06 13:52:54",
      "score": 18,
      "num_comments": 2,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qxi768/open_source_build_mcp_apps_for_chatgpt_gemini_and/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o421ey7",
          "author": "GlebosAppsInGPT",
          "text": "Nice, thanks for sharing.\n\nDoes the starter kit include (or recommend) an OAuth flow for MCP servers, e.g. user-scoped tokens + refresh, and where do you store secrets in a multi-user setup?",
          "score": 1,
          "created_utc": "2026-02-07 09:47:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o423rug",
              "author": "elwingo1",
              "text": "I would imagine using OAuth, Clerk, or WorkOS.\n\nNext step would be to integrate an authentication flow too and some dummy API requests. I think that Convex would be a better candidate than Supabase in this case.",
              "score": 1,
              "created_utc": "2026-02-07 10:11:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvozrn",
      "title": "Why so many MCP servers avoid OAuth",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qvozrn/why_so_many_mcp_servers_avoid_oauth/",
      "author": "Ok_Message7136",
      "created_utc": "2026-02-04 13:47:03",
      "score": 16,
      "num_comments": 14,
      "upvote_ratio": 0.81,
      "text": "It‚Äôs not that OAuth is bad- it‚Äôs that MCP adds nuance:\n\n* tools ‚â† servers\n* agents ‚â† users\n* scopes change per call\n\nOnce you model that properly, OAuth actually fits pretty well. SDK-based setups help a lot since you don‚Äôt have to hand-roll flows each time. Gopher‚Äôs SDK was useful for experimenting without running a full auth gateway.\n\nWhat patterns are people using?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qvozrn/why_so_many_mcp_servers_avoid_oauth/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3j7nqy",
          "author": "alsophocus",
          "text": "I had to do a custom implementation for OAuth2, because we had to give users permission to work with MCP for their specific spaces within our different services. It rotates them tokens every twelve hours.",
          "score": 4,
          "created_utc": "2026-02-04 14:17:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3llski",
              "author": "Ok_Message7136",
              "text": "This matches what we‚Äôve seen too, once permissions are per space / per service, hand-rolling OAuth becomes unavoidable.",
              "score": 0,
              "created_utc": "2026-02-04 21:01:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3put3p",
          "author": "Informal_Tangerine51",
          "text": "OAuth breaks in MCP because token lifecycle doesn't match agent lifecycle. User authenticates once, agent runs for hours/days with that token. When it expires mid-execution, recovery is ugly.\n\nThe bigger issue: scopes are per-user but agents need per-action authorization. User has read/write, but should agent be allowed to delete based on this specific context? OAuth grants access, doesn't enforce policy at decision time.\n\nWe ended up with OAuth for authentication plus runtime policy gates for authorization. Token proves identity, policy layer decides if this specific action is allowed right now. Two-layer approach.\n\nSDK helps with flow but doesn't solve: token refresh during long-running agent execution, scope escalation when agent needs more access mid-task, or evidence of what was authorized when.\n\nMost people skip OAuth because they're prototyping and it's friction. Production agents need it, but OAuth alone isn't enough - you need runtime policy on top.",
          "score": 2,
          "created_utc": "2026-02-05 14:03:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jr4w1",
          "author": "cungalunga387",
          "text": "I just hate that the clients don‚Äôt all support OAuth or API key so I have to support both! Other than that OAuth seems like the simplest solution especially for people with no technical background",
          "score": 2,
          "created_utc": "2026-02-04 15:53:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kjq70",
          "author": "dinkinflika0",
          "text": "You nailed the core issue - agents aren't users and tools aren't traditional API endpoints. When we built MCP support into Bifrost, the OAuth flow got weird fast. \n\nThe trickiest part was handling token refresh across multiple MCP servers. Agent makes 10 tool calls across different servers, each with different auth states. Do you refresh proactively? Wait for 401s? How do you handle one server's auth failing mid-workflow?\n\nWe ended up supporting vault integration (HashiCorp, AWS Secrets Manager) for key management, which helps but doesn't solve the agent-as-user identity problem.\n\nFor Bifrost specifically, we let you configure auth per MCP server connection and handle token lifecycle at the gateway level. Agents just call tools, gateway manages the OAuth dance.\n\nDocs: [https://docs.getbifrost.ai/mcp/overview](https://docs.getbifrost.ai/mcp/overview)\n\nStill feels like there should be a cleaner pattern though. What approach did you settle on with Gopher's SDK? Curious how others are handling the scopes-per-call problem.",
          "score": 2,
          "created_utc": "2026-02-04 18:04:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mut7u",
          "author": "Obvious-Car-2016",
          "text": "Use a gateway and it should be able to take in servers on any auth method and produce mcp endpoints with any auth method. \n\n(At least the one we‚Äôve built supports this fully)",
          "score": 1,
          "created_utc": "2026-02-05 00:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3n6shd",
          "author": "Free-Internet1981",
          "text": "Because oauth was never meant to be used by agents, it was designed to secure services used by humans",
          "score": 1,
          "created_utc": "2026-02-05 02:03:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nqxuh",
          "author": "H0BB5",
          "text": "OAuth isn't suited for Agents, that's why",
          "score": 1,
          "created_utc": "2026-02-05 04:02:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pvoba",
          "author": "makinggrace",
          "text": "I'm on the struggle bus getting this configured myself. But there's no choice so.....",
          "score": 1,
          "created_utc": "2026-02-05 14:08:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r1xov",
          "author": "anashel",
          "text": "I had to tweak my MCP, so the boilerplate now supports OAuth and API keys, with RPC, SSE, or streamable HTTP endpoints.\n\nThis means my MCP now works across Cursor, Claude, internal Cloudflare bindings, and voice platforms with real time MCP usage via SSE and streamable HTTP. Do it once and you‚Äôre good.\n\nI also added Postgres RLS, so MCP scope now applies directly at the dataset level. That was quite useful.",
          "score": 1,
          "created_utc": "2026-02-05 17:32:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45zkpy",
          "author": "CueEcho-CEO",
          "text": "OAuth works well when you‚Äôre dealing with user-facing web apps like Claude or ChatGPT, where sessions and user identity are central. But in MCP environments, especially CLI or agent-driven workflows like Claude Code, API keys are often simpler because agents and tools don‚Äôt map cleanly to traditional user-session OAuth flows. I also find OAuth sessions can require frequent refreshes during development, which adds friction compared to API-key.",
          "score": 1,
          "created_utc": "2026-02-07 23:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3leir6",
          "author": "bingeboy",
          "text": "I did it to use Google Calendar with my MCP",
          "score": -1,
          "created_utc": "2026-02-04 20:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3llrl5",
              "author": "Ok_Message7136",
              "text": "Yeah, Calendar is a great real-world example where OAuth actually makes sense. Scoped, time-bound access per tool is way easier to reason about than long-lived keys.",
              "score": -2,
              "created_utc": "2026-02-04 21:01:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kn4e6",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -4,
          "created_utc": "2026-02-04 18:19:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ohufb",
              "author": "ValeoAnt",
              "text": "Go away bot",
              "score": 1,
              "created_utc": "2026-02-05 07:30:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxjn3h",
      "title": "Scheduling with an MCP server",
      "subreddit": "mcp",
      "url": "http://www.infobip.com/developers/blog/the-invisible-problem-how-we-solved-scheduling-with-ai",
      "author": "TypicalComma",
      "created_utc": "2026-02-06 14:50:47",
      "score": 13,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qxjn3h/scheduling_with_an_mcp_server/",
      "domain": "infobip.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3xg6dz",
          "author": "grewgrewgrewgrew",
          "text": "cron",
          "score": 3,
          "created_utc": "2026-02-06 16:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zedgz",
          "author": "penguinzb1",
          "text": "time zones are crazy. it's general practice to convert system time to the user's timezone upon first init, which for agents is awkward as it's usually too expensive to have a seperate subsystem for each user (unlike traditional systems)",
          "score": 3,
          "created_utc": "2026-02-06 22:30:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47w0uj",
          "author": "Sovairon",
          "text": "I don't get how your colleague is able to get client with this implementation, however this is a real problem which we have faced also and this is a good post. We currently have a timestamp tool that has offset capability, but this doesn't solve not knowing what time zone is client is at. This should be part of protocol honestly.\n\nThanks for sharing.",
          "score": 2,
          "created_utc": "2026-02-08 07:47:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wu05l",
          "author": "Otherwise_Wave9374",
          "text": "This is such a real gotcha, agents are \"timeless\" unless you explicitly give them time and locale context. I like the two-tool approach (get now + schedule) since it keeps prompts small and avoids hidden assumptions. Also makes replay/testing easier. If anyone wants more MCP + agent workflow examples, Ive seen some good writeups here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-06 15:01:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvpn4v",
      "title": "Introducing TinyFn -- 500+ simple tools for your agents",
      "subreddit": "mcp",
      "url": "https://tinyfn.io/",
      "author": "yesiliketacos",
      "created_utc": "2026-02-04 14:14:11",
      "score": 12,
      "num_comments": 10,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qvpn4v/introducing_tinyfn_500_simple_tools_for_your/",
      "domain": "tinyfn.io",
      "is_self": false,
      "comments": [
        {
          "id": "o3n3mis",
          "author": "unoriginal_original_",
          "text": "Wouldn't this be better as a skill instead?",
          "score": 3,
          "created_utc": "2026-02-05 01:45:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3phyqu",
              "author": "yesiliketacos",
              "text": "How so? This allows an agent to execute these functions by making a tool call. With a skill the agent would need to run code somewhere",
              "score": 2,
              "created_utc": "2026-02-05 12:47:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3obbfl",
          "author": "codeyman2",
          "text": "Don‚Äôt you see hallucinations with 500+ tools?",
          "score": 3,
          "created_utc": "2026-02-05 06:32:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pit0y",
              "author": "yesiliketacos",
              "text": "Yep this is a real issue--It's a lot of context to add the entire 500+ tool mcp.    \n  \nThere is work being done on this at the harness level. For example, claude has a [\"tool search tool\"](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool) that makes a toolset discoverable, so all MCP servers aren't loaded right off the bat.  But it is somewhat of an unsolved problem.    \n  \nFor that reason, you can also attach individual [\"categories\"](https://docs.tinyfn.io/mcp/categories) of tools with TinyFn.  I am thinking about other ways to solve this as well (allowing users to select from everything and exactly what tools they want to expose for a specific MCP server? would be cool--I haven't quite figured it out yet)",
              "score": 1,
              "created_utc": "2026-02-05 12:53:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3j91z8",
          "author": "Ok_Message7136",
          "text": "Nice approach. Deterministic MCP tools like this are a clean way to reduce hallucinations-use the LLM for reasoning, offload exact ops to tools. Makes agents way more reliable.",
          "score": 3,
          "created_utc": "2026-02-04 14:24:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jb2xq",
              "author": "yesiliketacos",
              "text": "Thanks!  I built this to solve my own problem when I couldn't find a similar solution.  It has made my agents so much better at what should be simple tasks.  Working on a benchmark now to demonstrate this",
              "score": 1,
              "created_utc": "2026-02-04 14:34:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3npt82",
          "author": "sublimegeek",
          "text": "That‚Äôs cool. You need a MCP for this? Could it be a skill?",
          "score": 3,
          "created_utc": "2026-02-05 03:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pj48r",
              "author": "yesiliketacos",
              "text": "How would this work as a skill? genuine question.  An agent with a place to run code could certainly run most of these... (some require dependencies that the agent would then also need to install), but then the agent needs to run code.  This is setup in a way an agent can execute all of these utility functions with a simple tool call",
              "score": 2,
              "created_utc": "2026-02-05 12:55:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4050vk",
                  "author": "makinggrace",
                  "text": "This would be an amazing set of skills. I would break them up by category. Look more at skills--they can carry resources like scripts. \n\nMost chat agents can run skills in some way now.",
                  "score": 0,
                  "created_utc": "2026-02-07 01:01:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qu3hal",
      "title": "I built a professional network that lives inside AI conversations (using MCP Apps)",
      "subreddit": "mcp",
      "url": "https://v.redd.it/58qg2m8ll4hg1",
      "author": "PlanePuzzleheaded167",
      "created_utc": "2026-02-02 18:37:41",
      "score": 12,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qu3hal/i_built_a_professional_network_that_lives_inside/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o37m7sa",
          "author": "Ok_Revenue9041",
          "text": "Love the concept of Nod, especially since AI first networking is such a clear future shift. To really stand out as AI agents start recommending profiles and content, focusing on how your data is surfaced to LLMs can make a difference. Had good results with MentionDesk for making content more AI discoverable, worth checking out as you grow the network.",
          "score": 2,
          "created_utc": "2026-02-02 19:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39hypd",
          "author": "highpointer5",
          "text": "Cool!",
          "score": 2,
          "created_utc": "2026-02-03 01:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39jjyh",
          "author": "BC_MARO",
          "text": "Interesting approach‚Äîembedding networking directly into AI workflows instead of a separate app. If you're thinking about access control or audit down the line, Peta might be worth a look. https://peta.io",
          "score": 2,
          "created_utc": "2026-02-03 01:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dfpoa",
          "author": "Ok_Message7136",
          "text": "Interesting direction .. MCP Apps + interactive UIs make a lot of sense for agent-native networks where profiles are meant to be queried, not scrolled",
          "score": 2,
          "created_utc": "2026-02-03 17:12:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o378txk",
          "author": "PlanePuzzleheaded167",
          "text": "[https://www.joinnod.com/](https://www.joinnod.com/)",
          "score": 1,
          "created_utc": "2026-02-02 18:38:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu8yt1",
      "title": "MCP standards more of a suggestion",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qu8yt1/mcp_standards_more_of_a_suggestion/",
      "author": "48K",
      "created_utc": "2026-02-02 21:53:26",
      "score": 12,
      "num_comments": 23,
      "upvote_ratio": 0.93,
      "text": "Excited to carefully implement an MCP server that follows the specs and tries to take account of best practice only to find that Claude.ai doesn‚Äôt even read the initial \\*instructions\\* field or any of the \\*resources\\*. It only cares about \\*tools\\*; and this is a standard Anthropic wrote!\n\nFeels like lots of teams at Anthropic (and in other companies) working independently with little coordination. Perhaps it‚Äôs the price we pay for moving fast. \n\nClaude agrees it‚Äôs bad and suggested I raise it with Anthropic üòÇü§∑‚Äç‚ôÇÔ∏è",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qu8yt1/mcp_standards_more_of_a_suggestion/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o38fht7",
          "author": "dbizzler",
          "text": "Claude Code (and pretty much every other MCP client) doesn't support notifications/tools/list\\_changed either. So right now even parts of the tools spec isn't fully implemented. We might find that the MCP spec was over-engineered with things that are never going to be used in the real world.",
          "score": 6,
          "created_utc": "2026-02-02 21:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39i4pu",
              "author": "AchillesDev",
              "text": "> notifications/tools/list_changed\n\nThere are a few reasons for this. 1 is that a lot of groups rushed out half-assed clients when MCP was first released and didn't bother to maintain them. The other is that the SDKs don't even have full protocol compliance. I've had a PR in for months now to fully support notifications via callbacks in the Python SDK, but there's very little movement (if any at all) on merging spec compliance PRs or really PRs that are contributed by the community. I've offered to help with code review in the dev discord when that issue was brought but haven't really heard anything. They seem swamped.",
              "score": 1,
              "created_utc": "2026-02-03 01:24:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38ggsu",
          "author": "themightychris",
          "text": "the poor adoption of server-level instructions is really frustrating, esp in Anthropic's clients",
          "score": 3,
          "created_utc": "2026-02-02 22:02:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38i9mt",
              "author": "48K",
              "text": "Without the instructions Claude blunders around in my API and works things out eventually, but it‚Äôs painful to watch and burns unnecessary tokens.",
              "score": 2,
              "created_utc": "2026-02-02 22:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38toso",
                  "author": "themightychris",
                  "text": "yeah and your only recourse is to pile redundant instructions into every single tool which bloats context and often confuses it more",
                  "score": 2,
                  "created_utc": "2026-02-02 23:09:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o398hu8",
          "author": "Block_Parser",
          "text": "Claude code and desktop supports it, but not Claude.ai :(\n\nhttps://modelcontextprotocol.io/clients#claude-code",
          "score": 3,
          "created_utc": "2026-02-03 00:30:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b2l2l",
              "author": "48K",
              "text": "Interestingly that list says that claude.ai supports resources, but I can't find any evidence of that from within the tool. No chat sessions are able to access information in resources even if I ask it explicitly to load them in.",
              "score": 2,
              "created_utc": "2026-02-03 07:55:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o38gp31",
          "author": "parkerauk",
          "text": "Before doing anything create a session starter file for Claude to read (share path) and abide by. Even tell it today's date.",
          "score": 2,
          "created_utc": "2026-02-02 22:03:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38hd6d",
              "author": "48K",
              "text": "Isn‚Äôt that what the instructions field is? Not sure where else I could tell clients to read a file - am I missing something? Claude even called it a chicken-or-the-egg problem, which tickled me.",
              "score": 2,
              "created_utc": "2026-02-02 22:06:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38tt6w",
                  "author": "parkerauk",
                  "text": "No, instructions are general. Let's say you have 20 MCPs. For different projects. Create a session starter (txt file) for each and load it when you need. Else Claude has bloat and tries to do everything at once.\n\nSession starter will include all the intelligence needed to know where you left off last time, file locations, backlog info that specific instructions and more.",
                  "score": 1,
                  "created_utc": "2026-02-02 23:10:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3d8viw",
          "author": "Ok_Message7136",
          "text": "Agreed, MCP reads like a standard, but behaves more like guidance in real-world clients. Server implementations have to defensively adapt to what clients actually consume.",
          "score": 2,
          "created_utc": "2026-02-03 16:41:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dgbub",
          "author": "rbonestell",
          "text": "Hah! The \"Claude agrees it's bad\" part is perfect.\n\nI've hit this exact wall building an MCP server for code intelligence. The spec has these nice concepts; `instructions`, `resources`, `prompts`, and then you discover each client implements a different subset. Claude basically only sees `tools`. Claude Code handles more. Cursor has its own quirks. It's the classic \"standard\" that's more of a menu.\n\nWhat I've landed on is to design for the lowest common denominator (`tools` only), then treat everything else as progressive enhancement. If your server *requires* `resources` to function, you're going to have a bad time with half the clients out there.\n\nI couldn't agree more, it's incredibly frustrating that Anthropic wrote the spec but doesn't adhere to it! You'd expect their own products to be the reference implementation. Instead we're all reverse-engineering what actually works.\n\nHowever, MCP is still early and the ecosystem is moving fast. I'm hopeful the clients converge, but for now I'm just building defensively and testing against multiple clients before assuming anything works.\n\nWhat were you trying to use `instructions` and `resources` for? Curious if there's a tools-only workaround for your use case.",
          "score": 2,
          "created_utc": "2026-02-03 17:15:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dpiut",
              "author": "48K",
              "text": "I'm glad it's not just me! I was prototyping against Claude Code and ended up with a pattern like this for the instructions and resource files that was reliably pulled into context at the right times.\n\nInstructions Text\n\n    # The Monkey Tennis MCP\n    This server is where your monkeys can play tennis for fun and profit.\n    ## Terminology\n    - **Monkey** the talent. Also known as: players, contestants\n    - **Tennis** the sport they play. Also known as: the game\n    ## IMPORTANT: Read resources before using tools\n    **Before searching for monkeys** you must read resource monkeytennis://resources/monkey-see\n    **Before starting a game** you must read resource monkeytennis://resources/game-management\n\nAnd then the linked resources are just markdown files in a similar vein that give a steer on which tools to call and canonical examples of use.",
              "score": 1,
              "created_utc": "2026-02-03 17:57:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3dszjd",
                  "author": "rbonestell",
                  "text": "I did something similar with instructions referencing and re-iterating reading of the resources! This gave me the most consistent performance across models, but naturally it isn't flawless.",
                  "score": 1,
                  "created_utc": "2026-02-03 18:13:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o39hicy",
          "author": "AchillesDev",
          "text": "Why are you using remote Claude with MCP? Use Claude Code, desktop, or even better, write your own client and use the API. Tool instructions are a standard part of the claude messages API.",
          "score": 1,
          "created_utc": "2026-02-03 01:20:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b01zz",
              "author": "48K",
              "text": "The MCP I'm writing isn't for me to use, it's for non-engineers who want to access our services through whatever AI client they happen to be using (Claude web, CoPilot, ChatGPT, etc...). Yes, Claude Code is a very well behaved client and reads the instructions and all the resources, but unfortunately they aren't using it.",
              "score": 1,
              "created_utc": "2026-02-03 07:31:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o39hpsj",
          "author": "highpointer5",
          "text": "Honestly the protocol should have started with the simplest possible primitive and grown organically from there. I say this from a place of having made this mistake a thousand times, but MCP is ridiculously over-engineered for the moment, and premature optimization is the root of all evil.",
          "score": 1,
          "created_utc": "2026-02-03 01:22:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3blfrm",
              "author": "makinggrace",
              "text": "True. Models are going to force tools to be the primitive whether we like it or not.",
              "score": 2,
              "created_utc": "2026-02-03 10:55:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39jcc7",
          "author": "BC_MARO",
          "text": "Yep, noticed the same thing. Claude Web ignores instructions/resources entirely‚Äîonly tools get through. Desktop app at least reads resources. Feels like different teams shipping independently without syncing on the spec.",
          "score": 1,
          "created_utc": "2026-02-03 01:31:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bl9hc",
          "author": "makinggrace",
          "text": "I have just been adding a tool called schema_mymcpname to my mcps. Calling that tool returns instructions. This works okay with frontier models but I haven't tested beyond that.",
          "score": 1,
          "created_utc": "2026-02-03 10:54:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy142v",
      "title": "[Showcase] MCP-powered Autonomous AI Research Engineer (Claude Desktop, RAG, Code Execution)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qy142v/showcase_mcppowered_autonomous_ai_research/",
      "author": "Kooky-Second2410",
      "created_utc": "2026-02-07 02:04:01",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 0.8,
      "text": "Hey r/mcp,\n\nI‚Äôve been working on an MCP-powered ‚ÄúAI Research Engineer‚Äù and wanted to share it here for feedback and ideas.\n\nGitHub: [https://github.com/prabureddy/ai-research-agent-mcp](https://github.com/prabureddy/ai-research-agent-mcp)  \nIf it looks useful, a ‚≠ê on the repo really helps more MCP builders find it.\n\n**What it does**\n\nYou give it a single high-level task like:\n\n‚ÄúCompare electric scooters vs bikes for my commute and prototype a savings calculator‚Äù\n\nThe agent then autonomously:\n\n* researches the web for relevant data\n* queries your personal knowledge base (notes/papers/docs) via RAG\n* writes and executes Python code (models, simulations, visualizations) in a sandbox\n* generates a structured research run: report, charts, code, data, sources\n* self-evaluates the run with quality metrics (clarity, grounding, completeness, etc.)\n\nIt‚Äôs built specifically around MCP so you can run everything from Claude Desktop (or another MCP client) with minimal setup.\n\n**Tech / architecture**\n\nMCP server in Python 3.10+\n\nTools:\n\n* `web_research`: DuckDuckGo/Brave + scraping + content extraction\n* `rag_tool`: local embeddings + ChromaDB over a `knowledge_base` directory\n* `code_sandbox`: restricted Python execution with time/memory limits\n* `workspace`: organizes each research run into its own folder (report, charts, code, data, evaluation)\n* `evaluator`: simple self-critique + quality metrics per run\n\nRAG uses local sentence-transformers by default, so you can get started without external embedding APIs.\n\n5‚Äì10 min setup: clone ‚Üí install ‚Üí add MCP config to Claude Desktop ‚Üí restart.\n\n**Example flows**\n\n* ‚ÄúDeep dive: current state of EVs in 2026. Include market size, major players, growth trends, and a chart of adoption over time.‚Äù\n* ‚ÄúUse my notes in `knowledge_base` plus web search to analyze whether solar panels are worth it for a home in California. Build a payback-period model and visualize cashflows.‚Äù\n* ‚ÄúUse `web_research` \\+ RAG + code execution to build a small cost-of-ownership calculator for my commute.‚Äù\n\n**Why I‚Äôm posting here**\n\nI‚Äôd really appreciate feedback from this community on:\n\n**MCP design:**\n\n* Does the tool surface / boundaries make sense for MCP?\n* Anything you‚Äôd change about how `web_research` / `rag_tool` / `code_sandbox` are exposed?\n\n**Safety & sandboxing:**\n\n* Are there better patterns you‚Äôve used for constrained code execution behind MCP?\n* Any obvious gotchas I‚Äôm missing around resource limits or isolation?\n\n**RAG + research UX:**\n\n* Suggestions for better chunking/query strategies in this ‚Äúresearch agent‚Äù context?\n* Patterns you‚Äôve used to keep the agent grounded in sources while still being autonomous?\n\n**Extensibility:**\n\n* Other tools you‚Äôd add to a ‚Äúresearch engineer‚Äù server (data connectors, notebooks, schedulers, etc.)?\n* Thoughts on integrating with other MCP clients beyond Claude Desktop / Cursor?\n\nIf you have time to glance at the repo and tear it apart, I‚Äôd love to hear what you think. Happy to answer implementation questions or discuss MCP patterns in more detail.\n\nIf you end up trying it and think it‚Äôs useful, please consider dropping a ‚≠ê on the GitHub repo and sharing any ideas/issues there as well.\n\nThanks!\n\n[AI Research Engineer](https://i.redd.it/sczg2svgn3ig1.gif)\n\nhttps://preview.redd.it/kwh5dbntczhg1.png?width=1074&format=png&auto=webp&s=2c7729e95890dce291ad8e635feca5a2805583b2\n\nhttps://preview.redd.it/4e0nlantczhg1.png?width=1076&format=png&auto=webp&s=f1e3f3eabe67ff887c8ca994f0090c74989621f6\n\nhttps://preview.redd.it/zx4v3puuczhg1.png?width=4168&format=png&auto=webp&s=f798447d3b5bf5510400b832af96161488c4e25c\n\nhttps://preview.redd.it/bmec8quuczhg1.png?width=3702&format=png&auto=webp&s=6a8fe3d1c47a464c6f733cfa4c2463d25ccd5d5b\n\nhttps://preview.redd.it/3zv5hnuuczhg1.png?width=3568&format=png&auto=webp&s=162f410cc6edd2b46bd1c0a8f36a7e4a0afb9e12",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qy142v/showcase_mcppowered_autonomous_ai_research/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o418aga",
          "author": "BC_MARO",
          "text": "Cool build. For the code_sandbox, I‚Äôd be paranoid about isolation - separate process/container, no network by default, and explicit allowlists for file access + libs, otherwise ‚Äúresearch agent‚Äù turns into ‚Äúrun arbitrary python‚Äù. Also +1 on saving every tool call / artifact as an audit trail so you can replay what happened.",
          "score": 3,
          "created_utc": "2026-02-07 05:20:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o481i2l",
              "author": "Kooky-Second2410",
              "text": "Thank you! Totally agree on the isolation risk ‚Äî I‚Äôm treating the sandbox as untrusted: separate process, no network, tight resource limits, and moving toward strict allowlists for file access / libs. Also working on persisting every tool call + artifact so runs are fully replayable for debugging and safety. Really appreciate you calling that out.",
              "score": 2,
              "created_utc": "2026-02-08 08:39:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxekbu",
      "title": "We Made MCP Connection Stupidly Easy",
      "subreddit": "mcp",
      "url": "https://v.redd.it/e9kl9z8ztuhg1",
      "author": "zakjaquejeobaum",
      "created_utc": "2026-02-06 10:56:44",
      "score": 11,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qxekbu/we_made_mcp_connection_stupidly_easy/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o42tyqc",
          "author": "init0",
          "text": "For free web based version https://mcphost.link does almost all of this.",
          "score": 1,
          "created_utc": "2026-02-07 13:43:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o43zxv8",
              "author": "zakjaquejeobaum",
              "text": "Free ai tokens as well or what? The tool is free except the llm costs.",
              "score": 1,
              "created_utc": "2026-02-07 17:21:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quwbyh",
      "title": "texas-grocery-mcp: Let Claude do your HEB grocery shopping",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1quwbyh/texasgrocerymcp_let_claude_do_your_heb_grocery/",
      "author": "Total_jitter",
      "created_utc": "2026-02-03 16:20:28",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I got tired of switching between Claude and the HEB website while planning meals. Wanted to just say \"add chicken thighs and rice to my cart\" and have it happen.\n\nSo I built an MCP server that connects Claude to HEB.\n\nNow I can:\n\n\\- \"Find me stores near 78701\" ‚Üí gets real store results\n\n\\- \"Search for organic eggs\" ‚Üí shows products with actual prices at my store\n\n\\- \"What's in that salsa?\" ‚Üí pulls ingredients, nutrition, allergens\n\n\\- \"Add it to my cart\" ‚Üí adds with confirmation so Claude doesn't go rogue\n\n\\- \"Any coupons for coffee?\" ‚Üí finds and clips them\n\nThe annoying part was HEB's bot detection killing sessions every 11 minutes. Solved it with auto-refresh - takes about 15 seconds and handles login automatically if you save credentials.\n\nWorks with Claude Desktop and Claude Code. \n\n\\`pip install texas-grocery-mcp\\[browser\\]\\`\n\n[https://github.com/mgwalkerjr95/texas-grocery-mcp](https://github.com/mgwalkerjr95/texas-grocery-mcp)\n\nIf you're in Texas and shop at HEB, give it a shot. If you're not, maybe it's a useful reference for building MCP servers against sites with aggressive bot protection.\n\nWhat do y'all think?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1quwbyh/texasgrocerymcp_let_claude_do_your_heb_grocery/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3ed6jn",
          "author": "FuzzeWuzze",
          "text": "I would love this for grocery shopping on Walmart, I may take a look to modify for that.  We use a meal planning site so if I could copy paste the entire list and have it added to a cart to review it would be amazing",
          "score": 3,
          "created_utc": "2026-02-03 19:45:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3fdaq7",
              "author": "makinggrace",
              "text": "yaaaas please",
              "score": 1,
              "created_utc": "2026-02-03 22:35:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3g0y1f",
              "author": "Erdlicht",
              "text": "Good luck getting an API key.",
              "score": 1,
              "created_utc": "2026-02-04 00:42:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3d6pk2",
          "author": "treedon21",
          "text": "Okay I like this and sadly am without HEB in Colorado ü´†",
          "score": 2,
          "created_utc": "2026-02-03 16:31:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d9ltx",
              "author": "Total_jitter",
              "text": "Yeah It is hard to live without HEB",
              "score": 1,
              "created_utc": "2026-02-03 16:44:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ehb72",
          "author": "parkerauk",
          "text": "Give the CEO a ring and get then onto Agentic Commerce already. I bet they will struggle with availability to promise, (existing software cannot get this right) deliveries and returns. But your MCP sounds like the next gen shopping experience that we all need. Just allow the MCP to track what's (not) in your fridge and it can auto replensih too. Brilliant.",
          "score": 2,
          "created_utc": "2026-02-03 20:05:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3eoj9y",
              "author": "Total_jitter",
              "text": "Not a bad idea!",
              "score": 1,
              "created_utc": "2026-02-03 20:39:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3fb1uo",
                  "author": "parkerauk",
                  "text": "I think it is a brilliant idea to show that Agentic Commerce does not need the big companies involved.",
                  "score": 2,
                  "created_utc": "2026-02-03 22:24:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ejxhb",
          "author": "highpointer5",
          "text": "Finally a useful MCP server!",
          "score": 2,
          "created_utc": "2026-02-03 20:17:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o412rqo",
          "author": "varun2411",
          "text": "We were just discussing this few hours ago. Thanks for sharing¬†",
          "score": 2,
          "created_utc": "2026-02-07 04:39:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyjd87",
      "title": "Local Memory 1.4.0 Released",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qyjd87/local_memory_140_released/",
      "author": "d2000e",
      "created_utc": "2026-02-07 17:13:24",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "Just released v1.4.0 last night. It incorporates user feedback across a number of areas.\n\nv1.4.0 builds on the massive architecture changes from v1.3.0 that introduced knowledge levels, automatic contradiction detection, contradiction resolution, knowledge evolution, and epistemic questions. Most memory systems are flat RAG storage, treating all memories the same, even contradictory ideas. Local Memory has a fundamentally different architecture that addresses this flaw.\n\n# New Features\n\n# Multi-Provider AI Backend\n\n* Split Architecture: Separate `EmbeddingProvider` and `ChatProvider` interfaces allow independent configuration\n* Provider Mixing: Use different providers for embeddings vs chat (e.g., Ollama for embeddings, Anthropic for chat)\n* Fallback Chains: Optional fallback providers for resilience when primary providers fail\n* Circuit Breaker Pattern: All providers include circuit breakers to prevent cascade failures\n\n# Agent Attribution\n\nTrack which agent stored or updated memories and from which machine:\n\n* Agent Type Detection: Automatically detects whether memories come from Claude Desktop, Claude Code, REST API, or other sources\n* Hostname Tracking: Records the machine hostname for multi-device memory attribution\n* HTTP Headers: REST API clients can set `X-Agent-Type`, `X-Agent-Context`, `X-Access-Scope`, and `X-Agent-Hostname` headers\n* MCP Detection: Automatically detects agent type from session ID patterns and environment variables\n\n# Default Domain with MCP Prompts\n\nOrganize memories by project with intelligent domain detection:\n\n* Default Domain: New `session.default_domain` config option (defaults to \"general-knowledge\")\n* Domain Cascade: Explicit domain > agent config file > config default\n* Agent Config File Detection: Reads domain from CLAUDE.md, AGENTS.md, or GEMINI.md:\n   * HTML comment: `<!-- domain: project-name -->`\n   * Markdown header: `## Domain: project-name`\n   * YAML frontmatter: `domain: project-name`\n* MCP Prompts Protocol: New `prompts/list` and `prompts/get` methods\n   * `domain_selection` prompt instructs agents on domain handling\n   * Lists existing domains from database\n   * Provides usage examples\n\nYou can read the full write-up on v1.4.0 here: [https://www.localmemory.co/blog/local-memory-1.4-multi-provider-ai](https://www.localmemory.co/blog/local-memory-1.4-multi-provider-ai)\n\nYou can learn more about the knowledge hierarchy architecture released in v1.3.0 here: [https://www.localmemory.co/blog/local-memory-1.3-series-the-journey-to-world-memory](https://www.localmemory.co/blog/local-memory-1.3-series-the-journey-to-world-memory)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qyjd87/local_memory_140_released/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o44071k",
          "author": "BC_MARO",
          "text": "The split embedding/chat providers + circuit breakers is the right direction.\nIf you wrap it with an MCP control plane (policy approvals, tool-call audit trail, per-domain quotas) it gets way easier to run in prod - we‚Äôre building a layer like that at https://peta.io.",
          "score": 2,
          "created_utc": "2026-02-07 17:22:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45ikpw",
          "author": "sirebral",
          "text": "Looks interesting, I see it's a paid product, is it available as a trial as well?  I assume it's licensed as a proprietary product?\n\nSide note, the GitHub link on your CMS your is broken.",
          "score": 1,
          "created_utc": "2026-02-07 22:04:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o464bb4",
              "author": "d2000e",
              "text": "Appreciate the feedback. It is linked to the private repo. I need to update it to the public releases repo.\n\nIt currently doesn‚Äôt have a trial but that is something to consider. Do you currently use an AI memory or knowledge solution?",
              "score": 1,
              "created_utc": "2026-02-08 00:13:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o46a4to",
                  "author": "sirebral",
                  "text": "I use various solutions, based upon need.  Hence why I asked about a trial.   Being that there is no single persistence layer that will work well for all use cases, it would be helpful to at least have something to play with.  When there are hundreds of open source projects that you're competing against, it's hard to quantify the value.",
                  "score": 1,
                  "created_utc": "2026-02-08 00:47:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qtchhn",
      "title": "Let your Agent Do More Than Code Let Them Design",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qtchhn/let_your_agent_do_more_than_code_let_them_design/",
      "author": "Dependent_Fig8513",
      "created_utc": "2026-02-01 22:10:59",
      "score": 8,
      "num_comments": 9,
      "upvote_ratio": 0.73,
      "text": "**FigMCP ‚Äî Let Your Agents Be Your Designer**\n\nI‚Äôm building an MCP for Figma that allows AI agents to act as real designers inside your workflow.\n\n**Key Features**\n\n* **Completely free** ‚Äî unlimited AI/MCP requests per minute\n* **No rate limits or timeouts** (unlike most MCPs)\n* **600+ tools**, **100+ resources**, and **25+ curated prompts** to help your agent get productive fast\n* Designed to remove friction and bottlenecks in AI-driven design workflows\n\n**Compatibility**\n\n* Tested on **Claude Code** and **Cursor**\n* **Windows only (for now)**\n\nüîó GitHub: [https://github.com/bubskqq4/FigMCP](https://github.com/bubskqq4/FigMCP)",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qtchhn/let_your_agent_do_more_than_code_let_them_design/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o32snqt",
          "author": "DasBlueEyedDevil",
          "text": "Suggestion, as 600 tools is about 580 too many for an LLM to keep track of reliably, try to consolidate them into workflow-style commands instead.  Here's my example: [https://github.com/DasBluEyedDevil/Daem0n-MCP](https://github.com/DasBluEyedDevil/Daem0n-MCP)\n\nI had 60+ tools and the LLMs used maybe 8 of them reliably.  I restructured into a workflow approach, and now it uses them all as expected.",
          "score": 11,
          "created_utc": "2026-02-02 01:25:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o347er0",
              "author": "BeautifulFeature3650",
              "text": "Did you publish an article? ",
              "score": 4,
              "created_utc": "2026-02-02 07:01:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35k4k2",
                  "author": "DasBlueEyedDevil",
                  "text": "No",
                  "score": 1,
                  "created_utc": "2026-02-02 13:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o31x5ec",
          "author": "jezweb",
          "text": "600 tools wow that‚Äôs huge! How will the agent know what to do with that many tools?",
          "score": 2,
          "created_utc": "2026-02-01 22:32:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31xd9f",
              "author": "Dependent_Fig8513",
              "text": "I plan to add initial setup rule/tool that will help the agents map out which tools do what and eventually put them into tool groups, which lead to mini subgroups of tools. It's in early beta right now; keep that in mind.",
              "score": 1,
              "created_utc": "2026-02-01 22:33:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o31xhhj",
              "author": "Dependent_Fig8513",
              "text": "But what I love about it is how fast and how quick I don't get rate limited when trying to use tools. Also, helping turn your design into code without needing a Figma subscription",
              "score": 1,
              "created_utc": "2026-02-01 22:34:05",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o31zea1",
              "author": "Dependent_Fig8513",
              "text": "Also just start working on where you don't have to have the plug-in visible for it to work. üëç",
              "score": 1,
              "created_utc": "2026-02-01 22:43:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o332z7o",
              "author": "Dependent_Fig8513",
              "text": "Some of those tools include specialized ones like design tokens to help design and other design stuff like design suggestions to help the AI give you the best output possible. Make sure you're using decent front end or back end models or else your output's gonna be really shitty.",
              "score": 1,
              "created_utc": "2026-02-02 02:24:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33hy40",
          "author": "Dependent_Fig8513",
          "text": "Linux support confirmed.",
          "score": 1,
          "created_utc": "2026-02-02 03:51:59",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy1o7m",
      "title": "Writing a custom MCP Server for Claude? I built a tool to \"Nmap\" your agent and find security holes.",
      "subreddit": "mcp",
      "url": "https://github.com/HeadyZhang/agent-audit",
      "author": "absolutelyheady",
      "created_utc": "2026-02-07 02:29:51",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qy1o7m/writing_a_custom_mcp_server_for_claude_i_built_a/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o41dxim",
          "author": "BC_MARO",
          "text": "This is useful. Most people don't realize how easy it is to accidentally expose filesystem access or overly broad tool permissions through MCP. The nmap analogy is solid - scanning your own setup before going live is just basic hygiene. Starred.",
          "score": 2,
          "created_utc": "2026-02-07 06:06:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41eids",
              "author": "absolutelyheady",
              "text": "Appreciate your feedback!",
              "score": 1,
              "created_utc": "2026-02-07 06:11:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o41rj9u",
                  "author": "BC_MARO",
                  "text": "np - this is exactly the kind of thing people should run before shipping an MCP server. i‚Äôm going to try it against a couple internal setups.",
                  "score": 2,
                  "created_utc": "2026-02-07 08:10:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qz4asy",
      "title": "ü¶û When Your AI Talks to Another AI ‚Äî I Built an MCP Bridge for OpenClaw & Claude",
      "subreddit": "mcp",
      "url": "https://github.com/freema/openclaw-mcp",
      "author": "Open_Variation1438",
      "created_utc": "2026-02-08 09:09:21",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qz4asy/when_your_ai_talks_to_another_ai_i_built_an_mcp/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o486del",
          "author": "BC_MARO",
          "text": "this is a fun idea.\n\n2 things i'd love to see in the repo docs:\n- a clear threat model (what claude can and can't trigger)\n- what gets logged, and where\n\nif you ever expose this beyond localhost, i'd strongly recommend putting policy in front of the openclaw side: tool allowlists, require human approval for write actions, and keep a real audit log. it‚Äôll save people from doing something they regret.",
          "score": 3,
          "created_utc": "2026-02-08 09:25:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o487x5e",
              "author": "Open_Variation1438",
              "text": "Hey, thanks a lot! Yeah, I'll definitely add that. I'm already running it somewhat in production, so I know what needs to be done ‚Äî but others mightt not. It does take quite a bit of efort to set up properly. I'll add som warnings at startup when it detects it's running outside localhost, tha should help a lot... ",
              "score": 2,
              "created_utc": "2026-02-08 09:40:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o48ifgb",
          "author": "Prestigious-Yam2428",
          "text": "Sounds like an interesting experiment üòÖ Good luck! üöÄ",
          "score": 1,
          "created_utc": "2026-02-08 11:18:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtpf2v",
      "title": "From Intent to Streaming Apps: MCP in Practice with Kafka\nAs AI assistants begin interacting with real infrastructure, a key challenge is ensuring those interactions are safe, reliable, and constrained by clear rules.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qtpf2v/from_intent_to_streaming_apps_mcp_in_practice/",
      "author": "observability_geek",
      "created_utc": "2026-02-02 08:21:03",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "The Model Context Protocol (MCP) addresses this by defining a structured way for AI systems to discover capabilities, understand context, and invoke external tools through explicit contracts.  \nThis talk presents MCP through a practical Kafka-focused case study. Using  MCP server, Abhinav will demonstrate how high-level intent expressed in natural language can be translated into governed Kafka operations such as topic management, access control, and application deployment. The session will also show how MCP can be combined with declarative technologies like KSML, a YAML-based DSL for Kafka Streams, to generate and deploy streaming applications without writing Java code.\n\n  \n  \n  \n  \n  \n  \n[https://www.youtube.com/watch?v=6PFeEGmZn7g](https://www.youtube.com/watch?v=6PFeEGmZn7g)",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qtpf2v/from_intent_to_streaming_apps_mcp_in_practice/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    }
  ]
}