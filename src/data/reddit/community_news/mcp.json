{
  "metadata": {
    "last_updated": "2026-01-21 02:39:59",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 76,
    "file_size_bytes": 93505
  },
  "items": [
    {
      "id": "1qiecmt",
      "title": "Introducing FastMCP 3.0",
      "subreddit": "mcp",
      "url": "https://www.jlowin.dev/blog/fastmcp-3",
      "author": "jlowin123",
      "created_utc": "2026-01-20 21:36:02",
      "score": 64,
      "num_comments": 16,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qiecmt/introducing_fastmcp_30/",
      "domain": "jlowin.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o0qzgpd",
          "author": "Context_Core",
          "text": "Love fastmcp, thanks for your work.",
          "score": 7,
          "created_utc": "2026-01-20 22:18:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r043x",
              "author": "jlowin123",
              "text": "ðŸ™",
              "score": 3,
              "created_utc": "2026-01-20 22:21:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r5bsq",
          "author": "rednix",
          "text": "Awesome! ðŸš€",
          "score": 2,
          "created_utc": "2026-01-20 22:48:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r5er5",
              "author": "jlowin123",
              "text": "ðŸš€",
              "score": 1,
              "created_utc": "2026-01-20 22:48:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rkx00",
          "author": "Bitflight",
          "text": "Youâ€™re absolutely correct! Itâ€™s been a game changer!\n\nAre but the start of the phrases I will use in my new MCP server called, human-to-ai-email-response-mcp.\n\nNext time youâ€™re sending a manual email using your own language embedded with your personality you can call upon my MCP to ensure it sounds like the rest of your team members.",
          "score": 2,
          "created_utc": "2026-01-21 00:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rm5wp",
          "author": "dhana36",
          "text": "Thank you for your work. The SuperMCP depends on FastMCP. Hereâ€™s the link: https://github.com/dhanababum/supermcp. Does fastmcp3.0 support dynamic MCP servers now?",
          "score": 2,
          "created_utc": "2026-01-21 00:18:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0run06",
              "author": "jlowin123",
              "text": "I think so -- providers can return new components on every call, so you can build some really dynamic stuff. For example the new filesystem provider can reload files to automatically pick up changes. If there's something you need that isn't easy let us know!",
              "score": 1,
              "created_utc": "2026-01-21 01:05:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ruv0i",
                  "author": "dhana36",
                  "text": "awesome , thank you! I will take a look, do you have any snippets?",
                  "score": 2,
                  "created_utc": "2026-01-21 01:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0rtg9a",
          "author": "styyle",
          "text": "Very excited for this. I saw the docs earlier on the redis session store and I almost risked it all to install the beta in prod. Thanks for all the work you do!",
          "score": 2,
          "created_utc": "2026-01-21 00:58:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rtv34",
              "author": "jlowin123",
              "text": "I'm unreasonably excited by that feature. Thanks for trying it!",
              "score": 1,
              "created_utc": "2026-01-21 01:01:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rdz5d",
          "author": "gopietz",
          "text": "Has MCP already solved the context overflow problem? Like letting the agent decide when to know more about a tool?\n\nIt seems like that was the biggest limitation and why devs are switching over to skills instead.",
          "score": 2,
          "created_utc": "2026-01-20 23:34:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rpw86",
              "author": "circamidnight",
              "text": "IIMO it's not mcp or skills. It's MCP and skills.\n\nWhat you describe is an agent context management problem. Not something inherent in the protocol. Skills are meant to solve this but they can do so while also utilizing mcp tools. The tools they refer can be used to filter and mcp server's entire toolset.\n\nAlso skills + cli tools are mostly feasible for coding agents that have something like bash access whereas skills + mcp is available for more locked down agents.",
              "score": 2,
              "created_utc": "2026-01-21 00:39:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rugdy",
              "author": "jlowin123",
              "text": "Personally I think devs switched to skills because it's just more convenient to manage local context via files than through MCP. At least, that's why I did! But I'm not sure they're mutually exclusive, just appropriate for different jobs.\n\nTo your larger question, I think the protocol has many of the hooks this requires but there could be more (e.g. short and long descriptions), and ultimately many MCP client implementations are just frankly not great. So where we could dream up ways to progressively disclose details, it comes down to whether clients adopt it. \n\nIn 3.0 we're experimenting with skills-over-MCP which has been pretty fun.",
              "score": 1,
              "created_utc": "2026-01-21 01:04:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qf9day",
      "title": "MCP Tool Lazy Loading and TypeScript Sandbox with Workspace Output, for Claude Code. Context savings: ~97% reduction (48k to 1.1k tokens) for multi-tool workflows.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "author": "milkphetamine",
      "created_utc": "2026-01-17 09:57:25",
      "score": 24,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "https://github.com/elb-pr/claudikins-tool-executor\n\nAnthropic's API users getÂ advanced tool use - Claude writes code, executes N tools in a sandbox, returns once. Claude Code users get serial execution and lazy loading. Tool Executor brings the API pattern to Claude Code..\n\nClaude will:\n1. Use `search_tools` to find relevant tools\n2. Use `get_tool_schema` to load the exact parameters\n3. Use `execute_code` to run the generation in one shot\n \nMCP tools often return large payloads. Web scrapes, code analysis, generated content - all eating context.\n\nTool Executor intercepts responses over 200 characters and saves them to workspace files. Your code receives a reference:\n\nUnlike native MCP, Tool Executor injects guidance every session. Claude knows:\n- What MCP categories exist (ai-models, code-nav, web, knowledge, reasoning, ui)\n- When to use MCP vs basic tools\n- The exact search â†’ schema â†’ execute workflow\n\nNo guessing. No forgetting.\n\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04206p",
          "author": "punkpeye",
          "text": "/u/milkphetamine this looks like theoretically something that we could provide as part our [MCP gateway](https://glama.ai/mcp) service?\n\nMy thinking is... people deploy/add their MCP servers, then we provide a single MCP that has access to all other MCPs, that utilizes your project to actually resolve and execute tools.",
          "score": 1,
          "created_utc": "2026-01-17 14:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o047iz9",
              "author": "milkphetamine",
              "text": "Yeah that could definitely work no doubt. Feel free to message me",
              "score": 1,
              "created_utc": "2026-01-17 15:15:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o047vg7",
                  "author": "punkpeye",
                  "text": "Thanks. I will dig deeper later this afternoon and message you if any questions. A version of this has been on a TODO for a long time",
                  "score": 1,
                  "created_utc": "2026-01-17 15:17:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o030fjr",
          "author": "promethe42",
          "text": "Very good idea.\n\nTo make it even more efficient, you could mimic the skill progressive disclosure and add a list of 100 char name + description of the tools in the system prompt.\n\nIt will massively reduce the number of calls to \\`search\\_tools\\` to find relevant tools.",
          "score": 1,
          "created_utc": "2026-01-17 10:18:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o030q3k",
              "author": "milkphetamine",
              "text": "Interesting! The hooks and schema seem to do okay for chaining but there's definitely a few moments of okay that's a lot of calls but the tokens are minimal so, it's just me getting too lost in it at that point aha!\n\nOne issue I need to address though, output saves to the mcp workspace. Need to adjust it to save to project workspace. Had a few hiccups thereðŸ˜…",
              "score": 2,
              "created_utc": "2026-01-17 10:21:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03o5b2",
              "author": "Hofi2010",
              "text": "That was part of the problem why Anthropic proposed code use for MCP tools because the list of all tools and description are â€žeatingâ€œ the context window.",
              "score": 2,
              "created_utc": "2026-01-17 13:29:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04xxbn",
                  "author": "promethe42",
                  "text": "The schemas are eating a lot of tokens. But tool names and descriptions are just like skill names and descriptions.Â ",
                  "score": 3,
                  "created_utc": "2026-01-17 17:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o033c8m",
          "author": "Stock-Protection-453",
          "text": "Great effort, I also walked a similar path with Natural Context Provider [https://github.com/portel-dev/ncp](https://github.com/portel-dev/ncp)",
          "score": 0,
          "created_utc": "2026-01-17 10:45:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfop2k",
      "title": "n8n MCP Server â€“ Enables Large Language Models to interact with n8n automation instances through the Model Context Protocol. Supports workflow management, execution, credentials handling, and security audits through natural language commands.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-17 21:00:06",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qfop2k/n8n_mcp_server_enables_large_language_models_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o067jp8",
          "author": "modelcontextprotocol",
          "text": "This server has 33 tools:\n\n- [activate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/activate-workflow) â€“ Enable an n8n automation workflow to run by providing its ID. Use this tool to activate workflows for automated task execution.\n- [create-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-credential) â€“ Create authentication credentials for n8n automation workflows. Specify credential type and required data to enable nodes to connect to external services and APIs.\n- [create-project](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-project) â€“ Create new projects in n8n automation platform for organizing workflows and resources, requiring Enterprise license with project management enabled.\n- [create-tag](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-tag) â€“ Add tags to organize workflows in your n8n automation instance. Use this tool to create new tags for categorizing and managing automation processes.\n- [create-users](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-users) â€“ Add users to your n8n automation instance by specifying email addresses and roles to manage access and permissions.\n- [create-variable](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-variable) â€“ Create variables in n8n to store and share data across workflows. Requires n8n Enterprise license with variable management enabled.\n- [create-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-workflow) â€“ Build automation workflows in n8n by defining nodes and connections to automate business processes and integrate applications.\n- [deactivate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/deactivate-workflow) â€“ Stop a workflow from running by deactivating it using its ID. This prevents automated processes from executing until reactivated.\n- [delete-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-credential) â€“ Remove stored credentials by ID from n8n automation instances. Securely delete authentication data you own to manage access controls.\n- [delete-execution](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-execution) â€“ Remove a specific workflow execution by ID to manage automation history and maintain system performance.",
          "score": 3,
          "created_utc": "2026-01-17 21:00:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o06up5r",
          "author": "astrokat79",
          "text": "Any chance it has clouldflared auth for n8n instances behind token or email auth?",
          "score": 1,
          "created_utc": "2026-01-17 22:56:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcwp09",
      "title": "I built the MCP inspector I always wanted â€“ no login, full spec support, state in URL",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/inspector",
      "author": "punkpeye",
      "created_utc": "2026-01-14 19:24:18",
      "score": 18,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcwp09/i_built_the_mcp_inspector_i_always_wanted_no/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qh36t7",
      "title": "Anyone actually used an MCP gateway in production (or even internally)? Looking for real feedback.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qh36t7/anyone_actually_used_an_mcp_gateway_in_production/",
      "author": "Dazzling_Basil_4739",
      "created_utc": "2026-01-19 12:44:32",
      "score": 17,
      "num_comments": 11,
      "upvote_ratio": 0.9,
      "text": "Iâ€™m trying to learn from people who have actually used or are currently using an MCP gateway, not from docs or blog posts, but from **real experience.**\n\nIf youâ€™ve worked with one (in-house, enterprise, startup, side project anything), Iâ€™d really love to hear:\n\n* What problem pushed you to add an MCP gateway in the first place?\n* Did it actually improve control, security, or observability for agent/tool usage?\n* What surprised you after deploying it (good or bad)?\n* Whatâ€™s still missing or harder than it should be?\n\n**Iâ€™m not looking for vendor pitches** or theoretical takes just **honest experiences** from people whoâ€™ve been in the trenches.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qh36t7/anyone_actually_used_an_mcp_gateway_in_production/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o0h1e3d",
          "author": "babydecocx",
          "text": "* What problem pushed you to add an MCP gateway in the first place?\n\nInternal enterprise AI Platform, for a large enterprise in brazil, where non-technical (business users) people create assistants and workflows to automate part of their work. 3k users / day. They don't know (and don't want to learn) what tool should be called for each node/prompt/workflow. They want to write down a generic prompt and magically see their workflow being built and working. For instance, they want to build executive presentations using internal data from their CRM, ERP and commerce platform with a single generic prompt. We needed governance and control, and a smart tool selection.\n\n* Did it actually improve control, security, or observability for agent/tool usage?\n\nYes. Access/permission management + observabilitiy (latency, error rate, log)\n\n* What surprised you after deploying it (good or bad)?\n\nGood: Cost control, how much each user/team/group/tag is spending  \nBad: UX.  We tried one single UI  for both devs and non-devs, but now we are investing in a more general business-oriented UX, with a \"developer mode\" that add some features and details, non-technical people are simply not interested in the technical details.\n\n* Whatâ€™s still missing or harder than it should be?\n\n\\-Not so much about the MCP gateway, but for the internal AI Platform:   \n\\- Easier way to create Whatsapp workflows  \n\\- Auto-RAG when big/multiple files are added, and they are larger than the context window",
          "score": 10,
          "created_utc": "2026-01-19 13:33:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hh358",
              "author": "kdn86",
              "text": "What gateway did you go with?",
              "score": 3,
              "created_utc": "2026-01-19 14:58:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ip94c",
                  "author": "babydecocx",
                  "text": "We created our own: [decocms.com/mesh](http://decocms.com/mesh)",
                  "score": 3,
                  "created_utc": "2026-01-19 18:19:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0gvz2k",
          "author": "SpareIntroduction721",
          "text": "Following. As my solution of concept right now is using TAGS to route.",
          "score": 1,
          "created_utc": "2026-01-19 12:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0i7061",
              "author": "Dazzling_Basil_4739",
              "text": "What do you mean? Can you please elaborate?",
              "score": 1,
              "created_utc": "2026-01-19 16:57:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ikn71",
                  "author": "SpareIntroduction721",
                  "text": "Have the agent add a tag to each query, then based on said tag it gets routed to designated MCP.",
                  "score": 2,
                  "created_utc": "2026-01-19 17:58:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0iahb7",
                  "author": "Dazzling_Basil_4739",
                  "text": "Would love to know more about how it works for you",
                  "score": 1,
                  "created_utc": "2026-01-19 17:12:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jrvr9",
          "author": "Historical-Lie9697",
          "text": "Docker mcp gateway is open sourced and works very well",
          "score": 1,
          "created_utc": "2026-01-19 21:16:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ke2un",
          "author": "Nshx-",
          "text": "[https://www.reddit.com/r/mcp/comments/1q8fmmg/what\\_is\\_the\\_best\\_mcp\\_gateway/](https://www.reddit.com/r/mcp/comments/1q8fmmg/what_is_the_best_mcp_gateway/)",
          "score": 1,
          "created_utc": "2026-01-19 23:07:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ljsnd",
          "author": "drfritz2",
          "text": "https://mcphubx.com/\n\nwhy? too many MCP (lots of tokens and too many turn on and off)\n\nI dont know\n\nI can use any MCP and not worring about loosing tokens to them \n\nMost of the times if you need a specific MCP or tool you have to ask for it",
          "score": 1,
          "created_utc": "2026-01-20 02:53:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lsnls",
          "author": "jainnys",
          "text": "I am working on document parsing. so I am using the [https://github.com/microsoft/markitdown](https://github.com/microsoft/markitdown) \n\nit gives me a basic MCP server which is extendible. I have added these additional services and also add security (token and oauth) to the server \n\n\\- email send via ses\n\n\\- qbo online api's\n\n\\- llm base\n\n* What problem pushed you to add an MCP gateway in the first place? >> all these are stateless services and now I can - use them as micro services. claude code is able to use it better/ - also plan to use it to run agentic email, and accounting tasks\n* Did it actually improve control, security, or observability for agent/tool usage? - I now have centralized observability of various calls\n* What surprised you after deploying it (good or bad)? still experimenting\n* Whatâ€™s still missing or harder than it should be? - pretty easy so far.",
          "score": 1,
          "created_utc": "2026-01-20 03:43:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcjnc3",
      "title": "Built a YouTube MCP Server. Routed the scraping through an API so I don't have to manage proxies",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "author": "nikhonit",
      "created_utc": "2026-01-14 10:13:29",
      "score": 16,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "been building a few agent workflows that need to ingest youtube content (summarizers, sentiment analysis, etc).\n\nthe biggest bottleneck wasn't the agent logicâ€”it was the actual data fetching. local scrapers like youtube-dl or ytdlp are great but they get throttled/blocked constantly if you run them at any real volume, and managing a rotating proxy pool for a side project is overkill.\n\nso i built a dedicated YouTube MCP Server that offloads the heavy lifting.\n\nwhat it does:\n\n* exposes tools to fetch full transcripts (with timestamps). \n* grabs video metadata (views, likes, description). \n* handles the \"rate limit\" dance externally.\n\n\n\nthe stack: instead of raw-dogging the youtube html, i routed the requests through [TranscriptAPI](https://transcriptapi.com/r/reddit/mcp)  \n  \nit basically acts as the specialized layer to ensure the data actually comes back clean without the \"verify you are human\" capchas blocking the agent.\n\nallows you to plug youtube data into cursor, windsurf, or any custom mcp client without worrying about your ip getting flagged.\n\nif youâ€™re building video-aware agents, this should save you some headache.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzk1o7u",
          "author": "arnaldodelisio",
          "text": "I think too much headache for something very simple. Going to share my youtube transcription mcp when I am back to the laptop.",
          "score": 3,
          "created_utc": "2026-01-14 15:49:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzipztq",
          "author": "actual-time-traveler",
          "text": "Can you post a repo?",
          "score": 2,
          "created_utc": "2026-01-14 11:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzixjbq",
          "author": "0xKoller",
          "text": "this sounds cool!\n\ncan you share a video of a use case?",
          "score": 2,
          "created_utc": "2026-01-14 12:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkosus",
          "author": "First-Line9299",
          "text": "Try this one. They have youtube endpoints for searching YT videos and scraping subtitles https://docs.anysite.io/mcp-server/unlimited-plan",
          "score": 1,
          "created_utc": "2026-01-14 17:34:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrqvsh",
          "author": "Live_Vermicelli4307",
          "text": "Would love to see it working in action!",
          "score": 1,
          "created_utc": "2026-01-15 18:11:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcyrzk",
      "title": "Follow-up from yesterday's Code Mode post - MCP setup guide",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "author": "dinkinflika0",
      "created_utc": "2026-01-14 20:41:28",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 0.79,
      "text": "Got a few questions in my dms after yesterday's post about Code Mode, so writing up the actual MCP setup process since the folks asked how to get started.\n\n**Basic connection is pretty simple:**\n\nConnect to any MCP server via STDIO, HTTP, or SSE. For local tools like filesystem stuff, STDIO works fine. Remote services use HTTP.\n\n`{ \"mcp\": { \"client_configs\": [{ \"name\": \"filesystem\", \"connection_type\": \"stdio\", \"stdio_config\": { \"command\": \"npx\", \"args\": [\"-y\", \"@anthropic/mcp-filesystem\"] } }] } }`\n\n**Important security detail:**\n\nTool calls from the LLM are just suggestions by default. Nothing actually executes unless you explicitly call the execution endpoint. This caught me off guard initially but it's the right design - prevents accidental API calls or data modifications.\n\nIf you want autonomous execution, enable Agent Mode and specify which tools can auto-execute via `tools_to_auto_execute`.\n\n**Code Mode setup (from yesterday):**\n\nSet `is_code_mode_client: true` on your MCP clients. LLM writes TypeScript to orchestrate tools instead of the standard iterative approach. Cuts tokens significantly when you have multiple servers.\n\n**Tool filtering:**\n\nControl which tools are available per request or per virtual key. Useful for different environments or team permissions.\n\nBifrost can also act as an MCP server - expose your tools to Claude Desktop or other MCP clients through the gateway URL.\n\nSetup docs: [https://docs.getbifrost.ai/features/mcp](https://docs.getbifrost.ai/features/mcp)  \nGithub: [https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)\n\nAnyone run into issues setting this up?",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qghfy6",
      "title": "GitHub - eznix86/mcp-gateway: Too much tools in context. Use a gateway",
      "subreddit": "mcp",
      "url": "https://github.com/eznix86/mcp-gateway",
      "author": "Eznix86",
      "created_utc": "2026-01-18 19:13:07",
      "score": 14,
      "num_comments": 10,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qghfy6/github_eznix86mcpgateway_too_much_tools_in/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0e9kn9",
          "author": "milkphetamine",
          "text": "https://github.com/elb-pr/claudikins-tool-executor, I have this on git too, anthropic released lazy loading like a day after which was annoying but they didn't give us the sandbox lmao. I've got it up and running now it's super efficient",
          "score": 1,
          "created_utc": "2026-01-19 01:18:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ekqzo",
              "author": "Eznix86",
              "text": "Amazing work :)",
              "score": 1,
              "created_utc": "2026-01-19 02:21:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cdy0k",
          "author": "baykarmehmet",
          "text": "Thatâ€™s awesome! I just left the first star! Iâ€™m building something similar using Swift. Itâ€™s based on Metamcp and also includes a tool search feature.",
          "score": 1,
          "created_utc": "2026-01-18 19:33:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ce7r4",
              "author": "Eznix86",
              "text": "Thank you very much!",
              "score": 1,
              "created_utc": "2026-01-18 19:34:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0clwn7",
          "author": "Difficult_Hand_509",
          "text": "Are you planning to add docker support to this. This look awesome. I also use MetaMCP",
          "score": 0,
          "created_utc": "2026-01-18 20:12:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cndoh",
              "author": "Eznix86",
              "text": "I can dockerize it. Is http transport good for you?",
              "score": 1,
              "created_utc": "2026-01-18 20:19:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0gatag",
              "author": "Eznix86",
              "text": "docker added. :3000/mcp to read from http transport.",
              "score": 1,
              "created_utc": "2026-01-19 10:04:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0jtd8m",
                  "author": "Difficult_Hand_509",
                  "text": "Thank you Iâ€™ll try it out tonight.",
                  "score": 1,
                  "created_utc": "2026-01-19 21:23:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qerxaw",
      "title": "Following MCP & RAG questions: A self-hosted agent with LightRAG and MCP",
      "subreddit": "mcp",
      "url": "https://i.redd.it/7v0km08kyrdg1.png",
      "author": "motakuk",
      "created_utc": "2026-01-16 20:55:19",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qerxaw/following_mcp_rag_questions_a_selfhosted_agent/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0hb8t9",
          "author": "anywhereblue",
          "text": "I use something similar.  I have a context MCP server on the web, I can write artifacts from any agent to the MCP and read from any other.  It allows my agents to share long form context quickly and easily.  I can also review, markup and edit the context files on the server with a web ui edit ui. \n\nI can brainstorm on Claude have it write it out, have cursor read it st scaffold it out, then have Claude:code read it in as part of a code review. I have a few people testing with me.  It also allows sharing with other people agents.",
          "score": 1,
          "created_utc": "2026-01-19 14:28:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf3nm3",
      "title": "mcp-graph-engine - network algorithms and visualisation for your agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "author": "utilitydelta",
      "created_utc": "2026-01-17 04:34:47",
      "score": 13,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "MCP that your agents can use to build network graphs:\n\n[https://github.com/utilitydelta/mcp-graph-engine](https://github.com/utilitydelta/mcp-graph-engine)\n\nBuild a network from your problem domain and use graph algorithms like page rank and cycle detection to analyze it.\n\nYou can also visualize graphs being built in your browser, updated in real time from your agent.\n\nTool set is light and docs are small. They won't pollute your context window. Tell me what you think!\n\n[LOTR character network](https://preview.redd.it/3vokfkl38udg1.png?width=1213&format=png&auto=webp&s=d4a374431dffb5f2bb86903dd328ed05fc5869c2)\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o03tbv4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-17 14:00:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04dei2",
              "author": "Crafty_Disk_7026",
              "text": "Your better off using ast",
              "score": 1,
              "created_utc": "2026-01-17 15:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05xqy6",
          "author": "H0BB5",
          "text": "Nice! Does it have madge support?",
          "score": 1,
          "created_utc": "2026-01-17 20:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o063w3b",
              "author": "utilitydelta",
              "text": "Don't you find these kinds of tools really noisy? It's doesn't build any level of abstraction - just funcA() -> funcB(). Personally I don't find it valuable, it becomes chaos in anything but toy code bases. You gotta use the LLM at what it's good at - checking data flow, mapping out your design invariants,visualising service dependencies, all the really important stuff!",
              "score": 1,
              "created_utc": "2026-01-17 20:41:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0af6rs",
          "author": "joanmiro",
          "text": "I was looking smith like this",
          "score": 1,
          "created_utc": "2026-01-18 13:46:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh1tlt",
      "title": "Platforms for easy MCP deployment?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qh1tlt/platforms_for_easy_mcp_deployment/",
      "author": "benzene404",
      "created_utc": "2026-01-19 11:33:37",
      "score": 13,
      "num_comments": 15,
      "upvote_ratio": 0.81,
      "text": "I work for an IT company that's currently helping a client investigate how to connect various internal systems to AI tools like ChatGPT.\n\nWe use N8N for automations, but the MCP node doesn't support OAuth authentication (the only form supported by ChatGPT), meaning it's not suitable for our use-case at the moment.\n\nWith that in mind, we're looking for another platform that would allow us to easily develop and host MCP servers, preferably with no/low code (like N8N) for timesaving, although that's not a dealbreaker.\n\nAny recommendations for platforms would be much appreciated, particularly those suited to a business context.",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qh1tlt/platforms_for_easy_mcp_deployment/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o0gnzy8",
          "author": "jezweb",
          "text": "Iâ€™ve used fastmcp cloud and cloudflare quite well with Claude code over the past 18mths to make mcp servers and custom nodes to use with n8n. Claude is really quite capable with mcp now compared to its v3.x versions",
          "score": 6,
          "created_utc": "2026-01-19 12:00:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gr11m",
              "author": "benzene404",
              "text": "FastMCP cloud seems to be pretty much what we're looking for, thanks for the recommendation",
              "score": 3,
              "created_utc": "2026-01-19 12:24:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0gl90w",
          "author": "InfraScaler",
          "text": "I would suggest you take the plunge and code your own MCP servers using LLMs. I have an internal MCP quickly prototyped by an LLM on Python/FastAPI with OAuth support. Works like a charm!",
          "score": 1,
          "created_utc": "2026-01-19 11:38:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gr51a",
              "author": "benzene404",
              "text": "I think we'll probably use FastMCP as someone else suggested. We have engineers so coding isn't too much of an issue as that seems to be the best way to get the job done.",
              "score": 2,
              "created_utc": "2026-01-19 12:25:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0gyp52",
          "author": "babydecocx",
          "text": "take a look at our platform: [decocms.com/mesh](http://decocms.com/mesh)",
          "score": 1,
          "created_utc": "2026-01-19 13:17:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hvz9g",
          "author": "Just_Vugg_PolyMCP",
          "text": "I made PolyMCP https://github.com/poly-mcp/Polymcp which allows not only to create MCP servers that are http, stdio or even wasm but also to manage agents with Ollama, Openai, Claude and more. If I can be useful and help you I would be happy. I am looking for practical projects where I can use PolyMCP.",
          "score": 1,
          "created_utc": "2026-01-19 16:07:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ir6ig",
          "author": "diucameo",
          "text": "We have used mcpo to plug a mcp into chat gpt custom gpt action. It works pretty well. Basically converting the sctions into a openapi specification. Not sure about oauth",
          "score": 1,
          "created_utc": "2026-01-19 18:27:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m2zxc",
          "author": "beckywsss",
          "text": "[MCP Manager](https://mcpmanager.ai/) (where I work) would work for your use case. Free 2 week trial lets you check it out.",
          "score": 1,
          "created_utc": "2026-01-20 04:45:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ma84r",
          "author": "matt8p",
          "text": "Lots of good services like Alpic and FastMCP I recommend, but hosting a MCP server isnâ€™t any different than hosting any other server. \n\nIâ€™d recommend learning how to host on Cloudflare, AWS, or even Vercel.",
          "score": 1,
          "created_utc": "2026-01-20 05:35:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nj62g",
              "author": "Numerous-Rest-1153",
              "text": "You can also deploy MCP servers in Supabase\nhttps://supabase.com/docs/guides/getting-started/byo-mcp",
              "score": 1,
              "created_utc": "2026-01-20 12:06:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r2jmx",
          "author": "pbalIII",
          "text": "The n8n OAuth gap is a known pain point... there's been a feature request open since mid-2025 and it's still not resolved.\n\nFor business contexts with OAuth requirements, MCP gateways are probably the cleanest path. They sit in front of your servers and handle auth/audit/access control at the gateway level rather than per-server. Composio, Lunar.dev, and a few others have one-click deployment with OAuth baked in.\n\nFastMCP Cloud (mentioned in the comments) works well for simpler setups. If you're willing to write a bit of Python, FastAPI + an auth library gets you OAuth support pretty quickly... but that trades off against your low-code preference.",
          "score": 1,
          "created_utc": "2026-01-20 22:33:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gov4f",
          "author": "0xKoller",
          "text": "[Alpic](https://alpic.ai/) is an excelente choice! I would suggest trying them out",
          "score": 1,
          "created_utc": "2026-01-19 12:07:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0grbe4",
              "author": "benzene404",
              "text": "Thanks for the recommendation, are there any major benefits of Alpic over FastMCP cloud? As there seems to be quite a difference in pricing",
              "score": 2,
              "created_utc": "2026-01-19 12:26:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0gs2eo",
                  "author": "Flat_Living5435",
                  "text": "It's the same pricing for both, generous Free tier and similar features for the Pro plans. [Alpic.ai](http://Alpic.ai) is more targetted towards companies with high load and usage in the Business plan",
                  "score": -1,
                  "created_utc": "2026-01-19 12:32:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0gq6a9",
          "author": "marsel040",
          "text": "Sounds like [Yavio](https://yavio.io/) could fit perfect. You can define the MCP tool logic in a no code node builder and host it with one click. Its also possibile to design UI components for chatgpt apps.",
          "score": 0,
          "created_utc": "2026-01-19 12:18:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpioc",
      "title": "Is anybody using MCPs with ChatGPT?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "author": "raghav-mcpjungle",
      "created_utc": "2026-01-15 17:17:33",
      "score": 10,
      "num_comments": 15,
      "upvote_ratio": 0.92,
      "text": "I use ChatGPT mostly for all the non-coding stuff (brainstorms, travel, life, etc)\n\nI recently started connecting my MCPs to chatgpt via my gateway, mainly out of curiosity about the possibilities.\n\nI quickly realized that I mostly use MCPs for tech work only.\n\nOf course, chatgpt has \"Apps\", which are essentially mcp servers only. I just don't use most of them.\n\n  \nSo is anyone a \"power user\" of mcps on gpt?\n\nAnd are you using it for personal stuff or at your org?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzwdl0g",
          "author": "pswithlove",
          "text": "Connected it to clickhouse and team is loving it. No more asks to build UIs or reports or whatever. They simply chat with the data and Itâ€™s good enough.",
          "score": 2,
          "created_utc": "2026-01-16 10:49:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrvnl4",
          "author": "0xKoller",
          "text": "Just for really dumb stuff like calendar to plan a trip, after that nothing",
          "score": 1,
          "created_utc": "2026-01-15 18:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp2k4",
              "author": "raghav-mcpjungle",
              "text": "hmm fair, I can see some of my work becomign smoother if I integrate my calendar into gpt",
              "score": 1,
              "created_utc": "2026-01-16 07:07:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwp6az",
                  "author": "0xKoller",
                  "text": "Yeah but is not the big thing for now... untill stuff like emails unlocks maybe not that usefull\n\nyou can check with the Google Drive app, that one is kind of usefull if you want to avoid the hustle to copy/paste files",
                  "score": 1,
                  "created_utc": "2026-01-16 12:19:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzshpgk",
          "author": "naseemalnaji-mcpcat",
          "text": "Based on our findings at MCPcat <5% of agents are coming through ChatGPT ðŸ˜¬",
          "score": 1,
          "created_utc": "2026-01-15 20:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp4ez",
              "author": "raghav-mcpjungle",
              "text": "wow. where's the majority coming from I wonder",
              "score": 1,
              "created_utc": "2026-01-16 07:08:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsziii",
          "author": "digit1024",
          "text": "I use my MCp with multiple providers - sometimes with openAI, yet I find open AI overpriced ( via API ) comparing to alternatives.  \nI have to admit that I don't like the company...  this is basically a company that turned into profit company from foundation at the very moment they discovered something profitable . Shame on them.  \nAnd I hate Idea of entre humanity sending money to 4 big AI companies sooooo...",
          "score": 1,
          "created_utc": "2026-01-15 21:35:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt7fww",
              "author": "xFloaty",
              "text": "Theyâ€™re asking about using MCPs on the ChatGPT website via custom connectors",
              "score": 2,
              "created_utc": "2026-01-15 22:12:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztir9g",
                  "author": "digit1024",
                  "text": "Ohhh..... Someone is using websites? :) thanks for pointing it ðŸ˜‰\nThen the answer is no",
                  "score": 1,
                  "created_utc": "2026-01-15 23:09:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt76e2",
          "author": "tinyhousefever",
          "text": "I use MCP at ChatGTP to create, edit, publish content and  iterate SEO of my WordPress website.",
          "score": 1,
          "created_utc": "2026-01-15 22:11:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvpcyl",
              "author": "raghav-mcpjungle",
              "text": "that's the first good enterprise use case I've heard of. Otherwise people mostly seem to use it for personal only. Good stuff!",
              "score": 1,
              "created_utc": "2026-01-16 07:10:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuvr5d",
          "author": "NeoMCP_AI",
          "text": "We provide MCP servers for various tools, mainly in the GTM space. Does anyone want to try it out?",
          "score": 1,
          "created_utc": "2026-01-16 03:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzri3a0",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2026-01-15 17:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzst6so",
              "author": "Ordinary-You8102",
              "text": "Why u use google?",
              "score": 1,
              "created_utc": "2026-01-15 21:06:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzstcnl",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-15 21:07:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfahkm",
      "title": "Is there a free MCP for web and documentation search? (OpenAI Codex)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "author": "jakehj5167",
      "created_utc": "2026-01-17 11:04:43",
      "score": 9,
      "num_comments": 13,
      "upvote_ratio": 0.81,
      "text": "I'm struggling to find a way for Codex to perform thorough searches without having to pay for a plan or wasting tokens. What I've tried:\n\n* Codex's built-in web search tool: can't browse JS-only sites. In my case, it's unable to browse developer.apple.com.\n* \\`microsoft/playwright-mcp\\`: It's able to perform searches and read pages, but very heavy hit on context. Burned through 10% of the context window for a single search.\n* [Exa.ai](http://Exa.ai), [context7.com](http://context7.com), Brave Search MCP: I'm strongly turned off by the pay-per-thousand model or caps on free plans. I understand they have to make money, it's just not what I want to spend money on.\n* [https://github.com/arabold/docs-mcp-server:](https://github.com/arabold/docs-mcp-server:) I didn't test this, but I was turned off by the fact you have to run the server in the background instead of allowing it to be booted by the Codex instance (via npx) like it can for other kinds of MCP servers.\n\nDoes anyone have a solution to this that hits on all marks: free, able to read websites including JS ones, thorough and high-quality?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04jhyh",
          "author": "punkpeye",
          "text": "I think it is unlikely you will find something like Exa for free. I have implemented comparable service to Exa for our internal use case (we make hundreds of thousands of requests) and it took a lot of effort and still relies on external services (ie not free)\n\nMaybe if you define the problem better, you will find better solutions.\n\nLike, maybe you just need something that can navigate sites using browser and return markdown instead of html. There are a few of those",
          "score": 2,
          "created_utc": "2026-01-17 16:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05eqze",
          "author": "Technical-Shock-7385",
          "text": "If you Only use sub-agents for playwright-mcp you got resume of results without burning context window ?",
          "score": 1,
          "created_utc": "2026-01-17 18:38:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09qx9q",
          "author": "waxyslave",
          "text": "tavily , parallel. Very generous monthly allowances. If you want something even more basic there are website -> markdown chrome extensions.",
          "score": 1,
          "created_utc": "2026-01-18 10:35:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5szf",
          "author": "phdyle",
          "text": "Ref.tools",
          "score": 1,
          "created_utc": "2026-01-18 12:43:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o037f05",
          "author": "iohans",
          "text": "Try building your own. It will not be better than you listed, but you can get better over time and solve your current need.\n\nHybrid RAG, vector DB, rerankimg, use a sentence transformer for emeddings. Put your knowledge files in a folder, index, and wrap in an MCP Server. Claude Code or Codex will get you there in an hour. Then, hours of refining. It will be fun and yours.",
          "score": 0,
          "created_utc": "2026-01-17 11:22:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038moh",
              "author": "Express-One-1096",
              "text": "Yeah man, why not just your own llm while heâ€™s at it, maybe design his own ram aswell",
              "score": 6,
              "created_utc": "2026-01-17 11:33:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0iyokz",
                  "author": "Illustrious_Eye_1280",
                  "text": "if he does design his own ram can he let me know i'll pay lmao.",
                  "score": 2,
                  "created_utc": "2026-01-19 19:00:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o043vlj",
                  "author": "BeautifulFeature3650",
                  "text": "Damn",
                  "score": 1,
                  "created_utc": "2026-01-17 14:56:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08ikt3",
                  "author": "Doomtrain86",
                  "text": "Yeah man, why do ANYTHING yourself ! No need for that at all !",
                  "score": 1,
                  "created_utc": "2026-01-18 04:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03lyu1",
              "author": "jakehj5167",
              "text": "It's possible, and I thought about adjusting \\`playwright-mcp\\` to be a bit lighter, but it's honestly too deep of a rabbit hole for me. That's why I hoped people had found a way around this issue already.",
              "score": 1,
              "created_utc": "2026-01-17 13:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04uu8d",
                  "author": "Terrariant",
                  "text": "Itâ€™s actually way easier than you think. I started playing around with local LLMs about 4 days ago and already have a â€œcomposer model fileâ€ that runs an LLM to select one of 9 other models that is appropriate for the prompt. RAG and database stuff I am looking into next.\n\nBut yeah, really itâ€™s becoming more of a solved problem. You can have Gemini walk you through setting it up, even",
                  "score": 2,
                  "created_utc": "2026-01-17 17:06:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03sd53",
          "author": "jakehj5167",
          "text": "So far I've found [https://github.com/jae-jae/fetcher-mcp](https://github.com/jae-jae/fetcher-mcp) which mostly does what I want, but it only started working well when I asked Codex to run it with \\`disableMedia: false\\`.",
          "score": 0,
          "created_utc": "2026-01-17 13:54:38",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdr3f7",
      "title": "MCP for dev",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "author": "ProfessionNo3952",
      "created_utc": "2026-01-15 18:12:49",
      "score": 9,
      "num_comments": 28,
      "upvote_ratio": 0.8,
      "text": "I am really into AI for code. However I cannot understand why when and for what I can use MCP as software developer. I ask ChatGPT about it but nothing helpful. May be some of you have practical experience in enterprise development using MCP?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzs360p",
          "author": "circamidnight",
          "text": "I've built mcp dev servers for specific projects with tools to run tests, lint, run etc. this is nice because our team can use the agent of their choice and the agent doesn't burn tokens figuring out the way to run some bash command for what you want to do.",
          "score": 6,
          "created_utc": "2026-01-15 19:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs7t2h",
              "author": "ProfessionNo3952",
              "text": "Sound good. Is it difficult to do?",
              "score": 1,
              "created_utc": "2026-01-15 19:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsqme0",
                  "author": "circamidnight",
                  "text": "No, I've used FastMCP, it's very simple to get started with a simple server that can say run your tests. Heck Claude code or whatever coding agent can set it up easy enough.",
                  "score": 1,
                  "created_utc": "2026-01-15 20:54:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrt18w",
          "author": "0xKoller",
          "text": "When using AI for coding, tools like Cursor, CC, or Codex can really benefit from MCPs to improve output, for example, Context7, which lets the AI query up-to-date documentation, or the Figma MCP, which an agent can use to get pixel-perfect references for a UI design youâ€™re trying to nail.",
          "score": 3,
          "created_utc": "2026-01-15 18:21:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzryn29",
              "author": "ProfessionNo3952",
              "text": "Context7 is sound really cool. May be you can share how you use it and set up it? Or may be some cool article?",
              "score": 2,
              "created_utc": "2026-01-15 18:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nztk1lj",
                  "author": "colsatre",
                  "text": "https://letmegooglethat.com/?q=context7",
                  "score": 2,
                  "created_utc": "2026-01-15 23:15:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwph2c",
                  "author": "0xKoller",
                  "text": "Here is the official GH with the tutorial for some IDEs  \n[https://github.com/upstash/context7#installation](https://github.com/upstash/context7#installation)",
                  "score": 2,
                  "created_utc": "2026-01-16 12:21:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs0bd5",
              "author": "Shumuu",
              "text": "> Pixel perfect \nlol! I never get it to be pixel perfect BUT it is good to get like 90% of the way",
              "score": 2,
              "created_utc": "2026-01-15 18:53:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzslmq0",
                  "author": "finance-mcp-001",
                  "text": "The problem is that the last 10% takes two months of figuring out what happened with the 90% that took an hour.",
                  "score": 3,
                  "created_utc": "2026-01-15 20:31:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs104v",
          "author": "Capnjbrown",
          "text": "Hey, perhaps you might find some interests in my project\nI recently open sourced [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-15 18:56:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztf7jg",
              "author": "DasBlueEyedDevil",
              "text": "I feel like they compliment one another...\n\n[https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
              "score": 2,
              "created_utc": "2026-01-15 22:50:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzts27y",
                  "author": "Capnjbrown",
                  "text": "Interesting. Iâ€™ll check it out.",
                  "score": 1,
                  "created_utc": "2026-01-15 23:59:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu6ilc",
          "author": "TheLostWanderer47",
          "text": "MCP starts to make sense once an agent needs to do something outside your codebase. Itâ€™s basically a standard way to expose tools to an agent without bloating context or writing custom glue for every service. For example, when an agent needs live web data, instead of hardcoding scrapers or APIs, you can put a web-access layer behind MCP. Thatâ€™s where setups like Bright Dataâ€™s [MCP server](https://github.com/brightdata/brightdata-mcp) come in: the agent calls search/browse/extract tools on demand, and the infrastructure handles access and blocking. If your agent only works on local code or static docs, MCP adds little value.",
          "score": 2,
          "created_utc": "2026-01-16 01:18:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzur46g",
          "author": "NoAdministration6906",
          "text": "I have used mcptoolgate mcp server to guardrail the github, jira, slack for junior developers who are using coding agent to code. I can easily monitor any unwanted github actions and approve or disapprove the request like directly merging to main branch. Pretty useful",
          "score": 2,
          "created_utc": "2026-01-16 03:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gg221",
          "author": "kanundrumtt",
          "text": "I use the atlassian MCP to give access to the ticket details (so I say start work on Jira ticket ABC-123). This has lead to me adding more details on the ticket  (I use an agent to fill out more requirements based on usually vague tickets). I use the GitHub MCP to reference PRs on older tickets which new tickets might do. MCPs for documentation is also helpful (I used the forge MCP when building the agent that fills out my requirements)",
          "score": 2,
          "created_utc": "2026-01-19 10:52:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kczb6",
          "author": "Top_You_4391",
          "text": "A good example is the \"Astro docs\" - which allows the AI to find detailed instructions easier than having to web-search the website documentation.\n\nI use the playwright mcp server for: allowing claude to see and browse my website while we work on it. Claude can web-search but this is just a GET request. With playwright claude can browse SPAs.\n\nVercel is another one which allows the AI to view deployments, read logs and help you debug issues.\n\nMCP is almost limitless & can be combined with skills.",
          "score": 2,
          "created_utc": "2026-01-19 23:01:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrs6ko",
          "author": "requisiteString",
          "text": "What are you using to code with AI? MCP servers are like APIs for your AI agent. They allow the agent to do things with other software through a standard interface. Think of MCP like USB for your agents to connect to other apps.",
          "score": 1,
          "created_utc": "2026-01-15 18:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrsjlr",
              "author": "ProfessionNo3952",
              "text": "Yep, I got it. But using AI agent with which MCP and how can help for software development?",
              "score": 1,
              "created_utc": "2026-01-15 18:19:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzrt7ja",
                  "author": "colganc",
                  "text": "Interact with a web browser to automatically verify UI behavior as it iterates in the dev process?",
                  "score": 2,
                  "created_utc": "2026-01-15 18:22:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrw7a9",
                  "author": "SociableSociopath",
                  "text": "Youâ€™re looking for an answer that no one has because it completely depends on what youâ€™re doing and what your use cases are. There is no one magic MCP server to use itâ€™s just another name for an API",
                  "score": 2,
                  "created_utc": "2026-01-15 18:35:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvp76",
          "author": "texo_optimo",
          "text": "I have a txt2img mcp server that I connect can connect to from within any repo to gen image assets on demand. Mainly browser game image assets for my kids but works well for FE\n\nI have a governance mcp server I connect all my repos to. Guardrails \"vibecoding\" with blessed stack patterns, knowledge gained from prior ADRs, kind of a kanban board for me to either review via UI or programmatically from within the repo.",
          "score": 1,
          "created_utc": "2026-01-15 18:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzspy0d",
          "author": "naseemalnaji-mcpcat",
          "text": "I've found MCP can be really useful for integrating AI into your development workflows. For instance, you can use MCP to automate making changes to code reviews or generate test cases by connecting it with GitHub or JIRA. It's especially powerful in CI/CD pipelines for debugging based on logs.",
          "score": 1,
          "created_utc": "2026-01-15 20:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfnte",
          "author": "Prismshadow_AI",
          "text": "Think of it this way: Without MCP, your AI is like a genius stuck in a room with no internet and no windows. You have to copy-paste everying to it. With MCP, you are giving that genius a 'key' to your local dev environment.\n\nOne practical example: Yesterday I was debugging a legacy repo. Instead of pasting 10 files, I just used an MCP server to let Claude 'read' the whole folder. It found a naming conflict in a config file I didn't even tell it about. Thatâ€™s the 'aha' moment.\n\nIf you're using Claude Desktop or Cursor, just try the basic 'Google Search' or 'Filesystem' MCP first. Itâ€™s a game changer for keeping the AI in sync with what you're actually doing.",
          "score": 1,
          "created_utc": "2026-01-16 05:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyyo5e",
          "author": "Jealous_Document2508",
          "text": "MCP servers are really helpful. On a baseline, web search is a must as your agent will not have all the context needed, and will sometimes need to search the web.\n\nOn a side note, we're building an [SDK ](https://github.com/dedalus-labs/dedalus-sdk-python)at Dedalus that will allow you to use trusted MCP servers that are hosted on our marketplace. Check us out!",
          "score": 1,
          "created_utc": "2026-01-16 18:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0tgn",
          "author": "Classic_Chemical_237",
          "text": "Think of MCP as a wrapper over traditional API.\n\nIn text centric world, everything is done through chat and voice. So when you say â€œdo this for meâ€ and it needs to call some API to execute, a MCP is a reusable module which you delegate the responsibility to call the API. It can be used to run command line on local machine too.\n\nBasically itâ€™s a wrapper to call structured actions in an unstructured world",
          "score": 1,
          "created_utc": "2026-01-15 18:55:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzso3zv",
          "author": "Low-Efficiency-9756",
          "text": "Hi! Iâ€™m an mcp developer. I have a framework for LLMs that uses prompt engineering to guide agents into TDD development flows\n\nThe framework has some bolt ons mcp tools\n\nOODA mcp - full computer control for your agent (yes itâ€™s the type of server researchers would be scared of) \n\nSynch mcp - persistent memory bank for agents across workspaces (Claude code, to antigravity, to Roo code, etc.\n\nTrace mcp - consumer/ producer schema validation and bidirectional scaffolding for over 10 languages and model context protocol servers. \n\nIndex foundry mcp - Deterministic RAG pipeline  for deployed chatbots in less than an hour, while also adding to your local agents RAG capabilities. \n\nThese four tools give your agents most of the tools to fix the â€œbrain in a jarâ€ problem. \n\nIntegrate with GitHub cli, railway cli, supabase etc and you have yourself an agent that is capable of writing and deploying software on its own.",
          "score": 1,
          "created_utc": "2026-01-15 20:42:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzspkcy",
              "author": "Low-Efficiency-9756",
              "text": "Also did like to add mcp is way more than api for your agents. Any cli capable agent can use api services. \n\nMCP servers are executable tools that validate inputs (JSON-RPC), mutate state, return typed data, maintain invariants. LLM proposes, tool executes.\n\nLLMs are the hands, the database is the intelligence. MCPs allow agents to reason over state in ways that raw APIs canâ€™t. The tool enforces contracts, state persists across sessions, and the LLM doesnâ€™t have to remember, it just has to ask.",
              "score": 0,
              "created_utc": "2026-01-15 20:49:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhgo7q",
      "title": "I just converted Octocode MCP to a standalone skill ðŸ™ðŸŽ‰",
      "subreddit": "mcp",
      "url": "https://v.redd.it/1pwm5z0ecdeg1",
      "author": "_bgauryy_",
      "created_utc": "2026-01-19 21:03:15",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qhgo7q/i_just_converted_octocode_mcp_to_a_standalone/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qfvkah",
      "title": "FrontMCP: The TypeScript Way to Build MCP Servers",
      "subreddit": "mcp",
      "url": "https://i.redd.it/kadcv1lkk0eg1.png",
      "author": "DavidAntoon",
      "created_utc": "2026-01-18 01:52:47",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qfvkah/frontmcp_the_typescript_way_to_build_mcp_servers/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0fjhpx",
          "author": "saif_shines",
          "text": "u/DavidAntoon , Is there a documentation, how I can write a plugin for FrontMCP especially as a auth provider? For example, something like: [https://gofastmcp.com/integrations/scalekit#scalekit-fastmcp](https://gofastmcp.com/integrations/scalekit#scalekit-fastmcp)",
          "score": 3,
          "created_utc": "2026-01-19 06:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h1mfi",
              "author": "DavidAntoon",
              "text": "https://github.com/agentfront/frontmcp/tree/main/libs/plugins",
              "score": 2,
              "created_utc": "2026-01-19 13:34:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o07wqlb",
          "author": "punkpeye",
          "text": "Can you compare it to fastmcp?",
          "score": 2,
          "created_utc": "2026-01-18 02:16:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o089fpu",
              "author": "DavidAntoon",
              "text": "In summary, FrontMCP and FastMCP both greatly simplify building MCP servers, but they cater to different developer preferences. \n\nFrontMCP brings a TypeScript, enterprise-web approach: structured, heavily tooled, and extensible via plugins ï¿¼ ï¿¼. FastMCP brings a Pythonic approach: minimal ceremony, flexibility, and integration with Pythonâ€™s ecosystem ï¿¼. \n\nFrontMCP tends to be better when you need robust typing, modular architecture (multiple apps/tenants), and out-of-the-box solutions for cross-cutting concerns. \nFastMCP is better when you need quick development in Python or want to compose and deploy MCP services with existing Python infrastructure. Both adhere to the MCP specification and support core features like streaming responses, sessions, and secure transport, so either can get the job done. The choice often comes down to the language and feature philosophy that fit your project best. \n\nFrontMCP clearly stands out in areas like TypeScript DX and plugin-based extensibility, which can give it an edge for complex, large-scale applications that require maintainability and strong typing ï¿¼ï¿¼.\nFastMCPâ€™s maturity and simplicity make it a reliable choice for Python-centric teams or simpler use cases where quick development is paramount.",
              "score": 2,
              "created_utc": "2026-01-18 03:27:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o089krs",
          "author": "punkpeye",
          "text": "Wrong library https://github.com/punkpeye/fastmcp",
          "score": 0,
          "created_utc": "2026-01-18 03:27:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08hsub",
              "author": "DavidAntoon",
              "text": "FastMCPâ€™s TypeScript version is no slouch â€“ itâ€™s feature-rich (even ahead in some areas like a fully implemented OAuth proxy with dynamic registration) and is a proven way to build MCP servers quickly . \nHowever, FrontMCP offers a more advanced architecture that feels more at home for modern Node/TS developers, especially those who want structure and flexibility. In areas like plugin support, tooling, and multi-tenancy, FrontMCP provides capabilities that can significantly enhance developer productivity and maintainability, thereby offering a superior overall developer experience in many cases.",
              "score": 0,
              "created_utc": "2026-01-18 04:17:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qih2r2",
      "title": "Capturl MCP server lets agents include screenshots in PRs",
      "subreddit": "mcp",
      "url": "https://capturl.com/blog/introducing-capturl-mcp",
      "author": "PuzzledCulture25",
      "created_utc": "2026-01-20 23:20:29",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/mcp/comments/1qih2r2/capturl_mcp_server_lets_agents_include/",
      "domain": "capturl.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qgbwsu",
      "title": "Is there an MCP to allow context sharing across models?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qgbwsu/is_there_an_mcp_to_allow_context_sharing_across/",
      "author": "ilovefunc",
      "created_utc": "2026-01-18 15:46:50",
      "score": 8,
      "num_comments": 19,
      "upvote_ratio": 0.9,
      "text": "For example, I use Claude code, and then hit the rate limit. I would like to somehow continue with the same context on cursor (and vice versa). \n\nSame thing goes for my conversations with ChatGPT or Claude or Gemini. Would love to continue a conversation across these without manually copy / pasting the chat.  \n\nAny solution for this exists? Thanks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qgbwsu/is_there_an_mcp_to_allow_context_sharing_across/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o0b3mpg",
          "author": "Putrid_Barracuda_598",
          "text": "You can have Claude code build one.\nI've got a custom one; part of my bigger stack. \nIt uses pub/sub to share short term context and a \"vault\" to share long term.",
          "score": 2,
          "created_utc": "2026-01-18 15:56:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b47s2",
              "author": "ilovefunc",
              "text": "Can you share more about how it works please? Seems interesting.",
              "score": 1,
              "created_utc": "2026-01-18 15:58:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0b5zx1",
                  "author": "Putrid_Barracuda_598",
                  "text": "Basically I have multi-agent orchestration. Depending on the task and which cli Im running at the time I just have it use the board or vault to store long term or project logs. Then, if I switch to Gemini, or codex (Claude code is my main driver) I just have them review the board or value (per project or long term) for whatever context they need and they can pick up form there. \n\nI can share a spec later, as I don't remember exactly if the pub/sub uses postgres or something else (I have 157 specialized agents). \n\nI also have a \"deliberator\" where I can have Claude discuss a task with codex and Gemini cli before it makes a decision. Or it gets back to me with what they decided and I approve or ask them to discuss again based on the new info. \n\nThe easiest thing, if you have Claude code cli, would be to ask Claude to create an Mcp for you. It has Mcp builder built in and will do a pretty good job. As long as you tell it what you need.",
                  "score": 2,
                  "created_utc": "2026-01-18 16:07:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0d1rdl",
          "author": "Capnjbrown",
          "text": "A tool I built for this and recently open sourced it - technically you could accomplish what youâ€™re trying to do. If you chose the global archive storage option in your configurations. These folders/files are just JSON files located locally on your machine at a given pathway. You could easily pull the context from these regardless of the model or manual retrieval you are trying to accomplish. [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper) Hope this helps.",
          "score": 2,
          "created_utc": "2026-01-18 21:36:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c3xi7",
          "author": "anywhereblue",
          "text": "Great question I use a shared MCp service to allow one agent to write an artifact and another to read it.",
          "score": 1,
          "created_utc": "2026-01-18 18:46:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fm02z",
          "author": "coloradical5280",
          "text": "Thatâ€™s literally a technical impossibility with the transformer architecture. If you mean a fancy behind the scenes copy and paste into other context windows, sure. But two models ACTUALLY running attention on every token and sharing rich context, thatâ€™s not possible.",
          "score": 1,
          "created_utc": "2026-01-19 06:20:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fm3kc",
              "author": "ilovefunc",
              "text": "Oh yea, I meant the fancy behind the scene copy paste method.",
              "score": 1,
              "created_utc": "2026-01-19 06:21:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0fv3s5",
                  "author": "coloradical5280",
                  "text": "yeah there's a bunch, if you don't get the best answer here, r/claudecode might be a better place to ask. I could give you 2-3 names but I just don't use that workflow often , and wouldn't want to give you the 2-3 worst.  Stick with informed answers of people who actually use the workflow you want, which again will be easier to find those folks in cc or r/codex or the other coding subs :)",
                  "score": 1,
                  "created_utc": "2026-01-19 07:37:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ftpr3",
              "author": "GnistAI",
              "text": "This isnâ€™t really about machine learning architecture. It is a harness question. Copying context text from one harness to another.",
              "score": 1,
              "created_utc": "2026-01-19 07:25:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0futmw",
                  "author": "coloradical5280",
                  "text": "Literal context sharing between heterogeneous models is architecturally impossible, not a harness abstraction.\n\nThe KV cache stores projected key-value pairs computed as K=XW\\_k, V=XW\\_v where W\\_k and W\\_v are learned projection matrices specific to that model's weights. Attention is computed as softmax(QK\\^T/âˆšd\\_k)V - the Q from your current forward pass is computing dot products against cached K vectors. If those K vectors came from a different model's projection matrices, you're computing similarity in incompatible latent spaces. The attention scores are meaningless.\n\nBeyond that: different tokenizers (e.g., Claude's BPE vs Gemini's SentencePiece), different vocabulary mappings, different embedding dimensions, different positional encoding schemes. Token 4521 doesn't reference the same subword, and even if it did, the embedding vector lives in a completely different learned manifold.\n\nThere is no harness that reconciles incompatible learned representations. The \"harness solution\" (serialize text, re-tokenize, re-embed in target model's native space) exists precisely BECAUSE architectural constraints make true state sharing impossible.\n\nDismissing this as \"not an architecture question\" demonstrates a fundamental confusion about what the harness layer is abstracting over and why.\n\nedit: realizing you didn't actually read my whole response, or OPs response to it...  wrote this before i realized that.",
                  "score": 2,
                  "created_utc": "2026-01-19 07:35:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0hlcyh",
          "author": "smothered-onion",
          "text": "Sounds like you want an agent powered by mcp. Model switching occurs in agent. Agent shares context as necessary. Unless you want or need to build that logic yourself.",
          "score": 1,
          "created_utc": "2026-01-19 15:19:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dhfil",
          "author": "justgetting-started",
          "text": "Hey you could try asking the question in my app and see if it helps .. https://architectgbt.com",
          "score": 0,
          "created_utc": "2026-01-18 22:50:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi2xr5",
      "title": "MCP isn't deadâ€“it's maturing",
      "subreddit": "mcp",
      "url": "https://glama.ai/blog/2026-01-20-mcp-is-not-dead",
      "author": "punkpeye",
      "created_utc": "2026-01-20 14:44:55",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/mcp/comments/1qi2xr5/mcp_isnt_deadits_maturing/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qhmbzs",
      "title": "gemini-research-mcp: deep research agent as an MCP server â€” 5 min autonomous research, 25+ sources, full citations",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qhmbzs/geminiresearchmcp_deep_research_agent_as_an_mcp/",
      "author": "gfortaine",
      "created_utc": "2026-01-20 00:46:51",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "built an mcp server that exposes gemini's deep research capabilities to any mcp client.\n\n**tools exposed:**\n\n* `research_web`Â â€” quick grounded search (5-30s)\n* `research_deep`Â â€” autonomous multi-step research (3-20 min), returns structured report with citations\n* `research_followup`Â â€” continue conversation after deep research\n\n**what makes it different:**\n\n* recursive search (depth/breadth control)\n* full citation trail â€” no hallucinated sources\n* works with claude desktop, cursor, vs code copilot, any mcp client\n\n**example run:**Â asked it to analyze its own positioning in the mcp ecosystem â†’ 5 min, 338k tokens, 25 sources, strategic report with technical moats identified.\n\nhttps://preview.redd.it/wnt0ec3oieeg1.png?width=1034&format=png&auto=webp&s=e40a5db57a3e68505564e8e7aaddead4ec49fa19\n\nopen source (mit): [github.com/fortaine/gemini-research-mcp](http://github.com/fortaine/gemini-research-mcp)\n\nfeedback welcome â€” what features would make this useful for your workflows?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qhmbzs/geminiresearchmcp_deep_research_agent_as_an_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o0o6yf9",
          "author": "cab938",
          "text": "I think it looks interesting, especially as elicitation and tasks are used! What I would really like though is the ability to decouple the task (deep research) from the engine (gemini) and then be able to choose which engine I want to fulfill the deep research task. I will typically run multiple deep research tasks in different providers (including local models) and feed them all in to a synthesis agent - would be nice to have the MCP be able to manage this for me.",
          "score": 1,
          "created_utc": "2026-01-20 14:30:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r56wy",
              "author": "gfortaine",
              "text": "really appreciate this feedback â€” you're describing exactly the kind of \"multi-engine orchestration\" that makes sense for serious research workflows.\n\ndecoupling the task from the engine is definitely on my radar. the current architecture is gemini-first because of the grounding + deep think capabilities, but there's no reason the same mcp interface couldn't dispatch to:\n\n* openai (via responses api)\n* local models (ollama, vllm)\n* perplexity, tavily, etc.\n\nthe synthesis layer you're describing (multiple providers â†’ aggregated output) is interesting. would you want that managedÂ *inside*Â the mcp server (single tool call, multiple backends), or prefer separate tool calls that you orchestrate yourself?\n\ncurious what your current workflow looks like â€” are you using langchain/langgraph for the synthesis, or something custom?",
              "score": 1,
              "created_utc": "2026-01-20 22:47:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}