{
  "metadata": {
    "last_updated": "2026-02-04 02:59:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 107,
    "file_size_bytes": 144841
  },
  "items": [
    {
      "id": "1qqf4zo",
      "title": "3 MCPs that have genuinely made me 5x better",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "author": "Warm-Snow3302",
      "created_utc": "2026-01-29 17:33:36",
      "score": 267,
      "num_comments": 69,
      "upvote_ratio": 0.91,
      "text": "I've been testing MCPs extensively for fun, so I thought I‚Äôd share some of the ones I‚Äôve found most useful. Plus I've found most of the them here only.\n\nMy main criteria were minimal setup, reliability, and whether I kept using them after the novelty wore off:\n\ngreb MCP: Greb helps makes your coding agent 30% faster by helping them find correct files faster. That too without indexing It‚Äôs especially helpful for issue + commit context grounding and repo exploration. \n\nSlack / Messaging MCP: that‚Äúwow‚Äù factor with very low effort. Once an agent can talk where humans already are, teams love it instantly. My team even used this for something as basic as ordering and tracking deliveries for team lunch, which ended up being one of the most-used workflows for us.\n\nGitHub MCP: This is what finally made Claude feel like an actual teammate instead of a smarter autocomplete. If you‚Äôre tired of copy-pasting repos into prompts, you‚Äôre gonna love it. It‚Äôs especially helpful for issue + commit context grounding and repo exploration.\n\nSuper curious to hear what MCPs all of you have found useful?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2h9avr",
          "author": "slea95",
          "text": "Not sure the GitHub MCP is any better than the already-comprehensive gh CLI tool tbh. Unless there‚Äôs something I‚Äôm missing, it seems to be able to do all the things you listed but more efficiently and without bloat?",
          "score": 44,
          "created_utc": "2026-01-29 20:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hhjgc",
              "author": "sweettuse",
              "text": "+1 to this, might be worth reconsidering with Claude lazy mcp loading, but I just use the gh cli and it's great",
              "score": 9,
              "created_utc": "2026-01-29 21:25:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2j08sj",
                  "author": "bin-c",
                  "text": "I made the switch to GitHub mcp now that the mcp cli is available and for whatever reason it just seems to work better. Absolutely unusable before lazy loading though lol",
                  "score": 3,
                  "created_utc": "2026-01-30 02:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2kxxgj",
              "author": "AdResident780",
              "text": "i personally love the deepwiki mcp server as it is free (no PAT needed) , doesnt need to be self-hosted and can ask questions about literally any github repo in existence (if not indexed, you need to index the repo by going to [deepwiki.com/](http://deepwiki.com/) {owner-of-unindexed-repo} / {unindexed-repo} .",
              "score": 3,
              "created_utc": "2026-01-30 10:48:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2htqzs",
              "author": "command-shift",
              "text": "It‚Äôs much better at parsing reviewer comments and feedback than gh CLI as a user of both",
              "score": 2,
              "created_utc": "2026-01-29 22:24:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2z89rx",
              "author": "MrDiablerie",
              "text": "I was gonna say, why do you need the mcp when gh exists and works fine?",
              "score": 1,
              "created_utc": "2026-02-01 14:54:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35bufh",
                  "author": "Cast_Iron_Skillet",
                  "text": "I found issues with larger commits where the AI would run a git diff command in terminal and then get stuck waiting for input because I had to hold enter to scroll through the entire diff for each file and then escape with 'q' before agent would pick up again. \n\nSo annoying and still happens with Claude code and cursor and antigravity. \n\nThe MCP resolves that. You just have to be very selective of the available tools to reduce bloat. \n\nI could maybe include some rules as well to prevent that running, but checking diffs is a good thing to be able to do. Just wish they knew how to do it without requiring user input to terminal. \n\nI'm on windows 11 if that makes a diff.",
                  "score": 1,
                  "created_utc": "2026-02-02 12:57:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2gfmw8",
          "author": "Electronic_Boot_1598",
          "text": "Which Slack MCP do you use?",
          "score": 12,
          "created_utc": "2026-01-29 18:27:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g9eqj",
          "author": "Crab_Shark",
          "text": "I‚Äôd love to know more!\n* For greb MCP, does that speedup also come with a reduction of token usage? Have you noticed whether it‚Äôs affected search quality?\n* For GitHub MCP, how is it different than the connectors within Claude, or running Claude Code connected to specific repos?",
          "score": 11,
          "created_utc": "2026-01-29 17:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdu05",
              "author": "snix_e",
              "text": "idk of the OP but I read about greb on this reddit only and it has been great, there's a reduction in token usage plus it remembers the logic with millions of line of code \n\nGitHub is very similar to them but the transition is very smooth",
              "score": 4,
              "created_utc": "2026-01-29 18:19:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hekq2",
          "author": "Maasu",
          "text": "There's a plugin I created which combines context7, Serena and forgetful (my own memory mcp) \n\nhttps://github.com/ScottRBK/context-hub-plugin\n\nI basically use the context gather command before I start any work and memory save when I'm done.",
          "score": 6,
          "created_utc": "2026-01-29 21:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jjm9r",
              "author": "Impressive_Chemist59",
              "text": "What difference between Serena and forgetful?",
              "score": 1,
              "created_utc": "2026-01-30 04:03:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kjl0r",
                  "author": "Maasu",
                  "text": "Serena is more concentrated on single device and has fairly primitive memory storage/retrieval. \n\nI mainly use Serena because of its out of the box encoding capabilities, specifically the symbol mapping on a repo, I use that output in an encoding architecture doc attached to each project that an LLM can consume to get a quick understanding of the code. \n\nHandy if I in voice convo on my phone etc and I don't want an LLM trawling through loads of code during an architectural brain storming session when I'm out for a walk for example.",
                  "score": 1,
                  "created_utc": "2026-01-30 08:38:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h5pvi",
          "author": "UseHopeful8146",
          "text": "I haven‚Äôt used GitHub mcp since it like first released, but I found it to be a complete waste of context. Your basic git/gh cli tools are incredibly simple, and even scripting CI/CD stuff isn‚Äôt terribly complicated - I just don‚Äôt see the value there\n\nEven for codebase search/analysis, octocode semantic search and deepwiki have been way more beneficial. And even just browser searching a repo is faster and more efficient with browser mcp or whichever web search tool that OmO installs with\n\nBut again, I have not used it at all since like‚Ä¶ idk march?",
          "score": 5,
          "created_utc": "2026-01-29 20:29:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hlwow",
              "author": "cab938",
              "text": "My value was it was in an MCP and I wasn't having to give the agent shell access. But frankly I rarely use it just because MCPs are much more fragile it seems.",
              "score": 1,
              "created_utc": "2026-01-29 21:46:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hnbnw",
                  "author": "UseHopeful8146",
                  "text": "Yeah agreed, I use mcp for very specific purposes, usually for interacting with self hosted services. Memory functions, routine things that save me time, or in some rare cases for specific retrieval methods like pulling my project specs and related docs from any type.\n\nBut MCP isn‚Äôt saving me time on git add, git comment, git push or gh repo clone, etc. if I want to look at specific material in a codebase: octocode \n\nIf I have a theory or a particularly tricky problem, index and question with deepwiki.\n\nNeed current code examples for a given library: context7\n\nLike, MCP does really well in certain instances, but a lot of them are just context waste. Bt those, and OmO provided mcp‚Äôs I save time on the long form stuff like research, investigation, etc. and since I learn by doing - I learn a lot faster by getting to ‚Äúdo‚Äù sooner",
                  "score": 1,
                  "created_utc": "2026-01-29 21:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ht4qp",
          "author": "alex__richards",
          "text": "I would avoid MCP and use CLI tools where possible. I use Claude code and have cli‚Äôs configured for GitHub, Atlassian, Sentry, NewRelic - so much faster and economical (token usage) than an MCP",
          "score": 5,
          "created_utc": "2026-01-29 22:21:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2igmqq",
              "author": "SenorTortuga",
              "text": "Agreed. Not all MCPs are bad, but if there is a CLI tool that provides equivalent functionality it is almost always a better choice.  I‚Äôve been very happy since switching to acli and glab instead of Atlassian and GitLab MCPs.",
              "score": 3,
              "created_utc": "2026-01-30 00:25:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gclfg",
          "author": "Crafty_Disk_7026",
          "text": "GitHub MCP was clunky for me.  Uses lots of tokens and effort to do simple things like comparing a diff.  Which one did you use?",
          "score": 3,
          "created_utc": "2026-01-29 18:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdy0i",
              "author": "snix_e",
              "text": "opas",
              "score": 2,
              "created_utc": "2026-01-29 18:19:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfiv8",
                  "author": "Crafty_Disk_7026",
                  "text": "Gracias",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2gen3f",
          "author": "saloni1609",
          "text": "Nice list! I‚Äôve also been experimenting with MCPs recently.\n\nGreb stood out for me too especially for repo exploration without indexing. I‚Äôve been testing it inside Cheetah AI, which uses it as part of their context engine. It‚Äôs been interesting to see how it handles issue + commit grounding across bigger repos.\n\nGitHub MCP + Greb together feels like the closest thing to having a teammate who actually read the repo.\n\nCurious if you‚Äôve tried layering in memory systems too? I‚Äôve seen setups where the agent keeps commit history context, which makes debugging way smoother.",
          "score": 3,
          "created_utc": "2026-01-29 18:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gga4d",
          "author": "infidel_tsvangison",
          "text": "What does the GitHub mcp do really?",
          "score": 3,
          "created_utc": "2026-01-29 18:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hipdd",
              "author": "TeamCaspy",
              "text": "See pull requests easier, open pr, open issues,...",
              "score": 1,
              "created_utc": "2026-01-29 21:31:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2htkpa",
              "author": "command-shift",
              "text": "It‚Äôs also useful for fetching reviewer comments/feedback into your agent of choice to make decisions or issues to address or deliberate on",
              "score": 1,
              "created_utc": "2026-01-29 22:23:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gfdz8",
          "author": "Pitiful-Minute-2818",
          "text": "Nice one i tried greb mcp it was really good",
          "score": 2,
          "created_utc": "2026-01-29 18:25:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ghtbv",
          "author": "Capnjbrown",
          "text": "Good info thanks. Perhaps you might find my product I made for context archiving and context preservation (amongst other features) for coding within Claude Code CLI. I open sourced it a couple weeks ago: [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-29 18:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hl20o",
          "author": "adreportcard",
          "text": "People‚Ä¶. Copy and pasted repos into prompts?",
          "score": 2,
          "created_utc": "2026-01-29 21:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kt5bh",
              "author": "that__it_guy",
              "text": "Yeah I too didnt get this.",
              "score": 1,
              "created_utc": "2026-01-30 10:06:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ktyr7",
          "author": "that__it_guy",
          "text": "Why do people in general use so many mcps? When I have a coding task, i do research on Gemini, code on cursor/intellij and thats all. What are the manual workflows the agents have helped you in ?",
          "score": 2,
          "created_utc": "2026-01-30 10:13:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mrsly",
              "author": "vayana",
              "text": "I agree. I get by absolutely fine without an MCP. The only 2 I would consider using are a database MCP like neon or supabase and perhaps playwright, but I've so far never really needed to use these either.",
              "score": 1,
              "created_utc": "2026-01-30 16:52:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ty1qa",
                  "author": "testuser911",
                  "text": "I tried to convince my manager that an IDE is meant for coding task, we should provide a separate webpage like chatgpt or slack agent with which user can interact but failed miserably to convince him.",
                  "score": 1,
                  "created_utc": "2026-01-31 18:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hkvb0",
          "author": "oginome",
          "text": "Check out Forgetful MCP. It's a yet another vector-based semantic memory system that allows your agents to recollect stuff between sessions. I've been using it and it's actually pretty great - we can reference conversations from weeks ago instantly. I'm a huge fan of how it organizes by project, and I have basically replaced my note-taking workflow with it.\n\nCoupled with GLM 4.7 Flash, Karakeep MCP, and Searxng I've made strides in being able to efficiently provide it context so that I don't have to burn so many tokens reaching understanding. \n\n[https://github.com/scottrbk/forgetful](https://github.com/scottrbk/forgetful)",
          "score": 3,
          "created_utc": "2026-01-29 21:41:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g61wd",
          "author": "FewChart7648",
          "text": "I have used GitHub that is amazing but will try the rest, but GitHub also sometimes have a bad memory",
          "score": 1,
          "created_utc": "2026-01-29 17:44:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gc5u0",
          "author": "anywhereblue",
          "text": "Good list.",
          "score": 1,
          "created_utc": "2026-01-29 18:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gi1ur",
          "author": "PuzzledCulture25",
          "text": "When working on frontend I use [Linear](https://linear.app/docs/mcp), [ChromeDevTools](https://github.com/ChromeDevTools/chrome-devtools-mcp) and [Capturl](https://capturl.com). It lets agents see screenshots inside of tickets and update the ticket with new screenshots when it's done.",
          "score": 1,
          "created_utc": "2026-01-29 18:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h1tr4",
              "author": "Express-One-1096",
              "text": "Why not playwright mcp?",
              "score": 1,
              "created_utc": "2026-01-29 20:10:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h5e6g",
                  "author": "PuzzledCulture25",
                  "text": "I mainly switched over to chrome dev tools because it's nice for debugging but Playwright worked great too!",
                  "score": 1,
                  "created_utc": "2026-01-29 20:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h9da7",
          "author": "martin_xs6",
          "text": "There's an obsidian one that is really great if you use that.\n\nGmail + Google drive Is great too.  With Gmail you can have it draft emails to review before sending.  It's great for making notes to send to something about changes.",
          "score": 1,
          "created_utc": "2026-01-29 20:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hd46k",
          "author": "Traditional_Cress329",
          "text": "Really love devtools by google for debugging extensions or web apps.",
          "score": 1,
          "created_utc": "2026-01-29 21:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2he2rp",
          "author": "VictorCTavernari",
          "text": "For me as Swift developer, SwiftZilla.dev is the best",
          "score": 1,
          "created_utc": "2026-01-29 21:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hgw40",
          "author": "canihelpyoubreakthat",
          "text": "Nah huh. I saw 55x improvements! Measured with the trustmebro bench and all.\n\n55x more tokens\n55x more hallucinations \n55x more markdown\n55x more code to review",
          "score": 1,
          "created_utc": "2026-01-29 21:22:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hi68n",
          "author": "aviboy2006",
          "text": "I am using AWS ECS service MCP for debugging issue so far. I heard about Figma  and playwright MCP but didn‚Äôt try yet. Soon going to try.",
          "score": 1,
          "created_utc": "2026-01-29 21:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jght4",
              "author": "Warm-Snow3302",
              "text": "playwright is actually really good",
              "score": 2,
              "created_utc": "2026-01-30 03:44:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hoz7h",
          "author": "freeformz",
          "text": "I use the local version of the GitHub MCP (to remove tools I don‚Äôt care about) and it‚Äôs pretty awesome",
          "score": 1,
          "created_utc": "2026-01-29 22:01:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hvsib",
          "author": "dxlachx",
          "text": "Sequential thinking, Serena, and Context7",
          "score": 1,
          "created_utc": "2026-01-29 22:34:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i2nik",
          "author": "trolololster",
          "text": "greb?",
          "score": 1,
          "created_utc": "2026-01-29 23:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ihaid",
          "author": "Icanteven______",
          "text": "GitHub mcp is such a context hog. I just have it use the gh cli",
          "score": 1,
          "created_utc": "2026-01-30 00:28:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jqfpy",
          "author": "sincerodemais",
          "text": "Grep or filesystem mcp?",
          "score": 1,
          "created_utc": "2026-01-30 04:46:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kxnp8",
          "author": "AdResident780",
          "text": "i use the deepwiki MCP server (for up-to-date info about any github repo)",
          "score": 1,
          "created_utc": "2026-01-30 10:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sht17",
          "author": "deep_ak",
          "text": "Context7 MCP should deserve a mention\n\nFor implementing any feature in which I wan the plan to have a through spec and correct API docs context, context7 always comes handy",
          "score": 1,
          "created_utc": "2026-01-31 14:10:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2tyhh5",
          "author": "testuser911",
          "text": "You can also try ticket track board mcp like jira clickup and it would be more fun",
          "score": 1,
          "created_utc": "2026-01-31 18:31:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2vfrc9",
          "author": "bratorimatori",
          "text": "Thanks for the suggestions. I did not know about grab MCP. Searching is definitely where I spend most of my tokens. Here's my [workflow](https://intelligenttools.co/blog/claude-code-workflow-jira-to-production). Jira MCP + MySQL MCP, but yeah, workflow feels a bit outdated and probably needs some refactoring. I'll add grab for sure.",
          "score": 1,
          "created_utc": "2026-01-31 22:53:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2y619v",
          "author": "Desperate-Ad-9679",
          "text": "Great list! I've been using similar ones, but wanted to add one that's been a game-changer for me, and also developed by me:\n\n\"CodeGraphContext MCP\" - This one takes code understanding to another level beyond what greb offers. Instead of just file search, it builds a complete knowledge graph of your codebase with actual relationships between functions, classes, and modules.\n\nWhat makes it powerful:\n\n\\- Relationship queries: \"who calls this function?\", \"show me the class hierarchy\", \"find dead code\"\n\n\\- Cross-repo analysis: Index multiple projects + their dependencies in one graph\n\n\\- Pre-indexed bundles: Instantly load popular libraries (Flask, pandas, etc.) without re-indexing\n\n\\- Live watching: Auto-updates the graph as you code\n\n\\- Works with Neo4j or FalkorDB for visualization\n\nThe killer feature for me is being able to ask things like \"show me all functions that modify this variable\" or \"what's the call chain between X and Y\" - stuff that's impossible with just file search.\n\nIt's open source and has both a CLI and MCP server: [https://github.com/CodeGraphContext/CodeGraphContext](https://github.com/CodeGraphContext/CodeGraphContext)\n\nCurious if anyone else has tried it or has similar graph-based tools they like?",
          "score": 1,
          "created_utc": "2026-02-01 10:23:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zsb1w",
          "author": "PeteCapeCod4Real",
          "text": "You forgot Context7 lol so you can have the LLM go check the docs. Don't need it every time but when you do it's gold!",
          "score": 1,
          "created_utc": "2026-02-01 16:31:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30u78o",
          "author": "carlo_on_fire",
          "text": "GitHub mcp (gh cli) is one of the most time saving aspects right now.",
          "score": 1,
          "created_utc": "2026-02-01 19:22:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35phlw",
          "author": "RipKip",
          "text": "I've made a mcp for azure devops integration so the agent can grab user story context, including parents and children. It shaves a lot of the prompting needed",
          "score": 1,
          "created_utc": "2026-02-02 14:16:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g4ipy",
          "author": "TheLostWanderer47",
          "text": "Nice picks. One MCP that stuck for me was a [web access MCP](https://github.com/brightdata/brightdata-mcp) which lets agents search/browse/extract on demand instead of pasting pages or writing fragile scrapers. Once agents need live external data, velocity tanks unless it‚Äôs standardized.",
          "score": 1,
          "created_utc": "2026-02-04 01:02:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2geob1",
          "author": "DasBlueEyedDevil",
          "text": "You forgot the best one:  [https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
          "score": 0,
          "created_utc": "2026-01-29 18:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gfa0e",
              "author": "snix_e",
              "text": "you are promoting your MCP hereüòÇ",
              "score": 2,
              "created_utc": "2026-01-29 18:25:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfjt7",
                  "author": "DasBlueEyedDevil",
                  "text": "I meeeaaaaan, OP did end the post with asking which ones we've found useful ;-)",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2h8l0d",
              "author": "full_hyperion",
              "text": "Gonna try it out just because of the theme :D",
              "score": 1,
              "created_utc": "2026-01-29 20:43:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qt81d1",
      "title": "MCP directory that actually checks if servers are alive",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qt81d1/mcp_directory_that_actually_checks_if_servers_are/",
      "author": "punkpeye",
      "created_utc": "2026-02-01 19:26:31",
      "score": 29,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "There are dozens if not hundreds of remote MCP servers lists. The problem is that they get stale, don't tell you which servers work/which don't, or even what tools are available. That's what we're fixing with the MCP connector directory:\n\nhttps://glama.ai/mcp/connectors\n\nWe aggregate from the official MCP registry + community submissions, then actually connect to every server periodically and report:\n\n* Health ‚Äì Is the server up right now?\n* Auth ‚Äì how to authenticate to the server?\n* Schema ‚Äì what tools are available?\n* Changelog ‚Äì record of schema changes (new tools added, description updates, etc).\n\nAdditionally, if you are using our one-click connector, you can consolidate authentication/logging of all your MCP servers in one place. 100% free ‚Äì no subscription required.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qt81d1/mcp_directory_that_actually_checks_if_servers_are/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o310rp6",
          "author": "Ok_Message7136",
          "text": "This solves a real problem.  \nFor local validation before publishing, I‚Äôve been using Gopher‚Äôs free, open-source MCP SDK to spin up and test MCP servers (tools + schema) before listing them anywhere.\n\nLink: [https://github.com/GopherSecurity/gopher-mcp](https://github.com/GopherSecurity/gopher-mcp)",
          "score": 2,
          "created_utc": "2026-02-01 19:53:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs75xa",
      "title": "New Guide: Getting Started with FastMCP in TypeScript",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qs75xa/new_guide_getting_started_with_fastmcp_in/",
      "author": "ialijr",
      "created_utc": "2026-01-31 16:41:02",
      "score": 28,
      "num_comments": 2,
      "upvote_ratio": 0.98,
      "text": "Hey MCP community\n\n  \nI just published a guide to help folks build MCP servers quickly using **FastMCP for TypeScript,** inspired by how the Python ecosystem embraced FastMCP, but tailored for Node/TS.\n\nThe article walks through:\n\n* What FastMCP brings to the MCP ecosystem\n* Why it‚Äôs easier to use than the official SDK\n* How to scaffold, define tools/resources/prompts, and test your server\n* A working example of a calculator MCP server\n\nWhether you prefer TypeScript or are coming from Python, this should help you get a production-ready MCP server up and running in minutes:\n\nüîó [https://blog.agentailor.com/posts/getting-started-with-fastmcp](https://blog.agentailor.com/posts/getting-started-with-fastmcp?utm_source=reddit&utm_medium=social&utm_campaign=fastmcp_launch&utm_content=r_mcp)\n\nWould love feedback or questions about FastMCP in typescript. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qs75xa/new_guide_getting_started_with_fastmcp_in/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o316da7",
          "author": "Ok_Message7136",
          "text": "Nice write-up. Having a FastMCP-style approach for TypeScript makes onboarding a lot easier for Node folks.",
          "score": 1,
          "created_utc": "2026-02-01 20:21:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2wcozm",
          "author": "Block_Parser",
          "text": "I‚Äôd be more interested if the typescript version could infer descriptions and types by jsdoc/ type info like the python one can.",
          "score": 1,
          "created_utc": "2026-02-01 02:01:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrzade",
      "title": "MCP isn‚Äôt the hard part. Running it in production is.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qrzade/mcp_isnt_the_hard_part_running_it_in_production_is/",
      "author": "BC_MARO",
      "created_utc": "2026-01-31 10:49:38",
      "score": 21,
      "num_comments": 35,
      "upvote_ratio": 0.86,
      "text": "I‚Äôve been building with MCP across a few integrations and the pattern is pretty consistent: getting an MCP server running is straightforward, but operating tool access safely gets hard fast once you have more than a couple servers/clients.\n\nA few things that seem to become real problems earlier than people expect:\n\n1) Secrets sprawl first.\nAs soon as credentials live on the client side (agent configs, local env vars, copied tokens), you start accumulating shared keys, inconsistent scopes, and painful rotation. It‚Äôs not just a security issue, it turns into reliability and governance overhead.\n\n2) Permissions need to be tool-level, not server-level.\nMost risk is concentrated in a small set of tools (write/delete/outbound actions). Treating an entire MCP server as a single trust boundary is too coarse. You want identity-aware capability filtering per tool, ideally per user/agent/client/environment.\n\n3) Approvals are an operational control, not a UX feature.\nIf you don‚Äôt have a clean way to pause and approve a subset of high-risk calls, teams either never expose useful write tools or accept a scary blast radius. In practice you need a stop, review, continue path that‚Äôs consistent across tools.\n\n4) Audit is what makes it a system instead of a demo.\nWhen agents touch real systems, you need to answer: who invoked what, with what parameters, what policy decision was applied, and what happened. You also need to do it without leaking sensitive data into logs.\n\n5) MCP server sprawl becomes an ops problem.\nRouting, lifecycle management, quotas/rate limits, versioning, and observability become harder to solve piecemeal per server.\n\nNet takeaway: MCP lowers the cost of connecting tools, but it raises the importance of a centralized control layer for policy, secrets, approvals, and audit across every tool call.\n\nIf you‚Äôve run MCP in production, what did you centralize first? And what do you wish you had centralized earlier?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qrzade/mcp_isnt_the_hard_part_running_it_in_production_is/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2sf199",
          "author": "beckywsss",
          "text": "Nearly all the issues listed can be addressed by a gateway. Btw, lots of protocols/standards need platforms to make them work in a business:\n\n‚Ä¢ SMTP/IMAP ‚Äî> Microsoft 365, Proofpoint\n\n‚Ä¢ SAML & OAuth ‚Äî> Okta, Microsoft Entra ID\n\n‚Ä¢ Git protocol ‚Äî> GitHub, GitLab, Bitbucket\n\n‚Ä¢ APIs (HTTP/REST/gRPC) ‚Äî> Kong, Mulesoft\n\n‚Ä¢ MCP ‚Äî> [MCP Gateways](https://mcpmanager.ai/)\n\n(Full disclosure, I work at one such MCP gateway: https://mcpmanager.ai/ )\n\nTL;DR: MCP is a protocol. Not a product. You need to do work to make it ready for enterprise/to scale. \n\nGateways take care of governance and scalability issues like tool/team provisioning, reduced context bloat, containerizing local servers, alerts, audit logs, etc",
          "score": 12,
          "created_utc": "2026-01-31 13:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ynva9",
              "author": "BC_MARO",
              "text": "Agree with the protocol vs product framing. The protocol gets you interoperability, but production use still requires a bunch of operational controls (provisioning, environment separation, least-privilege, approvals for high-risk actions, and an audit trail that doesn‚Äôt leak sensitive data).\n\n(And appreciate the disclosure.)",
              "score": 3,
              "created_utc": "2026-02-01 12:53:08",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2wvcaz",
              "author": "PutPrestigious2718",
              "text": "‚Ä¶ what? \n\nThis is a terrible take, the OP highlights genuine blind spots in the protocol and your take is, mcp is fine, you just need to buy my gateway? ‚Ä¶what?\n\nSMTP and imap isn‚Äôt usable by a business unless they use office or proof point? Are you a teenager?\n\nAPIs aren‚Äôt usable by business without Kong or mulesoft?\n\n‚Ä¶ what?\n\nI‚Äôm sure your mcp gateway is very cool, vibe coded by only the best cans of monster energy. But your statement is just terrible.",
              "score": 1,
              "created_utc": "2026-02-01 03:56:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2x22yf",
                  "author": "DeLoMioFoodie",
                  "text": "i think he makes a point. plenty of protocols eventually move towards orchestration/platform systems to make management and security easier. Kubernetes is another example.",
                  "score": 1,
                  "created_utc": "2026-02-01 04:41:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2wvq70",
                  "author": "beckywsss",
                  "text": "My point was lots of protocols need products to make them scale in enterprise settings. That was the whole thrust of the post. Sorry it enraged you.",
                  "score": 0,
                  "created_utc": "2026-02-01 03:58:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3f9m2e",
              "author": "Plastic-Ad9036",
              "text": "Good Lord at least change your post title to not be the exact same tagline as the website you‚Äôre plugging.",
              "score": 0,
              "created_utc": "2026-02-03 22:17:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3fc3tu",
                  "author": "beckywsss",
                  "text": "Oh I actually updated the copy today because I liked how this person worded it. ü§∑‚Äç‚ôÄÔ∏è",
                  "score": 1,
                  "created_utc": "2026-02-03 22:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rswzw",
          "author": "speak-gently",
          "text": "Tailscale + 1Password or Setec for secrets. Tailscale ACLs for access control or tsidp for server auth. \n\nThe MCP loads secrets from setec on the Tailnet or from 1Password using the CLI. \n\nHaving said that it‚Äôs still a work in progress.",
          "score": 4,
          "created_utc": "2026-01-31 11:10:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rvd0o",
              "author": "BC_MARO",
              "text": "Thanks ‚Äî super helpful. Are you using Setec mainly as a Tailnet-accessible secrets source (service), or more as a CLI + local cache? Also curious if you‚Äôve run into any gotchas with 1Password CLI in the tool-call path (latency / rate limits / auth refresh).",
              "score": 1,
              "created_utc": "2026-01-31 11:32:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tx6tx",
                  "author": "speak-gently",
                  "text": "As a service. As for 1Password CLI we‚Äôre probably not using it heavily enough to run into issues.",
                  "score": 1,
                  "created_utc": "2026-01-31 18:25:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2snwsq",
          "author": "Knosh",
          "text": "I'm in a space where there are a handful of competitors. We sell software that has broad access to some pretty sensitive data. \n\nI'm one of the AI product engineers. The CEO the other day was looking at a product and saw that they have an MCP that they released. They're very happy and excited to shout from the rooftops that they're the first to market with an MCP in our space.\n\nBut they put no consideration for number two whatsoever. There's no awareness for who is actually asking for the data. Which in our space makes it a cool thing to look at but completely unusable by our customers. I complete non-starter on the security review front.\n\nI suspect quite a few of these MCP floating around are half baked first to market iterations.\n\n----\n\nIn general a lot of this is to a long way of saying that there is quite a gap between slapping something together and making something production ready. There's a lot of testing needed and a lot of design planning. \n\nI'm still stuck with the thought of the Claude Code lead saying he hasn't written any code in 2 months. That he's moved to a commander role over an army of agents and is now mainly coordinating the planning and debugging. \n\nI think with Opus we're still seeing incredible forward improvement, and I think entire projects at this point can be coded to production level. But without invoking a lot of the design principles you've talked about here it's absolutely useless.",
          "score": 5,
          "created_utc": "2026-01-31 14:45:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sx3y0",
              "author": "BC_MARO",
              "text": "Totally agree. A lot of \"first MCP\" implementations feel like a demo checkbox until you answer: who is the caller, what are they allowed to do, and how do you prove it (audit) without leaking sensitive data.\n\nIn your space, what tends to be the first hard blocker in customer security review: customer managed auth (SSO/SCIM), per tenant policy controls, or output level data exfiltration risk (e.g., tool results getting summarized into model context)?",
              "score": 1,
              "created_utc": "2026-01-31 15:33:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2u43oj",
          "author": "xrxie",
          "text": "We use both ‚Äúofficial‚Äù remote MCP servers and built/host some ourselves. All of them run through Barndoor.ai gateway. That stuff you said about permissions (#2) is truly tough without a gateway especially if you don‚Äôt own or run a server.\n\nOne very cool thing we can do is spawn virtual MCP servers with the gateway. So when someone says, ‚ÄúI want to build/prototype an agent that does ABC and I want to connect it to our XYZ MCP server‚Äù I can spawn a virtual MCP server with a subset of tools or policies, in a minute. No extra infra or cost. It‚Äôs cooler than I‚Äôm making it sound here. :)\n\nAgree that MCP isn‚Äôt the hardest part. Hardest part for us was to even acknowledge ‚Äúsprawl‚Äù was a thing. But every dev (and several non-dev) was just out there diddling around with every new AI client and MCP server tool they came upon. Wish we would have centralized on all of the toolset/toolchain things first.",
          "score": 3,
          "created_utc": "2026-01-31 18:58:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yndi2",
              "author": "BC_MARO",
              "text": "This resonates ‚Äî the ‚Äòvirtual MCP server‚Äô abstraction (subset of tools/policies on demand) is exactly the kind of control-plane primitive that becomes necessary once sprawl shows up.\n\nAlso +1 that the hard part isn‚Äôt standing up an MCP server; it‚Äôs getting consistent controls and operational hygiene across all the clients/servers/tools people start experimenting with.",
              "score": 2,
              "created_utc": "2026-02-01 12:49:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zuhgb",
          "author": "KeithLeague",
          "text": "I'm working on something to address these issues: [https://enact.tools](https://enact.tools)\n\nEach tool runs in a Dagger container (observability + isolation), secrets are managed externally, and tools are versioned with provenance via Sigstore.",
          "score": 2,
          "created_utc": "2026-02-01 16:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31bwu9",
          "author": "Ok_Message7136",
          "text": "\\+1 on this. We leaned toward an SDK-based setup early (using Gopher‚Äôs open-source MCP SDK) just to keep auth and tool-level permissions explicit as things scale.\n\nIn case you wanna try it, here's the link: [https://github.com/GopherSecurity/gopher-mcp](https://github.com/GopherSecurity/gopher-mcp)",
          "score": 2,
          "created_utc": "2026-02-01 20:48:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35s0go",
          "author": "pbalIII",
          "text": "Audit as the forcing function tracks. The tenant-context-through-every-layer pattern is basically row-level security for tool calls... and it composes well with the three-trust-boundary framing. One thing that's helped us: versioned policy snapshots alongside the audit log. When you're debugging a confused deputy incident six months later, knowing exactly what permissions were in effect at call time saves hours.",
          "score": 2,
          "created_utc": "2026-02-02 14:29:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3858i4",
          "author": "MoP342",
          "text": "These concerns are exactly what I'm trying to tackle by building [https://www.air-lock.ai](https://www.air-lock.ai) . The first thing I added there was Governance (Human-in-the-Loop approval), but I notice the cost-reduction also resonates with solo developers/smaller teams (did some benchmarks on that: [https://github.com/Air-Lock-AI/airlock-benchmark](https://github.com/Air-Lock-AI/airlock-benchmark) )\n\n  \nBy tracking what tools use most tokens, it should also be possible to edit their description, so agents have a better understanding of what they do and only use them in certain scenarios, rather than unsollicited increasing your token burning (e.g. list\\_issues in the Linear MCP uses like 20k tokens, which gets costly fast when agents try to call it unneeded).\n\n  \nSo I think concerns greatly differ by which group of people you are talking to. For solo-devs/small teams/startups, I think cost (or by extension context limiting and thus increasing speed) is more important than the actual security. But obviously, larger companies are (and should be) more concerned with agents wiping their production systems.",
          "score": 2,
          "created_utc": "2026-02-02 21:09:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2u8mpw",
          "author": "owlpellet",
          "text": "Governance, rate limits, bookkeeping and observability is external to the networking protocol. You should probably do those though.\n\n[https://konghq.com/solutions/mcp-governance](https://konghq.com/solutions/mcp-governance)",
          "score": 1,
          "created_utc": "2026-01-31 19:19:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yn7en",
              "author": "BC_MARO",
              "text": "Yep ‚Äî totally agree. Governance, quotas/rate limits, and observability live above the wire protocol.\n\nAppreciate the Kong link ‚Äî it‚Äôs a good reference point for what teams end up needing once MCP moves past a demo and into production operations.",
              "score": 1,
              "created_utc": "2026-02-01 12:48:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xdmgf",
          "author": "Mediocre-Abroad6083",
          "text": "Of the five issues listed, #3 (Approvals) and #4(Audit) should primarily happen at the level of the platform consuming the MCP servers. They are not MCP-level problems. The same issues exist with any protocol used to connect from an agentic system to other business applications. And the context needed for approvals and for meaningful audit is broader in scope than any one MCP server or tool call. Of course, an MCP Gateway handling outbound MCP traffic from the agent clients can provide meaningful observability, but that's not the same as a meaningful audit.   \nIssue #2 (Permissions) -- here you raise a really interesting point. The protocol chooses to do permissions based on user identity. The latest MCP spec mandates OAuth2.1 as the auth method. This makes sense for systems with end user accounts. Since OAuth has scope definitions custom to each auth provider (eg: read\\_only, read\\_write), it can inherit the same mechanisms that have been built over the years for API permissioning. This seems sensible to me. If API keys are being used, many systems also have the ability to treat these like service accounts with scoped capabilities.  \nIf you have many clients and a few MCP servers, then issue #1 (secrets sprawl) is a problem. But not if you are using OAuth2.1 for your MCP server (no API keys being distributed anywhere). From my perspective, the MCP protocol is solving this problem via OAuth2.1 with DCR/PKCE.  \nIf you've got AI agents running automation and connecting to many MCP servers, then I'd focus on issue #5 (MCP server sprawl). In our company, [Thunk.AI](http://Thunk.AI), that's been what we centralized first. That's because we're deploying an AI automation platform in an enterprise environment. Strong requirement to have controls over whose AI agents connect to which business applications, separation of dev/test/prod environments with different keys, rate limiting, token consumption metrics tracking, etc. Our agentic automation service sends all outbound agentic traffic through an AI Gateway (we use a self-hosted instance of LiteLLM). The agentic automation service is responsible for approvals, audits, subsetting tools, overall AI agent reliability and orchestration. The AI gateway is an admin control point and responsible for protocol-level traffic management. As an aside, we see some AI gateways mixing protocol/traffic-level functionality with higher-level semantic functionality (guardrails, agents, etc) and think that's a very bad idea. But that's a whole other topic.",
          "score": 1,
          "created_utc": "2026-02-01 06:06:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ymx8j",
              "author": "BC_MARO",
              "text": "Appreciate the thoughtful breakdown ‚Äî especially the distinction between protocol-level observability vs. true audit/approval context (which tends to live above any single MCP server call). The point about OAuth2.1 reducing key distribution where it‚Äôs available is also well taken.\n\nIn practice we still see a long tail of API keys/service accounts and mixed auth modes across tools, and that‚Äôs where a centralized control layer (inventory/sprawl management, per-env separation, and consistent policy enforcement) tends to pay off.\n\nCurious: in your setup, where do you draw the line between the AI gateway‚Äôs responsibilities (traffic/metrics) vs. the automation platform‚Äôs responsibilities (policy + HITL + audit export/reporting)?",
              "score": 1,
              "created_utc": "2026-02-01 12:46:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30soqs",
                  "author": "Mediocre-Abroad6083",
                  "text": "Yes I agree, in the current moment, there is a long tail of API keys and I suspect it will take a while for this to go away if ever, because API keys are so much easier to understand and implement at the moment than OAuth2.1 with dynamic registration.  \nOur general guiding principle that the platform needs to have a set of capabilities for the automation developer and set of a capabilities for the IT admin. The latter will get implemented as a platform service that acts as an AI gateway.   \nIt is not yet clear how tightly coupled the platform and the gateway need to be. As an analogy, in pre-AI apps, the application platform is agnostic to the API gateway and vice versa. But the API gateway tends to do very low level things that need zero application semantics. The needs of the AI gateway are still fuzzy and it might well be that it needs to be closer to the application platform.",
                  "score": 1,
                  "created_utc": "2026-02-01 19:15:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rukff",
          "author": "thys123",
          "text": "MCP's are over. Bloats context window. Skills is the new MCP, can be called for specific tasks",
          "score": -1,
          "created_utc": "2026-01-31 11:25:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sagns",
              "author": "Equivalent_Hope5015",
              "text": "You're hilarious. Thats not even the same thing at all, they do not solve the same context challenges. Skills are not composable, and good luck getting any real security out of skills.",
              "score": 7,
              "created_utc": "2026-01-31 13:26:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2u7job",
              "author": "xrxie",
              "text": "It‚Äôs not so zero sum. SKILLS.md, AGENTS.md (generally referencing) and can help with improving context and thus accuracy. But saying that MCP is over is definitely not true for many a business out there that require access control and monitoring. \n\nRegarding bloat ‚Äî there are advanced being made on tool selection side so that your context windows aren‚Äôt blowing up. Anthropic has Tool Search Tool (https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool) so you‚Äôre not loading up every MCP server and tool into your window. Barndoor has ToolIQ (https://barndoor.ai/introducing-tooliq-mcp-tool-optimization/). Worth staying on top of this and not saying ‚ÄúX is dead.‚Äù Far from it.",
              "score": 2,
              "created_utc": "2026-01-31 19:14:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2u9nfd",
              "author": "owlpellet",
              "text": "\"MCPs\" as a plural noun is a tell that someone can't differentiate a networking protocol from a resource.",
              "score": 2,
              "created_utc": "2026-01-31 19:24:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2znu7j",
                  "author": "xrxie",
                  "text": "Funny you mention this. Couple days ago, got a message from friend who referred to two of his MCP servers just as ‚Äúmy MCPs‚Ä¶‚Äù and I had an adverse reaction (internally). Mind you, he‚Äôs a super experienced principal level architect and still a hardcore dev. I imagine if he were writing more formally, like a paper or postmortem, he‚Äôd refer to them as ‚ÄúMCP servers.‚Äù At least I hope. (sorry, MT, if you‚Äôre reading this)\n\nCan‚Äôt think of another example off the top of my head. DNS server. SSH server. SQL server.",
                  "score": 1,
                  "created_utc": "2026-02-01 16:10:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ryxvx",
              "author": "Electronic_Budget468",
              "text": "What are skills?",
              "score": 1,
              "created_utc": "2026-01-31 12:02:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2u98jg",
                  "author": "owlpellet",
                  "text": "A branded version of tool calling favored by Anthropic users. The comparison is Facebook vs HTTP.",
                  "score": 2,
                  "created_utc": "2026-01-31 19:22:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wvqar",
          "author": "PutPrestigious2718",
          "text": "Your points are very valid OP and every vibe ceo is shilling the crap out of their mcp gateway, like locusts.\n\nMCP was a rush because it was easy to build tooling, but has lethal flaws.",
          "score": -1,
          "created_utc": "2026-02-01 03:58:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yn27h",
              "author": "BC_MARO",
              "text": "Appreciate the perspective. I‚Äôm not anti-gateway ‚Äî just skeptical of the idea that a gateway alone makes this safe/operable.\n\nThe stuff that tends to matter in production is still least-privilege at the tool/action level, a clean pause/review/continue path for high-risk operations, and audit trails that don‚Äôt leak sensitive data.\n\nWhen you say MCP has ‚Äúlethal flaws‚Äù, which specific failure modes have you seen bite first in practice (permissions/authZ, trust boundaries, lifecycle/session behavior, auditability)? Concrete examples would be really helpful.",
              "score": 2,
              "created_utc": "2026-02-01 12:47:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqior0",
      "title": "I built a playground to test MCP + Skills Pairing",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/gallery/1qqior0",
      "author": "matt8p",
      "created_utc": "2026-01-29 19:38:23",
      "score": 20,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqior0/i_built_a_playground_to_test_mcp_skills_pairing/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2gvr7y",
          "author": "matt8p",
          "text": "Skills + MCP is still a fairly new concept. I would love to hear your opinions on MCP with Skills. \n\nIf you're interested in reading more about the new features we put out, I encourage you to read the blog below!\n\n[https://www.mcpjam.com/blog/skills](https://www.mcpjam.com/blog/skills)",
          "score": 3,
          "created_utc": "2026-01-29 19:41:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2gyuq4",
              "author": "Bobification",
              "text": "This is interesting timing...we have an MCP server in front of our GraphQL api and Claude consistently fails at using the right query and params despite running a schema check first.  Instead of making an attempt to make better tools, management has (just this morning) suggested we use skills to explain to Claude how to use our MCP server.  I'm not yet convinced that we should go that route ourselves but maybe at least we can attempt to test that here.",
              "score": 3,
              "created_utc": "2026-01-29 19:56:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h2e9e",
                  "author": "matt8p",
                  "text": "I'd start off by being more descriptive in the tool descriptions / tool param descriptions, or the MCP server instructions. This could give better context to Claude on how to use the server. \n\nHaving skills is nice, but the only downside is that it's not attached / bundled with the MCP server. It's loaded separately. Try tweaking the server itself first, then if that doesn't work, use the skill.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:13:11",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o2h2nxh",
                  "author": "matt8p",
                  "text": "On a tangent, I'd wish Anthropic encourage use of MCP prompts more rather than push for MCP + Skills. You can have skills be loaded up in the prompt so they're bundled together. This would accomplish the same thing.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:14:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qritks",
      "title": "Is Sequential Thinking MCP still a thing?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qritks/is_sequential_thinking_mcp_still_a_thing/",
      "author": "ShaneIGucci",
      "created_utc": "2026-01-30 21:35:40",
      "score": 17,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Does anyone else still use Sequential Thinking MCP with Opus 4.5?\n\nI‚Äôve been using Opus 4.5 for planning and it‚Äôs been insanely reliable. But here‚Äôs the thing‚ÄîI still manually ask Claude to trigger Sequential Thinking MCP out of habit, even though I‚Äôm not sure it actually improves the output.\n\nHas anyone else noticed this? I can‚Äôt really tell the difference in quality between answers with and without it. At this point, it feels like a placebo effect‚Äîmaybe I‚Äôm just stuck in my old workflow.\n\nShould I just drop the MCP prompt and trust Opus 4.5 fully? Or am I missing something? Would love to hear your experiences!",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qritks/is_sequential_thinking_mcp_still_a_thing/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2p8khn",
          "author": "TokenRingAI",
          "text": "In our coding app, we built around 10 different versions of sequential thinking, such as scientific method, socratic method, feynman principles, decision matrix, the original sequential thinking, working step by step, and quite a few more, and saw no measurable performance increase, even with small models.\n\nThey make the LLM look smarter but the results were the same or maybe worse, slower, more tokens.\n\nYou can see some of them here, if you are interested in what has been tried and did not work:\nhttps://github.com/tokenring-ai/thinking/tree/main/tools\n\nThe only thing that showed a clear benefit, was the under-appreciated append-only TODO list that is standard in most agents these days",
          "score": 12,
          "created_utc": "2026-01-30 23:52:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pitii",
          "author": "DasBlueEyedDevil",
          "text": "I find that just using plan mode first functions better than sequential thinking ever really did",
          "score": 4,
          "created_utc": "2026-01-31 00:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oszry",
          "author": "deafpigeon39",
          "text": "Massively increases the output when i need the agent to properly plan my request , asking them to use it before doing something makes them overthink mostly.",
          "score": 1,
          "created_utc": "2026-01-30 22:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3d2t6n",
          "author": "Jdonavan",
          "text": "The 'think' tool from Anthropic has always been better than the sequential thinking MCP.",
          "score": 1,
          "created_utc": "2026-02-03 16:13:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ojw74",
          "author": "Nice_Profession_9078",
          "text": "I have my own tool built that even records and embeds it's thought chains, it can reopen them and branch, can't back out until over 90% confident or the last thought is reached, extremely useful.",
          "score": 0,
          "created_utc": "2026-01-30 21:44:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr1e2y",
      "title": "I built an MCP server to explore Epstein's emails. Here's what I learned about mcp-use",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qr1e2y/i_built_an_mcp_server_to_explore_epsteins_emails/",
      "author": "GIOSCOP",
      "created_utc": "2026-01-30 10:01:17",
      "score": 14,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "When I wanted to test mcp-use (9k+ stars on GitHub), I needed a dataset spicy enough to keep me awake. Enter: 2322 Epstein emails. What followed was an afternoon of hot module reloading, CSP hell, and discovering OpenAI silently requires Plus to use custom apps.\n\n# What I needed\n\n* Basic dependencies (e.g. Node)\n* A `mcp-use` [cloud account](https://mcp-use.com/signup) to host the server (currently free)\n* ChatGPT *Plus* subscription - more on this later\n* Epstein's emails: `https://www.docetl.org/api/epstein-emails`\n\n# Setup\n\nGetting started was trivial. `npx create-mcp-use-app mcp-demo` scaffolds a demo project - I used the `mcp-apps` preset to have both OpenAI Apps SDK integration and a standard MCP server.\n\nThen, a `npm run dev` is enough to see and debug tools (both classic and UI Widgets) thanks to the inspector. This is bundled and starts automatically: a very convenient way to test.\n\n# Development\n\nDeveloping with `mcp-use` is very straightforward. The inspector (paired with HMR, aka \"hot module reload\") makes iterating VERY fast. However, I had a few minor issues with it:\n\n* The setting CSP to \"Declared\" leads to a violation even in the starter template\n* \"Hover: Disabled\" doesn't actually disable hover effects\n* Sometimes, especially when dealing with UI elements, it glitches out - a reload is usually enough\n\nThe library itself abstracts away all of the boilerplate and makes the code concise, for both tools and UI elements. You're writing only the bare minimum: title, description, schema and logic. It feels like what Stripe did for payments, but for tool definitions.\n\nThe best part is that the Model Context Protocol, being very new, hasn't crystallized yet - and you don't have to care. By using a library you're guaranteed to always be compliant and compatible - for example, I imagine Anthropic/Google creating their own variants for UI components.\n\nThe only major issue I had with the library was related to CSP (content security policy): it was not whitelisting the server's domain `fetch` requests. After a few hours of debugging I was ready to open an issue, only to find it already resolved in a development branch by a maintainer (props to Enrico). To quickly patch the issue I hardcoded the CSP `connectDomains` urls and used the PR's canary build: `npm i https://pkg.pr.new/mcp-use/mcp-use@911`. However, I'm sure that by the time you read this it will be already merged.\n\n# Deployment\n\nDeploying using `mcp-use`'s cloud offering is super straightforward: `npm run deploy` takes care of everything. It guides you through login, GitHub repo access, verifies your commits are pushed and finally shows the stream of remote build logs.\n\nIt's also nice that they provide documentation on how to self-host (and even made specific helpers) so vendor lock-in is not an issue. However, I'd still choose their version as it's tailor-made and shows interesting mcp-specific metrics (e.g. client breakdown).\n\nGiven the CSP issue I needed a \"double deploy\" to hardcode the production URL in the widgets code; build environment variables are available but they didn't work consistently for me.\n\n# Testing on ChatGPT\n\nWhen it came time to test, I happily headed to ChatGPT to add my server. It should be easy: Account -> Settings -> Apps -> Advanced Settings -> Enable Dev Mode -> Apps -> Create App.\n\n*However*, after adding the URL and everything, the app wasn't there. After way too much time I found out that the Free Plan doesn't allow you to add custom apps \\[[1](https://community.openai.com/t/chatgpt-apps-sdk-not-creating-a-custom-app-on-my-account/1369338/7), [2](https://help.openai.com/en/articles/11487775-apps-in-chatgpt)\\] (no warnings whatsoever). This might change in the future so before upgrading take a look.\n\n>Disclaimer: This is not the library's fault, but rather a rant against OpenAI\n\nSo, I had to buy the Plus version (luckily by signing up with a custom domain email I got a month free). While developing, make sure to hit \"refresh\" in the app's section if you make any changes.\n\n# TL;DR\n\n`mcp-use` = Rails for MCP. You write actual logic, boilerplate is handled. Few bugs, nothing blocking. *Use* it.\n\n**Try it yourself:** [https://lively-poetry-gt8c1.mcp-use.run/mcp](https://lively-poetry-gt8c1.mcp-use.run/mcp)\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qr1e2y/i_built_an_mcp_server_to_explore_epsteins_emails/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2pmgrf",
          "author": "SS2907",
          "text": "You sir/maam have won the internet today.",
          "score": 2,
          "created_utc": "2026-01-31 01:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r26lk",
              "author": "GIOSCOP",
              "text": "‚ù§Ô∏è",
              "score": 3,
              "created_utc": "2026-01-31 06:59:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3cxd52",
          "author": "Jarmsicle",
          "text": "The details of MCP are the less interesting bits in my opinion. How did you index the data?",
          "score": 1,
          "created_utc": "2026-02-03 15:47:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ecb3a",
              "author": "GIOSCOP",
              "text": "Since the dataset was around only 2.5k emails (a 16MB JSON) they're actually just stored in memory, with some hash maps.  \nIt's the first few lines of index.ts if you wanna check it out",
              "score": 1,
              "created_utc": "2026-02-03 19:41:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqk0j3",
      "title": "Have I understood MCP correctly?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "author": "DoNotBelieveHim",
      "created_utc": "2026-01-29 20:26:52",
      "score": 12,
      "num_comments": 12,
      "upvote_ratio": 0.94,
      "text": "My understanding of MCP is that I can publish details about what my REST API does, what each end point can do (\"This is for creating new clients\", \"This gives a list of overdue tasks for the current user\") and how to use the endpoints (JSON payload looks like this. \n\nBasically a subset of whats already in my OpenAPI Spec (swagger.json) with some natural langauge explanations of whats there.\n\nThis then enables LLMs to take user input in natural language (\"Create a new client call John\", \"Whats on my plate today?\") to then take actions on my server via the REST API\n\nIs that anywhere near correct or am I missing something important?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2ha2vg",
          "author": "guyernest",
          "text": "Your swagger file and other OpenAPI specs were designed for developers to use to call the API. Each developer reviewed the schema and decided what they wanted to use for their use case. You don't expect every developer to use every API call for every application.   \nAn MCP server, such as an API, can take two extreme approaches: either implement a couple of tools or allow \"code mode\". The former is similar to human developers who know what they need from the API and use only that, while the latter allows the LLM in the MCP client the freedom to call any API in any sequence.   \nMy advice is to take the middle ground and wrap a couple of the APIs as tools, based on the Pareto principle: 80% of calls will use 20% of the API. For the long tail of requests, you should enable a \"Code mode\" that provides the API schema and allows the MCP client to generate calls as needed to answer user requests.   \nThere are many security concerns for the \"Code mode\", but we some attention, you can build it safely.   \n",
          "score": 6,
          "created_utc": "2026-01-29 20:50:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hdyxe",
              "author": "DoNotBelieveHim",
              "text": "Thanks. Useful. Then it sounds like I‚Äôve not missed anything, other than that you can choose to be selective/prescriptive in how the API should be used. \n\nRe the security concerns, if the user of the LLM is authenticating themselves and has a token which the MCP uses to call the API - what are the security concerns beyond the regular concerns you‚Äôd have if a user was posting requests directly to the API? I assume you‚Äôd just pass through the bearer header or whatever you are using so the authorisation would be the same so I don‚Äôt see how the MCP could introduce new security risks.",
              "score": 1,
              "created_utc": "2026-01-29 21:09:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2huc8s",
                  "author": "guyernest",
                  "text": "MCP is an interface to your data, and it should be protected against two main types of risks: LLM mistakes and malicious users. A simple example is the option to delete data, or, less obviously, to update it. Once the user is authenticated, the MCP client stores the access token, and the MCP client can do everything that the user can do.   \nIf you only select the listUsers and getUser APIs (read-only) as MCP tools, there is not much risk that the MCP client will do anything else. However, if you also allow updateUser, the MCP client can now update the user record and grant them an unwarranted discount, for example. The MCP client typically doesn't display the full details of each call it makes to the MCP server, making it easy for users to miss such changes. Also, users might remember to log out of a sensitive website, but they will not remember to disconnect the MCP server from their ChatGPT. Therefore, a malicious user can use the MCP client connection to the MCP server and, through it, to the API to perform harmful actions on the data system. ",
                  "score": 3,
                  "created_utc": "2026-01-29 22:27:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2lrs4a",
              "author": "Melodic-Swimmer-4155",
              "text": "Really good explanation there m8!",
              "score": 1,
              "created_utc": "2026-01-30 14:05:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hlkne",
          "author": "naseemalnaji-mcpcat",
          "text": "You're basically on the right track! MCP lets you describe your API's endpoints and expected behaviors in a way that's accessible to LLM-powered agents, often with a mix of structured data and natural language. While it overlaps with OpenAPI, MCP is more focused on making your API explorable and actionable by AI agents rather than human eyeballs. One key difference is that MCP emphasizes clarity and intent in descriptions, which helps reduce ambiguity for AI.",
          "score": 5,
          "created_utc": "2026-01-29 21:45:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2igw9o",
          "author": "laresek",
          "text": "Kinda except MCP doesn't use REST/Swagger and instead uses JSON-RPC 2.0. Instead of many endpoints like in REST there's only one endpoint that's used and the payload has a method and parameters that are passed along with it. There's some info here:\n https://modelcontextprotocol.io/specification/2025-03-26/basic",
          "score": 2,
          "created_utc": "2026-01-30 00:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jiyak",
          "author": "Sufficient_Waltz4299",
          "text": "here is a video that explains this really well - [https://youtu.be/Eq21IF54VuE](https://youtu.be/Eq21IF54VuE)",
          "score": 2,
          "created_utc": "2026-01-30 03:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ovbf1",
          "author": "pbalIII",
          "text": "Wrapped an internal CRUD API with MCP a few months back. The mental shift was subtle but real: OpenAPI tells developers how to call endpoints, MCP tells agents why and when to use them.\n\nOne gotcha we hit... the model kept trying to chain writes together in ways that made sense semantically but violated business rules. Ended up having to add explicit constraints in tool descriptions, not just input schemas. The reasoning layer is powerful but it needs guardrails you wouldn't think to add for human devs.\n\nThe auth question in the comments is worth digging into. MCP clients hold tokens persistently, so the blast radius of a compromised session is bigger than a user forgetting to log out of a browser.",
          "score": 2,
          "created_utc": "2026-01-30 22:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2klip6",
          "author": "Ordinary-You8102",
          "text": "Yes the important thing is that its a protocol (standard) so any agent that is also a mcp client will be able to connect to any MCP throughout the world (single implementation and not 1 for each Agent) \nit solves the N * M problem",
          "score": 1,
          "created_utc": "2026-01-30 08:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lh5zv",
          "author": "BC_MARO",
          "text": "Mostly yes. MCP is basically a standard way for an agent/client to talk to ‚Äútool servers‚Äù (DB/search/files/APIs) over a defined protocol (stdio/HTTP).\n\nOne practical gotcha: auth/secrets + timeouts/retries end up being the real work.\n\n(I maintain it.) Reference/checklist (peta): [https://github.com/dunialabs/peta-core](https://github.com/dunialabs/peta-core)",
          "score": 1,
          "created_utc": "2026-01-30 13:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2xac1f",
          "author": "Mediocre-Abroad6083",
          "text": "OP, your general understand is correct. The various comments are also spot-on. I've had to both build MCP servers and use them. There's some things to consider:  \n \\*) There's parallels between API design and MCP design. You have to choose the level of abstraction. Often an API (especially a REST API) is at the level of the entity model of the application database. Each entity has an id and that becomes one uri in the REST API with get and update methods. REST has some stylistic guidelines that steer in this direction. MCP doesn't. You can make anything you want an MCP tool. That said, many MCP servers are 1:1 wrappers over REST APIs  \n \\*) Why 1:1 -- because many of the people/companies building MCP servers are not doing it specifically for one application. And it is relatively straightforward to reflect over an OpenAPI spec and produce an MCP equivalent. This of course leads to all the concerns listed in the comments about \"code mode\" (and there's many more concerns than just what's listed)  \n \\*) One difference between MCP and REST APIs is that MCP can be stateful. For example, an MCP server over a file system can have two tools: find\\_spreadsheet and open\\_spreadsheet. If the MCP client calls open\\_spreadsheet, then the MCP server can dynamically provide tools like lookup\\_value\\_in\\_sheet. Many MCP servers don't bother and just provide stateless tools. But it is one of the powerful features of an MCP server  \n \\*) Using an LLM to chain low-level API calls is possible, but if the chaining is deterministic, you're always better off (just for reliability) to let code do the deterministic part of the work. You can put this code inside your MCP server, or it could be generated outside your MCP server (the agent could do code-gen, for example).  \n \\*) As for filtering the set of tools available, you may not need to do this at the MCP server. But most systems that consume an MCP server also have mechanisms to list the exported tools and disable some of them.   \n \\*) There are some other issues related to AI reliability if your MCP server is being used in automated agent scenarios. This article talks about some of them .. https://pravse.medium.com/the-mcp-mess-and-how-to-solve-it-7a479b31fa11.",
          "score": 1,
          "created_utc": "2026-02-01 05:41:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu3hal",
      "title": "I built a professional network that lives inside AI conversations (using MCP Apps)",
      "subreddit": "mcp",
      "url": "https://v.redd.it/58qg2m8ll4hg1",
      "author": "PlanePuzzleheaded167",
      "created_utc": "2026-02-02 18:37:41",
      "score": 11,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qu3hal/i_built_a_professional_network_that_lives_inside/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o37m7sa",
          "author": "Ok_Revenue9041",
          "text": "Love the concept of Nod, especially since AI first networking is such a clear future shift. To really stand out as AI agents start recommending profiles and content, focusing on how your data is surfaced to LLMs can make a difference. Had good results with MentionDesk for making content more AI discoverable, worth checking out as you grow the network.",
          "score": 2,
          "created_utc": "2026-02-02 19:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39hypd",
          "author": "highpointer5",
          "text": "Cool!",
          "score": 2,
          "created_utc": "2026-02-03 01:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39jjyh",
          "author": "BC_MARO",
          "text": "Interesting approach‚Äîembedding networking directly into AI workflows instead of a separate app. If you're thinking about access control or audit down the line, Peta might be worth a look. https://peta.io",
          "score": 2,
          "created_utc": "2026-02-03 01:32:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dfpoa",
          "author": "Ok_Message7136",
          "text": "Interesting direction .. MCP Apps + interactive UIs make a lot of sense for agent-native networks where profiles are meant to be queried, not scrolled",
          "score": 2,
          "created_utc": "2026-02-03 17:12:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o378txk",
          "author": "PlanePuzzleheaded167",
          "text": "[https://www.joinnod.com/](https://www.joinnod.com/)",
          "score": 1,
          "created_utc": "2026-02-02 18:38:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu8yt1",
      "title": "MCP standards more of a suggestion",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qu8yt1/mcp_standards_more_of_a_suggestion/",
      "author": "48K",
      "created_utc": "2026-02-02 21:53:26",
      "score": 10,
      "num_comments": 23,
      "upvote_ratio": 0.86,
      "text": "Excited to carefully implement an MCP server that follows the specs and tries to take account of best practice only to find that Claude.ai doesn‚Äôt even read the initial \\*instructions\\* field or any of the \\*resources\\*. It only cares about \\*tools\\*; and this is a standard Anthropic wrote!\n\nFeels like lots of teams at Anthropic (and in other companies) working independently with little coordination. Perhaps it‚Äôs the price we pay for moving fast. \n\nClaude agrees it‚Äôs bad and suggested I raise it with Anthropic üòÇü§∑‚Äç‚ôÇÔ∏è",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qu8yt1/mcp_standards_more_of_a_suggestion/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o38fht7",
          "author": "dbizzler",
          "text": "Claude Code (and pretty much every other MCP client) doesn't support notifications/tools/list\\_changed either. So right now even parts of the tools spec isn't fully implemented. We might find that the MCP spec was over-engineered with things that are never going to be used in the real world.",
          "score": 4,
          "created_utc": "2026-02-02 21:57:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o39i4pu",
              "author": "AchillesDev",
              "text": "> notifications/tools/list_changed\n\nThere are a few reasons for this. 1 is that a lot of groups rushed out half-assed clients when MCP was first released and didn't bother to maintain them. The other is that the SDKs don't even have full protocol compliance. I've had a PR in for months now to fully support notifications via callbacks in the Python SDK, but there's very little movement (if any at all) on merging spec compliance PRs or really PRs that are contributed by the community. I've offered to help with code review in the dev discord when that issue was brought but haven't really heard anything. They seem swamped.",
              "score": 1,
              "created_utc": "2026-02-03 01:24:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38ggsu",
          "author": "themightychris",
          "text": "the poor adoption of server-level instructions is really frustrating, esp in Anthropic's clients",
          "score": 3,
          "created_utc": "2026-02-02 22:02:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38i9mt",
              "author": "48K",
              "text": "Without the instructions Claude blunders around in my API and works things out eventually, but it‚Äôs painful to watch and burns unnecessary tokens.",
              "score": 2,
              "created_utc": "2026-02-02 22:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38toso",
                  "author": "themightychris",
                  "text": "yeah and your only recourse is to pile redundant instructions into every single tool which bloats context and often confuses it more",
                  "score": 2,
                  "created_utc": "2026-02-02 23:09:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o398hu8",
          "author": "Block_Parser",
          "text": "Claude code and desktop supports it, but not Claude.ai :(\n\nhttps://modelcontextprotocol.io/clients#claude-code",
          "score": 3,
          "created_utc": "2026-02-03 00:30:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b2l2l",
              "author": "48K",
              "text": "Interestingly that list says that claude.ai supports resources, but I can't find any evidence of that from within the tool. No chat sessions are able to access information in resources even if I ask it explicitly to load them in.",
              "score": 2,
              "created_utc": "2026-02-03 07:55:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o38gp31",
          "author": "parkerauk",
          "text": "Before doing anything create a session starter file for Claude to read (share path) and abide by. Even tell it today's date.",
          "score": 2,
          "created_utc": "2026-02-02 22:03:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38hd6d",
              "author": "48K",
              "text": "Isn‚Äôt that what the instructions field is? Not sure where else I could tell clients to read a file - am I missing something? Claude even called it a chicken-or-the-egg problem, which tickled me.",
              "score": 2,
              "created_utc": "2026-02-02 22:06:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38tt6w",
                  "author": "parkerauk",
                  "text": "No, instructions are general. Let's say you have 20 MCPs. For different projects. Create a session starter (txt file) for each and load it when you need. Else Claude has bloat and tries to do everything at once.\n\nSession starter will include all the intelligence needed to know where you left off last time, file locations, backlog info that specific instructions and more.",
                  "score": 1,
                  "created_utc": "2026-02-02 23:10:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3d8viw",
          "author": "Ok_Message7136",
          "text": "Agreed, MCP reads like a standard, but behaves more like guidance in real-world clients. Server implementations have to defensively adapt to what clients actually consume.",
          "score": 2,
          "created_utc": "2026-02-03 16:41:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dgbub",
          "author": "rbonestell",
          "text": "Hah! The \"Claude agrees it's bad\" part is perfect.\n\nI've hit this exact wall building an MCP server for code intelligence. The spec has these nice concepts; `instructions`, `resources`, `prompts`, and then you discover each client implements a different subset. Claude basically only sees `tools`. Claude Code handles more. Cursor has its own quirks. It's the classic \"standard\" that's more of a menu.\n\nWhat I've landed on is to design for the lowest common denominator (`tools` only), then treat everything else as progressive enhancement. If your server *requires* `resources` to function, you're going to have a bad time with half the clients out there.\n\nI couldn't agree more, it's incredibly frustrating that Anthropic wrote the spec but doesn't adhere to it! You'd expect their own products to be the reference implementation. Instead we're all reverse-engineering what actually works.\n\nHowever, MCP is still early and the ecosystem is moving fast. I'm hopeful the clients converge, but for now I'm just building defensively and testing against multiple clients before assuming anything works.\n\nWhat were you trying to use `instructions` and `resources` for? Curious if there's a tools-only workaround for your use case.",
          "score": 2,
          "created_utc": "2026-02-03 17:15:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dpiut",
              "author": "48K",
              "text": "I'm glad it's not just me! I was prototyping against Claude Code and ended up with a pattern like this for the instructions and resource files that was reliably pulled into context at the right times.\n\nInstructions Text\n\n    # The Monkey Tennis MCP\n    This server is where your monkeys can play tennis for fun and profit.\n    ## Terminology\n    - **Monkey** the talent. Also known as: players, contestants\n    - **Tennis** the sport they play. Also known as: the game\n    ## IMPORTANT: Read resources before using tools\n    **Before searching for monkeys** you must read resource monkeytennis://resources/monkey-see\n    **Before starting a game** you must read resource monkeytennis://resources/game-management\n\nAnd then the linked resources are just markdown files in a similar vein that give a steer on which tools to call and canonical examples of use.",
              "score": 1,
              "created_utc": "2026-02-03 17:57:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3dszjd",
                  "author": "rbonestell",
                  "text": "I did something similar with instructions referencing and re-iterating reading of the resources! This gave me the most consistent performance across models, but naturally it isn't flawless.",
                  "score": 1,
                  "created_utc": "2026-02-03 18:13:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o39hicy",
          "author": "AchillesDev",
          "text": "Why are you using remote Claude with MCP? Use Claude Code, desktop, or even better, write your own client and use the API. Tool instructions are a standard part of the claude messages API.",
          "score": 1,
          "created_utc": "2026-02-03 01:20:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b01zz",
              "author": "48K",
              "text": "The MCP I'm writing isn't for me to use, it's for non-engineers who want to access our services through whatever AI client they happen to be using (Claude web, CoPilot, ChatGPT, etc...). Yes, Claude Code is a very well behaved client and reads the instructions and all the resources, but unfortunately they aren't using it.",
              "score": 1,
              "created_utc": "2026-02-03 07:31:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o39hpsj",
          "author": "highpointer5",
          "text": "Honestly the protocol should have started with the simplest possible primitive and grown organically from there. I say this from a place of having made this mistake a thousand times, but MCP is ridiculously over-engineered for the moment, and premature optimization is the root of all evil.",
          "score": 1,
          "created_utc": "2026-02-03 01:22:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3blfrm",
              "author": "makinggrace",
              "text": "True. Models are going to force tools to be the primitive whether we like it or not.",
              "score": 2,
              "created_utc": "2026-02-03 10:55:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39jcc7",
          "author": "BC_MARO",
          "text": "Yep, noticed the same thing. Claude Web ignores instructions/resources entirely‚Äîonly tools get through. Desktop app at least reads resources. Feels like different teams shipping independently without syncing on the spec.",
          "score": 1,
          "created_utc": "2026-02-03 01:31:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bl9hc",
          "author": "makinggrace",
          "text": "I have just been adding a tool called schema_mymcpname to my mcps. Calling that tool returns instructions. This works okay with frontier models but I haven't tested beyond that.",
          "score": 1,
          "created_utc": "2026-02-03 10:54:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpn0d5",
      "title": "LAD-A2A: How AI agents find each other on local networks",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "author": "franzvill",
      "created_utc": "2026-01-28 20:29:18",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.85,
      "text": "AI agents are getting really good at doing things, but they're completely blind to their physical surroundings.\n\nIf you walk into a hotel and you have an AI assistant (like the Chatgpt mobile app), it has no idea there may be a concierge agent on the network that could help you book a spa, check breakfast times, or request late checkout. Same thing at offices, hospitals, cruise ships. The agents are there, but there's no way to discover them.\n\nA2A (Google's agent-to-agent protocol) handles how agents talk to each other. MCP handles how agents use tools. But neither answers a basic question: how do you find agents in the first place?\n\nSo I built LAD-A2A, a simple discovery protocol. When you connect to a Wi-Fi, your agent can automatically find what's available using mDNS (like how AirDrop finds nearby devices) or a standard HTTP endpoint.\n\nThe spec is intentionally minimal. I didn't want to reinvent A2A or create another complex standard. LAD-A2A just handles discovery, then hands off to A2A for actual communication.\n\nOpen source, Apache 2.0. Includes a working Python implementation you can run to see it in action. Repo can be found at franzvill/lad.\n\nCurious what people think!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2b0ei3",
          "author": "Upstairs_Safe2922",
          "text": "Interesting stuff! Will it automatically connect or will need human final approval? Follow up, can something that was already on the network connect to the agent unprompted?",
          "score": 1,
          "created_utc": "2026-01-28 22:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2djyd9",
              "author": "franzvill",
              "text": "Human approval always required! Discovery is passive (just shows what's available), but connecting requires explicit user consent. \n\nNothing can connect to your agent unprompted as it's client-initiated and consent-gated by design. If you are curious, you can see Section 4.3 of the spec:\n\n[https://lad-a2a.org/](https://lad-a2a.org/)\n\n[https://github.com/franzvill/lad](https://github.com/franzvill/lad)",
              "score": 2,
              "created_utc": "2026-01-29 08:12:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qsafrs",
      "title": "Sharing MCP Gateway: run MCP in production on top of existing systems",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qsafrs/sharing_mcp_gateway_run_mcp_in_production_on_top/",
      "author": "kduman",
      "created_utc": "2026-01-31 18:40:47",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 0.85,
      "text": "About 4 months ago I was working on a side project - a Telegram chat agent. I had a Telegram Bot API that I'd built a while back, running as a plain HTTP server. So what I wanted is to re-expose some of those API methods as MCP tools and give them to my agent I was working on.\n\nThe thing is, I didn't want to give the agent access to everything. Just a few specific methods, and I wanted to tune some parameters. I looked around for existing solutions and found a couple of projects that could solve my problems, but not fully. So I had an option to either write yet another MCP server and end up doing this again for my other APIs and then support all of them or build some generic solution. So this is how I ended up building my own MCP Gateway.\n\nNow, the way it works: you point it at your existing backends - existing MCP servers (over streamable HTTP), OpenAPI specs, and plain HTTP APIs - and it exposes them as a single MCP endpoint (or multiple ones if you wish). And if you‚Äôve got an stdio-only MCP server, you can still plug it in via the Adapter.\n\nThe workflow is pretty straightforward:\n\n1. Connect your backends (MCP servers, OpenAPI specs, or HTTP APIs) as sources\n2. Create a profile and pick which tools you want to expose\n3. Profile gets you a new stable URL - that's your public MCP endpoint\n4. The UI generates a config you can paste straight into the agent / system of your choice\n5. You can now dynamically enable / disable tools, transform parameters, and do other fun stuff\n\nhttps://preview.redd.it/19rpzpu8cqgg1.png?width=1750&format=png&auto=webp&s=f1da42d2117cdcd447a85da58b8b6db3ed308645\n\nhttps://preview.redd.it/ot2vlhz9cqgg1.png?width=1404&format=png&auto=webp&s=517c75935b85284928224238db8953a8e6c53c8b\n\nFor most of the things you can do it via the UI, but you can also do it directly with just configs, if you like. For example, the simplest case is when you want to re-expose your existing OpenAPI-based server, so you do it like this:\n\n    servers:\n      billing:\n        type: openapi\n        spec: https://billing.internal/openapi.json\n        baseUrl: https://billing.internal\n        autoDiscover: true\n\nEvery operation in that spec becomes an MCP tool. No SDK, no wrapper code.\n\nSo, to summarize, my MCP Gateway is like a layer in front of your servers that handles aggregation, auth, and routing. If you've used API gateways like Kong or AWS API Gateway, same idea but for MCP. Some of my friends who used it described the experience as \"ngrok for MCP with some neat features on top\".\n\nIt's written in Rust, MIT licensed, Docker-ready. There's a web UI for managing profiles, sources, and API keys, and more.\n\nYou can learn more here: [https://github.com/unrelated-ai/mcp-gateway](https://github.com/unrelated-ai/mcp-gateway)\n\nIf you have questions I'm happy to answer in the comments. Also looking for contributors if this is something that interests you.\n\nhttps://preview.redd.it/tcuhpb14cqgg1.png?width=1778&format=png&auto=webp&s=92d9b9a8c57b7482adec41be0aa9d9fd86280d30\n\n",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qsafrs/sharing_mcp_gateway_run_mcp_in_production_on_top/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o31l8k1",
          "author": "makinggrace",
          "text": "How does this handle per-mcp auth -- or is that just passed through? (On the struggle bus with chatgcp's beta workflow for auth and trying to avoid oauth lol.)",
          "score": 2,
          "created_utc": "2026-02-01 21:33:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33ndub",
              "author": "kduman",
              "text": "It depends on what exactly you're asking, but let me answer in detail to cover as much as I can in one go.\n\nSo, first of all, there are upstream servers. Currently, you can add four types of them. If you select MCP Server or Adapter on the \"Sources\" page, the UI wizard will prompt you to enter auth details for that particular upstream. You can also do the same programmatically, the UI is fully optional, but I'm referring to it as a quick way to play with the gateway.\n\nThen there's downstream-related authentication: in the first screenshot above, you can see the \"Auth\" and \"Auth Help\" buttons. This is where you can configure how auth options for your specific profile should work. You can disable it entirely, switch to using gateway-issued API keys, or use JWT/OIDC if needed. Speaking of tokens: you can issue them yourself at the tenant level (which means you can use one token to access any profile you create), or you can take a more granular approach and issue profile-level tokens. You can do it in a few clicks in the UI, so just give it a try you'll like it.\n\nThere is also a big topic around auth identity. I haven't decided exactly how it should work just yet, so as of today the work is still in progress. I'll update the community later.",
              "score": 1,
              "created_utc": "2026-02-02 04:26:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2u4o62",
          "author": "macromind",
          "text": "This is a great example of where MCP starts to feel like the glue for real agents, tool aggregation + auth + scoping is exactly what gets painful in production. I like the profile concept a lot, stable URL plus selective tool exposure is basically least privilege for agent tooling. Any plans for per tool rate limits or audit logs by default? Ive been following MCP and agent infra patterns and collecting notes here: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-01-31 19:01:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2u74xd",
              "author": "kduman",
              "text": "Hello, thank you!\n\n\\> Any plans for per tool rate limits or audit logs by default?\n\nThe gateway supports per-profile rate limits as of today. I'll consider expanding it further (\"per-tools\" or \"per-mcp-capability\") somewhere later, especially if there will be a demand\n\n\\> audit logs¬†\n\nThe gateway and adapter obviously support observability-related logs, but no audit as of today.  \nI think this will be a subject of future improvements, with high priority.",
              "score": 0,
              "created_utc": "2026-01-31 19:12:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2v2mat",
          "author": "Beliskner64",
          "text": "How would this compare to [MCP ContextForge](https://pages.github.com/ibm/mcp-context-forge/)?",
          "score": 1,
          "created_utc": "2026-01-31 21:46:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vochx",
              "author": "kduman",
              "text": "Pretty close, and in some cases much better than mine, plus more mature for obvious reasons. My gateway might potentially be better in terms of transformation capabilities though.",
              "score": 0,
              "created_utc": "2026-01-31 23:40:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtchhn",
      "title": "Let your Agent Do More Than Code Let Them Design",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qtchhn/let_your_agent_do_more_than_code_let_them_design/",
      "author": "Dependent_Fig8513",
      "created_utc": "2026-02-01 22:10:59",
      "score": 9,
      "num_comments": 9,
      "upvote_ratio": 0.8,
      "text": "**FigMCP ‚Äî Let Your Agents Be Your Designer**\n\nI‚Äôm building an MCP for Figma that allows AI agents to act as real designers inside your workflow.\n\n**Key Features**\n\n* **Completely free** ‚Äî unlimited AI/MCP requests per minute\n* **No rate limits or timeouts** (unlike most MCPs)\n* **600+ tools**, **100+ resources**, and **25+ curated prompts** to help your agent get productive fast\n* Designed to remove friction and bottlenecks in AI-driven design workflows\n\n**Compatibility**\n\n* Tested on **Claude Code** and **Cursor**\n* **Windows only (for now)**\n\nüîó GitHub: [https://github.com/bubskqq4/FigMCP](https://github.com/bubskqq4/FigMCP)",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qtchhn/let_your_agent_do_more_than_code_let_them_design/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o32snqt",
          "author": "DasBlueEyedDevil",
          "text": "Suggestion, as 600 tools is about 580 too many for an LLM to keep track of reliably, try to consolidate them into workflow-style commands instead.  Here's my example: [https://github.com/DasBluEyedDevil/Daem0n-MCP](https://github.com/DasBluEyedDevil/Daem0n-MCP)\n\nI had 60+ tools and the LLMs used maybe 8 of them reliably.  I restructured into a workflow approach, and now it uses them all as expected.",
          "score": 11,
          "created_utc": "2026-02-02 01:25:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o347er0",
              "author": "BeautifulFeature3650",
              "text": "Did you publish an article? ",
              "score": 4,
              "created_utc": "2026-02-02 07:01:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35k4k2",
                  "author": "DasBlueEyedDevil",
                  "text": "No",
                  "score": 1,
                  "created_utc": "2026-02-02 13:46:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o31x5ec",
          "author": "jezweb",
          "text": "600 tools wow that‚Äôs huge! How will the agent know what to do with that many tools?",
          "score": 2,
          "created_utc": "2026-02-01 22:32:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31xd9f",
              "author": "Dependent_Fig8513",
              "text": "I plan to add initial setup rule/tool that will help the agents map out which tools do what and eventually put them into tool groups, which lead to mini subgroups of tools. It's in early beta right now; keep that in mind.",
              "score": 1,
              "created_utc": "2026-02-01 22:33:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o31xhhj",
              "author": "Dependent_Fig8513",
              "text": "But what I love about it is how fast and how quick I don't get rate limited when trying to use tools. Also, helping turn your design into code without needing a Figma subscription",
              "score": 1,
              "created_utc": "2026-02-01 22:34:05",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o31zea1",
              "author": "Dependent_Fig8513",
              "text": "Also just start working on where you don't have to have the plug-in visible for it to work. üëç",
              "score": 1,
              "created_utc": "2026-02-01 22:43:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o332z7o",
              "author": "Dependent_Fig8513",
              "text": "Some of those tools include specialized ones like design tokens to help design and other design stuff like design suggestions to help the AI give you the best output possible. Make sure you're using decent front end or back end models or else your output's gonna be really shitty.",
              "score": 1,
              "created_utc": "2026-02-02 02:24:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33hy40",
          "author": "Dependent_Fig8513",
          "text": "Linux support confirmed.",
          "score": 1,
          "created_utc": "2026-02-02 03:51:59",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr8f60",
      "title": "I build an MCP UI app for interactive text rewriting and grammar improvement visualization",
      "subreddit": "mcp",
      "url": "https://i.redd.it/zldlqi0y7igg1.png",
      "author": "arif_szn",
      "created_utc": "2026-01-30 15:24:02",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qr8f60/i_build_an_mcp_ui_app_for_interactive_text/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2o0bmo",
          "author": "Melodic-Swimmer-4155",
          "text": "This feature is available for developers in Claude? I thought this was only a thing in ChatGPT",
          "score": 1,
          "created_utc": "2026-01-30 20:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oxwxl",
          "author": "matt8p",
          "text": "Really cool work! Was able to play around with it on my inspector. Tip for building an MCP app, you can try using the `registerAppTool` and resource tool from the ext-apps SDK!",
          "score": 1,
          "created_utc": "2026-01-30 22:54:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rdimy",
              "author": "arif_szn",
              "text": "Thanks for the tip üôå",
              "score": 1,
              "created_utc": "2026-01-31 08:44:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qs5ki7",
      "title": "Context Transporter",
      "subreddit": "mcp",
      "url": "https://v.redd.it/d3lj68a6gpgg1",
      "author": "Educational_Guava_67",
      "created_utc": "2026-01-31 15:40:32",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qs5ki7/context_transporter/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2yksf4",
          "author": "InevitableJudgment43",
          "text": "Looks great! Does this work with Antigravity?",
          "score": 1,
          "created_utc": "2026-02-01 12:30:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yu6j5",
              "author": "Educational_Guava_67",
              "text": "Yep should work with any IDE",
              "score": 1,
              "created_utc": "2026-02-01 13:34:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qux52j",
      "title": "Built an MCP server for automatic file organization - Claude helped me handle 12+ file categories and security hardening",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qux52j/built_an_mcp_server_for_automatic_file/",
      "author": "Technocratix902",
      "created_utc": "2026-02-03 16:49:26",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 0.9,
      "text": "Hey everyone! I wanted to share a project I built that makes Claude really useful for organizing messy folders.\n\n**What I built:** File Organizer MCP Server - an MCP server that lets Claude automatically organize your files into categories, find duplicates, and identify space-consuming files.\n\n**How Claude helped:**\n\n* Helped me design the security architecture (path traversal protection, symlink validation)\n* Debugged the content-based duplicate detection algorithm\n* Wrote comprehensive test coverage for the security features\n* Helped optimize the file hashing to handle large directories without memory issues\n* Refined the category system to cover 12+ file types\n\n**What it does:** When connected to Claude Desktop, you can ask Claude to:\n\n* \"Organize my Downloads folder\" - automatically sorts files into Executables, Videos, Documents, Images, Audio, etc.\n* \"Find duplicate files in my Documents\" - identifies wasted space from duplicate files\n* \"Show me the 20 largest files\" - helps you find space hogs\n* \"Categorize files in this directory\" - gives you a breakdown without moving anything\n* \"Organize with dry run\" - preview changes before executing\n\n**Technical highlights:**\n\n* Security score: 9.5/10 (multi-layer path validation, resource limits, streaming operations)\n* Handles naming conflicts automatically\n* Preserves file metadata\n* Memory-safe for large directories (tested with 10,000+ files)\n\n**Free to use:** The entire project is open source (MIT license) and free. Just install via npm and configure in Claude Desktop.\n\n**Link:** [https://github.com/kridaydave/File-Organizer-MCP](https://github.com/kridaydave/File-Organizer-MCP)\n\nI'm 15 and this is my first real open-source project, so feedback would be amazing! Claude was basically my pair programming partner throughout the entire build - especially for the security hardening parts where I didn't have prior experience.\n\nHas anyone else used MCP servers for file management workflows? Curious what other use cases people have found.\n\n*Processing video sxpwhyu751hg1...*\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qux52j/built_an_mcp_server_for_automatic_file/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o3ddk7p",
          "author": "Ok_Message7136",
          "text": "Nice MCP use case, file ops + dry-run + security hardening is exactly where MCP shines. This feels genuinely practical.",
          "score": 1,
          "created_utc": "2026-02-03 17:02:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3defg7",
              "author": "Technocratix902",
              "text": "Thanks üôè! It's entirely free to use and available on NPM . Check it out, would love feedback from the community!",
              "score": 1,
              "created_utc": "2026-02-03 17:07:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3dtedp",
          "author": "Educational-Bison786",
          "text": "Awesome project especially at 15. For other MCP uses, I've seen people build them for smart home control or even automating dev workflows. When agents get complex, ensuring their reliability is critical. [Maxim AI](https://getmax.im/Max1m) helps teams evaluate agent performance and catch issues. Also look into tools like SonarQube for code quality checks.",
          "score": 1,
          "created_utc": "2026-02-03 18:15:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fajz9",
          "author": "Great_Scene_5604",
          "text": "Congrats, very practical application. Do you run the MCP server locally? Wondering if could extend to Drive ...",
          "score": 1,
          "created_utc": "2026-02-03 22:21:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ggfh8",
          "author": "Putrid-Pair-6194",
          "text": "Congrats on your first project. Impressed that you focused so much on security. That will serve you well as you publish more in the future.",
          "score": 1,
          "created_utc": "2026-02-04 02:09:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qt33r8",
      "title": "Technical Explanation of Memory Based MCP Servers",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qt33r8/technical_explanation_of_memory_based_mcp_servers/",
      "author": "Ok-Cattle8254",
      "created_utc": "2026-02-01 16:32:27",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Thank you for your time...\n\nI have been diving into tool/mcp servers and I am a bit confused on how Memory MCP Servers work exactly.\n\nHow does a \"memory\" get into a Memory MCP Server?  Does the end user ask the LLM to store a memory and there is a store memory tool?  Or does the Memory MCP Server have its own web interface or something like that where the end user has to add the \"memory\" them selves and then the memory is stored in a graph database or something similar?\n\nThen how is the LLM encouraged to use the Memory MCP Server?  I'm guessing the Memory MCP Server is handed off like any other tool, but does the LLM have to be directed to use the specific Memory MCP Server, by saying something like \"Do you remember that time...\"\n\nAny friendly direction on this would be greatly appreciated.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qt33r8/technical_explanation_of_memory_based_mcp_servers/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o30deml",
          "author": "Ok_Message7136",
          "text": "MCP ‚Äúmemory‚Äù is just external state, the model doesn‚Äôt learn or persist anything on its own. Memories are written/read via explicit MCP tool calls (DB / vector store), and the LLM only uses them when instructed.\n\nI‚Äôve been testing this using Gopher‚Äôs free, open-source MCP SDK to build custom MCP servers.\n\nLink: [https://github.com/GopherSecurity/gopher-mcp](https://github.com/GopherSecurity/gopher-mcp)",
          "score": 1,
          "created_utc": "2026-02-01 18:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3731yy",
          "author": "naseemalnaji-mcpcat",
          "text": "Typically, a Memory MCP Server exposes tool endpoints (like \"store\\_memory\" or \"retrieve\\_memory\") that the LLM can call programmatically. The end user doesn't have to add memories manually (by telling the LLM or otherwise). The LLM is encouraged to use the memory tool by being given the MCP servers tool schema and, optionally, example prompts or system instructions that nudge it to store or recall memories as needed. It's common to use a vector or graph database under the hood, but from the LLM's perspective, everything happens through tool calls.",
          "score": 1,
          "created_utc": "2026-02-02 18:12:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2zv31u",
          "author": "Maasu",
          "text": "It depends on the type of memory mcp server and agent using it of course, but ultimately it involves some form of prompt/skill mechanism that will instruct an LLM to call the MCP tool to use the memory system. \n\nHere is an example of a copilot skill (which is a dynamically loaded prompt effectively) for a memory mcp https://github.com/ScottRBK/forgetful/blob/main/docs%2Fcopilot-cli%2Fskills%2Fusing-forgetful-memory%2FSKILL.md\n\nHope this helps",
          "score": 1,
          "created_utc": "2026-02-01 16:43:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpa84z",
      "title": "HTTP2/HTTP3 support in the future?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "author": "DorkyMcDorky",
      "created_utc": "2026-01-28 12:38:07",
      "score": 7,
      "num_comments": 24,
      "upvote_ratio": 1.0,
      "text": "Quick question for r/mcp: has anyone considered an HTTP/2 or HTTP/3 transport option for MCP, even if HTTP/1 stays the baseline? I get the tradeoffs like HTTP/1 ubiquity, stateless infra, and simpler deployment, but I am curious how folks weigh those against streaming and long lived connections.\n\nI know HTTP/2 or HTTP/3 can be a pain in cloud environments and external facing SaaS, but for internal networks and home labs it is much easier and brings real benefits like multiplexing and true streaming. Maybe MCP is mainly targeting SaaS cloud infra, but it feels like a huge miss that there is no true streaming option for internal use cases.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o27mkvy",
          "author": "Crafty_Disk_7026",
          "text": "I have grpc mcps with streaming but they are custom integrations I created and not MCP based but does the same thing.  Also I have been experimenting with codemode mcps which is not really http difference but instead executes the agent logic as a sandboxed code execution.  Te codemode flow has made the biggest improvement difference since it eliminates api round teips",
          "score": 3,
          "created_utc": "2026-01-28 13:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27mpbm",
              "author": "Crafty_Disk_7026",
              "text": "Please check out Google ADK streaming agent development workflow.  I believe this is more what you want than MCP on http2",
              "score": 1,
              "created_utc": "2026-01-28 13:37:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27ntei",
                  "author": "DorkyMcDorky",
                  "text": "My intent is to make an MCP option that's streaming that can still work with MCP clients that are standard MCP services.  To have it so if you define this spec, you get MCP serving as well.  It would be a streaming version of the MCP service.  If both clients negotiate with each other and they're both HTTP2, then they can stay that way or else downgrade to HTTP1. \n\nI'll check it out!  Thanks for perking my ears in this direction..",
                  "score": 1,
                  "created_utc": "2026-01-28 13:43:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27fksg",
          "author": "NoAdministration6906",
          "text": "‚Å†Hey, great question! I‚Äôve also been thinking about long‚Äëlived streams for internal MCP deployments. HTTP/2 (and especially HTTP/3) can unlock true multiplexing and lower‚Äëlatency streaming, but you‚Äôre right that cloud/SaaS environments often pose challenges around proxies and certs. One approach I‚Äôve seen is experimenting with WebTransport (over HTTP/3) in a home‚Äëlab setup to validate streaming performance, then rolling back to HTTP/2 or gRPC‚ÄëWeb for external/cloud contexts.",
          "score": 1,
          "created_utc": "2026-01-28 12:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27hrbj",
              "author": "DorkyMcDorky",
              "text": "Thanks. There is a gRPC transport effort, but it is a 1:1 mapping of current MCP, so it inherits the lack of true streaming. The current proto is here: [https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/](https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/) and it mirrors the MCP spec and looks good.\n\nI plan to work on a wrapper that enables HTTP/2 streaming on top of that once the gRPC transport solidifies. The idea is to keep MCP compatibility, add HTTP/2 tunneling for true streaming, and avoid multiple server implementations. I can share details if you are interested.\n\nThat is why I asked the question. Why not define an HTTP/2 option and a tunneling spec too? My guess is it would over burden the spec, and the HTTP/1 work is leaning away from streaming to keep transports compatible. That is a reasonable direction, but it leaves a gap for internal and home lab use cases.",
              "score": 1,
              "created_utc": "2026-01-28 13:09:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27zmod",
          "author": "ToHallowMySleep",
          "text": "In the context of a streaming solution to MCP, I would favour HTTP/3 over HTTP/2, simply because HTTP/2 seems to have been slept on - it was adopted by only 50% of websites at its peak and now that is already down to 35% or so, as it just didn't resonate for full bidirectional support.\n\nBrowsers are more likely to jump to HTTP/3 support, and that's going to be a strong driver for protocol adoption.",
          "score": 1,
          "created_utc": "2026-01-28 14:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bosp0",
              "author": "DorkyMcDorky",
              "text": "100% I agree with you. However the latest spec is encouraging reeling back any streaming and staying pure stateless. \n\nThey want to focus on a common layer between transfer protocols which is a good idea but they need two implementations: one that is streaming and one that is not.  \n\nPersonally, they shouldn't even have a stateless solution. I know it would be a challenge to get this far but it's clearly the future. After all nvidia's even inventing new network interfaces to replace ethernet. The protocols are already there with http3.  So they should start that spec now. \n\nIt's worth bringing this up. My voice has been exhausted, I didn't do a good job communicating this :)",
              "score": 2,
              "created_utc": "2026-01-29 00:49:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28a02s",
          "author": "naseemalnaji-mcpcat",
          "text": "A few folks I know have experimented with custom proxies or sidecar services to enable HTTP/2 streaming on top of MCP, but nothing's standardized yet. If streaming is critical for your use case, it might be worth prototyping an internal fork or raising the discussion on the MCP repo‚Äîthere's likely more demand than the current baseline suggests.",
          "score": 1,
          "created_utc": "2026-01-28 15:32:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bnty5",
              "author": "DorkyMcDorky",
              "text": "I did that. With code examples. It was grpc and they said it belongs in grpc, missing the point. So I brought up the streaming. They likely didn't understand my communication. But I dropped it, the interest and point wasn't getting the attention it needed\n\nIf you can bring it up, it might help. Feel free to reach out to them; I'd love a chorus on this.",
              "score": 1,
              "created_utc": "2026-01-29 00:43:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2929a6",
          "author": "Creamy-And-Crowded",
          "text": "Nice catch on this gap. Right now, if an MCP server is pushing a large resource, it can effectively block the entire connection until it is done...   \nA priority lane for urgent reasoning steps while the heavy data moves in the background would be much desirable.",
          "score": 1,
          "created_utc": "2026-01-28 17:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bp4xt",
              "author": "DorkyMcDorky",
              "text": "Not only that can you imagine how much cheaper it would be? Can you imagine that you can use agents in the middle of pipeline that can observe all of your logs and even react to your prompts in the middle of an answer,? There are so many use cases.",
              "score": 1,
              "created_utc": "2026-01-29 00:50:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2cfom6",
          "author": "pbalIII",
          "text": "Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases. The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nThe rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations. For internal/homelab setups where you control the infra, gRPC custom integrations (like the other commenter mentioned) work fine. But getting that into the spec would conflict with the stateless direction they're pushing.",
          "score": 1,
          "created_utc": "2026-01-29 03:16:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dx3t6",
              "author": "DorkyMcDorky",
              "text": "You summarize the tension well (with a slight clarification on the streamable option available today).\n\nYou‚Äôve touched on the fact that the MCP spec focuses on **stateless transport**. This feels like short-term gains to help massive, stateless cloud infrastructure. I agree - and that‚Äôs exactly the point of my post. They flirt with streaming but miss the opportunity; it‚Äôs a massive resource waste simply because true bidirectional streaming is difficult to deploy in large, legacy cloud infrastructure right now.  So I completely agree....\n\n... however ...\n\nAlthough MCP‚Äôs approach is \"pragmatic\" - creating an interface that *looks* like streaming - there‚Äôs no mention of how they‚Äôd ever make the jump to a real persistent transport in the future.  In fact, they're doing the opposite - removing streaming and double downing on stateless. (you touch on this too, just reiterating it for clarity)\n\nTo work around this, I use gRPC extensively already - so totally aware that streaming protocols DO exist - I'm suggesting that MCP should do that.\n\nThe downside is that it doesn‚Äôt offer an easily consumable public API for the now-popular chat protocols. However, agentic protocols like **ADK (Agent Development Kit)** or custom gRPC setups are embracing true streaming, leaving the \"popular\" MCP behind. It‚Äôs a missing scale on the dragon that I hope gets addressed.\n\n>Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases.\n\nThe **Streamable HTTP** implementation (please correct me if I‚Äôm reading the code wrong) is not \"true\" streaming because the spec is still fundamentally **cursor-based**. The chunks are collected and yielded after the fact - making it \"polling with extra steps.\" This seems intentional, but I don‚Äôt see why they can‚Äôt offer a streaming option similar to how gRPC handles bidirectional streams.  It's streaming where you need to code like it's not.  Simulating non-streaming on a streaming transfer - blocking... \n\n>The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nYes... instead of 2026 being the year of HTTP/3, we are scaling like it‚Äôs 2001. It works, but it‚Äôs putting **rockets on roller skates**.\n\n>The rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations.\n\nI get that, and it is pragmatic. But that mainly helps Google, Amazon, and Oracle while it makes us pay more in data center costs for their ease of deployment.\n\nThe current gRPC spec in the MCP ecosystem doesn't even offer true streaming; it‚Äôs just a 1:1 mapping of the MCP JSON-RPC. Again, a miss.   \n  \nSo reeling it back to my point: **MCP is not true streaming, but should be.** I‚Äôm not arguing that \"streaming-like\" behavior doesn't exist, but MCP is literally no different than the browser polling mechanisms we‚Äôve seen for 25 years.\n\nIf getting real streaming into the spec conflicts with the \"stateless direction\" they‚Äôre pushing, then the line in the sand should be clear: **MCP is for stateless utility; ADK and custom gRPC are for agentic streaming.**",
              "score": 1,
              "created_utc": "2026-01-29 10:15:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gbwub",
                  "author": "pbalIII",
                  "text": "Stateless at the transport layer, stateful at the app layer... that's basically how HTTP has worked forever. The session-as-cookie approach they're proposing isn't regression, it's unbundling concerns that got conflated when MCP was primarily local STDIO.\n\nThe gRPC angle is interesting but the hybrid pattern emerging makes more sense to me. MCP for discovery and semantics, gRPC for the hot path when you need real streaming. Google Cloud is already shipping pluggable transports in the SDK for exactly this reason.\n\nWhere I'd push back: the June 2026 spec release is targeting stateless-first, but the Transport Working Group has multi-turn SSE as an active SEP. So it's not purely abandoning streaming... it's separating the concerns. Whether that's better or worse depends on your deployment model.",
                  "score": 1,
                  "created_utc": "2026-01-29 18:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qrvhzj",
      "title": "Using MCP Push Notifications in AI Agents. I have got the working setup",
      "subreddit": "mcp",
      "url": "https://gelembjuk.com/blog/post/using-mcp-push-notifications-in-ai-agents/",
      "author": "gelembjuk",
      "created_utc": "2026-01-31 07:03:29",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qrvhzj/using_mcp_push_notifications_in_ai_agents_i_have/",
      "domain": "gelembjuk.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qr75zp",
      "title": "Agent Skill repo for Building with Google AI Frameworks and models",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qr75zp/agent_skill_repo_for_building_with_google_ai/",
      "author": "chou404",
      "created_utc": "2026-01-30 14:37:20",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I just open-sourced the Google GenAI Skills repo.\n\n\n\nUsing Agent Skills standard (SKILL md), you can now give your favorite CLI agents (Gemini CLI, Antigravity, Claude Code, Cursor) instant mastery over:\n\n\n\nüß† Google ADK\n\nüìπ DeepMind Veo\n\nüçå Gemini Nano Banana\n\nüêç GenAI Python SDK\n\nand more to come...\n\n\n\nAgents use \"progressive disclosure\" to load only the context they need, keeping your prompts fast and cheap. ‚ö°Ô∏è\n\n\n\nTry installing Google ADK skill for example:\n\nnpx skills add cnemri/google-genai-skills --skill google-adk-python\n\nCheck out the repo and drop a ‚≠êÔ∏è. Feel free to contribute:\n\n\n\nüîó [https://github.com/cnemri/google-genai-skills](https://github.com/cnemri/google-genai-skills)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qr75zp/agent_skill_repo_for_building_with_google_ai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2m8bhb",
          "author": "Ok_Message7136",
          "text": "Nice share, the Agent Skills idea is interesting, especially for keeping context lean.\n\nI‚Äôve been testing MCP setups using Gopher‚Äôs free MCP server / open-source SDK lately, and it‚Äôs been handy for quickly wiring tool-driven agents.\n\nLMK if you want the Gopher MCP link or want to compare approaches.",
          "score": 1,
          "created_utc": "2026-01-30 15:25:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uhpd3",
              "author": "chou404",
              "text": "Please share I am curious",
              "score": 1,
              "created_utc": "2026-01-31 20:03:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2y2912",
                  "author": "Ok_Message7136",
                  "text": "Yep, happy to , just sent you the file access via DM.",
                  "score": 1,
                  "created_utc": "2026-02-01 09:48:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}