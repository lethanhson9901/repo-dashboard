{
  "metadata": {
    "last_updated": "2026-01-19 16:49:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 94,
    "file_size_bytes": 118327
  },
  "items": [
    {
      "id": "1qb7bx7",
      "title": "Anyone else find mcp setup to be a massive pain?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qb7bx7/anyone_else_find_mcp_setup_to_be_a_massive_pain/",
      "author": "Apprehensive_Ice9370",
      "created_utc": "2026-01-12 21:09:03",
      "score": 60,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Recently introduced to MCP thinking the hard part would be getting a server running, but I was surprised that that was the easy bit.. the pain started when I tried to make it usable in practice like custom server logic, proper auth and permissions, logging and analytics.. to understand what the agent is doing, and then figuring out how to host it safely without creating a security mess\n\nWanted to connect Postgres and some internal docs to Claude Desktop, but turning that into something Iâ€™d be comfortable running for more than a demo took way longer than expected.\n\nI needed to find a tool mostly out of fatigue, and it helped with a lot of the plumbing (especially auth, logging, and hosting), but Iâ€™m curious how others are handling this (ogment ai, in case anyone else is using it). Are people rolling their own production MCP servers, or is there a better pattern Iâ€™m missing?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qb7bx7/anyone_else_find_mcp_setup_to_be_a_massive_pain/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nz8o42s",
          "author": "BallsOfStonk",
          "text": "How are these considerations remotely relevant to MCP. This is just all standard production stuff, anything you host in a production environment has these issues.",
          "score": 8,
          "created_utc": "2026-01-12 21:53:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8j3sm",
          "author": "drakgremlin",
          "text": "Would be great to run them in Docker.  Sadly most agents do not integrate with it, meaning a larger attack surface.",
          "score": 2,
          "created_utc": "2026-01-12 21:30:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz8xpt6",
              "author": "coloradical5280",
              "text": "Are you talking about locally hosted servers? Cause you can absolutely get any agent to communicate with a local server in docker.",
              "score": 1,
              "created_utc": "2026-01-12 22:40:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz97xdg",
                  "author": "drakgremlin",
                  "text": "Technically, yes?\n\nPractically it gets really funky with the edge cases in the lifecycle.",
                  "score": 1,
                  "created_utc": "2026-01-12 23:33:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz8jzc8",
          "author": "clipd_dead_stop_fall",
          "text": "I'm way behind you folks. I just started this journey. \n\nI want to use the Docker MCP Toolkit version of the AWS documentation mcp server with another that I want to build. I want to use mcp gateway to have one point of contact for the custom client, and I want all of it running local on developer machines. \n\nPretty sure I can handle the custom client and server, but the plumbing is proving a challenge.",
          "score": 2,
          "created_utc": "2026-01-12 21:35:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8x2rk",
          "author": "theapidude",
          "text": "Try out [https://getgram.ai/](https://getgram.ai/) \\- its not a framework like FastMCP rather a platform to plumb data to AI applications using MCP. The \"mcp bits\" (hosting, Oauth, logging, tool curation) are abstracted away but everything is compliant with the protocol so you're not locked in.",
          "score": 2,
          "created_utc": "2026-01-12 22:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcm24q",
          "author": "0xKoller",
          "text": "Hey!  \nKoller from [xmcp.dev](http://xmcp.dev) here. I totally get your pain, this use case really *is* painful. I encourage you to try building an MCP server with xmcp. Our main focus is DX, so it doesnâ€™t have to feel like a headache.\n\nFor auth, we support Better Auth, Clerk, and WorkOS, with Auth0 coming later this week. You can host your MCP server on Vercel using our zero-config deployment.\n\nIâ€™ll put together an example for the problem you mentioned over the next few weeks.",
          "score": 2,
          "created_utc": "2026-01-13 13:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nze65pc",
          "author": "motakuk",
          "text": "[https://github.com/archestra-ai/archestra](https://github.com/archestra-ai/archestra) addresses most of the pain points of running MCP servers yourself: auth, connecting to clients, logging, etc.",
          "score": 2,
          "created_utc": "2026-01-13 18:19:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8vz3j",
          "author": "AchillesDev",
          "text": "This is setting up any customer-facing application, nothing specific to MCP. Arcade.dev and FastMCP both are frameworks that live on top of the MCP SDK that can help with these things.",
          "score": 1,
          "created_utc": "2026-01-12 22:31:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8zoj4",
          "author": "Ol010101O1Ol",
          "text": "Itâ€™s absolutely painful\n\nWorking on a real solution for that. Standby.",
          "score": 1,
          "created_utc": "2026-01-12 22:49:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzeif7a",
              "author": "Live_Vermicelli4307",
              "text": "Keep us posted!",
              "score": 1,
              "created_utc": "2026-01-13 19:14:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz93qy6",
          "author": "naseemalnaji-mcpcat",
          "text": "Yep, existing frameworks help, but most (or any basic apps) require a fundamental understanding of authorization and identity. For most usecases I think itâ€™s fine to settle for simplicity in someways, like using token based authentication. \n\nMy stack: FastMCP running in ECS with an RDS database",
          "score": 1,
          "created_utc": "2026-01-12 23:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzanqa2",
              "author": "punkpeye",
              "text": "I really need to rename FastMCP (TypeScript) to something else.\n\nEvery time someone says FastMCP, I have no clue which framework they are talking about.",
              "score": 1,
              "created_utc": "2026-01-13 04:14:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzanzh8",
                  "author": "naseemalnaji-mcpcat",
                  "text": "Haha yeaaaa and thereâ€™s two Python implementations ðŸ¤¦â€â™‚ï¸",
                  "score": 1,
                  "created_utc": "2026-01-13 04:16:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz9a490",
          "author": "lujunsan",
          "text": "Yeah, I agree with the pain. Getting an MCP server running is easy, but turning it into something you want to run long-term can get messy fast, with auth, secrets, permissions, safe hosting,  visibility... Weâ€™re building Toolhive, an open-source project that helps by running MCP servers in isolation (locally or on Kubernetes), managing secrets and permissions, and quite a lot more. If that sounds interesting, you can check it out here: https://toolhive.dev https://docs.stacklok.com/toolhive/ Iâ€™m one of the devs working on it, so I'm happy to answer any questions!",
          "score": 1,
          "created_utc": "2026-01-12 23:45:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaxqza",
          "author": "hasmcp",
          "text": "This was the main reason that I created HasMCP and opensource a community version. It was super painful to setup the env, find the right tool then try to figure out the setup. Now I just provide the url and token then I choose the tools that I need only and relax while seeing what is going on behind scene with realtime logs.",
          "score": 1,
          "created_utc": "2026-01-13 05:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb21nn",
          "author": "raghav-mcpjungle",
          "text": "What you're describing is not a MCP problem but rather an operational problem.\n\nA good strategy is to \"centralize\" all your MCP servers by putting them behind a mcp gateway. A gateway becomes a single MCP endpoint that all your clients (like claude, ai agents) can connect to, to access all your MCP tools.\n\nGateways can solve a lot of these problems for you - centralized observability, audit logging, auth & ACLs, discoverability and give a holistic view of all your MCPs.\n\nfor eg, I'm a core developer of [mcpjungle](https://github.com/mcpjungle/MCPJungle). It is open source and self hosted, which improves your security & privacy aspects as well.  \nYou can run it on your local machine for personal use or deploy to your server in an enterprise setting.",
          "score": 1,
          "created_utc": "2026-01-13 05:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbphnj",
          "author": "babydecocx",
          "text": "yep. running the server is the easy part. making it â€œprod-safeâ€ is the grind (auth, perms, logs, hosting, wtf did the agent do)\n\nwhat helped us:\n\n* dont expose raw apis / 100 tools. wrap a few high level intent tools\n* put a gateway in front (oauth/ss0, allowlists, rate limits, audit logs). \n* postgres: read-only user, timeouts + row limits, schema allowlist. avoid â€œrun any sqlâ€\n* docs: split search vs fetch (search -> ids, then get(id)) so you can scope + audit\n\nmcp is just the wire. you still need the platform stuff around it, or use something that already ships those rails, we have our own version, it's open-source and free to test: [decocms.com/mesh](http://decocms.com/mesh)",
          "score": 1,
          "created_utc": "2026-01-13 09:24:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbxnwi",
          "author": "jezweb",
          "text": "Yes but once I got a good starting set of components to build on it was a lot easier. Fastmcp cloud was the easiest I found to build on for learning but just use cloudflare now instead. Claude 4.5 is a way better with mcp than 3.7 era was. It used to be like force feeding and reminding constantly that mcp was not minecraft protocols lol.",
          "score": 1,
          "created_utc": "2026-01-13 10:41:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhd5dv",
          "author": "saif_shines",
          "text": "The auth parts needs to be able to expand into auth'z, rather than just usual auth'n for MCP stuff. That has been my observation.  We use MCPJam for local inspection and development, try and checkout their blog: [https://www.mcpjam.com/blog/scalekit-oauth](https://www.mcpjam.com/blog/scalekit-oauth)",
          "score": 1,
          "created_utc": "2026-01-14 04:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzodrs9",
          "author": "moonshinemclanmower",
          "text": "Try having a good starting point, here are some examples you can use for source code examples:\n\n[https://github.com/AnEntrypoint/code-search](https://github.com/AnEntrypoint/code-search)\n\n[https://github.com/anentrypoint/coolify-mcp](https://github.com/anentrypoint/coolify-mcp)",
          "score": 1,
          "created_utc": "2026-01-15 05:00:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzaltgf",
          "author": "punkpeye",
          "text": "It's literally one button click (Okay, two) if you are using Glama (I am the founder).\n\nhttps://glama.ai/blog/2025-07-08-how-to-install-and-use-mcp-servers\n\nOut of the box you get:\n\n* updates\n* secret management\n* analytics\n* streamable HTTP\n* chat (https://glama.ai/chat)\n\nand can even share it with others using access tokens",
          "score": 1,
          "created_utc": "2026-01-13 04:03:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbzdhz",
      "title": "MCPs are a workaround",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbzdhz/mcps_are_a_workaround/",
      "author": "Accomplished-Emu8030",
      "created_utc": "2026-01-13 18:40:19",
      "score": 39,
      "num_comments": 29,
      "upvote_ratio": 0.85,
      "text": "Youâ€™ll see posts saying â€œMCPs are a fad,â€ and other posts saying â€œMCPs are amazing.â€ I think both sides are missing the point.\n\nMCPs exist because theyâ€™re solving a very real painÂ *right now*.\n\nWhen Anthropic shipped MCP, the intent was clear: make it easier for models to plug into real systems. The â€œUSB-C for AI toolsâ€ line was great marketing, but the deeper truth is simpler: MCP fit their product constraints and made integrations safer and more repeatable.\n\nThen adoption took off and a narrative formed: â€œThis is the new wave.â€\n\nBut I donâ€™t think teams adopted MCP because everyone concluded itâ€™s the One True Interface. Adoption happened because lots of teams hit the same wall at the same time: **LLMs werenâ€™t reliable enough to write integration code live without messing it up.**\n\nIn theory, if a model could generate perfect code every time, you wouldnâ€™t need MCP. The model could just generate whatever connector you need on the spot and it would work. But that wasnâ€™t the world we were living in. Models could code, sureâ€”but â€œpretty goodâ€ isnâ€™t good enough when youâ€™re dealing with production systems, permissions, and actions that move money.\n\nFast-forward to now: models are meaningfully better at code. And you can see the product direction shifting with that reality. Anthropic started talking aboutÂ *code-based tool calling*â€”roughly: â€œwhat if tools are scripts (real code) instead of only protocol-shaped endpoints?â€ That arc naturally leads into things like Skills.\n\nThatâ€™s the part I find most interesting:Â *tooling evolves with model capability.* MCP made sense when models needed tighter guardrails. Code-first approaches make more sense as models get stronger.\n\nAnd all this brings me to what weâ€™re releasing today.\n\nWeâ€™re releasingÂ a framework called [Operai](https://github.com/brwse/operai)Â (operations + AI, and yes, a nod to operads). Call it a plug if you wantâ€”it's public and we think itâ€™s the better direction for the ecosystem.\n\nOur main thesis is: Instead of orchestrating agents + a giant pile of tools,Â *orchestrate tools with policies*Â and keep the tool surface areaÂ *small, scoped, and deliberate.*\n\nWhy?\n\n* *A dedicated toolset beats a Swiss Army knife.* You can fumble around with a â€œdo-everythingâ€ MCP, or you can just program a tool that does the jobâ€”cleanly, predictably, and safely.\n* *Policy orchestration matters more than agent orchestration.* In a real org, leadership doesnâ€™t micromanage every personâ€™s steps. They define constraints: approval rules, audit requirements, budgets, access boundaries. When you â€œorchestrate agents,â€ youâ€™re implicitly trying to micromanage. You shouldnâ€™t care about the agentâ€™s personalityâ€”you should care aboutÂ **what it is allowed to do**.\n\nOperai uses anÂ *effect-based policy system*: agents can behave flexibly, but the system enforces guardrails on side effects. The policies protect the endgame.\n\nThe workflow with operai is simple:\n\n1. Create a Git repo that stores your tools.\n2. Build tools with your favorite coding assistant + the Operai CLI.\n3. Serve them with Operai.\n\nUnder the hood we made choices that are biased toward enterprise reality and how LLMs actually behave. For example, we choseÂ RustÂ because Python/JS donâ€™t give you compile-time guaranteesâ€”and when youâ€™re exposing capabilities to an agent, you want as many guarantees as you can get.\n\n**Why do we think this is where things go?**\n\nBecause programs arenâ€™t going away. Even with infinite context, weâ€™re not â€œhedging probabilityâ€ hereâ€”weâ€™re enforcing logic: access control, schemas, invariants, side effects, logging, auditing. Those arenâ€™t optional. The transport is secondary. What we need is a solid mechanism for AI to generateÂ **good** programsâ€”not ad-hoc scripts, not unaudited glue code, but real software: versioned, typed, testable, reviewable, observable. The kind of quality level youâ€™d expect from something like ripgrep.\n\nSo our bet is simple:\n\nThe future isnâ€™t picking a single protocol and arguing forever. Itâ€™s treating tools like real softwareâ€”whether it's fully authored by a human or an AIâ€”without pretending the model is perfect.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qbzdhz/mcps_are_a_workaround/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzeuk4z",
          "author": "Biruleiby",
          "text": "i like this take. for me MCP is more like a bridge than â€œthe final interfaceâ€.  \nthe real hard part is not the transport, is all the ops: who can do what, audit trail, debugging, costs etc.  \n  \nhow do you handle RBAC / approvals / audit logs / cost limits in operai when tools start to spread in a big org?",
          "score": 7,
          "created_utc": "2026-01-13 20:09:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzf4wxw",
              "author": "Accomplished-Emu8030",
              "text": "Thank you! And really great question :) I actually hoped someone would ask this\n\nOperai is stateless (scalable) so it scales based on IO. Also regarding audit logs, you just hook a database to operai which captures all activity. For everything else, our effects system is what drives everything.\n\nFor example, for the things you mentioned, you can use the following policies:\n\n    [[policies]]\n    name = \"rbac-policy\"\n    version = \"1.0\"\n    \n    [[policies.effects]]\n    tool = \"admin.*\" Â  Â  Â  # Pattern matching for tool names\n    stage = \"before\" Â  Â  Â  # Run before the tool executes\n    when = \"user.id != 'Fred'\"\n    fail_message = \"permission denied: Admin access required.\"\n    \n    [[policies]]\n    name = \"deploy-approval\"\n    version = \"1.0\"\n    \n    # Initialize state\n    [[policies.context]\n    approval_status = \"pending\"\n    \n    # Rule 1: Guard the sensitive tool\n    [[policies.effects]]\n    tool = \"deploy_prod\"\n    stage = \"before\"\n    when = \"context.approval_status != 'granted'\"\n    fail_message = \"Deployment requires approval. Please run 'request_approval' first.\"\n    \n    # Rule 2: Grant approval (Action)\n    # Assumes you created an 'approve_request' tool and it was called successfully\n    [[policies.effects]]\n    tool = \"approve_request\"\n    stage = \"after\"\n    when = \"result.is_ok\"\n    [policies.effects.set]\n    approval_status = \"'granted'\"\n\nI think you can probably come up with cost control example (we'll write a list of examples in the repo at some point).\n\nYou would handle policies like you would in a large scale systems. You can bundle them however you wish and deploy it to the file system (for example, ConfigMap in K8S).",
              "score": 2,
              "created_utc": "2026-01-13 20:58:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzgbv6j",
          "author": "intertubeluber",
          "text": "I stopped reading before the pitch for your product, but the first part addresses a subset of how MCPs are useful. And MCP isnâ€™t even about guardrails.Â \n\nThey provide context that the LLMs need. Â Ie my LLM needs time know my internal database schema to build queries or optimize indexes. Or connect to my task management system. Or Spotify to create a playlist.Â \n\nMCPs provide the _model_ with a _protocol_ for the needed _context_ from different resources.Â ",
          "score": 3,
          "created_utc": "2026-01-14 00:33:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzge5la",
              "author": "Accomplished-Emu8030",
              "text": "Yesâ€”MCP gives a clean protocol for context/tool access. Agreed.\n\nBut you just said you stopped reading before the pitchâ€¦ which is the part where I explain the actual problem: MCP in enterprise isnâ€™t blocked by 'can it fetch context,' itâ€™s blocked by 'can it do it safely, compliantly, and repeatedly'.",
              "score": 0,
              "created_utc": "2026-01-14 00:45:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfmcn6",
          "author": "Low-Efficiency-9756",
          "text": "MCP is a protocol for executable tools that:\n\n1. Validate inputs â€” Schema enforcement via JSON-RPC before execution\n\n2. Mutate state â€” Write to databases, filesystems, APIs\n\n3. Return structured data â€” Not prose, actual typed responses the LLM can parse\n\n4. Maintain invariants â€” The LLM proposes, the tool validates and executes",
          "score": 2,
          "created_utc": "2026-01-13 22:19:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfpue8",
              "author": "Accomplished-Emu8030",
              "text": "I don't understand what this comment is supposed to be about; I think everyone in r/mcp knows what an MCP is for, but I need to correct several things:\n\n3. This is completely wrong. LLMs do not need structured data. They actually work better with prose. Tools return structured data for the purpose of orchestration (e.g. intercepting a tool call and doing something with that data).\n\n4. This is also completely wrong. Nothing about MCPs maintains invariants. In fact, it's one of the main reasons I created Operai. To maintain invariants.",
              "score": 1,
              "created_utc": "2026-01-13 22:36:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzft48u",
                  "author": "Low-Efficiency-9756",
                  "text": "\nJust because you donâ€™t build MCPs like that doesnâ€™t mean the rest of us donâ€™t.\n\nStructured data isnâ€™t about what LLMs â€œwork better withâ€ LLMs are stateless. They donâ€™t have data, but data is prose. When a tool returns coordinates in 3D space, thatâ€™s the interface between a stateless model and actual persistent state. The structure exists for the database, the game engine, the system, not the model. However structured data is useful for the user behind the scene, we should all be designing our tool outputs for structured data so humans can easily parse it as well. \n\nAnd â€œLLM proposes, tool validates and executesâ€ is invariant maintenance. The protocol doesnâ€™t prescribe your business rules, it ensures all mutations flow through server-controlled logic where you enforce them. Thatâ€™s the architecture.\nMCP isnâ€™t a workaround. Shallow implementations are.",
                  "score": 6,
                  "created_utc": "2026-01-13 22:53:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzhwls2",
          "author": "d2000e",
          "text": "I wrote this a while back, explaining that MCP is just one of several methods to get work done with LLMs, with other interfaces like REST and CLI being great options depending on what is needed and the context of the work.\n\n[https://www.localmemory.co/blog/the-mcp-backlash-is-missing-the-point](https://www.localmemory.co/blog/the-mcp-backlash-is-missing-the-point)",
          "score": 2,
          "created_utc": "2026-01-14 06:32:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj5tyj",
              "author": "Accomplished-Emu8030",
              "text": "Really great article. Particularly \"Domain-centric operations with semantic guarantees\". This is exactly what I'm talking about. It's funny because there are some people who view this article and see this as some negative feedback to MCPs when in reality we're really just highlighting what needs actual focus.",
              "score": 2,
              "created_utc": "2026-01-14 13:02:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjgwqo",
                  "author": "d2000e",
                  "text": "Appreciate the feedback. I think people forget that they have agency. No one has to use MCP or any other protocol. We are all free to use whatever works for our needs.\n\nFor example, I frequently use plain old JSON-RPC instead of installing an MCP. However, there are times when I need to install an MCP or use bash scripts to automate CLI commands. This is the beauty of software engineering. There is no \"one right way\" for anything.",
                  "score": 2,
                  "created_utc": "2026-01-14 14:05:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzinaq6",
          "author": "actual-time-traveler",
          "text": "Iâ€™m all for opinionated ideas in tool protocols, thanks for the work. I starred your repo and would love to give it a spin, but Iâ€™m not smart enough to understand it without examples. \n\nI really like that audit and logging are first class. The fact that MCP didnâ€™t initially spin out with built in tracing is bewildering to me.\n\nEdit: forgot to ask how does the LLM discover and load the tools into context?",
          "score": 2,
          "created_utc": "2026-01-14 10:42:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjacer",
              "author": "Accomplished-Emu8030",
              "text": "We implement a search endpoint using embeddings that can be used for semantic search. We're debating about implementing a \"code mode\" which means the tools embed their source code and provide a ripgrep like endpoint, but for our use case, the search endpoint is sufficient.",
              "score": 2,
              "created_utc": "2026-01-14 13:29:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzl9czn",
          "author": "promethe42",
          "text": "I agree that code mode is better and more agentic.\n\nBut (and that's a big but) Claude Code has to burn loooots of token before being able to do integration/glue code that works.\n\nIn the other hand, code mode based on MCP tools is a good middleground when the tool schemas are clean and documented. Plus progressive disclosure can easily be implemented based on the MCP tools. Not so much on an entire code base.",
          "score": 2,
          "created_utc": "2026-01-14 19:05:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn8eam",
              "author": "Accomplished-Emu8030",
              "text": "\\> But (and that's a big but) Claude Code has to burn loooots of token before being able to do integration/glue code that works.\n\nClaude creates scripts on the fly and uses those so it's not that bad.\n\n\\> In the other hand, code mode based on MCP tools is a good middleground when the tool schemas are clean and documented.\n\nDefinitely, but it's a shit show because of how MCPs work. Even if an MCP is completely stateless, MCPs are not cross-system invariant in general. Ultimately this means you are back to just coding a server that works for your use-case which is basically just API programming again. With Operai, you can code once and it will literally expand (this is a rust joke) to every use-case (API, tools, even code mode \\[but we're not convinced code mode is actually the best solution\\]).",
              "score": 1,
              "created_utc": "2026-01-15 00:48:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzp0xkp",
                  "author": "promethe42",
                  "text": "But to create integration scripts and debug them, the LLM must inspect the code base. That burns a lot of token.\n\n\nIf the client - say Claude Code - were to save said script automatically as a shareable/reusable skill for example then that would truly be the best solution.Â ",
                  "score": 1,
                  "created_utc": "2026-01-15 08:13:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzh43nj",
          "author": "socrateslee",
          "text": "\\> In theory, if a model could generate perfect code every time, you wouldnâ€™t need MCP.\n\nI just think MCP provides a standard way to prompt what tool calls are. It is mainly used for direct communicate with LLMs. And generated code is more like to build something not only for direct use of LLMs.",
          "score": 1,
          "created_utc": "2026-01-14 03:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh543x",
              "author": "socrateslee",
              "text": "And MCP are probably 'the final interface', except it evolves itself.\n\nMCP come out at right time and only get much more adoption in the future. Consider MCP like the distance between two horses in the AI age, it already get adopted(and growing), it only becomes the distance between two wheels of cars or trains as it developed.",
              "score": 1,
              "created_utc": "2026-01-14 03:18:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhrvcq",
          "author": "Big-Victory-3948",
          "text": "MCP's are an amazing fad!",
          "score": 1,
          "created_utc": "2026-01-14 05:54:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzldhxs",
              "author": "Live_Vermicelli4307",
              "text": "Well, let's see how far along we can make it then.",
              "score": 1,
              "created_utc": "2026-01-14 19:24:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzi1fp3",
          "author": "Virviil",
          "text": "So, why cdylib in a world where wasm is already invented?",
          "score": 1,
          "created_utc": "2026-01-14 07:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzj53le",
              "author": "Accomplished-Emu8030",
              "text": "This is on our roadmap. We want to be able to plug in to the JS community but we've been using this in server-sided/client-side code that uses Rust so far.",
              "score": 1,
              "created_utc": "2026-01-14 12:58:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzj7xmy",
                  "author": "Virviil",
                  "text": "i want to work on this. Are you hiring?",
                  "score": 1,
                  "created_utc": "2026-01-14 13:15:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzj8tky",
          "author": "Accomplished-Emu8030",
          "text": "Hey everyone. I really appreciate all the comments. The ultimate goal of this article is to present how much care needs to be made when building programs and reducing the spotlight of MCPs back to classical backend programming. Also, Operai is still in its infancy so it's experimental. We recently got it working for some of our backend infra so now we're focusing pushing this upstream and making the DX impeccable :).",
          "score": 1,
          "created_utc": "2026-01-14 13:21:05",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzoqplr",
          "author": "moonshinemclanmower",
          "text": "Mcp is a protocol... its api with, but with modern consteraints applied for realtime observation during persistent compute, and yes, its here to say, we wont go back to non streaming apis again. That's because of our CAP theorem needs when it comes to internet calls that have to have state now",
          "score": 1,
          "created_utc": "2026-01-15 06:41:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0979vs",
          "author": "McNemarra",
          "text": "I mean I think I understand what you are trying to solve and the problem is real but it just seems like everyone will build their own version of this and the big boys will win out. I'm certain this idea is being done a hundred times over a leading ai companies but good luck. Great website btw",
          "score": 1,
          "created_utc": "2026-01-18 07:34:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhy0se",
          "author": "martial_fluidity",
          "text": "Except your ai generated connector code will break as soon as that service releases a breaking change.",
          "score": -1,
          "created_utc": "2026-01-14 06:45:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzy6bm9",
              "author": "Illustrious_Eye_1280",
              "text": "And then it gets patched up again, so what's the issue.",
              "score": 1,
              "created_utc": "2026-01-16 16:48:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qf9day",
      "title": "MCP Tool Lazy Loading and TypeScript Sandbox with Workspace Output, for Claude Code. Context savings: ~97% reduction (48k to 1.1k tokens) for multi-tool workflows.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "author": "milkphetamine",
      "created_utc": "2026-01-17 09:57:25",
      "score": 24,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "https://github.com/elb-pr/claudikins-tool-executor\n\nAnthropic's API users getÂ advanced tool use - Claude writes code, executes N tools in a sandbox, returns once. Claude Code users get serial execution and lazy loading. Tool Executor brings the API pattern to Claude Code..\n\nClaude will:\n1. Use `search_tools` to find relevant tools\n2. Use `get_tool_schema` to load the exact parameters\n3. Use `execute_code` to run the generation in one shot\n \nMCP tools often return large payloads. Web scrapes, code analysis, generated content - all eating context.\n\nTool Executor intercepts responses over 200 characters and saves them to workspace files. Your code receives a reference:\n\nUnlike native MCP, Tool Executor injects guidance every session. Claude knows:\n- What MCP categories exist (ai-models, code-nav, web, knowledge, reasoning, ui)\n- When to use MCP vs basic tools\n- The exact search â†’ schema â†’ execute workflow\n\nNo guessing. No forgetting.\n\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qf9day/mcp_tool_lazy_loading_and_typescript_sandbox_with/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04206p",
          "author": "punkpeye",
          "text": "/u/milkphetamine this looks like theoretically something that we could provide as part our [MCP gateway](https://glama.ai/mcp) service?\n\nMy thinking is... people deploy/add their MCP servers, then we provide a single MCP that has access to all other MCPs, that utilizes your project to actually resolve and execute tools.",
          "score": 1,
          "created_utc": "2026-01-17 14:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o047iz9",
              "author": "milkphetamine",
              "text": "Yeah that could definitely work no doubt. Feel free to message me",
              "score": 1,
              "created_utc": "2026-01-17 15:15:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o047vg7",
                  "author": "punkpeye",
                  "text": "Thanks. I will dig deeper later this afternoon and message you if any questions. A version of this has been on a TODO for a long time",
                  "score": 1,
                  "created_utc": "2026-01-17 15:17:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o030fjr",
          "author": "promethe42",
          "text": "Very good idea.\n\nTo make it even more efficient, you could mimic the skill progressive disclosure and add a list of 100 char name + description of the tools in the system prompt.\n\nIt will massively reduce the number of calls to \\`search\\_tools\\` to find relevant tools.",
          "score": 1,
          "created_utc": "2026-01-17 10:18:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o030q3k",
              "author": "milkphetamine",
              "text": "Interesting! The hooks and schema seem to do okay for chaining but there's definitely a few moments of okay that's a lot of calls but the tokens are minimal so, it's just me getting too lost in it at that point aha!\n\nOne issue I need to address though, output saves to the mcp workspace. Need to adjust it to save to project workspace. Had a few hiccups thereðŸ˜…",
              "score": 2,
              "created_utc": "2026-01-17 10:21:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o03o5b2",
              "author": "Hofi2010",
              "text": "That was part of the problem why Anthropic proposed code use for MCP tools because the list of all tools and description are â€žeatingâ€œ the context window.",
              "score": 2,
              "created_utc": "2026-01-17 13:29:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04xxbn",
                  "author": "promethe42",
                  "text": "The schemas are eating a lot of tokens. But tool names and descriptions are just like skill names and descriptions.Â ",
                  "score": 3,
                  "created_utc": "2026-01-17 17:20:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o033c8m",
          "author": "Stock-Protection-453",
          "text": "Great effort, I also walked a similar path with Natural Context Provider [https://github.com/portel-dev/ncp](https://github.com/portel-dev/ncp)",
          "score": 0,
          "created_utc": "2026-01-17 10:45:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfop2k",
      "title": "n8n MCP Server â€“ Enables Large Language Models to interact with n8n automation instances through the Model Context Protocol. Supports workflow management, execution, credentials handling, and security audits through natural language commands.",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server",
      "author": "modelcontextprotocol",
      "created_utc": "2026-01-17 21:00:06",
      "score": 21,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qfop2k/n8n_mcp_server_enables_large_language_models_to/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o067jp8",
          "author": "modelcontextprotocol",
          "text": "This server has 33 tools:\n\n- [activate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/activate-workflow) â€“ Enable an n8n automation workflow to run by providing its ID. Use this tool to activate workflows for automated task execution.\n- [create-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-credential) â€“ Create authentication credentials for n8n automation workflows. Specify credential type and required data to enable nodes to connect to external services and APIs.\n- [create-project](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-project) â€“ Create new projects in n8n automation platform for organizing workflows and resources, requiring Enterprise license with project management enabled.\n- [create-tag](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-tag) â€“ Add tags to organize workflows in your n8n automation instance. Use this tool to create new tags for categorizing and managing automation processes.\n- [create-users](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-users) â€“ Add users to your n8n automation instance by specifying email addresses and roles to manage access and permissions.\n- [create-variable](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-variable) â€“ Create variables in n8n to store and share data across workflows. Requires n8n Enterprise license with variable management enabled.\n- [create-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/create-workflow) â€“ Build automation workflows in n8n by defining nodes and connections to automate business processes and integrate applications.\n- [deactivate-workflow](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/deactivate-workflow) â€“ Stop a workflow from running by deactivating it using its ID. This prevents automated processes from executing until reactivated.\n- [delete-credential](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-credential) â€“ Remove stored credentials by ID from n8n automation instances. Securely delete authentication data you own to manage access controls.\n- [delete-execution](https://glama.ai/mcp/servers/@guinness77/n8n-mcp-server/tools/delete-execution) â€“ Remove a specific workflow execution by ID to manage automation history and maintain system performance.",
          "score": 3,
          "created_utc": "2026-01-17 21:00:07",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o06up5r",
          "author": "astrokat79",
          "text": "Any chance it has clouldflared auth for n8n instances behind token or email auth?",
          "score": 1,
          "created_utc": "2026-01-17 22:56:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcwp09",
      "title": "I built the MCP inspector I always wanted â€“ no login, full spec support, state in URL",
      "subreddit": "mcp",
      "url": "https://glama.ai/mcp/inspector",
      "author": "punkpeye",
      "created_utc": "2026-01-14 19:24:18",
      "score": 18,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcwp09/i_built_the_mcp_inspector_i_always_wanted_no/",
      "domain": "glama.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qcyrzk",
      "title": "Follow-up from yesterday's Code Mode post - MCP setup guide",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "author": "dinkinflika0",
      "created_utc": "2026-01-14 20:41:28",
      "score": 17,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "Got a few questions in my dms after yesterday's post about Code Mode, so writing up the actual MCP setup process since the folks asked how to get started.\n\n**Basic connection is pretty simple:**\n\nConnect to any MCP server via STDIO, HTTP, or SSE. For local tools like filesystem stuff, STDIO works fine. Remote services use HTTP.\n\n`{ \"mcp\": { \"client_configs\": [{ \"name\": \"filesystem\", \"connection_type\": \"stdio\", \"stdio_config\": { \"command\": \"npx\", \"args\": [\"-y\", \"@anthropic/mcp-filesystem\"] } }] } }`\n\n**Important security detail:**\n\nTool calls from the LLM are just suggestions by default. Nothing actually executes unless you explicitly call the execution endpoint. This caught me off guard initially but it's the right design - prevents accidental API calls or data modifications.\n\nIf you want autonomous execution, enable Agent Mode and specify which tools can auto-execute via `tools_to_auto_execute`.\n\n**Code Mode setup (from yesterday):**\n\nSet `is_code_mode_client: true` on your MCP clients. LLM writes TypeScript to orchestrate tools instead of the standard iterative approach. Cuts tokens significantly when you have multiple servers.\n\n**Tool filtering:**\n\nControl which tools are available per request or per virtual key. Useful for different environments or team permissions.\n\nBifrost can also act as an MCP server - expose your tools to Claude Desktop or other MCP clients through the gateway URL.\n\nSetup docs: [https://docs.getbifrost.ai/features/mcp](https://docs.getbifrost.ai/features/mcp)  \nGithub: [https://github.com/maximhq/bifrost](https://github.com/maximhq/bifrost)\n\nAnyone run into issues setting this up?",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qcyrzk/followup_from_yesterdays_code_mode_post_mcp_setup/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbwcuq",
      "title": "Consolidated 195 tools down to 28 using action enums",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbwcuq/consolidated_195_tools_down_to_28_using_action/",
      "author": "Low-Efficiency-9756",
      "created_utc": "2026-01-13 16:44:56",
      "score": 15,
      "num_comments": 15,
      "upvote_ratio": 0.94,
      "text": "Working on an RPG MCP server, we hit a scaling problem: every CRUD operation got its own tool. Characters alone had \\`create\\_character\\`, \\`get\\_character\\`, \\`update\\_character\\`, \\`delete\\_character\\`, \\`list\\_characters\\`. Multiply that across items, quests, combat, parties, etc. and we ended up with 195 tools and \\~50k tokens of schema definitions.\n\nThe fix was simple. Instead of separate tools per operation, we made domain tools with an \\`action\\` enum:\n\nBefore\n\ncreate\\_character\n\nget\\_character\n\nupdate\\_character\n\ndelete\\_character\n\nlist\\_characters\n\nAfter\n\ncharacter\\_manage(action: \"create\" | \"get\" | \"update\" | \"delete\" | \"list\" | \"search\")\n\nApplied across the board, this dropped us to 28 tools and \\~6-8k tokens of schema. Same functionality, 85% less overhead.\n\nWe also added fuzzy matching on action values so typos get helpful suggestions instead of opaque failures.\n\nIf youâ€™re building MCP servers and your tool count is ballooning, action enums might be worth considering. Happy to answer questions about the implementation.",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qbwcuq/consolidated_195_tools_down_to_28_using_action/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzeaq62",
          "author": "Crafty_Disk_7026",
          "text": "Great tip, simple APIs with very concrete types always better with llm.   \n\nFor example never use a generic dictionary in Python as an api input.  Ensure it's string: string or string:number or Cat:Dog.   Or else the llm will just put anything there",
          "score": 3,
          "created_utc": "2026-01-13 18:39:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzipeju",
              "author": "TechToolsForYourBiz",
              "text": "llms are just typescript underneath, confirmed",
              "score": 2,
              "created_utc": "2026-01-14 11:00:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzf9aad",
              "author": "Low-Efficiency-9756",
              "text": "Thanks! Totally agree on specifying types. One of the drivers behind the consolidation was to make every parameter as explicit as possible so the model canâ€™t â€œmake upâ€ keys or values. \n\nFor example, most of our actions are enums and many of the nested fields are typed (string, integer, even specific regex patterns) rather than just any. Thatâ€™s eliminated a lot of ambiguity and improved reliability and fuzzy matching helps us to ensure that llm typos or close hallucinations still can call a tool even without exact syntax.",
              "score": 1,
              "created_utc": "2026-01-13 21:18:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzexbbd",
          "author": "Biruleiby",
          "text": "love the approach. i can see this being really useful once tool counts start to blow up.  \nhave you thought about how youâ€™d do per-action rules later (like some actions being more restricted), or is that out of scope for your setup?",
          "score": 3,
          "created_utc": "2026-01-13 20:22:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfaoa6",
              "author": "Low-Efficiency-9756",
              "text": "We havenâ€™t implemented per-action restrictions yet, but itâ€™s definitely something weâ€™ll need.\n\nFunny enough, Iâ€™m hitting a related problem right now. We have a simple math_tools with a dice roll function, and we have combat_manage actions that handle attacks with all the context like attacker stats, target AC, spell AoE calculations, skill checks, the works. The LLM keeps reaching for the simple dice roll instead of the combat actions that would do the heavy lifting for it.\nI think the model sees â€œI need to roll diceâ€ and pattern-matches to the simpler tool, even though the domain-specific one would give it a complete resolution in one call. Been trying to steer it with prompting but itâ€™s stubborn. The math tools were meant for crazy stuff like calculating the trajectory of a cannon ball, or calculating how far an enemy is that is flying in 3d space not simple dice rolls. \n\nSo yeah, per-action rules or even just tool prioritization/hints would help a lot. Something like â€œprefer combat_manage.attack over math_tools.roll when in combatâ€ at the schema level. Havenâ€™t figured out the cleanest way to express that yet.",
              "score": 1,
              "created_utc": "2026-01-13 21:25:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjeyxq",
                  "author": "Biruleiby",
                  "text": "oh wow, yeah iâ€™ve seen that exact behavior. two small things that sometimes help:\n\n1. rename the dice tool to make it feel â€œadvanced onlyâ€ (like `math_tools.advanced_roll` / `raw_dice_roll`) and in the description say â€œnot for combatâ€.\n2. in `combat_manage.attack` description, be super explicit: â€œuse this for any combat roll, includes dice + modifiers + resolutionâ€.\n\nwhat client are you testing with (Claude Desktop / Cursor / custom)? and do you pass any â€œmodeâ€ context like `state=combat`?",
                  "score": 2,
                  "created_utc": "2026-01-14 13:55:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzfiigp",
          "author": "forgotMyPrevious",
          "text": "Ahh interesting, I totally would have split operations over dedicated tools too, because traditionally that would be the â€œcleanestâ€ way to go about it..",
          "score": 2,
          "created_utc": "2026-01-13 22:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfkbw1",
              "author": "Low-Efficiency-9756",
              "text": "Yeah itâ€™s been a learning curve for me for sure. Iâ€™m transitioning from heavy equipment operator into a more developer oriented hobby and I donâ€™t have a strong idea of what best practices are.",
              "score": 1,
              "created_utc": "2026-01-13 22:09:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhj0pj",
          "author": "raghav-mcpjungle",
          "text": "Pretty wild! Great way to reduce the tokens.  \nI'm curious though - did you also notice improvement in the LLM's accuracy?  \nI mean, the LLM still sees the same number of actions it can take overall. But did it start calling the right tool+action more often just because the token count was reduced?",
          "score": 2,
          "created_utc": "2026-01-14 04:48:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzho11y",
              "author": "Low-Efficiency-9756",
              "text": "Actually Iâ€™ve initially got less coherency than I used to have in a weird way. Earlier versions the models usually had no issue with calling the right tools, just mostly in the wrong order (need to create an item before adding to inventory type errors) \n\nIn this newest release, weâ€™re having issues getting the model to use the combat suite instead of the math suite for rolling attacks. However it handles it just fine doing manual action economy instead of the automated tool for it. \n\nThe biggest plus is that I can get way longer and cheaper sessions now that context isnâ€™t stuffed so heavily.",
              "score": 2,
              "created_utc": "2026-01-14 05:24:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzi23me",
          "author": "Maasu",
          "text": "Nice, but I think you can keep going.\n\nCheck out the meta tools pattern on this repo https://github.com/ScottRBK/forgetful\n\nThe how to use pattern almost becomes lazy loading of skills for an MCP tool",
          "score": 2,
          "created_utc": "2026-01-14 07:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzipc5e",
          "author": "TechToolsForYourBiz",
          "text": "clever",
          "score": 2,
          "created_utc": "2026-01-14 11:00:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzje64f",
          "author": "0xKoller",
          "text": "Love this!\n\nHow much was the cost of migrating this? I have some friends that have some of +100 tools",
          "score": 2,
          "created_utc": "2026-01-14 13:51:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkr1p3",
              "author": "Low-Efficiency-9756",
              "text": "Thanks! Time cost for me was about 3 hours. I donâ€™t track inference costs as I use Claude code. It was done in one sitting within the 5 hour window on the $100 plan.",
              "score": 2,
              "created_utc": "2026-01-14 17:44:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qcjnc3",
      "title": "Built a YouTube MCP Server. Routed the scraping through an API so I don't have to manage proxies",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "author": "nikhonit",
      "created_utc": "2026-01-14 10:13:29",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "been building a few agent workflows that need to ingest youtube content (summarizers, sentiment analysis, etc).\n\nthe biggest bottleneck wasn't the agent logicâ€”it was the actual data fetching. local scrapers like youtube-dl or ytdlp are great but they get throttled/blocked constantly if you run them at any real volume, and managing a rotating proxy pool for a side project is overkill.\n\nso i built a dedicated YouTube MCP Server that offloads the heavy lifting.\n\nwhat it does:\n\n* exposes tools to fetch full transcripts (with timestamps). \n* grabs video metadata (views, likes, description). \n* handles the \"rate limit\" dance externally.\n\n\n\nthe stack: instead of raw-dogging the youtube html, i routed the requests through [TranscriptAPI](https://transcriptapi.com/r/reddit/mcp)  \n  \nit basically acts as the specialized layer to ensure the data actually comes back clean without the \"verify you are human\" capchas blocking the agent.\n\nallows you to plug youtube data into cursor, windsurf, or any custom mcp client without worrying about your ip getting flagged.\n\nif youâ€™re building video-aware agents, this should save you some headache.",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qcjnc3/built_a_youtube_mcp_server_routed_the_scraping/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzipztq",
          "author": "actual-time-traveler",
          "text": "Can you post a repo?",
          "score": 2,
          "created_utc": "2026-01-14 11:05:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzixjbq",
          "author": "0xKoller",
          "text": "this sounds cool!\n\ncan you share a video of a use case?",
          "score": 2,
          "created_utc": "2026-01-14 12:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzk1o7u",
          "author": "arnaldodelisio",
          "text": "I think too much headache for something very simple. Going to share my youtube transcription mcp when I am back to the laptop.",
          "score": 2,
          "created_utc": "2026-01-14 15:49:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzkosus",
          "author": "First-Line9299",
          "text": "Try this one. They have youtube endpoints for searching YT videos and scraping subtitles https://docs.anysite.io/mcp-server/unlimited-plan",
          "score": 1,
          "created_utc": "2026-01-14 17:34:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrqvsh",
          "author": "Live_Vermicelli4307",
          "text": "Would love to see it working in action!",
          "score": 1,
          "created_utc": "2026-01-15 18:11:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf3nm3",
      "title": "mcp-graph-engine - network algorithms and visualisation for your agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "author": "utilitydelta",
      "created_utc": "2026-01-17 04:34:47",
      "score": 11,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "MCP that your agents can use to build network graphs:\n\n[https://github.com/utilitydelta/mcp-graph-engine](https://github.com/utilitydelta/mcp-graph-engine)\n\nBuild a network from your problem domain and use graph algorithms like page rank and cycle detection to analyze it.\n\nYou can also visualize graphs being built in your browser, updated in real time from your agent.\n\nTool set is light and docs are small. They won't pollute your context window. Tell me what you think!\n\n[LOTR character network](https://preview.redd.it/3vokfkl38udg1.png?width=1213&format=png&auto=webp&s=d4a374431dffb5f2bb86903dd328ed05fc5869c2)\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qf3nm3/mcpgraphengine_network_algorithms_and/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o03tbv4",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-17 14:00:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04dei2",
              "author": "Crafty_Disk_7026",
              "text": "Your better off using ast",
              "score": 1,
              "created_utc": "2026-01-17 15:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05xqy6",
          "author": "H0BB5",
          "text": "Nice! Does it have madge support?",
          "score": 1,
          "created_utc": "2026-01-17 20:09:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o063w3b",
              "author": "utilitydelta",
              "text": "Don't you find these kinds of tools really noisy? It's doesn't build any level of abstraction - just funcA() -> funcB(). Personally I don't find it valuable, it becomes chaos in anything but toy code bases. You gotta use the LLM at what it's good at - checking data flow, mapping out your design invariants,visualising service dependencies, all the really important stuff!",
              "score": 1,
              "created_utc": "2026-01-17 20:41:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0af6rs",
          "author": "joanmiro",
          "text": "I was looking smith like this",
          "score": 1,
          "created_utc": "2026-01-18 13:46:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpioc",
      "title": "Is anybody using MCPs with ChatGPT?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "author": "raghav-mcpjungle",
      "created_utc": "2026-01-15 17:17:33",
      "score": 10,
      "num_comments": 15,
      "upvote_ratio": 0.92,
      "text": "I use ChatGPT mostly for all the non-coding stuff (brainstorms, travel, life, etc)\n\nI recently started connecting my MCPs to chatgpt via my gateway, mainly out of curiosity about the possibilities.\n\nI quickly realized that I mostly use MCPs for tech work only.\n\nOf course, chatgpt has \"Apps\", which are essentially mcp servers only. I just don't use most of them.\n\n  \nSo is anyone a \"power user\" of mcps on gpt?\n\nAnd are you using it for personal stuff or at your org?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qdpioc/is_anybody_using_mcps_with_chatgpt/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzwdl0g",
          "author": "pswithlove",
          "text": "Connected it to clickhouse and team is loving it. No more asks to build UIs or reports or whatever. They simply chat with the data and Itâ€™s good enough.",
          "score": 2,
          "created_utc": "2026-01-16 10:49:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrvnl4",
          "author": "0xKoller",
          "text": "Just for really dumb stuff like calendar to plan a trip, after that nothing",
          "score": 1,
          "created_utc": "2026-01-15 18:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp2k4",
              "author": "raghav-mcpjungle",
              "text": "hmm fair, I can see some of my work becomign smoother if I integrate my calendar into gpt",
              "score": 1,
              "created_utc": "2026-01-16 07:07:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwp6az",
                  "author": "0xKoller",
                  "text": "Yeah but is not the big thing for now... untill stuff like emails unlocks maybe not that usefull\n\nyou can check with the Google Drive app, that one is kind of usefull if you want to avoid the hustle to copy/paste files",
                  "score": 1,
                  "created_utc": "2026-01-16 12:19:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzshpgk",
          "author": "naseemalnaji-mcpcat",
          "text": "Based on our findings at MCPcat <5% of agents are coming through ChatGPT ðŸ˜¬",
          "score": 1,
          "created_utc": "2026-01-15 20:12:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvp4ez",
              "author": "raghav-mcpjungle",
              "text": "wow. where's the majority coming from I wonder",
              "score": 1,
              "created_utc": "2026-01-16 07:08:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsziii",
          "author": "digit1024",
          "text": "I use my MCp with multiple providers - sometimes with openAI, yet I find open AI overpriced ( via API ) comparing to alternatives.  \nI have to admit that I don't like the company...  this is basically a company that turned into profit company from foundation at the very moment they discovered something profitable . Shame on them.  \nAnd I hate Idea of entre humanity sending money to 4 big AI companies sooooo...",
          "score": 1,
          "created_utc": "2026-01-15 21:35:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzt7fww",
              "author": "xFloaty",
              "text": "Theyâ€™re asking about using MCPs on the ChatGPT website via custom connectors",
              "score": 2,
              "created_utc": "2026-01-15 22:12:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztir9g",
                  "author": "digit1024",
                  "text": "Ohhh..... Someone is using websites? :) thanks for pointing it ðŸ˜‰\nThen the answer is no",
                  "score": 1,
                  "created_utc": "2026-01-15 23:09:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt76e2",
          "author": "tinyhousefever",
          "text": "I use MCP at ChatGTP to create, edit, publish content and  iterate SEO of my WordPress website.",
          "score": 1,
          "created_utc": "2026-01-15 22:11:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvpcyl",
              "author": "raghav-mcpjungle",
              "text": "that's the first good enterprise use case I've heard of. Otherwise people mostly seem to use it for personal only. Good stuff!",
              "score": 1,
              "created_utc": "2026-01-16 07:10:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuvr5d",
          "author": "NeoMCP_AI",
          "text": "We provide MCP servers for various tools, mainly in the GTM space. Does anyone want to try it out?",
          "score": 1,
          "created_utc": "2026-01-16 03:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzri3a0",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -1,
          "created_utc": "2026-01-15 17:32:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzst6so",
              "author": "Ordinary-You8102",
              "text": "Why u use google?",
              "score": 1,
              "created_utc": "2026-01-15 21:06:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzstcnl",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 0,
                  "created_utc": "2026-01-15 21:07:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qfahkm",
      "title": "Is there a free MCP for web and documentation search? (OpenAI Codex)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "author": "jakehj5167",
      "created_utc": "2026-01-17 11:04:43",
      "score": 10,
      "num_comments": 12,
      "upvote_ratio": 0.82,
      "text": "I'm struggling to find a way for Codex to perform thorough searches without having to pay for a plan or wasting tokens. What I've tried:\n\n* Codex's built-in web search tool: can't browse JS-only sites. In my case, it's unable to browse developer.apple.com.\n* \\`microsoft/playwright-mcp\\`: It's able to perform searches and read pages, but very heavy hit on context. Burned through 10% of the context window for a single search.\n* [Exa.ai](http://Exa.ai), [context7.com](http://context7.com), Brave Search MCP: I'm strongly turned off by the pay-per-thousand model or caps on free plans. I understand they have to make money, it's just not what I want to spend money on.\n* [https://github.com/arabold/docs-mcp-server:](https://github.com/arabold/docs-mcp-server:) I didn't test this, but I was turned off by the fact you have to run the server in the background instead of allowing it to be booted by the Codex instance (via npx) like it can for other kinds of MCP servers.\n\nDoes anyone have a solution to this that hits on all marks: free, able to read websites including JS ones, thorough and high-quality?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qfahkm/is_there_a_free_mcp_for_web_and_documentation/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o04jhyh",
          "author": "punkpeye",
          "text": "I think it is unlikely you will find something like Exa for free. I have implemented comparable service to Exa for our internal use case (we make hundreds of thousands of requests) and it took a lot of effort and still relies on external services (ie not free)\n\nMaybe if you define the problem better, you will find better solutions.\n\nLike, maybe you just need something that can navigate sites using browser and return markdown instead of html. There are a few of those",
          "score": 1,
          "created_utc": "2026-01-17 16:13:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05eqze",
          "author": "Technical-Shock-7385",
          "text": "If you Only use sub-agents for playwright-mcp you got resume of results without burning context window ?",
          "score": 1,
          "created_utc": "2026-01-17 18:38:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09qx9q",
          "author": "waxyslave",
          "text": "tavily , parallel. Very generous monthly allowances. If you want something even more basic there are website -> markdown chrome extensions.",
          "score": 1,
          "created_utc": "2026-01-18 10:35:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a5szf",
          "author": "phdyle",
          "text": "Ref.tools",
          "score": 1,
          "created_utc": "2026-01-18 12:43:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o037f05",
          "author": "iohans",
          "text": "Try building your own. It will not be better than you listed, but you can get better over time and solve your current need.\n\nHybrid RAG, vector DB, rerankimg, use a sentence transformer for emeddings. Put your knowledge files in a folder, index, and wrap in an MCP Server. Claude Code or Codex will get you there in an hour. Then, hours of refining. It will be fun and yours.",
          "score": 0,
          "created_utc": "2026-01-17 11:22:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o038moh",
              "author": "Express-One-1096",
              "text": "Yeah man, why not just your own llm while heâ€™s at it, maybe design his own ram aswell",
              "score": 2,
              "created_utc": "2026-01-17 11:33:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o043vlj",
                  "author": "BeautifulFeature3650",
                  "text": "Damn",
                  "score": 1,
                  "created_utc": "2026-01-17 14:56:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o08ikt3",
                  "author": "Doomtrain86",
                  "text": "Yeah man, why do ANYTHING yourself ! No need for that at all !",
                  "score": 1,
                  "created_utc": "2026-01-18 04:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o03lyu1",
              "author": "jakehj5167",
              "text": "It's possible, and I thought about adjusting \\`playwright-mcp\\` to be a bit lighter, but it's honestly too deep of a rabbit hole for me. That's why I hoped people had found a way around this issue already.",
              "score": 1,
              "created_utc": "2026-01-17 13:16:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o04uu8d",
                  "author": "Terrariant",
                  "text": "Itâ€™s actually way easier than you think. I started playing around with local LLMs about 4 days ago and already have a â€œcomposer model fileâ€ that runs an LLM to select one of 9 other models that is appropriate for the prompt. RAG and database stuff I am looking into next.\n\nBut yeah, really itâ€™s becoming more of a solved problem. You can have Gemini walk you through setting it up, even",
                  "score": 2,
                  "created_utc": "2026-01-17 17:06:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03sd53",
          "author": "jakehj5167",
          "text": "So far I've found [https://github.com/jae-jae/fetcher-mcp](https://github.com/jae-jae/fetcher-mcp) which mostly does what I want, but it only started working well when I asked Codex to run it with \\`disableMedia: false\\`.",
          "score": 0,
          "created_utc": "2026-01-17 13:54:38",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qghfy6",
      "title": "GitHub - eznix86/mcp-gateway: Too much tools in context. Use a gateway",
      "subreddit": "mcp",
      "url": "https://github.com/eznix86/mcp-gateway",
      "author": "Eznix86",
      "created_utc": "2026-01-18 19:13:07",
      "score": 10,
      "num_comments": 8,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qghfy6/github_eznix86mcpgateway_too_much_tools_in/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0e9kn9",
          "author": "milkphetamine",
          "text": "https://github.com/elb-pr/claudikins-tool-executor, I have this on git too, anthropic released lazy loading like a day after which was annoying but they didn't give us the sandbox lmao. I've got it up and running now it's super efficient",
          "score": 1,
          "created_utc": "2026-01-19 01:18:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ekqzo",
              "author": "Eznix86",
              "text": "Amazing work :)",
              "score": 1,
              "created_utc": "2026-01-19 02:21:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cdy0k",
          "author": "baykarmehmet",
          "text": "Thatâ€™s awesome! I just left the first star! Iâ€™m building something similar using Swift. Itâ€™s based on Metamcp and also includes a tool search feature.",
          "score": 1,
          "created_utc": "2026-01-18 19:33:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ce7r4",
              "author": "Eznix86",
              "text": "Thank you very much!",
              "score": 1,
              "created_utc": "2026-01-18 19:34:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0clwn7",
          "author": "Difficult_Hand_509",
          "text": "Are you planning to add docker support to this. This look awesome. I also use MetaMCP",
          "score": 0,
          "created_utc": "2026-01-18 20:12:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cndoh",
              "author": "Eznix86",
              "text": "I can dockerize it. Is http transport good for you?",
              "score": 1,
              "created_utc": "2026-01-18 20:19:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0gatag",
              "author": "Eznix86",
              "text": "docker added. :3000/mcp to read from http transport.",
              "score": 1,
              "created_utc": "2026-01-19 10:04:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfvkah",
      "title": "FrontMCP: The TypeScript Way to Build MCP Servers",
      "subreddit": "mcp",
      "url": "https://i.redd.it/kadcv1lkk0eg1.png",
      "author": "DavidAntoon",
      "created_utc": "2026-01-18 01:52:47",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qfvkah/frontmcp_the_typescript_way_to_build_mcp_servers/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o07wqlb",
          "author": "punkpeye",
          "text": "Can you compare it to fastmcp?",
          "score": 2,
          "created_utc": "2026-01-18 02:16:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o089fpu",
              "author": "DavidAntoon",
              "text": "In summary, FrontMCP and FastMCP both greatly simplify building MCP servers, but they cater to different developer preferences. \n\nFrontMCP brings a TypeScript, enterprise-web approach: structured, heavily tooled, and extensible via plugins ï¿¼ ï¿¼. FastMCP brings a Pythonic approach: minimal ceremony, flexibility, and integration with Pythonâ€™s ecosystem ï¿¼. \n\nFrontMCP tends to be better when you need robust typing, modular architecture (multiple apps/tenants), and out-of-the-box solutions for cross-cutting concerns. \nFastMCP is better when you need quick development in Python or want to compose and deploy MCP services with existing Python infrastructure. Both adhere to the MCP specification and support core features like streaming responses, sessions, and secure transport, so either can get the job done. The choice often comes down to the language and feature philosophy that fit your project best. \n\nFrontMCP clearly stands out in areas like TypeScript DX and plugin-based extensibility, which can give it an edge for complex, large-scale applications that require maintainability and strong typing ï¿¼ï¿¼.\nFastMCPâ€™s maturity and simplicity make it a reliable choice for Python-centric teams or simpler use cases where quick development is paramount.",
              "score": 2,
              "created_utc": "2026-01-18 03:27:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fjhpx",
          "author": "saif_shines",
          "text": "u/DavidAntoon , Is there a documentation, how I can write a plugin for FrontMCP especially as a auth provider? For example, something like: [https://gofastmcp.com/integrations/scalekit#scalekit-fastmcp](https://gofastmcp.com/integrations/scalekit#scalekit-fastmcp)",
          "score": 2,
          "created_utc": "2026-01-19 06:00:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h1mfi",
              "author": "DavidAntoon",
              "text": "https://github.com/agentfront/frontmcp/tree/main/libs/plugins",
              "score": 1,
              "created_utc": "2026-01-19 13:34:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o089krs",
          "author": "punkpeye",
          "text": "Wrong library https://github.com/punkpeye/fastmcp",
          "score": 0,
          "created_utc": "2026-01-18 03:27:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08hsub",
              "author": "DavidAntoon",
              "text": "FastMCPâ€™s TypeScript version is no slouch â€“ itâ€™s feature-rich (even ahead in some areas like a fully implemented OAuth proxy with dynamic registration) and is a proven way to build MCP servers quickly . \nHowever, FrontMCP offers a more advanced architecture that feels more at home for modern Node/TS developers, especially those who want structure and flexibility. In areas like plugin support, tooling, and multi-tenancy, FrontMCP provides capabilities that can significantly enhance developer productivity and maintainability, thereby offering a superior overall developer experience in many cases.",
              "score": 0,
              "created_utc": "2026-01-18 04:17:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdr3f7",
      "title": "MCP for dev",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "author": "ProfessionNo3952",
      "created_utc": "2026-01-15 18:12:49",
      "score": 9,
      "num_comments": 27,
      "upvote_ratio": 0.8,
      "text": "I am really into AI for code. However I cannot understand why when and for what I can use MCP as software developer. I ask ChatGPT about it but nothing helpful. May be some of you have practical experience in enterprise development using MCP?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qdr3f7/mcp_for_dev/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzs360p",
          "author": "circamidnight",
          "text": "I've built mcp dev servers for specific projects with tools to run tests, lint, run etc. this is nice because our team can use the agent of their choice and the agent doesn't burn tokens figuring out the way to run some bash command for what you want to do.",
          "score": 4,
          "created_utc": "2026-01-15 19:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzs7t2h",
              "author": "ProfessionNo3952",
              "text": "Sound good. Is it difficult to do?",
              "score": 1,
              "created_utc": "2026-01-15 19:27:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzsqme0",
                  "author": "circamidnight",
                  "text": "No, I've used FastMCP, it's very simple to get started with a simple server that can say run your tests. Heck Claude code or whatever coding agent can set it up easy enough.",
                  "score": 1,
                  "created_utc": "2026-01-15 20:54:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrt18w",
          "author": "0xKoller",
          "text": "When using AI for coding, tools like Cursor, CC, or Codex can really benefit from MCPs to improve output, for example, Context7, which lets the AI query up-to-date documentation, or the Figma MCP, which an agent can use to get pixel-perfect references for a UI design youâ€™re trying to nail.",
          "score": 3,
          "created_utc": "2026-01-15 18:21:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzryn29",
              "author": "ProfessionNo3952",
              "text": "Context7 is sound really cool. May be you can share how you use it and set up it? Or may be some cool article?",
              "score": 2,
              "created_utc": "2026-01-15 18:46:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nztk1lj",
                  "author": "colsatre",
                  "text": "https://letmegooglethat.com/?q=context7",
                  "score": 2,
                  "created_utc": "2026-01-15 23:15:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzwph2c",
                  "author": "0xKoller",
                  "text": "Here is the official GH with the tutorial for some IDEs  \n[https://github.com/upstash/context7#installation](https://github.com/upstash/context7#installation)",
                  "score": 2,
                  "created_utc": "2026-01-16 12:21:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzs0bd5",
              "author": "Shumuu",
              "text": "> Pixel perfect \nlol! I never get it to be pixel perfect BUT it is good to get like 90% of the way",
              "score": 2,
              "created_utc": "2026-01-15 18:53:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzslmq0",
                  "author": "finance-mcp-001",
                  "text": "The problem is that the last 10% takes two months of figuring out what happened with the 90% that took an hour.",
                  "score": 3,
                  "created_utc": "2026-01-15 20:31:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs104v",
          "author": "Capnjbrown",
          "text": "Hey, perhaps you might find some interests in my project\nI recently open sourced [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-15 18:56:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztf7jg",
              "author": "DasBlueEyedDevil",
              "text": "I feel like they compliment one another...\n\n[https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
              "score": 2,
              "created_utc": "2026-01-15 22:50:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzts27y",
                  "author": "Capnjbrown",
                  "text": "Interesting. Iâ€™ll check it out.",
                  "score": 1,
                  "created_utc": "2026-01-15 23:59:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu6ilc",
          "author": "TheLostWanderer47",
          "text": "MCP starts to make sense once an agent needs to do something outside your codebase. Itâ€™s basically a standard way to expose tools to an agent without bloating context or writing custom glue for every service. For example, when an agent needs live web data, instead of hardcoding scrapers or APIs, you can put a web-access layer behind MCP. Thatâ€™s where setups like Bright Dataâ€™s [MCP server](https://github.com/brightdata/brightdata-mcp) come in: the agent calls search/browse/extract tools on demand, and the infrastructure handles access and blocking. If your agent only works on local code or static docs, MCP adds little value.",
          "score": 2,
          "created_utc": "2026-01-16 01:18:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzur46g",
          "author": "NoAdministration6906",
          "text": "I have used mcptoolgate mcp server to guardrail the github, jira, slack for junior developers who are using coding agent to code. I can easily monitor any unwanted github actions and approve or disapprove the request like directly merging to main branch. Pretty useful",
          "score": 2,
          "created_utc": "2026-01-16 03:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gg221",
          "author": "kanundrumtt",
          "text": "I use the atlassian MCP to give access to the ticket details (so I say start work on Jira ticket ABC-123). This has lead to me adding more details on the ticket  (I use an agent to fill out more requirements based on usually vague tickets). I use the GitHub MCP to reference PRs on older tickets which new tickets might do. MCPs for documentation is also helpful (I used the forge MCP when building the agent that fills out my requirements)",
          "score": 2,
          "created_utc": "2026-01-19 10:52:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrs6ko",
          "author": "requisiteString",
          "text": "What are you using to code with AI? MCP servers are like APIs for your AI agent. They allow the agent to do things with other software through a standard interface. Think of MCP like USB for your agents to connect to other apps.",
          "score": 1,
          "created_utc": "2026-01-15 18:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrsjlr",
              "author": "ProfessionNo3952",
              "text": "Yep, I got it. But using AI agent with which MCP and how can help for software development?",
              "score": 1,
              "created_utc": "2026-01-15 18:19:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzrt7ja",
                  "author": "colganc",
                  "text": "Interact with a web browser to automatically verify UI behavior as it iterates in the dev process?",
                  "score": 2,
                  "created_utc": "2026-01-15 18:22:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzrw7a9",
                  "author": "SociableSociopath",
                  "text": "Youâ€™re looking for an answer that no one has because it completely depends on what youâ€™re doing and what your use cases are. There is no one magic MCP server to use itâ€™s just another name for an API",
                  "score": 2,
                  "created_utc": "2026-01-15 18:35:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzrvp76",
          "author": "texo_optimo",
          "text": "I have a txt2img mcp server that I connect can connect to from within any repo to gen image assets on demand. Mainly browser game image assets for my kids but works well for FE\n\nI have a governance mcp server I connect all my repos to. Guardrails \"vibecoding\" with blessed stack patterns, knowledge gained from prior ADRs, kind of a kanban board for me to either review via UI or programmatically from within the repo.",
          "score": 1,
          "created_utc": "2026-01-15 18:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzspy0d",
          "author": "naseemalnaji-mcpcat",
          "text": "I've found MCP can be really useful for integrating AI into your development workflows. For instance, you can use MCP to automate making changes to code reviews or generate test cases by connecting it with GitHub or JIRA. It's especially powerful in CI/CD pipelines for debugging based on logs.",
          "score": 1,
          "created_utc": "2026-01-15 20:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvfnte",
          "author": "Prismshadow_AI",
          "text": "Think of it this way: Without MCP, your AI is like a genius stuck in a room with no internet and no windows. You have to copy-paste everying to it. With MCP, you are giving that genius a 'key' to your local dev environment.\n\nOne practical example: Yesterday I was debugging a legacy repo. Instead of pasting 10 files, I just used an MCP server to let Claude 'read' the whole folder. It found a naming conflict in a config file I didn't even tell it about. Thatâ€™s the 'aha' moment.\n\nIf you're using Claude Desktop or Cursor, just try the basic 'Google Search' or 'Filesystem' MCP first. Itâ€™s a game changer for keeping the AI in sync with what you're actually doing.",
          "score": 1,
          "created_utc": "2026-01-16 05:52:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyyo5e",
          "author": "Jealous_Document2508",
          "text": "MCP servers are really helpful. On a baseline, web search is a must as your agent will not have all the context needed, and will sometimes need to search the web.\n\nOn a side note, we're building an [SDK ](https://github.com/dedalus-labs/dedalus-sdk-python)at Dedalus that will allow you to use trusted MCP servers that are hosted on our marketplace. Check us out!",
          "score": 1,
          "created_utc": "2026-01-16 18:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzs0tgn",
          "author": "Classic_Chemical_237",
          "text": "Think of MCP as a wrapper over traditional API.\n\nIn text centric world, everything is done through chat and voice. So when you say â€œdo this for meâ€ and it needs to call some API to execute, a MCP is a reusable module which you delegate the responsibility to call the API. It can be used to run command line on local machine too.\n\nBasically itâ€™s a wrapper to call structured actions in an unstructured world",
          "score": 1,
          "created_utc": "2026-01-15 18:55:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzso3zv",
          "author": "Low-Efficiency-9756",
          "text": "Hi! Iâ€™m an mcp developer. I have a framework for LLMs that uses prompt engineering to guide agents into TDD development flows\n\nThe framework has some bolt ons mcp tools\n\nOODA mcp - full computer control for your agent (yes itâ€™s the type of server researchers would be scared of) \n\nSynch mcp - persistent memory bank for agents across workspaces (Claude code, to antigravity, to Roo code, etc.\n\nTrace mcp - consumer/ producer schema validation and bidirectional scaffolding for over 10 languages and model context protocol servers. \n\nIndex foundry mcp - Deterministic RAG pipeline  for deployed chatbots in less than an hour, while also adding to your local agents RAG capabilities. \n\nThese four tools give your agents most of the tools to fix the â€œbrain in a jarâ€ problem. \n\nIntegrate with GitHub cli, railway cli, supabase etc and you have yourself an agent that is capable of writing and deploying software on its own.",
          "score": 1,
          "created_utc": "2026-01-15 20:42:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzspkcy",
              "author": "Low-Efficiency-9756",
              "text": "Also did like to add mcp is way more than api for your agents. Any cli capable agent can use api services. \n\nMCP servers are executable tools that validate inputs (JSON-RPC), mutate state, return typed data, maintain invariants. LLM proposes, tool executes.\n\nLLMs are the hands, the database is the intelligence. MCPs allow agents to reason over state in ways that raw APIs canâ€™t. The tool enforces contracts, state persists across sessions, and the LLM doesnâ€™t have to remember, it just has to ask.",
              "score": 0,
              "created_utc": "2026-01-15 20:49:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qerxaw",
      "title": "Following MCP & RAG questions: A self-hosted agent with LightRAG and MCP",
      "subreddit": "mcp",
      "url": "https://i.redd.it/7v0km08kyrdg1.png",
      "author": "motakuk",
      "created_utc": "2026-01-16 20:55:19",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qerxaw/following_mcp_rag_questions_a_selfhosted_agent/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0hb8t9",
          "author": "anywhereblue",
          "text": "I use something similar.  I have a context MCP server on the web, I can write artifacts from any agent to the MCP and read from any other.  It allows my agents to share long form context quickly and easily.  I can also review, markup and edit the context files on the server with a web ui edit ui. \n\nI can brainstorm on Claude have it write it out, have cursor read it st scaffold it out, then have Claude:code read it in as part of a code review. I have a few people testing with me.  It also allows sharing with other people agents.",
          "score": 1,
          "created_utc": "2026-01-19 14:28:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc1obq",
      "title": "Postman V3 MCP server",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qc1obq/postman_v3_mcp_server/",
      "author": "The_Post_Man_V3",
      "created_utc": "2026-01-13 20:02:57",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.91,
      "text": "easy install:\n\n    npm iÂ @postmanv3/postman-mcp-server\n\n[Git](https://github.com/PostmanV3/postman-mcp-server)\n\n[GLama](https://glama.ai/mcp/servers/@PostmanV3/mcp-PostmanV3)\n\nHope this helps! and if it does, please leave a star!\n\n  \nFull disclosure - I made this MCP server for myself because I didnt like the official one - made my cursor glitch and use wrong tools\n\nThis is not an official release by any means - just a good release that has all the tools that im using on a day to day basis",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qc1obq/postman_v3_mcp_server/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbpofz",
      "title": "Mapped the agent infrastructure stack - where MCP fits relative to A2A, ACP, UCP, and the payment protocols",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbpofz/mapped_the_agent_infrastructure_stack_where_mcp/",
      "author": "PutPurple844",
      "created_utc": "2026-01-13 12:09:59",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.83,
      "text": "Notion Doc: [https://agentic-ecosystem-daily.notion.site/Agentic-Ecosystem-Research-2e4ff2f808c381fab03adbe8d4b168f1](https://agentic-ecosystem-daily.notion.site/Agentic-Ecosystem-Research-2e4ff2f808c381fab03adbe8d4b168f1)  \n  \nBeen tracking how the ecosystem around MCP is evolving. Here's how I'm seeing the layers:\n\n    Commerce:      ACP (OpenAI) / UCP (Google)\n    Payments:      Visa TAP / Mastercard Agent Pay / x402\n    Agent-Agent:   A2A (Google)\n    Agent-Tool:    MCP (Anthropic)\n\nKey recent stuff:\n\n* **AAIF launched** \\- MCP, A2A, ACP now under Linux Foundation governance. Anthropic, OpenAI, Google, and Microsoft are all involved.\n* **A2A explicitly \"complements MCP\"** \\- agent-to-agent vs agent-to-tool. Boundary still fuzzy.\n* **Identity unsolved** \\- Microsoft, AWS, startups all taking different approaches. No standard for MCP server auth yet.\n* **OWASP Agentic Top 10** shipped in December â€” an actual security framework now exists.\n\nPut together a research hub covering all the protocols, payment rails, identity approaches, and security frameworks.\n\nKeeping it updated. Curious what others are seeing - especially around MCP auth patterns and how A2A/MCP will interact in practice.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qbpofz/mapped_the_agent_infrastructure_stack_where_mcp/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzouq4e",
          "author": "Prestigious-Play8738",
          "text": "Agent-Service: [UAIP](https://github.com/concierge-hq/uaip)",
          "score": 1,
          "created_utc": "2026-01-15 07:16:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpakn6",
              "author": "PutPurple844",
              "text": "UAIP looks small compared to global players, but I will add it to the page, though.",
              "score": 1,
              "created_utc": "2026-01-15 09:47:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qbmn6p",
      "title": "Jira MCP - Better than ever",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qbmn6p/jira_mcp_better_than_ever/",
      "author": "EcstaticDiscussion32",
      "created_utc": "2026-01-13 09:07:41",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.82,
      "text": "Hey all!\n\nSaw the emerging wave of improving official MCPs, and wanted to give it a try.\n\nI've developed a Jira MCP - more efficient, less tools, focuses only on what matters.\n\nThe most important part is the local hosting. I don't trust remote servers.\n\nGive it a try, and don't hesitate to give the repo a star!\n\n[https://github.com/Jira-MCP/Jira-MCP](https://github.com/Jira-MCP/Jira-MCP)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qbmn6p/jira_mcp_better_than_ever/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "nzi681o",
          "author": "chadrik",
          "text": "404",
          "score": 1,
          "created_utc": "2026-01-14 07:59:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi8tll",
          "author": "SafetySouthern6397",
          "text": "404 error",
          "score": 1,
          "created_utc": "2026-01-14 08:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzij262",
          "author": "GuaranteeCurrent8084",
          "text": "404",
          "score": 1,
          "created_utc": "2026-01-14 10:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzovqq4",
          "author": "EcstaticDiscussion32",
          "text": "    ### Via npm (recommended)\n    \n    npm install -g jira-mcp-server\n    \n    ### From Source\n    \n    \n    1. Install dependencies: `npm install`\n    2. Build the project: `npm run build`\n    3. Configure your MCP client (see below)\n    \n    \n    ## Configuration\n    \n    \n    ### For Cursor Users\n    \n    \n    Add this to your Cursor MCP configuration (`~/.cursor/mcp.json`):\n    \n    \n    ```json\n    {\n      \"mcpServers\": {\n        \"Jira MCP\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"/path/to/mcp-server-atlassian-jira/dist/index.js\"\n          ],\n          \"env\": {\n            \"ATLASSIAN_SITE_NAME\": \"your-company\",\n            \"ATLASSIAN_USER_EMAIL\": \"your.email@company.com\",\n            \"ATLASSIAN_API_TOKEN\": \"your_api_token\"\n          }\n        }\n      }\n    }",
          "score": 1,
          "created_utc": "2026-01-15 07:25:58",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgbwsu",
      "title": "Is there an MCP to allow context sharing across models?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qgbwsu/is_there_an_mcp_to_allow_context_sharing_across/",
      "author": "ilovefunc",
      "created_utc": "2026-01-18 15:46:50",
      "score": 7,
      "num_comments": 19,
      "upvote_ratio": 0.89,
      "text": "For example, I use Claude code, and then hit the rate limit. I would like to somehow continue with the same context on cursor (and vice versa). \n\nSame thing goes for my conversations with ChatGPT or Claude or Gemini. Would love to continue a conversation across these without manually copy / pasting the chat.  \n\nAny solution for this exists? Thanks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qgbwsu/is_there_an_mcp_to_allow_context_sharing_across/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o0b3mpg",
          "author": "Putrid_Barracuda_598",
          "text": "You can have Claude code build one.\nI've got a custom one; part of my bigger stack. \nIt uses pub/sub to share short term context and a \"vault\" to share long term.",
          "score": 2,
          "created_utc": "2026-01-18 15:56:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b47s2",
              "author": "ilovefunc",
              "text": "Can you share more about how it works please? Seems interesting.",
              "score": 1,
              "created_utc": "2026-01-18 15:58:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0b5zx1",
                  "author": "Putrid_Barracuda_598",
                  "text": "Basically I have multi-agent orchestration. Depending on the task and which cli Im running at the time I just have it use the board or vault to store long term or project logs. Then, if I switch to Gemini, or codex (Claude code is my main driver) I just have them review the board or value (per project or long term) for whatever context they need and they can pick up form there. \n\nI can share a spec later, as I don't remember exactly if the pub/sub uses postgres or something else (I have 157 specialized agents). \n\nI also have a \"deliberator\" where I can have Claude discuss a task with codex and Gemini cli before it makes a decision. Or it gets back to me with what they decided and I approve or ask them to discuss again based on the new info. \n\nThe easiest thing, if you have Claude code cli, would be to ask Claude to create an Mcp for you. It has Mcp builder built in and will do a pretty good job. As long as you tell it what you need.",
                  "score": 2,
                  "created_utc": "2026-01-18 16:07:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0d1rdl",
          "author": "Capnjbrown",
          "text": "A tool I built for this and recently open sourced it - technically you could accomplish what youâ€™re trying to do. If you chose the global archive storage option in your configurations. These folders/files are just JSON files located locally on your machine at a given pathway. You could easily pull the context from these regardless of the model or manual retrieval you are trying to accomplish. [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper) Hope this helps.",
          "score": 2,
          "created_utc": "2026-01-18 21:36:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c3xi7",
          "author": "anywhereblue",
          "text": "Great question I use a shared MCp service to allow one agent to write an artifact and another to read it.",
          "score": 1,
          "created_utc": "2026-01-18 18:46:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fm02z",
          "author": "coloradical5280",
          "text": "Thatâ€™s literally a technical impossibility with the transformer architecture. If you mean a fancy behind the scenes copy and paste into other context windows, sure. But two models ACTUALLY running attention on every token and sharing rich context, thatâ€™s not possible.",
          "score": 1,
          "created_utc": "2026-01-19 06:20:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fm3kc",
              "author": "ilovefunc",
              "text": "Oh yea, I meant the fancy behind the scene copy paste method.",
              "score": 1,
              "created_utc": "2026-01-19 06:21:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0fv3s5",
                  "author": "coloradical5280",
                  "text": "yeah there's a bunch, if you don't get the best answer here, r/claudecode might be a better place to ask. I could give you 2-3 names but I just don't use that workflow often , and wouldn't want to give you the 2-3 worst.  Stick with informed answers of people who actually use the workflow you want, which again will be easier to find those folks in cc or r/codex or the other coding subs :)",
                  "score": 1,
                  "created_utc": "2026-01-19 07:37:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ftpr3",
              "author": "GnistAI",
              "text": "This isnâ€™t really about machine learning architecture. It is a harness question. Copying context text from one harness to another.",
              "score": 1,
              "created_utc": "2026-01-19 07:25:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0futmw",
                  "author": "coloradical5280",
                  "text": "Literal context sharing between heterogeneous models is architecturally impossible, not a harness abstraction.\n\nThe KV cache stores projected key-value pairs computed as K=XW\\_k, V=XW\\_v where W\\_k and W\\_v are learned projection matrices specific to that model's weights. Attention is computed as softmax(QK\\^T/âˆšd\\_k)V - the Q from your current forward pass is computing dot products against cached K vectors. If those K vectors came from a different model's projection matrices, you're computing similarity in incompatible latent spaces. The attention scores are meaningless.\n\nBeyond that: different tokenizers (e.g., Claude's BPE vs Gemini's SentencePiece), different vocabulary mappings, different embedding dimensions, different positional encoding schemes. Token 4521 doesn't reference the same subword, and even if it did, the embedding vector lives in a completely different learned manifold.\n\nThere is no harness that reconciles incompatible learned representations. The \"harness solution\" (serialize text, re-tokenize, re-embed in target model's native space) exists precisely BECAUSE architectural constraints make true state sharing impossible.\n\nDismissing this as \"not an architecture question\" demonstrates a fundamental confusion about what the harness layer is abstracting over and why.\n\nedit: realizing you didn't actually read my whole response, or OPs response to it...  wrote this before i realized that.",
                  "score": 2,
                  "created_utc": "2026-01-19 07:35:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0hlcyh",
          "author": "smothered-onion",
          "text": "Sounds like you want an agent powered by mcp. Model switching occurs in agent. Agent shares context as necessary. Unless you want or need to build that logic yourself.",
          "score": 1,
          "created_utc": "2026-01-19 15:19:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dhfil",
          "author": "justgetting-started",
          "text": "Hey you could try asking the question in my app and see if it helps .. https://architectgbt.com",
          "score": 0,
          "created_utc": "2026-01-18 22:50:49",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeoy8k",
      "title": "MCPbundler now free and open source!",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qeoy8k/mcpbundler_now_free_and_open_source/",
      "author": "lifeisgoodlabs",
      "created_utc": "2026-01-16 19:02:29",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 0.88,
      "text": "Hi everyone,\n\nIâ€™ve decided to make **MCPbundler** free and open source (thanks to the bagsapp project).\n\nThe goal is to make it the go-to tool for managing **Skills** and **MCP servers** across multiple projects in the simplest possible way.\n\n## What it does\n\n- Install Skills directly from marketplaces or GitHub links  \n- Sync Skills across Claude, Codex, AMP, Goose, and other tools  \n- Organize Skills and MCP servers using folders  \n- Generate context-optimized outputs  \n- Reuse Claude/Codex Skills to extend your workflows  \n- Enable or disable tools and MCP servers as needed  \n- Assign specific groups of MCP servers per task or workflow  \n- Avoid repeatedly adding the same MCPs to every AI tool  \n\nIf you manage multiple AI tools or projects and want less duplication and setup overhead, this should help.\n\nFeedback and contributions are welcome.\n\nX: https://x.com/MCPbundler\n\nWWW: https://mcp-bundler.com\n\nGithub(code soon): https://github.com/eugenepyvovarov/MCPbundler ",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qeoy8k/mcpbundler_now_free_and_open_source/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    }
  ]
}