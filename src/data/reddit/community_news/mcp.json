{
  "metadata": {
    "last_updated": "2026-01-31 16:49:57",
    "time_filter": "week",
    "subreddit": "mcp",
    "total_items": 20,
    "total_comments": 97,
    "file_size_bytes": 129905
  },
  "items": [
    {
      "id": "1qqf4zo",
      "title": "3 MCPs that have genuinely made me 5x better",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "author": "Warm-Snow3302",
      "created_utc": "2026-01-29 17:33:36",
      "score": 191,
      "num_comments": 55,
      "upvote_ratio": 0.89,
      "text": "I've been testing MCPs extensively for fun, so I thought I‚Äôd share some of the ones I‚Äôve found most useful. Plus I've found most of the them here only.\n\nMy main criteria were minimal setup, reliability, and whether I kept using them after the novelty wore off:\n\ngreb MCP: Greb helps makes your coding agent 30% faster by helping them find correct files faster. That too without indexing It‚Äôs especially helpful for issue + commit context grounding and repo exploration. \n\nSlack / Messaging MCP: that‚Äúwow‚Äù factor with very low effort. Once an agent can talk where humans already are, teams love it instantly. My team even used this for something as basic as ordering and tracking deliveries for team lunch, which ended up being one of the most-used workflows for us.\n\nGitHub MCP: This is what finally made Claude feel like an actual teammate instead of a smarter autocomplete. If you‚Äôre tired of copy-pasting repos into prompts, you‚Äôre gonna love it. It‚Äôs especially helpful for issue + commit context grounding and repo exploration.\n\nSuper curious to hear what MCPs all of you have found useful?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqf4zo/3_mcps_that_have_genuinely_made_me_5x_better/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2h9avr",
          "author": "slea95",
          "text": "Not sure the GitHub MCP is any better than the already-comprehensive gh CLI tool tbh. Unless there‚Äôs something I‚Äôm missing, it seems to be able to do all the things you listed but more efficiently and without bloat?",
          "score": 40,
          "created_utc": "2026-01-29 20:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hhjgc",
              "author": "sweettuse",
              "text": "+1 to this, might be worth reconsidering with Claude lazy mcp loading, but I just use the gh cli and it's great",
              "score": 10,
              "created_utc": "2026-01-29 21:25:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2j08sj",
                  "author": "bin-c",
                  "text": "I made the switch to GitHub mcp now that the mcp cli is available and for whatever reason it just seems to work better. Absolutely unusable before lazy loading though lol",
                  "score": 2,
                  "created_utc": "2026-01-30 02:13:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2htqzs",
              "author": "command-shift",
              "text": "It‚Äôs much better at parsing reviewer comments and feedback than gh CLI as a user of both",
              "score": 2,
              "created_utc": "2026-01-29 22:24:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2kxxgj",
              "author": "AdResident780",
              "text": "i personally love the deepwiki mcp server as it is free (no PAT needed) , doesnt need to be self-hosted and can ask questions about literally any github repo in existence (if not indexed, you need to index the repo by going to [deepwiki.com/](http://deepwiki.com/) {owner-of-unindexed-repo} / {unindexed-repo} .",
              "score": 2,
              "created_utc": "2026-01-30 10:48:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gfmw8",
          "author": "Electronic_Boot_1598",
          "text": "Which Slack MCP do you use?",
          "score": 11,
          "created_utc": "2026-01-29 18:27:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g9eqj",
          "author": "Crab_Shark",
          "text": "I‚Äôd love to know more!\n* For greb MCP, does that speedup also come with a reduction of token usage? Have you noticed whether it‚Äôs affected search quality?\n* For GitHub MCP, how is it different than the connectors within Claude, or running Claude Code connected to specific repos?",
          "score": 11,
          "created_utc": "2026-01-29 17:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdu05",
              "author": "snix_e",
              "text": "idk of the OP but I read about greb on this reddit only and it has been great, there's a reduction in token usage plus it remembers the logic with millions of line of code \n\nGitHub is very similar to them but the transition is very smooth",
              "score": 5,
              "created_utc": "2026-01-29 18:19:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hekq2",
          "author": "Maasu",
          "text": "There's a plugin I created which combines context7, Serena and forgetful (my own memory mcp) \n\nhttps://github.com/ScottRBK/context-hub-plugin\n\nI basically use the context gather command before I start any work and memory save when I'm done.",
          "score": 6,
          "created_utc": "2026-01-29 21:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jjm9r",
              "author": "Impressive_Chemist59",
              "text": "What difference between Serena and forgetful?",
              "score": 1,
              "created_utc": "2026-01-30 04:03:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kjl0r",
                  "author": "Maasu",
                  "text": "Serena is more concentrated on single device and has fairly primitive memory storage/retrieval. \n\nI mainly use Serena because of its out of the box encoding capabilities, specifically the symbol mapping on a repo, I use that output in an encoding architecture doc attached to each project that an LLM can consume to get a quick understanding of the code. \n\nHandy if I in voice convo on my phone etc and I don't want an LLM trawling through loads of code during an architectural brain storming session when I'm out for a walk for example.",
                  "score": 1,
                  "created_utc": "2026-01-30 08:38:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h5pvi",
          "author": "UseHopeful8146",
          "text": "I haven‚Äôt used GitHub mcp since it like first released, but I found it to be a complete waste of context. Your basic git/gh cli tools are incredibly simple, and even scripting CI/CD stuff isn‚Äôt terribly complicated - I just don‚Äôt see the value there\n\nEven for codebase search/analysis, octocode semantic search and deepwiki have been way more beneficial. And even just browser searching a repo is faster and more efficient with browser mcp or whichever web search tool that OmO installs with\n\nBut again, I have not used it at all since like‚Ä¶ idk march?",
          "score": 4,
          "created_utc": "2026-01-29 20:29:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hlwow",
              "author": "cab938",
              "text": "My value was it was in an MCP and I wasn't having to give the agent shell access. But frankly I rarely use it just because MCPs are much more fragile it seems.",
              "score": 1,
              "created_utc": "2026-01-29 21:46:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hnbnw",
                  "author": "UseHopeful8146",
                  "text": "Yeah agreed, I use mcp for very specific purposes, usually for interacting with self hosted services. Memory functions, routine things that save me time, or in some rare cases for specific retrieval methods like pulling my project specs and related docs from any type.\n\nBut MCP isn‚Äôt saving me time on git add, git comment, git push or gh repo clone, etc. if I want to look at specific material in a codebase: octocode \n\nIf I have a theory or a particularly tricky problem, index and question with deepwiki.\n\nNeed current code examples for a given library: context7\n\nLike, MCP does really well in certain instances, but a lot of them are just context waste. Bt those, and OmO provided mcp‚Äôs I save time on the long form stuff like research, investigation, etc. and since I learn by doing - I learn a lot faster by getting to ‚Äúdo‚Äù sooner",
                  "score": 1,
                  "created_utc": "2026-01-29 21:53:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ht4qp",
          "author": "alex__richards",
          "text": "I would avoid MCP and use CLI tools where possible. I use Claude code and have cli‚Äôs configured for GitHub, Atlassian, Sentry, NewRelic - so much faster and economical (token usage) than an MCP",
          "score": 4,
          "created_utc": "2026-01-29 22:21:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2igmqq",
              "author": "SenorTortuga",
              "text": "Agreed. Not all MCPs are bad, but if there is a CLI tool that provides equivalent functionality it is almost always a better choice.  I‚Äôve been very happy since switching to acli and glab instead of Atlassian and GitLab MCPs.",
              "score": 3,
              "created_utc": "2026-01-30 00:25:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gclfg",
          "author": "Crafty_Disk_7026",
          "text": "GitHub MCP was clunky for me.  Uses lots of tokens and effort to do simple things like comparing a diff.  Which one did you use?",
          "score": 3,
          "created_utc": "2026-01-29 18:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gdy0i",
              "author": "snix_e",
              "text": "opas",
              "score": 2,
              "created_utc": "2026-01-29 18:19:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfiv8",
                  "author": "Crafty_Disk_7026",
                  "text": "Gracias",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2gen3f",
          "author": "saloni1609",
          "text": "Nice list! I‚Äôve also been experimenting with MCPs recently.\n\nGreb stood out for me too especially for repo exploration without indexing. I‚Äôve been testing it inside Cheetah AI, which uses it as part of their context engine. It‚Äôs been interesting to see how it handles issue + commit grounding across bigger repos.\n\nGitHub MCP + Greb together feels like the closest thing to having a teammate who actually read the repo.\n\nCurious if you‚Äôve tried layering in memory systems too? I‚Äôve seen setups where the agent keeps commit history context, which makes debugging way smoother.",
          "score": 3,
          "created_utc": "2026-01-29 18:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gga4d",
          "author": "infidel_tsvangison",
          "text": "What does the GitHub mcp do really?",
          "score": 3,
          "created_utc": "2026-01-29 18:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2htkpa",
              "author": "command-shift",
              "text": "It‚Äôs also useful for fetching reviewer comments/feedback into your agent of choice to make decisions or issues to address or deliberate on",
              "score": 2,
              "created_utc": "2026-01-29 22:23:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2hipdd",
              "author": "TeamCaspy",
              "text": "See pull requests easier, open pr, open issues,...",
              "score": 1,
              "created_utc": "2026-01-29 21:31:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gfdz8",
          "author": "Pitiful-Minute-2818",
          "text": "Nice one i tried greb mcp it was really good",
          "score": 2,
          "created_utc": "2026-01-29 18:25:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ghtbv",
          "author": "Capnjbrown",
          "text": "Good info thanks. Perhaps you might find my product I made for context archiving and context preservation (amongst other features) for coding within Claude Code CLI. I open sourced it a couple weeks ago: [c0ntextKeeper](https://github.com/Capnjbrown/c0ntextKeeper)",
          "score": 2,
          "created_utc": "2026-01-29 18:36:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hl20o",
          "author": "adreportcard",
          "text": "People‚Ä¶. Copy and pasted repos into prompts?",
          "score": 2,
          "created_utc": "2026-01-29 21:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kt5bh",
              "author": "that__it_guy",
              "text": "Yeah I too didnt get this.",
              "score": 1,
              "created_utc": "2026-01-30 10:06:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ktyr7",
          "author": "that__it_guy",
          "text": "Why do people in general use so many mcps? When I have a coding task, i do research on Gemini, code on cursor/intellij and thats all. What are the manual workflows the agents have helped you in ?",
          "score": 2,
          "created_utc": "2026-01-30 10:13:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mrsly",
              "author": "vayana",
              "text": "I agree. I get by absolutely fine without an MCP. The only 2 I would consider using are a database MCP like neon or supabase and perhaps playwright, but I've so far never really needed to use these either.",
              "score": 1,
              "created_utc": "2026-01-30 16:52:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hkvb0",
          "author": "oginome",
          "text": "Check out Forgetful MCP. It's a yet another vector-based semantic memory system that allows your agents to recollect stuff between sessions. I've been using it and it's actually pretty great - we can reference conversations from weeks ago instantly. I'm a huge fan of how it organizes by project, and I have basically replaced my note-taking workflow with it.\n\nCoupled with GLM 4.7 Flash, Karakeep MCP, and Searxng I've made strides in being able to efficiently provide it context so that I don't have to burn so many tokens reaching understanding. \n\n[https://github.com/scottrbk/forgetful](https://github.com/scottrbk/forgetful)",
          "score": 4,
          "created_utc": "2026-01-29 21:41:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g61wd",
          "author": "FewChart7648",
          "text": "I have used GitHub that is amazing but will try the rest, but GitHub also sometimes have a bad memory",
          "score": 1,
          "created_utc": "2026-01-29 17:44:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gc5u0",
          "author": "anywhereblue",
          "text": "Good list.",
          "score": 1,
          "created_utc": "2026-01-29 18:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gi1ur",
          "author": "PuzzledCulture25",
          "text": "When working on frontend I use [Linear](https://linear.app/docs/mcp), [ChromeDevTools](https://github.com/ChromeDevTools/chrome-devtools-mcp) and [Capturl](https://capturl.com). It lets agents see screenshots inside of tickets and update the ticket with new screenshots when it's done.",
          "score": 1,
          "created_utc": "2026-01-29 18:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h1tr4",
              "author": "Express-One-1096",
              "text": "Why not playwright mcp?",
              "score": 1,
              "created_utc": "2026-01-29 20:10:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h5e6g",
                  "author": "PuzzledCulture25",
                  "text": "I mainly switched over to chrome dev tools because it's nice for debugging but Playwright worked great too!",
                  "score": 1,
                  "created_utc": "2026-01-29 20:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h9da7",
          "author": "martin_xs6",
          "text": "There's an obsidian one that is really great if you use that.\n\nGmail + Google drive Is great too.  With Gmail you can have it draft emails to review before sending.  It's great for making notes to send to something about changes.",
          "score": 1,
          "created_utc": "2026-01-29 20:46:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hd46k",
          "author": "Traditional_Cress329",
          "text": "Really love devtools by google for debugging extensions or web apps.",
          "score": 1,
          "created_utc": "2026-01-29 21:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2he2rp",
          "author": "VictorCTavernari",
          "text": "For me as Swift developer, SwiftZilla.dev is the best",
          "score": 1,
          "created_utc": "2026-01-29 21:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hgw40",
          "author": "canihelpyoubreakthat",
          "text": "Nah huh. I saw 55x improvements! Measured with the trustmebro bench and all.\n\n55x more tokens\n55x more hallucinations \n55x more markdown\n55x more code to review",
          "score": 1,
          "created_utc": "2026-01-29 21:22:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hi68n",
          "author": "aviboy2006",
          "text": "I am using AWS ECS service MCP for debugging issue so far. I heard about Figma  and playwright MCP but didn‚Äôt try yet. Soon going to try.",
          "score": 1,
          "created_utc": "2026-01-29 21:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jght4",
              "author": "Warm-Snow3302",
              "text": "playwright is actually really good",
              "score": 1,
              "created_utc": "2026-01-30 03:44:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hoz7h",
          "author": "freeformz",
          "text": "I use the local version of the GitHub MCP (to remove tools I don‚Äôt care about) and it‚Äôs pretty awesome",
          "score": 1,
          "created_utc": "2026-01-29 22:01:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hvsib",
          "author": "dxlachx",
          "text": "Sequential thinking, Serena, and Context7",
          "score": 1,
          "created_utc": "2026-01-29 22:34:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2i2nik",
          "author": "trolololster",
          "text": "greb?",
          "score": 1,
          "created_utc": "2026-01-29 23:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ihaid",
          "author": "Icanteven______",
          "text": "GitHub mcp is such a context hog. I just have it use the gh cli",
          "score": 1,
          "created_utc": "2026-01-30 00:28:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jqfpy",
          "author": "sincerodemais",
          "text": "Grep or filesystem mcp?",
          "score": 1,
          "created_utc": "2026-01-30 04:46:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kxnp8",
          "author": "AdResident780",
          "text": "i use the deepwiki MCP server (for up-to-date info about any github repo)",
          "score": 1,
          "created_utc": "2026-01-30 10:45:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sht17",
          "author": "deep_ak",
          "text": "Context7 MCP should deserve a mention\n\nFor implementing any feature in which I wan the plan to have a through spec and correct API docs context, context7 always comes handy",
          "score": 1,
          "created_utc": "2026-01-31 14:10:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2geob1",
          "author": "DasBlueEyedDevil",
          "text": "You forgot the best one:  [https://dasblueyeddevil.github.io/Daem0n-MCP/](https://dasblueyeddevil.github.io/Daem0n-MCP/)",
          "score": -1,
          "created_utc": "2026-01-29 18:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2gfa0e",
              "author": "snix_e",
              "text": "you are promoting your MCP hereüòÇ",
              "score": 2,
              "created_utc": "2026-01-29 18:25:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2gfjt7",
                  "author": "DasBlueEyedDevil",
                  "text": "I meeeaaaaan, OP did end the post with asking which ones we've found useful ;-)",
                  "score": 1,
                  "created_utc": "2026-01-29 18:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2h8l0d",
              "author": "full_hyperion",
              "text": "Gonna try it out just because of the theme :D",
              "score": 1,
              "created_utc": "2026-01-29 20:43:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmhh5r",
      "title": "I built `mcp2skill` which converts your MCP servers into Skills with one command! ‚ú®",
      "subreddit": "mcp",
      "url": "https://github.com/fenwei-dev/mcp2skill",
      "author": "Ok_You4416",
      "created_utc": "2026-01-25 12:09:02",
      "score": 78,
      "num_comments": 39,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qmhh5r/i_built_mcp2skill_which_converts_your_mcp_servers/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1pjfld",
          "author": "Ok_Mix_2823",
          "text": "Ngl the core premise is a bit off. MCP and Skills have different purposes. MCP is for connecting AI models to external tools and data sources. Skills are essentially curated markdown instructions and context that coding agents load on demand. They‚Äôre complementary, not competing. this tool actually just wraps MCP server interactions behind a SKILL.md and a CLI binary. Which is what skills were made for essentially",
          "score": 10,
          "created_utc": "2026-01-25 22:42:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1qiw2w",
              "author": "Ok_You4416",
              "text": "I agree! This is essentially a CLI that calls MCP servers. What I wanted to propose is this pattern could be a better approach to use MCP compared to loading all MCP tools into agent context at the same time. With MCP protocol itself going [\"state-less\"](https://blog.modelcontextprotocol.io/posts/2025-12-19-mcp-transport-future/#a-stateless-protocol), this  approach will work for more MCP servers.",
              "score": 6,
              "created_utc": "2026-01-26 01:33:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1rnmq0",
                  "author": "Successful-Raisin241",
                  "text": "I was struggling to give Claude skills to perform certain api calls with certain limitations, with clear API docs available. Claude was dumb, ignored instructions, ignored skills, and composed prompt injections to overcome limitations. So MCP is still needed and Skills can't replace it",
                  "score": 2,
                  "created_utc": "2026-01-26 05:26:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1s7p1x",
                  "author": "Ok_Mix_2823",
                  "text": "Ah I see!",
                  "score": 1,
                  "created_utc": "2026-01-26 08:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1utm1n",
              "author": "dashingsauce",
              "text": "People just need a continuous source of ‚Äúacshually‚Äù to continue reaping engagement points",
              "score": 1,
              "created_utc": "2026-01-26 17:36:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1n5pr7",
          "author": "shikima",
          "text": "I use the skills to make the LLMs understand the MCPs",
          "score": 2,
          "created_utc": "2026-01-25 16:33:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1oly24",
              "author": "Groveres",
              "text": "Same here. Give them more context how and when to use it.",
              "score": 2,
              "created_utc": "2026-01-25 20:16:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1mdejr",
          "author": "Possible-Benefit4569",
          "text": "Skills eating my context Window very fast, so more skills dumb ai. I have to keep them small and smart.",
          "score": 2,
          "created_utc": "2026-01-25 14:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mq448",
              "author": "One-Poet7900",
              "text": "Skills are loaded on demand, MCP tools are loaded up front. Skills should have less context bloat",
              "score": 5,
              "created_utc": "2026-01-25 15:24:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1nixxx",
                  "author": "zaphodp3",
                  "text": "Yeah I thought context size management was one of the big reasons to use skills instead of mcp only.",
                  "score": 2,
                  "created_utc": "2026-01-25 17:30:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1ol5cb",
                  "author": "WealthSad4337",
                  "text": "You can choose which MCP tools your client has access to. You can just create an MCP tool to return a string and it behaves exactly as a skill would.",
                  "score": 1,
                  "created_utc": "2026-01-25 20:12:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1mi3hh",
              "author": "Crafty_Disk_7026",
              "text": "Please check out \"codemode\".  This has given me the benefits of MCP with much more reasonable token usage.  Here's a SQLite MCP I converted to codemode to prove it:  https://github.com/imran31415/codemode-sqlite-mcp/tree/main",
              "score": 1,
              "created_utc": "2026-01-25 14:45:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1mk4tr",
                  "author": "mycall",
                  "text": "> https://github.com/imran31415/codemode-sqlite-mcp/tree/main\n\nThe trade off of codemode is slower performance, yes?",
                  "score": 2,
                  "created_utc": "2026-01-25 14:55:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1pph8d",
              "author": "Specialist_Solid523",
              "text": "An inefficient skill will behave just like inefficient code. If skills are chewing up your context window and burning tokens, it might be worth reconsidering how you are writing them.\n\nThe point is, I wouldn‚Äôt be so quick to write them off. I‚Äôve seen significant token saving and reduced context rot from skills usage - they are OP.\n\nHappy to share my approach if you want!",
              "score": 1,
              "created_utc": "2026-01-25 23:09:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1rpsea",
                  "author": "Possible-Benefit4569",
                  "text": "Different approaches here. My case is like ‚Äûexcel‚Äú. Will it be code in future or not. Mostly not. In my case probably yes, because my Skills are POCs. They combine domain Knowledge with ‚Äûapi‚Äú/mcp and llm. So it creates business value but in Claude.ai / Desktop they consumes half of context but working together. \nHead of dev can decide to transfer them to code or i book another claude for other complex cases. End of day claude, custome mcp and skills are a very beneficial combination. Like a already tested and running Spec üôÇ",
                  "score": 1,
                  "created_utc": "2026-01-26 05:41:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1zc1y9",
              "author": "Possible-Benefit4569",
              "text": "Edit: Yes, as Users mentioned on demand in that chat.",
              "score": 1,
              "created_utc": "2026-01-27 08:10:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1mghm2",
          "author": "WealthSad4337",
          "text": "Cool but skills and MCP essentially do the same thing.",
          "score": 5,
          "created_utc": "2026-01-25 14:36:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1oqznm",
              "author": "cab938",
              "text": "No? Skills teach the LLM something, MCPs execute code based on LLM input. One is reasoning, the other is computation.",
              "score": -1,
              "created_utc": "2026-01-25 20:38:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p2vqf",
                  "author": "WealthSad4337",
                  "text": "Just make a tool that returns a string and it‚Äôs a skill.",
                  "score": 2,
                  "created_utc": "2026-01-25 21:29:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qu2pr",
                  "author": "sivadneb",
                  "text": "Not exactly. Both augment the context in some way. Both can do reasoning, both can do computation. It's all context in the end. \n\nThat's not to say each doesn't have their uses. I think what skills will largely replace is *local* MCP servers. Remote MCP servers will always have their place. But again, those servers could do reasoning, computation, or a mix of both.",
                  "score": 2,
                  "created_utc": "2026-01-26 02:30:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qzxhr",
                  "author": "Excited_Idiot",
                  "text": "This is a very misinformed take on what MCPs do. I have a lot of MCPs I run that are not remotely related to code execution.",
                  "score": 1,
                  "created_utc": "2026-01-26 03:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ogymg",
          "author": "vskhosa",
          "text": "Can skills 'really' replace MCP for good? Does that mean Anthropic donated a dying project to Linux Foundation?",
          "score": 1,
          "created_utc": "2026-01-25 19:54:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ooaud",
              "author": "Fafadom",
              "text": "There still needs to be guard railed non-coding AI tools for non-devs in production systems.",
              "score": 1,
              "created_utc": "2026-01-25 20:26:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1sbxqx",
          "author": "Sachka",
          "text": "MCPs aren‚Äôt meant for us, they are meant for them, if you build MCP for them you build an entry door for you, a CLI, or like in most cases, the CLI is there already and you build an MCP for them on top of it. Skills are just instructions at prompt evaluation time. These are not the same thing. This is pretty much like saying ‚ÄúI‚Äôve built a Docker Container to bash script tool‚Äù or even worse, ‚ÄúHere is a container to readme tool‚Äù. What you need to be better at or at least understand is how THEY read function description, so that you understand HOW they see the tools in their context, and what it means to add an MCP to an agent configuration or an MCP Gateway.",
          "score": 1,
          "created_utc": "2026-01-26 08:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1seejy",
          "author": "Sachka",
          "text": "You are overloading the context with redundant instructions at best, you got to understand skills are not the same thing as MCP and aren‚Äôt meant to replace them, skills are at best just instructions on how to use tools (MCP) in a specific way, think of it as guardrails for the way you develop. You may have a skill that describes how to read sdk info using an MCP tool, write the code in a particular location and then write documentation using a different MCP tool (Maybe Notion). And I could write a skill to tell the same agent in the same project to never write to Notion, and always do testing before pushing into production. Same project, different skills, different uses, BUT! you cannot replace MCP tools!",
          "score": 1,
          "created_utc": "2026-01-26 09:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1te5kc",
          "author": "ChronoFish",
          "text": "I've built my system around agents instead of skills.\n\n\nI have a routing (master) agent that simply determines \"who is going to respond to this request?\"\n\n\nEach (sub) agent has its own preamble and MCP list.\n\n\nI can see the bennift of bolt on or reusable preamble bits.. which is where skills come in.¬† But so far (in my architecture) that level of granularity is unnecessary.¬† But it's on my radar once I need consistency with instructions around tool use between agents.",
          "score": 1,
          "created_utc": "2026-01-26 13:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1uqtu7",
          "author": "kuaythrone",
          "text": "I like wrapping my mcps in sub agents instead, I find it better for context management and saving tokens using haiku and sonnet since they have the smaller task of just calling the mcp functions",
          "score": 1,
          "created_utc": "2026-01-26 17:24:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21wdqu",
              "author": "unc0nnected",
              "text": "Can you share some of your lessons learned good vs bad ways to do this and results from any benchmarks you ran?  Really curious!",
              "score": 1,
              "created_utc": "2026-01-27 17:32:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o200d74",
          "author": "maxkatz6",
          "text": "Necessity to write skills for MCP is an indicator of poorly implemented MCP server.\n\nMCP server's tool descriptions and standard server-instructions promt should do this job of explaining how to call them, in what order, and in what scenarios.\n\nSee [Server Instructions: Giving LLMs a user manual for your server](https://blog.modelcontextprotocol.io/posts/2025-11-03-using-server-instructions/) for example.",
          "score": 1,
          "created_utc": "2026-01-27 11:46:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20s0gb",
          "author": "Only_Internal_7266",
          "text": "Skill: llm does the work it discovers in the instructions  \nMCP: llm executes the work from existing context (not 'discovered')  \nSubtle, but meaning full distinction.  \n\n    {\n      \"mcpServers\": {\n        \"apifunnel\": {\n          \"url\": \"https://tool.apifunnel.ai/mcp/\",\n          \"headers\": {\n            \"Authorization\": \"Bearer YOUR_TOKEN_HERE\"\n          }\n        }\n      }\n    }\n\n[get a key.](https://app.apifunnel.ai/engineering)  \n",
          "score": 1,
          "created_utc": "2026-01-27 14:30:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qodaze",
      "title": "Sims 1 Legacy MCP",
      "subreddit": "mcp",
      "url": "https://i.redd.it/nnn207a64wfg1.png",
      "author": "pevers",
      "created_utc": "2026-01-27 13:05:39",
      "score": 70,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o223p6l",
          "author": "Select-Bell-5920",
          "text": "I didn't know that I wanted nor needed this, but turns out I actually do...",
          "score": 7,
          "created_utc": "2026-01-27 18:03:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23qoaj",
              "author": "VIDGuide",
              "text": "Holy shit.. the idea of AI playing a simulation of humans.. and .. fuck it, I‚Äôm in, let‚Äôs go!",
              "score": 4,
              "created_utc": "2026-01-27 22:24:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o213kmm",
          "author": "Odd-Cardiologist1905",
          "text": "Gosh now I imagine having claude like a porn director: \"Hey Claude make them fuck! now!\"",
          "score": 3,
          "created_utc": "2026-01-27 15:26:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o277tgt",
          "author": "SecureHunter3678",
          "text": "Holy shit letting Claude work Ghydra is fucking genius... That just gave me soooo many Ideas.",
          "score": 3,
          "created_utc": "2026-01-28 12:04:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279zmv",
              "author": "pevers",
              "text": "It is a game changer. I did this in a fraction of the time it would cost me without AI. I remember painfully debugging method after method trying to figure out the flow. Now I can just let it crunch for an hour and it comes back with \\~100 renamed methods and data structures.",
              "score": 1,
              "created_utc": "2026-01-28 12:19:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27bn15",
                  "author": "SecureHunter3678",
                  "text": "Some while ago I also saw a Cheat Engine MCP Floating around. I guess i know what I'm going to do this weekend. That opens some modding doors on Retro Games, at which I had been crunching my teeth out for a while.",
                  "score": 1,
                  "created_utc": "2026-01-28 12:30:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o21cylx",
          "author": "InfraScaler",
          "text": "haahahah fcking brilliant mate! and I bet it was lots of fun working on it!",
          "score": 2,
          "created_utc": "2026-01-27 16:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o229ahz",
          "author": "cionut",
          "text": "So cool!! Planning to open source/share? Back in my days people had travian at work on a second screen - this could fit the same role",
          "score": 2,
          "created_utc": "2026-01-27 18:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22rrxn",
              "author": "pevers",
              "text": "Thanks! There is a GitHub repo with the code. It is mainly DLL injection to read values from memory but I‚Äôm working on a patch for more control.",
              "score": 2,
              "created_utc": "2026-01-27 19:47:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o22ndcg",
          "author": "Open_Resolution_1969",
          "text": "I took the liberty to cross post your message on another reddit since the idea is amazing and very appealing!",
          "score": 2,
          "created_utc": "2026-01-27 19:27:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o22svvm",
              "author": "pevers",
              "text": "Thanks! In which sub-reddit? I'm not sure why but I can't see it",
              "score": 1,
              "created_utc": "2026-01-27 19:52:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o22tbgq",
                  "author": "Open_Resolution_1969",
                  "text": "https://www.reddit.com/r/impressionsgames/s/DTjC6s1P9u",
                  "score": 1,
                  "created_utc": "2026-01-27 19:54:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o22xup8",
          "author": "jotarokato",
          "text": "    hay que jder",
          "score": 1,
          "created_utc": "2026-01-27 20:14:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o26viqx",
          "author": "msghost1989",
          "text": "Thats why i love paying so much money for ddrs üòç",
          "score": 1,
          "created_utc": "2026-01-28 10:24:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qog1wq",
      "title": "I wrote Concierge, an Open Source library to convert MCPs into tool groups, stages and workflows which are progressively discovered as agents interact with the server.",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/",
      "author": "Prestigious-Play8738",
      "created_utc": "2026-01-27 14:56:15",
      "score": 66,
      "num_comments": 12,
      "upvote_ratio": 0.96,
      "text": "Hey everyone!\n\nAnyone else tired of configuring 50¬†tools into MCP and just¬†hoping¬†the¬†agent figures¬†it out? (invoking the right tools in the right order).\n\nWe keep¬†hitting same problems:\n\n* Agent¬†calls¬†\\`checkout()\\`¬†before¬†\\`add\\_to\\_cart()\\`\n* Context bloat: 50+ tools served for every conversation message.\n* Semantic loss: Agent does not know which tools are relevant for the current interaction\n* Adding¬†a system¬†prompt describing the order of tool invocation and praying that the agent follows it.\n\nSo I wrote Concierge. It converts¬†your¬†MCP into a stateful graph, where you¬†can organize tools into¬†stages and workflows, and agents only have tools¬†**visible to the¬†current stage**.\n\n    from concierge import Concierge\n    \n    app = Concierge(\"my-server\")\n    \n    \n    app.stages = {\n        \"browse\": [\"search_products\"],\n        \"cart\": [\"add_to_cart\"],\n        \"checkout\": [\"pay\"]\n    }\n    \n    \n    app.transitions = {\n        \"browse\": [\"cart\"],\n        \"cart\": [\"checkout\"]\n    }\n\nThis also supports sharded distributed state and semantic¬†search for¬†thousands of tools. (also compatible with existing MCPs)\n\nDo try it out and love to know what you think. Thanks!\n\nRepo: [https://github.com/concierge-hq/concierge](https://github.com/concierge-hq/concierge)\n\nInstall it with: `pip¬†install concierge-sdk`",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o20xlhe",
          "author": "Choice-Party4676",
          "text": "Following",
          "score": 4,
          "created_utc": "2026-01-27 14:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21bb6e",
          "author": "fizzcuber",
          "text": "very interesting. did you considering contributing this to the mcp spec? I remember seeing something about progressive disclosure for mcps tools",
          "score": 2,
          "created_utc": "2026-01-27 16:00:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o21cp4t",
              "author": "Prestigious-Play8738",
              "text": "Thank you for your interest! Concierge provides constructs like distributed state, discovery, orchestration, storage etc.\n\nSuch features may not be relevant to the protocol, but very relevant to the application layer to build apps/servers.",
              "score": 2,
              "created_utc": "2026-01-27 16:06:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o24l9zi",
          "author": "pbalIII",
          "text": "Stage-gated tool visibility is the part that scales best. Most teams I've seen hit a wall around 20-30 tools where the model starts confusing semantically similar actions... checkout vs complete_order vs finalize_purchase.\n\nThe semantic search mode compressing to two meta-tools (search_tools + call_tool) is clever for the long tail case. For backtracking scenarios like abandoned carts mid-checkout, the cleanest pattern I've seen is treating reverse transitions as explicit stages rather than reverse edges. Reset to a known stage, don't try to unwind.",
          "score": 2,
          "created_utc": "2026-01-28 00:58:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279jf8",
              "author": "Prestigious-Play8738",
              "text": "Reset is a really great idea! Support should be added shortly",
              "score": 1,
              "created_utc": "2026-01-28 12:16:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26u7sg",
          "author": "kduman",
          "text": "This is really cool. I like the idea.",
          "score": 2,
          "created_utc": "2026-01-28 10:13:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279eo8",
              "author": "Prestigious-Play8738",
              "text": "Thanks! Concierge makes your MCP server a first class citizen, let me know if you want to use it in the future. Can share unlimited lifetime deployment credits on the platform",
              "score": 1,
              "created_utc": "2026-01-28 12:15:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o29zza4",
                  "author": "Select-Bell-5920",
                  "text": "Would love to give it a go!",
                  "score": 2,
                  "created_utc": "2026-01-28 20:01:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2786t0",
          "author": "Childish_Ganon",
          "text": "Landed on a similar pattern for my project, an MCP server with 60+ data science tools. I split them into classes (utils, parent tools, workflow tools, and subtools), then group subtools by function (EDA, cleaning, visualization, ML, etc.). Parent tools wrap subtools via `describe_<category>` \\+ `execute_<category>`, so the agent discovers tools progressively rather than getting everything dumped into context at once. Workflow tools package related subtools together for common pipelines.\n\nGitHub: [https://github.com/oogunbiyi21/stats-compass-mcp](https://github.com/oogunbiyi21/stats-compass-mcp)",
          "score": 0,
          "created_utc": "2026-01-28 12:07:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o279611",
              "author": "Prestigious-Play8738",
              "text": "This is awesome, happy to connect if you want to implement this with Concierge, change 4-5 lines and get superpowers! Great to see your server, starred it!",
              "score": 1,
              "created_utc": "2026-01-28 12:13:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o27azix",
                  "author": "Childish_Ganon",
                  "text": "Will definitely consider it in the future! As the number of data science tools expands I'm conscious that I might need even tighter tool orchestration, and in particular I think the way I've managed workflows could be simplified.",
                  "score": 1,
                  "created_utc": "2026-01-28 12:26:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnhf18",
      "title": "finally found a stack that doesn't break my agents every 5 mins",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qnhf18/finally_found_a_stack_that_doesnt_break_my_agents/",
      "author": "Ilove_Cakez",
      "created_utc": "2026-01-26 14:25:28",
      "score": 58,
      "num_comments": 5,
      "upvote_ratio": 0.97,
      "text": "idk about you guys but i've spent way too much of 2025 just fighting with my mcp config files instead of actually building. finally feel like i‚Äôve got a stable setup that doesn't require me to babysit my terminal all day so i thought i'd drop it here.\n\nthis is what i‚Äôm using for my agentic workflow right now:\n\n1. mcp jam - local testing tool for chatgpt apps and mcp servers. lets you build locally with a widget emulator and test against any llm in the playground\n\n2. smithery - still the best place to find ready-to-go servers. i basically use it as my app store for mcp... usually grab their github and figma connectors first thing on any new project.\n\n3. ogment ai - this is my secret weapon for the \"adult\" stuff. i use it to handle the remote hosting and the nasty auth/governance bits that i don't want to hardcode into my own servers. it basically lets me select a data source (api/db/3rd party) and customise the server tools in plain english and it just stays live/secure without me touching it.\n\n4. context7 - been using this to keep the agent's docs updated. helps so much when you're working with fast-moving libraries that claude‚Äôs base training hasn‚Äôt seen yet.\n\nhonestly, once i offloaded the server hosting and auth to ogment and started using smithery for the standard stuff, my dev velocity basically tripled. it‚Äôs nice to actually have a \"production\" grade setup without needing a whole devops team to manage the backend.\n\nwhat are you guys using for your registry/governance? i'm still looking for a better way to handle long-term memory across sessions if anyone has suggestions.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qnhf18/finally_found_a_stack_that_doesnt_break_my_agents/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o1tsj9f",
          "author": "MoP342",
          "text": "Hi! I'm building Airlock ([https://www.air-lock.ai](https://www.air-lock.ai)), which acts as an MCP server, security layer and audit trail. Obviously, I'm using that as registry/governance, but it's very interesting to see what other people are using.\n\nHaven't used smithery. Where do you end up in terms of cost, monthly?\n\nFor long-term memory: since I basically live in Claude, CLAUDE.md does the trick for me...",
          "score": 2,
          "created_utc": "2026-01-26 14:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xv8d8",
              "author": "isoman",
              "text": "Governance is the future of AI: https://github.com/ariffazil/arifOS",
              "score": 2,
              "created_utc": "2026-01-27 02:09:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ylz9j",
          "author": "Honest-Antelope-2589",
          "text": "Can u share wdym by config file issues isn't the config file catching up and the tools getting used or its the ide in loading state or something else can u share it clearly .",
          "score": 2,
          "created_utc": "2026-01-27 04:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o274kmn",
          "author": "saif_shines",
          "text": "Try scalekit.com! Very lightweight OAuth 2.1 layer.",
          "score": 1,
          "created_utc": "2026-01-28 11:40:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g8pm1",
          "author": "pbalIII",
          "text": "Splitting hosting/auth from the registry layer is underrated. I've seen teams waste weeks debugging config drift when both concerns are tangled in one server.\n\nFor long-term memory: check out Mem0's OpenMemory MCP or the doobidoo/mcp-memory-service repo. Both do semantic indexing so the agent retrieves relevant context instead of dumping everything into the prompt. The key is scoped memory keys... user_id + namespace prevents contamination across sessions.\n\nOne thing I'd push back on: CLAUDE.md works for project context but doesn't scale for user-specific state across multiple projects. You end up needing a proper memory layer eventually.",
          "score": 1,
          "created_utc": "2026-01-29 17:56:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnpgrl",
      "title": "MCP Apps - Bringing UI Capabilities To MCP Clients",
      "subreddit": "mcp",
      "url": "https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps/",
      "author": "beckywsss",
      "created_utc": "2026-01-26 19:05:12",
      "score": 28,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qnpgrl/mcp_apps_bringing_ui_capabilities_to_mcp_clients/",
      "domain": "blog.modelcontextprotocol.io",
      "is_self": false,
      "comments": [
        {
          "id": "o1y1ear",
          "author": "Zach543",
          "text": "Is this the same as Google's A2UI?",
          "score": 1,
          "created_utc": "2026-01-27 02:43:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o242ogs",
              "author": "EnvironmentSilent647",
              "text": "Not really, A2UI is generative UI where the model ‚Äòbuilds‚Äô a UI out of a component catalog. MCP Apps are fully custom interactive UI apps that the MCP server provides.",
              "score": 1,
              "created_utc": "2026-01-27 23:23:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yw1vp",
          "author": "Ok-Bedroom8901",
          "text": "I‚Äôm really glad to see Claude finally supporting MCP apps. I was getting a little worried there since ChatGPT had app support first.\n\nChatGPT has a tendency to do things slowly, poorly, and terribly.",
          "score": 1,
          "created_utc": "2026-01-27 05:56:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zsriu",
          "author": "jezweb",
          "text": "Awesome. Glad to see this is standardised.",
          "score": 1,
          "created_utc": "2026-01-27 10:44:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2310sw",
          "author": "mkaufman09",
          "text": "Anyone know what changes you need to make when they add chatgpt support if you built according to chatgpts app protocol originally",
          "score": 1,
          "created_utc": "2026-01-27 20:28:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qobxmj",
      "title": "MCP apps VS Apps SDK (OpenAI)",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/",
      "author": "0xKoller",
      "created_utc": "2026-01-27 12:01:00",
      "score": 24,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "MCP Apps is now an official extension to the Model Context Protocol (MCP), enabling tools to return interactive UI components that render directly within MCP clients. It overcomes the limitations of text-based interactions by delivering rich, sandboxed UI experiences right inside conversations, while keeping the model involved through seamless bidirectional communication.\n\nBefore this, we had OpenAI's Apps SDK, a proprietary alternative that allowed similar functionality but was limited to the ChatGPT sandbox, with exclusive runtime variables and APIs. In contrast, MCP Apps enables UI rendering in *any* MCP client that supports it, promoting a more open and portable ecosystem.\n\n# GPT Apps vs. MCP Apps\n\n* **Backbone**: GPT Apps build on MCP plus OpenAI's proprietary widget runtime, while MCP Apps use pure MCP with a standardized UI extension.\n* **UI Declaration**: GPT Apps declare UIs via `_meta.openai/outputTemplate` or similar, whereas MCP Apps use the standard `_meta.ui.resourceUri: \"ui://dashboard\"`.\n* **UI Delivery**: Both deliver bundled HTML/JS resources served by an MCP server.\n* **Host and UI**: GPT Apps rely on OpenAI-specific widget runtime and postMessage, but MCP Apps standardize it with JSON-RPC over postMessage.\n\nThe ecosystem has converged remarkably fast. MCP Apps emerges as the open, multi-platform winner going forward and with ChatGPT now supporting the official standard, you no longer have to choose between them. OpenAI may even phase out their proprietary development in the near future.\n\n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o231bsw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-01-27 20:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23722l",
              "author": "sylre",
              "text": "There is a statement on the mcp website talking about convergence of both standard",
              "score": 1,
              "created_utc": "2026-01-27 20:56:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o23lli4",
          "author": "matt8p",
          "text": "I was skeptical of ChatGPT adopting MCP apps at all. It's great for the ecosystem to have a single protocol for apps. From a business perspective, it might be better off for OpenAI to maintain their own ecosystem. They could implement add-ons like payment flows that aren't part of the MCP apps spec.",
          "score": 1,
          "created_utc": "2026-01-27 22:00:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o24lkcx",
          "author": "pbalIII",
          "text": "Portability is the real win here. Building on MCP means your server works with Claude, Cursor, VS Code, whatever supports the protocol... not just ChatGPT. That compounds over time as more clients ship support.\n\nOne thing worth watching: the spec leaves a lot of implementation details to individual hosts. Could see some fragmentation creep in between how OpenAI, Anthropic, and VS Code handle edge cases. The double iframe architecture and pre-declared resources are aligned, but the Host-to-Guest communication layer has room for drift.",
          "score": 1,
          "created_utc": "2026-01-28 00:59:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o255idg",
              "author": "Sad-Passage-4653",
              "text": "Reminds me of when everyone had to put custom <!-- if ie6 --> code in their HTML back in the day.  Hopefully no on makes an MCP version of internet explorer lol",
              "score": 2,
              "created_utc": "2026-01-28 02:44:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2655qy",
          "author": "Euphoric-Mark-4750",
          "text": "Has anyone had any success getting there (remote) MCP hosted in either of Anthropic / OpenAI connectors/apps directories?\n\nI submitted mine to Anthropic a week plus ago - the submission messaged involved a ‚Äòwe may not list your connector nor may we contact you‚Äô and no email acknowledgment of submission - not exactly hopeful.\n\nI got stuck with OpenAI‚Äôs business verification process. Just starting to wonder if any of it was worth the effort.",
          "score": 1,
          "created_utc": "2026-01-28 06:31:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o28vf4f",
          "author": "Ok_Message7136",
          "text": "This is a good breakdown. The big win with MCP Apps is portability, same UI + tools across any MCP client, not locked to one runtime.\n\nFeels like the natural evolution now that MCP is becoming the shared standard instead of every platform inventing its own app model.",
          "score": 1,
          "created_utc": "2026-01-28 17:05:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqior0",
      "title": "I built a playground to test MCP + Skills Pairing",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/gallery/1qqior0",
      "author": "matt8p",
      "created_utc": "2026-01-29 19:38:23",
      "score": 20,
      "num_comments": 4,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qqior0/i_built_a_playground_to_test_mcp_skills_pairing/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2gvr7y",
          "author": "matt8p",
          "text": "Skills + MCP is still a fairly new concept. I would love to hear your opinions on MCP with Skills. \n\nIf you're interested in reading more about the new features we put out, I encourage you to read the blog below!\n\n[https://www.mcpjam.com/blog/skills](https://www.mcpjam.com/blog/skills)",
          "score": 4,
          "created_utc": "2026-01-29 19:41:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2gyuq4",
              "author": "Bobification",
              "text": "This is interesting timing...we have an MCP server in front of our GraphQL api and Claude consistently fails at using the right query and params despite running a schema check first.  Instead of making an attempt to make better tools, management has (just this morning) suggested we use skills to explain to Claude how to use our MCP server.  I'm not yet convinced that we should go that route ourselves but maybe at least we can attempt to test that here.",
              "score": 3,
              "created_utc": "2026-01-29 19:56:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2h2e9e",
                  "author": "matt8p",
                  "text": "I'd start off by being more descriptive in the tool descriptions / tool param descriptions, or the MCP server instructions. This could give better context to Claude on how to use the server. \n\nHaving skills is nice, but the only downside is that it's not attached / bundled with the MCP server. It's loaded separately. Try tweaking the server itself first, then if that doesn't work, use the skill.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:13:11",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o2h2nxh",
                  "author": "matt8p",
                  "text": "On a tangent, I'd wish Anthropic encourage use of MCP prompts more rather than push for MCP + Skills. You can have skills be loaded up in the prompt so they're bundled together. This would accomplish the same thing.",
                  "score": 1,
                  "created_utc": "2026-01-29 20:14:28",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnqm5q",
      "title": "A practical open-source repo for learning AI agents",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qnqm5q/a_practical_opensource_repo_for_learning_ai_agents/",
      "author": "Creepy-Row970",
      "created_utc": "2026-01-26 19:44:19",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 0.94,
      "text": "A practical open-source repo for learning AI agents. I‚Äôve contributed 10+ examples\n\nI‚Äôve contributed 10+ agent examples to an open-source repo that‚Äôs grown into a solid reference for building AI agents.\n\nRepo:[ https://github.com/Arindam200/awesome-ai-apps](https://github.com/Arindam200/awesome-ai-apps)\n\nWhat makes it useful:\n\n* 70+ runnable agent projects, not toy demos\n* Same ideas built across different frameworks\n* Covers starter agents, MCP, memory, RAG, and multi-stage workflows\n\nFrameworks include LangChain, LangGraph, LlamaIndex, CrewAI, Agno, Google ADK, OpenAI Agents SDK, AWS Strands, and PydanticAI.\n\nSharing in case others here prefer learning agents by reading real code instead of theory.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnqm5q/a_practical_opensource_repo_for_learning_ai_agents/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qnflkf",
      "title": "MCP and Skills: Why Not Both?",
      "subreddit": "mcp",
      "url": "https://kvg.dev/posts/20260125-skills-and-mcp/",
      "author": "kurtisvg",
      "created_utc": "2026-01-26 13:10:20",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnflkf/mcp_and_skills_why_not_both/",
      "domain": "kvg.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o1tqjl7",
          "author": "Block_Parser",
          "text": "Why not make skills a special type of resource `skill://` similar to `ui://`",
          "score": 2,
          "created_utc": "2026-01-26 14:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yd3w4",
              "author": "kurtisvg",
              "text": "That's definitely one approach, but I think it's a bit of shame if skills can't call tools or read files without just copying the resource locally.",
              "score": 1,
              "created_utc": "2026-01-27 03:49:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1unyli",
          "author": "Joy_Boy_12",
          "text": "What is a skill?",
          "score": 1,
          "created_utc": "2026-01-26 17:12:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yepyl",
              "author": "kurtisvg",
              "text": "There is a TL;DR in the post, but you can find the full spec here: [https://agentskills.io/home](https://agentskills.io/home)",
              "score": 1,
              "created_utc": "2026-01-27 03:59:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2d8d9c",
          "author": "p1zzuh",
          "text": "i actually just built a skill and an mcp server this week for my product\n\ni think i prefer skills. also if you're just getting started skills have a much lower barrier to entry, it's just a [SKILL.md](http://SKILL.md) file",
          "score": 1,
          "created_utc": "2026-01-29 06:32:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qritks",
      "title": "Is Sequential Thinking MCP still a thing?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qritks/is_sequential_thinking_mcp_still_a_thing/",
      "author": "ShaneIGucci",
      "created_utc": "2026-01-30 21:35:40",
      "score": 14,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Does anyone else still use Sequential Thinking MCP with Opus 4.5?\n\nI‚Äôve been using Opus 4.5 for planning and it‚Äôs been insanely reliable. But here‚Äôs the thing‚ÄîI still manually ask Claude to trigger Sequential Thinking MCP out of habit, even though I‚Äôm not sure it actually improves the output.\n\nHas anyone else noticed this? I can‚Äôt really tell the difference in quality between answers with and without it. At this point, it feels like a placebo effect‚Äîmaybe I‚Äôm just stuck in my old workflow.\n\nShould I just drop the MCP prompt and trust Opus 4.5 fully? Or am I missing something? Would love to hear your experiences!",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qritks/is_sequential_thinking_mcp_still_a_thing/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2p8khn",
          "author": "TokenRingAI",
          "text": "In our coding app, we built around 10 different versions of sequential thinking, such as scientific method, socratic method, feynman principles, decision matrix, the original sequential thinking, working step by step, and quite a few more, and saw no measurable performance increase, even with small models.\n\nThey make the LLM look smarter but the results were the same or maybe worse, slower, more tokens.\n\nYou can see some of them here, if you are interested in what has been tried and did not work:\nhttps://github.com/tokenring-ai/thinking/tree/main/tools\n\nThe only thing that showed a clear benefit, was the under-appreciated append-only TODO list that is standard in most agents these days",
          "score": 9,
          "created_utc": "2026-01-30 23:52:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pitii",
          "author": "DasBlueEyedDevil",
          "text": "I find that just using plan mode first functions better than sequential thinking ever really did",
          "score": 5,
          "created_utc": "2026-01-31 00:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oszry",
          "author": "deafpigeon39",
          "text": "Massively increases the output when i need the agent to properly plan my request , asking them to use it before doing something makes them overthink mostly.",
          "score": 1,
          "created_utc": "2026-01-30 22:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ojw74",
          "author": "Nice_Profession_9078",
          "text": "I have my own tool built that even records and embeds it's thought chains, it can reopen them and branch, can't back out until over 90% confident or the last thought is reached, extremely useful.",
          "score": 0,
          "created_utc": "2026-01-30 21:44:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnntj7",
      "title": "We built Colin, a context engine that can keep agent skills fresh",
      "subreddit": "mcp",
      "url": "/r/AI_Agents/comments/1qnns7n/we_built_colin_a_context_engine_that_can_keep/",
      "author": "jlowin123",
      "created_utc": "2026-01-26 18:10:48",
      "score": 11,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qnntj7/we_built_colin_a_context_engine_that_can_keep/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qpn0d5",
      "title": "LAD-A2A: How AI agents find each other on local networks",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "author": "franzvill",
      "created_utc": "2026-01-28 20:29:18",
      "score": 10,
      "num_comments": 3,
      "upvote_ratio": 0.92,
      "text": "AI agents are getting really good at doing things, but they're completely blind to their physical surroundings.\n\nIf you walk into a hotel and you have an AI assistant (like the Chatgpt mobile app), it has no idea there may be a concierge agent on the network that could help you book a spa, check breakfast times, or request late checkout. Same thing at offices, hospitals, cruise ships. The agents are there, but there's no way to discover them.\n\nA2A (Google's agent-to-agent protocol) handles how agents talk to each other. MCP handles how agents use tools. But neither answers a basic question: how do you find agents in the first place?\n\nSo I built LAD-A2A, a simple discovery protocol. When you connect to a Wi-Fi, your agent can automatically find what's available using mDNS (like how AirDrop finds nearby devices) or a standard HTTP endpoint.\n\nThe spec is intentionally minimal. I didn't want to reinvent A2A or create another complex standard. LAD-A2A just handles discovery, then hands off to A2A for actual communication.\n\nOpen source, Apache 2.0. Includes a working Python implementation you can run to see it in action. Repo can be found at franzvill/lad.\n\nCurious what people think!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2b0ei3",
          "author": "Upstairs_Safe2922",
          "text": "Interesting stuff! Will it automatically connect or will need human final approval? Follow up, can something that was already on the network connect to the agent unprompted?",
          "score": 1,
          "created_utc": "2026-01-28 22:43:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2djyd9",
              "author": "franzvill",
              "text": "Human approval always required! Discovery is passive (just shows what's available), but connecting requires explicit user consent. \n\nNothing can connect to your agent unprompted as it's client-initiated and consent-gated by design. If you are curious, you can see Section 4.3 of the spec:\n\n[https://lad-a2a.org/](https://lad-a2a.org/)\n\n[https://github.com/franzvill/lad](https://github.com/franzvill/lad)",
              "score": 2,
              "created_utc": "2026-01-29 08:12:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqk0j3",
      "title": "Have I understood MCP correctly?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "author": "DoNotBelieveHim",
      "created_utc": "2026-01-29 20:26:52",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "My understanding of MCP is that I can publish details about what my REST API does, what each end point can do (\"This is for creating new clients\", \"This gives a list of overdue tasks for the current user\") and how to use the endpoints (JSON payload looks like this. \n\nBasically a subset of whats already in my OpenAPI Spec (swagger.json) with some natural langauge explanations of whats there.\n\nThis then enables LLMs to take user input in natural language (\"Create a new client call John\", \"Whats on my plate today?\") to then take actions on my server via the REST API\n\nIs that anywhere near correct or am I missing something important?",
      "is_original_content": false,
      "link_flair_text": "question",
      "permalink": "https://reddit.com/r/mcp/comments/1qqk0j3/have_i_understood_mcp_correctly/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2ha2vg",
          "author": "guyernest",
          "text": "Your swagger file and other OpenAPI specs were designed for developers to use to call the API. Each developer reviewed the schema and decided what they wanted to use for their use case. You don't expect every developer to use every API call for every application.   \nAn MCP server, such as an API, can take two extreme approaches: either implement a couple of tools or allow \"code mode\". The former is similar to human developers who know what they need from the API and use only that, while the latter allows the LLM in the MCP client the freedom to call any API in any sequence.   \nMy advice is to take the middle ground and wrap a couple of the APIs as tools, based on the Pareto principle: 80% of calls will use 20% of the API. For the long tail of requests, you should enable a \"Code mode\" that provides the API schema and allows the MCP client to generate calls as needed to answer user requests.   \nThere are many security concerns for the \"Code mode\", but we some attention, you can build it safely.   \n",
          "score": 6,
          "created_utc": "2026-01-29 20:50:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hdyxe",
              "author": "DoNotBelieveHim",
              "text": "Thanks. Useful. Then it sounds like I‚Äôve not missed anything, other than that you can choose to be selective/prescriptive in how the API should be used. \n\nRe the security concerns, if the user of the LLM is authenticating themselves and has a token which the MCP uses to call the API - what are the security concerns beyond the regular concerns you‚Äôd have if a user was posting requests directly to the API? I assume you‚Äôd just pass through the bearer header or whatever you are using so the authorisation would be the same so I don‚Äôt see how the MCP could introduce new security risks.",
              "score": 1,
              "created_utc": "2026-01-29 21:09:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2huc8s",
                  "author": "guyernest",
                  "text": "MCP is an interface to your data, and it should be protected against two main types of risks: LLM mistakes and malicious users. A simple example is the option to delete data, or, less obviously, to update it. Once the user is authenticated, the MCP client stores the access token, and the MCP client can do everything that the user can do.   \nIf you only select the listUsers and getUser APIs (read-only) as MCP tools, there is not much risk that the MCP client will do anything else. However, if you also allow updateUser, the MCP client can now update the user record and grant them an unwarranted discount, for example. The MCP client typically doesn't display the full details of each call it makes to the MCP server, making it easy for users to miss such changes. Also, users might remember to log out of a sensitive website, but they will not remember to disconnect the MCP server from their ChatGPT. Therefore, a malicious user can use the MCP client connection to the MCP server and, through it, to the API to perform harmful actions on the data system. ",
                  "score": 2,
                  "created_utc": "2026-01-29 22:27:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2lrs4a",
              "author": "Melodic-Swimmer-4155",
              "text": "Really good explanation there m8!",
              "score": 1,
              "created_utc": "2026-01-30 14:05:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2hlkne",
          "author": "naseemalnaji-mcpcat",
          "text": "You're basically on the right track! MCP lets you describe your API's endpoints and expected behaviors in a way that's accessible to LLM-powered agents, often with a mix of structured data and natural language. While it overlaps with OpenAPI, MCP is more focused on making your API explorable and actionable by AI agents rather than human eyeballs. One key difference is that MCP emphasizes clarity and intent in descriptions, which helps reduce ambiguity for AI.",
          "score": 3,
          "created_utc": "2026-01-29 21:45:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2igw9o",
          "author": "laresek",
          "text": "Kinda except MCP doesn't use REST/Swagger and instead uses JSON-RPC 2.0. Instead of many endpoints like in REST there's only one endpoint that's used and the payload has a method and parameters that are passed along with it. There's some info here:\n https://modelcontextprotocol.io/specification/2025-03-26/basic",
          "score": 2,
          "created_utc": "2026-01-30 00:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jiyak",
          "author": "Sufficient_Waltz4299",
          "text": "here is a video that explains this really well - [https://youtu.be/Eq21IF54VuE](https://youtu.be/Eq21IF54VuE)",
          "score": 2,
          "created_utc": "2026-01-30 03:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2klip6",
          "author": "Ordinary-You8102",
          "text": "Yes the important thing is that its a protocol (standard) so any agent that is also a mcp client will be able to connect to any MCP throughout the world (single implementation and not 1 for each Agent) \nit solves the N * M problem",
          "score": 1,
          "created_utc": "2026-01-30 08:56:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lh5zv",
          "author": "BC_MARO",
          "text": "Mostly yes. MCP is basically a standard way for an agent/client to talk to ‚Äútool servers‚Äù (DB/search/files/APIs) over a defined protocol (stdio/HTTP).\n\nOne practical gotcha: auth/secrets + timeouts/retries end up being the real work.\n\n(I maintain it.) Reference/checklist (peta): [https://github.com/dunialabs/peta-core](https://github.com/dunialabs/peta-core)",
          "score": 1,
          "created_utc": "2026-01-30 13:07:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ovbf1",
          "author": "pbalIII",
          "text": "Wrapped an internal CRUD API with MCP a few months back. The mental shift was subtle but real: OpenAPI tells developers how to call endpoints, MCP tells agents why and when to use them.\n\nOne gotcha we hit... the model kept trying to chain writes together in ways that made sense semantically but violated business rules. Ended up having to add explicit constraints in tool descriptions, not just input schemas. The reasoning layer is powerful but it needs guardrails you wouldn't think to add for human devs.\n\nThe auth question in the comments is worth digging into. MCP clients hold tokens persistently, so the blast radius of a compromised session is bigger than a user forgetting to log out of a browser.",
          "score": 1,
          "created_utc": "2026-01-30 22:40:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qno8lg",
      "title": "Kent Dodds has an interesting metaphor about MCP vs naked API's",
      "subreddit": "mcp",
      "url": "https://v.redd.it/xkes8tw0kqfg1",
      "author": "sean-adapt",
      "created_utc": "2026-01-26 18:24:33",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "resource",
      "permalink": "https://reddit.com/r/mcp/comments/1qno8lg/kent_dodds_has_an_interesting_metaphor_about_mcp/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1ytcqa",
          "author": "AyeMatey",
          "text": "This is still not right. \n\nIt was never right and it isn‚Äôt right now.\n\nThink about it. How does MCP work? look at the interaction diagram on the modelcontextprotocol.io website. \n\nAn agent or tool uses MCP to talk to a server to \n- ask which tools are available \n- learn about the purpose of each of the tools and how to invoke (required params and expected responses)\n- invoke tools and get responses. \n\nAn agent.  Read that again. An agent uses MCP.  What uses MCP to talk to a server ?  An AGENT.\nDoes the agent use MCP to talk to the model? No. It does not. Check the diagram on the MCP website. \n\nOk at startup the agent calls each MCP server‚Ä¶ using the MCP protocol‚Ä¶.  and says ‚Äútell me which tools you have available‚Äù.  And the MCP server ‚Ä¶. Using the MCP protocol‚Ä¶. Returns the list of tools available, back to the agent. \n\nThen, _after the agent gets the list of tools available from the MCP server (or maybe multiple)_, the agent sends to the LLM a user query along with a list of tools available. This list of tools is a transformation of the list retrieved from the servers. It is not jsonrpc , it is not MCP (the protocol). It is json.  \n\nLet me repeat that because it‚Äôs important: The agent does not use MCP to communicate with the LLM (aka model).  The model does not know about MCP. The model does not know where the tools came from.  \n\nThere is no universe in which the model will find it ‚Äúeasier‚Äù to use a tool that was originally propagated to the agent via MCP, as compared to a tool that was originally propagated to the agent via API. IT DOES NOT MAKE SENSE. \n\n\nPeople who say ‚Äúit‚Äôs easier for a model to use tools exposed via MCP‚Äù ‚Ä¶ either do not understand, or want to fool you. \n\n2nd thing - there is a bit of truth to the idea that IN THEORY, MCP allows progressive expansion of the list of tools.  \n\nIn theory. \n\nAnd in actuality, there are approximately zero concrete implementations of MCP servers that expose different sets of tools at different times to the same agent. I have seen MCP servers that expose different sets of tools to different agents, depending on the user or agent identity. But not different over time for the same identities. \n\nSo it is true that MCP, the protocol, allows for this progressive exposure of tools.  And it is also true that there‚Äôs no practical way to implement it. The MCP server does not have the context that the agent has.  The MCP server knows only that an agent (MCP client) has or has not invoked a tool. This information is not enough to produce a high quality ‚Äúprogressive‚Äù expansion of the list of tools. \n\nImagine an MCP server: ‚ÄúOh you invoked tool A? I will now tell you about tool B!‚Äù  That‚Äôs possible but that kind of interaction will starve agents of reasoning capability. The agent solves problems with the model by assembling a plan for invoking multiple tools to arrive at a solution. If the MCP server doesn‚Äôt tell the agent about all the tools, a priori, then the agent+model cannot reason through a solution. \n\nAnd why do we want this progressive release of tools anyway? What is the benefit?  As I understand, The issue is that multiple MCP servers with multiple tools each can incur a token tax. Just telling the model about the tools can consume lots of tokens. Imagining that a progressive exposure of tools will reduce on that token tax‚Ä¶ is a fantasy. That‚Äôs not what is happening in practice. \n\nIn short. This opinion is not useful. It confuses or misleads people.",
          "score": 2,
          "created_utc": "2026-01-27 05:36:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yuiiy",
              "author": "AyeMatey",
              "text": "The one key benefit of MCP over APIs that i have seen: people produce better documentation for MCP servers. And THAT is what allows an agent+model to figure out which tools to invoke.  \n\nOpenAPI specs typically have poor documentation with few examples. And the agent cannot make sense of when to call it. Or how .\n\nIf you want agents to have a better time with tools exposed as APIs‚Ä¶. Improve the documentation in the OpenAPI spec.  Add examples.",
              "score": 3,
              "created_utc": "2026-01-27 05:45:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1z46dn",
              "author": "Darnaldt-rump",
              "text": "You said does an agent use mcp to talk to a model not usually but it can, depending on how you‚Äôre building an mcp server you can have dynamic tool lists that are exposed to the agent using the mcp server. \n\nBut all of what I said it dependent on how the mcp server is developed.",
              "score": 1,
              "created_utc": "2026-01-27 07:01:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o22j7yd",
                  "author": "AyeMatey",
                  "text": "> does an agent use mcp to talk to a model not usually but it can,  \n\nNo. Still no.  Check the diagram. Agents do not talk to models via MCP. \n\nModels have their own APIs which predate MCP. The agents use the model‚Äôs api to talk to the model. Each model has a different API. Though, due to first mover advantage, the ChatGPT api is often implemented by non-ChatGPT models. \n\nIf this is not clear, i suggest that you review the documentation at modelcontextprotocol.io.\n\n> depending on how you‚Äôre building an mcp server you can have dynamic tool lists that are exposed to the agent using the mcp server.\n\nYea. I addressed that in my comment. It‚Äôs possible and rarely (if ever) actually implemented. \n\nAnd regardless, a dynamic tool list doesn‚Äôt mean an agent communicates to a model via MCP. Those are different links in the distributed architecture.",
                  "score": 1,
                  "created_utc": "2026-01-27 19:09:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o25a9md",
              "author": "DangerousSubject",
              "text": "I made an MCP server that proxies other MCP servers. Exposes two tools, findTools, loadTools. Agent chooses when to load new tools which refreshes the tool list. Multiple tool sets swapped out by the same agent in the same session.",
              "score": 1,
              "created_utc": "2026-01-28 03:10:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o28heb6",
                  "author": "AyeMatey",
                  "text": "I understand that it‚Äôs possible for an MCP server to disclose different sets of tools at different times. \n\nNow please tell me how the agent knows when it needs to do this, to load new tools.\n\nYour layered /proxied approach doesn‚Äôt change the physics. An unlayered MCP server could do the same filtering / finding. Right?  But it doesn‚Äôt matter - dynamically loaded tools or not. \n\nThe agent+LLM is responsible for reasoning through the solution to the problem. It does so with the list of tools it has available. \n\nIt does not know, a priori, what tools it needs. It‚Äôs more of an Apollo 13 thing - you know the scene where they dump a bunch of parts and materials on a desktop and say, ‚Äúok given this stuff we have available, let‚Äôs figure out how to solve the problem.‚Äù?  That is what the agent does. \n\nAnd to do that, it wants all the possible tools in the beginning. The MCP server does not participate in this reasoning phase. It has no context beyond which tools the agent has already invoked. It cannot ‚Äúknow‚Äù when it is appropriate to dribble out more tools.\n\nGrandpa teaching his 7yr old grandkid how to make a stool, knows the solution, and the steps. Grandpa can say ‚Äúok, now that you used the saw, I think you‚Äôre going to need the drill.  Do you know why?‚Äù Leading the 7 yr old to the solution. The MCP + agent relationship is not like that. The MCP server does not know the problem. Does not know the steps or the sequence of tools necessary. And before the agent sees all the tools, it cannot know that either. \n\nI‚Äôm fairly convinced but am open to counter arguments. Explain how the MCP server ‚Äúknows‚Äù when it will need to disclose additional tools, or how the agent will ‚Äúknow‚Äù which tools to ask for, before knowing all the possible tools. \n\nYou can offer as an example a ‚Äúblank slate‚Äù agent that searches for and finds tools (MCP servers)‚Ä¶ via the equivalent of a google search. that‚Äôs a possible avenue. But to make this happen , the agent has to modify its MCP server configuration after doing the search.  \n\nIn which case, there‚Äôs no point to filtering tools. Basically the solution devolves into a ‚Äúassemble tools‚Äù phase and a ‚Äúuse tools‚Äù phase and in the ‚Äúuse tools‚Äù phase, once again, tool filtering isn‚Äôt practical or beneficial to reduce the token tax. \n\nLike legos, you can attach pieces in all sorts of ways, but not all of the connections are useful or stable or sensible. Some combinations will be a hallucinogenic Picasso architecture. No bueno.",
                  "score": 1,
                  "created_utc": "2026-01-28 16:04:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qpa84z",
      "title": "HTTP2/HTTP3 support in the future?",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "author": "DorkyMcDorky",
      "created_utc": "2026-01-28 12:38:07",
      "score": 8,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "Quick question for r/mcp: has anyone considered an HTTP/2 or HTTP/3 transport option for MCP, even if HTTP/1 stays the baseline? I get the tradeoffs like HTTP/1 ubiquity, stateless infra, and simpler deployment, but I am curious how folks weigh those against streaming and long lived connections.\n\nI know HTTP/2 or HTTP/3 can be a pain in cloud environments and external facing SaaS, but for internal networks and home labs it is much easier and brings real benefits like multiplexing and true streaming. Maybe MCP is mainly targeting SaaS cloud infra, but it feels like a huge miss that there is no true streaming option for internal use cases.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o27mkvy",
          "author": "Crafty_Disk_7026",
          "text": "I have grpc mcps with streaming but they are custom integrations I created and not MCP based but does the same thing.  Also I have been experimenting with codemode mcps which is not really http difference but instead executes the agent logic as a sandboxed code execution.  Te codemode flow has made the biggest improvement difference since it eliminates api round teips",
          "score": 3,
          "created_utc": "2026-01-28 13:36:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27mpbm",
              "author": "Crafty_Disk_7026",
              "text": "Please check out Google ADK streaming agent development workflow.  I believe this is more what you want than MCP on http2",
              "score": 1,
              "created_utc": "2026-01-28 13:37:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o27ntei",
                  "author": "DorkyMcDorky",
                  "text": "My intent is to make an MCP option that's streaming that can still work with MCP clients that are standard MCP services.  To have it so if you define this spec, you get MCP serving as well.  It would be a streaming version of the MCP service.  If both clients negotiate with each other and they're both HTTP2, then they can stay that way or else downgrade to HTTP1. \n\nI'll check it out!  Thanks for perking my ears in this direction..",
                  "score": 1,
                  "created_utc": "2026-01-28 13:43:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o27fksg",
          "author": "NoAdministration6906",
          "text": "‚Å†Hey, great question! I‚Äôve also been thinking about long‚Äëlived streams for internal MCP deployments. HTTP/2 (and especially HTTP/3) can unlock true multiplexing and lower‚Äëlatency streaming, but you‚Äôre right that cloud/SaaS environments often pose challenges around proxies and certs. One approach I‚Äôve seen is experimenting with WebTransport (over HTTP/3) in a home‚Äëlab setup to validate streaming performance, then rolling back to HTTP/2 or gRPC‚ÄëWeb for external/cloud contexts.",
          "score": 1,
          "created_utc": "2026-01-28 12:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27hrbj",
              "author": "DorkyMcDorky",
              "text": "Thanks. There is a gRPC transport effort, but it is a 1:1 mapping of current MCP, so it inherits the lack of true streaming. The current proto is here: [https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/](https://github.com/GoogleCloudPlatform/mcp-grpc-transport-proto/) and it mirrors the MCP spec and looks good.\n\nI plan to work on a wrapper that enables HTTP/2 streaming on top of that once the gRPC transport solidifies. The idea is to keep MCP compatibility, add HTTP/2 tunneling for true streaming, and avoid multiple server implementations. I can share details if you are interested.\n\nThat is why I asked the question. Why not define an HTTP/2 option and a tunneling spec too? My guess is it would over burden the spec, and the HTTP/1 work is leaning away from streaming to keep transports compatible. That is a reasonable direction, but it leaves a gap for internal and home lab use cases.",
              "score": 1,
              "created_utc": "2026-01-28 13:09:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27zmod",
          "author": "ToHallowMySleep",
          "text": "In the context of a streaming solution to MCP, I would favour HTTP/3 over HTTP/2, simply because HTTP/2 seems to have been slept on - it was adopted by only 50% of websites at its peak and now that is already down to 35% or so, as it just didn't resonate for full bidirectional support.\n\nBrowsers are more likely to jump to HTTP/3 support, and that's going to be a strong driver for protocol adoption.",
          "score": 1,
          "created_utc": "2026-01-28 14:43:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bosp0",
              "author": "DorkyMcDorky",
              "text": "100% I agree with you. However the latest spec is encouraging reeling back any streaming and staying pure stateless. \n\nThey want to focus on a common layer between transfer protocols which is a good idea but they need two implementations: one that is streaming and one that is not.  \n\nPersonally, they shouldn't even have a stateless solution. I know it would be a challenge to get this far but it's clearly the future. After all nvidia's even inventing new network interfaces to replace ethernet. The protocols are already there with http3.  So they should start that spec now. \n\nIt's worth bringing this up. My voice has been exhausted, I didn't do a good job communicating this :)",
              "score": 2,
              "created_utc": "2026-01-29 00:49:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28a02s",
          "author": "naseemalnaji-mcpcat",
          "text": "A few folks I know have experimented with custom proxies or sidecar services to enable HTTP/2 streaming on top of MCP, but nothing's standardized yet. If streaming is critical for your use case, it might be worth prototyping an internal fork or raising the discussion on the MCP repo‚Äîthere's likely more demand than the current baseline suggests.",
          "score": 1,
          "created_utc": "2026-01-28 15:32:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bnty5",
              "author": "DorkyMcDorky",
              "text": "I did that. With code examples. It was grpc and they said it belongs in grpc, missing the point. So I brought up the streaming. They likely didn't understand my communication. But I dropped it, the interest and point wasn't getting the attention it needed\n\nIf you can bring it up, it might help. Feel free to reach out to them; I'd love a chorus on this.",
              "score": 1,
              "created_utc": "2026-01-29 00:43:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2929a6",
          "author": "Creamy-And-Crowded",
          "text": "Nice catch on this gap. Right now, if an MCP server is pushing a large resource, it can effectively block the entire connection until it is done...   \nA priority lane for urgent reasoning steps while the heavy data moves in the background would be much desirable.",
          "score": 1,
          "created_utc": "2026-01-28 17:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2bp4xt",
              "author": "DorkyMcDorky",
              "text": "Not only that can you imagine how much cheaper it would be? Can you imagine that you can use agents in the middle of pipeline that can observe all of your logs and even react to your prompts in the middle of an answer,? There are so many use cases.",
              "score": 1,
              "created_utc": "2026-01-29 00:50:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2cfom6",
          "author": "pbalIII",
          "text": "Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases. The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nThe rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations. For internal/homelab setups where you control the infra, gRPC custom integrations (like the other commenter mentioned) work fine. But getting that into the spec would conflict with the stateless direction they're pushing.",
          "score": 1,
          "created_utc": "2026-01-29 03:16:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dx3t6",
              "author": "DorkyMcDorky",
              "text": "You summarize the tension well (with a slight clarification on the streamable option available today).\n\nYou‚Äôve touched on the fact that the MCP spec focuses on **stateless transport**. This feels like short-term gains to help massive, stateless cloud infrastructure. I agree - and that‚Äôs exactly the point of my post. They flirt with streaming but miss the opportunity; it‚Äôs a massive resource waste simply because true bidirectional streaming is difficult to deploy in large, legacy cloud infrastructure right now.  So I completely agree....\n\n... however ...\n\nAlthough MCP‚Äôs approach is \"pragmatic\" - creating an interface that *looks* like streaming - there‚Äôs no mention of how they‚Äôd ever make the jump to a real persistent transport in the future.  In fact, they're doing the opposite - removing streaming and double downing on stateless. (you touch on this too, just reiterating it for clarity)\n\nTo work around this, I use gRPC extensively already - so totally aware that streaming protocols DO exist - I'm suggesting that MCP should do that.\n\nThe downside is that it doesn‚Äôt offer an easily consumable public API for the now-popular chat protocols. However, agentic protocols like **ADK (Agent Development Kit)** or custom gRPC setups are embracing true streaming, leaving the \"popular\" MCP behind. It‚Äôs a missing scale on the dragon that I hope gets addressed.\n\n>Streamable HTTP already gives you chunked transfer encoding and progressive delivery over a single connection, which covers most of the streaming use cases.\n\nThe **Streamable HTTP** implementation (please correct me if I‚Äôm reading the code wrong) is not \"true\" streaming because the spec is still fundamentally **cursor-based**. The chunks are collected and yielded after the fact - making it \"polling with extra steps.\" This seems intentional, but I don‚Äôt see why they can‚Äôt offer a streaming option similar to how gRPC handles bidirectional streams.  It's streaming where you need to code like it's not.  Simulating non-streaming on a streaming transfer - blocking... \n\n>The 2026 roadmap is actually moving the opposite direction... toward a stateless protocol where session state lives at the app layer (cookie-style) rather than the transport.\n\nYes... instead of 2026 being the year of HTTP/3, we are scaling like it‚Äôs 2001. It works, but it‚Äôs putting **rockets on roller skates**.\n\n>The rationale is horizontal scaling. Sticky sessions and distributed state management are the bottleneck for enterprise deployments, not HTTP/1.1 limitations.\n\nI get that, and it is pragmatic. But that mainly helps Google, Amazon, and Oracle while it makes us pay more in data center costs for their ease of deployment.\n\nThe current gRPC spec in the MCP ecosystem doesn't even offer true streaming; it‚Äôs just a 1:1 mapping of the MCP JSON-RPC. Again, a miss.   \n  \nSo reeling it back to my point: **MCP is not true streaming, but should be.** I‚Äôm not arguing that \"streaming-like\" behavior doesn't exist, but MCP is literally no different than the browser polling mechanisms we‚Äôve seen for 25 years.\n\nIf getting real streaming into the spec conflicts with the \"stateless direction\" they‚Äôre pushing, then the line in the sand should be clear: **MCP is for stateless utility; ADK and custom gRPC are for agentic streaming.**",
              "score": 1,
              "created_utc": "2026-01-29 10:15:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gbwub",
                  "author": "pbalIII",
                  "text": "Stateless at the transport layer, stateful at the app layer... that's basically how HTTP has worked forever. The session-as-cookie approach they're proposing isn't regression, it's unbundling concerns that got conflated when MCP was primarily local STDIO.\n\nThe gRPC angle is interesting but the hybrid pattern emerging makes more sense to me. MCP for discovery and semantics, gRPC for the hot path when you need real streaming. Google Cloud is already shipping pluggable transports in the SDK for exactly this reason.\n\nWhere I'd push back: the June 2026 spec release is targeting stateless-first, but the Transport Working Group has multi-turn SSE as an active SEP. So it's not purely abandoning streaming... it's separating the concerns. Whether that's better or worse depends on your deployment model.",
                  "score": 1,
                  "created_utc": "2026-01-29 18:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qogxy6",
      "title": "MCP Server Security Standard (MSSS)",
      "subreddit": "mcp",
      "url": "https://github.com/mcp-security-standard/mcp-server-security-standard",
      "author": "cr0hn",
      "created_utc": "2026-01-27 15:28:45",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qogxy6/mcp_server_security_standard_msss/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o25i6j2",
          "author": "barefootsanders",
          "text": "Interesting. Ive been exploring security for mcp for a bit. My efforts are way less organized than what you have here üòÖ  what are your goals for the framework? Is thus used out in the wild anywhere?",
          "score": 1,
          "created_utc": "2026-01-28 03:55:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o289dbj",
              "author": "cr0hn",
              "text": "Hey! This proposal defines security controls that security teams can check to enforce MCP security. It‚Äôs meant to be a reference framework teams can lean on",
              "score": 1,
              "created_utc": "2026-01-28 15:29:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28x83s",
          "author": "Ok_Message7136",
          "text": "This is much needed. Having a concrete, testable security baseline for MCP servers makes conversations around trust and production readiness way more actionable.",
          "score": 1,
          "created_utc": "2026-01-28 17:13:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29seip",
              "author": "cr0hn",
              "text": "Sure! And it's essential to have a reference framework for it",
              "score": 1,
              "created_utc": "2026-01-28 19:27:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpjn96",
      "title": "How I program everywhere",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/",
      "author": "Eyoba_19",
      "created_utc": "2026-01-28 18:29:58",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.78,
      "text": "So I've been programming in the metro, when waiting for the doctor, heck even in the bathroom. I mean it's quite the downfall from my dream of sitting in front of multiple large monitors with cmatrix style code, dark hoodies and insane typing speeds with Jarvis handing me my coffee.\n\nBut yeah I think I like this more.\n\nSo wanted to share how I do it, starting with the tools I use:¬†\n\n* Linear for managing my tasks\n* Github for hosting my repo\n* Slack/Telegram for communication (currently in progress, but promising I tell you)\n* LLMs - codex and claude code (expanding to gemini)\n\nHow they come together, imagine this:¬†\n\nUsing Linear on my phone,¬† I write down a task for my project,¬† put it in spec status.\n\nFew minutes later I see a spec, read it, if I'm happy,¬† I set it as ready for dev, few minutes later a PR is ready.\n\nIf there are any failed checks on actions,¬† no worries few minutes later they're all fixed and ready for merge,¬† just needs my approval.¬†\n\nI make a few comments,¬†few minutes again all fixed,¬†I look at it again, if I'm happy, I approve and merge.¬†\n\nAnd how long? 30min, maybe an hour max, what could‚Äôve possibly taken me a day or even a week?\n\nHere‚Äôs the cool thing, I‚Äôm always doing multiple tasks and all in parallel. That was possibly weeks I was saving. Yeah Ik it‚Äôs pretty wild.\n\nSo what's happening under the hood?\n\nWell whenever a Linear task is created a webhook is sent to my server (Linear has their webhook Api specs online so you could easily check the data that‚Äôs sent back). In the payload, I check whether the sent request is an issue/comment, see if it‚Äôs labeled AI (linear allows custom labels) and that the current status is \"Spec\" or \"Ready for dev (custom status), any other status just returns from here.\n\nIf the paylod is an issue and it‚Äôs in Spec, the webhook will use linear‚Äôs graphql api to comment ‚ÄúWriting spec‚Äù and assign itself to the task, fetches latest repo, automatically creates a new worktree, and then launches a docker container with the worktree mounted as a volume, the container has codex/claude in it(you can just use a slim alpine and install codex/claude on it) and passes on the command ‚Äúwork on {issue\\_identifier}‚Äù.¬†\n\nThe LLM has linear‚Äôs mcp configured (you can check my last [post](https://www.reddit.com/r/mcp/comments/1qlhj62/a_few_of_the_mcps_i_use_on_a_daily_basis/) for the MCPs I use) so it can easily fetch the issue contents, see the title and any description in the issue, refer the codebase and write a proper spec directly to linear. I do not kill the container after the spec, mainly to save costs and to reuse context for following tasks.\n\nIf the spec isn‚Äôt ideal, I can comment under the spec/issue with the changes I want. Webhook fires-> payload is parsed-> content of the comment is checked, it must include ‚Äú@ai‚Äù, if so it‚Äôs meant for the ai, since the container is still alive the llm can re-use the context session, saves me a lot of credit, you‚Äôll thank me for it. Now command is passed- ‚ÄúAmend the spec on issue {issue\\_identifier} according to this comment {comment\\_content}‚Äù. The LLM does its thing and posts the new spec.\n\nOnce I‚Äôm satisfied with the spec, I move the issue to ‚ÄúReady for Dev‚Äù, another webhook-> parse the payload-> checks issue statuses and sees it‚Äôs ready for dev, moves it to \"In Progress\", fetches that same container and passes the command- ‚ÄúIssue {issue\\_identifier} is ready for implementation, start working on it, once finished commit and push to origin with a new PR‚Äù.\n\nI‚Äôll continue on another post on how I do the git side of things and communication as well, how I converse with codex/claude about new features and then tell it- ‚Äúyeah sounds good, start working on on it‚Äù and it immediately sets up the linear issue, and does everything on its own, it‚Äôs pretty sick.¬†\n\nBut yeah, happy to get any more ways to improve on it, hope this helps and would love to see you guys set up your own coding Jarvis too ;).",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2d6lpe",
          "author": "Peace_Seeker_1319",
          "text": "this is cool but you're auto-merging AI code with no review? that's asking for runtime bugs that pass CI. we tried similar but had to add checks because AI ships stuff that looks fine but breaks under load. using [codeant.ai](http://codeant.ai/) in our pipeline - catches race conditions, memory issues, generates sequence diagrams so you can actually see what the code does at runtime before merging. even with that we don't auto-merge. someone reviews the diagram + the automated findings, then approves. saves time but doesn't skip the human judgment part. one API change still kills your whole setup though.",
          "score": 1,
          "created_utc": "2026-01-29 06:17:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2d7tej",
              "author": "Eyoba_19",
              "text": "If you read agin I mention I review the code when I said leave some comments, I never auto-merge. But the API part is true, didn‚Äôt think about it. Thanks",
              "score": 1,
              "created_utc": "2026-01-29 06:27:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lnvq2",
                  "author": "Peace_Seeker_1319",
                  "text": "nice setup, the linear webhook -> container workflow is clean we do something similar but yeah the [codeant.ai](http://codeant.ai/) checks before merge are necessary. even with good specs AI can miss edge cases  \ncurious how you handle the container costs though? keeping them alive between tasks vs spinning up fresh each time?",
                  "score": 1,
                  "created_utc": "2026-01-30 13:44:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kemmq",
          "author": "nbegiter",
          "text": "I understand and appreciate the setup but you must already be aware that this is not programming. This is management and handholding.\n\nIt produces results, yes, makes things very easy, yes, but this is not programming.\n\nIf a junior were writing code and showing it to you every now and then, you wouldn‚Äôt say YOU are programming.",
          "score": 1,
          "created_utc": "2026-01-30 07:54:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr8f60",
      "title": "I build an MCP UI app for interactive text rewriting and grammar improvement visualization",
      "subreddit": "mcp",
      "url": "https://i.redd.it/zldlqi0y7igg1.png",
      "author": "arif_szn",
      "created_utc": "2026-01-30 15:24:02",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "showcase",
      "permalink": "https://reddit.com/r/mcp/comments/1qr8f60/i_build_an_mcp_ui_app_for_interactive_text/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2o0bmo",
          "author": "Melodic-Swimmer-4155",
          "text": "This feature is available for developers in Claude? I thought this was only a thing in ChatGPT",
          "score": 1,
          "created_utc": "2026-01-30 20:11:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oxwxl",
          "author": "matt8p",
          "text": "Really cool work! Was able to play around with it on my inspector. Tip for building an MCP app, you can try using the `registerAppTool` and resource tool from the ext-apps SDK!",
          "score": 1,
          "created_utc": "2026-01-30 22:54:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rdimy",
              "author": "arif_szn",
              "text": "Thanks for the tip üôå",
              "score": 1,
              "created_utc": "2026-01-31 08:44:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr1e2y",
      "title": "I built an MCP server to explore Epstein's emails. Here's what I learned about mcp-use",
      "subreddit": "mcp",
      "url": "https://www.reddit.com/r/mcp/comments/1qr1e2y/i_built_an_mcp_server_to_explore_epsteins_emails/",
      "author": "GIOSCOP",
      "created_utc": "2026-01-30 10:01:17",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "When I wanted to test mcp-use (9k+ stars on GitHub), I needed a dataset spicy enough to keep me awake. Enter: 2322 Epstein emails. What followed was an afternoon of hot module reloading, CSP hell, and discovering OpenAI silently requires Plus to use custom apps.\n\n# What I needed\n\n* Basic dependencies (e.g. Node)\n* A `mcp-use` [cloud account](https://mcp-use.com/signup) to host the server (currently free)\n* ChatGPT *Plus* subscription - more on this later\n* Epstein's emails: `https://www.docetl.org/api/epstein-emails`\n\n# Setup\n\nGetting started was trivial. `npx create-mcp-use-app mcp-demo` scaffolds a demo project - I used the `mcp-apps` preset to have both OpenAI Apps SDK integration and a standard MCP server.\n\nThen, a `npm run dev` is enough to see and debug tools (both classic and UI Widgets) thanks to the inspector. This is bundled and starts automatically: a very convenient way to test.\n\n# Development\n\nDeveloping with `mcp-use` is very straightforward. The inspector (paired with HMR, aka \"hot module reload\") makes iterating VERY fast. However, I had a few minor issues with it:\n\n* The setting CSP to \"Declared\" leads to a violation even in the starter template\n* \"Hover: Disabled\" doesn't actually disable hover effects\n* Sometimes, especially when dealing with UI elements, it glitches out - a reload is usually enough\n\nThe library itself abstracts away all of the boilerplate and makes the code concise, for both tools and UI elements. You're writing only the bare minimum: title, description, schema and logic. It feels like what Stripe did for payments, but for tool definitions.\n\nThe best part is that the Model Context Protocol, being very new, hasn't crystallized yet - and you don't have to care. By using a library you're guaranteed to always be compliant and compatible - for example, I imagine Anthropic/Google creating their own variants for UI components.\n\nThe only major issue I had with the library was related to CSP (content security policy): it was not whitelisting the server's domain `fetch` requests. After a few hours of debugging I was ready to open an issue, only to find it already resolved in a development branch by a maintainer (props to Enrico). To quickly patch the issue I hardcoded the CSP `connectDomains` urls and used the PR's canary build: `npm i https://pkg.pr.new/mcp-use/mcp-use@911`. However, I'm sure that by the time you read this it will be already merged.\n\n# Deployment\n\nDeploying using `mcp-use`'s cloud offering is super straightforward: `npm run deploy` takes care of everything. It guides you through login, GitHub repo access, verifies your commits are pushed and finally shows the stream of remote build logs.\n\nIt's also nice that they provide documentation on how to self-host (and even made specific helpers) so vendor lock-in is not an issue. However, I'd still choose their version as it's tailor-made and shows interesting mcp-specific metrics (e.g. client breakdown).\n\nGiven the CSP issue I needed a \"double deploy\" to hardcode the production URL in the widgets code; build environment variables are available but they didn't work consistently for me.\n\n# Testing on ChatGPT\n\nWhen it came time to test, I happily headed to ChatGPT to add my server. It should be easy: Account -> Settings -> Apps -> Advanced Settings -> Enable Dev Mode -> Apps -> Create App.\n\n*However*, after adding the URL and everything, the app wasn't there. After way too much time I found out that the Free Plan doesn't allow you to add custom apps \\[[1](https://community.openai.com/t/chatgpt-apps-sdk-not-creating-a-custom-app-on-my-account/1369338/7), [2](https://help.openai.com/en/articles/11487775-apps-in-chatgpt)\\] (no warnings whatsoever). This might change in the future so before upgrading take a look.\n\n>Disclaimer: This is not the library's fault, but rather a rant against OpenAI\n\nSo, I had to buy the Plus version (luckily by signing up with a custom domain email I got a month free). While developing, make sure to hit \"refresh\" in the app's section if you make any changes.\n\n# TL;DR\n\n`mcp-use` = Rails for MCP. You write actual logic, boilerplate is handled. Few bugs, nothing blocking. *Use* it.\n\n**Try it yourself:** [https://lively-poetry-gt8c1.mcp-use.run/mcp](https://lively-poetry-gt8c1.mcp-use.run/mcp)\n",
      "is_original_content": false,
      "link_flair_text": "server",
      "permalink": "https://reddit.com/r/mcp/comments/1qr1e2y/i_built_an_mcp_server_to_explore_epsteins_emails/",
      "domain": "self.mcp",
      "is_self": true,
      "comments": [
        {
          "id": "o2pmgrf",
          "author": "SS2907",
          "text": "You sir/maam have won the internet today.",
          "score": 1,
          "created_utc": "2026-01-31 01:09:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r26lk",
              "author": "GIOSCOP",
              "text": "‚ù§Ô∏è",
              "score": 2,
              "created_utc": "2026-01-31 06:59:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}