{
  "metadata": {
    "last_updated": "2026-02-03 02:59:56",
    "time_filter": "week",
    "subreddit": "learnmachinelearning",
    "total_items": 20,
    "total_comments": 164,
    "file_size_bytes": 157512
  },
  "items": [
    {
      "id": "1qpnlml",
      "title": "ML research papers to Code",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/dp397ckwk5gg1",
      "author": "Big-Stick4446",
      "created_utc": "2026-01-28 20:51:33",
      "score": 258,
      "num_comments": 27,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qpnlml/ml_research_papers_to_code/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2gact8",
          "author": "dutchpsychologist",
          "text": "Tried it a bit and I love it! Has amazing potential. Love the visualization. It's brilliant.org meets leetcode for machine learning. Very nice.",
          "score": 10,
          "created_utc": "2026-01-29 18:03:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ggmwd",
              "author": "Big-Stick4446",
              "text": "thankyou! any particular feedback?",
              "score": 3,
              "created_utc": "2026-01-29 18:31:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gjm3l",
                  "author": "dutchpsychologist",
                  "text": "Personally, I think the theory parts could be more chunked into smaller steps. That would make it even more attractive to me and makes it easier to keep focused on the information given.",
                  "score": 3,
                  "created_utc": "2026-01-29 18:45:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2adoel",
          "author": "Big-Stick4446",
          "text": "[Tensortonic](https://tensortonic.com)\n\nhere's the link",
          "score": 7,
          "created_utc": "2026-01-28 21:02:16",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2d1ilh",
          "author": "Inevitable-Opening61",
          "text": "About to start my ML job and this is perfect for getting a refresher and preparing for the job. Thank you!",
          "score": 7,
          "created_utc": "2026-01-29 05:38:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ffdtq",
          "author": "Longjumping-Bag-7976",
          "text": "Love this idea, i'm gonna use this",
          "score": 3,
          "created_utc": "2026-01-29 15:45:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fiizq",
          "author": "TheSpaceCaptain1106",
          "text": "Such a cool idea!",
          "score": 3,
          "created_utc": "2026-01-29 15:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2cx8p0",
          "author": "dommycaste",
          "text": "I looked all over if there is a paid tier. Is this actually completely free?\n\nAlso I noticed that the math part has problems + lessons to learn the math. The research part has problems only, but no lessons. I assume you're working on that?",
          "score": 2,
          "created_utc": "2026-01-29 05:08:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dcgwp",
              "author": "Big-Stick4446",
              "text": "currently free. yes, more content is coming.",
              "score": 7,
              "created_utc": "2026-01-29 07:06:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2j6d4i",
                  "author": "ash4reddit",
                  "text": "What‚Äôs your bus model?",
                  "score": 1,
                  "created_utc": "2026-01-30 02:46:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2eia4s",
          "author": "One_Citron_4350",
          "text": "Looks pretty interesting. Congrats!",
          "score": 2,
          "created_utc": "2026-01-29 12:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f1tdt",
          "author": "Ndirangu7",
          "text": "Amazing stuff!",
          "score": 2,
          "created_utc": "2026-01-29 14:41:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2j4886",
          "author": "here4CHAOS-cn8",
          "text": "I've been using it for like 5-6 days, even recommended it to friends and they're loving it too. You're doing good work, keep it up",
          "score": 2,
          "created_utc": "2026-01-30 02:35:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jfchg",
              "author": "Big-Stick4446",
              "text": "thankyou! any particular feedback?",
              "score": 1,
              "created_utc": "2026-01-30 03:37:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jz5jx",
          "author": "Human-Computer4161",
          "text": "Crazyyyyy",
          "score": 2,
          "created_utc": "2026-01-30 05:47:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36zugp",
          "author": "NNNiharri-229",
          "text": "this is so cool. definitely gonna use it",
          "score": 2,
          "created_utc": "2026-02-02 17:57:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kap4y",
          "author": "-_-johnwick-_-",
          "text": "Sickkk!!!! Thanks for sharing.",
          "score": 1,
          "created_utc": "2026-01-30 07:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lgjaa",
          "author": "Any_Mobile2714",
          "text": "Is there a way to upload problems yourself?",
          "score": 1,
          "created_utc": "2026-01-30 13:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mt28d",
          "author": "ArtAccomplished6466",
          "text": "This is a awesome platform, and I am loving this so far, my only problem is this could get locked behind a subscription model !\n\nMay be OP, if you want any help with your platform, please let me know, I can contribute to the platform (building and problems).",
          "score": 1,
          "created_utc": "2026-01-30 16:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q27fx",
          "author": "bezdazen",
          "text": "This is fantastic stuff and thanks for sharing and making it free!\n\nDo you mind if I give you a few suggestions? There are some things that give a 'rough around the edges\" feel. \n\nWhen you enter a problem, there is a left and right panel. Right has the code, and left has some interactive widgets mixed into markdown (mdx?). The markdown is not very well styled. The sizes of the fonts in the widgets and even in equations is noticeably larger than in the rendered markdown text. I would suggest making the font size larger for the explanatory text (markdown text). Indentation is lacking. \n\nJust off the bat, here is some things I would do:\n\n- Increase font size a tiny bit for the content (not the widget)\n\n- Change the `p-4` in `p-4 overflow-auto text-sm leading-6 text-zinc-200 flex-1` to `p-8`. Or better yet, set `max-w` on the content to be better suited to the font size. <- The latter would be better for wide and less wide screens (than changing padding).  \n\n- Change the padding of the panel header (tabs) to match: `px-4` -> `px-8` or set max-w to be the same as the header \n\n- Make the `:r1u:` data panel have scrollbars that are styled the same as the scrollbar for the code editor in the right panel.  \n\n- Increase margins for markdown block elements (lists, quote, etc).  \n\n- Increase left & right padding for code blocks (`<pre>` elements)\n\nWidgets look great!\n\nAs far as content goes, my only suggestion is to start users off in a intro/starting page when they go to the ML Research and ML Math page. It could give you the opportunity to give some general background, at timeline of these papers, a suggested/recommended path for the users to follow, etc.\n\nLastly, I dont know if its just on my end, but I am getting a bunch of errors in the console. App still seems to work though!\n\nThis is an amazing effort! And a killer resource.",
          "score": 1,
          "created_utc": "2026-01-31 02:42:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2cnk4c",
          "author": "CriticalTemperature1",
          "text": "Love this idea! I wonder what stops someone from just copying code from somewhere else here?",
          "score": 1,
          "created_utc": "2026-01-29 04:04:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lcshw",
              "author": "Turbulent-Log5758",
              "text": "The question is, why would someone paste code here?",
              "score": 1,
              "created_utc": "2026-01-30 12:40:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ad3au",
          "author": "GamingWithShaurya_YT",
          "text": "crazy! will check it out",
          "score": 1,
          "created_utc": "2026-01-28 20:59:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qt5tju",
      "title": "Upskilling in your 30s hits different",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qt5tju/upskilling_in_your_30s_hits_different/",
      "author": "ReflectionSad3029",
      "created_utc": "2026-02-01 18:09:22",
      "score": 161,
      "num_comments": 26,
      "upvote_ratio": 0.95,
      "text": "Learning new skills in your 30s while working full-time is tough.\n\n I recently attended a weekend AI workshop and realized how behind I actually was. \nSlightly uncomfortable, but also motivating. Made me stop procrastinating on learning new tools. \n\nit really helped me to get comfortable with something  i was worried about\n\nJust a reminder: feeling uncomfortable means you‚Äôre growing.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qt5tju/upskilling_in_your_30s_hits_different/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o30kgqi",
          "author": "Winners-magic",
          "text": "You gotta borrow time from your 9-5",
          "score": 116,
          "created_utc": "2026-02-01 18:38:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fxdv",
              "author": "Only-Ad2239",
              "text": "My previous job did the opposite - borrowed time from my 5 PM to 9 AM.",
              "score": 11,
              "created_utc": "2026-02-02 08:20:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o37g81i",
              "author": "SizePunch",
              "text": "This 100%",
              "score": 2,
              "created_utc": "2026-02-02 19:11:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ggop",
          "author": "EntrepreneurHuge5008",
          "text": ">Learning new skills in your 30s while working full-time is tough.\n\n100% agreed",
          "score": 37,
          "created_utc": "2026-02-01 18:20:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31g2i8",
              "author": "opparasite",
              "text": "Totally agree, I only have like a couple of hours to study a bit, and trying to stay focused is challenging.",
              "score": 8,
              "created_utc": "2026-02-01 21:08:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30wh5a",
          "author": "SeaZealousideal5651",
          "text": "I did a lot of that in my 30s both borrowing time from my 9-5 and sacrificing sleep. Sleep is not the healthy way of doing it but after about a year and change of that, I was able to change job, and I couldn‚Äôt be any happier.\n\nIf there‚Äôs a will there‚Äôs a way‚Ä¶you got this!",
          "score": 29,
          "created_utc": "2026-02-01 19:33:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30loxb",
          "author": "Signal_Ad657",
          "text": "I literally quit my full time job to just learn about computers and AI all day and there‚Äôs not enough hours in the day to stay on top of all of it even now.  There‚Äôs so many sub topics, tools, platforms, potential skills to develop and you could disappear into any of them very easily and while doing that you are missing countless other things.  If you are trying at all you are in a good club.",
          "score": 21,
          "created_utc": "2026-02-01 18:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o310pip",
              "author": "bingbpbmbmbmbpbam",
              "text": "Literally. If you‚Äôre serious you‚Äôd cut out distractions anyways, and if not, there‚Äôs definitely a guy who will quit his job and move across the country to make it happen, so maybe ask yourself if it‚Äôs the kind of life you actually want, or you just think it would be nice.",
              "score": 1,
              "created_utc": "2026-02-01 19:53:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o32bku4",
                  "author": "Signal_Ad657",
                  "text": "Yeah you just have to accept you can‚Äôt know everything, and try your best to know what matters and be hyper productive and that‚Äôs what full time AI work looks like in my experience.",
                  "score": 8,
                  "created_utc": "2026-02-01 23:50:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o30t28z",
          "author": "Extra_Intro_Version",
          "text": "Late 50s, early 60s here when I started. Honestly, it sucked.",
          "score": 24,
          "created_utc": "2026-02-01 19:17:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30vmvs",
          "author": "Expensive_Fun4346",
          "text": "even after learning all this material, i struggle to keep up.  AI is moving so fast and the tools/pipelines are so different from 2 years ago.  it's a struggle to keep up.",
          "score": 6,
          "created_utc": "2026-02-01 19:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30kgx4",
          "author": "hc_fella",
          "text": "I've combined my master thesis with my first year of work... It will be a while before I commit my hours after work to even more work...",
          "score": 7,
          "created_utc": "2026-02-01 18:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30w714",
          "author": "valkon_gr",
          "text": "Any interesting tools that you saw there?",
          "score": 6,
          "created_utc": "2026-02-01 19:32:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31ix4a",
          "author": "Top_Limit_",
          "text": "Agreed. Going thru this now.\n\nHard to keep motivated knowing that im very far from even being able to use it professionally.",
          "score": 1,
          "created_utc": "2026-02-01 21:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32irug",
          "author": "pixiebutcurly",
          "text": "Hard relate. ...especially building some solutions on your own",
          "score": 1,
          "created_utc": "2026-02-02 00:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3419lg",
          "author": "SilverSpearhead",
          "text": "I always tell myself to catch up with latest technology and learn from younger generation",
          "score": 1,
          "created_utc": "2026-02-02 06:09:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o341vax",
          "author": "AccordingWeight6019",
          "text": "that discomfort is pretty normal, especially once you already have some experience to compare against. learning later tends to surface gaps more clearly, but it also comes with better judgment about what actually matters. I‚Äôve found progress feels slower because time is constrained, not because the learning itself is harder. the upside is that you can usually connect new tools to real problems much faster. that tends to make what sticks more durable, even if the ramp feels rough at first.",
          "score": 1,
          "created_utc": "2026-02-02 06:14:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35fcnr",
          "author": "no_spoon",
          "text": "What do they teach at an ‚ÄúAI workshop‚Äù that you can‚Äôt already learn by asking ChatGPT yourself?",
          "score": 1,
          "created_utc": "2026-02-02 13:19:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o383j06",
          "author": "Stargazer1884",
          "text": "Hah wait till you're 50 with kids.",
          "score": 1,
          "created_utc": "2026-02-02 21:01:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39fk50",
          "author": "Gintoki100702",
          "text": "Best thing one can do is to upskill \nKeep working",
          "score": 1,
          "created_utc": "2026-02-03 01:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31rkm8",
          "author": "ab624",
          "text": "any insights from the workshop",
          "score": 0,
          "created_utc": "2026-02-01 22:04:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31s7fa",
          "author": "EffectiveOk4641",
          "text": "Its quite an eye opener, the field is moving so fast. In ML myself, upskilling on AI. Actually building a coach to help create personal roadmaps that fit in my daily schedule, so i make progress even though i have a busy week. You can check it out[ here](https://skillmapperai.com/landing/?utm_source=reddit&utm_medium=reddit&utm_campaign=dataanalysiscareers) if it sounds interesting, appreciate any feedback!",
          "score": -2,
          "created_utc": "2026-02-01 22:07:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o310gr8",
          "author": "bingbpbmbmbmbpbam",
          "text": "Don‚Äôt work a full time job. Ask yourself what you want more, comfort now or leverage later?",
          "score": -6,
          "created_utc": "2026-02-01 19:52:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35byyn",
              "author": "kaystar101",
              "text": "Horrible advice",
              "score": 1,
              "created_utc": "2026-02-02 12:57:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qot7q5",
      "title": "[Project] Reached 96.0% accuracy on CIFAR-10 from scratch using a custom ResNet-9 (No pre-training)",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/qwfza5wcxyfg1.png",
      "author": "Distinct-Figure2957",
      "created_utc": "2026-01-27 22:42:10",
      "score": 127,
      "num_comments": 37,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qot7q5/project_reached_960_accuracy_on_cifar10_from/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o28etvn",
          "author": "auto_mata",
          "text": "you didn‚Äôt have a proper train/val/test split and you wrote the post with an llm‚Ä¶ I get being excited about ml but this is not a good post for a learning machine learning subreddit. Lacks the most basic rigor",
          "score": 60,
          "created_utc": "2026-01-28 15:53:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dw6nu",
              "author": "Distinct-Figure2957",
              "text": "I'm not fully fluent in english so I used LLM to reformulate and be sure it's clear and understandable. I can assure you the ideas are mine.   \n  \nI have a very clearly separated train/test split, my model is only trained on training data. I didn't use a validation set beacause I didn't know I was gonna use advanced TTA when I trained my model, and my grid search was only to calibrate just 3 hyperparameters.\n\nThis is my first ML project I was happy to share, please be carefull before raging on a project you don't even know.",
              "score": -2,
              "created_utc": "2026-01-29 10:07:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ndpnk",
                  "author": "auto_mata",
                  "text": "I understand being excited! I really do! I would suggest starting from very basic fundamentals and working up from there. There are some very clear violations of rigor here, but that‚Äôs not a bad thing it‚Äôs a learning experience. \n\nWork on very very basic things, like linear regression, logistic regression, perceptions, basic FFNN, THEN start moving to advanced projects and topics. Try not to use LLMs while you are first learning ‚Äî ml is a topic which builds on itself over and over, and if you let stuff slip by while you‚Äôre learning you‚Äôll be much worse off later on. \n\nbest of luck and keep experimenting man",
                  "score": 1,
                  "created_utc": "2026-01-30 18:29:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o24dof0",
          "author": "Rize92",
          "text": "As you‚Äôre using the test set to inform training process, I would recommend you further split the test into test and holdout. Leave the holdout set out of the training inference entirely and score your final model against that. That will help you demonstrate if your final trained model is truly performing at this level or not. Even though your test set is spit out it‚Äôs still being used for some training guidance and so it not totally separate from training.",
          "score": 56,
          "created_utc": "2026-01-28 00:19:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2if7x8",
              "author": "Extra_Intro_Version",
              "text": "Isn‚Äôt this deep learning 101? Don‚Äôt test on data used for training or validation?",
              "score": 1,
              "created_utc": "2026-01-30 00:17:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2m66ev",
                  "author": "Rize92",
                  "text": "Yes, in fact it is data science/machine learning/statistical learning 101. But not everybody is at the same level of understanding, and the proliferation of coding agents has made it really easy to build models, without an understanding of these concepts. So we should encourage people who are asking for feedback to apply these concepts and improve their understanding.",
                  "score": 1,
                  "created_utc": "2026-01-30 15:15:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o275zin",
              "author": "Moist-Matter5777",
              "text": "Solid point! A holdout set would definitely give a clearer picture of generalization. I‚Äôll keep that in mind for my next experiments. Thanks for the suggestion!",
              "score": -10,
              "created_utc": "2026-01-28 11:51:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o299bko",
                  "author": "GazelleFeisty7749",
                  "text": "im crying bro who are you üò≠üò≠üò≠",
                  "score": 21,
                  "created_utc": "2026-01-28 18:05:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ih459",
                  "author": "Extra_Intro_Version",
                  "text": "Having test data separate from train / val data is a must do. Not a ‚Äúsuggestion‚Äù. If you aren‚Äôt doing this, everything else you claim to have done is pretty meaningless. \n\nBurying what you did in vague yet sycophantic LLM verbiage isn‚Äôt helping your case, at all. The whole thing comes across as either grossly disingenuous or quackery.",
                  "score": 0,
                  "created_utc": "2026-01-30 00:27:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o285iqe",
          "author": "TourGreat8958",
          "text": "Wait so you didnt use a data split? Was the model evaluated on previously seen data?",
          "score": 15,
          "created_utc": "2026-01-28 15:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dxl6a",
              "author": "Distinct-Figure2957",
              "text": "No not at all. I just used train/test split instead of train/validation/test split which is a bit mor rigourous since I used grid search to calibrate 3 hyperparameters. But my model is only trained using train data.",
              "score": -3,
              "created_utc": "2026-01-29 10:19:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2frdm9",
                  "author": "SongsAboutFracking",
                  "text": "Just to be clear, did you use a hold out set using cross validation to do hyperparameter tuning, or did you use the test dataset to validate each combination of hyperparameters?",
                  "score": 1,
                  "created_utc": "2026-01-29 16:38:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o243r7p",
          "author": "trelco",
          "text": "Can you reproduce this with a setup of train/val/test dataset splits?",
          "score": 30,
          "created_utc": "2026-01-27 23:28:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26jpm2",
              "author": "Distinct-Figure2957",
              "text": "Maybe one day but as said before I belive the difference is negligeable and it's like 10h of training in kaggle, so I prefer keep my GPU quota in other projects.   \n  \nSince the code is open-source, I‚Äôd be interested to see the results if you (or anyone else) decide to fork the repo and run that specific split validation",
              "score": -47,
              "created_utc": "2026-01-28 08:36:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o28lzb0",
                  "author": "trelco",
                  "text": "I more strongly believe that you underly the multiple testing problem.",
                  "score": 17,
                  "created_utc": "2026-01-28 16:24:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2faq9l",
                  "author": "leon_bass",
                  "text": "Telling a whole machine learning subreddit that the difference is negligible is criminal.\n\nYou are using your test split as a validation split to inform your training, therefore you don't know what performance you will get on unseen data",
                  "score": 2,
                  "created_utc": "2026-01-29 15:24:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2b49io",
          "author": "External_Manager6737",
          "text": "\"Lightweight\" training a 6M parameter model on a 60K sample dataset üòÇüòÇüòÇ do you even know what overfitting is?",
          "score": 6,
          "created_utc": "2026-01-28 23:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e4fv5",
              "author": "Distinct-Figure2957",
              "text": "Compare to the very best performing models, it's still \"pretty low\". Aggressive cutout and data augmentation are used to prevent/reduce overfitting.",
              "score": 0,
              "created_utc": "2026-01-29 11:18:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2f8z22",
                  "author": "External_Manager6737",
                  "text": "No it is not, you can get over 90% accuracy with less than 100K parameters on cifar10. What do you think your remaining 5.9M parameters are doing to achieve an extra 5%? üòÇ",
                  "score": 1,
                  "created_utc": "2026-01-29 15:16:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o29dv5d",
          "author": "Ok-Outcome2266",
          "text": "honest take here, CNN (and NN in general) take max advantage of transfer learning. \n\nit makes no sense to train from scratch (unless for academic purposes)",
          "score": 5,
          "created_utc": "2026-01-28 18:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2bz9cf",
          "author": "guachimingos",
          "text": "use test, validation an train sets.",
          "score": 4,
          "created_utc": "2026-01-29 01:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o245apo",
          "author": "Sabaj420",
          "text": "confusion matrices that look like this make me very happy for some reason",
          "score": 10,
          "created_utc": "2026-01-27 23:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28p0w9",
              "author": "Entire_Ad_6447",
              "text": "Really they fill.me with dread cause I know something has gone wrong.",
              "score": 18,
              "created_utc": "2026-01-28 16:37:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o24sglq",
              "author": "HasFiveVowels",
              "text": "Yea, they really clear things up",
              "score": 6,
              "created_utc": "2026-01-28 01:36:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o296wgx",
          "author": "galvinw",
          "text": "How's it compared to [https://github.com/matthias-wright/cifar10-resnet](https://github.com/matthias-wright/cifar10-resnet)",
          "score": 3,
          "created_utc": "2026-01-28 17:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dzjas",
              "author": "Distinct-Figure2957",
              "text": "My model is a bit larger and is trained for a lot longer with various optimisations, so I hit 96%, which is better than his 92%. But 92% is yet pretty good for this size",
              "score": 1,
              "created_utc": "2026-01-29 10:36:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ccvut",
          "author": "Jaded_Individual_630",
          "text": "More GPT slop for the slop pile. Is this what \"computer science students\" have become?",
          "score": 5,
          "created_utc": "2026-01-29 03:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2d7iol",
          "author": "hyxon4",
          "text": "Slop. Everything.",
          "score": 2,
          "created_utc": "2026-01-29 06:25:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2d4ev4",
          "author": "Eager_Crow",
          "text": "What is the test R2 ?",
          "score": 1,
          "created_utc": "2026-01-29 06:00:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2du3vn",
          "author": "Distinct-Figure2957",
          "text": "TO BE CLEAR FOR EVERYONE:  \nThe model is train using ONLY train data. \n\nThe grid search is just testing a few combinations to find **3** hyperparameters faster. The model already reached¬†**95.80%**¬†with suboptimal standard TTA.",
          "score": 1,
          "created_utc": "2026-01-29 09:48:19",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2lodol",
          "author": "user221272",
          "text": "\"Training on Test set is All You Need\"",
          "score": 1,
          "created_utc": "2026-01-30 13:47:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2og7oa",
          "author": "Rize92",
          "text": "The issue people are having with your responses, is that you are not taking any of their constructive criticism seriously - even though you asked for advice. \n\nI don‚Äôt care if you do it, or don‚Äôt do it. I don‚Äôt care if you realized you made a mistake beforehand or not. I have no reason to care about it. I offered you very generic advice on how to convince people your model generalizes on unseen data. That‚Äôs as far as it goes. You can interpret what you have in whatever way you want. You won‚Äôt convince anybody it works if you aren‚Äôt willing to do it. You also don‚Äôt have to do it, we don‚Äôt care. But you‚Äôre coming across as disingenuous because you asked for feedback and then rejected all of it. You‚Äôre not going to get very far in a career in data science if you can‚Äôt take criticism. We all make mistakes and we all don‚Äôt do things the best way first time. That‚Äôs life.",
          "score": 1,
          "created_utc": "2026-01-30 21:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oruao",
              "author": "Distinct-Figure2957",
              "text": "Sorry if I was a bit aggressive, you're right indeed my goal should be to learn, not to show off what I can do. I was just disappointed because I expected whether positive feedback or people showing things I missed and helping improve even more my model and my knowledge. But instead I felt like people were just throwing away all I did like if it had no value to focus on a small thing I already know was minor and just badly explained in my post. I should probably take a step back from all of this and focus on improving my skills. And for sure next time I won't forget the validation set !",
              "score": 1,
              "created_utc": "2026-01-30 22:23:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr1bpk",
      "title": "Python Crash Course Notebook for Data Engineering",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "author": "analyticsvector-yt",
      "created_utc": "2026-01-30 09:57:41",
      "score": 118,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "Hey everyone! Sometime back, I put together a¬†**crash course on Python**¬†specifically tailored for Data Engineers. I hope you find it useful! I have been a data engineer for¬†**5+ years**¬†and went through various blogs, courses to make sure I cover the essentials along with my own experience.\n\nFeedback and suggestions are always welcome!\n\nüìî¬†**Full Notebook:**¬†[Google Colab](https://colab.research.google.com/drive/1r_MmG8vxxboXQCCoXbk2nxEG9mwCjnNy?usp=sharing)\n\nüé•¬†**Walkthrough Video**¬†(1 hour):¬†[YouTube](https://youtu.be/IJm--UbuSaM)¬†\\- Already has almost¬†**20k views & 99%+ positive ratings**\n\nüí° Topics Covered:\n\n**1. Python Basics**¬†\\- Syntax, variables, loops, and conditionals.\n\n**2. Working with Collections**¬†\\- Lists, dictionaries, tuples, and sets.\n\n**3. File Handling**¬†\\- Reading/writing CSV, JSON, Excel, and Parquet files.\n\n**4. Data Processing**¬†\\- Cleaning, aggregating, and analyzing data with pandas and NumPy.\n\n**5. Numerical Computing**¬†\\- Advanced operations with NumPy for efficient computation.\n\n**6. Date and Time Manipulations**\\- Parsing, formatting, and managing date time data.\n\n**7. APIs and External Data Connections**¬†\\- Fetching data securely and integrating APIs into pipelines.\n\n**8. Object-Oriented Programming (OOP)**¬†\\- Designing modular and reusable code.\n\n**9. Building ETL Pipelines**¬†\\- End-to-end workflows for extracting, transforming, and loading data.\n\n**10. Data Quality and Testing**¬†\\- Using¬†\\`unittest\\`,¬†\\`great\\_expectations\\`, and¬†\\`flake8\\`¬†to ensure clean and robust code.\n\n**11. Creating and Deploying Python Packages**¬†\\- Structuring, building, and distributing Python packages for reusability.\n\n**Note:**¬†I have not considered PySpark in this notebook, I think PySpark in itself deserves a separate notebook!",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2rs7wl",
          "author": "PixelLight",
          "text": "Everything looks really good. I think my main question is why you chose os over pathlib? To my understanding thats a more modern approach",
          "score": 3,
          "created_utc": "2026-01-31 11:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sqzo7",
              "author": "analyticsvector-yt",
              "text": "Agree this was 1.5 years back I will do a updated version soon",
              "score": 2,
              "created_utc": "2026-01-31 15:01:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l0sxn",
          "author": "Ok-Blacksmith6403",
          "text": "Thank you üëç",
          "score": 6,
          "created_utc": "2026-01-30 11:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nfay8",
              "author": "analyticsvector-yt",
              "text": "Glad you found it helpful!",
              "score": 1,
              "created_utc": "2026-01-30 18:36:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pvbi9",
          "author": "bhariLund",
          "text": "Saving this",
          "score": 2,
          "created_utc": "2026-01-31 02:01:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ntwgj",
          "author": "diegoasecas",
          "text": "CUT THE CABLE",
          "score": 1,
          "created_utc": "2026-01-30 19:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ogh4p",
              "author": "Sufficient-Main-4101",
              "text": "LOL",
              "score": 2,
              "created_utc": "2026-01-30 21:28:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2s1i77",
          "author": "Always_Learning_000",
          "text": "Thank you for sharing this!!",
          "score": 1,
          "created_utc": "2026-01-31 12:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sbycb",
          "author": "KGagan1",
          "text": "Thank you",
          "score": 1,
          "created_utc": "2026-01-31 13:35:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m7a50",
          "author": "vanisle_kahuna",
          "text": "Cheers ü•Ç",
          "score": 1,
          "created_utc": "2026-01-30 15:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nf94y",
              "author": "analyticsvector-yt",
              "text": "ü§ù",
              "score": 0,
              "created_utc": "2026-01-30 18:36:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qu0vgq",
      "title": "Finally getting interviews!!",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/yfp7ce1h54hg1.jpeg",
      "author": "Full_Meat_57",
      "created_utc": "2026-02-02 17:07:16",
      "score": 99,
      "num_comments": 16,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qu0vgq/finally_getting_interviews/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o38oxth",
          "author": "Cheek_Powerful",
          "text": "If all your languages are <C1, then what is your native tongue?",
          "score": 6,
          "created_utc": "2026-02-02 22:44:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38jwxq",
          "author": "Full_Meat_57",
          "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
          "score": 2,
          "created_utc": "2026-02-02 22:19:33",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o39igur",
          "author": "Status-Supermarket98",
          "text": "Is C1 German is needed for applying in Germany?",
          "score": 1,
          "created_utc": "2026-02-03 01:26:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39nc6r",
          "author": "Comfortable-Bath-905",
          "text": "Fantastic!",
          "score": 1,
          "created_utc": "2026-02-03 01:54:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o373fuu",
          "author": "migrated-human",
          "text": "Do you make it in Canva or latex? \nI'm only getting rejected even though I've tried doing ats checks and everything",
          "score": 1,
          "created_utc": "2026-02-02 18:13:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37libd",
              "author": "Full_Meat_57",
              "text": "Simple ms word",
              "score": 2,
              "created_utc": "2026-02-02 19:36:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jtuo",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 0,
              "created_utc": "2026-02-02 22:19:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o37y1zz",
              "author": "SithEmperorX",
              "text": "Suffering from the same. Made it all in LaTeX still no reaction.",
              "score": -2,
              "created_utc": "2026-02-02 20:35:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38c0rc",
          "author": "ufl_exchange",
          "text": "Are you applying for jobs in the US or Germany?",
          "score": 1,
          "created_utc": "2026-02-02 21:41:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j583",
              "author": "Full_Meat_57",
              "text": "Germany only",
              "score": 4,
              "created_utc": "2026-02-02 22:15:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o38gjw3",
          "author": "EcstaticBank",
          "text": "Could you post the old cv as well to see what really worked and what didn't",
          "score": 1,
          "created_utc": "2026-02-02 22:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38jayj",
              "author": "Full_Meat_57",
              "text": "Check the last post of mine",
              "score": 2,
              "created_utc": "2026-02-02 22:16:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jvur",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o37ubx4",
          "author": "MMechree",
          "text": "Could you share a template, please?",
          "score": -1,
          "created_utc": "2026-02-02 20:17:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j87r",
              "author": "Full_Meat_57",
              "text": "It‚Äôs simple ms word, I made everything from scratch",
              "score": 2,
              "created_utc": "2026-02-02 22:16:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jurg",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqk5rl",
      "title": "Just finished a high-resolution DFM face model (448px), of the actress elizabeth olsen",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/jo2e45h2mcgg1",
      "author": "Emergency_Pause1678",
      "created_utc": "2026-01-29 20:32:08",
      "score": 96,
      "num_comments": 27,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqk5rl/just_finished_a_highresolution_dfm_face_model/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2j4v23",
          "author": "BigDaddyPrime",
          "text": "The original and swapped kinda looks the same.",
          "score": 103,
          "created_utc": "2026-01-30 02:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l0hxx",
          "author": "ShelZuuz",
          "text": "Does this only work for identical twins?",
          "score": 44,
          "created_utc": "2026-01-30 11:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l2m7z",
              "author": "Emergency_Pause1678",
              "text": "works for al types of faces",
              "score": -4,
              "created_utc": "2026-01-30 11:27:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30m7qg",
                  "author": "jakeStacktrace",
                  "text": "Just like mirrors.",
                  "score": 1,
                  "created_utc": "2026-02-01 18:46:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2m8yiv",
          "author": "peenismane",
          "text": "I honestly don't understand what the purpose of this when left and right just look like the same video",
          "score": 13,
          "created_utc": "2026-01-30 15:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p3opb",
              "author": "peenismane",
              "text": "Like does this generate a model that allows the face input to be anybody's face and they can then \"look like them\" deep fake?",
              "score": 2,
              "created_utc": "2026-01-30 23:25:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kdvi6",
          "author": "genserismyname",
          "text": "who does this serve purpose? genuinely asking.",
          "score": 15,
          "created_utc": "2026-01-30 07:47:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nem2f",
              "author": "SuperMegaOwl2",
              "text": "Well Besides the obvious... It could be used to recast movies or keep the likeness of said actors around even after They're gone, but that's my thought",
              "score": 7,
              "created_utc": "2026-01-30 18:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2orbne",
                  "author": "Affectionate-Let3744",
                  "text": "Both horrible horrible ideas\n\nGood luck to any future actors when companies can just rent a variety of old A/B/C listers for cheap and with absolutely no scheduling or on-set issues. They'll just keep using the faces that sell already",
                  "score": 4,
                  "created_utc": "2026-01-30 22:20:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qu0rb",
                  "author": "genserismyname",
                  "text": "I dont see the \"obvious\" purpose your preaching about. It's not useful. Recast movies? Are you forreal now. And keeping the likeness of someone who's dead around you just because what? You can't live without elizabeth olsen? It's trash, doesn't server purpose, plus DID YOU ASK ELIZBETH OLSEN WOULD SHE WANT THAT? no. so then shut the hell up, this is stupid idea that's gonna get abused for money or something worse, and that's all it's gonna be.",
                  "score": 1,
                  "created_utc": "2026-01-31 05:50:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2k2859",
          "author": "CollectionGuilty1320",
          "text": "Porn industry üìà",
          "score": 24,
          "created_utc": "2026-01-30 06:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m23w9",
          "author": "johnfkngzoidberg",
          "text": "This looks terrible.",
          "score": 7,
          "created_utc": "2026-01-30 14:56:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2leg7e",
          "author": "thatpizzatho",
          "text": "Hi, I'm working in AI research since 2016 because I think that there are some super cool and important applications of AI (protein discovery, healthcare, some *but not all* applications in the creativity industry, potentially robotics and self-driving, etc). Some other applications are less exciting because they have the potential to be misused. Tbf anything has the potential to be misused, but some more than others. Deep fakes is one of those things. This is not to say that the technology behind it (the maths and the engineering) is not exciting. It is! But the actual implementation of those cool ideas is potentially harmful, so when learning it's important to keep that in mind",
          "score": 16,
          "created_utc": "2026-01-30 12:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r5frl",
              "author": "redditownersdad",
              "text": "Ethics you mean",
              "score": 0,
              "created_utc": "2026-01-31 07:28:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k0cs2",
          "author": "recursion_is_love",
          "text": "Can I request Arnold Schwarzenegger ?",
          "score": 1,
          "created_utc": "2026-01-30 05:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kumym",
              "author": "Emergency_Pause1678",
              "text": "sure",
              "score": 1,
              "created_utc": "2026-01-30 10:19:23",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2ocfdy",
              "author": "Pickymarker",
              "text": "No need don't reccomend requests from him he just is starting when others like me have been making dfms for a while there is already like 5 Arnold models already",
              "score": -1,
              "created_utc": "2026-01-30 21:09:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l1qrb",
          "author": "DeepInEvil",
          "text": "Do you have a link to the model?",
          "score": 1,
          "created_utc": "2026-01-30 11:20:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oci2y",
              "author": "Pickymarker",
              "text": "I do might make it public on my discord server soon",
              "score": 0,
              "created_utc": "2026-01-30 21:09:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pdrn3",
          "author": "CorpusculantCortex",
          "text": "After I read that it was supposed to be Elizabeth Olsen I kinda thought I saw the woman looked vaguely like her for a fraction of a second. But when I kept watching i honestly had a hard time noticing any differences in the side by side. Im no expert but I think this still needs work.",
          "score": 1,
          "created_utc": "2026-01-31 00:20:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r5afi",
          "author": "redditownersdad",
          "text": "You da real olsen",
          "score": 1,
          "created_utc": "2026-01-31 07:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hcpam",
          "author": "valkiii",
          "text": "Do you have a repo to share?",
          "score": 1,
          "created_utc": "2026-01-29 21:02:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ilckq",
              "author": "Pickymarker",
              "text": "This guy is just starting off and this is not his model it's this other guy's I know",
              "score": 9,
              "created_utc": "2026-01-30 00:50:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2nxsen",
          "author": "Chelokot",
          "text": "People saying left and right look the same have zero comprehension of human faces",
          "score": -3,
          "created_utc": "2026-01-30 19:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k19nz",
          "author": "2reform",
          "text": "Next Elle Fanning please",
          "score": -6,
          "created_utc": "2026-01-30 06:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs1588",
      "title": "10 GitHub Repositories to Ace Any Tech Interview",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "author": "kingabzpro",
      "created_utc": "2026-01-31 12:30:32",
      "score": 66,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "The most trusted GitHub repositories to help you master coding interviews, system design, backend engineering, scalability, data structures and algorithms, and machine learning interviews with confidence.\n\n\n\nLink: [https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview](https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview)",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2wfh9o",
          "author": "Southern-Common-2715",
          "text": "Wow",
          "score": 1,
          "created_utc": "2026-02-01 02:18:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo6ti2",
      "title": "I Built a Hand‚ÄëDrawn Curve Learner in JavaScript",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/8apax439bufg1",
      "author": "Glittering_ken",
      "created_utc": "2026-01-27 07:04:13",
      "score": 58,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qo6ti2/i_built_a_handdrawn_curve_learner_in_javascript/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o210097",
          "author": "unskilledexplorer",
          "text": "nice. I remember this was my first assignment in the AI course at uni, maybe 8 years ago. the first time working with a multilayer perceptron finally gave me an idea what \"universal approximator\" means :) nice memories.\n\nI also remember how magical and incomprehensible it felt at the time, things that feel almost intuitive today.\n\nthanks for reviving the memories :))",
          "score": 3,
          "created_utc": "2026-01-27 15:09:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zaxqs",
          "author": "ObviousOriginal4959",
          "text": "amazing\n\n",
          "score": 2,
          "created_utc": "2026-01-27 08:00:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22b4ze",
          "author": "zitr0y",
          "text": "That's really cool!\n\nCan you zoom out the loss curve to get an overview of how it changed over time?",
          "score": 1,
          "created_utc": "2026-01-27 18:35:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qspkjb",
      "title": "Day 2 of Machine Learning",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qspkjb",
      "author": "Rare-Variety-1192",
      "created_utc": "2026-02-01 05:20:52",
      "score": 57,
      "num_comments": 8,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qspkjb/day_2_of_machine_learning/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2yfiwx",
          "author": "StrikingBeautiful558",
          "text": "Which platform is this?",
          "score": 2,
          "created_utc": "2026-02-01 11:48:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yocn7",
              "author": "Rare-Variety-1192",
              "text": "thinktube",
              "score": 1,
              "created_utc": "2026-02-01 12:56:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30zdwd",
                  "author": "smuhamm4",
                  "text": "Beginner friendly ?",
                  "score": 1,
                  "created_utc": "2026-02-01 19:47:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3339di",
          "author": "2exxgr",
          "text": "What is the name of the program used to take notes on the right, it looks nice",
          "score": 1,
          "created_utc": "2026-02-02 02:25:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33sqc5",
              "author": "Rare-Variety-1192",
              "text": "Thinktube",
              "score": 2,
              "created_utc": "2026-02-02 05:03:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o334s3b",
              "author": "DazzedXI",
              "text": "I also second that",
              "score": 1,
              "created_utc": "2026-02-02 02:34:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qoha8y",
      "title": "My ML learning arc (decision tree)",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qoha8y",
      "author": "Ancient-Teach7606",
      "created_utc": "2026-01-27 15:41:29",
      "score": 54,
      "num_comments": 8,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qoha8y/my_ml_learning_arc_decision_tree/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o21w6g4",
          "author": "Maleficent_Chance_15",
          "text": "where are you learning from?",
          "score": 1,
          "created_utc": "2026-01-27 17:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24v7gk",
              "author": "Ancient-Teach7606",
              "text": "From data camp",
              "score": 1,
              "created_utc": "2026-01-28 01:50:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o256mfj",
                  "author": "smuhamm4",
                  "text": "How would you review them?",
                  "score": 1,
                  "created_utc": "2026-01-28 02:50:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2tk0vk",
          "author": "sanjogs",
          "text": "how many days had it been for you?",
          "score": 1,
          "created_utc": "2026-01-31 17:23:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2tk8bf",
              "author": "Ancient-Teach7606",
              "text": "Sry can you explain!",
              "score": 1,
              "created_utc": "2026-01-31 17:24:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2wf4jk",
                  "author": "sanjogs",
                  "text": "How many days had it been when you started machine learning.",
                  "score": 1,
                  "created_utc": "2026-02-01 02:15:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqy5d1",
      "title": "Should I list a Kaggle competition result (top 20%) as a competition or a personal project on my resume?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "author": "Cheap_Train_6660",
      "created_utc": "2026-01-30 06:45:29",
      "score": 44,
      "num_comments": 23,
      "upvote_ratio": 0.93,
      "text": "Hey all,\n\nI recently participated in my first Kaggle competition (CSIRO Biomass). There were \\~3,800 teams, and my **final private leaderboard rank was 722 (top 20%)**.\n\nNo medal or anything, just a solid mid-upper placement.\n\nI‚Äôm applying for ML / data science / research-adjacent internships and was wondering what‚Äôs considered best practice on a resume:\n\n* Is it better to list this explicitly as a **Kaggle competition** with the rank?\n* Or frame it as a **personal ML project using a Kaggle dataset**, and not emphasize the competition aspect?\n\nI don‚Äôt want to oversell it, but I also don‚Äôt want to undersell or hide useful signal. Curious how hiring managers / experienced folks view this.\n\nWould appreciate any advice üôè",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2katnv",
          "author": "DuckSaxaphone",
          "text": "As a hiring manager, the only thing that would make it worth mentioning to me is that if it's a competition, I guess it was a new data set you couldn't follow a tutorial for?\n\nBut honestly, I wouldn't spend too much CV space on this and it would be better to quickly say what you did and how.",
          "score": 31,
          "created_utc": "2026-01-30 07:21:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kb765",
              "author": "Cheap_Train_6660",
              "text": "For this competition it *was* a new, real-world dataset (remote sensing + biomass targets). There wasn‚Äôt a step-by-step tutorial to follow, so I had to decide on feature engineering, validation strategy, and modeling choices myself. I was just concerend about a non impressive rank of 722/3803. it was my first ever comp tho",
              "score": 9,
              "created_utc": "2026-01-30 07:24:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lbzo5",
                  "author": "Palmquistador",
                  "text": "In my experience, what one company/person/founder thinks is trash / useless, another appreciates and finds valuable.\n\nI think, OP, this sub is too small for you to gleam an accurate model so I would just say, take the advice with a grain of salt.\n\nMaybe try different formats if you can get a feel. Some postings may encourage you to list projects and competitions while others may have hard set requirements and not budge. It really is a roll of the dice from company to company.",
                  "score": 9,
                  "created_utc": "2026-01-30 12:35:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kkir2",
          "author": "AccordingWeight6019",
          "text": "I would list it as a competition and be very factual about it. Something like the problem, the methods you used, and the final rank. Top 20 percent out of a few thousand teams is solid, especially for a first competition. Framing it as just a personal project kind of hides the competitive signal, but overselling medals you did not get would be worse. most hiring managers I have talked to care less about the exact rank and more about what you actually did. feature engineering, validation strategy, ensembling, error analysis, that stuff. If you can explain your approach clearly, the competition context helps rather than hurts.",
          "score": 7,
          "created_utc": "2026-01-30 08:47:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kahhq",
          "author": "juanurena",
          "text": "I would not add it. If you want, you can add a section with Kaggle projects, and then comment shortly which projects you joined (once you have 3/4), your user, etc. This will show me a good  interest, that you like some areas, and that you keep yourself updated.\n\nBut I would never add, I was top 20% on this competition.",
          "score": 19,
          "created_utc": "2026-01-30 07:18:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l1v10",
              "author": "Palmquistador",
              "text": "Why not? He is better than 80% of the people that did it‚Ä¶",
              "score": 4,
              "created_utc": "2026-01-30 11:21:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lkjpa",
                  "author": "sam_the_tomato",
                  "text": "Because that implies he is not better than the top 20% of people, or he would have written a higher percentile. In most cases, this will actively hurt his chances.\n\n---\n\n\n\nIf there are N random applicants to the job (including you), the probability of you being the best applicant is 0.8^N-1 . That's what your employer will assume if you put that on the resume. However, if you leave it out, they will think the probability of you being the best applicant is 1/N.\n\n1/N > 0.8^N-1 at around N = 13. So if there are 12 or more other applicants (ML jobs can have hundreds), you should leave it out. \n\nAlso, this is before accounting for selection bias, e.g. he may have entered 10 competitions and only gotten top 20% in 1 of them, which an employer might assume, further lowering his odds of being the best applicant.",
                  "score": 11,
                  "created_utc": "2026-01-30 13:26:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2mjg28",
                  "author": "Suspicious-Beyond547",
                  "text": "Have you ever done a kaggle? Most teams (possibly close to 80 percent) that sign up spend less than an hour and call it quits.¬†\n\n\nAnother issue is that youll never deal with clean kaggle like datatsets in production.¬†",
                  "score": 3,
                  "created_utc": "2026-01-30 16:15:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2l5utp",
                  "author": "juanurena",
                  "text": "And? What does mean? Being better than other people (random people that we don't know) is not something valuable for me.\n\nI will value that you can solve real problems and you have interest, but I cannot compare if the other 80% are good or bad engineers. So it is not really a useful metric.",
                  "score": 0,
                  "created_utc": "2026-01-30 11:52:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ko5n0",
          "author": "Adept_Carpet",
          "text": "If your resume has nothing besides coursework, it's good.\n\n\nAfter the internship, maybe relegate it to one line. After a second internship or a full time job remove it entirely.",
          "score": 4,
          "created_utc": "2026-01-30 09:20:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2koync",
          "author": "Suspicious-Beyond547",
          "text": "I'd say anything outside top 2-5 percent isnt impressive, mostly because theyre usually one or two good teams that make their notebooks public and 25 percent of teams just just the same approach with some 'hyperparameter tuning'.",
          "score": 5,
          "created_utc": "2026-01-30 09:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kqkrp",
          "author": "misingnoglic",
          "text": "I would call it a project and add a bullet saying it was the top X% of results.",
          "score": 3,
          "created_utc": "2026-01-30 09:42:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k6z6p",
          "author": "Standard_Iron6393",
          "text": "That is good , add in a resume it would be a plus point",
          "score": 6,
          "created_utc": "2026-01-30 06:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kk2ch",
          "author": "pleaseineedanadvice",
          "text": "Wouldn't mention it if you have something else (totally fine not having it, l m just saying) if not maybe like a link to your kaggle page (on top of my mind can't remember if they are shown)",
          "score": 2,
          "created_utc": "2026-01-30 08:43:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l9o5j",
          "author": "TruthIll4102",
          "text": "Hiring folks know Kaggle is competitive and noisy, so they‚Äôre usually more interested in *what you did* than the rank alone. I wouldn‚Äôt reframe it as ‚Äújust a personal project‚Äù unless you heavily extended it beyond the competition. Calling it a competition shows you worked under constraints, evaluated properly, and compared against others. Also don‚Äôt overthink the ‚Äúno medal‚Äù part. There are lot of strong candidates have Kaggle entries without medals. Just don‚Äôt hype it as ‚Äútop performer‚Äù or anything like that and you‚Äôre fine.",
          "score": 2,
          "created_utc": "2026-01-30 12:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2x5f71",
          "author": "Sad-Net-4568",
          "text": "I also want to ask something related to it, if kaggle competition not just mentioned as a competition but also a project.\nI mean proper structured code on GitHub link is provided not just the rank on CV.\nWhat would be your take on it?",
          "score": 1,
          "created_utc": "2026-02-01 05:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oqsru",
          "author": "Jaded_Individual_630",
          "text": "I can't imagine a Kaggle result being on a resume making me think one thing or another, probably more negative thoughts than positive given the amount of absolute garbage on Kaggle.",
          "score": -1,
          "created_utc": "2026-01-30 22:18:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr6n7l",
      "title": "Want to start Machine learning...i know the basics of python, pls help me guyss",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "author": "Different-Sell2195",
      "created_utc": "2026-01-30 14:16:59",
      "score": 43,
      "num_comments": 16,
      "upvote_ratio": 0.92,
      "text": "see i know basics of c, c++, python and R....i want to do machine learning. I have good understanding of mathematics and little of statistics and i grab things easily. I don't know where to start and how so please give me some advice on it  \nAnd please mention the source from whre i should start too",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2lyfvk",
          "author": "starksince2004",
          "text": "Statquest if you want to grasp concepts quickly\n\nAndrew old Ng courses are also very good. You can find them on YouTube.\n\nCampusx 100 days of machine learning, if you are ready to invest time\n\nIf you want to pay, course on edx provided by MIT\n\nBooks:\n\nOreilly publication books\n\nNeural Networks and Deep Learning by Michael Nielsen",
          "score": 10,
          "created_utc": "2026-01-30 14:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nao2z",
              "author": "dutchpsychologist",
              "text": "Upvote for statquest! It is awesome. Josh Starmer from statquest also has books that are basically the videos in readable format, I also recommend those",
              "score": 6,
              "created_utc": "2026-01-30 18:16:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2nvau9",
                  "author": "Leading_Tourist9814",
                  "text": "baaaam",
                  "score": 2,
                  "created_utc": "2026-01-30 19:48:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2nf67o",
          "author": "DataCamp",
          "text": "If it helps, here‚Äôs a first month plan that won‚Äôt overwhelm you.\n\nIn the first week, focus on understanding what machine learning actually is and how it‚Äôs used. Learn the difference between supervised and unsupervised learning and get comfortable with the idea of features, labels, training, and testing. At the same time, refresh Python basics you‚Äôll use all the time in ML, especially NumPy and pandas. Try loading a dataset, cleaning it, and doing some simple exploration.\n\nIn week two, start with your first real models. Learn linear regression and logistic regression and implement them using scikit-learn. Don‚Äôt worry about the math being perfect, just understand what the model is trying to do and how to evaluate it. Work with a small dataset and focus on things like train/test split, accuracy, and mean squared error.\n\nWeek three, classic machine learning algorithms. Learn decision trees, k-nearest neighbors, and random forests. This is where ideas like overfitting and bias vs variance start to make sense. Try changing model parameters and see how performance changes. This experimentation is more important than memorizing formulas.\n\nIn the fourth week, put everything together in a small project. Take a dataset from Kaggle and go end to end: clean the data, choose a model, train it, evaluate it, and explain your results in plain language. Even a simple project here will boost your confidence a lot.\n\nBy the end of the month, you won‚Äôt be an expert, but you‚Äôll actually understand how machine learning works and how to build models. From there, you can decide whether to go deeper into math, try deep learning, or focus on more projects.",
          "score": 5,
          "created_utc": "2026-01-30 18:36:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ovg4e",
              "author": "Gullible-Bluejay-848",
              "text": "Stopping by to thank you for this very helpful run down. Thanks :) üôè",
              "score": 1,
              "created_utc": "2026-01-30 22:41:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35t3ot",
                  "author": "DataCamp",
                  "text": "Np :)",
                  "score": 1,
                  "created_utc": "2026-02-02 14:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2lxfqo",
          "author": "AdDiligent1688",
          "text": "I would see if you can find some university slideshows on machine learning concepts and have a look at those, as well as videos, to understand how basic ML algorithms work. Then practice applying them in Jupyter notebooks or google collab with real data from kaggle.",
          "score": 2,
          "created_utc": "2026-01-30 14:33:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ly2aj",
          "author": "CalmGuy69",
          "text": "You can watch the machine learning specialization on Coursera. It consists of 3 lectures. Amazing stuff for beginners.",
          "score": 2,
          "created_utc": "2026-01-30 14:36:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ojtng",
          "author": "Automatic_Lab2084",
          "text": "Here are some curated playlists   \n[https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art](https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art)   \n[https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch](https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch)  \n[https://brightclips.ai/playlist/demystifying-large-language-models](https://brightclips.ai/playlist/demystifying-large-language-models)",
          "score": 2,
          "created_utc": "2026-01-30 21:44:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m8o2f",
          "author": "Jaded_Individual_630",
          "text": "Would be curious to hear what you think a good understanding of mathematics means.",
          "score": 1,
          "created_utc": "2026-01-30 15:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2otgrn",
          "author": "ViciousIvy",
          "text": "hey there! my company offers a free ai/ml engineering fundamentals course for beginners! if you'd like to check it out feel free to message me¬†\n\n\n\nwe're also building an ai/ml community on discord where we hold events, share news/ discussions on various topics. feel free to come join us [https://discord.gg/WkSxFbJdpP](https://discord.gg/WkSxFbJdpP)",
          "score": 1,
          "created_utc": "2026-01-30 22:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rn3qt",
          "author": "East-Muffin-6472",
          "text": "Campusx X ML and DL playlist on YouTube\nAndrew ng ml  and dl courses \nStat quest yt channel and it‚Äôs book\n3b1b for linear algebra \nMIT probability course on yt\nIsle book for in depth ml algorithms intuition and rigorous math proofs \n\nA few of my own work I‚Äôd like to pus forward which maybe of assistance to you!\n\nhttps://www.smolhub.com",
          "score": 1,
          "created_utc": "2026-01-31 10:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sy9y3",
          "author": "redirkt",
          "text": "Deeplearning.ai - start from there",
          "score": 1,
          "created_utc": "2026-01-31 15:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2w93bd",
          "author": "Entire-Parsley-6035",
          "text": "HandsonMachine Learning Aurelion Geron",
          "score": 1,
          "created_utc": "2026-02-01 01:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qswm2l",
      "title": "How do I get out of ML tutorial hell and actually grasp MLÔºü",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qswm2l/how_do_i_get_out_of_ml_tutorial_hell_and_actually/",
      "author": "MaximumAd8046",
      "created_utc": "2026-02-01 11:58:16",
      "score": 40,
      "num_comments": 37,
      "upvote_ratio": 0.9,
      "text": "I‚Äôm trying to get out of ‚ÄúML tutorial hell‚Äù and build a solid foundation that I can steadily grow from. I tried starting with papers (e.g., *Attention Is All You Need*), but I quickly hit a prerequisite chain: the paper assumes concepts I haven‚Äôt fully internalized yet (FFNs, layer norm, residuals, training details, etc.). I end up jumping between resources to fill gaps and lose a clear sense of progression.\n\n**Background:** Bachelor‚Äôs degree; some linear algebra & calculus (needs review); basic/intermediate Python.\n\n**Goal:**\n\nAt minimum, stay on a correct learning path and accumulate skills steadily.\n\nLong-term, build a strong foundation and the ability to implement/diagnose models independently.\n\n**Questions:**\n\n1. When does it make sense to read papers, and how do you avoid getting lost in prerequisites?\n2. What ‚Äúmust-have‚Äù fundamentals should come before reading modern deep learning papers?\n3. Top-down (papers ‚Üí fill gaps) vs bottom-up (fundamentals ‚Üí models ‚Üí papers): which works better, and what milestone sequence would you recommend?\n4. What practice routine forces real understanding (e.g., implementations, reproductions, projects)?\n\nNot looking for a huge link dump‚Äîjust a practical roadmap and milestones.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qswm2l/how_do_i_get_out_of_ml_tutorial_hell_and_actually/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2z7nbp",
          "author": "Reasonable_Listen888",
          "text": "  \nWhat helped me was trying to create things on my own. For example, I read an article about grokking (Deep Networks Always Grok and Here is Why), and after more or less understanding what it said, I checked if it was true that the gradient descent was smooth, but my observations said otherwise, and here I am trying to prove it: [https://zenodo.org/records/18447432](https://zenodo.org/records/18447432)",
          "score": 7,
          "created_utc": "2026-02-01 14:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2z2um8",
          "author": "king_of_walrus",
          "text": "Bottom-up always or you will be lost in the sauce. Here is what I‚Äôd suggest.\n\nYou need to start in the metaphorical basement: linear algebra (at least understanding the topics covered by a typical college course, and maybe some extras - critical concepts include vector spaces and their properties, matrix manipulation / multiplication and matrix properties, linear transformations and their properties), calculus (limits, differentiation, integration, multi-variable calculus should be sufficient for basics), and maybe most importantly probability + statistics (understanding probability spaces, I.e., how do we define them, random variables, random vectors, functions of random variables, stochastic processes, etc.) I would also strongly recommend studying statistical estimation and detection - the theory underpins fundamental problems tackled by ML. Also, understanding some optimization theory would be useful (e.g., convex optimization, KKT, etc.).\n\nThen you can move onto an ML intro course‚Äôs content: linear regression, logistic regression, decision trees, basic optimization if not already learned (GD and SGD), multi-layer perceptrons (simple NNs), etc. There are of course more ‚Äúintro‚Äù concepts, but I think these would give you a strong foundation.\n\nFrom here, you should dive into more advanced topics that interest you. I would advise avoiding papers until you have a very high mathematical maturity level and truly understand fundamental concepts. Most papers (or their key concepts) can be found described in blog posts that are easier to digest.\n\nWith all of this in mind, I would strongly suggest pursuing an MS or a PhD if you are serious about getting into ML. Self-learning ML is much more difficult than just learning to code. Coding is a part of the job of course, but it is the easiest part (at least for researchers).",
          "score": 12,
          "created_utc": "2026-02-01 14:25:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o328mqo",
              "author": "fruini",
              "text": "Not sure you say coding in general is simple, or coding in ML. Your last paragraph can read in different ways.\n\nI interview MLEs and Applied Scientists in big tech. The market is full of candidates that know ML theory. Very few of those can properly code. Even fewer know how to actually build systems and work in complex socio-technical environments.\n\nWhile the candidates pool increased a lot in the past years, the quality did not really improve. Many older MLEs only worked on isolated executive pet projects for most of their career. While new-gen's culprit is trying to shortcut the learning path to strictly ML, with no engineering foundations nor complementary domain expertise.",
              "score": 6,
              "created_utc": "2026-02-01 23:34:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37iupc",
                  "author": "Lower_Improvement763",
                  "text": "Really? That‚Äôs scary we have all those scientists out there now‚Ä¶ coding is a different beast. Many people outside the US devalued it though. But like every Python snippet I feel is difficult as heck to grasp what it does. It sounds as if people want a web developer with a phd in ml",
                  "score": 1,
                  "created_utc": "2026-02-02 19:23:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2zvg9e",
              "author": "numice",
              "text": "I've taken an optimization course and linear algebra and among other math courses. Also work in data but not machine learning. I've tried teaching myself ML a couple times and I'm kinda at least feel familair with some basic techniques like K-nearest neighbour, SVM, linear/logistic regressions. Took a couple of online courses.\n\nHowever, I sill feel like I haven't learned much neither done much and don't exactly know where to go from here. I used to aim for a career in ML like in 2018 but pretty given up now. Right now I'm just learning for fun and upskilling. I like mathematics so there's also one reason. Any advice to go from here? Building simple projects? I've done several basic projects like linear regression, some clustering, some basic NLP stuff but I still feel like it's just, well, basic. Should I focus on one particular area like, for example, approximate nearest neighbour, and look for techniques developed within this topic?",
              "score": 1,
              "created_utc": "2026-02-01 16:45:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o34etcj",
              "author": "MaximumAd8046",
              "text": "Thanks for your advice, it really helps",
              "score": 1,
              "created_utc": "2026-02-02 08:09:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yjg30",
          "author": "Radiant-Rain2636",
          "text": "The Lazy Programmer on Udemy",
          "score": 2,
          "created_utc": "2026-02-01 12:19:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3304ks",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 02:08:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zfupn",
          "author": "Steve_cents",
          "text": "I would suggest to have a project in mind ,eg write a Hemingway style novel, or forecast interest rate movement .\n\nRun tutorials , research to understand the tutorials, using google or copilot or whatever \n\nModify the tutorial for your project.",
          "score": 2,
          "created_utc": "2026-02-01 15:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3303n7",
              "author": "MaximumAd8046",
              "text": "Sounds great, thanks!",
              "score": 1,
              "created_utc": "2026-02-02 02:08:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33p4v6",
          "author": "Enough-Profit-681",
          "text": "Search for datasets, think of ways on how you can use that or what it can be used for, train an ml model on the dataset, test and tune your model, make it into a basic app, show to friends and family",
          "score": 2,
          "created_utc": "2026-02-02 04:38:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33sreu",
              "author": "MaximumAd8046",
              "text": "That sounds like a very practical path to bridge the gap between tutorials and real-world understanding. Thanks for the suggestion!",
              "score": 2,
              "created_utc": "2026-02-02 05:03:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zfvlw",
          "author": "Lower_Improvement763",
          "text": "Do you know how to program? It depends on what your priorities are. There‚Äôs cool new tech/ideas out there everyday. But much of this has been evolving rapidly since 2015. And then there‚Äôs parts of it which have been there since the 1960s",
          "score": 1,
          "created_utc": "2026-02-01 15:32:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33001z",
              "author": "MaximumAd8046",
              "text": "I have some basic programming knowledge. I totally agree with you‚Äîmy learning plan is to focus more on the **fundamentals** that stand the test of time. As for the technologies that are still rapidly evolving, I‚Äôm happy to **let the dust settle** first before diving too deep into them.",
              "score": 1,
              "created_utc": "2026-02-02 02:07:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33mb7l",
                  "author": "Lower_Improvement763",
                  "text": "What is maximum Ad mean? lol",
                  "score": 1,
                  "created_utc": "2026-02-02 04:19:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o302mq8",
          "author": "Commercial-Fly-6296",
          "text": "Same problem but I think once we get some knowledge (just a course is fine), learning on the fly by doing a project or internship will help.(I think people call it Just in Time learning)",
          "score": 1,
          "created_utc": "2026-02-01 17:18:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32zjka",
              "author": "MaximumAd8046",
              "text": "I agree it's a good short-term fix, but for long-term growth, we need a more structured learning path.",
              "score": 1,
              "created_utc": "2026-02-02 02:04:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ap5d",
          "author": "jmugan",
          "text": "Mitchell's book Machine Learning from 1997",
          "score": 1,
          "created_utc": "2026-02-01 17:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34ff82",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:15:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ianc",
          "author": "kira2288",
          "text": "Kaggle",
          "score": 1,
          "created_utc": "2026-02-01 18:28:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fflo",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:15:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30imtd",
          "author": "Aquatiac",
          "text": "My suggestion is:\n\n1. Brush up on linear algebra, calculus, probability, and statistics. Stuff you should understand includes vector spaces, eigenvalues/positive definiteness, PDFs, bayes rule, etc etc\n\n2. Take a introductory machine learning course with some mathematical rigor. This should go over linear regression, logistic regression, SVMs, RBF-networks, and maybe up to basic neural networks (but nothing fancier). The important thing is building an understanding behind regularization, data snooping, and other fundamental concepts\n\n3. More optional, but a course on ML focused on optimization math to gain better understanding of convergence guarantees, various forms of regularization, and looking at the same problem from multiple perspectives\n\n4. THEN beginning to look at more advanced architecture and building other projects\n\nA lot of people are saying \"just learn on the fly and build projects\" but I think its best to have some theory to start with :)",
          "score": 1,
          "created_utc": "2026-02-01 18:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32z5tk",
              "author": "MaximumAd8046",
              "text": "Can't agree any more, I think we need to balance both **top-down** and **bottom-up** learning. It‚Äôs better to stay flexible with them‚Äî**learning on the fly** when needed, but also taking the time to **build a strong foundation** when the theory gets complex.",
              "score": 1,
              "created_utc": "2026-02-02 02:02:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30nwj4",
          "author": "Safe_Towel_8470",
          "text": "Personally, I would kind of just do it. TensorFlow has some pretty good tutorials to get started, and you can get using it pretty quick with OpenCV for something more visual.",
          "score": 1,
          "created_utc": "2026-02-01 18:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32xucc",
              "author": "MaximumAd8046",
              "text": "Sounds great",
              "score": 1,
              "created_utc": "2026-02-02 01:55:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31um12",
          "author": "EffectiveOk4641",
          "text": "Transitioned from business to ml engineering myself, step by step. Many say you have to do fundamentals first, but its also possible to start in the practical end developing models then go deeper into the mathematics. I have created a skill coach that can help you find your personalised roadmap. Try it out [here](https://skillmapperai.com/landing/?utm_source=reddit&utm_medium=reddit&utm_campaign=dataanalysiscareers) if you are curious, would appreciate feedback!",
          "score": 1,
          "created_utc": "2026-02-01 22:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32xrup",
              "author": "MaximumAd8046",
              "text": "Thanks, I've added my gmail into waiting list, but how I can login in?",
              "score": 1,
              "created_utc": "2026-02-02 01:54:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o328rqz",
          "author": "CorpusculantCortex",
          "text": "Find a data set, think of a practical problem you can solve with the tools you want to learn, apply knowledge.",
          "score": 1,
          "created_utc": "2026-02-01 23:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fgs8",
              "author": "MaximumAd8046",
              "text": "Sounds great",
              "score": 1,
              "created_utc": "2026-02-02 08:15:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33aewk",
          "author": "Comfortable-Unit9880",
          "text": "i work full time, then uni in the evenings. I've been trying to do the bottom up approach via khan academy math first but i said fuck it im gonna switch to top down. Just dont have that much time in a given day, at this rate i'll be doing math prep for months before i get my hands dirty. I bought the latest Hands On ML Pytorch book and im just gonna dive in, top down approach and basically fill the gaps as I go along and start building a project sooner than later. Otherwise with my current approach im gonna lose motivation lol",
          "score": 1,
          "created_utc": "2026-02-02 03:06:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fpyq",
              "author": "MaximumAd8046",
              "text": "Thanks, rooting for all of us to succeed eventually!",
              "score": 1,
              "created_utc": "2026-02-02 08:18:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33u1ig",
          "author": "RoyalCities",
          "text": "I'd get your hands dirty and start fine tuning models. See what works and what doesn't. Kaggle also has challenged and datasets.\n\nIf your into the generative stuff then fine-tune some image models, or train an LLM / do the free hugging face LLM course.",
          "score": 1,
          "created_utc": "2026-02-02 05:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34epbh",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:08:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36ydfe",
          "author": "EngramAI-io",
          "text": "I am in the same boat as you and I have the same background. What I feel like works really well is finding a real world problem that could be solved using machine learning. Once you have discovered a problem you can ask whatever LLM you prefer a structured a roadmap of what you should know to tackle the problem using ML from basics. From there you learn + build simultaneously whether its by reading up on an algorithm or seeing how others have implemented it in code etc. \n\nFor example, if you have to use linear regression at some point just knowing what is it about the fundamental nature of linear regression that helps solve this problem can help you master certain commonly used ML algorithms\n\nAlthough i would say before u build something serious u should have a good grasp on the mathematics especially linear algebra. im currently studying it from this book https://mml-book.github.io which has been recommended a lot in this subreddit. Good Luck!",
          "score": 1,
          "created_utc": "2026-02-02 17:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39rnl2",
          "author": "Aggressive-Bother470",
          "text": "Build a home rig and try to figure out why it's nowhere near as good as Opus.\n\n\nYou get to go on so many amusing side quests.\n\n\nWhy is KLD better than PPL?\nIs flash attention truly lossless?\nWhy is this model looping it's tits off?\nWhy are so many 'papers' referring to sft as distillation?\nHow the hell do you intuitively understand a 2880 dimension vector?",
          "score": 1,
          "created_utc": "2026-02-03 02:18:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qow8t6",
      "title": "I‚Äôm writing a from-scratch neural network guide (no frameworks). What concepts do learners struggle with most?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qow8t6/im_writing_a_fromscratch_neural_network_guide_no/",
      "author": "palash90",
      "created_utc": "2026-01-28 00:43:14",
      "score": 38,
      "num_comments": 39,
      "upvote_ratio": 0.89,
      "text": "Most ML resources introduce NumPy and then quickly jump to frameworks.\n\nThey work but I always felt I was using a library I didn‚Äôt actually understand.\n\nSo I‚Äôm writing a guide where I build a minimal neural network engine from first principles:\n\n*  flat-buffer tensors\n* explicit matrix multiplication\n* manual backprop\n* no ML frameworks, no hidden abstractions\n\nThe goal is not performance.\n\nThe goal is understanding what‚Äôs really happening under the hood.\n\nBefore going further, I‚Äôd really like feedback from people who‚Äôve learned ML already:\n\n*  Which NN concepts were hardest to understand the first time?\n*  Where do existing tutorials usually gloss over details?\n*  Is ‚Äúfrom scratch‚Äù actually helpful, or just academic pain?\n\nDraft is here if you want to skim specific sections: [https://ai.palashkantikundu.in](https://ai.palashkantikundu.in)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qow8t6/im_writing_a_fromscratch_neural_network_guide_no/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o24nd21",
          "author": "beingsubmitted",
          "text": "I think most people going into this aren't ready for the linear algebra and multivariable calculus. I think most people would agree backprop is the main struggle.",
          "score": 21,
          "created_utc": "2026-01-28 01:08:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24nmfo",
              "author": "palash90",
              "text": "Thank you for your response. I have tried to explain as much as possible with different tools",
              "score": 3,
              "created_utc": "2026-01-28 01:10:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o25x1mm",
              "author": "Suspicious_Tax8577",
              "text": "I have a PhD, as well as undergrad and masters in chemistry. Objectively, I've survived worse (statistical thermodynamics), but manual backprop made me cry. \n\nBuilding a vanilla MLP in numpy is pretty much the reason why the PI I'm currently working with on a proposal for hypergraph neural networks wants to work with me ü•¥.",
              "score": 0,
              "created_utc": "2026-01-28 05:30:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ar8jn",
                  "author": "om_nama_shiva_31",
                  "text": "There‚Äôs no way simple derivatives and matrix multiplication made you cry if you have a phd in any science",
                  "score": 2,
                  "created_utc": "2026-01-28 22:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o24y6sl",
          "author": "unlikely_ending",
          "text": "I did that too, for a CNN\n\nJust used Numpy and Python \n\nVery inefficient but it worked\n\nProbs the back prop took me the longest to figure out",
          "score": 8,
          "created_utc": "2026-01-28 02:06:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o269bp2",
              "author": "palash90",
              "text": "Yes, Backprop was the hardest for me too. But weaving every piece by hand made it very logical.",
              "score": 3,
              "created_utc": "2026-01-28 07:05:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2538qc",
          "author": "ProfessionalShop9137",
          "text": "I‚Äôve done this in uni classes and it‚Äôs always back prop. The math isn‚Äôt crazy crazy but setting it up programmatically is a struggle to wrap your head around.",
          "score": 9,
          "created_utc": "2026-01-28 02:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o269rl8",
              "author": "palash90",
              "text": "Yeah. I really have a clear explanation why autograd exists.",
              "score": 1,
              "created_utc": "2026-01-28 07:08:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25yiob",
          "author": "AtMaxSpeed",
          "text": "A note on backprop, it is \"easy\" to do it if you have a fixed architecture. There are many guides on how to build a 1/2 hidden layer NN and code up the backprop after you work out the formulas. It is tedious and annoying, but simple to work out. The hard part, and useful part, and undertaught part, is autograd: generalizing the framework so you can use different losses, different activations, and different architecture. This also teaches people how to really understand backprop, since you have to operate on generalized incoming gradients and activation values.\n\nIf you're building a course, it may be neat to help people build an autograd for the simple functions (add, subtract, matmul, etc.) to implement a neural network from scratch.",
          "score": 6,
          "created_utc": "2026-01-28 05:40:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26ax9i",
              "author": "Correct_Scene143",
              "text": "Fcuk this is the real hard part rest is just tedious. Autograd is the real shit show",
              "score": 2,
              "created_utc": "2026-01-28 07:18:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o26aqx7",
              "author": "palash90",
              "text": "Yes, this is the foundation part. with no gpu, no fancy layers and all.\n\n  \nstill I got quite good result out of it. next up is extend this to build transformers. there I will introduce autograd.",
              "score": 1,
              "created_utc": "2026-01-28 07:17:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25wiyi",
          "author": "AccordingWeight6019",
          "text": "backprop itself is usually not the hardest part. the confusion comes from how gradients flow across layers and why small choices like initialization or shapes affect learning. from scratch helps if it builds intuition that transfers to frameworks, not if it becomes the destination.",
          "score": 4,
          "created_utc": "2026-01-28 05:26:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2575hz",
          "author": "thebriefmortal",
          "text": "I built my first NN from scratch in MaxMsp, a visual language for audio applications. I hadn‚Äôt heard of NNs until I watched Welch Labs video on the Perceptron, after which I just kind of felt my way through the mechanics of it and built it in sections. Forward pass and error calculation was relatively easy, but backpropagating the corrections was a nightmare that took me ageeeeees to figure out. I was deep inside Overflow City for the longest time.",
          "score": 3,
          "created_utc": "2026-01-28 02:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o25hqoj",
          "author": "irekit_",
          "text": "when I coded my first neural network from scratch I would have literal nightmares about the calculus in backprop.",
          "score": 3,
          "created_utc": "2026-01-28 03:52:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c73o",
              "author": "palash90",
              "text": "It's difficult for sure.",
              "score": 2,
              "created_utc": "2026-01-28 07:29:36",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o39cmrr",
              "author": "R-EDA",
              "text": "That happened to me also, I dreamed of myself doing all vectorized forms of derivatives by hand. There was also this big ass Jacobian on the paper, it wasn't a good dream.",
              "score": 1,
              "created_utc": "2026-02-03 00:53:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o261p02",
          "author": "Duflo",
          "text": "It's only a matter of time until this evolves into a framework :)\n\nSeriously though, looks cool.",
          "score": 3,
          "created_utc": "2026-01-28 06:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c4rn",
              "author": "palash90",
              "text": "Thanks.\n\n  \nYes, I am seeing it myself. Near the end, I already build two methods - builder.build() and nn.predict\n\n()",
              "score": 1,
              "created_utc": "2026-01-28 07:29:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27tam1",
          "author": "JanBitesTheDust",
          "text": "Focus of backprop like most people mention. But specifically focus on the idea of linearization via gradient descent and the idea of automatic differentiation. It makes the hard math much easier to digest and allows for good conceptual understanding on the flow of computations via a DAG. A while back I implemented autodiff in C which may be useful for your guide: https://github.com/Janko-dev/autodiff",
          "score": 3,
          "created_utc": "2026-01-28 14:11:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o288zvn",
              "author": "palash90",
              "text": "Great headstart. thank you.",
              "score": 1,
              "created_utc": "2026-01-28 15:27:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25nuya",
          "author": "Correct_Scene143",
          "text": "i too am planning to do this but i wanna know if it is worth it like learning wise ik it is but cv and visibility wise ??",
          "score": 2,
          "created_utc": "2026-01-28 04:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o25xofj",
              "author": "Suspicious_Tax8577",
              "text": "Building a vanilla MLP in numpy is pretty much the reason why the PI I'm currently working with on a proposal for hypergraph neural networks wants to work with me ü•¥.\n\nWhether this applies for industry, idk. But once you've cried over manual backprop, you'll never take autodiff for granted and tensorflow/pytorch no longer feels like you're writing a magical incantation.",
              "score": 2,
              "created_utc": "2026-01-28 05:34:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o26a41h",
                  "author": "Correct_Scene143",
                  "text": "True true , the learning value is great no doubt. When was this tho cause every second guy I see today is trying to do this as an exercise or I'm just in good ml circles that don't revolve around hype",
                  "score": 1,
                  "created_utc": "2026-01-28 07:11:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o26acgu",
              "author": "palash90",
              "text": "trust me, it's rewarding. if you have good grasp of the math and programming it won't take more than  weekend in python, more than 2 weeks in Rust.\n\nbut the strong understanding of AI basics will always stay with you.",
              "score": 1,
              "created_utc": "2026-01-28 07:13:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25zhpu",
          "author": "ForeignAdvantage5198",
          "text": "intro to stat learning should be a start",
          "score": 2,
          "created_utc": "2026-01-28 05:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c0ho",
              "author": "palash90",
              "text": "Weight Initialisation leans on Probability and Statistics heavily.\n\n  \nI just dodged the bullet for now but can't keep it away forever. At some point, I will have to move to real distribution collections than my simple RNG.",
              "score": 1,
              "created_utc": "2026-01-28 07:28:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2aawt2",
          "author": "jplatipus",
          "text": "Wow this is neat, love it. A few years ago I found an Australian uni tutorial that built a nn using Java, with animated graphics. It really showed me the magic of nn's: me running it several times, asking how does it do that? Magic.\n\nI think your implementation brings it into the present (using rust), but also does a lot more. \n\nExcellent work",
          "score": 2,
          "created_utc": "2026-01-28 20:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2cwkyj",
              "author": "palash90",
              "text": "thank you for your encouragement",
              "score": 1,
              "created_utc": "2026-01-29 05:03:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26d26k",
          "author": "LofiCoochie",
          "text": "math\nbridge between math and code",
          "score": 1,
          "created_utc": "2026-01-28 07:37:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26f8ne",
              "author": "palash90",
              "text": "thanks for the suggestion. I‚Äôve been trying to start from why the math exists and only then map it to code, because jumping straight to formulas never worked for me either.",
              "score": 2,
              "created_utc": "2026-01-28 07:56:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2d89d3",
          "author": "thunderbootyclap",
          "text": "How do you choose the number of nodes in each inner layer?",
          "score": 1,
          "created_utc": "2026-01-29 06:31:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dlbhu",
              "author": "palash90",
              "text": "through experiment. first try small and run for 1000 epochs and start deeper from there, until I find a balance I do hypermeter tuning. there is a chapter in the guide where I show how to do that.\n\n  \nhowever, based on the task and the input fed to network, you have to take the ownership.\n\n  \nthere are other ways, I will have to include in my next guide.\n\n  \nthis is the simplest explanation, kind of a hellow world but it takes users name.\n\n  \nin the next, we use the tool and expand on it.",
              "score": 2,
              "created_utc": "2026-01-29 08:25:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2db2wb",
          "author": "nemesis1836",
          "text": "Can you add a follow up guide where you improve the performance of the network? I haven't seen much articles related to this.",
          "score": 1,
          "created_utc": "2026-01-29 06:54:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dkubg",
              "author": "palash90",
              "text": "in this, I am relying on AutoVectorization by LLVM compiler.\n\nbut, in the second part, I will build a neural network for NGram and transformers.\n\n  \nwe need performance there. optimizers will be optimised, batch training would be new norm, gpu trick may be required.",
              "score": 2,
              "created_utc": "2026-01-29 08:20:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26q7pw",
          "author": "Shark-gear",
          "text": "From scratch guides are a big waste of time.\n\nThe best way of learning is to explain an abstraction (for example backprop), with math. The end.\n\nIn your guide, you will not explain the math, because it's complicated, you'll simply do a very verbose python implementation, and you'll just give something long and overcomplicated and unusable to the community. \n\nThanks for your bloatware and for wasting everybody's time.",
          "score": -2,
          "created_utc": "2026-01-28 09:36:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26twps",
              "author": "palash90",
              "text": "We‚Äôre talking past each other.\n\n\nThe guide is written in Rust and walks through the math step by step, then maps each term to concrete computation and gradient flow, because that‚Äôs where understanding broke down for me.\n\n\nIt‚Äôs not meant to replace formal mathematical treatments, and it‚Äôs not intended for everyone.\n\n\nIf a math-only abstraction works better for you, that‚Äôs completely fine.",
              "score": 2,
              "created_utc": "2026-01-28 10:10:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o26us54",
                  "author": "Shark-gear",
                  "text": "You're just trying to make it easy and nice. You're just dishonest. Math is the only way.",
                  "score": 1,
                  "created_utc": "2026-01-28 10:18:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qr2fx2",
      "title": "What is the skills of Strong Junior MLE?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "author": "sunnakh",
      "created_utc": "2026-01-30 11:02:04",
      "score": 37,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "Hello, guys what do u think to reach Middle level Machine Learning Engineer on which skills I should be master ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2labv1",
          "author": "TruthIll4102",
          "text": "IMO a strong junior MLE isn‚Äôt about knowing every model. It‚Äôs more like:\n\n* solid ML fundamentals (classical ML, eval, data leakage, CV)\n* good Python + pandas/numpy, can write clean code not just notebooks\n* basic stats intuition (why things overfit, why metrics lie)\n* some production sense: training to serving to monitoring (even at a small scale)\n* ability to debug models and data\n\nTo move to mid-level, the big jump is owning stuff end-to-end and understanding tradeoffs. You don‚Äôt need to be an expert in everything, just reliable and hard to break",
          "score": 28,
          "created_utc": "2026-01-30 12:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m2gcm",
              "author": "NotYourASH1",
              "text": "Are you an engineer?",
              "score": 1,
              "created_utc": "2026-01-30 14:58:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2m3sqv",
              "author": "sunnakh",
              "text": "This is great information, thank you)",
              "score": 1,
              "created_utc": "2026-01-30 15:04:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ml5fz",
          "author": "Quiet-Illustrator-79",
          "text": "There‚Äôs no such thing as a junior MLE, work as a software engineer or scientist for a bit.",
          "score": 1,
          "created_utc": "2026-01-30 16:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2poe4y",
              "author": "Soggy-Shopping-4356",
              "text": "Idk why you‚Äôre getting downvoted but it‚Äôs true, MLE is a late-mid to senior role",
              "score": 3,
              "created_utc": "2026-01-31 01:20:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yebs5",
          "author": "Madesh_25",
          "text": "Junior MLE must have:\nSolid ML basics (regression, trees, CV, data leakage)\nPython + pandas/numpy (clean code, not just notebooks)\nBasic stats intuition (overfitting, metrics, bias‚Äìvariance)\nDebug data & models\nBasic production sense (train ‚Üí serve ‚Üí monitor)\nTo move to Mid-level:\nOwn projects end-to-end\nChoose models + metrics with reasons\nUnderstand trade-offs (accuracy vs latency, bias vs variance)\nHandle real-world messy data\nWrite maintainable, production-ready code",
          "score": 0,
          "created_utc": "2026-02-01 11:37:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq90xu",
      "title": "What is the best way to learn ML",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qq90xu/what_is_the_best_way_to_learn_ml/",
      "author": "vetti_pechalar",
      "created_utc": "2026-01-29 13:48:30",
      "score": 37,
      "num_comments": 11,
      "upvote_ratio": 0.86,
      "text": "I currently enrolling in 4th sem of cse specialization of ai ml,i like to learn ml completely.so friends or peers kindly suggest the best way to learn ml completely.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qq90xu/what_is_the_best_way_to_learn_ml/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2excf1",
          "author": "DataCamp",
          "text": "The most effective way to learn ML is to do it in layers. Start with Python plus just enough math to understand what models are doing (linear algebra for vectors/matrices, basic probability, and gradients).   \n  \nThen learn core ML concepts alongside practice: supervised vs unsupervised learning, model evaluation, overfitting, and feature engineering.   \n  \nWhile you‚Äôre learning each concept, train small models in scikit-learn on real datasets so the theory sticks. After that, you can go deeper into areas like deep learning, NLP, or MLOps depending on what you want to work on,  but the main thing is learning ML while building, not waiting until you ‚Äúknow everything‚Äù first.",
          "score": 23,
          "created_utc": "2026-01-29 14:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jwuh5",
              "author": "TotallyNota1lama",
              "text": "Great advice wanted to add¬†https://github.com/hkevin01/Machine-Learning-Model. A project I been playing with; just another tool to try¬†",
              "score": 2,
              "created_utc": "2026-01-30 05:30:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2k0yck",
              "author": "Strange-Inflation-73",
              "text": "heyy what resources do you suggest for getting good at model evaluation overfitting feature engineering data handling concepts",
              "score": 1,
              "created_utc": "2026-01-30 06:01:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2nbpy0",
                  "author": "DataCamp",
                  "text": "A sequence that could work well and that we've got courses for:   \n  \n‚Ä¢ Supervised Learning with scikit-learn: you‚Äôll actually train models, compare metrics, spot overfitting, and tune hyperparameters on real datasets  \n[https://www.datacamp.com/courses/supervised-learning-with-scikit-learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn?utm_source=chatgpt.com)\n\n‚Ä¢ Feature Engineering for Machine Learning in Python: very practical, covers leakage, encoding, scaling, and when features help vs hurt  \n[https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python](https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python)\n\n‚Ä¢ Model Validation in Python: cross-validation, bias/variance tradeoffs, and choosing the right metrics  \n[https://www.datacamp.com/courses/model-validation-in-python](https://www.datacamp.com/courses/model-validation-in-python)",
                  "score": 2,
                  "created_utc": "2026-01-30 18:21:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ffut3",
          "author": "Holiday_Lie_9435",
          "text": "Also learning ML right now and it's mostly self-study. I'd say the 'best' way really depends on your learning style, but a mix of different mediums/resources usually works. Structured courses like *Andrew Ng's Machine Learnin*g course on Coursera are classic for a reason since they give you a strong foundation. Then, maybe you can branch out into more specialized areas that pique your interest, like NLP or computer vision, using resources like [fast.ai](http://fast.ai) or specific textbooks like *Computer Vision: Algorithms and Applications* by Richard Szeliski. Having a roadmap (even a loose one) really helps to stay on track, can link something structured that helped me a lot if it's something you're interested in.",
          "score": 1,
          "created_utc": "2026-01-29 15:47:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fx2lw",
              "author": "melodyofasong",
              "text": "Agreed. As for road map, you can look through machine learning on roadmap.sh",
              "score": 0,
              "created_utc": "2026-01-29 17:03:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gk1kl",
          "author": "Cultural_Book_400",
          "text": "you guys are all good at math right? for me, I try to learn ML but math really gets in the way. I am sorry, I am too not so great for this....   Is there way for none math person to learn ML or am i hopeless completely.",
          "score": 1,
          "created_utc": "2026-01-29 18:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i9muw",
              "author": "bean_217",
              "text": "Yeah I'm honestly not great at the math part either. I can understand how it works with a good explanation, but not if a paper just slaps you with an equation and says \"that right there is attention\".\n\nIf you do struggle with the math, I recommend checking out channels like StatQuest on YouTube.\n\n They explain things step by step. Though sometimes they make things too simple by, for example, not using linear algebra where it would obviously make things easier.\n\nBest of luck to you.",
              "score": 4,
              "created_utc": "2026-01-29 23:47:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2grp10",
          "author": "udede",
          "text": "as a dev who just launched a migraine app with an ai prediction engine, my biggest advice is: don't get stuck in tutorial hell. 4th semester is the perfect time to start building a real-world project.\n\ntheoretically, you'll learn a lot in class, but you'll only 'get it' when you try to implement something like a 3d pain mapping system or an ai report generator using real datasets.\n\nfocus on these 3 things:\n\n1. **data cleaning:** in the real world, data is messy. learning how to handle outliers is 80% of the job.\n2. **api integration:** learn how to connect your models to a mobile or web app (i used fastapi and groqcloud for mine).\n3. **user privacy:** especially in health-tech, learning about secure data handling is just as important as the model accuracy.\n\nbuild something small, ship it, and look at your app store metrics. that's where the real learning starts. good luck!",
          "score": 1,
          "created_utc": "2026-01-29 19:22:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g4nid",
          "author": "Ok_Aide140",
          "text": "–£—á–∏—Ç—å—Å—è, —É—á–∏—Ç—å—Å—è, —É—á–∏—Ç—å—Å—è!",
          "score": -2,
          "created_utc": "2026-01-29 17:38:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtxbns",
      "title": "I learned why cosine similarity fails for compatibility matching",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "author": "Ok_Promise_9470",
      "created_utc": "2026-02-02 15:00:17",
      "score": 36,
      "num_comments": 22,
      "upvote_ratio": 0.74,
      "text": "I've been helping friends build the matching system for their dating app, Wavelength. Wanted to share a lesson I learned the hard way about embedding-based matching  might save someone else the same mistake.\n\n**The approach**: Embed user profiles via LLM into 1536-dim vectors, store in Pinecone, query with ANN + metadata filters. Sub-200ms, scales well, semantically smart ‚Äî \"loves hiking\" matches \"outdoor enthusiast\" automatically.\n\n**What went wrong**: 22% mutual acceptance rate. I audited the rejected high-scoring matches and found this:\n\n    User A: \"Career-focused lawyer, wants kids in 2 years, monogamy essential\"\n    User B: \"Career-focused consultant, never wants kids, open relationship\"\n    \n    Cosine similarity: 0.91\n    Reality: incompatible on two dealbreakers\n    \n\nEmbeddings captured¬†*how someone describes their life*, tone, topic, semantic texture. They completely missed¬†*what someone actually needs*, the structured preferences buried in the prose.\n\nThis wasn't an edge case. It was the dominant failure mode. High similarity, fundamental incompatibility. Two people who sounded alike but wanted completely different things.\n\n**The lesson**: Embedding similarity is necessary but not sufficient for compatibility. If your domain has dealbreakers, hard constraints where incompatibility on a single dimension overrides overall similarity, you need structured signal extraction on top.\n\n**What I did instead**¬†(brief summary):\n\n1. Extracted 26 structured features from natural AI conversations (not surveys, 30% survey completion vs 85% conversational extraction)\n2. Built distance matrices: nuanced compatibility scores (0.0-1.0) instead of binary match/no-match\n3. Added hard filters: 4 dealbreaker features that reject pairs before scoring, zero exceptions\n4. Combined signals:¬†`0.25 √ó text + 0.15 √ó visual + 0.60 √ó features`\n\n22% to 35% with this. Two more stages (personalized weights + bidirectional matching) took it to 68%.\n\nThis generalizes beyond dating; job matching (remote vs on-site is a dealbreaker regardless of skill similarity), marketplace matching (budget overrides preference), probably others.\n\nHas anyone else hit this wall with embeddings? Curious how others handle the structured-vs-semantic tradeoff.\n\nEdit:\nI know how training a biencoder on pairwise data would help, but mining hard negatives in such cases becomes a key challenge and also loses bidirectional non equivalence of liking one another ",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o36ijqm",
          "author": "-Cubie-",
          "text": "If you want a different definition of similarity, then you should finetune your embedding model.\nThe finetuning docs for sentence transformers has a similar example as you, where different systems might consider a certain pair of texts very similar or very dissimilar: https://sbert.net/docs/sentence_transformer/training_overview.html",
          "score": 19,
          "created_utc": "2026-02-02 16:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36m0mf",
              "author": "Ok_Promise_9470",
              "text": "I agree thats a fair point, finetuning on accept/reject pairs would definitely improve retrieval quality and it's something we've considered for the candidate generation step (the Pinecone layer, and finetuning is in progress). The reason we added structured features on top is that even a perfect embedding can't handle three things: \n\n(1) hard dealbreakers that should veto an otherwise-great match, \n\n(2) asymmetric scoring where A‚ÜíB ‚â† B‚ÜíA because users weight features differently, and \n\n(3) interpretability for the feedback loop. \n\nThe embedding narrows 10K users to 10 candidates, the structured layer decides which of those 10 actually has mutual potential.",
              "score": 4,
              "created_utc": "2026-02-02 16:54:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37u6y0",
                  "author": "saw79",
                  "text": "You know more than I do here, so correct me where I'm wrong. But your reasoning doesn't strike me as quite right:\n\n1) Shouldn't hard dealbreakers make the model reduce the cosine similarity significantly? Isn't this an embedding problem? A bad embedding doesn't mean embeddings are bad.\n\n2) I understand that how person A feels about person B doesn't have to match how person B feels about person A, but that isn't what you're trying to estimate. You're trying to estimate the compatibility between A and B, which in my mind IS symmetric. \"are A and B compatible?\" should give the same answer as \"are B and A compatible?\".\n\n3) fair enough :)",
                  "score": 2,
                  "created_utc": "2026-02-02 20:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o377qoo",
          "author": "youniquest",
          "text": "Interesting discussion but the title is misleading. It's not cosine similarity that is failing but rather the embeddings or vector representations of your input. If you have hard dealbreakers another simple approach could be adding a new dimension where two sides of deals breakers have negative values of each other with appropriate weights depending on how important those deal breakers for the user.",
          "score": 7,
          "created_utc": "2026-02-02 18:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37id9k",
              "author": "Ok_Promise_9470",
              "text": "1. We didnt have that data (dealbreakers) at the start - had to be mined\n2. We need to have a cold start approach to solving it,\n \nso making such simpler approaches only makes sense with the assumption that i have every data point for each user at the start itself, the easiest way to filter similar users was using a user description that we generated post user on-boarding, and that did contain dealbreakers for some but for others it had to be mined using post date feedbacks. Then we used this summary (which kept updating), we used off the shelf pretrained embeddings to start with to do initial filtering of users for finding suitable match (not the best of the methods I agree) but thats where we started",
              "score": 1,
              "created_utc": "2026-02-02 19:21:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38d11p",
              "author": "Substantial_Oil_7421",
              "text": "I agree with this. Your post is interesting but misleading - cosine similarity is not at fault here, the input is. You got a high score because of common tokens; it won‚Äôt pick up the nuance or semantic meaning well.\n\nAlso saw your Substack post and quite frankly, calling things ‚Äúthe embedding trap‚Äù is just a poor choice of words. You can fool a generalist or a strategy person with this kind of fluff but experienced data scientists will catch it quite easily. Didn‚Äôt read beyond that heading",
              "score": 1,
              "created_utc": "2026-02-02 21:46:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38k0l7",
                  "author": "unlikely_ending",
                  "text": "Too harsh\n\nDon't assume bad faith",
                  "score": 1,
                  "created_utc": "2026-02-02 22:20:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o39cuxn",
                  "author": "Ok_Promise_9470",
                  "text": "I can understand your frustration here, but the reason I was talking about cosine similarity is because of the following reasons\n1) model isn't finetuned on dating data of personal\n2) it is a cold start problem so taking off the shelf models seems like a fair choice initially hence the embedding trap\n3) even finetuned embeddings can get you the right top 10 I.e improve your recall over the search space but at the end you need a reranker that views each user differently \n4) reducing it to just 1 number throws interpretability out of the window\n\n\nI hope these make sense to you, as these ate some points I have further focused on in the substack article",
                  "score": 1,
                  "created_utc": "2026-02-03 00:54:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36nh6w",
          "author": "No-Square8182",
          "text": "The stable marriage problem has non ML algos that should be employed once you get the scores. The problem is model choice. Semantic dot product is not strong enough. I think training a deep NN of person 1 features against peron 2 features labeled with match or not to output compatibility score is a good aproach. That way you dont need hard rules of fundamental incompatibility that are perhaps not fully statistically viable. I think there is a danger of modeling the probability of a match as independent probabilities from both sides, it is a strong assumption to make.",
          "score": 5,
          "created_utc": "2026-02-02 17:00:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36qg3m",
              "author": "Ok_Promise_9470",
              "text": "Yeah we are attempting to create KGs of features and represent users as subgraphs and then using sub graph embeddings to model pairwise compatibility",
              "score": 2,
              "created_utc": "2026-02-02 17:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36mnms",
          "author": "Thick-Protection-458",
          "text": "Well, similar topic makes similar embeddings with default embedder. Who could know.\n\n\nAnyway still can be useful as a preliminary filter before smarter approach.\n\n\nAlso, did you tried finetune embber? Like make sure it, instead of placing them close because of being mentioned in similar context - place such dealbreaker phrases far?",
          "score": 5,
          "created_utc": "2026-02-02 16:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36nmdf",
              "author": "Ok_Promise_9470",
              "text": "Yeah, as we progress and get more data on mutual matches then there'd be enough data to train the biencoder. Thats the plan, however mining hard negatives is still a big challenge",
              "score": 2,
              "created_utc": "2026-02-02 17:01:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36f88e",
          "author": "hc_fella",
          "text": "A post on smarter LLM embeddings could be interesting, but both the Reddit and Substack post reek of AI generated slop... If you want me to read your stuff, at least put in the effort of writing the posts yourself...",
          "score": 12,
          "created_utc": "2026-02-02 16:23:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36hnky",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -4,
              "created_utc": "2026-02-02 16:34:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36nrqs",
                  "author": "theGamer2K",
                  "text": "Don't want to read the vomit worthy AI writeup. Doesn't matter if you \"only used AI to clean up and format\". It sounds like the average AI slop post on LinkedIn.",
                  "score": 3,
                  "created_utc": "2026-02-02 17:02:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36ozri",
          "author": "Few_Detail9288",
          "text": "Ai slop",
          "score": 7,
          "created_utc": "2026-02-02 17:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37fxoe",
          "author": "PM_ME_CALC_HW",
          "text": "Why use cosine similarity with nominal data? Forget about NN and other fancy things for a moment. What's the justification?",
          "score": 2,
          "created_utc": "2026-02-02 19:10:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37hcfe",
              "author": "Ok_Promise_9470",
              "text": "The on-boarding data was conversational data between our AI and the user, it was not meant to feel like filling a survey, hence its not nominal in its nature",
              "score": 1,
              "created_utc": "2026-02-02 19:16:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37o3tl",
                  "author": "PM_ME_CALC_HW",
                  "text": "Excuse my ignorance, but why not have them fill out a profile?",
                  "score": 2,
                  "created_utc": "2026-02-02 19:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35y95x",
          "author": "Ok_Promise_9470",
          "text": "I wrote up the full four-stage journey if anyone wants the details: [https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want](https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want)",
          "score": -3,
          "created_utc": "2026-02-02 15:02:13",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qttx04",
      "title": "Why I Decided to Learn Machine Learning First",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/80e41bi6t2hg1.jpeg",
      "author": "Visible-Ad-2482",
      "created_utc": "2026-02-02 12:37:59",
      "score": 31,
      "num_comments": 5,
      "upvote_ratio": 0.68,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qttx04/why_i_decided_to_learn_machine_learning_first/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o36rwbj",
          "author": "Farkler3000",
          "text": "And yet you write the post with AI",
          "score": 7,
          "created_utc": "2026-02-02 17:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36k1s7",
          "author": "Stochastic_berserker",
          "text": "Disingenious post",
          "score": 5,
          "created_utc": "2026-02-02 16:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39bjxp",
          "author": "L33t_Cyborg",
          "text": "I‚Äôd be embarrassed if I created this post ngl",
          "score": 3,
          "created_utc": "2026-02-03 00:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39qc99",
          "author": "seltkirk-",
          "text": "Stats & probability too.",
          "score": 1,
          "created_utc": "2026-02-03 02:11:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39x6v4",
          "author": "mystical-wizard",
          "text": "And those things are just math under the hood, which is just philosophy under the hood, which is just‚Ä¶.",
          "score": 1,
          "created_utc": "2026-02-03 02:50:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsz2my",
      "title": "Hey guys I need help",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/jgwktena2wgg1.jpeg",
      "author": "Dark_lightxy",
      "created_utc": "2026-02-01 13:55:13",
      "score": 28,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qsz2my/hey_guys_i_need_help/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o32emhm",
          "author": "seraphius",
          "text": "If you really want to get into deep learning faster 1-4 followed 9-17 seems like it would work without you missing anything foundational. However, I would recommend that you revisit the other things later if you plan to do this as a career (more tools in your toolbag).",
          "score": 2,
          "created_utc": "2026-02-02 00:07:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33pizs",
              "author": "Dark_lightxy",
              "text": "Sounds good, thank you",
              "score": 2,
              "created_utc": "2026-02-02 04:41:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpgvve",
      "title": "Free Guide: Build a Simple Deep Learning Library from Scratch",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qpgvve/free_guide_build_a_simple_deep_learning_library/",
      "author": "MXXMM001",
      "created_utc": "2026-01-28 16:56:25",
      "score": 22,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "I found this free guide that walks through building a simple deep learning library from scratch using just NumPy. It starts from a blank file and takes you all the way to a functional autograd engine and a set of layer modules, ending with training on MNIST, a simple CNN, and even a basic ResNet.\n\nBut Numpy does the heavy lifting mostly, so nothing GPU serious!! \n\nLink : [https://zekcrates.quarto.pub/deep-learning-library/](https://zekcrates.quarto.pub/deep-learning-library/) \n\n  \nWould love to hear if anyone has tried it or knows similar resources!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qpgvve/free_guide_build_a_simple_deep_learning_library/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2d4dr3",
          "author": "mandevillelove",
          "text": "Looks like a great hands on way to really understand deep learning basics.",
          "score": 1,
          "created_utc": "2026-01-29 06:00:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}