{
  "metadata": {
    "last_updated": "2026-02-01 16:49:57",
    "time_filter": "week",
    "subreddit": "learnmachinelearning",
    "total_items": 20,
    "total_comments": 172,
    "file_size_bytes": 166953
  },
  "items": [
    {
      "id": "1qmot37",
      "title": "I made a Python library for Graph Neural Networks (GNNs) on geospatial data",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qmot37",
      "author": "Tough_Ad_6598",
      "created_utc": "2026-01-25 17:07:58",
      "score": 624,
      "num_comments": 31,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qmot37/i_made_a_python_library_for_graph_neural_networks/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1ng8hy",
          "author": "lazystylediffuse",
          "text": "This is really cool",
          "score": 18,
          "created_utc": "2026-01-25 17:18:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1p6due",
          "author": "Marty_Br",
          "text": "Is that Barcelona?",
          "score": 12,
          "created_utc": "2026-01-25 21:45:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1pcstb",
              "author": "Tough_Ad_6598",
              "text": "Yes, Eixample!",
              "score": 7,
              "created_utc": "2026-01-25 22:13:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1pnwez",
                  "author": "qweetpal",
                  "text": "Spotted at first sight !",
                  "score": 3,
                  "created_utc": "2026-01-25 23:02:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1qhsyx",
                  "author": "Marty_Br",
                  "text": "Those blocks are hard to mistake. Nicely done.",
                  "score": 3,
                  "created_utc": "2026-01-26 01:28:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1t7ddy",
          "author": "AncientCup1633",
          "text": "Is it possible to create a dataset with it and then use that dataset to train ml models to find the optimal setup and roots for traffic lights and to optimize transport?",
          "score": 8,
          "created_utc": "2026-01-26 13:01:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1te7xm",
              "author": "Tough_Ad_6598",
              "text": "Yes, it's exactly one of the primary use cases!",
              "score": 4,
              "created_utc": "2026-01-26 13:41:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1tq9ks",
                  "author": "SubstantialPay2869",
                  "text": "Lol this is gonna sound weird but I built a similar visualization tool for exactly this last year (just loop detectors with distance adj, so nothing fancy) on a real dataset with different stgnns for viewing traffic patterns and model predictions",
                  "score": 2,
                  "created_utc": "2026-01-26 14:43:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1nmibw",
          "author": "SuitOk4758",
          "text": "excellent work!",
          "score": 3,
          "created_utc": "2026-01-25 17:45:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ny59o",
          "author": "isogonal-conjugate",
          "text": "Amazing!",
          "score": 3,
          "created_utc": "2026-01-25 18:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1o75vw",
          "author": "tusharthakur210902",
          "text": "How much time did it take?",
          "score": 3,
          "created_utc": "2026-01-25 19:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o997y",
              "author": "Tough_Ad_6598",
              "text": "It took roughly 6 months to prepare for all the targeted domains of graph construction!",
              "score": 5,
              "created_utc": "2026-01-25 19:19:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ts0wv",
                  "author": "Letzbluntandbong",
                  "text": "Six months is a solid chunk of time! Did you face any major hurdles along the way?",
                  "score": 2,
                  "created_utc": "2026-01-26 14:51:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1oi7p0",
          "author": "Delicious-Couple-947",
          "text": "Amazing!",
          "score": 3,
          "created_utc": "2026-01-25 19:59:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1oplyq",
          "author": "RJSabouhi",
          "text": "Looks like cellular automata at points. Wild.",
          "score": 3,
          "created_utc": "2026-01-25 20:32:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1optia",
          "author": "Ok-Blacksmith6403",
          "text": "Congratulations üëè excellent work",
          "score": 3,
          "created_utc": "2026-01-25 20:33:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qw7es",
          "author": "secondhand_goulash",
          "text": "Great eixample of GNNs",
          "score": 3,
          "created_utc": "2026-01-26 02:41:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ti2rr",
          "author": "okbro_9",
          "text": "Looks cool!",
          "score": 2,
          "created_utc": "2026-01-26 14:01:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1tqb1f",
          "author": "rog-uk",
          "text": "This might be a silly question, but I wonder if there would be any way to bring in Google maps data with traffic live, or historical, congestion?",
          "score": 2,
          "created_utc": "2026-01-26 14:43:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1tqvsk",
              "author": "Tough_Ad_6598",
              "text": "In principle, they close most of the dataset. That‚Äôs why open data would be beneficial like OpenStreetMap, Overture Maps, or transport schedule in GTFS format provided by local governments, etc.",
              "score": 2,
              "created_utc": "2026-01-26 14:46:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ts6b7",
                  "author": "rog-uk",
                  "text": "Thanks for the reply. Once could imagine your work contributing to city wide *coordinated* traffic planning, on a Journey by journey level, but that would require a lot of buy-in, however being able to suggest optimal routes and travel times would be an interesting opportunity - maybe one for if we ever get truly self driving cars.",
                  "score": 2,
                  "created_utc": "2026-01-26 14:52:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ueifc",
          "author": "wwwdotlk",
          "text": "It cool üëçüéâÔ∏è",
          "score": 2,
          "created_utc": "2026-01-26 16:31:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1xik8u",
          "author": "Substantial_Oil_7421",
          "text": "Really cool! I was curious about a few things:\n1/ Which modules were more difficult to build and why?¬†\n\n2/ how much help did you take from ChatGPT/gemini etc. - which tasks did they do well and where did they fail?\n\n3/ I‚Äôve been following DuckDB for a while and while their projection conversion is not straightforward, other operations can be faster than geopandas. Have you explored this bit? Any thoughts on potentially replacing geopandas with other tools/libraries?¬†\n\nFinally, congrats! I‚Äôll definitely dig deeper into the code next month because this is high value stuff you‚Äôve built¬†",
          "score": 2,
          "created_utc": "2026-01-27 01:00:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1xvor8",
              "author": "Tough_Ad_6598",
              "text": "Thanks!! I think the proximity module took loads of time and was the toughest, as it has standardised functionalities of distance metrics (L1, L2, and network distance). \n\nI mainly wrote the modules first and AI was used for refactoring to make them computationally efficient and readable. But, the very initial ideas (and passion) cannot be generated by AI.\n\nFor the scalability, it will support GraphQL-based solution in the future, like neo4j. The direction would be confirmed once the use cases are piled:)\n\nI‚Äôm always happy to have collaborators, so feel free to give comments and PR on the repo anytime!!",
              "score": 5,
              "created_utc": "2026-01-27 02:11:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1y1alg",
                  "author": "Substantial_Oil_7421",
                  "text": "Will do once I check it out thoroughly. Thanks for providing those details!¬†",
                  "score": 2,
                  "created_utc": "2026-01-27 02:42:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1sx1io",
          "author": "Money-Desperated",
          "text": "May i guess, Are you Yuta Sato?",
          "score": 0,
          "created_utc": "2026-01-26 11:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1teaho",
              "author": "Tough_Ad_6598",
              "text": "Right I'm the maintainer:)",
              "score": 1,
              "created_utc": "2026-01-26 13:41:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1tqpp3",
                  "author": "TMHDD_TMBHK",
                  "text": "mad doxx",
                  "score": 2,
                  "created_utc": "2026-01-26 14:45:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qpnlml",
      "title": "ML research papers to Code",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/dp397ckwk5gg1",
      "author": "Big-Stick4446",
      "created_utc": "2026-01-28 20:51:33",
      "score": 256,
      "num_comments": 26,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qpnlml/ml_research_papers_to_code/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2gact8",
          "author": "dutchpsychologist",
          "text": "Tried it a bit and I love it! Has amazing potential. Love the visualization. It's brilliant.org meets leetcode for machine learning. Very nice.",
          "score": 9,
          "created_utc": "2026-01-29 18:03:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ggmwd",
              "author": "Big-Stick4446",
              "text": "thankyou! any particular feedback?",
              "score": 4,
              "created_utc": "2026-01-29 18:31:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2gjm3l",
                  "author": "dutchpsychologist",
                  "text": "Personally, I think the theory parts could be more chunked into smaller steps. That would make it even more attractive to me and makes it easier to keep focused on the information given.",
                  "score": 3,
                  "created_utc": "2026-01-29 18:45:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2adoel",
          "author": "Big-Stick4446",
          "text": "[Tensortonic](https://tensortonic.com)\n\nhere's the link",
          "score": 7,
          "created_utc": "2026-01-28 21:02:16",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2d1ilh",
          "author": "Inevitable-Opening61",
          "text": "About to start my ML job and this is perfect for getting a refresher and preparing for the job. Thank you!",
          "score": 8,
          "created_utc": "2026-01-29 05:38:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ffdtq",
          "author": "Longjumping-Bag-7976",
          "text": "Love this idea, i'm gonna use this",
          "score": 3,
          "created_utc": "2026-01-29 15:45:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fiizq",
          "author": "TheSpaceCaptain1106",
          "text": "Such a cool idea!",
          "score": 3,
          "created_utc": "2026-01-29 15:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2cx8p0",
          "author": "dommycaste",
          "text": "I looked all over if there is a paid tier. Is this actually completely free?\n\nAlso I noticed that the math part has problems + lessons to learn the math. The research part has problems only, but no lessons. I assume you're working on that?",
          "score": 2,
          "created_utc": "2026-01-29 05:08:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dcgwp",
              "author": "Big-Stick4446",
              "text": "currently free. yes, more content is coming.",
              "score": 8,
              "created_utc": "2026-01-29 07:06:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2j6d4i",
                  "author": "ash4reddit",
                  "text": "What‚Äôs your bus model?",
                  "score": 1,
                  "created_utc": "2026-01-30 02:46:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2eia4s",
          "author": "One_Citron_4350",
          "text": "Looks pretty interesting. Congrats!",
          "score": 2,
          "created_utc": "2026-01-29 12:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2f1tdt",
          "author": "Ndirangu7",
          "text": "Amazing stuff!",
          "score": 2,
          "created_utc": "2026-01-29 14:41:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2j4886",
          "author": "here4CHAOS-cn8",
          "text": "I've been using it for like 5-6 days, even recommended it to friends and they're loving it too. You're doing good work, keep it up",
          "score": 2,
          "created_utc": "2026-01-30 02:35:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jfchg",
              "author": "Big-Stick4446",
              "text": "thankyou! any particular feedback?",
              "score": 1,
              "created_utc": "2026-01-30 03:37:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2jz5jx",
          "author": "Human-Computer4161",
          "text": "Crazyyyyy",
          "score": 2,
          "created_utc": "2026-01-30 05:47:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kap4y",
          "author": "-_-johnwick-_-",
          "text": "Sickkk!!!! Thanks for sharing.",
          "score": 1,
          "created_utc": "2026-01-30 07:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lgjaa",
          "author": "Any_Mobile2714",
          "text": "Is there a way to upload problems yourself?",
          "score": 1,
          "created_utc": "2026-01-30 13:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mt28d",
          "author": "ArtAccomplished6466",
          "text": "This is a awesome platform, and I am loving this so far, my only problem is this could get locked behind a subscription model !\n\nMay be OP, if you want any help with your platform, please let me know, I can contribute to the platform (building and problems).",
          "score": 1,
          "created_utc": "2026-01-30 16:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2q27fx",
          "author": "bezdazen",
          "text": "This is fantastic stuff and thanks for sharing and making it free!\n\nDo you mind if I give you a few suggestions? There are some things that give a 'rough around the edges\" feel. \n\nWhen you enter a problem, there is a left and right panel. Right has the code, and left has some interactive widgets mixed into markdown (mdx?). The markdown is not very well styled. The sizes of the fonts in the widgets and even in equations is noticeably larger than in the rendered markdown text. I would suggest making the font size larger for the explanatory text (markdown text). Indentation is lacking. \n\nJust off the bat, here is some things I would do:\n\n- Increase font size a tiny bit for the content (not the widget)\n\n- Change the `p-4` in `p-4 overflow-auto text-sm leading-6 text-zinc-200 flex-1` to `p-8`. Or better yet, set `max-w` on the content to be better suited to the font size. <- The latter would be better for wide and less wide screens (than changing padding).  \n\n- Change the padding of the panel header (tabs) to match: `px-4` -> `px-8` or set max-w to be the same as the header \n\n- Make the `:r1u:` data panel have scrollbars that are styled the same as the scrollbar for the code editor in the right panel.  \n\n- Increase margins for markdown block elements (lists, quote, etc).  \n\n- Increase left & right padding for code blocks (`<pre>` elements)\n\nWidgets look great!\n\nAs far as content goes, my only suggestion is to start users off in a intro/starting page when they go to the ML Research and ML Math page. It could give you the opportunity to give some general background, at timeline of these papers, a suggested/recommended path for the users to follow, etc.\n\nLastly, I dont know if its just on my end, but I am getting a bunch of errors in the console. App still seems to work though!\n\nThis is an amazing effort! And a killer resource.",
          "score": 1,
          "created_utc": "2026-01-31 02:42:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2cnk4c",
          "author": "CriticalTemperature1",
          "text": "Love this idea! I wonder what stops someone from just copying code from somewhere else here?",
          "score": 1,
          "created_utc": "2026-01-29 04:04:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2lcshw",
              "author": "Turbulent-Log5758",
              "text": "The question is, why would someone paste code here?",
              "score": 1,
              "created_utc": "2026-01-30 12:40:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ad3au",
          "author": "GamingWithShaurya_YT",
          "text": "crazy! will check it out",
          "score": 1,
          "created_utc": "2026-01-28 20:59:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qnqvem",
      "title": "Perplexity CEO just followed my app/project on twitter",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/ifl4ob6p0rfg1.jpeg",
      "author": "Big-Stick4446",
      "created_utc": "2026-01-26 19:53:13",
      "score": 215,
      "num_comments": 18,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qnqvem/perplexity_ceo_just_followed_my_appproject_on/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1y0q7v",
          "author": "[deleted]",
          "text": "Why are we advertising here?",
          "score": 57,
          "created_utc": "2026-01-27 02:39:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o200p8o",
              "author": "Imperial_Squid",
              "text": "You must be new here, a good proportion of the posts are people advertising their own courses/platforms/whatever ü§∑üôÉ",
              "score": 21,
              "created_utc": "2026-01-27 11:49:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1y1w0z",
          "author": "nbo10",
          "text": "Hey Jamie, put that into our sponsor Perplexity.... ask it, \"Does the perplexity CEO follow TensorTonic?\"",
          "score": 14,
          "created_utc": "2026-01-27 02:45:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1w30jw",
          "author": "Zerothe000",
          "text": "Hey, what‚Äôs your project on?",
          "score": 9,
          "created_utc": "2026-01-26 20:52:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1w5cti",
              "author": "Big-Stick4446",
              "text": "i made leetcode for ML",
              "score": 24,
              "created_utc": "2026-01-26 21:02:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1x8w73",
                  "author": "SadInfluence",
                  "text": "so i learned a lot of coding my simply solving many algorithms questions. can one do the same for ML with your platform? are there problem lists?",
                  "score": 8,
                  "created_utc": "2026-01-27 00:10:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1woj7u",
          "author": "Substantial_Oil_7421",
          "text": "My man needs some interview practice for ML rounds¬†",
          "score": 6,
          "created_utc": "2026-01-26 22:28:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1w4grm",
          "author": "florinandrei",
          "text": "*\"Notice me, sensei!\"*",
          "score": 5,
          "created_utc": "2026-01-26 20:58:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o20m7cm",
          "author": "Expensive_Fun4346",
          "text": "step #1: open powerpoint\n\nstep #2:  make two slides, \"What is TensorTonic?\"  \"Who is the Team\"\n\nstep #3:  add third slide w/ screenshot of @aravsrinivas following @tensortonic project\n\nstep #4:  raise $1.7 B from VCs",
          "score": 2,
          "created_utc": "2026-01-27 14:01:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2511q6",
          "author": "dikiprawisuda",
          "text": "Tensortonic is actually good. What framework did you use for animation if I might ask? Do you plan to make this open-source?",
          "score": 1,
          "created_utc": "2026-01-28 02:21:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1wa5ar",
          "author": "RealSataan",
          "text": "Link it here",
          "score": 1,
          "created_utc": "2026-01-26 21:23:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wagst",
              "author": "Big-Stick4446",
              "text": "[Tensortonic](https://tensortonic.com)",
              "score": 0,
              "created_utc": "2026-01-26 21:25:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1z4qr2",
          "author": "infinty1729",
          "text": "I'm using it and it is really an awesome platform to practice",
          "score": 1,
          "created_utc": "2026-01-27 07:06:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1yh1md",
          "author": "undefined06",
          "text": "Good project! Hope it age well",
          "score": -1,
          "created_utc": "2026-01-27 04:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ypmgd",
          "author": "droid786",
          "text": "Its pretty sick project man, ngl. You can try to advertise the leaderboard to companies and get some finder fees(for ML talent) from them",
          "score": -2,
          "created_utc": "2026-01-27 05:09:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qmpvox",
      "title": "Math + ML",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/svd3au4r8jfg1.png",
      "author": "Friendly-Youth-3856",
      "created_utc": "2026-01-25 17:47:01",
      "score": 190,
      "num_comments": 20,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qmpvox/math_ml/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1r7duz",
          "author": "ackermen_",
          "text": " where does it starts first ?",
          "score": 7,
          "created_utc": "2026-01-26 03:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1rnrdo",
              "author": "Friendly-Youth-3856",
              "text": "I will be starting from Linear Algebra by Gilbert Strang",
              "score": 4,
              "created_utc": "2026-01-26 05:27:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1rbmfm",
          "author": "15jorada",
          "text": "I think it makes sense. You might want to throw in some more probability and statistics.",
          "score": 6,
          "created_utc": "2026-01-26 04:07:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ro12u",
              "author": "Friendly-Youth-3856",
              "text": "There is some statistics....and ig probability and statistics would be taught together.....Can you pls tell what can i follow for it ?",
              "score": 2,
              "created_utc": "2026-01-26 05:28:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1rzak1",
                  "author": "15jorada",
                  "text": "So Probability theory: the logic of science by E.T Jaynes, is good for getting a decent intuition of the whys of probability while not going too heavy on proofs so I recommend that.",
                  "score": 4,
                  "created_utc": "2026-01-26 06:54:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1shtro",
          "author": "RohitGi",
          "text": "If I am not wrong, the pre-reqs for MIT 18.06 Linear Algebra is multivariable calculus and the pre-reqs for that (obviously) is 18.01 single variable calculus. So, I think it's best to design the roadmap keeping the pre-reqs in mind (finishing them first and following what comes after), so the learning gets more structured and you don't have to stuggle that much in the journey.",
          "score": 5,
          "created_utc": "2026-01-26 09:37:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1si9nb",
              "author": "Friendly-Youth-3856",
              "text": "so i should do 18.01 -> 18.02 -> 18.06 .... will keep it in mind!",
              "score": 1,
              "created_utc": "2026-01-26 09:41:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vrezr",
          "author": "theeeiceman",
          "text": "Ok kinda late and kinda long but here‚Äôs my take\n\n- Intro to Higher Math is essential. This is intro to logic and proof writing. Would go after diff eqs + calc, def before any analysis classes.\n\n- DS&A should go after Linear algebra, sooner rather than later. Ideally in Python. \n\n- Stats should be way earlier. Would put after calc, diff eqs and higher math. Would also add Bayesian stats or stochastics after stats.\n\n- I‚Äôd add regression after linear algebra/ calc and before ML.\n\n- ML shouldn‚Äôt be until after the stats and regression classes if you add them\n\n- i don‚Äôt think you need a whole ML theory class. I think you‚Äôll get enough on that between regular ML, DL, RL and all the stats leading up to it. \n\n- I took real analysis then numerical analysis after higher math. I never took complex analysis, abstract algebra or topology, but since you have RA at the bottom, Id consult a pure math person about ordering those. \n\n- I never took CV and I didnt need it for NLP. So I think you can move NLP up if you‚Äôd like.\n\n- everything below reinforcement I think is overkill, a reasonably up to date NLP class should cover what you need to know there. \n\n- I think Reinforcement could be moved up to around Deep Learning. I never took pure RL so idk how involved neural nets are, but I didn‚Äôt need more than the jist of RL for NLP. That might depend on if the ML class touches on RL or not. \n\nJust my opinions from my undergrad + grad experience",
          "score": 4,
          "created_utc": "2026-01-26 20:00:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o266gd8",
              "author": "Friendly-Youth-3856",
              "text": "Thanks a lot for you time !!..... I will keep this in mind !.... I have been doing dsa (competitive programming) on codeforces but i am doing this in cpp",
              "score": 1,
              "created_utc": "2026-01-28 06:42:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1sgwo9",
          "author": "n0obmaster699",
          "text": "Artin is better than dummitfoote. Dummitfoote can be too terse.",
          "score": 3,
          "created_utc": "2026-01-26 09:28:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1shc7o",
              "author": "Friendly-Youth-3856",
              "text": "ohhkayy....thanks for the feedback ! will be doing artin then !",
              "score": 2,
              "created_utc": "2026-01-26 09:32:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1rvt7j",
          "author": "Admirable_Trick5588",
          "text": "As somone who's a noob this looks nice I'll be following this too, thanks op!",
          "score": 2,
          "created_utc": "2026-01-26 06:26:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1rw5zg",
              "author": "Friendly-Youth-3856",
              "text": "I am a noob myself !! All the best !! lfg",
              "score": 2,
              "created_utc": "2026-01-26 06:29:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yx7en",
          "author": "ObfuscatedSource",
          "text": "It's certainly quite a lot!\n\nPersonally, I would split it into 4 main sequences to be studied at the same time:\n\nCS/ML, Algebra, Analysis, Misc.\n\nI don't know much about the courses, but going off the texts, the analysis sequence you have is rather unusual. Usually, you have spivak -> abbott -> rudin--though as a matter of taste, I would use tao rather than abbott. Complex analysis isn't really necessary for ML, but if you want the completeness, you should be putting it after real analysis, despite it being \"more well-behaved\". I would also recommend splitting up the algebra sequence, with at least something like \"A First Course in Abstract Algebra\" by John B. Fraleigh before D&F.\n\nYou will want to at least have gone through abbott + most of D&F before starting topology, as it builds the motivation (and covers the basics) for point-set topology.\n\nStats should be handled much earlier... and I recommend prefacing it with some kind probabilities work.\n\nLastly, I'm not sure how much CS background you have, but if it's not a lot, I recommend more CS groundwork before diving straight into ML. Theory of computation, data structures & algorithms, etc.",
          "score": 2,
          "created_utc": "2026-01-27 06:05:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o266xzs",
              "author": "Friendly-Youth-3856",
              "text": "Ohhkay....thanks !!.... So should i start with calc -> linear -> Probability -> Stats ....or something like that . I am doing DSA (comeptitive programming) in cpp .",
              "score": 1,
              "created_utc": "2026-01-28 06:46:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2a8kr4",
                  "author": "ObfuscatedSource",
                  "text": "Usually you wouldn't do them in such strict succession, since they are frequently mutually required. It would be like trying to completely walk up a flight of stairs with your right leg first, then your left leg. Either your legs are ridiculously long or the stairs are comically short.\n\n\n\nI recommend you to map out the prerequisites first, then approach how you want to study it. Many things can be moved around, but you need to get a sense of what knowledge depends on what before trying to commit to a strict ordering. \n\n\n\nIf you want to be efficient with time and have a regular background, undergrad curricula aren't too far off. A common set of courses for Math + CS in the first year is: differential & integral calculus, intro linear algebra, elementary probability, intro discrete mathematics, and intro predicate logic.",
                  "score": 3,
                  "created_utc": "2026-01-28 20:40:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2uu26s",
          "author": "Categorically_",
          "text": "LOL reading Dummit and Foote for algebra while reading Stephen Abbott for analysis.",
          "score": 1,
          "created_utc": "2026-01-31 21:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2uubtk",
          "author": "Categorically_",
          "text": "Some of this choices are hilarious. Dummit and Foote is basically a year long sequence for math phd students. You don't need anywhere near this much algebra to do ML. If anything, dig deeper in analysis, Abbott is very basic.",
          "score": 1,
          "created_utc": "2026-01-31 21:06:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qot7q5",
      "title": "[Project] Reached 96.0% accuracy on CIFAR-10 from scratch using a custom ResNet-9 (No pre-training)",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/qwfza5wcxyfg1.png",
      "author": "Distinct-Figure2957",
      "created_utc": "2026-01-27 22:42:10",
      "score": 128,
      "num_comments": 37,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qot7q5/project_reached_960_accuracy_on_cifar10_from/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o28etvn",
          "author": "auto_mata",
          "text": "you didn‚Äôt have a proper train/val/test split and you wrote the post with an llm‚Ä¶ I get being excited about ml but this is not a good post for a learning machine learning subreddit. Lacks the most basic rigor",
          "score": 62,
          "created_utc": "2026-01-28 15:53:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dw6nu",
              "author": "Distinct-Figure2957",
              "text": "I'm not fully fluent in english so I used LLM to reformulate and be sure it's clear and understandable. I can assure you the ideas are mine.   \n  \nI have a very clearly separated train/test split, my model is only trained on training data. I didn't use a validation set beacause I didn't know I was gonna use advanced TTA when I trained my model, and my grid search was only to calibrate just 3 hyperparameters.\n\nThis is my first ML project I was happy to share, please be carefull before raging on a project you don't even know.",
              "score": -3,
              "created_utc": "2026-01-29 10:07:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2ndpnk",
                  "author": "auto_mata",
                  "text": "I understand being excited! I really do! I would suggest starting from very basic fundamentals and working up from there. There are some very clear violations of rigor here, but that‚Äôs not a bad thing it‚Äôs a learning experience. \n\nWork on very very basic things, like linear regression, logistic regression, perceptions, basic FFNN, THEN start moving to advanced projects and topics. Try not to use LLMs while you are first learning ‚Äî ml is a topic which builds on itself over and over, and if you let stuff slip by while you‚Äôre learning you‚Äôll be much worse off later on. \n\nbest of luck and keep experimenting man",
                  "score": 1,
                  "created_utc": "2026-01-30 18:29:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o24dof0",
          "author": "Rize92",
          "text": "As you‚Äôre using the test set to inform training process, I would recommend you further split the test into test and holdout. Leave the holdout set out of the training inference entirely and score your final model against that. That will help you demonstrate if your final trained model is truly performing at this level or not. Even though your test set is spit out it‚Äôs still being used for some training guidance and so it not totally separate from training.",
          "score": 58,
          "created_utc": "2026-01-28 00:19:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2if7x8",
              "author": "Extra_Intro_Version",
              "text": "Isn‚Äôt this deep learning 101? Don‚Äôt test on data used for training or validation?",
              "score": 1,
              "created_utc": "2026-01-30 00:17:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2m66ev",
                  "author": "Rize92",
                  "text": "Yes, in fact it is data science/machine learning/statistical learning 101. But not everybody is at the same level of understanding, and the proliferation of coding agents has made it really easy to build models, without an understanding of these concepts. So we should encourage people who are asking for feedback to apply these concepts and improve their understanding.",
                  "score": 1,
                  "created_utc": "2026-01-30 15:15:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o275zin",
              "author": "Moist-Matter5777",
              "text": "Solid point! A holdout set would definitely give a clearer picture of generalization. I‚Äôll keep that in mind for my next experiments. Thanks for the suggestion!",
              "score": -10,
              "created_utc": "2026-01-28 11:51:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o299bko",
                  "author": "GazelleFeisty7749",
                  "text": "im crying bro who are you üò≠üò≠üò≠",
                  "score": 21,
                  "created_utc": "2026-01-28 18:05:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2ih459",
                  "author": "Extra_Intro_Version",
                  "text": "Having test data separate from train / val data is a must do. Not a ‚Äúsuggestion‚Äù. If you aren‚Äôt doing this, everything else you claim to have done is pretty meaningless. \n\nBurying what you did in vague yet sycophantic LLM verbiage isn‚Äôt helping your case, at all. The whole thing comes across as either grossly disingenuous or quackery.",
                  "score": 0,
                  "created_utc": "2026-01-30 00:27:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o285iqe",
          "author": "TourGreat8958",
          "text": "Wait so you didnt use a data split? Was the model evaluated on previously seen data?",
          "score": 16,
          "created_utc": "2026-01-28 15:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dxl6a",
              "author": "Distinct-Figure2957",
              "text": "No not at all. I just used train/test split instead of train/validation/test split which is a bit mor rigourous since I used grid search to calibrate 3 hyperparameters. But my model is only trained using train data.",
              "score": -2,
              "created_utc": "2026-01-29 10:19:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2frdm9",
                  "author": "SongsAboutFracking",
                  "text": "Just to be clear, did you use a hold out set using cross validation to do hyperparameter tuning, or did you use the test dataset to validate each combination of hyperparameters?",
                  "score": 1,
                  "created_utc": "2026-01-29 16:38:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o243r7p",
          "author": "trelco",
          "text": "Can you reproduce this with a setup of train/val/test dataset splits?",
          "score": 30,
          "created_utc": "2026-01-27 23:28:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26jpm2",
              "author": "Distinct-Figure2957",
              "text": "Maybe one day but as said before I belive the difference is negligeable and it's like 10h of training in kaggle, so I prefer keep my GPU quota in other projects.   \n  \nSince the code is open-source, I‚Äôd be interested to see the results if you (or anyone else) decide to fork the repo and run that specific split validation",
              "score": -49,
              "created_utc": "2026-01-28 08:36:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o28lzb0",
                  "author": "trelco",
                  "text": "I more strongly believe that you underly the multiple testing problem.",
                  "score": 15,
                  "created_utc": "2026-01-28 16:24:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2faq9l",
                  "author": "leon_bass",
                  "text": "Telling a whole machine learning subreddit that the difference is negligible is criminal.\n\nYou are using your test split as a validation split to inform your training, therefore you don't know what performance you will get on unseen data",
                  "score": 2,
                  "created_utc": "2026-01-29 15:24:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2b49io",
          "author": "External_Manager6737",
          "text": "\"Lightweight\" training a 6M parameter model on a 60K sample dataset üòÇüòÇüòÇ do you even know what overfitting is?",
          "score": 8,
          "created_utc": "2026-01-28 23:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e4fv5",
              "author": "Distinct-Figure2957",
              "text": "Compare to the very best performing models, it's still \"pretty low\". Aggressive cutout and data augmentation are used to prevent/reduce overfitting.",
              "score": 0,
              "created_utc": "2026-01-29 11:18:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2f8z22",
                  "author": "External_Manager6737",
                  "text": "No it is not, you can get over 90% accuracy with less than 100K parameters on cifar10. What do you think your remaining 5.9M parameters are doing to achieve an extra 5%? üòÇ",
                  "score": 1,
                  "created_utc": "2026-01-29 15:16:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o29dv5d",
          "author": "Ok-Outcome2266",
          "text": "honest take here, CNN (and NN in general) take max advantage of transfer learning. \n\nit makes no sense to train from scratch (unless for academic purposes)",
          "score": 5,
          "created_utc": "2026-01-28 18:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2bz9cf",
          "author": "guachimingos",
          "text": "use test, validation an train sets.",
          "score": 5,
          "created_utc": "2026-01-29 01:46:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o245apo",
          "author": "Sabaj420",
          "text": "confusion matrices that look like this make me very happy for some reason",
          "score": 9,
          "created_utc": "2026-01-27 23:36:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28p0w9",
              "author": "Entire_Ad_6447",
              "text": "Really they fill.me with dread cause I know something has gone wrong.",
              "score": 19,
              "created_utc": "2026-01-28 16:37:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o24sglq",
              "author": "HasFiveVowels",
              "text": "Yea, they really clear things up",
              "score": 5,
              "created_utc": "2026-01-28 01:36:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o296wgx",
          "author": "galvinw",
          "text": "How's it compared to [https://github.com/matthias-wright/cifar10-resnet](https://github.com/matthias-wright/cifar10-resnet)",
          "score": 3,
          "created_utc": "2026-01-28 17:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dzjas",
              "author": "Distinct-Figure2957",
              "text": "My model is a bit larger and is trained for a lot longer with various optimisations, so I hit 96%, which is better than his 92%. But 92% is yet pretty good for this size",
              "score": 1,
              "created_utc": "2026-01-29 10:36:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ccvut",
          "author": "Jaded_Individual_630",
          "text": "More GPT slop for the slop pile. Is this what \"computer science students\" have become?",
          "score": 5,
          "created_utc": "2026-01-29 03:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2d7iol",
          "author": "hyxon4",
          "text": "Slop. Everything.",
          "score": 2,
          "created_utc": "2026-01-29 06:25:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2d4ev4",
          "author": "Eager_Crow",
          "text": "What is the test R2 ?",
          "score": 1,
          "created_utc": "2026-01-29 06:00:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2du3vn",
          "author": "Distinct-Figure2957",
          "text": "TO BE CLEAR FOR EVERYONE:  \nThe model is train using ONLY train data. \n\nThe grid search is just testing a few combinations to find **3** hyperparameters faster. The model already reached¬†**95.80%**¬†with suboptimal standard TTA.",
          "score": 1,
          "created_utc": "2026-01-29 09:48:19",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2lodol",
          "author": "user221272",
          "text": "\"Training on Test set is All You Need\"",
          "score": 1,
          "created_utc": "2026-01-30 13:47:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2og7oa",
          "author": "Rize92",
          "text": "The issue people are having with your responses, is that you are not taking any of their constructive criticism seriously - even though you asked for advice. \n\nI don‚Äôt care if you do it, or don‚Äôt do it. I don‚Äôt care if you realized you made a mistake beforehand or not. I have no reason to care about it. I offered you very generic advice on how to convince people your model generalizes on unseen data. That‚Äôs as far as it goes. You can interpret what you have in whatever way you want. You won‚Äôt convince anybody it works if you aren‚Äôt willing to do it. You also don‚Äôt have to do it, we don‚Äôt care. But you‚Äôre coming across as disingenuous because you asked for feedback and then rejected all of it. You‚Äôre not going to get very far in a career in data science if you can‚Äôt take criticism. We all make mistakes and we all don‚Äôt do things the best way first time. That‚Äôs life.",
          "score": 1,
          "created_utc": "2026-01-30 21:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oruao",
              "author": "Distinct-Figure2957",
              "text": "Sorry if I was a bit aggressive, you're right indeed my goal should be to learn, not to show off what I can do. I was just disappointed because I expected whether positive feedback or people showing things I missed and helping improve even more my model and my knowledge. But instead I felt like people were just throwing away all I did like if it had no value to focus on a small thing I already know was minor and just badly explained in my post. I should probably take a step back from all of this and focus on improving my skills. And for sure next time I won't forget the validation set !",
              "score": 1,
              "created_utc": "2026-01-30 22:23:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr1bpk",
      "title": "Python Crash Course Notebook for Data Engineering",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "author": "analyticsvector-yt",
      "created_utc": "2026-01-30 09:57:41",
      "score": 119,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "Hey everyone! Sometime back, I put together a¬†**crash course on Python**¬†specifically tailored for Data Engineers. I hope you find it useful! I have been a data engineer for¬†**5+ years**¬†and went through various blogs, courses to make sure I cover the essentials along with my own experience.\n\nFeedback and suggestions are always welcome!\n\nüìî¬†**Full Notebook:**¬†[Google Colab](https://colab.research.google.com/drive/1r_MmG8vxxboXQCCoXbk2nxEG9mwCjnNy?usp=sharing)\n\nüé•¬†**Walkthrough Video**¬†(1 hour):¬†[YouTube](https://youtu.be/IJm--UbuSaM)¬†\\- Already has almost¬†**20k views & 99%+ positive ratings**\n\nüí° Topics Covered:\n\n**1. Python Basics**¬†\\- Syntax, variables, loops, and conditionals.\n\n**2. Working with Collections**¬†\\- Lists, dictionaries, tuples, and sets.\n\n**3. File Handling**¬†\\- Reading/writing CSV, JSON, Excel, and Parquet files.\n\n**4. Data Processing**¬†\\- Cleaning, aggregating, and analyzing data with pandas and NumPy.\n\n**5. Numerical Computing**¬†\\- Advanced operations with NumPy for efficient computation.\n\n**6. Date and Time Manipulations**\\- Parsing, formatting, and managing date time data.\n\n**7. APIs and External Data Connections**¬†\\- Fetching data securely and integrating APIs into pipelines.\n\n**8. Object-Oriented Programming (OOP)**¬†\\- Designing modular and reusable code.\n\n**9. Building ETL Pipelines**¬†\\- End-to-end workflows for extracting, transforming, and loading data.\n\n**10. Data Quality and Testing**¬†\\- Using¬†\\`unittest\\`,¬†\\`great\\_expectations\\`, and¬†\\`flake8\\`¬†to ensure clean and robust code.\n\n**11. Creating and Deploying Python Packages**¬†\\- Structuring, building, and distributing Python packages for reusability.\n\n**Note:**¬†I have not considered PySpark in this notebook, I think PySpark in itself deserves a separate notebook!",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2rs7wl",
          "author": "PixelLight",
          "text": "Everything looks really good. I think my main question is why you chose os over pathlib? To my understanding thats a more modern approach",
          "score": 3,
          "created_utc": "2026-01-31 11:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sqzo7",
              "author": "analyticsvector-yt",
              "text": "Agree this was 1.5 years back I will do a updated version soon",
              "score": 2,
              "created_utc": "2026-01-31 15:01:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l0sxn",
          "author": "Ok-Blacksmith6403",
          "text": "Thank you üëç",
          "score": 6,
          "created_utc": "2026-01-30 11:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nfay8",
              "author": "analyticsvector-yt",
              "text": "Glad you found it helpful!",
              "score": 1,
              "created_utc": "2026-01-30 18:36:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pvbi9",
          "author": "bhariLund",
          "text": "Saving this",
          "score": 2,
          "created_utc": "2026-01-31 02:01:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ntwgj",
          "author": "diegoasecas",
          "text": "CUT THE CABLE",
          "score": 1,
          "created_utc": "2026-01-30 19:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ogh4p",
              "author": "Sufficient-Main-4101",
              "text": "LOL",
              "score": 2,
              "created_utc": "2026-01-30 21:28:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2s1i77",
          "author": "Always_Learning_000",
          "text": "Thank you for sharing this!!",
          "score": 1,
          "created_utc": "2026-01-31 12:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sbycb",
          "author": "KGagan1",
          "text": "Thank you",
          "score": 1,
          "created_utc": "2026-01-31 13:35:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m7a50",
          "author": "vanisle_kahuna",
          "text": "Cheers ü•Ç",
          "score": 1,
          "created_utc": "2026-01-30 15:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nf94y",
              "author": "analyticsvector-yt",
              "text": "ü§ù",
              "score": 0,
              "created_utc": "2026-01-30 18:36:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqk5rl",
      "title": "Just finished a high-resolution DFM face model (448px), of the actress elizabeth olsen",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/jo2e45h2mcgg1",
      "author": "Emergency_Pause1678",
      "created_utc": "2026-01-29 20:32:08",
      "score": 94,
      "num_comments": 26,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqk5rl/just_finished_a_highresolution_dfm_face_model/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2j4v23",
          "author": "BigDaddyPrime",
          "text": "The original and swapped kinda looks the same.",
          "score": 103,
          "created_utc": "2026-01-30 02:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l0hxx",
          "author": "ShelZuuz",
          "text": "Does this only work for identical twins?",
          "score": 43,
          "created_utc": "2026-01-30 11:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l2m7z",
              "author": "Emergency_Pause1678",
              "text": "works for al types of faces",
              "score": -3,
              "created_utc": "2026-01-30 11:27:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2m8yiv",
          "author": "peenismane",
          "text": "I honestly don't understand what the purpose of this when left and right just look like the same video",
          "score": 12,
          "created_utc": "2026-01-30 15:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p3opb",
              "author": "peenismane",
              "text": "Like does this generate a model that allows the face input to be anybody's face and they can then \"look like them\" deep fake?",
              "score": 2,
              "created_utc": "2026-01-30 23:25:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kdvi6",
          "author": "genserismyname",
          "text": "who does this serve purpose? genuinely asking.",
          "score": 15,
          "created_utc": "2026-01-30 07:47:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nem2f",
              "author": "SuperMegaOwl2",
              "text": "Well Besides the obvious... It could be used to recast movies or keep the likeness of said actors around even after They're gone, but that's my thought",
              "score": 7,
              "created_utc": "2026-01-30 18:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2orbne",
                  "author": "Affectionate-Let3744",
                  "text": "Both horrible horrible ideas\n\nGood luck to any future actors when companies can just rent a variety of old A/B/C listers for cheap and with absolutely no scheduling or on-set issues. They'll just keep using the faces that sell already",
                  "score": 5,
                  "created_utc": "2026-01-30 22:20:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qu0rb",
                  "author": "genserismyname",
                  "text": "I dont see the \"obvious\" purpose your preaching about. It's not useful. Recast movies? Are you forreal now. And keeping the likeness of someone who's dead around you just because what? You can't live without elizabeth olsen? It's trash, doesn't server purpose, plus DID YOU ASK ELIZBETH OLSEN WOULD SHE WANT THAT? no. so then shut the hell up, this is stupid idea that's gonna get abused for money or something worse, and that's all it's gonna be.",
                  "score": 1,
                  "created_utc": "2026-01-31 05:50:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2k2859",
          "author": "CollectionGuilty1320",
          "text": "Porn industry üìà",
          "score": 25,
          "created_utc": "2026-01-30 06:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m23w9",
          "author": "johnfkngzoidberg",
          "text": "This looks terrible.",
          "score": 6,
          "created_utc": "2026-01-30 14:56:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2leg7e",
          "author": "thatpizzatho",
          "text": "Hi, I'm working in AI research since 2016 because I think that there are some super cool and important applications of AI (protein discovery, healthcare, some *but not all* applications in the creativity industry, potentially robotics and self-driving, etc). Some other applications are less exciting because they have the potential to be misused. Tbf anything has the potential to be misused, but some more than others. Deep fakes is one of those things. This is not to say that the technology behind it (the maths and the engineering) is not exciting. It is! But the actual implementation of those cool ideas is potentially harmful, so when learning it's important to keep that in mind",
          "score": 16,
          "created_utc": "2026-01-30 12:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r5frl",
              "author": "redditownersdad",
              "text": "Ethics you mean",
              "score": 0,
              "created_utc": "2026-01-31 07:28:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k0cs2",
          "author": "recursion_is_love",
          "text": "Can I request Arnold Schwarzenegger ?",
          "score": 1,
          "created_utc": "2026-01-30 05:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kumym",
              "author": "Emergency_Pause1678",
              "text": "sure",
              "score": 1,
              "created_utc": "2026-01-30 10:19:23",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2ocfdy",
              "author": "Pickymarker",
              "text": "No need don't reccomend requests from him he just is starting when others like me have been making dfms for a while there is already like 5 Arnold models already",
              "score": -1,
              "created_utc": "2026-01-30 21:09:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l1qrb",
          "author": "DeepInEvil",
          "text": "Do you have a link to the model?",
          "score": 1,
          "created_utc": "2026-01-30 11:20:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oci2y",
              "author": "Pickymarker",
              "text": "I do might make it public on my discord server soon",
              "score": 0,
              "created_utc": "2026-01-30 21:09:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pdrn3",
          "author": "CorpusculantCortex",
          "text": "After I read that it was supposed to be Elizabeth Olsen I kinda thought I saw the woman looked vaguely like her for a fraction of a second. But when I kept watching i honestly had a hard time noticing any differences in the side by side. Im no expert but I think this still needs work.",
          "score": 1,
          "created_utc": "2026-01-31 00:20:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r5afi",
          "author": "redditownersdad",
          "text": "You da real olsen",
          "score": 1,
          "created_utc": "2026-01-31 07:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hcpam",
          "author": "valkiii",
          "text": "Do you have a repo to share?",
          "score": 1,
          "created_utc": "2026-01-29 21:02:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ilckq",
              "author": "Pickymarker",
              "text": "This guy is just starting off and this is not his model it's this other guy's I know",
              "score": 8,
              "created_utc": "2026-01-30 00:50:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2nxsen",
          "author": "Chelokot",
          "text": "People saying left and right look the same have zero comprehension of human faces",
          "score": -4,
          "created_utc": "2026-01-30 19:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k19nz",
          "author": "2reform",
          "text": "Next Elle Fanning please",
          "score": -7,
          "created_utc": "2026-01-30 06:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qn8g7c",
      "title": "Saddle Points: The Pringles That Trap Neural Networks",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/6r26o85j1nfg1",
      "author": "No_Skill_8393",
      "created_utc": "2026-01-26 06:31:04",
      "score": 77,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qn8g7c/saddle_points_the_pringles_that_trap_neural/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1t1h3i",
          "author": "theMLguynextDoor",
          "text": "Well to be fair, in SGD we assume the Hessian to be an Identity matrix. Even with Adam we don't really calculate the Hessian, we kinda approximate it with the moving average momentum term. Correct me if I'm wrong, I'm a little rusty on the basics.",
          "score": 6,
          "created_utc": "2026-01-26 12:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1rx44b",
          "author": "East-Muffin-6472",
          "text": "I always wonder \nA saddle point is it possible during model quantisation that the weights belong to this region can be cut off since it does not provide any valuable information?\nBut then it‚Äôs this region only when the model kinda more stable?",
          "score": 4,
          "created_utc": "2026-01-26 06:37:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ry57u",
              "author": "No_Skill_8393",
              "text": "We have to find the flat minima first before we use and quantize our model.",
              "score": 5,
              "created_utc": "2026-01-26 06:45:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1rym13",
                  "author": "East-Muffin-6472",
                  "text": "Ah so we do quanta that part huh? Well second order Taylor aerie is just for that I guess?",
                  "score": 1,
                  "created_utc": "2026-01-26 06:49:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ygxnj",
              "author": "Low-Temperature-6962",
              "text": "The hessian is too unstable to use.  Perhaps better to views it as density of loss values around a point.",
              "score": 1,
              "created_utc": "2026-01-27 04:12:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ykw3n",
                  "author": "East-Muffin-6472",
                  "text": "Hmm a density of loss values like how will that look like around a saddle point? Bouncing up and down around a mean ?",
                  "score": 1,
                  "created_utc": "2026-01-27 04:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o23hpzy",
          "author": "GraciousMule",
          "text": "lol. The optimizer doesn‚Äôt walk the landscape, it is walked *by* the landscape.",
          "score": 1,
          "created_utc": "2026-01-27 21:43:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs1588",
      "title": "10 GitHub Repositories to Ace Any Tech Interview",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "author": "kingabzpro",
      "created_utc": "2026-01-31 12:30:32",
      "score": 66,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "The most trusted GitHub repositories to help you master coding interviews, system design, backend engineering, scalability, data structures and algorithms, and machine learning interviews with confidence.\n\n\n\nLink: [https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview](https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview)",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2wfh9o",
          "author": "Southern-Common-2715",
          "text": "Wow",
          "score": 0,
          "created_utc": "2026-02-01 02:18:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qo6ti2",
      "title": "I Built a Hand‚ÄëDrawn Curve Learner in JavaScript",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/8apax439bufg1",
      "author": "Glittering_ken",
      "created_utc": "2026-01-27 07:04:13",
      "score": 63,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qo6ti2/i_built_a_handdrawn_curve_learner_in_javascript/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o210097",
          "author": "unskilledexplorer",
          "text": "nice. I remember this was my first assignment in the AI course at uni, maybe 8 years ago. the first time working with a multilayer perceptron finally gave me an idea what \"universal approximator\" means :) nice memories.\n\nI also remember how magical and incomprehensible it felt at the time, things that feel almost intuitive today.\n\nthanks for reviving the memories :))",
          "score": 3,
          "created_utc": "2026-01-27 15:09:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1zaxqs",
          "author": "ObviousOriginal4959",
          "text": "amazing\n\n",
          "score": 2,
          "created_utc": "2026-01-27 08:00:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o22b4ze",
          "author": "zitr0y",
          "text": "That's really cool!\n\nCan you zoom out the loss curve to get an overview of how it changed over time?",
          "score": 1,
          "created_utc": "2026-01-27 18:35:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qoha8y",
      "title": "My ML learning arc (decision tree)",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qoha8y",
      "author": "Ancient-Teach7606",
      "created_utc": "2026-01-27 15:41:29",
      "score": 54,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qoha8y/my_ml_learning_arc_decision_tree/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o21w6g4",
          "author": "Maleficent_Chance_15",
          "text": "where are you learning from?",
          "score": 1,
          "created_utc": "2026-01-27 17:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24v7gk",
              "author": "Ancient-Teach7606",
              "text": "From data camp",
              "score": 1,
              "created_utc": "2026-01-28 01:50:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o256mfj",
                  "author": "smuhamm4",
                  "text": "How would you review them?",
                  "score": 1,
                  "created_utc": "2026-01-28 02:50:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2tk0vk",
          "author": "sanjogs",
          "text": "how many days had it been for you?",
          "score": 1,
          "created_utc": "2026-01-31 17:23:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2tk8bf",
              "author": "Ancient-Teach7606",
              "text": "Sry can you explain!",
              "score": 1,
              "created_utc": "2026-01-31 17:24:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2wf4jk",
                  "author": "sanjogs",
                  "text": "How many days had it been when you started machine learning.",
                  "score": 1,
                  "created_utc": "2026-02-01 02:15:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qnarn5",
      "title": "Automated Data Preprocessing Framework for Supervised Machine Learning",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/fq9o68xdonfg1.png",
      "author": "TsLu1s",
      "created_utc": "2026-01-26 08:45:04",
      "score": 52,
      "num_comments": 2,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qnarn5/automated_data_preprocessing_framework_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1tgbgs",
          "author": "Krekken24",
          "text": "This looks amazing to me.\n\n\nI would suggest re-add the links again as they are not working.",
          "score": 1,
          "created_utc": "2026-01-26 13:52:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1trbm9",
              "author": "TsLu1s",
              "text": "Thanks a lot for your feedback.\n\nRegarding the hyperlink issue, they work fine to me and are correctly addressed.   \nRe-added them as you said just in case.. If they still don't work, copying them would ofc be the boring alternative.",
              "score": 1,
              "created_utc": "2026-01-26 14:48:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnwyy7",
      "title": "If you could go back a year, what would you change about learning AI?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qnwyy7/if_you_could_go_back_a_year_what_would_you_change/",
      "author": "TheeClark",
      "created_utc": "2026-01-26 23:34:46",
      "score": 48,
      "num_comments": 16,
      "upvote_ratio": 0.96,
      "text": "I spent a lot of last year hopping between tutorials, articles, and videos while trying to learn AI, and looking back it feels pretty inefficient. With a fresh year starting, I‚Äôm reflecting on what I would actually do differently if I had to start over and focus my time better. For people further along now, what‚Äôs the one change you wish you had made earlier in your learning process?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qnwyy7/if_you_could_go_back_a_year_what_would_you_change/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o1y00xc",
          "author": "kratoz0r",
          "text": "I would‚Äôve followed something structured like Coursiv instead of random resources.",
          "score": 18,
          "created_utc": "2026-01-27 02:35:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1y7g72",
              "author": "HarkonXX",
              "text": "What part felt like the biggest waste of time for you?",
              "score": 1,
              "created_utc": "2026-01-27 03:16:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1y7zny",
                  "author": "kratoz0r",
                  "text": "Having guided projects earlier would‚Äôve helped everything click sooner.",
                  "score": 1,
                  "created_utc": "2026-01-27 03:19:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o24xioe",
              "author": "PresentationOk8334",
              "text": "my son learned a lot from Coursiv",
              "score": 1,
              "created_utc": "2026-01-28 02:03:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yafpe",
          "author": "AccordingWeight6019",
          "text": "I would have spent less time optimizing for coverage and more time going deep on a small number of problems. Jumping between tutorials felt productive, but nothing really stuck until I tried to build and debug something end to end, including data issues and evaluation. In hindsight, reading papers made more sense after I had felt the pain points they were addressing. another thing I underestimated was how much learning comes from failure modes rather than clean examples. the moment things clicked was when I stopped asking whether I understood a concept and started asking whether I could make it work under constraints.",
          "score": 15,
          "created_utc": "2026-01-27 03:33:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1x2g0p",
          "author": "letsTalkDude",
          "text": "Why don't you tell what do you do differently?",
          "score": 8,
          "created_utc": "2026-01-26 23:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1x55vd",
          "author": "unlikely_ending",
          "text": "Nothing.",
          "score": 3,
          "created_utc": "2026-01-26 23:51:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yzhjf",
              "author": "UnforeseenDerailment",
              "text": "So, what did you do that you wouldn't change?",
              "score": 1,
              "created_utc": "2026-01-27 06:23:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o26ckmr",
                  "author": "unlikely_ending",
                  "text": "I wouldn't change anything\n\nIt was a meandering learning exercise \n\nLots of coding, lots of reading. Running models hundreds if not thousands of times\n\nLots of use of AI for learning and coding (mostly ChatGPT plus)",
                  "score": 2,
                  "created_utc": "2026-01-28 07:32:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1z42qc",
          "author": "Cybyss",
          "text": "Nothing. But, that's because I'm doing an actual Masters degree in AI.\n\n\nThere ain't no way in hell I would have been able to cobble together on my own the curriculum that my professors have curated.¬†\n\n\nIn particular, we delve deep into the mathematics of how and why the various models and methods work the way they do. Diffusion models, for example, are a real rabbit hole that goes well beyond just training a model to remove noise from an image. That's what they do, but why they work is quite fascinating but is something I would have completely glossed over trying to learn on my own.",
          "score": 3,
          "created_utc": "2026-01-27 07:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ymwdv",
          "author": "dommycaste",
          "text": "Pay for course subscriptions. Currently paying for the [deeplearning.ai](http://deeplearning.ai) course subscriptions. The fact your spent money holds you accountable, so you're more likely to finish it. The structure and exercises that courses give you also help too.",
          "score": 2,
          "created_utc": "2026-01-27 04:51:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ynwf3",
          "author": "ChipsAhoy21",
          "text": "Learn concepts not frameworks. I spent the better part of 2023 learning react and 2024 learning langgraph. \n\nYes, I built and launched a successful product, but in 2025, genai has made it where I could have built it in a weekend. Wish I would have spent that time learning UI/IX fundamentals, and agentic designs rather than the coding frameworks to power them.",
          "score": 1,
          "created_utc": "2026-01-27 04:57:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ysjsq",
          "author": "Huge_Law4072",
          "text": "shipped more",
          "score": 1,
          "created_utc": "2026-01-27 05:30:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1yzti6",
          "author": "deep_m6",
          "text": "I would select a single resource to study and complete it after choosing that resource. I achieved my best results through early small project creation which helped me solve actual difficulties that I encountered. The combination of deep knowledge and practical experience proves more effective than continuous tutorial watching.",
          "score": 1,
          "created_utc": "2026-01-27 06:26:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o21me79",
          "author": "Sussy_Imposter2412",
          "text": "I would have focused more on practical projects that challenged my understanding rather than just following tutorials. Building real applications forced me to confront and solve issues that I wouldn't have encountered otherwise, leading to deeper learning.",
          "score": 1,
          "created_utc": "2026-01-27 16:48:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqy5d1",
      "title": "Should I list a Kaggle competition result (top 20%) as a competition or a personal project on my resume?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "author": "Cheap_Train_6660",
      "created_utc": "2026-01-30 06:45:29",
      "score": 44,
      "num_comments": 23,
      "upvote_ratio": 0.93,
      "text": "Hey all,\n\nI recently participated in my first Kaggle competition (CSIRO Biomass). There were \\~3,800 teams, and my **final private leaderboard rank was 722 (top 20%)**.\n\nNo medal or anything, just a solid mid-upper placement.\n\nI‚Äôm applying for ML / data science / research-adjacent internships and was wondering what‚Äôs considered best practice on a resume:\n\n* Is it better to list this explicitly as a **Kaggle competition** with the rank?\n* Or frame it as a **personal ML project using a Kaggle dataset**, and not emphasize the competition aspect?\n\nI don‚Äôt want to oversell it, but I also don‚Äôt want to undersell or hide useful signal. Curious how hiring managers / experienced folks view this.\n\nWould appreciate any advice üôè",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2katnv",
          "author": "DuckSaxaphone",
          "text": "As a hiring manager, the only thing that would make it worth mentioning to me is that if it's a competition, I guess it was a new data set you couldn't follow a tutorial for?\n\nBut honestly, I wouldn't spend too much CV space on this and it would be better to quickly say what you did and how.",
          "score": 30,
          "created_utc": "2026-01-30 07:21:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kb765",
              "author": "Cheap_Train_6660",
              "text": "For this competition it *was* a new, real-world dataset (remote sensing + biomass targets). There wasn‚Äôt a step-by-step tutorial to follow, so I had to decide on feature engineering, validation strategy, and modeling choices myself. I was just concerend about a non impressive rank of 722/3803. it was my first ever comp tho",
              "score": 11,
              "created_utc": "2026-01-30 07:24:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lbzo5",
                  "author": "Palmquistador",
                  "text": "In my experience, what one company/person/founder thinks is trash / useless, another appreciates and finds valuable.\n\nI think, OP, this sub is too small for you to gleam an accurate model so I would just say, take the advice with a grain of salt.\n\nMaybe try different formats if you can get a feel. Some postings may encourage you to list projects and competitions while others may have hard set requirements and not budge. It really is a roll of the dice from company to company.",
                  "score": 9,
                  "created_utc": "2026-01-30 12:35:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kkir2",
          "author": "AccordingWeight6019",
          "text": "I would list it as a competition and be very factual about it. Something like the problem, the methods you used, and the final rank. Top 20 percent out of a few thousand teams is solid, especially for a first competition. Framing it as just a personal project kind of hides the competitive signal, but overselling medals you did not get would be worse. most hiring managers I have talked to care less about the exact rank and more about what you actually did. feature engineering, validation strategy, ensembling, error analysis, that stuff. If you can explain your approach clearly, the competition context helps rather than hurts.",
          "score": 8,
          "created_utc": "2026-01-30 08:47:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kahhq",
          "author": "juanurena",
          "text": "I would not add it. If you want, you can add a section with Kaggle projects, and then comment shortly which projects you joined (once you have 3/4), your user, etc. This will show me a good  interest, that you like some areas, and that you keep yourself updated.\n\nBut I would never add, I was top 20% on this competition.",
          "score": 18,
          "created_utc": "2026-01-30 07:18:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l1v10",
              "author": "Palmquistador",
              "text": "Why not? He is better than 80% of the people that did it‚Ä¶",
              "score": 3,
              "created_utc": "2026-01-30 11:21:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lkjpa",
                  "author": "sam_the_tomato",
                  "text": "Because that implies he is not better than the top 20% of people, or he would have written a higher percentile. In most cases, this will actively hurt his chances.\n\n---\n\n\n\nIf there are N random applicants to the job (including you), the probability of you being the best applicant is 0.8^N-1 . That's what your employer will assume if you put that on the resume. However, if you leave it out, they will think the probability of you being the best applicant is 1/N.\n\n1/N > 0.8^N-1 at around N = 13. So if there are 12 or more other applicants (ML jobs can have hundreds), you should leave it out. \n\nAlso, this is before accounting for selection bias, e.g. he may have entered 10 competitions and only gotten top 20% in 1 of them, which an employer might assume, further lowering his odds of being the best applicant.",
                  "score": 9,
                  "created_utc": "2026-01-30 13:26:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2mjg28",
                  "author": "Suspicious-Beyond547",
                  "text": "Have you ever done a kaggle? Most teams (possibly close to 80 percent) that sign up spend less than an hour and call it quits.¬†\n\n\nAnother issue is that youll never deal with clean kaggle like datatsets in production.¬†",
                  "score": 3,
                  "created_utc": "2026-01-30 16:15:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2l5utp",
                  "author": "juanurena",
                  "text": "And? What does mean? Being better than other people (random people that we don't know) is not something valuable for me.\n\nI will value that you can solve real problems and you have interest, but I cannot compare if the other 80% are good or bad engineers. So it is not really a useful metric.",
                  "score": 0,
                  "created_utc": "2026-01-30 11:52:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ko5n0",
          "author": "Adept_Carpet",
          "text": "If your resume has nothing besides coursework, it's good.\n\n\nAfter the internship, maybe relegate it to one line. After a second internship or a full time job remove it entirely.",
          "score": 3,
          "created_utc": "2026-01-30 09:20:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2koync",
          "author": "Suspicious-Beyond547",
          "text": "I'd say anything outside top 2-5 percent isnt impressive, mostly because theyre usually one or two good teams that make their notebooks public and 25 percent of teams just just the same approach with some 'hyperparameter tuning'.",
          "score": 6,
          "created_utc": "2026-01-30 09:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kqkrp",
          "author": "misingnoglic",
          "text": "I would call it a project and add a bullet saying it was the top X% of results.",
          "score": 3,
          "created_utc": "2026-01-30 09:42:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k6z6p",
          "author": "Standard_Iron6393",
          "text": "That is good , add in a resume it would be a plus point",
          "score": 5,
          "created_utc": "2026-01-30 06:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kk2ch",
          "author": "pleaseineedanadvice",
          "text": "Wouldn't mention it if you have something else (totally fine not having it, l m just saying) if not maybe like a link to your kaggle page (on top of my mind can't remember if they are shown)",
          "score": 2,
          "created_utc": "2026-01-30 08:43:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l9o5j",
          "author": "TruthIll4102",
          "text": "Hiring folks know Kaggle is competitive and noisy, so they‚Äôre usually more interested in *what you did* than the rank alone. I wouldn‚Äôt reframe it as ‚Äújust a personal project‚Äù unless you heavily extended it beyond the competition. Calling it a competition shows you worked under constraints, evaluated properly, and compared against others. Also don‚Äôt overthink the ‚Äúno medal‚Äù part. There are lot of strong candidates have Kaggle entries without medals. Just don‚Äôt hype it as ‚Äútop performer‚Äù or anything like that and you‚Äôre fine.",
          "score": 2,
          "created_utc": "2026-01-30 12:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2x5f71",
          "author": "Sad-Net-4568",
          "text": "I also want to ask something related to it, if kaggle competition not just mentioned as a competition but also a project.\nI mean proper structured code on GitHub link is provided not just the rank on CV.\nWhat would be your take on it?",
          "score": 1,
          "created_utc": "2026-02-01 05:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oqsru",
          "author": "Jaded_Individual_630",
          "text": "I can't imagine a Kaggle result being on a resume making me think one thing or another, probably more negative thoughts than positive given the amount of absolute garbage on Kaggle.",
          "score": -1,
          "created_utc": "2026-01-30 22:18:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr6n7l",
      "title": "Want to start Machine learning...i know the basics of python, pls help me guyss",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "author": "Different-Sell2195",
      "created_utc": "2026-01-30 14:16:59",
      "score": 43,
      "num_comments": 15,
      "upvote_ratio": 0.92,
      "text": "see i know basics of c, c++, python and R....i want to do machine learning. I have good understanding of mathematics and little of statistics and i grab things easily. I don't know where to start and how so please give me some advice on it  \nAnd please mention the source from whre i should start too",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2lyfvk",
          "author": "starksince2004",
          "text": "Statquest if you want to grasp concepts quickly\n\nAndrew old Ng courses are also very good. You can find them on YouTube.\n\nCampusx 100 days of machine learning, if you are ready to invest time\n\nIf you want to pay, course on edx provided by MIT\n\nBooks:\n\nOreilly publication books\n\nNeural Networks and Deep Learning by Michael Nielsen",
          "score": 10,
          "created_utc": "2026-01-30 14:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nao2z",
              "author": "dutchpsychologist",
              "text": "Upvote for statquest! It is awesome. Josh Starmer from statquest also has books that are basically the videos in readable format, I also recommend those",
              "score": 4,
              "created_utc": "2026-01-30 18:16:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2nvau9",
                  "author": "Leading_Tourist9814",
                  "text": "baaaam",
                  "score": 2,
                  "created_utc": "2026-01-30 19:48:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2nf67o",
          "author": "DataCamp",
          "text": "If it helps, here‚Äôs a first month plan that won‚Äôt overwhelm you.\n\nIn the first week, focus on understanding what machine learning actually is and how it‚Äôs used. Learn the difference between supervised and unsupervised learning and get comfortable with the idea of features, labels, training, and testing. At the same time, refresh Python basics you‚Äôll use all the time in ML, especially NumPy and pandas. Try loading a dataset, cleaning it, and doing some simple exploration.\n\nIn week two, start with your first real models. Learn linear regression and logistic regression and implement them using scikit-learn. Don‚Äôt worry about the math being perfect, just understand what the model is trying to do and how to evaluate it. Work with a small dataset and focus on things like train/test split, accuracy, and mean squared error.\n\nWeek three, classic machine learning algorithms. Learn decision trees, k-nearest neighbors, and random forests. This is where ideas like overfitting and bias vs variance start to make sense. Try changing model parameters and see how performance changes. This experimentation is more important than memorizing formulas.\n\nIn the fourth week, put everything together in a small project. Take a dataset from Kaggle and go end to end: clean the data, choose a model, train it, evaluate it, and explain your results in plain language. Even a simple project here will boost your confidence a lot.\n\nBy the end of the month, you won‚Äôt be an expert, but you‚Äôll actually understand how machine learning works and how to build models. From there, you can decide whether to go deeper into math, try deep learning, or focus on more projects.",
          "score": 6,
          "created_utc": "2026-01-30 18:36:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ovg4e",
              "author": "Gullible-Bluejay-848",
              "text": "Stopping by to thank you for this very helpful run down. Thanks :) üôè",
              "score": 1,
              "created_utc": "2026-01-30 22:41:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2lxfqo",
          "author": "AdDiligent1688",
          "text": "I would see if you can find some university slideshows on machine learning concepts and have a look at those, as well as videos, to understand how basic ML algorithms work. Then practice applying them in Jupyter notebooks or google collab with real data from kaggle.",
          "score": 2,
          "created_utc": "2026-01-30 14:33:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ly2aj",
          "author": "CalmGuy69",
          "text": "You can watch the machine learning specialization on Coursera. It consists of 3 lectures. Amazing stuff for beginners.",
          "score": 2,
          "created_utc": "2026-01-30 14:36:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ojtng",
          "author": "Automatic_Lab2084",
          "text": "Here are some curated playlists   \n[https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art](https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art)   \n[https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch](https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch)  \n[https://brightclips.ai/playlist/demystifying-large-language-models](https://brightclips.ai/playlist/demystifying-large-language-models)",
          "score": 2,
          "created_utc": "2026-01-30 21:44:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m8o2f",
          "author": "Jaded_Individual_630",
          "text": "Would be curious to hear what you think a good understanding of mathematics means.",
          "score": 1,
          "created_utc": "2026-01-30 15:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2otgrn",
          "author": "ViciousIvy",
          "text": "hey there! my company offers a free ai/ml engineering fundamentals course for beginners! if you'd like to check it out feel free to message me¬†\n\n\n\nwe're also building an ai/ml community on discord where we hold events, share news/ discussions on various topics. feel free to come join us [https://discord.gg/WkSxFbJdpP](https://discord.gg/WkSxFbJdpP)",
          "score": 1,
          "created_utc": "2026-01-30 22:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rn3qt",
          "author": "East-Muffin-6472",
          "text": "Campusx X ML and DL playlist on YouTube\nAndrew ng ml  and dl courses \nStat quest yt channel and it‚Äôs book\n3b1b for linear algebra \nMIT probability course on yt\nIsle book for in depth ml algorithms intuition and rigorous math proofs \n\nA few of my own work I‚Äôd like to pus forward which maybe of assistance to you!\n\nhttps://www.smolhub.com",
          "score": 1,
          "created_utc": "2026-01-31 10:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sy9y3",
          "author": "redirkt",
          "text": "Deeplearning.ai - start from there",
          "score": 1,
          "created_utc": "2026-01-31 15:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2w93bd",
          "author": "Entire-Parsley-6035",
          "text": "HandsonMachine Learning Aurelion Geron",
          "score": 1,
          "created_utc": "2026-02-01 01:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qn53wz",
      "title": "Is \"Attention all you need\", underselling the other components?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qn53wz/is_attention_all_you_need_underselling_the_other/",
      "author": "morimn2",
      "created_utc": "2026-01-26 03:43:46",
      "score": 42,
      "num_comments": 16,
      "upvote_ratio": 0.88,
      "text": "Hi, I'm new to AI and recently studying the concept of transformers.\n\nAs I dig into the implementation details, I keep running into design choices that seem to me under-justified. For example,\n\nWhy is there an FFN after each attention block?\n\nWhy is there a linear map before the softmax?\n\nWhy are multi-head attention outputs simply concatenated rather than combined through somthing more sophisticated?\n\nThe original paper doesn't really explain these decisions, and when I asked Claude about it, it (somewhat reluctantly) acknowledged that many of these design choices are empirical: they work, but aren't theoretically motivated or necessarily optimal.\n\nI get that we don't fully understand *why* transformers work so well. But if what Claude tells me is true, then can we really claim that attention is all that is important? Shouldn't it be \"attention - combined with FFN, add & norm, multi-head concat, linear projection and everything else - is all you need?\"\n\nIs there more recent work that tries to justify these architectural details? Or should I just give up trying to find the answer?\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qn53wz/is_attention_all_you_need_underselling_the_other/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o1ra9oa",
          "author": "1h3_fool",
          "text": "Hi, I suggest you check this work ---->[ CRATE](https://ma-lab-berkeley.github.io/CRATE/#crate_original_paper), this is a nice theoretical work that approaches the attention algorithm from a different more interpretable perspective (Representation Learning and compressed sensing). Also it breaks down the objective of each component also. It starts from a compressed sensing objective and ultimately derives the Attention equation (with Q = K). I mostly work around Image and audio signals so this explanation to attention mechanism gives me a better \"signal friendly\" intuition to why Attention is always the go to for SOTA results on my data, where the token as such is not as discrete or interpretable like a  word token in language.",
          "score": 37,
          "created_utc": "2026-01-26 03:59:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ram5v",
              "author": "morimn2",
              "text": "Looks interesting. Thanks!",
              "score": 3,
              "created_utc": "2026-01-26 04:01:26",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o1u58c3",
              "author": "Wooden_Cellist_207",
              "text": "What is your work on audio signals? Just curious as Im very interested in the field and currently trying to shift into an Audio ML",
              "score": 1,
              "created_utc": "2026-01-26 15:51:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1u7gwc",
                  "author": "1h3_fool",
                  "text": "It's mostly SSMs (State Space Models) vs Self-attention (Transformer based models) performance comparison on audio tasks and proving why one works better than the other through signal processing theory these days. But I have worked on wider problems like Speech to transcription for low resource languages or Sound source localisation.",
                  "score": 1,
                  "created_utc": "2026-01-26 16:01:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1rr9ak",
          "author": "home_free",
          "text": "I think the title needs to be taken in context. If I recall, attention was developed to help break the problem recurrent nets had with exploding/vanishing gradients since pure RNNs have everything chained together in a product. Attention improved performance on RNNs by allowing a channel to learn pairwise importance weights basically. Attention is all you need is saying you don't even need recurrence, just linear layers with attention.",
          "score": 23,
          "created_utc": "2026-01-26 05:52:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ryupr",
          "author": "literum",
          "text": "Because other layers have been here a long time. FFN just means a Linear layer with activations and normalization, basically the same thing as MLPs. In fact, removing the attention makes the transformer very similar to a parallel MLP. Softmax is used almost everywhere in ML since it produces outputs that sum to 1, a property of probabilities.\n\nBefore transformers we had RNNs like GRUs, LSTMs, but they had vanishing/exploding gradient problems and couldn't learn over long horizons. Memory cells were good, but it meant you need to get through thousands of tokens to remember what happened before. In addition, LSTMs were not very parallellizable because you had to do backprop through time, meaning you need to process previous token before you can process current one.\n\nLatest innovation in RNNs was using attention to close some of these gaps. These models started outperforming the pure LSTM/GRU models and were gaining traction. The paper is called \"Attention is all you need\" because they proposed that the memory layers were not necessary. Giving them up and having only attention and linear layers meant 1) More stable learning due to attention outperforming memory cells 2) parallellizable in both training and in inference.\n\nYou correctly pointed out that a lot of those decisions are empirical. Theory might suggest one thing, but we'll probably go with what works better. Look at the pre-norm and post-norm debate. There's also papers explaining these, but I'm not sure whether there is one that explains all. There's usually deep dive papers that try to explain these with other tools. It could be training stability, gradient flow etc.",
          "score": 6,
          "created_utc": "2026-01-26 06:50:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1skx7i",
          "author": "Apathiq",
          "text": "As others said, the main novelty of the paper was replacing convolutional and/or recurrent layers by self-attention and positional encoding in the context of seq2seq models. I agree that they should have showed the effect of removing self-attention from their architecture, since positional encoding + FNN could work too. It's similar to DeepSets (was published around the same time) with the addition of positional encoding.",
          "score": 3,
          "created_utc": "2026-01-26 10:05:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1yw1pv",
          "author": "SafetyNervous4011",
          "text": "The reason behind the concatenation a more computationally efficient way to do matrix addition. I'm sure you are familiar with how attention works where the output is equivalent to softmax(QK\\^T/\\\\sqrt(d\\_k))\\*V. Now originally, you would add this to the residual stream. However, researchers realized there were two things that made this naive way more computationally expensive.¬†\n\nFirst, the QK attention scores are typically in the form nxn (where n is sequence length). This would need to be multiplied by a matrix V, which projected nxn matrix back into a matrix of nxd\\_embed to match the dimension of its input. However, this meant that the V matrix needed to be of size nxd\\_embed. Remember that the V matrix is created by multiplying the inputs x in the form n x d\\_embed by a corresponding learned weight matrix commonly dubbed W\\_v. This W\\_v matrix would, therefore, need to be d\\_embed x d\\_embed. The original authors, I believe, planned thinking that embedding dimension might be parameter set very large in the future. For instance, GPT3's embedding dimension is around 12288 long. Therefore, the W\\_v matrix in the naive way would be 12288x12288, which is massive for each head. They realized that they didn't actually need this many parameters and also storing this massive matrix 96 times(the amount of heads GPT3 would eventually have) is prohibitively expensive. The original authors likely foresaw this and factorized the W\\_v matrix into two lower rank forms. The first matrix commonly retains the name W\\_v(the matrix first multiplied to input x that projects it down to some smaller dimension, say 128). The second matrix is now typically called W\\_o (the matrix that is multiplied to the output of x\\*W\\_v that converts it from an nx128 matrix into an nxd\\_embed matrix aka projecting back into the token embedding dimension)¬†\n\nNow, with this design choice, we are given our second clever computational save. The original design behind multi-headed attention is for the outputs of each head to be jointed added to the residual stream. This creates a lot of additional matrix multiplications then matrix additions per head. The original designers of attention actually realized that the concatenation operation was *mathematically equivalent* to the summation operation with clever concatenation of the matrices. This allowed several matrix multiplications and additions to be condensed into a single matrix multiplication. Try this at home, if you stack n x n matrices A, B, C, D horizontally such that you get a matrix P of the dimensions n x 4n, and then take n x n matrices E\\^T, F\\^T, G\\^T, H\\^T and stack them horizontally in some matrix Q of the dimensions 4n x n. You will find that PQ is the equivalent of AE\\^T + BF\\^T + CG\\^T + DH\\^T. As a result, what they essentially did was concatenate the outputs of attention and multiplied it by some massive W\\_o matrix that was the vertical concatenation of the individual W\\_o matrices that we talked about before. Thus, saving a lot on computation.¬†  \n  \nEDIT: after rereading a blog, actually there are some helpful things that happen with concatenation that aren‚Äôt just computational. It allows the larger W\\_o matrix to learn ways to mix information across different heads, which allows the attention to actually separate different heads for different tasks better than if it was just all added together. It preserves the subspaces that summing would forget and it allows for greater degrees of freedom with the larger W\\_o. ¬†",
          "score": 2,
          "created_utc": "2026-01-27 05:56:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1yzc1f",
          "author": "SafetyNervous4011",
          "text": "With regard to the FFN question, this was answered really well by some other‚Äôs in this thread with regards to the evolution of it past GRUs/LSTMs but there is also one detail that I think could be added. Transformers, like most deep learning architectures are meant to be universal function approximators (you‚Äôll likely hear this a lot in machine learning discourse). But this is the exact reason why transformers work for literally anything, not just text. The theory of deep learning systems being universal approximators is that any standard FFN with infinite width, infinite data, and sufficient non-linearity can learn ANY function. The necessary part of universal function approximators are non-linearity. This is why there are functions like ReLU/GeLU in standard feed forward networks, it allows the network to learn non-linear behavior. There are a lot of ways to do this but ReLU/GeLU was learned as the simplest but ‚Äúgood enough‚Äù way to inject nonlinearity into deep learning (really easy computationally as it‚Äôs just putting negative values to zero + GeLU is smoother). Without this non-linearity, no matter how deep your network goes, you are only really able to fit linear functions (lines, planes, hyperplanes) through your data.\n\nNow, going back to transformers, if you look at attention as an operation, where is the non-linearity? Technically, the only non-linear operation in attention is the softmax function between the QK matrix and the VO matrix and the quadratic behavior of xW\\_q(xW\\_k)\\^T. As a result, attention itself as an architecture while still being a universal function approximator, has trouble going beyond. It‚Äôs really difficult for the network to learn new things because attention functionally just passes information between tokens. The FFN network is actually there to make the entire transformer *better* because it adds information and deeper non-linearity instead of primarily passing information between tokens, making it therefore better at whatever task it needs to imitate a function to succeed at.\n\nThe very common question of why we don‚Äôt just use FFNs for everything if they can approximate any function. Well, the assumption is infinite data and infinite width, which we don‚Äôt have. Architectural choices are made to make the model more easily propagate information and learn based on the limited amount of data and width (but mostly data)we have. So, another way we can think about it is that the FFNs don‚Äôt modify attention. You can think of attention as an add-on to the FFNs to help them better approximate the function of natural language given our non-finite data situation.¬†",
          "score": 2,
          "created_utc": "2026-01-27 06:22:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1sx1yk",
          "author": "kunkkatechies",
          "text": "in deep learning most of the architecture choices and training procedures are chosen because it has been empirically better.",
          "score": 1,
          "created_utc": "2026-01-26 11:49:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1y10l1",
          "author": "as_ninja6",
          "text": "Attention is all you need is just one of the papers in NLP research which was trying to improve the existing models at that time. It may be true that a lot of components and how they are connected might be based on empirical evidence but these choices are not random. \nTo better understand these choices it's important to know what feature learning is and how we look at those feature representations and how we want them to be consumed. If you follow the history of NMT and other NLP papers you'll get a sense of how each component got its shape. \n\nAlso they are only going to focus on the novelties of their architecture in the paper so not explaining other components which be there in the early work is not underselling",
          "score": 1,
          "created_utc": "2026-01-27 02:41:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ryods",
          "author": "East-Muffin-6472",
          "text": "I would highly recommend reading papers on each of those components first and then taking got 2 125 model and just playing around with it pruning its layers for example to see what each components does!\n\nReading mech interp paper on such arch and why it works and maybe even code out your own got model and pretrain it !",
          "score": 0,
          "created_utc": "2026-01-26 06:49:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1rk81t",
          "author": "elbiot",
          "text": "Concatenation leaves it up to the next layer to combine them in a sophisticated way. Anything else would destroy information",
          "score": 0,
          "created_utc": "2026-01-26 05:02:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qow8t6",
      "title": "I‚Äôm writing a from-scratch neural network guide (no frameworks). What concepts do learners struggle with most?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qow8t6/im_writing_a_fromscratch_neural_network_guide_no/",
      "author": "palash90",
      "created_utc": "2026-01-28 00:43:14",
      "score": 39,
      "num_comments": 38,
      "upvote_ratio": 0.88,
      "text": "Most ML resources introduce NumPy and then quickly jump to frameworks.\n\nThey work but I always felt I was using a library I didn‚Äôt actually understand.\n\nSo I‚Äôm writing a guide where I build a minimal neural network engine from first principles:\n\n*  flat-buffer tensors\n* explicit matrix multiplication\n* manual backprop\n* no ML frameworks, no hidden abstractions\n\nThe goal is not performance.\n\nThe goal is understanding what‚Äôs really happening under the hood.\n\nBefore going further, I‚Äôd really like feedback from people who‚Äôve learned ML already:\n\n*  Which NN concepts were hardest to understand the first time?\n*  Where do existing tutorials usually gloss over details?\n*  Is ‚Äúfrom scratch‚Äù actually helpful, or just academic pain?\n\nDraft is here if you want to skim specific sections: [https://ai.palashkantikundu.in](https://ai.palashkantikundu.in)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qow8t6/im_writing_a_fromscratch_neural_network_guide_no/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o24nd21",
          "author": "beingsubmitted",
          "text": "I think most people going into this aren't ready for the linear algebra and multivariable calculus. I think most people would agree backprop is the main struggle.",
          "score": 20,
          "created_utc": "2026-01-28 01:08:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o24nmfo",
              "author": "palash90",
              "text": "Thank you for your response. I have tried to explain as much as possible with different tools",
              "score": 3,
              "created_utc": "2026-01-28 01:10:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o25x1mm",
              "author": "Suspicious_Tax8577",
              "text": "I have a PhD, as well as undergrad and masters in chemistry. Objectively, I've survived worse (statistical thermodynamics), but manual backprop made me cry. \n\nBuilding a vanilla MLP in numpy is pretty much the reason why the PI I'm currently working with on a proposal for hypergraph neural networks wants to work with me ü•¥.",
              "score": 0,
              "created_utc": "2026-01-28 05:30:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ar8jn",
                  "author": "om_nama_shiva_31",
                  "text": "There‚Äôs no way simple derivatives and matrix multiplication made you cry if you have a phd in any science",
                  "score": 2,
                  "created_utc": "2026-01-28 22:01:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o24y6sl",
          "author": "unlikely_ending",
          "text": "I did that too, for a CNN\n\nJust used Numpy and Python \n\nVery inefficient but it worked\n\nProbs the back prop took me the longest to figure out",
          "score": 8,
          "created_utc": "2026-01-28 02:06:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o269bp2",
              "author": "palash90",
              "text": "Yes, Backprop was the hardest for me too. But weaving every piece by hand made it very logical.",
              "score": 3,
              "created_utc": "2026-01-28 07:05:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2538qc",
          "author": "ProfessionalShop9137",
          "text": "I‚Äôve done this in uni classes and it‚Äôs always back prop. The math isn‚Äôt crazy crazy but setting it up programmatically is a struggle to wrap your head around.",
          "score": 8,
          "created_utc": "2026-01-28 02:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o269rl8",
              "author": "palash90",
              "text": "Yeah. I really have a clear explanation why autograd exists.",
              "score": 1,
              "created_utc": "2026-01-28 07:08:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25yiob",
          "author": "AtMaxSpeed",
          "text": "A note on backprop, it is \"easy\" to do it if you have a fixed architecture. There are many guides on how to build a 1/2 hidden layer NN and code up the backprop after you work out the formulas. It is tedious and annoying, but simple to work out. The hard part, and useful part, and undertaught part, is autograd: generalizing the framework so you can use different losses, different activations, and different architecture. This also teaches people how to really understand backprop, since you have to operate on generalized incoming gradients and activation values.\n\nIf you're building a course, it may be neat to help people build an autograd for the simple functions (add, subtract, matmul, etc.) to implement a neural network from scratch.",
          "score": 5,
          "created_utc": "2026-01-28 05:40:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26ax9i",
              "author": "Correct_Scene143",
              "text": "Fcuk this is the real hard part rest is just tedious. Autograd is the real shit show",
              "score": 2,
              "created_utc": "2026-01-28 07:18:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o26aqx7",
              "author": "palash90",
              "text": "Yes, this is the foundation part. with no gpu, no fancy layers and all.\n\n  \nstill I got quite good result out of it. next up is extend this to build transformers. there I will introduce autograd.",
              "score": 1,
              "created_utc": "2026-01-28 07:17:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25wiyi",
          "author": "AccordingWeight6019",
          "text": "backprop itself is usually not the hardest part. the confusion comes from how gradients flow across layers and why small choices like initialization or shapes affect learning. from scratch helps if it builds intuition that transfers to frameworks, not if it becomes the destination.",
          "score": 4,
          "created_utc": "2026-01-28 05:26:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2575hz",
          "author": "thebriefmortal",
          "text": "I built my first NN from scratch in MaxMsp, a visual language for audio applications. I hadn‚Äôt heard of NNs until I watched Welch Labs video on the Perceptron, after which I just kind of felt my way through the mechanics of it and built it in sections. Forward pass and error calculation was relatively easy, but backpropagating the corrections was a nightmare that took me ageeeeees to figure out. I was deep inside Overflow City for the longest time.",
          "score": 3,
          "created_utc": "2026-01-28 02:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o25hqoj",
          "author": "irekit_",
          "text": "when I coded my first neural network from scratch I would have literal nightmares about the calculus in backprop.",
          "score": 3,
          "created_utc": "2026-01-28 03:52:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c73o",
              "author": "palash90",
              "text": "It's difficult for sure.",
              "score": 1,
              "created_utc": "2026-01-28 07:29:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o261p02",
          "author": "Duflo",
          "text": "It's only a matter of time until this evolves into a framework :)\n\nSeriously though, looks cool.",
          "score": 3,
          "created_utc": "2026-01-28 06:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c4rn",
              "author": "palash90",
              "text": "Thanks.\n\n  \nYes, I am seeing it myself. Near the end, I already build two methods - builder.build() and nn.predict\n\n()",
              "score": 1,
              "created_utc": "2026-01-28 07:29:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o27tam1",
          "author": "JanBitesTheDust",
          "text": "Focus of backprop like most people mention. But specifically focus on the idea of linearization via gradient descent and the idea of automatic differentiation. It makes the hard math much easier to digest and allows for good conceptual understanding on the flow of computations via a DAG. A while back I implemented autodiff in C which may be useful for your guide: https://github.com/Janko-dev/autodiff",
          "score": 3,
          "created_utc": "2026-01-28 14:11:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o288zvn",
              "author": "palash90",
              "text": "Great headstart. thank you.",
              "score": 1,
              "created_utc": "2026-01-28 15:27:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25nuya",
          "author": "Correct_Scene143",
          "text": "i too am planning to do this but i wanna know if it is worth it like learning wise ik it is but cv and visibility wise ??",
          "score": 2,
          "created_utc": "2026-01-28 04:29:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o25xofj",
              "author": "Suspicious_Tax8577",
              "text": "Building a vanilla MLP in numpy is pretty much the reason why the PI I'm currently working with on a proposal for hypergraph neural networks wants to work with me ü•¥.\n\nWhether this applies for industry, idk. But once you've cried over manual backprop, you'll never take autodiff for granted and tensorflow/pytorch no longer feels like you're writing a magical incantation.",
              "score": 2,
              "created_utc": "2026-01-28 05:34:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o26a41h",
                  "author": "Correct_Scene143",
                  "text": "True true , the learning value is great no doubt. When was this tho cause every second guy I see today is trying to do this as an exercise or I'm just in good ml circles that don't revolve around hype",
                  "score": 1,
                  "created_utc": "2026-01-28 07:11:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o26acgu",
              "author": "palash90",
              "text": "trust me, it's rewarding. if you have good grasp of the math and programming it won't take more than  weekend in python, more than 2 weeks in Rust.\n\nbut the strong understanding of AI basics will always stay with you.",
              "score": 1,
              "created_utc": "2026-01-28 07:13:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o25zhpu",
          "author": "ForeignAdvantage5198",
          "text": "intro to stat learning should be a start",
          "score": 2,
          "created_utc": "2026-01-28 05:48:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26c0ho",
              "author": "palash90",
              "text": "Weight Initialisation leans on Probability and Statistics heavily.\n\n  \nI just dodged the bullet for now but can't keep it away forever. At some point, I will have to move to real distribution collections than my simple RNG.",
              "score": 1,
              "created_utc": "2026-01-28 07:28:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2aawt2",
          "author": "jplatipus",
          "text": "Wow this is neat, love it. A few years ago I found an Australian uni tutorial that built a nn using Java, with animated graphics. It really showed me the magic of nn's: me running it several times, asking how does it do that? Magic.\n\nI think your implementation brings it into the present (using rust), but also does a lot more. \n\nExcellent work",
          "score": 2,
          "created_utc": "2026-01-28 20:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2cwkyj",
              "author": "palash90",
              "text": "thank you for your encouragement",
              "score": 1,
              "created_utc": "2026-01-29 05:03:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26d26k",
          "author": "LofiCoochie",
          "text": "math\nbridge between math and code",
          "score": 1,
          "created_utc": "2026-01-28 07:37:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26f8ne",
              "author": "palash90",
              "text": "thanks for the suggestion. I‚Äôve been trying to start from why the math exists and only then map it to code, because jumping straight to formulas never worked for me either.",
              "score": 2,
              "created_utc": "2026-01-28 07:56:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2d89d3",
          "author": "thunderbootyclap",
          "text": "How do you choose the number of nodes in each inner layer?",
          "score": 1,
          "created_utc": "2026-01-29 06:31:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dlbhu",
              "author": "palash90",
              "text": "through experiment. first try small and run for 1000 epochs and start deeper from there, until I find a balance I do hypermeter tuning. there is a chapter in the guide where I show how to do that.\n\n  \nhowever, based on the task and the input fed to network, you have to take the ownership.\n\n  \nthere are other ways, I will have to include in my next guide.\n\n  \nthis is the simplest explanation, kind of a hellow world but it takes users name.\n\n  \nin the next, we use the tool and expand on it.",
              "score": 2,
              "created_utc": "2026-01-29 08:25:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2db2wb",
          "author": "nemesis1836",
          "text": "Can you add a follow up guide where you improve the performance of the network? I haven't seen much articles related to this.",
          "score": 1,
          "created_utc": "2026-01-29 06:54:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2dkubg",
              "author": "palash90",
              "text": "in this, I am relying on AutoVectorization by LLVM compiler.\n\nbut, in the second part, I will build a neural network for NGram and transformers.\n\n  \nwe need performance there. optimizers will be optimised, batch training would be new norm, gpu trick may be required.",
              "score": 2,
              "created_utc": "2026-01-29 08:20:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o26q7pw",
          "author": "Shark-gear",
          "text": "From scratch guides are a big waste of time.\n\nThe best way of learning is to explain an abstraction (for example backprop), with math. The end.\n\nIn your guide, you will not explain the math, because it's complicated, you'll simply do a very verbose python implementation, and you'll just give something long and overcomplicated and unusable to the community. \n\nThanks for your bloatware and for wasting everybody's time.",
          "score": -2,
          "created_utc": "2026-01-28 09:36:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o26twps",
              "author": "palash90",
              "text": "We‚Äôre talking past each other.\n\n\nThe guide is written in Rust and walks through the math step by step, then maps each term to concrete computation and gradient flow, because that‚Äôs where understanding broke down for me.\n\n\nIt‚Äôs not meant to replace formal mathematical treatments, and it‚Äôs not intended for everyone.\n\n\nIf a math-only abstraction works better for you, that‚Äôs completely fine.",
              "score": 2,
              "created_utc": "2026-01-28 10:10:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o26us54",
                  "author": "Shark-gear",
                  "text": "You're just trying to make it easy and nice. You're just dishonest. Math is the only way.",
                  "score": 1,
                  "created_utc": "2026-01-28 10:18:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qr2fx2",
      "title": "What is the skills of Strong Junior MLE?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "author": "sunnakh",
      "created_utc": "2026-01-30 11:02:04",
      "score": 37,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "Hello, guys what do u think to reach Middle level Machine Learning Engineer on which skills I should be master ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2labv1",
          "author": "TruthIll4102",
          "text": "IMO a strong junior MLE isn‚Äôt about knowing every model. It‚Äôs more like:\n\n* solid ML fundamentals (classical ML, eval, data leakage, CV)\n* good Python + pandas/numpy, can write clean code not just notebooks\n* basic stats intuition (why things overfit, why metrics lie)\n* some production sense: training to serving to monitoring (even at a small scale)\n* ability to debug models and data\n\nTo move to mid-level, the big jump is owning stuff end-to-end and understanding tradeoffs. You don‚Äôt need to be an expert in everything, just reliable and hard to break",
          "score": 26,
          "created_utc": "2026-01-30 12:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m2gcm",
              "author": "NotYourASH1",
              "text": "Are you an engineer?",
              "score": 1,
              "created_utc": "2026-01-30 14:58:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2m3sqv",
              "author": "sunnakh",
              "text": "This is great information, thank you)",
              "score": 1,
              "created_utc": "2026-01-30 15:04:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yebs5",
          "author": "Madesh_25",
          "text": "Junior MLE must have:\nSolid ML basics (regression, trees, CV, data leakage)\nPython + pandas/numpy (clean code, not just notebooks)\nBasic stats intuition (overfitting, metrics, bias‚Äìvariance)\nDebug data & models\nBasic production sense (train ‚Üí serve ‚Üí monitor)\nTo move to Mid-level:\nOwn projects end-to-end\nChoose models + metrics with reasons\nUnderstand trade-offs (accuracy vs latency, bias vs variance)\nHandle real-world messy data\nWrite maintainable, production-ready code",
          "score": 1,
          "created_utc": "2026-02-01 11:37:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ml5fz",
          "author": "Quiet-Illustrator-79",
          "text": "There‚Äôs no such thing as a junior MLE, work as a software engineer or scientist for a bit.",
          "score": 1,
          "created_utc": "2026-01-30 16:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2poe4y",
              "author": "Soggy-Shopping-4356",
              "text": "Idk why you‚Äôre getting downvoted but it‚Äôs true, MLE is a late-mid to senior role",
              "score": 2,
              "created_utc": "2026-01-31 01:20:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnhc8r",
      "title": "CV Review - ML Engineer (3 Months in, No leads)",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qnhc8r",
      "author": "Far-Run-3778",
      "created_utc": "2026-01-26 14:22:25",
      "score": 35,
      "num_comments": 26,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qnhc8r/cv_review_ml_engineer_3_months_in_no_leads/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o1tnam6",
          "author": "Unlucky_You6904",
          "text": "400 applications with almost no responses is brutal, but it doesn‚Äôt necessarily mean your profile is weak ‚Äì it usually means your CV + targeting aren‚Äôt aligned with what recruiters search for. For ML/GenAI roles I‚Äôd make sure your CV leads with: the exact job titles you‚Äôre targeting, 2‚Äì3 concrete ML projects (problem, data size, models, metrics), and only the tech stack you actually used in production‚Äëlike settings. I‚Äôd also split your search: a smaller number of highly tailored applications (JD keywords reflected in your bullets) plus networking on LinkedIn/Hackathons/Kaggle/Discord so you‚Äôre not relying only on Naukri filters. If you want, you can DM me your CV and 2‚Äì3 job links and I can suggest very specific line‚Äëby‚Äëline changes to improve your hit rate.",
          "score": 19,
          "created_utc": "2026-01-26 14:28:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1tocr7",
              "author": "Far-Run-3778",
              "text": "Thanks a lot for cheering me up and Sure, I would definitely give it a shot. I actually just had one question, actually can you try to read a bit of it and see if it‚Äôs actually understandable and how the wording sounds to you?",
              "score": 1,
              "created_utc": "2026-01-26 14:33:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1uh585",
          "author": "buggy-robot7",
          "text": "I hire ml engineers and will share my candid thoughts. A CV is often skimmed in a very short time, e.g. 60 seconds and a decision is made.\n\n1. Please make the CV 1-page. I‚Äôd recommend cutting down bullet points.\n2. In education, put comma separate keywords of your courses, helps quickly scan your knowledge.\n3. Developed multiple 3D ‚Ä¶ achieving 2x over baselines: I generally prefer explicit model names - what‚Äôs your model name, which baseline model did you beat, etc. More specific, the more you stand out. \n4. Check online tips on how to frame sentences: ‚ÄúDeveloped, built,‚Ä¶‚Äù are very passive words. Instead you should focus on achievement: ‚ÄúImproved, Achieved, etc.‚Äù There are tons of blogs on this out there.\n5. Instead of 7-8 projects, focus on fewer but which are unique and really well built.\n\nFinding a job sucks, wishing you the best, you can do it!",
          "score": 31,
          "created_utc": "2026-01-26 16:42:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1uklnn",
              "author": "Far-Run-3778",
              "text": "Thanks a lot, that was indeed a great feedback",
              "score": 2,
              "created_utc": "2026-01-26 16:57:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1wpo7l",
          "author": "PeeVee_",
          "text": "This is a really strong CV. The combination of physics + large-scale ML + medical imaging / CERN-style data is not something you see often, and the fact that you‚Äôre quantifying impact (2√ó improvements, 50% training time reduction, multi-GPU pipelines) makes it clear this isn‚Äôt just coursework.\n\nOne thing I‚Äôm curious about‚Äîhow are you thinking about positioning yourself going forward? Research-heavy roles, applied ML engineering, or more GenAI/RAG-style systems? Your background seems flexible enough to go a few different directions.",
          "score": 3,
          "created_utc": "2026-01-26 22:34:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wuq8t",
              "author": "Far-Run-3778",
              "text": "Thanks a lot for such a positive feedback. \n\nIt was indeed lot of work to be able to keep all these options open. Generally, I enjoy research heavy roles but at the same time, I try to overwork myself in research. So right now, my ideal role would be applied ML Engineering where I will do all the model building stuff + deployment but at the same time occasionally, also work on designing an agentic RAG system as well. This way, I would have more flexibility for my future roles as well.",
              "score": 1,
              "created_utc": "2026-01-26 22:58:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vav08",
          "author": "Leading_Pay4635",
          "text": "I‚Äôve gotten feedback that in the current hiring market, recruiters are looking for exact tech stack matches. Keep in mind they aren‚Äôt technical, so they can‚Äôt read between the lines of you dont have every part of the stack listed.¬†",
          "score": 2,
          "created_utc": "2026-01-26 18:49:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1vcc9l",
              "author": "Far-Run-3778",
              "text": "Yeah it definitely makes sense but does that means, Should I have all the tech stack mentioned in the skills section? or Should i twist my bullet points in a way that such that it has key Tech stack mentioned in the bullet points? or both?",
              "score": 2,
              "created_utc": "2026-01-26 18:56:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ve4ex",
                  "author": "Leading_Pay4635",
                  "text": "I‚Äôm not really sure what is preferred in terms of formatting. My point was mostly that hiring is strict right now, the first line of scrutiny is by someone who only recognizes keywords. Could replace these fools with AI before anyone else tbh.¬†",
                  "score": 2,
                  "created_utc": "2026-01-26 19:03:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1y4zkw",
          "author": "HowToBeAwkward_7",
          "text": "experience not coming across. Adapt mentality from focusing on domain skills to that of addressing business needs with complex methods. How did you impact the business, productivity, etc. Most bullets should have qualitative/quantitative outcome. You did the thing but why should they care. \n\n  Do not list basic skills that don‚Äôt differentiate (GitHub repo creation, docker image, etc)\n\nRAG is outdated. If you are going to show experience in ai you need to keep up\n\nMinor- but I hate 2 page resume. You took almost half a page to write irrelevant details/basic skills/common tooling\n\n  Best of luck",
          "score": 2,
          "created_utc": "2026-01-27 03:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yrsvj",
              "author": "Far-Run-3778",
              "text": "Thanks a lot for this review. I have kept basic skills just for sake of ATS honestly and RAG is outdated is understandable, I will try working on some better properly agentic projects. I actually tried to make it one page, it was just kinda hard, will give ut a try again or maybe tailor versions of this can be one page",
              "score": 1,
              "created_utc": "2026-01-27 05:25:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ys53o",
                  "author": "HowToBeAwkward_7",
                  "text": "We highly value ml scientists with software engineering skills. You just have to expand beyond basics was only point I was trying to make. It‚Äôs an extremely tough market and wish you the besr",
                  "score": 2,
                  "created_utc": "2026-01-27 05:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1uw80s",
          "author": "Timus0708",
          "text": "You exp looks good to me, refine your resume and DM me\nwe are on hiring spree, you will get a interview aleast\n\nOne of top US banks- AI/ML role - Blr/Gurgaon location -",
          "score": 2,
          "created_utc": "2026-01-26 17:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1v753r",
              "author": "Far-Run-3778",
              "text": "Done and thanks a lot for this!",
              "score": 0,
              "created_utc": "2026-01-26 18:34:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1vsqmv",
          "author": "crizzy_mcawesome",
          "text": "I see so much unused space. First thing i would do is condense it within 1 page. 2nd give it gemini or claude and ask it to make the bullet points ATS friendly",
          "score": 1,
          "created_utc": "2026-01-26 20:06:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1wibd1",
              "author": "Far-Run-3778",
              "text": "I tried condensing it to one page earlier and couldn‚Äôt really do it but will sure give it a try again",
              "score": 1,
              "created_utc": "2026-01-26 22:00:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1x8a27",
                  "author": "crizzy_mcawesome",
                  "text": "Also Keep the projects to one bullet point per. No one is going to read your project descriptions otherwise",
                  "score": 1,
                  "created_utc": "2026-01-27 00:07:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1y0f3l",
          "author": "drwebb",
          "text": "I review ML CVs all the time, and I definitely wouldn't toss it out, it would be placed in the call back pile. However, a lot of ML work now involves a lot of transformer architectures, would be nice to see project or something. I usually would ask a candidate at least to describe what a decoder block is. The actual modeling aspects look more like standard DNN architecture, and classical machine learning, those are good projects though. The agentic and RAG stuff is new area, and good to include.",
          "score": 1,
          "created_utc": "2026-01-27 02:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1yr9e4",
              "author": "Far-Run-3778",
              "text": "Thanks a lot and actually I don't have experience with transformers as well. I developed a kind of new efficient attention mechanism when I was a research intern and I tried out VITs as well",
              "score": 1,
              "created_utc": "2026-01-27 05:21:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1zhqa4",
          "author": "BlobbyMcBlobber",
          "text": "Your only experience is an internship?",
          "score": 1,
          "created_utc": "2026-01-27 09:03:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1zk4ja",
              "author": "Far-Run-3778",
              "text": "Yeah, thats true. Although my course was pretty prestigious and during my course, we worked with people who work with CERN and under their supervision, we conducted some hands on experiments with different type of sensors and we were given task and infrastructure access to work with dataset from CERN, IceCube laboratory -> Generally, people do CS internships at CERN to learn that",
              "score": 1,
              "created_utc": "2026-01-27 09:26:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1zsetr",
          "author": "CountryDue8065",
          "text": "400 applications with barely any callbacks usually means you need way more volume to break through, not just CV tweaks. Been seeing SimpleApply (https:/ /simpleapply .ai) recommended a lot for ML roles lately since it automates the whole application process and customizes your materials for each job, so you can hit way more postings without burning out on teh repetitive stuff.",
          "score": 1,
          "created_utc": "2026-01-27 10:41:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o213u63",
              "author": "Far-Run-3778",
              "text": "Thanks and sure, i can give it a try",
              "score": 1,
              "created_utc": "2026-01-27 15:27:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qq90xu",
      "title": "What is the best way to learn ML",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qq90xu/what_is_the_best_way_to_learn_ml/",
      "author": "vetti_pechalar",
      "created_utc": "2026-01-29 13:48:30",
      "score": 35,
      "num_comments": 11,
      "upvote_ratio": 0.85,
      "text": "I currently enrolling in 4th sem of cse specialization of ai ml,i like to learn ml completely.so friends or peers kindly suggest the best way to learn ml completely.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qq90xu/what_is_the_best_way_to_learn_ml/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2excf1",
          "author": "DataCamp",
          "text": "The most effective way to learn ML is to do it in layers. Start with Python plus just enough math to understand what models are doing (linear algebra for vectors/matrices, basic probability, and gradients).   \n  \nThen learn core ML concepts alongside practice: supervised vs unsupervised learning, model evaluation, overfitting, and feature engineering.   \n  \nWhile you‚Äôre learning each concept, train small models in scikit-learn on real datasets so the theory sticks. After that, you can go deeper into areas like deep learning, NLP, or MLOps depending on what you want to work on,  but the main thing is learning ML while building, not waiting until you ‚Äúknow everything‚Äù first.",
          "score": 23,
          "created_utc": "2026-01-29 14:19:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jwuh5",
              "author": "TotallyNota1lama",
              "text": "Great advice wanted to add¬†https://github.com/hkevin01/Machine-Learning-Model. A project I been playing with; just another tool to try¬†",
              "score": 2,
              "created_utc": "2026-01-30 05:30:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2k0yck",
              "author": "Strange-Inflation-73",
              "text": "heyy what resources do you suggest for getting good at model evaluation overfitting feature engineering data handling concepts",
              "score": 1,
              "created_utc": "2026-01-30 06:01:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2nbpy0",
                  "author": "DataCamp",
                  "text": "A sequence that could work well and that we've got courses for:   \n  \n‚Ä¢ Supervised Learning with scikit-learn: you‚Äôll actually train models, compare metrics, spot overfitting, and tune hyperparameters on real datasets  \n[https://www.datacamp.com/courses/supervised-learning-with-scikit-learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn?utm_source=chatgpt.com)\n\n‚Ä¢ Feature Engineering for Machine Learning in Python: very practical, covers leakage, encoding, scaling, and when features help vs hurt  \n[https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python](https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python)\n\n‚Ä¢ Model Validation in Python: cross-validation, bias/variance tradeoffs, and choosing the right metrics  \n[https://www.datacamp.com/courses/model-validation-in-python](https://www.datacamp.com/courses/model-validation-in-python)",
                  "score": 2,
                  "created_utc": "2026-01-30 18:21:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ffut3",
          "author": "Holiday_Lie_9435",
          "text": "Also learning ML right now and it's mostly self-study. I'd say the 'best' way really depends on your learning style, but a mix of different mediums/resources usually works. Structured courses like *Andrew Ng's Machine Learnin*g course on Coursera are classic for a reason since they give you a strong foundation. Then, maybe you can branch out into more specialized areas that pique your interest, like NLP or computer vision, using resources like [fast.ai](http://fast.ai) or specific textbooks like *Computer Vision: Algorithms and Applications* by Richard Szeliski. Having a roadmap (even a loose one) really helps to stay on track, can link something structured that helped me a lot if it's something you're interested in.",
          "score": 1,
          "created_utc": "2026-01-29 15:47:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2fx2lw",
              "author": "melodyofasong",
              "text": "Agreed. As for road map, you can look through machine learning on roadmap.sh",
              "score": 0,
              "created_utc": "2026-01-29 17:03:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2gk1kl",
          "author": "Cultural_Book_400",
          "text": "you guys are all good at math right? for me, I try to learn ML but math really gets in the way. I am sorry, I am too not so great for this....   Is there way for none math person to learn ML or am i hopeless completely.",
          "score": 1,
          "created_utc": "2026-01-29 18:46:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2i9muw",
              "author": "bean_217",
              "text": "Yeah I'm honestly not great at the math part either. I can understand how it works with a good explanation, but not if a paper just slaps you with an equation and says \"that right there is attention\".\n\nIf you do struggle with the math, I recommend checking out channels like StatQuest on YouTube.\n\n They explain things step by step. Though sometimes they make things too simple by, for example, not using linear algebra where it would obviously make things easier.\n\nBest of luck to you.",
              "score": 3,
              "created_utc": "2026-01-29 23:47:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2grp10",
          "author": "udede",
          "text": "as a dev who just launched a migraine app with an ai prediction engine, my biggest advice is: don't get stuck in tutorial hell. 4th semester is the perfect time to start building a real-world project.\n\ntheoretically, you'll learn a lot in class, but you'll only 'get it' when you try to implement something like a 3d pain mapping system or an ai report generator using real datasets.\n\nfocus on these 3 things:\n\n1. **data cleaning:** in the real world, data is messy. learning how to handle outliers is 80% of the job.\n2. **api integration:** learn how to connect your models to a mobile or web app (i used fastapi and groqcloud for mine).\n3. **user privacy:** especially in health-tech, learning about secure data handling is just as important as the model accuracy.\n\nbuild something small, ship it, and look at your app store metrics. that's where the real learning starts. good luck!",
          "score": 1,
          "created_utc": "2026-01-29 19:22:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2g4nid",
          "author": "Ok_Aide140",
          "text": "–£—á–∏—Ç—å—Å—è, —É—á–∏—Ç—å—Å—è, —É—á–∏—Ç—å—Å—è!",
          "score": -2,
          "created_utc": "2026-01-29 17:38:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}