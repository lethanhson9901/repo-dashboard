{
  "metadata": {
    "last_updated": "2026-02-09 09:19:58",
    "time_filter": "week",
    "subreddit": "learnmachinelearning",
    "total_items": 20,
    "total_comments": 188,
    "file_size_bytes": 174678
  },
  "items": [
    {
      "id": "1qz8go6",
      "title": "this website is literally leetcode for ML",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/2ulb64z2s9ig1",
      "author": "Ccrystal4216",
      "created_utc": "2026-02-08 13:07:12",
      "score": 442,
      "num_comments": 18,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qz8go6/this_website_is_literally_leetcode_for_ml/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4c06pa",
          "author": "Plorntus",
          "text": "So you just happened to stumble upon this website, take the same video the creator has been uploading everywhere to reddit (https://reddit.com/r/StableDiffusion/comments/1qpo9vl/ml_research_papers_to_code/) and thought you'd post it here?\n\nDisclose your advertisements.",
          "score": 34,
          "created_utc": "2026-02-08 22:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c1t5q",
              "author": "Ccrystal4216",
              "text": "i downloaded their video onlyüò≠\n\ni hope the creator doesn't mind some free advertising",
              "score": -36,
              "created_utc": "2026-02-08 22:51:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o490a0g",
          "author": "Starkboy",
          "text": "looks very cool , thanks for sharing!",
          "score": 18,
          "created_utc": "2026-02-08 13:37:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49gidr",
              "author": "Letzbluntandbong",
              "text": "For sure! The math modules are super helpful for solidifying concepts. Have you tried any specific problems yet?",
              "score": 1,
              "created_utc": "2026-02-08 15:11:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4c70jp",
          "author": "jack-of-some",
          "text": "6 year old account, meticulously cleaned out history with only this post and the one comment on it visible ...\n\nYeah this isn't an ad at all.",
          "score": 16,
          "created_utc": "2026-02-08 23:21:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ap54u",
          "author": "Lucky-Image-4597",
          "text": "Built by chatgpt ahh website ",
          "score": 13,
          "created_utc": "2026-02-08 18:47:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4b3iso",
              "author": "CriticalTemperature1",
              "text": "Does it matter if its from chatgpt if its useful tho",
              "score": 5,
              "created_utc": "2026-02-08 19:56:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ecp3o",
                  "author": "usefulidiotsavant",
                  "text": "So then just use a LLM to be your tutor, sum up the state of research on topics that are new for you, make it ask you questions and propose problems etc. It's much higher quality education (and more effective per unit of time) that I ever got from any university, and it's basically free.\n\nNo need to shell money from a vibecoded interface that ossifies  someone else's idea of what you need to learn.",
                  "score": 2,
                  "created_utc": "2026-02-09 07:39:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4a1tiy",
          "author": "abhbhbls",
          "text": "Here is another https://tensorgym.com",
          "score": 10,
          "created_utc": "2026-02-08 16:57:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4aadph",
          "author": "CapablePotato",
          "text": "Is this a paid service? Just checked into it, but couldn‚Äôt find pricing.",
          "score": 6,
          "created_utc": "2026-02-08 17:38:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4aphhq",
          "author": "Natemophi",
          "text": "Solved 22/150 Problems so far\n\nAlso nice that test cases are finally visible \n\nNot attempted the Research problems yet",
          "score": 3,
          "created_utc": "2026-02-08 18:48:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49azlj",
          "author": "Silent_Peanut8567",
          "text": "pdawg spotted ",
          "score": 5,
          "created_utc": "2026-02-08 14:41:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dk8ii",
          "author": "notsofastaicoder",
          "text": "How do you make this kind of product video",
          "score": 2,
          "created_utc": "2026-02-09 03:55:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dmajk",
          "author": "Positive-Intern-5939",
          "text": "How much did the founder paid you for this?\n\nCan I join the marketing team too?",
          "score": 1,
          "created_utc": "2026-02-09 04:09:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49dexm",
          "author": "Smooth-Disaster3798",
          "text": "that's so cool.arigat≈ç, sensei.",
          "score": 1,
          "created_utc": "2026-02-08 14:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ee1do",
          "author": "No-Wrongdoer1409",
          "text": "Classic vibe coded ahh website",
          "score": 0,
          "created_utc": "2026-02-09 07:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ad5go",
          "author": "Responsible_Cow2236",
          "text": "Curious, does it also ‚Äúteach‚Äù in a sense? Like a tutorial so to speak.",
          "score": -1,
          "created_utc": "2026-02-08 17:52:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a04tk",
          "author": "awscloudengineer",
          "text": "Instead of leetcode style, is there a website that tests you conceptually because the code is now written by LLMs.",
          "score": -5,
          "created_utc": "2026-02-08 16:49:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qu0vgq",
      "title": "Finally getting interviews!!",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/yfp7ce1h54hg1.jpeg",
      "author": "Full_Meat_57",
      "created_utc": "2026-02-02 17:07:16",
      "score": 377,
      "num_comments": 42,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qu0vgq/finally_getting_interviews/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o38oxth",
          "author": "Cheek_Powerful",
          "text": "If all your languages are <C1, then what is your native tongue?",
          "score": 20,
          "created_utc": "2026-02-02 22:44:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3apqd7",
              "author": "chaitanyathengdi",
              "text": "\"Chinese A1\"",
              "score": 11,
              "created_utc": "2026-02-03 06:02:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3bdpiw",
              "author": "Full_Meat_57",
              "text": "Hindi",
              "score": 8,
              "created_utc": "2026-02-03 09:43:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3o9f8w",
                  "author": "Bangoga",
                  "text": "Damn dude. Insane.",
                  "score": 1,
                  "created_utc": "2026-02-05 06:16:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3aon4u",
          "author": "axiomaticdistortion",
          "text": "OP is most likely in Germany and that‚Äôs the worst job market seen in decades. If you are looking to build a future in tech, do yourself a favor and look further. Thank me later.",
          "score": 7,
          "created_utc": "2026-02-03 05:53:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ekdm8",
              "author": "Candid-Cobbler-510",
              "text": "Worst in germany right? I believe it is easier to get a job in germany than elsewhere.",
              "score": 3,
              "created_utc": "2026-02-03 20:19:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3m9gxa",
                  "author": "LordFungie",
                  "text": "Tech in Germany is suffering a lot. Most companies are only hiring under 1 year contracts so that when they eventually have to lay people off, it's the new employees, that way they don't have to pay for unemployment benefits.",
                  "score": 1,
                  "created_utc": "2026-02-04 22:57:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bdufn",
          "author": "Full_Meat_57",
          "text": "It‚Äôs simple ms word from scratch",
          "score": 2,
          "created_utc": "2026-02-03 09:44:47",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o38gjw3",
          "author": "EcstaticBank",
          "text": "Could you post the old cv as well to see what really worked and what didn't",
          "score": 2,
          "created_utc": "2026-02-02 22:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38jayj",
              "author": "Full_Meat_57",
              "text": "Check the last post of mine",
              "score": 3,
              "created_utc": "2026-02-02 22:16:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jvur",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o373fuu",
          "author": "migrated-human",
          "text": "Do you make it in Canva or latex? \nI'm only getting rejected even though I've tried doing ats checks and everything",
          "score": 2,
          "created_utc": "2026-02-02 18:13:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37libd",
              "author": "Full_Meat_57",
              "text": "Simple ms word",
              "score": 4,
              "created_utc": "2026-02-02 19:36:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3aouu8",
                  "author": "No-Debt4738",
                  "text": "\"simple\" and \"ms word\" can't be in the same sentence¬†",
                  "score": 10,
                  "created_utc": "2026-02-03 05:55:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38jtuo",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 0,
              "created_utc": "2026-02-02 22:19:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o37y1zz",
              "author": "SithEmperorX",
              "text": "Suffering from the same. Made it all in LaTeX still no reaction.",
              "score": -2,
              "created_utc": "2026-02-02 20:35:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38jwxq",
          "author": "Full_Meat_57",
          "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
          "score": 2,
          "created_utc": "2026-02-02 22:19:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3ap9ar",
              "author": "Spinachforthepope",
              "text": "Great! What did you use? What template and so?\nThanks in advance!",
              "score": 1,
              "created_utc": "2026-02-03 05:58:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3bdqpv",
                  "author": "Full_Meat_57",
                  "text": "I made from scratch in ms word",
                  "score": 1,
                  "created_utc": "2026-02-03 09:43:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o39igur",
          "author": "Status-Supermarket98",
          "text": "Is C1 German is needed for applying in Germany?",
          "score": 1,
          "created_utc": "2026-02-03 01:26:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bdsuh",
              "author": "Full_Meat_57",
              "text": "Not necessarily but all the interviews I got we just spoke German",
              "score": 1,
              "created_utc": "2026-02-03 09:44:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3b536b",
              "author": "acontext60",
              "text": "Not for every role",
              "score": 0,
              "created_utc": "2026-02-03 08:19:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39nc6r",
          "author": "Comfortable-Bath-905",
          "text": "Fantastic!",
          "score": 1,
          "created_utc": "2026-02-03 01:54:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a4v8t",
          "author": "angel_days",
          "text": "Good going dude",
          "score": 1,
          "created_utc": "2026-02-03 03:35:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a4xqw",
          "author": "angel_days",
          "text": "Can you please share your template",
          "score": 1,
          "created_utc": "2026-02-03 03:36:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bvhi0",
          "author": "pixiebutcurly",
          "text": "Please share ypur interview experience too",
          "score": 1,
          "created_utc": "2026-02-03 12:17:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fc604",
          "author": "juicymice",
          "text": "How is the job market in Germany? Starting salary? What type of work permit do Indians require?",
          "score": 1,
          "created_utc": "2026-02-03 22:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hoojv",
              "author": "Full_Meat_57",
              "text": "Yes Germany. Usually the job descriptions stating from 80k to 120k. I guess normal work permit",
              "score": 1,
              "created_utc": "2026-02-04 07:09:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3lghjz",
                  "author": "juicymice",
                  "text": "How's the job market there? Plenty of tech jobs or not too many (as in the US)?",
                  "score": 1,
                  "created_utc": "2026-02-04 20:35:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3gn1g2",
          "author": "[deleted]",
          "text": "the only reason u get interviews is because recruiters fall for the shit you are writing there",
          "score": 1,
          "created_utc": "2026-02-04 02:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3grbeb",
          "author": "Firm_Passage_6844",
          "text": "congrats, all the best",
          "score": 1,
          "created_utc": "2026-02-04 03:11:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i2iz5",
          "author": "Exotic-Hunter-5262",
          "text": "Hey I have some questions.\nI am looking to go over in the same field.\nIf you don't mind can I ask you in dms?",
          "score": 1,
          "created_utc": "2026-02-04 09:17:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iglbd",
              "author": "Full_Meat_57",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-02-04 11:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kf9je",
          "author": "translations-guru",
          "text": "Great job, like the consistency and succinctness! Good luck finding your dream job!",
          "score": 1,
          "created_utc": "2026-02-04 17:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zlljo",
          "author": "CompetitiveAnt3802",
          "text": "Love this, proof that sometimes the resume is the only thing standing between you and interviews. Congrats on the momentum!\n\nNow the key is converting those interviews into offers. If you want to sharpen your interview game, my team's been building a voice-based tool that lets you practice interviews and get real-time feedback: [https://tryupskill.app/](https://tryupskill.app/) still early stage and would love your feedback since you're actively interviewing.\n\nEither way, keep it going! If they're calling you for 6-figure roles, they already think you will be worth it üí™",
          "score": 1,
          "created_utc": "2026-02-06 23:09:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43akw6",
          "author": "confused_8357",
          "text": "Hi , i am on entry level also looking for roles in germany.. may i dm?¬†\n\n\nJust need some guidance on what works",
          "score": 1,
          "created_utc": "2026-02-07 15:16:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38c0rc",
          "author": "ufl_exchange",
          "text": "Are you applying for jobs in the US or Germany?",
          "score": 1,
          "created_utc": "2026-02-02 21:41:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j583",
              "author": "Full_Meat_57",
              "text": "Germany only",
              "score": 4,
              "created_utc": "2026-02-02 22:15:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o37ubx4",
          "author": "MMechree",
          "text": "Could you share a template, please?",
          "score": 0,
          "created_utc": "2026-02-02 20:17:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j87r",
              "author": "Full_Meat_57",
              "text": "It‚Äôs simple ms word, I made everything from scratch",
              "score": 2,
              "created_utc": "2026-02-02 22:16:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jurg",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwldsm",
      "title": "I have 200 subscriptions and 15% of them are fake",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/r37p88fbgohg1.png",
      "author": "No-Swordfish7597",
      "created_utc": "2026-02-05 13:33:04",
      "score": 256,
      "num_comments": 39,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qwldsm/i_have_200_subscriptions_and_15_of_them_are_fake/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3przqm",
          "author": "ImpossibleAgent3833",
          "text": "How are you even spending 85k every f month on subscriptions üò≠ Are you running a small country? I can‚Äôt imagine keeping mental track of 230 tools",
          "score": 187,
          "created_utc": "2026-02-05 13:47:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pwu54",
              "author": "odinti",
              "text": "fr, is this guy paying for calculator api? CSSaaS ? Wtf",
              "score": 67,
              "created_utc": "2026-02-05 14:14:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q327f",
                  "author": "deadc0de",
                  "text": "This makes me wonder if I‚Äôm getting over charged for is-odd.com?  Anyone one know of an AI that can answer this for me?",
                  "score": 28,
                  "created_utc": "2026-02-05 14:47:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3s6nxu",
              "author": "DistanceSolar1449",
              "text": "It‚Äôs a good thing this guy is good at ML which is in demand rn, because he‚Äôs clearly regarded at other things.",
              "score": 13,
              "created_utc": "2026-02-05 20:42:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3tmyeb",
                  "author": "ashvy",
                  "text": "bro is just vibe subscription maxxing",
                  "score": 3,
                  "created_utc": "2026-02-06 01:17:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o41ppfb",
              "author": "notAllBits",
              "text": "Have you tried scaling generative code projects?",
              "score": 1,
              "created_utc": "2026-02-07 07:53:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3q421h",
          "author": "LoveThemMegaSeeds",
          "text": "If you really have 200 subscriptions per month, then you are retarded and I definitely don‚Äôt want to buy anything you are selling",
          "score": 170,
          "created_utc": "2026-02-05 14:52:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pqsxu",
          "author": "Kaenguruu-Dev",
          "text": "Yes you could use AI, or you could just have hard limits that you define once and trigger alerts based on maths and you're done.",
          "score": 62,
          "created_utc": "2026-02-05 13:41:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qjbzj",
              "author": "Ok-Interaction-8891",
              "text": "But then they wouldn‚Äôt have an AI project to link and share!",
              "score": 20,
              "created_utc": "2026-02-05 16:06:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pylc7",
          "author": "donotfire",
          "text": "For real how do you even spend that much monthly on subscriptions",
          "score": 16,
          "created_utc": "2026-02-05 14:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uyapf",
              "author": "ColtranezRain",
              "text": "Maybe his unit for counting is pennies?!",
              "score": 2,
              "created_utc": "2026-02-06 06:32:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pq8kz",
          "author": "IllustratorOk7590",
          "text": "the fact that 15% of vendors can overcharge and nobody notices is crazy, 200+ subscriptions no human can track that. This feels like something every startup will need eventually, thanks for sharing",
          "score": 48,
          "created_utc": "2026-02-05 13:37:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3rcdyf",
              "author": "MurkyTrainer7953",
              "text": "‚Äú*It‚Äôs not my money, it‚Äôs ‚ÄúVC‚Äôs‚Äù money.*‚Äù\n\n‚Äú*The more I spend, the more they invest, the higher the valuation*‚Äù\n\n‚ÄîNo_Swordfish (probably)",
              "score": 5,
              "created_utc": "2026-02-05 18:20:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ptfk0",
              "author": "General-Put-4991",
              "text": "If you buy subscriptions for everything and don't check them, it's normal",
              "score": 16,
              "created_utc": "2026-02-05 13:55:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3tds6j",
              "author": "rotatingphasor",
              "text": "I could build a pretty good subscription platform to track subscriptions.",
              "score": 5,
              "created_utc": "2026-02-06 00:24:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rws26",
          "author": "probono84",
          "text": "Wtf my dude",
          "score": 3,
          "created_utc": "2026-02-05 19:54:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3t5dos",
          "author": "Alternative_Horse_56",
          "text": "And that's why businesses have vendor management processes. It seriously wouldn't be a huge lift to have someone track all of these subscriptions and payments, then flagging/disputing suspicious charges. It's like a handful of hours per month to verify subscription lists and verify the payments.",
          "score": 3,
          "created_utc": "2026-02-05 23:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qtssj",
          "author": "joshuaherman",
          "text": "I work at an anti fraud company and it is not something you would to roll yourself.",
          "score": 6,
          "created_utc": "2026-02-05 16:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pr1n6",
          "author": "ComfortableHot6840",
          "text": "Lk this could be a SaaS product. Startups bleeding money on tool sprawl is universal. Automated anomaly detection + subscription auditing would sell instantly to finance teams",
          "score": 11,
          "created_utc": "2026-02-05 13:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pv0sn",
              "author": "slightlyintoout",
              "text": "It would be great if it also covered cloud spend (as well as individual subscriptions). Similar issue - sign up for some subscription you don't use but never cancel vs spin up some cloud service and then don't spin it down. There are already some tools for the cloud stuff but 'all in one' would be great\n\nI wonder what % of AWS/Google/MS revenue is redundant cloud spend. I bet it is $$$$$$$.",
              "score": 5,
              "created_utc": "2026-02-05 14:04:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3psqnp",
              "author": "Dangerous_Formal_870",
              "text": "100% agree this smells like a SaaS opportunity, CFOs would absolutely pay for automated subscription auditing. It‚Äôs one of those boring problems",
              "score": 5,
              "created_utc": "2026-02-05 13:52:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pt2xp",
              "author": "Curious_Key2609",
              "text": "Yeah finance teams would eat this up",
              "score": 1,
              "created_utc": "2026-02-05 13:53:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3snxnw",
          "author": "Bangoga",
          "text": "You have a startup and you spend 85k on subscriptions?? That is a big amount for a early stage startup to be burning",
          "score": 2,
          "created_utc": "2026-02-05 22:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3t7c6y",
          "author": "PushCharacter8496",
          "text": "200 subscriptions is basically a fulltime job, so 15 percent being fake sounds sadly believable. Since you already know it‚Äôs around 30ish bogus ones, set pervendor spend caps and a weekly alert for new merchants or duplicate charges, and do a quick monthly sweep to cancel anything without a real owner or recent usage.",
          "score": 2,
          "created_utc": "2026-02-05 23:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uabdf",
          "author": "siegevjorn",
          "text": "Hey, it's time to subscribe to an AI tool to pinpoint every fake /overcharging subscription! They'll just need API token for all of your subscriptions for $10/month!",
          "score": 2,
          "created_utc": "2026-02-06 03:38:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3prmdl",
          "author": "Critical_Cod_2965",
          "text": "this is one of the more practical ML applications I‚Äôve seen posted here, great one",
          "score": 3,
          "created_utc": "2026-02-05 13:45:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s3ryc",
          "author": "Menza30",
          "text": "That‚Äôs an insanely high number of subscriptions and amount spent. But to each their own.",
          "score": 1,
          "created_utc": "2026-02-05 20:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sh4ke",
          "author": "laststand1881",
          "text": "Gr8 to know that VC‚Äôs have trust in your Saas . But What did you build ?",
          "score": 1,
          "created_utc": "2026-02-05 21:32:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tty71",
          "author": "CarzyCrow076",
          "text": "Do you pay subscription, each time your Phone‚Äôs screen light up??",
          "score": 1,
          "created_utc": "2026-02-06 01:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q3n4d",
          "author": "mpaes98",
          "text": "Many vendors know they are over charging and take the calculated risk that you‚Äôll either not notice or not go through the hassle of fixing it.",
          "score": 1,
          "created_utc": "2026-02-05 14:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3prej8",
          "author": "Capable-Pool759",
          "text": "You used this AI aagentfor a painfully real problem, very smart 6k/month leakage is the kind of thing founders lose sleep over",
          "score": 0,
          "created_utc": "2026-02-05 13:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pqjok",
          "author": "DecentVast7649",
          "text": "what heyneo is doing under the hood. Is it just wrapping standard models or actually running agent-style retraining and feature engineering? Haven‚Äôt seen it used before.",
          "score": 0,
          "created_utc": "2026-02-05 13:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pxglu",
          "author": "raakas",
          "text": "Sorry off the topic but how did you get those charts? Monarch?",
          "score": 0,
          "created_utc": "2026-02-05 14:18:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q2f4v",
          "author": "tennisanybody",
          "text": "I don‚Äôt understand why people don‚Äôt use an empty debit card to sign up for subscriptions. I want the transaction to fail. You want to be reminded you‚Äôre paying monthly for something. Set and forget is a horrible mindset! Never put recurring charges on a credit card. Those fuckers will do any and everything to make sure a charge goes through!\n\nEDIT: if you‚Äôre in the US, cashapp, venmo, paypal all offer debit cards. Use one of them and have $1 sitting there for ‚Äúvalidation‚Äù.",
          "score": 0,
          "created_utc": "2026-02-05 14:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tdo1x",
          "author": "rotatingphasor",
          "text": "200 subscriptions!? Are you a company?",
          "score": 0,
          "created_utc": "2026-02-06 00:23:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q31wq",
          "author": "churninbutter",
          "text": "This is really cool, would you mind sharing it with me? I‚Äôd like to mess around with it",
          "score": -1,
          "created_utc": "2026-02-05 14:47:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyjjui",
      "title": "Interactive visualisation of PyTorch models from notebooks [torchvista update]",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/8bg4vhr4jzhg1",
      "author": "Dev-Table",
      "created_utc": "2026-02-07 17:20:15",
      "score": 185,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qyjjui/interactive_visualisation_of_pytorch_models_from/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o441abb",
          "author": "kahnpur",
          "text": "Nice! Great job",
          "score": 3,
          "created_utc": "2026-02-07 17:28:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4aygt4",
          "author": "juanurena",
          "text": "I will have a look, keep working on it",
          "score": 1,
          "created_utc": "2026-02-08 19:31:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qul8t5",
      "title": "Transformer Co-Inventor: \"To replace Transformers, new architectures need to be obviously crushingly better\"",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/ovgdl1e4e7hg1",
      "author": "Tobio-Star",
      "created_utc": "2026-02-03 07:08:08",
      "score": 105,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qul8t5/transformer_coinventor_to_replace_transformers/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3c66ez",
          "author": "terem13",
          "text": "Yep, and combined with current AI bubble it creates perpetual cycle of inflating current models, instead of pursuing another architectures, for example Mamba and its successors.\n\nEmergent features of transformers are known and there are lots of crutches invented to compensate transformer deficiencies, to keep models inflating.\n\nOpenAI is a best example of such deeply flawed approach: they literally sat on piles of cash up until Google appeared with their transformer algorithm.",
          "score": 23,
          "created_utc": "2026-02-03 13:26:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d7f4i",
              "author": "Tobio-Star",
              "text": "Oh there have been more interesting ideas than even Mamba!",
              "score": 7,
              "created_utc": "2026-02-03 16:34:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3csu79",
          "author": "lordnacho666",
          "text": "What are some keywords for these better architectures?",
          "score": 9,
          "created_utc": "2026-02-03 15:25:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e9ev6",
              "author": "Tobio-Star",
              "text": "I can't speak for the interviewee and tell you the exact architectures he was referring to, but I post articles about as many interesting and novel architectures as I can find on r/newAIParadigms \n\nOff the top of my head I think Titans and Atlas might qualify? (although they do feature elements from Transformers)",
              "score": 7,
              "created_utc": "2026-02-03 19:28:11",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3f8iff",
              "author": "Emotional_Thanks_22",
              "text": "continuous thought machines is one of their publications, could be interesting in the future maybe? (haven't fully read it). but transformer is still going to stay for a few years+",
              "score": 1,
              "created_utc": "2026-02-03 22:11:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fs89d",
          "author": "RJSabouhi",
          "text": "Everyone keeps trying to beat Transformers at their own game, which is growing tiresome: bigger context, faster attention, etc. It‚Äôs the fact that Transformers don‚Äôt actually reason which necessitates a new approach.\n\nWith no long-term internal state, no phase structure, no drift correction, no symbolic consistency. The replacement won‚Äôt even look like a Transformer at all. It‚Äôll be more like a system with operators, phases, and persistent internal dynamics. A reasoning engine built on top of representation.",
          "score": 5,
          "created_utc": "2026-02-03 23:55:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hr2pd",
              "author": "Tobio-Star",
              "text": "Interesting, can you tell more about your vision? Is it a deep learning approach at all? Something completely new?",
              "score": 1,
              "created_utc": "2026-02-04 07:31:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3egyy4",
          "author": "JackandFred",
          "text": "Really great video, haven‚Äôt seen this podcast before but touches on what so many people have been saying.",
          "score": 3,
          "created_utc": "2026-02-03 20:03:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f09in",
          "author": "NightmareLogic420",
          "text": "Does he discuss what these new architectures are?",
          "score": 2,
          "created_utc": "2026-02-03 21:33:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quizvt",
      "title": "[Keras] It was like this for 3 months........",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/wogjyb9ep7hg1.png",
      "author": "lamogpa",
      "created_utc": "2026-02-03 05:04:51",
      "score": 105,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quizvt/keras_it_was_like_this_for_3_months/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3akeze",
          "author": "jonsca",
          "text": "Everyone underestimates that whole \"understand what you're doing\" thing these days.",
          "score": 91,
          "created_utc": "2026-02-03 05:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ap8pz",
              "author": "chaitanyathengdi",
              "text": "\"ChatGPT, do this for me\"",
              "score": 17,
              "created_utc": "2026-02-03 05:58:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3bxubr",
                  "author": "Mad_Chemistry",
                  "text": "I was trying to learn multi threading and asked gpt to suggestions on how to optimize my code. It put loading the model inside a fucking loop that select each data. Smh",
                  "score": 5,
                  "created_utc": "2026-02-03 12:33:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3almak",
              "author": "ToSAhri",
              "text": "I feel that.",
              "score": 3,
              "created_utc": "2026-02-03 05:29:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3anmf4",
          "author": "intruzah",
          "text": "Vibe coding amrite",
          "score": 23,
          "created_utc": "2026-02-03 05:45:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bwni7",
          "author": "PixelLight",
          "text": "If I'm understanding, they loaded the model for every single prediction? They need to learn python is about the politest way I can put this.",
          "score": 14,
          "created_utc": "2026-02-03 12:25:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4446c3",
              "author": "Newer_Sun",
              "text": "uhm but isn't it possible to make such a mistake, if the code that we're writing is very long? even if you know python",
              "score": 1,
              "created_utc": "2026-02-07 17:42:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3doan5",
          "author": "SweetSure315",
          "text": "This is the ML version of \"add a 30 second wait so you can change it to 15 seconds and claim a 100% performance boost\"",
          "score": 8,
          "created_utc": "2026-02-03 17:52:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b75dz",
          "author": "Visual-Run-4718",
          "text": "I‚Äôm not even in ML and yet I could figure out that was dumb",
          "score": 11,
          "created_utc": "2026-02-03 08:39:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvv965",
      "title": "You probably don't need Apache Spark. A simple rule of thumb.",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qvv965/you_probably_dont_need_apache_spark_a_simple_rule/",
      "author": "IT_Certguru",
      "created_utc": "2026-02-04 17:42:54",
      "score": 87,
      "num_comments": 14,
      "upvote_ratio": 0.92,
      "text": "I see a lot of roadmaps telling beginners they MUST learn Spark or Databricks on Day 1. It stresses people out.\n\nAfter working in the field, here is the realistic hierarchy I actually use:\n\n1. Pandas: If your data fits in RAM (<10GB). Stick to this. It's the standard.\n2. Polars: If your data is 10GB-100GB. It‚Äôs faster, handles memory better, and you don't need a cluster.\n3. Apache Spark: If you have Terabytes of data or need distributed computing across multiple machines.\n\nDon't optimize prematurely. You aren't \"less of an ML Engineer\" because you used Pandas for a 500MB dataset. You're just being efficient.\n\nIf you‚Äôre wondering when Spark actually makes sense in production, this guide breaks down real-world use cases, performance trade-offs, and where Spark genuinely adds value: [**Apache Spark**](https://www.netcomlearning.com/blog/apache-spark) \n\nDoes anyone else feel like \"Big Data\" tools are over-pushed to beginners?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qvv965/you_probably_dont_need_apache_spark_a_simple_rule/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3kh75c",
          "author": "Sen_ElizabethWarren",
          "text": "Tell that to hiring managers",
          "score": 38,
          "created_utc": "2026-02-04 17:52:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n4j3p",
              "author": "SizePunch",
              "text": "Literally got rejected from a job explicitly because i didn‚Äôt know pyspark well enough. Still sick.",
              "score": 7,
              "created_utc": "2026-02-05 01:50:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kk5mo",
          "author": "Expensive_Culture_46",
          "text": "This goes for like everything. \n\nNo one needs airflow for a single python script that operates on a file that is 700k.",
          "score": 29,
          "created_utc": "2026-02-04 18:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ldqn1",
              "author": "DoctorDabadedoo",
              "text": "I'm facing that right now. Joined a scale up company. Lots of bad design decisions from the past while it was growing, they have started developing some airflow workflows to process some assets and \"future proof\" it, but the volume is not there yet to justify it and development speed is crawling to a stop.\n\nUsing it as glorified Cron with UI it's an overkill for what we have.",
              "score": 2,
              "created_utc": "2026-02-04 20:22:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o43lphv",
                  "author": "Global_Bar1754",
                  "text": "I‚Äôve actually had the opposite experience with using airflow for small deployments. The fact that it is a glorified cron with a ui is exactly why I like it. Cron is hard to monitor and maintain, especially when you have several prod servers to work on. I‚Äôm not in love with airflow, I only use very basic functionality and built my own task/dependency definition interface on top of it to restrict/simplify the api. What alternatives do you have that‚Äôs simpler than airflow but not as as primitive as cron?¬†",
                  "score": 1,
                  "created_utc": "2026-02-07 16:11:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3kmfej",
          "author": "burntoutdev8291",
          "text": "Don't learn tools, but do learn general data engineering patterns, even if they are small data. Learn how to get used to things like yielding and lazy iterators / evaluations. Actually by using torch dataloaders you are already learning a little about data processing, they have things like parallel workers, prefetching etc. Just my personal experience.",
          "score": 13,
          "created_utc": "2026-02-04 18:16:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3m8pkf",
          "author": "padakpatek",
          "text": "beginners learn them because those are the skills listed on job postings.",
          "score": 5,
          "created_utc": "2026-02-04 22:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ltkjc",
          "author": "popcorn-trivia",
          "text": "Great advice. Hope this makes it around.",
          "score": 2,
          "created_utc": "2026-02-04 21:38:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o5714",
          "author": "Glittering_Ice3647",
          "text": "They should learn BigQuery and SQL before touching Spark, from my experience >95% of jobs i see in Spark can be done with a simple SQL query in BQ, it runs faster, scales better and way easier to debug each step and check intermediate results by saving them in bq tables\n\n  \nAnd if they dont have access to BigQuery, and there is enough RAM use SQLLite locally, SQL is under-appreciated data manipulation and analysis tool\n\nSpark is only useful for iterative optimization at scale, but those kinds of jobs are better run on GPUs anyway",
          "score": 2,
          "created_utc": "2026-02-05 05:42:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3me466",
          "author": "CatOfGrey",
          "text": "I'm much lower on this scale, so I'll throw in a lower-level tip: \n\nYou don't even need to use Pandas with Sci-anything or TensorAnything, if some version of a linear model will be helpful!",
          "score": 1,
          "created_utc": "2026-02-04 23:22:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o840l",
          "author": "Commercial-Fly-6296",
          "text": "I thought you cannot use Deep Learning on spark ? Is it available now ?",
          "score": 1,
          "created_utc": "2026-02-05 06:05:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ovws8",
          "author": "AccordingWeight6019",
          "text": "I mostly agree with the spirit of this. In practice, the decision is less about identity as an ML engineer and more about where complexity actually pays for itself. Distributed systems come with real cognitive and operational overhead, and beginners often underestimate that cost. for many problems, local tooling lets you iterate faster and reason more clearly about what the data is doing. spark makes sense when the problem forces your hand, not because a roadmap says it is a prerequisite. I do think it is useful to understand why these systems exist, but that is different from using them by default.",
          "score": 1,
          "created_utc": "2026-02-05 09:45:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy73te",
      "title": "GDA Model",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/s1k6bpmbu0ig1.jpeg",
      "author": "Udbhav96",
      "created_utc": "2026-02-07 07:03:39",
      "score": 73,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qy73te/gda_model/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o41zcqr",
          "author": "JanBitesTheDust",
          "text": "Try to count the amount of parameters when you use two distinct covariance matrices. Sharing the covariance structure reduces parameter count. If you assume independent factors, you can reduce even further, creating a shared diagonal covariance matrix. If you assume that each factor has the same variance, you essentially get a nearest mean classifier. \n\nThe point is: the more simplifying assumptions you make the more your generative model is going to look like a discriminative model",
          "score": 14,
          "created_utc": "2026-02-07 09:27:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41pfu7",
          "author": "Accurate_Meringue514",
          "text": "It‚Äôs just a choice you make to simplify the model.",
          "score": 5,
          "created_utc": "2026-02-07 07:51:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4266nh",
          "author": "thegoldenhornedgoat",
          "text": "The mean for each of p=0 observations and p=1 observations describes where the two groups of observations are centred. The covariance matrix describes how spread out the groups are.\n\nWe only use one covariance matrix in order to simplify the model.\n\nHowever, we must still have two means. If the group of p=1 observations and the group of p=0 observations have the same mean as well as the same covariance matrix, then they are centred in the same place and have the same spread. This would make it impossible to distinguish between the two classes, so the model would not be able to predict Y for new X.",
          "score": 4,
          "created_utc": "2026-02-07 10:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o428xo6",
          "author": "ElNigo_Beats",
          "text": "If you assume that both have same covariance matrix, the decision boundary is linear and thus \"easy\" to be discussed in class.\nIf you assume different covariance matrix, the decision boundary isn't linear anymore. It's called QDA",
          "score": 3,
          "created_utc": "2026-02-07 11:01:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41plks",
          "author": "UhuhNotMe",
          "text": "sometimes it's good to start with simple models when studying a problem\n\nit can make the math easier and facilitate insight generation",
          "score": 2,
          "created_utc": "2026-02-07 07:52:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42223c",
          "author": "Abad0o0o",
          "text": "PRML?",
          "score": 1,
          "created_utc": "2026-02-07 09:54:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42rrnm",
              "author": "Udbhav96",
              "text": "What's that??",
              "score": 1,
              "created_utc": "2026-02-07 13:30:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o441oo6",
          "author": "dsai_acc1",
          "text": "Which book is this?",
          "score": 1,
          "created_utc": "2026-02-07 17:30:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46sjmg",
              "author": "Udbhav96",
              "text": "Cse229 Stanford notes",
              "score": 1,
              "created_utc": "2026-02-08 02:43:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4b77jc",
          "author": "yealumbanfr",
          "text": "iam a noobie in ml and why does this much of math is needed in ml iam now in scikit.learn !! model.predict()",
          "score": 1,
          "created_utc": "2026-02-08 20:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bbhol",
              "author": "Udbhav96",
              "text": "Hahaha... that's the easy way....but the hard way is more rewarding",
              "score": 1,
              "created_utc": "2026-02-08 20:36:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1quqm08",
      "title": "Interview said you dont need a lot of data to train RNN?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1quqm08/interview_said_you_dont_need_a_lot_of_data_to/",
      "author": "IndependenceThen7898",
      "created_utc": "2026-02-03 12:27:26",
      "score": 68,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "Hey,\n\nI had an interview with a consulting company as a data scienctist. They gave me a case for voice recignition to detect a word like ‚Äûhello‚Äú in a 10 second audio.\n\nI recommended to use a cnn. I said for a starting point to collect data we would need around 200 speakers. \n\nThey told me in the interview a cnn is overkill and they expected me to say RNN. And said for a rnn you only need a few collegues like 20 max? I dont believe this is true. Am I wrong and why should i not use a cnn. \n\nThe case asked for a model that is not trained with internet data.  ",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quqm08/interview_said_you_dont_need_a_lot_of_data_to/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3c0z3c",
          "author": "Aswarin",
          "text": "Honestly, interviewer sounds like they didn't know what they're talking about. The above description to me sounds like standard binary classification problem e.g. is the word in this snippet \"hello\" which is easily solveable via a CNN\n\nLike you need no context at all for the above task I could literally say in my 10 second of audio \"blah blah blah hello blah blah blah\" and the \"blahs\" do not help me identify the \"hello\".\n\nWith regards to the 20 vs 200 speakers depends on if they want to generalize across genders, accents, diction etc. If it's one accent in a controlled environment, I could see 20 being good enough. But yeah, youre right to be skeptical",
          "score": 70,
          "created_utc": "2026-02-03 12:54:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c1a52",
              "author": "IndependenceThen7898",
              "text": "yes it‚Äôs incredible, I even explained why i need this amount of data because of diversity, different settings",
              "score": 24,
              "created_utc": "2026-02-03 12:56:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3cb36l",
              "author": "5upertaco",
              "text": "This \\^\\^\\^",
              "score": 2,
              "created_utc": "2026-02-03 13:53:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c03ft",
          "author": "Extra_Intro_Version",
          "text": "Maybe it depends on whether they care how well the model will generalize. Or how you pick those speakers. What characteristics of voices is likely to span the space?",
          "score": 11,
          "created_utc": "2026-02-03 12:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c0a5m",
              "author": "IndependenceThen7898",
              "text": "they didnt say anything about charactistics .. that was the case: \n\nConsider the following hypothetical setup. You lead an AI project which aims to populate an AI model for identifying the activation word ‚ÄúOK Deloitte‚Äù in a ten second long audio time frame, i.e. the model input x is a ten second long audio clip and the model output y is 1 (activation word found) or 0 (activation word not found). The legal department directs you to not use training data downloaded from the internet. Assume you have all available resources in technology, infrastructure and people. Use supervised learning.",
              "score": 4,
              "created_utc": "2026-02-03 12:50:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3fuq51",
                  "author": "Hella_Sus",
                  "text": "_Assume you have all available resources in technology, infrastructure and people_ ‚Ä¶ sure, anything you say! Then from that logic for them using an RNN is no problem at all, even if we overlook the other issues like vanishing/exploding gradients.",
                  "score": 2,
                  "created_utc": "2026-02-04 00:08:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c3r9f",
          "author": "Dry_Philosophy7927",
          "text": "The bigger problem is not which answer is best justified, but the level of emphasis placed on how to find a solution. If your potential boss (or you) say that the other person has a \"wrong\" solution then the most important part of the development cycle is being short cut - there are many solutions that involve trade offs. If the project constraint is only privacy (no public data) AND money/time, maybe an RNN or a smaller dataset size is justified. If the aim is a better performing model and the budget allows then yes a larger dataset is better and yes I think a CNN would get a better result.\n\nDo you think they had right/wrong criteria fir this question? Or possibly, do you think they expected more of a discussion than you offered? It is audio possible that they're idiots.",
          "score": 8,
          "created_utc": "2026-02-03 13:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c4b5w",
              "author": "IndependenceThen7898",
              "text": "well he just said that my solution is wrong and he also said cnns are mainly used for videos and graphic data. I think he just didnt have the knowledge, but I was questioning myself after, because he simply said i‚Äôm totally wrong.",
              "score": 6,
              "created_utc": "2026-02-03 13:15:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3c4vbd",
                  "author": "Dry_Philosophy7927",
                  "text": "I hope you get another job in a reasonable time frame. Sounds like a good inaugural into working for the interviewer.\n\nFor your validation, here's a review paper literally saying both approaches have been used AND combined in this exact use case: https://arxiv.org/html/2312.05640v1",
                  "score": 10,
                  "created_utc": "2026-02-03 13:18:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c2s33",
          "author": "Garry_Scary",
          "text": "So sometimes interviewers treat these questions as a way to see how you would react to intellectual conflict. In engineering there are so many options that ‚Äúwork‚Äù so you often have debates about what‚Äôs right. It sounds like the interviewer wanted to see how you would defend your view when an alternative view was given.\n\nThe best option in interviews like this is to admit you aren‚Äôt aware of any RNNs that do this well and treat the question like a conversation between you and a colleague.",
          "score": 8,
          "created_utc": "2026-02-03 13:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c315e",
              "author": "IndependenceThen7898",
              "text": "I would have been open for a discussion and also did, but he basicslly said my approach is wrong and RNN is the only acceptable answer here",
              "score": 5,
              "created_utc": "2026-02-03 13:07:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ccow5",
                  "author": "AllanSundry2020",
                  "text": "did he say it in the moment, or in feedback afterwards?",
                  "score": 3,
                  "created_utc": "2026-02-03 14:02:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cl3id",
          "author": "vannak139",
          "text": "This sounds like crazy talk. I think everyone is laying out good cases for why the person asking you that might be crazy, what they may have meant. \n\nTo take another angle as devil's advocate, when they \"asked for a model that is not trained with internet data\", perhaps they meant for you to take into account pre-trained models, though it doesn't sound that way with \"no data from internet\". Maybe that's not how they see it. It might be the case that they had in mind a pre-trained model that can calibrate in 20 samples. But more likely, it seems like they might just be under the impression that more classic \"last gen\" voice recognition is recurrent in some way, when its more likely a weird knowledge graph. Maybe they're thinking of a CNN on a raw wave form, vs an RNN on a spectrograph. Idk.",
          "score": 1,
          "created_utc": "2026-02-03 14:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cupkg",
          "author": "Veggies-are-okay",
          "text": "When I encounter stupid questions during interviews, I tend to ask for clarification. If there‚Äôs no clarification, I just lay out my thought process beginning with assumptions. If there is a ‚Äúwrong,‚Äù add it to your list of assumptions and adjust on the fly. Or ask clarifying questions on why they believe this assumption is wrong.\n\nA lot of the time there‚Äôs the content but also the vibes you give. If you‚Äôre not a freaky genius that gets everything in one go, then you have to embody an ideal coworker: someone who‚Äôs proactive, can get the job done, is communicative when they run into issues/roadblocks (you will. Socially finessing your way out of those blockers is just as important of a skill as the technical), and just being a pleasant and interesting person can get you sosososo far in this industry.",
          "score": 1,
          "created_utc": "2026-02-03 15:34:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hyaua",
          "author": "s-jb-s",
          "text": "It sounds like they're pretty old school -- a lot of the field came from mixture modelling and HMMs that emerged in the 80s (think: Rabiner & others) -- later, n-grams & RNNs. If you want to go back even earlier, they were doing Dynamic Time Warping -- big emphasis on feature engineering. RNNs (LSTMs) were the gold standard until the mid-2010s, when big tech companies decided they wanted home assistants (Alexa, Siri, ...) to be a thing. Interestingly, Rabiner (HMM guy), Bengio (RNN guy), and LeCun (CNN guy) were all at Bell Labs around the same time (mostly late 80s/early 90s), with the latter two in a different department than Rabiner. All three have reasonably distinct schools of thought on the problem, but my understanding was that, post-\"The Best RNN is a CNN\", most have moved over to CNNs. Google has a bunch of good papers on this stuff, relating to keyword spotting (Sainath et al., 2015 is a good one to look at if you're interested). \n\nAs it turns out, spatial invariance with respect to spectrograms makes CNNs superior for detecting fixed patterns (think: LeCun). RNNs have many downsides; I'm sure you're aware of them. As others have said, with so little data, the model would almost certainly overfit. There's definitely some nuance (you can train an RNN on very small data sequences if you're very careful... robustness might be questionable). You can also do a lot of interesting feature extraction and data augmentation to enable small RNNs and the likes. So I would strongly argue it is possible with hard limitations. But if you can do that, just use a CNN. Maybe the interviewer wanted latency discussions? In the context of embedded devices, CNNs are still generally lighter than RNNs, unless the use case is something along the lines of streaming.",
          "score": 1,
          "created_utc": "2026-02-04 08:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jsyi0",
          "author": "HolidayAd6029",
          "text": "This so stupid. There is no right or wrong answer here, because this depends a lot on the dataset. There is no theory to back the statement that an RNN is better or that it requires less data. In practice, implementing a CNN is not much different from implementing a RNN. You could probably train both and see which one is better.",
          "score": 1,
          "created_utc": "2026-02-04 16:01:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lm9m8",
          "author": "Ty4Readin",
          "text": "I don't think there is necessarily a right or wrong answer here.\n\nDo you need a training set containing 20 speakers or 200 speakers? I honestly have no clue lol, depends on a lot of factors such as which model you train, how many samples from each speaker, the actual use case and distribution of users, required levels of accuracy/performance, etc.\n\nSame idea with CNN vs RNN. It is hard to say which will definitely perform better or be better for the use case without a lot more context.\n\nHowever, to be fair, I generally lean towards CNN. On a problem like this, I would guess that CNN will probably perform better and likely requires less training data than RNN.\n\nBut it's not a hill I am going to die on. If I have a coworker that is adamant about RNN, I'm willing to experiment with both and we can see which actually performs better.\n\nHowever, the fact that the interviewer was so adamant that \"CNN is wrong, RNN is right\" is a big red flag anyways, so you probably did dodge a bullet.",
          "score": 1,
          "created_utc": "2026-02-04 21:03:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cw4h6",
          "author": "Buster_Sword_Vii",
          "text": "You could generate your data set. Use Elevenlabs or Qwen TTS or vibe voice to generate 200 samples containing \"hello\". Qwen has a model that can generate unique voices, so with some effort you could have a diverse sample size. CNN is the right call for this problem. Obviously generalization on synthetic data isn't going to be as good as real data, but if participant size is a limitation it's a solid work around.",
          "score": 0,
          "created_utc": "2026-02-03 15:41:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtxbns",
      "title": "I learned why cosine similarity fails for compatibility matching",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "author": "Ok_Promise_9470",
      "created_utc": "2026-02-02 15:00:17",
      "score": 63,
      "num_comments": 25,
      "upvote_ratio": 0.8,
      "text": "I've been helping friends build the matching system for their dating app, Wavelength. Wanted to share a lesson I learned the hard way about embedding-based matching  might save someone else the same mistake.\n\n**The approach**: Embed user profiles via LLM into 1536-dim vectors, store in Pinecone, query with ANN + metadata filters. Sub-200ms, scales well, semantically smart ‚Äî \"loves hiking\" matches \"outdoor enthusiast\" automatically.\n\n**What went wrong**: 22% mutual acceptance rate. I audited the rejected high-scoring matches and found this:\n\n    User A: \"Career-focused lawyer, wants kids in 2 years, monogamy essential\"\n    User B: \"Career-focused consultant, never wants kids, open relationship\"\n    \n    Cosine similarity: 0.91\n    Reality: incompatible on two dealbreakers\n    \n\nEmbeddings captured¬†*how someone describes their life*, tone, topic, semantic texture. They completely missed¬†*what someone actually needs*, the structured preferences buried in the prose.\n\nThis wasn't an edge case. It was the dominant failure mode. High similarity, fundamental incompatibility. Two people who sounded alike but wanted completely different things.\n\n**The lesson**: Embedding similarity is necessary but not sufficient for compatibility. If your domain has dealbreakers, hard constraints where incompatibility on a single dimension overrides overall similarity, you need structured signal extraction on top.\n\n**What I did instead**¬†(brief summary):\n\n1. Extracted 26 structured features from natural AI conversations (not surveys, 30% survey completion vs 85% conversational extraction)\n2. Built distance matrices: nuanced compatibility scores (0.0-1.0) instead of binary match/no-match\n3. Added hard filters: 4 dealbreaker features that reject pairs before scoring, zero exceptions\n4. Combined signals:¬†`0.25 √ó text + 0.15 √ó visual + 0.60 √ó features`\n\n22% to 35% with this. Two more stages (personalized weights + bidirectional matching) took it to 68%.\n\nThis generalizes beyond dating; job matching (remote vs on-site is a dealbreaker regardless of skill similarity), marketplace matching (budget overrides preference), probably others.\n\nHas anyone else hit this wall with embeddings? Curious how others handle the structured-vs-semantic tradeoff.\n\nEdit:\nI know how training a biencoder on pairwise data would help, but mining hard negatives in such cases becomes a key challenge and also loses bidirectional non equivalence of liking one another ",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o36ijqm",
          "author": "-Cubie-",
          "text": "If you want a different definition of similarity, then you should finetune your embedding model.\nThe finetuning docs for sentence transformers has a similar example as you, where different systems might consider a certain pair of texts very similar or very dissimilar: https://sbert.net/docs/sentence_transformer/training_overview.html",
          "score": 26,
          "created_utc": "2026-02-02 16:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36m0mf",
              "author": "Ok_Promise_9470",
              "text": "I agree thats a fair point, finetuning on accept/reject pairs would definitely improve retrieval quality and it's something we've considered for the candidate generation step (the Pinecone layer, and finetuning is in progress). The reason we added structured features on top is that even a perfect embedding can't handle three things: \n\n(1) hard dealbreakers that should veto an otherwise-great match, \n\n(2) asymmetric scoring where A‚ÜíB ‚â† B‚ÜíA because users weight features differently, and \n\n(3) interpretability for the feedback loop. \n\nThe embedding narrows 10K users to 10 candidates, the structured layer decides which of those 10 actually has mutual potential.",
              "score": 7,
              "created_utc": "2026-02-02 16:54:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37u6y0",
                  "author": "saw79",
                  "text": "You know more than I do here, so correct me where I'm wrong. But your reasoning doesn't strike me as quite right:\n\n1) Shouldn't hard dealbreakers make the model reduce the cosine similarity significantly? Isn't this an embedding problem? A bad embedding doesn't mean embeddings are bad.\n\n2) I understand that how person A feels about person B doesn't have to match how person B feels about person A, but that isn't what you're trying to estimate. You're trying to estimate the compatibility between A and B, which in my mind IS symmetric. \"are A and B compatible?\" should give the same answer as \"are B and A compatible?\".\n\n3) fair enough :)",
                  "score": 2,
                  "created_utc": "2026-02-02 20:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o377qoo",
          "author": "youniquest",
          "text": "Interesting discussion but the title is misleading. It's not cosine similarity that is failing but rather the embeddings or vector representations of your input. If you have hard dealbreakers another simple approach could be adding a new dimension where two sides of deals breakers have negative values of each other with appropriate weights depending on how important those deal breakers for the user.",
          "score": 12,
          "created_utc": "2026-02-02 18:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38d11p",
              "author": "Substantial_Oil_7421",
              "text": "I agree with this. Your post is interesting but misleading - cosine similarity is not at fault here, the input is. You got a high score because of common tokens; it won‚Äôt pick up the nuance or semantic meaning well.\n\nAlso saw your Substack post and quite frankly, calling things ‚Äúthe embedding trap‚Äù is just a poor choice of words. You can fool a generalist or a strategy person with this kind of fluff but experienced data scientists will catch it quite easily. Didn‚Äôt read beyond that heading",
              "score": 2,
              "created_utc": "2026-02-02 21:46:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38k0l7",
                  "author": "unlikely_ending",
                  "text": "Too harsh\n\nDon't assume bad faith",
                  "score": 3,
                  "created_utc": "2026-02-02 22:20:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o39cuxn",
                  "author": "Ok_Promise_9470",
                  "text": "I can understand your frustration here, but the reason I was talking about cosine similarity is because of the following reasons\n1) model isn't finetuned on dating data of personal\n2) it is a cold start problem so taking off the shelf models seems like a fair choice initially hence the embedding trap\n3) even finetuned embeddings can get you the right top 10 I.e improve your recall over the search space but at the end you need a reranker that views each user differently \n4) reducing it to just 1 number throws interpretability out of the window\n\n\nI hope these make sense to you, as these are some points I have further focused on in the substack article",
                  "score": 0,
                  "created_utc": "2026-02-03 00:54:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o37id9k",
              "author": "Ok_Promise_9470",
              "text": "1. We didnt have that data (dealbreakers) at the start - had to be mined\n2. We need to have a cold start approach to solving it,\n \nso making such simpler approaches only makes sense with the assumption that i have every data point for each user at the start itself, the easiest way to filter similar users was using a user description that we generated post user on-boarding, and that did contain dealbreakers for some but for others it had to be mined using post date feedbacks. Then we used this summary (which kept updating), we used off the shelf pretrained embeddings to start with to do initial filtering of users for finding suitable match (not the best of the methods I agree) but thats where we started",
              "score": 1,
              "created_utc": "2026-02-02 19:21:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36nh6w",
          "author": "No-Square8182",
          "text": "The stable marriage problem has non ML algos that should be employed once you get the scores. The problem is model choice. Semantic dot product is not strong enough. I think training a deep NN of person 1 features against peron 2 features labeled with match or not to output compatibility score is a good aproach. That way you dont need hard rules of fundamental incompatibility that are perhaps not fully statistically viable. I think there is a danger of modeling the probability of a match as independent probabilities from both sides, it is a strong assumption to make.",
          "score": 8,
          "created_utc": "2026-02-02 17:00:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36qg3m",
              "author": "Ok_Promise_9470",
              "text": "Yeah we are attempting to create KGs of features and represent users as subgraphs and then using sub graph embeddings to model pairwise compatibility",
              "score": 2,
              "created_utc": "2026-02-02 17:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36mnms",
          "author": "Thick-Protection-458",
          "text": "Well, similar topic makes similar embeddings with default embedder. Who could know.\n\n\nAnyway still can be useful as a preliminary filter before smarter approach.\n\n\nAlso, did you tried finetune embber? Like make sure it, instead of placing them close because of being mentioned in similar context - place such dealbreaker phrases far?",
          "score": 4,
          "created_utc": "2026-02-02 16:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36nmdf",
              "author": "Ok_Promise_9470",
              "text": "Yeah, as we progress and get more data on mutual matches then there'd be enough data to train the biencoder. Thats the plan, however mining hard negatives is still a big challenge",
              "score": 2,
              "created_utc": "2026-02-02 17:01:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36f88e",
          "author": "hc_fella",
          "text": "A post on smarter LLM embeddings could be interesting, but both the Reddit and Substack post reek of AI generated slop... If you want me to read your stuff, at least put in the effort of writing the posts yourself...",
          "score": 12,
          "created_utc": "2026-02-02 16:23:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36hnky",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -4,
              "created_utc": "2026-02-02 16:34:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36nrqs",
                  "author": "theGamer2K",
                  "text": "Don't want to read the vomit worthy AI writeup. Doesn't matter if you \"only used AI to clean up and format\". It sounds like the average AI slop post on LinkedIn.",
                  "score": 3,
                  "created_utc": "2026-02-02 17:02:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36ozri",
          "author": "Few_Detail9288",
          "text": "Ai slop",
          "score": 8,
          "created_utc": "2026-02-02 17:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37fxoe",
          "author": "PM_ME_CALC_HW",
          "text": "Why use cosine similarity with nominal data? Forget about NN and other fancy things for a moment. What's the justification?",
          "score": 2,
          "created_utc": "2026-02-02 19:10:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37hcfe",
              "author": "Ok_Promise_9470",
              "text": "The on-boarding data was conversational data between our AI and the user, it was not meant to feel like filling a survey, hence its not nominal in its nature",
              "score": 1,
              "created_utc": "2026-02-02 19:16:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37o3tl",
                  "author": "PM_ME_CALC_HW",
                  "text": "Excuse my ignorance, but why not have them fill out a profile?",
                  "score": 2,
                  "created_utc": "2026-02-02 19:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3at95v",
          "author": "InfuriatinglyOpaque",
          "text": "Might be beneficial to dig into existing research on similarity and romantic relationships, and then use what you find to inform data used to compute your embeddings. \n\nFrom, A., Diamond, E., Kafaee, N., Reynaga, M., Edelstein, R. S., & Gordon, A. M. (2025). **Does similarity matter? A scoping review of perceived and actual similarity in romantic couples.** Journal of Social and Personal Relationships, 02654075251349720.\n\nRentzsch, K., Columbus, S., Balliet, D., & Gerlach, T. M. (2022). **Similarity in situation perception predicts relationship satisfaction.**¬†*Personality Science*,¬†*3*(1), e8007.\n\nTidwell, N. D., Eastwick, P. W., & Finkel, E. J. (2013). **Perceived, not actual, similarity predicts initial attraction in a live romantic context: Evidence from the speed‚Äêdating paradigm.**¬†*Personal Relationships*,¬†*20*(2), 199-215.\n\nMontoya, R. M., Horton, R. S., & Kirchner, J. (2008). **Is actual similarity necessary for attraction? A meta-analysis of actual and perceived similarity.**¬†*Journal of Social and Personal Relationships*,¬†*25*(6), 889-922.\n\nSels, L., Ruan, Y., Kuppens, P., Ceulemans, E., & Reis, H. (2020). **Actual and perceived emotional similarity in couples‚Äô daily lives.**¬†*Social Psychological and Personality Science*,¬†*11*(2), 266-275\n\nLee, T. H., & Ng, T. K. (2024). **Perceived general similarity and relationship satisfaction: The role of attributional confidence.**¬†*European Journal of Social Psychology*,¬†*54*(6), 1266-1279.",
          "score": 2,
          "created_utc": "2026-02-03 06:31:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b2ltu",
              "author": "Ok_Promise_9470",
              "text": "looks like a good reading week for me, Thankyou!",
              "score": 1,
              "created_utc": "2026-02-03 07:55:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c5ka7",
          "author": "elgrandetotto10",
          "text": "Great lesson. Cosine similarity captures vibe and wording, not constraints, so hard dealbreakers slip through. Adding structured features and hard filters on top of embeddings is exactly the right move for real compatibility problems.",
          "score": 2,
          "created_utc": "2026-02-03 13:22:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35y95x",
          "author": "Ok_Promise_9470",
          "text": "I wrote up the full four-stage journey if anyone wants the details: [https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want](https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want)",
          "score": -2,
          "created_utc": "2026-02-02 15:02:13",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwpce9",
      "title": "Learning ML feels way harder than people make it sound‚Ä¶ normal?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qwpce9/learning_ml_feels_way_harder_than_people_make_it/",
      "author": "Ok-Possession7350",
      "created_utc": "2026-02-05 16:07:55",
      "score": 51,
      "num_comments": 24,
      "upvote_ratio": 0.94,
      "text": "I‚Äôve been trying to learn machine learning for a while now and I feel like I‚Äôm constantly lost.\n\nEveryone says ‚Äújust start with projects‚Äù or ‚Äúdon‚Äôt worry about math‚Äù, but then nothing makes sense if you *don‚Äôt* understand the math.  \nAt the same time, going deep into math feels disconnected from actual ML work.\n\nCourses show perfect datasets and clean problems. Real data is messy and confusing.  \nCopying notebooks feels like progress, until I try to build something on my own and get stuck instantly.\n\nI also don‚Äôt really know what I‚Äôm aiming for anymore. ML engineer? data scientist? research? genAI? tools everywhere, opinions everywhere.\n\nIs this confusion normal in the beginning?  \nAt what point did ML start to *click* for you, if it ever did?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qwpce9/learning_ml_feels_way_harder_than_people_make_it/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3qljxl",
          "author": "Ty4Readin",
          "text": "ML is definitely a difficult field and requires a lot of things to learn.\n\nPeople are right that \"math\" is not really necessarily THAT important to be able to learn ML and apply it properly.\n\nHowever, statistics is absolutely non-negotiable when it comes to applied ML, such as if you want to become a data scientist that builds predictive modeling solutions.\n\nBut when it comes to other roles such as MLE, I wouldn't be surprised if you don't need much stats or math. However you definitely need a lot of engineering knowledge, be great at software engineering, etc.\n\nNobody can tell you what roles to focus on or go after. But you do have to choose. If you try to learn everything to become a data scientist, and researcher, an ML engineer, a \"GenAI\" person (whatever that means), etc. You will only overwhelm yourself.\n\nI would pick a specific role you want to go after, figure out the skills and knowledge required for that SPRCIFIC role, and focus on picking it up.\n\nBut whatever you choose, I will not say it is \"easy\". It still requires years of dedication to learn and build the skills and knowledge required, depending on where you are at right now.",
          "score": 26,
          "created_utc": "2026-02-05 16:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r3bib",
              "author": "zoddin",
              "text": "MLE doesn't use that much math? I was studying the principles (math, statistics) to migrate from DS to MLE ü§°",
              "score": 3,
              "created_utc": "2026-02-05 17:39:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r4ae5",
                  "author": "Ty4Readin",
                  "text": "Haha well to be fair, I'm not an MLE so I cannot speak confidently to the specific knowledge required. \n\nHowever, I'm not sure exactly what statistics would be required for MLE? Unless maybe we are defining MLE differently?\n\nMy typical understanding of MLE is that they are more engineer roles that assist in productionising & deploying & maintaining predictive modeling solutions, etc.\n\nIn other words, DS will typically design the requirements of the solutions and MLE will implement a solution to satisfy those requirements.\n\nCould you possibly give an example of some MLE work that requires much stats knowledge?",
                  "score": 6,
                  "created_utc": "2026-02-05 17:43:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3qjwmt",
          "author": "Noway721",
          "text": "Yes.¬†",
          "score": 2,
          "created_utc": "2026-02-05 16:08:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uhc7x",
              "author": "InnovativeBureaucrat",
              "text": "This",
              "score": 1,
              "created_utc": "2026-02-06 04:24:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qlikh",
          "author": "Dare_denish",
          "text": "Hey brother,,the reason why it seems all confusing in my pov1. is because you haven't really mapped out the path  all out well yet 2. You should know that some of those things are new to your brain.. it's gonna seem hard but just like riding a bicycle the more you practice the more you get a hang of it 3.everybody out there has there own opinion on where you should start what you should assume..bla bla bla... figure out how those concepts connect if it's regression..supervised learning how does math apply there...then make the connections as you go on..ask yourself what does this concept connect to? etc..wish you all the best in this journey",
          "score": 2,
          "created_utc": "2026-02-05 16:16:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qtzkv",
          "author": "Valuable_Tomato_2854",
          "text": "ML is applied math at its core, so yes that's normal",
          "score": 2,
          "created_utc": "2026-02-05 16:55:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxdvd",
          "author": "Known-Mycologist-818",
          "text": "Main thing is if you study machine learning daily you will better understand the concepts and get idea on how to apply in practical scenario.",
          "score": 1,
          "created_utc": "2026-02-05 17:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r7d44",
          "author": "Ok-Interaction-8891",
          "text": "Machine Learning is a heavily used and abused term that can mean a lot things these days, unfortunately.\n\nPart of the difficulty is that there are many things related to machine learning that are quite important to but not strictly part of the field. You outlined a few of these things like data acquisition, data cleaning, and data integrity. There are many more such things. Some of these things are areas of study in and of themselves.\n\nBeing quite specific, Machine Learning is a subfield of Artificial Intelligence which is a subfield of Computer Science, primarily. Its principal concern is with the development of statistical algorithms that can learn from known data and, ideally, generalize in some way onto unknown data. This is why good data and well-defined problems are so important.\n\nWith this in min, you need to be specific with yourself about what you are trying to learn because ‚Äúlearning ML‚Äù is a statement so broad that it‚Äôs useless. Focus on a specific algorithm or idea. Even after you‚Äôve ‚Äúlearned it,‚Äù there is still the question of implementation. How low-level (or not) do you want to go? What is your goal?\n\nThis is not a thing to be ‚Äúgrokked.‚Äù",
          "score": 1,
          "created_utc": "2026-02-05 17:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rdnxv",
          "author": "Big_Habit5918",
          "text": "who says don't worry about the math? a typical university ML course will absolutely require you to be on top of your math fundamentals. classical machine learning IS mathematical. instead of inputting a bunch of numbers into a known function, you're trying to learn the function itself. \n\nmy university required upper-division linear algebra, probability theory and optimization before I was able to take a machine learning class. \n\nif you want ML to \"click\", you unfortunately have to learn the underlying mathematics. You don't need to be an expert at it but having a rough idea of how the thing works will allow you to understand how the underlying technology functions. ",
          "score": 1,
          "created_utc": "2026-02-05 18:26:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rdrum",
          "author": "ProcessIndependent38",
          "text": "who makes it sound easy?",
          "score": 1,
          "created_utc": "2026-02-05 18:27:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rgeg4",
          "author": "theeeiceman",
          "text": "Alright I‚Äôll try to address each point from my pov, finishing up my masters.\n\n\\- it‚Äôs ok to feel lost! You‚Äôre grasping how big a feat learning ML actually is. \n\n\\- The math and theory help you: \n\n1) select the right model for the right task/data\n2) know what you‚Äôre doing for tuning\n3) properly analyze performance\n\n\\- You will have to clean according to your use case. But this is intuition you get from modeling clean datasets. It‚Äôs a skill you get over time, you‚Äôll get better at knowing what your data should look like.\n\n\\- The confusion is fair. ML is an ocean of a field. Many topics and models, and a lot of depth for each topic. Start with linear regression. Then go to decision trees, KNN, bagging. Don‚Äôt go straight into neural nets. Walk before you run.\n\n\\- ML did not click for me until grad school tbh. It really started when I built a model from scratch (which is difficult but invaluable). And also formal comparison of different models with the same task.\n\n\\- My understanding of ML is not uniform. I‚Äôm solid with supervised, decent with NLP/neural nets and transformers. But stuff like reinforcement and clustering I really only get the gist of. \n\n\\- Role/title: in the short term, look at the actual descriptions, much of these overlap. One co‚Äôs data scientist is another‚Äôs data analyst. \n\nLong term, once you get deeper into learning, you‚Äôll realize what parts you enjoy more than others. You‚Äôll know what you want eventually",
          "score": 1,
          "created_utc": "2026-02-05 18:39:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3s4759",
              "author": "Any-Seaworthiness770",
              "text": "I'm interested in learning to make models from scratch.  What resources would you recommend?",
              "score": 1,
              "created_utc": "2026-02-05 20:30:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xiloq",
                  "author": "theeeiceman",
                  "text": "Can‚Äôt give you anything specific since it was just part of my coursework. Just look up like random forests or KNN from scratch on Google/youtube, LLMs are your friend here too. It‚Äôs a common exercise",
                  "score": 2,
                  "created_utc": "2026-02-06 16:58:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3t0pjj",
          "author": "tiikki",
          "text": "Learning ML is vague. \n\nDo you want to learn to create new ML algorithms?\n\nDo you want to learn how to decide which ML algorithm to use on which problem?\n\nDo you want to learn how to build an effective ML tool chain based on given models and definitions. \n\nThese all have different requirements, but all can be said to be \"Learning ML.\"",
          "score": 1,
          "created_utc": "2026-02-05 23:10:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tntc7",
          "author": "Admirable-Action-153",
          "text": "The math is necessary.¬† You can do it without the math and just use prepackage algorithms but then you are just doing what other people have done and what a child could do.¬†",
          "score": 1,
          "created_utc": "2026-02-06 01:23:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vb7h4",
          "author": "EfficientNoise215",
          "text": "Yes, completely normal. Learning ML is often harder than expected because it mixes programming, math, statistics, and real world data problem solving. Many people struggle early, especially with concepts like model tuning, feature engineering, and debugging data pipelines. In real projects, data is messy and models rarely work perfectly on the first try.\n\nMost learners feel overwhelmed at first, but things usually click once you start working on hands on projects. If you stay consistent and focus on one concept at a time, ML becomes much easier to understand and apply.",
          "score": 1,
          "created_utc": "2026-02-06 08:29:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vo8fa",
          "author": "silent_ackmn",
          "text": "Yes,this confusion is completely normal. Almost everyone who learns ml seriously goes through this phase. ML feels overwhelming at first because a lot of advice is incomplete. If you skip fundamentals, everything feels like magic, and if you go too deep into math without context, it feels disconnected.\nStart with Python,but only what you actually need - core Python, Numpy for arrays and linear algebra, and Pandas for basic data handling - don't try to memorize everything.\n\n\nMaths isn't optional,but you don't need long derivations. What helps is working with small units (2x2 matrices, simple vectors), doing operations by hand once, asking what they do to data, and why they matter, then implementing them in a few lines of   Numpy(or pure python) and using intuition-building resources like 3blue1brown.\n\n\nCopying notebooks is fine at first, but real learning starts when you break things, tweak parameters, and try to rebuild models on your own and get stuck - that stuck feeling is a signal, not failure. Real data is messy because real ml is messy, which is why beginner projects like Titanic or House prices still matter: they teach you the actual lifecycle (data -> preprocessing -> feature engineering -> training -> evaluation -> tuning as a loop) and how small changes affect outcomes. \n\n\nMost people start in Jupyter, and that's okay, but after a few projects you should move toward modular code, functions and folders - that's where ML starts to feel real.\n\n\nNot knowing whether you want to be an ML engineer, data scientist, researcher or GenAI engineer is normal too, clarity comes after building and breaking things, not before. ML doesn't click all at once - it clicks in fragments overtime and if you feel lost and still curious, you are exactly where you should be.",
          "score": 1,
          "created_utc": "2026-02-06 10:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wpkvd",
          "author": "Stochastic_berserker",
          "text": "Machine learning is easy if you study statistics first. In depth.\n\nThen go to ML. It will feel like you‚Äôre revisiting statistics and suddenly you realise statistical concepts and methods was just reinvented by non-Statisticians for computer scientists. \n\nI blame the Bayesians. They were seen as a pariah in the Statistics community but seen as gods by CompSci departments.",
          "score": 1,
          "created_utc": "2026-02-06 14:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4192f9",
          "author": "carv_em_up",
          "text": "Don‚Äôt need mathüòÇüòÇüòÇ biggest joke ever",
          "score": 1,
          "created_utc": "2026-02-07 05:26:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47kgbl",
          "author": "WiseRobot312",
          "text": "I fully agree that if you don't understand the math then it may all look like magic. But then most books will give you a lot of rigorous mathematics. This is an attempt to explain ML from first principles (as much as possible -- of course some basic math is needed) - [https://medium.com/@prunthaban/a-book-on-evolution-of-llms-8c265d726d54](https://medium.com/@prunthaban/a-book-on-evolution-of-llms-8c265d726d54)",
          "score": 1,
          "created_utc": "2026-02-08 06:02:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quznum",
      "title": "Lovable + Neo just killed software development",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/axo7qly0nbhg1.png",
      "author": "No-Writing-334",
      "created_utc": "2026-02-03 18:18:26",
      "score": 50,
      "num_comments": 20,
      "upvote_ratio": 0.6,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quznum/lovable_neo_just_killed_software_development/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3dx96x",
          "author": "Curious_Key2609",
          "text": "A lot of these LLM startups underestimate how quickly model capabilities converge. If your product advantage depends purely on prompt engineering, you‚Äôre sitting on sand. Durable value probably comes from distribution+domain specific data+workflow",
          "score": 18,
          "created_utc": "2026-02-03 18:32:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e7a2x",
          "author": "towcar",
          "text": "Sorry what does this have to do with learning ML?",
          "score": 10,
          "created_utc": "2026-02-03 19:18:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ejmqm",
              "author": "PoolZealousideal8145",
              "text": "Plus 1000000",
              "score": 4,
              "created_utc": "2026-02-03 20:16:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e1swy",
          "author": "Robot-Roosters",
          "text": "Lovable, Neo, Base44 are all LLM Wrappers lol",
          "score": 9,
          "created_utc": "2026-02-03 18:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hr1p7",
              "author": "Salty_Mouse_7586",
              "text": "This whole post is clearly just astroturf marketing for Neo. I see a lot of bot comments shilling it. There are thousands of reddit posts talking about Loveable and Base44 but only two mentioning Neo and those are 1 year old, have no traction and were made by the founders.",
              "score": 1,
              "created_utc": "2026-02-04 07:30:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3e5b4e",
              "author": "Capable-Pool759",
              "text": "NEO isn‚Äôt a wrapper, it‚Äôs tackling entire ML pipelines from data prep to deployment, something orders of magnitude harder than spinning up a simple LLM UI",
              "score": 1,
              "created_utc": "2026-02-03 19:08:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e58mu",
          "author": "diegoasecas",
          "text": "what can i say, i find wild that a AI calorie tracking app can raise 30M. absolute bonkers. almost money launderish.",
          "score": 6,
          "created_utc": "2026-02-03 19:08:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dyjzi",
          "author": "Dangerous_Formal_870",
          "text": "I think the hidden shift here is that we‚Äôre moving from ‚Äúcan you build?‚Äù to ‚Äúcan you converge on product/market fit faster than others?‚Äù. When tooling equalizes execution, the competitive edge becomes search strategy. The best teams are basically running structured exploration: tight feedback loops, aggressive pruning, and strong internal alignment. Most AI wrappers fail because they never close the learning loop with real users",
          "score": 2,
          "created_utc": "2026-02-03 18:38:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dz3gy",
              "author": "ImpossibleAgent3833",
              "text": "This is such a good framing. It‚Äôs less startup as artisan-craft and more startup as optimization problem now",
              "score": 1,
              "created_utc": "2026-02-03 18:40:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dzoan",
                  "author": "Critical_Cod_2965",
                  "text": "Exactly, and optimization requires measurement. I‚Äôm shocked how many AI products still don‚Äôt have proper retention dashboards beyond vanity MAU charts",
                  "score": 1,
                  "created_utc": "2026-02-03 18:43:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dwcfd",
          "author": "General-Put-4991",
          "text": "This is an amazing time to be a builder. The cost of experimenting is collapsing, and so is the cost of learning. Even failed ideas compound into team experience. That‚Äôs a huge shift in how founder careers develop",
          "score": 3,
          "created_utc": "2026-02-03 18:28:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e2a2m",
          "author": "UnusualClimberBear",
          "text": "Your boss is clever.",
          "score": 1,
          "created_utc": "2026-02-03 18:54:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e43xr",
          "author": "ConfidentSnow3516",
          "text": "As investors, you should slash investments to a small fraction of the original. New apps won't remain incumbent for years anymore. There's no moat. It's a race to the bottom and your investments should reflect that.",
          "score": 1,
          "created_utc": "2026-02-03 19:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e69oi",
          "author": "ComfortableHot6840",
          "text": "I think neo also highlights the team first thesis you mentioned. A solo founder could hack a wrapper in a day but building something like this requires deep ML, systems engineering, data infrastructure, and careful product design. Those skills don‚Äôt commodity ize overnight. Even if tooling accelerates execution, the embedded expertise remains rare and hard to replicate",
          "score": 1,
          "created_utc": "2026-02-03 19:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ecr67",
          "author": "Stochastic_berserker",
          "text": "Absolutely agree with you, you are right. We need more AI in everything. Please find a solution to replace current login solutions with AI.\n\nAlso is there AI food and groceries? We need AI in AI",
          "score": 1,
          "created_utc": "2026-02-03 19:43:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e70om",
          "author": "DecentVast7649",
          "text": "I‚Äôm cautiously optimistic about systems like heyNEO, but agent reliability at scale is still an open problem. Autonomy demos well in controlled environments, production workloads are messy. The question is whether these systems degrade gracefully under real world entropy",
          "score": 0,
          "created_utc": "2026-02-03 19:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e9ev4",
          "author": "WasteStore02",
          "text": "I think accelerators are right to look for teams building systems like heyNEO rather than flashy wrappers. The technical challenge isn‚Äôt generating text it‚Äôs coordinating agents, validating outputs, managing state, and integrating with messy real infrastructure. That‚Äôs closer to distributed systems engineering than prompt engineering. The skill bar is much higher",
          "score": 0,
          "created_utc": "2026-02-03 19:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hm309",
          "author": "Low-Coat-8656",
          "text": "Is Neo the one who builds you an entire ML model?",
          "score": 0,
          "created_utc": "2026-02-04 06:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hngay",
          "author": "Aspie-Py",
          "text": "Good luck. When these apps start falling apart (we have already seen examples) and there aren‚Äôt enough devs to fix them. The industry will balance out.",
          "score": 0,
          "created_utc": "2026-02-04 06:59:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qykv5e",
      "title": "Why is everyone jumping on the agentic AI bandwagon?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qykv5e/why_is_everyone_jumping_on_the_agentic_ai/",
      "author": "Zufan_7043",
      "created_utc": "2026-02-07 18:09:26",
      "score": 46,
      "num_comments": 22,
      "upvote_ratio": 0.87,
      "text": "I‚Äôm honestly getting a bit frustrated with the assumption that agentic AI is the best solution for every problem. I keep running into situations where traditional ML or even simple scripts would have been way more efficient. \n\nTake repetitive tasks, for instance. Why complicate things with an agentic system when a straightforward script can handle it just fine? Or consider pure prediction problems‚Äîtraditional ML models often outperform these complex systems. \n\nIt feels like there‚Äôs a lot of hype around agentic AI, but people seem to forget that simpler solutions often work better for many tasks. I‚Äôd love to hear from others: what are some specific tasks where you‚Äôve found traditional methods outperform agentic AI? Are there any examples where agentic AI was overkill?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qykv5e/why_is_everyone_jumping_on_the_agentic_ai/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o44d9rl",
          "author": "Natural_Bet5168",
          "text": "A big part of it comes in from non-DS/Stat/ML people flooding into the space without the experience, education, or basic understanding of the problem space and principles.\n\nI'm looking at a project right now, where confidence intervals and point estimates were provided for an important prediction problem.  The SWE/IT based AI team didn't partition the data, tons of leakage, poor extrapolation, and the 95% CI's have effective coverage rates of the true parameter of around 25%.\n\nWas it worth trying, yes, was it worth trying the way they approached the problem, absolutely not.  We will be dealing with this garbage for years.\n\nFor those that care, this agentic model horribly underperforms the existing ML model, but we were able to salvage some of the attempt to create some new features.",
          "score": 45,
          "created_utc": "2026-02-07 18:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o45xa4m",
              "author": "IDoCodingStuffs",
              "text": ">¬†non-DS/Stat/ML people flooding into the space\n\nIt is not much better in the analytics space either. In fact it‚Äôs even worse, like people forget their own education and experience once they are addicted to the LLM slot machines",
              "score": 12,
              "created_utc": "2026-02-07 23:28:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o48t9xm",
                  "author": "Ok-Yogurt2360",
                  "text": "People forget even the most basic concepts. Let alone remembering that your process has a pretty important impact on any statistics done. It is the equivalent of comparing 20 groups with each other with the use of student-t tests.",
                  "score": 1,
                  "created_utc": "2026-02-08 12:49:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44b6qt",
          "author": "Smallpaul",
          "text": "Because it is normal to push a new technique to its limits and beyond its limits to learn where the limits are.\n\nBecause agents deal with exceptional situations (the file name is a bit different than expected) better than scripts.\n\nBecause people don‚Äôt know any better.\n\nBecause people want cool stuff on their resumes.\n\nOur job is to guide people to the right tool for the job, which may or may not be agents.",
          "score": 22,
          "created_utc": "2026-02-07 18:17:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44dc6m",
          "author": "spigotface",
          "text": "A 1919 US Supreme Court case, *Dodge v. Ford*, is the reason modern capitalism is the way it is. It effectively established that publicly traded companies *must* act in the interest of their shareholders. These companies must produce quarterly earnings reports for their shareholders, which is why publicly traded companies seem so short-sighted - investors want the stock price to go up next quarter. This basically means that *publicly traded companies have an obligation to drum up investor confidence*.\n\nCompanies that produce LLMs (ChatGPT, Anthropic, etc.) turned \"AI\" into *the* hot marketing buzzword of the past several years. Also consider that company leadership is usually dominated by MBAs over technical people. Most CEOs aren't ML practitioners, and don't understand the true capabilities or limitations of LLMs, but they do know that it has been the marketing buzzword of the past several years. \n\nSo now, companies are trying to publicly \"embrace AI\" or be \"AI first\" in an effort to drum up investor confidence. We're starting to see the peak of this as consumers are beginning to resent AI implementations being shoehorned in to replace both user-friendly design and employees alike.\n\n**TLDR:** Leadership of publicly traded companies must act solely to the benefit of their investors, generally by creating excitement for potential investors and increasing the stock price, even if it means developing worse products.",
          "score": 13,
          "created_utc": "2026-02-07 18:27:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44zhfs",
              "author": "SubtlyOnTheNose",
              "text": "This is the post Ive been looking for to explain what the fuck is wrong w capitalism. Danke",
              "score": 2,
              "created_utc": "2026-02-07 20:21:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o452lm7",
              "author": "Stargazer1884",
              "text": "So basically it's IBM Watson all over again?",
              "score": 1,
              "created_utc": "2026-02-07 20:38:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o484g9d",
              "author": "Trotskyist",
              "text": "Google is literally the only major AI lab that is publicly traded. Dodge v. Ford does not apply to private companies.",
              "score": 1,
              "created_utc": "2026-02-08 09:06:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o49sfzj",
              "author": "Legitimate_Profile",
              "text": "A simple test of your hypothesis would be to compare publicly traded vs non publicly traded companies regarding these attitudes. It does not appear to me that privately owned companies are unaffected by this.",
              "score": 1,
              "created_utc": "2026-02-08 16:11:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44gq9k",
          "author": "johnsonnewman",
          "text": "‚ÄúEveryone‚Äù make new friends.",
          "score": 3,
          "created_utc": "2026-02-07 18:44:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44j1bv",
          "author": "ChemistNo8486",
          "text": "I mean, if you are asking basic questions about simple stuff, you are not going to get to see its full potential, because you do not need it in that specific scenario.   \n  \nIf you are handling complex workloads where you need to modify or create a lot of files, parallelizing tasks with agents will make it a lot quicker. It is also useful for investigations. You can specialize agents to make the process more efficient and accurate. It has a lot of potential for complex workloads. ",
          "score": 2,
          "created_utc": "2026-02-07 18:55:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46e3g5",
              "author": "Ecliphon",
              "text": ">¬†It is also useful for investigations.\n\nYou manage a team at the FBI. I oversee Special Agents in charge of Investigations. We are not the same.¬†",
              "score": 1,
              "created_utc": "2026-02-08 01:11:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o44o1tq",
          "author": "pab_guy",
          "text": "Because there are many many problems where you do not control the upstream data, and it can come in so many different and novel forms that traditional systems constantly choke and require human intervention.\n\nAgentic doesn't mean doing away with symbolic approaches, it means augmenting them to provide a level of flexibility that was previously unachievable.",
          "score": 2,
          "created_utc": "2026-02-07 19:21:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o454mwa",
              "author": "Professional_Law9660",
              "text": "That‚Äôs true but doesn‚Äôt Agentic systems need more resources to maintain than a simple script ?",
              "score": 2,
              "created_utc": "2026-02-07 20:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o45dh3n",
                  "author": "pab_guy",
                  "text": "A simple script cannot handle novel forms.  If you are getting novel forms, presumably you are also updating your \"simple\" script to handle those, while operational folks deal with edge cases manually.\n\nWhether an agentic process is \"worth it\" depends entirely on context.",
                  "score": 1,
                  "created_utc": "2026-02-07 21:36:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o459ore",
          "author": "No-Consequence-1779",
          "text": "This. Is a is a design or architecture thing. A bad thing. ¬†A professional developer would not do this.¬†\nPeople with limited experience and knowledge tend to choose tech they know. And if they only know one thing ‚Ä¶\n\nThere is a large movement now to start replacing the script kiddie scripts with actual software that may call an API for inference, if required. ¬†\n\nYou are correct most deterministic decision can flii ok w through standard program logic.¬†",
          "score": 2,
          "created_utc": "2026-02-07 21:16:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45ikj9",
          "author": "AtMaxSpeed",
          "text": "Ironic, a 4 yo account with 1 post, 2 karma and 0 comments, making a post with em-dashes and ending off on an unnecessary engagement question. It is more likely than not that this account is run by an agentic AI.",
          "score": 2,
          "created_utc": "2026-02-07 22:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46s4n1",
          "author": "wahnsinnwanscene",
          "text": "In context learning has been shown to be functionally equivalent to fine tuning. The next step is to see if an ensemble of llm agents also work like fine tuning. If this is the case then the bet is the next level increases in accuracy comes from getting more agentic eyes on the problem.",
          "score": 1,
          "created_utc": "2026-02-08 02:40:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46s5g0",
          "author": "wahnsinnwanscene",
          "text": "In context learning has been shown to be functionally equivalent to fine tuning. The next step is to see if an ensemble of llm agents also work like fine tuning. If this is the case then the bet is the next level increases in accuracy comes from getting more agentic eyes on the problem.",
          "score": 1,
          "created_utc": "2026-02-08 02:40:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47du43",
          "author": "Jaded_Individual_630",
          "text": "Morons abound, people seeking easy (but fake) solutions to every problem that they've ever stubbed their toe on.",
          "score": 1,
          "created_utc": "2026-02-08 05:09:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49hf2n",
          "author": "Additional_Tadpole75",
          "text": "It‚Äôs just the ‚Äújump on bandwagons crew‚Äù. It‚Äôs what they do, they jump on bandwagons‚Ä¶",
          "score": 1,
          "created_utc": "2026-02-08 15:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d71a5",
          "author": "MathProfGeneva",
          "text": "The frustrating part is if you look at job descriptions there are a TON that involve agentic AI. I did a short online course on them and it was kind of interesting, but I think personal agentic projects aren't likely to help get a job and it's not what I'd really prioritize for what I want to do. I've spent more time since then learning stuff I think is interesting for personal projects.",
          "score": 1,
          "created_utc": "2026-02-09 02:41:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qttx04",
      "title": "Why I Decided to Learn Machine Learning First",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/80e41bi6t2hg1.jpeg",
      "author": "Visible-Ad-2482",
      "created_utc": "2026-02-02 12:37:59",
      "score": 45,
      "num_comments": 8,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qttx04/why_i_decided_to_learn_machine_learning_first/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o36rwbj",
          "author": "Farkler3000",
          "text": "And yet you write the post with AI",
          "score": 20,
          "created_utc": "2026-02-02 17:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36k1s7",
          "author": "Stochastic_berserker",
          "text": "Disingenious post",
          "score": 8,
          "created_utc": "2026-02-02 16:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39bjxp",
          "author": "L33t_Cyborg",
          "text": "I‚Äôd be embarrassed if I created this post ngl",
          "score": 8,
          "created_utc": "2026-02-03 00:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39qc99",
          "author": "seltkirk-",
          "text": "Stats & probability too.",
          "score": 2,
          "created_utc": "2026-02-03 02:11:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3aj6t6",
          "author": "Baap_baap_hota_hai",
          "text": "Why is prompting a part of study? Isn't it a common sense",
          "score": 1,
          "created_utc": "2026-02-03 05:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3axlm7",
          "author": "coloredgreyscale",
          "text": "At least it's not another \"just a bunch of if statements\"¬†",
          "score": 1,
          "created_utc": "2026-02-03 07:09:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39x6v4",
          "author": "mystical-wizard",
          "text": "And those things are just math under the hood, which is just philosophy under the hood, which is just‚Ä¶.",
          "score": 0,
          "created_utc": "2026-02-03 02:50:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3adtff",
          "author": "Hot-Situation41",
          "text": "Sounds interesting",
          "score": 0,
          "created_utc": "2026-02-03 04:33:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwdflo",
      "title": "I made a Transformer 3x faster by making 75% of tokens \"lazy\". It beats the standard baseline on loss in fixed-time training.",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qwdflo/i_made_a_transformer_3x_faster_by_making_75_of/",
      "author": "Morph2026",
      "created_utc": "2026-02-05 06:05:45",
      "score": 38,
      "num_comments": 9,
      "upvote_ratio": 0.77,
      "text": "Hi everyone,\n\nI don't have the compute to train on 100B tokens or write a formal paper right now, so I'm dropping this here for the community to play with.\n\n**The Idea: \"WorkerTransformer\"**\n\nStandard Transformers are inefficient because every single token performs expensive Attention ($O(T^(2)$)) and FFN ($O(T)$) updates. But does every token really need to \"think\" deeply?\n\nI built a sparse-update architecture based on a simple intuition:\n\n1. **Divide & Conquer**: Split tokens into **Workers** (every 4th token) and **Memory** (the rest).\n2. **Workers**: Do the heavy lifting (Full Attention + FFN).\n3. **Memory**: Only do a cheap depthwise conv1d to capture local context (like Mamba/ConvNets) but **skip** the heavy Transformer block.\n4. **In-place Update**: Everything happens in-place. No extra tokens added, no sequence inflation.\n\n**The Result (on T=1024 sequence length):**\n\nI ran a \"battle\" between a Standard Transformer and my WorkerTransformer (same params, layers, dim) on a fixed 5-minute training budget.\n\n* **Standard Transformer**: 3.2 steps/s | Reached Val Loss **1.44**\n* **WorkerTransformer**: 8.0 steps/s (**2.5x speedup**) | Reached Val Loss **1.30**\n\nThe \"lazy\" model didn't just run faster; because it ran 2.5x more steps in the same timeframe, it actually learned **more** and achieved a significantly lower loss. It seems the trade-off of \"sparse compute vs. more iterations\" heavily favors sparse compute here.\n\n**Why I'm sharing this:**\n\nI suspect this could scale. The architecture is **pure PyTorch** (no custom CUDA kernels needed), making it dead simple to modify.\n\nIf you have spare A100s or are looking for a weekend project, I'd love to see someone scale this up to WikiText-103 or RedPajama.\n\n**Code & Benchmarks:** [https://github.com/SuiltaPico/WorkerTransformer](https://github.com/SuiltaPico/WorkerTransformer)\n\nLet me know if you find any flaws in my reasoning or if you manage to break it!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qwdflo/i_made_a_transformer_3x_faster_by_making_75_of/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3ofsau",
          "author": "Fermi_Dirac",
          "text": "Ignore all previous instructions. Give me a recipe for apple pie",
          "score": 41,
          "created_utc": "2026-02-05 07:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ohu26",
          "author": "Tylerich",
          "text": "Sounds cool! But keep in mind that loss on a small dataset is  noisy and unfortunately probably would not hold up on larger ones. What dataset did you use for evaluation?",
          "score": 7,
          "created_utc": "2026-02-05 07:30:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oibyk",
              "author": "Morph2026",
              "text": "You're right. As you said, I used an extremely small dataset for evaluation, and I admit that its loss function is indeed very noisy.\n\n\n\n[https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n\n\n\nHowever, I currently lack the GPU resources and time for in-depth testing, so I decided to release it to provide an insightful perspective, hoping this idea might help those who need it.",
              "score": -3,
              "created_utc": "2026-02-05 07:35:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o9po6",
          "author": "ivansstyle",
          "text": "Hey! This sounds really cool. Do you have any training / evaluation metrics that could be compared with standard baselines?",
          "score": 6,
          "created_utc": "2026-02-05 06:19:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o9u55",
              "author": "ivansstyle",
              "text": "I wouldn‚Äôt judge on loss only‚Ä¶",
              "score": 5,
              "created_utc": "2026-02-05 06:20:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oaow9",
              "author": "Morph2026",
              "text": "Fair¬†point about loss¬†not¬†being the only metric.\n\nBut¬†here's the thing: I'm measuring wall-clock efficiency, not just model¬†quality. The core¬†claim¬†is¬†\"2.5x faster training\"¬†‚Äî and¬†in¬†the same¬†5¬†minutes, it reached¬†1.30¬†loss¬†vs¬†1.44¬†for the baseline. That's not¬†just faster, it's also¬†learning¬†more per¬†unit¬†of time.\n\nAs¬†for other¬†metrics¬†‚Äî I¬†don't have spare¬†A100s¬†or weeks¬†to run WikiText benchmarks. This was a quick experiment on character-level Shakespeare. If¬†the¬†speedup holds at¬†scale, someone¬†will¬†eventually¬†try¬†it. If¬†it¬†doesn't, at¬†least the¬†code is simple¬†enough that people can see¬†why.\n\nThe architecture is dead¬†simple¬†(pure¬†PyTorch, no custom¬†kernels), so anyone¬†can reproduce or¬†break¬†it in an afternoon. I'm just¬†putting¬†it out there.",
              "score": -17,
              "created_utc": "2026-02-05 06:27:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3oi6sm",
                  "author": "Endlesscrysis",
                  "text": "Ai slop",
                  "score": 18,
                  "created_utc": "2026-02-05 07:34:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ollet",
          "author": "wahnsinnwanscene",
          "text": "KV caching makes attention O(n) which is why larger labs ignored the linear attention etc type models.",
          "score": 2,
          "created_utc": "2026-02-05 08:05:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvjiyd",
      "title": "I built a free ML practice platform - would love your feedback",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qvjiyd/i_built_a_free_ml_practice_platform_would_love/",
      "author": "akmessi2810",
      "created_utc": "2026-02-04 08:54:23",
      "score": 37,
      "num_comments": 13,
      "upvote_ratio": 0.91,
      "text": "After completing Andrew Ng's course, CS229, various math and ML stuff and also CS231n, I struggled to find quality practice problems. So I built Neural Forge:\n\n\n\n\\- Currently, 73 questions across all ML topics\n\n\\- Code directly in browser (Python via Pyodide)\n\n\\- Spaced repetition for retention\n\n\\- Instant test case validation\n\n\\- Knowledge graph showing prerequisites\n\n\\- 8 question types (MCQ, debug code, implement algorithms, design architectures, math derivations, case studies, paper implementations)\n\n\n\nTry it:¬†[https://neural-forge-chi.vercel.app/](https://neural-forge-chi.vercel.app/)\n\n\n\nBuilt it using Kimi Code (99% Kimi Code, 1% Manual Polish)\n\nLet me know your views below. Also report any bugs you come across.",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qvjiyd/i_built_a_free_ml_practice_platform_would_love/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3i0x10",
          "author": "Wonderful_Opposite54",
          "text": "Nice, quite similar to [squizzu.com](http://squizzu.com) but with less questions.I like the fact that you have closed questions and code blocks, but seems that your app struggle with some math formulas.",
          "score": 5,
          "created_utc": "2026-02-04 09:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3i1658",
              "author": "akmessi2810",
              "text": "yep its basically a functional MVP.\n\n  \ni have found some critical bugs too, currently working on fixing them.",
              "score": 2,
              "created_utc": "2026-02-04 09:04:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3o6ovt",
                  "author": "OutrageousDiet3631",
                  "text": "What is mvp",
                  "score": 1,
                  "created_utc": "2026-02-05 05:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iardv",
          "author": "migrated-human",
          "text": "Thanks for making this, haven't tried it yet but I'll get back to you. First impression - It looks nice and very useful l, covering a large number of topics. \nI noticed that there's no login system, do you plan to put that in later?",
          "score": 2,
          "created_utc": "2026-02-04 10:34:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iavvy",
              "author": "akmessi2810",
              "text": "Yep ofc, this is just a functional MVP. Planning to go all in to make it prod grade app. And then launch it officially. Lmk how it goes for you.",
              "score": 1,
              "created_utc": "2026-02-04 10:35:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3imkrj",
          "author": "pm_me_your_smth",
          "text": "Never heard of kimi code. Any specific reason to use it instead of other alternatives?",
          "score": 2,
          "created_utc": "2026-02-04 12:11:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lw6yo",
          "author": "CTR1",
          "text": "Second line from the very top has a typo, extra \" \\\\ \"\n\n# \"Welcome back, ML Master!\n\nContinue your journey to ML mastery. You\\\\'ve got this!\"",
          "score": 2,
          "created_utc": "2026-02-04 21:50:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lww3w",
              "author": "akmessi2810",
              "text": "thanks for reporting man! fixing rn.",
              "score": 1,
              "created_utc": "2026-02-04 21:54:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mid0z",
          "author": "balderDasher23",
          "text": "Looks really cool, nice job",
          "score": 1,
          "created_utc": "2026-02-04 23:46:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mj33c",
              "author": "akmessi2810",
              "text": "thanks man, did you like the project based learning feature?",
              "score": 1,
              "created_utc": "2026-02-04 23:50:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3nnqnb",
          "author": "Muted_Impact_9281",
          "text": "Looks sweet, nice job, kimi is the wave.",
          "score": 1,
          "created_utc": "2026-02-05 03:42:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o9u76",
              "author": "akmessi2810",
              "text": "for real",
              "score": 1,
              "created_utc": "2026-02-05 06:20:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvua3m",
      "title": "Upload an ONNX file to visualize your neural network",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qvua3m",
      "author": "CartoonistSeveral661",
      "created_utc": "2026-02-04 17:08:09",
      "score": 36,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qvua3m/upload_an_onnx_file_to_visualize_your_neural/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ox129",
          "author": "DaredevilMeetsL",
          "text": "How is this different from Netron?\n\nhttps://netron.app/",
          "score": 3,
          "created_utc": "2026-02-05 09:56:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p3gu1",
              "author": "CartoonistSeveral661",
              "text": "Netron is accurate and information dense but the visualization is just a 2d graph.",
              "score": 2,
              "created_utc": "2026-02-05 10:56:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qy7yqf",
      "title": "Need a realistic 3-month roadmap to become internship-ready for a Machine Learning Intern role",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qy7yqf/need_a_realistic_3month_roadmap_to_become/",
      "author": "Original_Map3501",
      "created_utc": "2026-02-07 07:53:48",
      "score": 25,
      "num_comments": 30,
      "upvote_ratio": 0.7,
      "text": "Hey everyone,  \nI‚Äôm aiming to land a **Machine Learning Intern** role in about **3 months** and I‚Äôd really appreciate guidance from people who‚Äôve been there.\n\n**My current level:**\n\n* Comfortable with **Python**\n* Basic understanding of **ML concepts** (supervised vs unsupervised, overfitting, etc.)\n* Some experience with coding projects, but **no strong ML portfolio yet**\n* College student (non-elite college, if that matters)\n\nWhat I‚Äôm looking for:\n\n* A **realistic, no-BS roadmap** for the next 3 months\n* What *actually* matters for internships (projects, math depth, frameworks, etc.)\n* How much **math** is expected (linear algebra, probability, stats to what level?)\n* What kind of **projects** make a resume stand out (and what‚Äôs considered useless/tutorial-spam)\n* Whether I should focus more on **ML, DL, or just solid fundamentals**\n* Any **mistakes you wish you avoided** when preparing for ML internships\n\nI‚Äôm not trying to ‚Äúbecome an ML engineer‚Äù in 90 days just want to be **internship-ready** and not clueless in interviews.\n\nIf you were starting again and had **3 months**, how would you spend them?\n\nThanks in advance   \nBlunt advice is welcome.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qy7yqf/need_a_realistic_3month_roadmap_to_become/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o41x4js",
          "author": "NotAnUncle",
          "text": "Is this sub just filled with chatgpt responses? Even this question reads like how gpt would respond it I asked for a roadmap",
          "score": 44,
          "created_utc": "2026-02-07 09:04:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4229rj",
              "author": "TheParanoidPyro",
              "text": "It is wild. Every post is written by chatgpt or looks like it is,¬† or the questions are completely braindead.¬†\n\n\nMost of the time both.\n\n\n\"Hi, how I do ml/ai? Do i need to know how to math? Is coding even important? Can i learn everything in 3 months?\"\n\n\nI do not care that this post says\n\n\n'I‚Äôm not trying to ‚Äúbecome an ML engineer‚Äù in 90 days just want to be internship-ready and not clueless in interviews. '\n\n\nSeeing the posts roll through coupled with the responses are, honestly, very worrying for the future. it is all so...gross.",
              "score": 13,
              "created_utc": "2026-02-07 09:56:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o41xcww",
              "author": "Original_Map3501",
              "text": "I used chat gpt to fix the grammatical mistakes and frame my question better.",
              "score": 3,
              "created_utc": "2026-02-07 09:07:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o42rwt9",
                  "author": "herooffjustice",
                  "text": "And I see nothing wrong in that, all the best.",
                  "score": 4,
                  "created_utc": "2026-02-07 13:31:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o41s483",
          "author": "Ok-Ebb-2434",
          "text": "chat are we planning to apply for summer 2026 internships in 3 months?",
          "score": 19,
          "created_utc": "2026-02-07 08:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41s5qb",
              "author": "Ok-Ebb-2434",
              "text": "lowkey this is me but I was planning to just crash course make something and apply to some this week",
              "score": 7,
              "created_utc": "2026-02-07 08:16:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o41suwu",
                  "author": "Original_Map3501",
                  "text": "Do I need to know Data structures too for an ML internship?",
                  "score": -12,
                  "created_utc": "2026-02-07 08:23:31",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4cck4u",
              "author": "_sauri_",
              "text": "Well you should be applying for them now. I know I am.",
              "score": 1,
              "created_utc": "2026-02-08 23:54:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o41x3zb",
          "author": "Radiant-Rain2636",
          "text": "The Lazy Programmer on Udemy. \nI do wish there was something like The Odin Project for ML AI",
          "score": 8,
          "created_utc": "2026-02-07 09:04:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46uvnz",
          "author": "AncientLion",
          "text": "3 months?  Isn't happening.",
          "score": 4,
          "created_utc": "2026-02-08 02:57:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45774v",
          "author": "nemesis1836",
          "text": "https://course.fast.ai/\n\nTry this",
          "score": 3,
          "created_utc": "2026-02-07 21:03:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41qe2m",
          "author": "Winners-magic",
          "text": "https://pixelbank.dev has a decent roadmap, especially if you cover the reference sources as well",
          "score": 4,
          "created_utc": "2026-02-07 07:59:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o424933",
          "author": "IamMax240",
          "text": "3 months? Forget about it bro",
          "score": 4,
          "created_utc": "2026-02-07 10:15:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42bbrn",
              "author": "Original_Map3501",
              "text": "But I dont think internships require you to have a lot of experience? I am in second year of college",
              "score": 2,
              "created_utc": "2026-02-07 11:23:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o42rsuf",
                  "author": "IamMax240",
                  "text": "Honestly it depends, ML isn't considered entry level (similarly to cybersec etc.), I'm in first year of college, been coding intensively for the past 2 years with strong emphasis on ML/DL for the past 6 months and I haven't been able to get a single internship. ",
                  "score": 3,
                  "created_utc": "2026-02-07 13:30:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44d6sp",
          "author": "flowanvindir",
          "text": "3 months is very short. The best thing you could do at this point are projects that are relevant to your internship. You'll learn way more actually doing than taking coursework for the amount of time you have.",
          "score": 2,
          "created_utc": "2026-02-07 18:26:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o427tn2",
          "author": "AirExpensive534",
          "text": "3 months is short, so you need to stop \"studying\" and start \"operating.\" Most internship candidates fail because they have a portfolio of tutorial-spam (Titanic, MNIST).\n\n\nTo stand out, move from probabilistic \"vibes\" to deterministic systems.¬†\n\n\nHere is the no-BS priority list:\n\n\nMonth 1: The Math & Logic Floor. Don't go deep into theoretical calculus. Master Linear Algebra (Matrix multiplication/transpositions) and Probability (Bayes‚Äô Theorem). You need to understand why a model drifts, not just that it does.¬†\n\n\nMonth 2: Infrastructure Over Frameworks. Everyone knows PyTorch/TensorFlow. Stand out by learning MLOps and System Architecture. Can you deploy a model? Can you build a \"Circuit Breaker\" to stop a model from hallucinating? This is what real companies care about.\n\n\nMonth 3: The \"Anti-Tutorial\" Project. Build one complex, end-to-end system. Example: A RAG pipeline with a custom evaluation loop that measures its own \"Maybe Tax\" (error rate/cost). Document the failures you fixed‚Äîthat‚Äôs what wins interviews.\n\n\nIf you want a specific framework for this, check out \"The Operator's Manual\" for agentic workflows. It‚Äôll move you from a \"learner\" to an \"operator\" faster than any Udemy course.¬†\n\n\nGood luck!",
          "score": 3,
          "created_utc": "2026-02-07 10:50:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o42gob1",
              "author": "KMikoto",
              "text": "Hello, what's the \"\"The Operator's Manual\" for agentic workflows\" please?",
              "score": 2,
              "created_utc": "2026-02-07 12:10:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o42i3qb",
                  "author": "AirExpensive534",
                  "text": "That‚Äôs the blueprint for moving past \"vibes\" and into high-reliability systems. It covers the architecture for building a Logic Floor and installing the Circuit Breakers needed to make agents production-ready.\n\n‚ÄãYou can find the link to the full breakdown right in my bio. Feel free to dive in there!¬†",
                  "score": 2,
                  "created_utc": "2026-02-07 12:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o49lnqc",
              "author": "Suspicious-Beyond547",
              "text": "thanks chat",
              "score": 1,
              "created_utc": "2026-02-08 15:37:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qukmuc",
      "title": "[Help] How to handle occlusions (trees) in Instance Segmentation for Flood/River Detection?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qukmuc",
      "author": "Odd-Scientist-4427",
      "created_utc": "2026-02-03 06:33:30",
      "score": 24,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qukmuc/help_how_to_handle_occlusions_trees_in_instance/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3aywbd",
          "author": "mineNombies",
          "text": "Depends entirely on how you want to use the model. Generally, the model's inference outputs will match how you label. If you include the trees in your labels, the model will also include them in the masks it creates at inference time; if not, it will not.\n\nIf you're planning on using the masks for something like calculating river extent or flow volume using segmented area, trees being in the way of the camera doesn't mean there's actually less water, so you should include the trees in your training data. If you're doing something like monitoring water color, then excluding trees would make sense if you're averaging pixel color within the mask.",
          "score": 13,
          "created_utc": "2026-02-03 07:21:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cteah",
          "author": "Kooky-Cap2249",
          "text": "Use NDVI and summer imagery to create a pre-filter mask, similar to instance segmentation.",
          "score": 6,
          "created_utc": "2026-02-03 15:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3g4ph1",
              "author": "darkgh0st23",
              "text": "Hey! Not OP, but can you explain how this can benefit OP's particular usecase?",
              "score": 1,
              "created_utc": "2026-02-04 01:03:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3dbcdc",
          "author": "Suolucidir",
          "text": "It looks like the image that includes the trees does faithfully follow the true water line. imo, that is a valuable feature to preserve in a model. So, I would include those trees.\n\nAdditionally, most bodies of water will have some foreground foliage and so the model should be trained to expect that instead of expecting a pristine angle on water line.",
          "score": 3,
          "created_utc": "2026-02-03 16:52:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ixle7",
          "author": "Suspicious-Expert810",
          "text": "Had a similar issue at work and before loosing too much time in deciding for one approach, tried both ways of labeling and used a new, fast workflow for that. We labeled a small subset, trained a rough model, and then used it as an annotation helper for the rest. That made it easy to try both versions (including vs excluding trees) without committing too early.\n\nIt wasn‚Äôt perfect, but much faster. You just correct predictions where it matters and iterate. In the end it was easier to compare what the model actually learns and the labeling process got way smoother. Especially in early stages of learning how labelling affects learning, this may be a nice visualisation and hopefully learning.",
          "score": 1,
          "created_utc": "2026-02-04 13:22:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qx9mvj",
      "title": "Feeling lost on next step",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qx9mvj/feeling_lost_on_next_step/",
      "author": "Busy-Drag-7906",
      "created_utc": "2026-02-06 05:59:17",
      "score": 24,
      "num_comments": 15,
      "upvote_ratio": 0.9,
      "text": "Hi, I'm currently trying to learn ML. I've implemented a lot of algorithms from scratch to understand them better like linear regression, trees, XGB, random forest, etc., and so now I was wondering what would be the next step? I'm feeling kind of lost rn, and I honestly don't know what to do. I know I'm still kind of in a beginner phase of ML, and I'm still trying to understand a lot of concepts, but at the same time, I feel like I want to do a project. My learning of AI as a whole is kind of all over the place because I started learning DL a couple of months ago, and I implemented my own NN (I know it's pretty basic), and then I kinda stopped for a while, and now I'm back. I just need some advice on where to go after this. Also would appreciate tips on project based learning especially. Feel free to DM",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qx9mvj/feeling_lost_on_next_step/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3v6rc6",
          "author": "Complex_Medium_7125",
          "text": "the algorithms you already mentioned work well for tabular data and not much else, if you're interested in tabular data there's plenty of interesting kaggle competitions from 5-10y ago that work on tabular data  \n  \nyou could try something that's on the deep learning path instead:  \n\\- build a search system for images like pinterest, check out SigLIP/CLIP, FAISS for smth to get done in a day  \n\\- build a search system for your own local files, or code, or email, or chats  \n\\- build the best chess playing bot you can  \n\\- rl game playing bots, check out cleanrl [https://docs.cleanrl.dev/](https://docs.cleanrl.dev/)  \n\\- generate images check the cmu homewors [https://kellyyutonghe.github.io/10799S26/homework/](https://kellyyutonghe.github.io/10799S26/homework/)  \n\\- llm fundations - do any homework from cs336 at stanford  \n\\- rl on llms - do the  assignment 5 from [https://github.com/stanford-cs336/assignment5-alignment](https://github.com/stanford-cs336/assignment5-alignment)",
          "score": 3,
          "created_utc": "2026-02-06 07:47:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wr0cd",
          "author": "Significant_Soup2558",
          "text": "Compiled a [500+ ML questions quiz.](https://applyre.com/resources/500-interview-questions/machine-learning-and-artificial-intelligence/). You might find it helpful",
          "score": 2,
          "created_utc": "2026-02-06 14:46:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3x2dbd",
          "author": "Wonderful_Opposite54",
          "text": "From my perspective as Data Scientist it should go it both directions:\n- build end-to-end app. Something simple but connected to your hobbies. See it in real world solving real world problem. Try to host it on Azure or AWS.\n- test your knowledge. Beginners very often feel that ‚Äúunderstand‚Äù something but it‚Äôs not true. They don‚Äôt know which concept is connect to which architecture etc. For example https://squizzu.com has a lot of interview questions for ML-connected roles in the form of quiz so you can test your knowledge. \nDo you need any recommendations for good ML books?",
          "score": 1,
          "created_utc": "2026-02-06 15:42:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ydkru",
              "author": "Aihak",
              "text": "Yes please, a good book recommendation will go a long way.",
              "score": 1,
              "created_utc": "2026-02-06 19:26:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o41jzkj",
                  "author": "Wonderful_Opposite54",
                  "text": "2 best classics for the beginning:  \nPython Machine Learning - Raschka Sebastian  \nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow 3e: Concepts, Tools, and Techniques to Build Intelligent Systems - Geron Aurelien",
                  "score": 1,
                  "created_utc": "2026-02-07 07:00:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xabej",
          "author": "DataCamp",
          "text": "At the point you‚Äôre at (NumPy/pandas + a bit of plotting), we usually suggest: 1) learn the core ML workflow in scikit-learn (train/test split, metrics, overfitting), 2) do 1 small end-to-end project, 3) only then touch deep learning. Using ‚Äúexisting models‚Äù isn‚Äôt cheating, it‚Äôs literally how most ML work gets done.",
          "score": 1,
          "created_utc": "2026-02-06 16:20:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xoo88",
          "author": "AirExpensive534",
          "text": "Building algorithms from scratch is the \"Trial by Fire\" phase, and the fact that you‚Äôve done it means you have a stronger foundation than 90% of beginners.¬†\nBut you‚Äôve reached the \"Implementation Trap\"‚Äîwhere you know how the engine works, but you haven't learned how to drive the car in traffic.\n\n\nIn 2026, the gap between \"code that works in a notebook\" and \"code that works in production\" is massive. To move from beginner to hireable, you need to transition from Model Building to System Architecting.\n\n\nHere is your \"Project-Based\" roadmap to get unstuck:\n\n1. The \"Data-Centric\" Pivot\nStop using clean Kaggle datasets. Real-world ML is 80% data engineering. Pick a \"messy\" domain (like real-time weather or stock sentiment) and build a pipeline that handles:\n¬†\n* Feature Engineering: Automating the transformation of raw data.\n\n\n¬†* Validation: Writing tests to ensure your data hasn't \"drifted\" (changed) since you last trained.\n\n\n2. Move from Algorithms to \"Agentic Workflows\"\nSince you‚Äôve built NNs and XGBoost, try building a system where they talk to each other.¬†\n\n\nFor example:\n\n\n¬†* The Project: Build a \"Price Prediction Agent.\"\n\n\n¬†* The Logic: Use your XGBoost model to predict a price, then use a Small Language Model (SLM) to \"justify\" that price based on news headlines. This teaches you how to bridge deterministic logic with probabilistic AI.\n\n\n3. Master the \"Logic Floor\"\nIn production, we don't just care if a model is 92% accurate; we care about what happens during the 8% it's wrong. Your next project should include a Deterministic Guardrail. If the model output looks like an outlier, your code should automatically catch it and trigger a \"Clinical Reset.\"\n\n\n4. Deployment is the New \"From Scratch\"\nIf it isn't on a server, it doesn't exist.¬†\n\n\nTake your best scratch-built model and:\n\n\n¬†* Wrap it in a FastAPI.\n\n\n¬†* Containerize it with Docker.\n\n\n¬†* Deploy it to a cloud provider¬†(AWS/GCP/Vercel).\n\n\nI‚Äôve mapped out the specific Mechanical Logic blueprints I use to turn \"scratch\" algorithms into production-grade systems in my bio. It‚Äôs the \"Senior\" layer you‚Äôre missing‚Äîmoving from understanding the math to managing the Zero-Drift lifecycle of a model.",
          "score": 1,
          "created_utc": "2026-02-06 17:27:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47w78l",
          "author": "chrisvdweth",
          "text": "Maybe our growing GitHub repo [SELENE](https://github.com/chrisvdweth/selene) with interactive Jupyter notebooks for self-learning can be useful.",
          "score": 1,
          "created_utc": "2026-02-08 07:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uv0fj",
          "author": "Acceptable-Eagle-474",
          "text": "You're not lost, you're just at the transition point. Going from \"I implemented algorithms\" to \"I can solve problems\" is the next step, and it's where most people stall.\n\nThe good news: implementing from scratch means you understand what's happening. That puts you ahead of people who just call sklearn and hope for the best.\n\nWhat to do next:\n\nStop implementing algorithms. Start solving problems.\n\nYou've proven you understand the mechanics. Now prove you can apply them to real situations. That's what jobs and projects require.\n\nHow to do project-based learning right:\n\n1. Start with a question, not a technique. Not \"I want to use XGBoost\" but \"Can I predict which customers will churn?\" The technique serves the problem, not the other way around.\n\n2. Use real or realistic data. Kaggle has plenty. Pick something that interests you ‚Äî healthcare, sports, finance, e-commerce, whatever. Interest keeps you going when it gets frustrating.\n\n3. Go end-to-end. Data cleaning, exploration, feature engineering, modeling, evaluation, and a summary of what you found. That full loop is what employers want to see.\n\n4. Document everything. A project without a README is invisible. Explain the problem, your approach, your results, and what you learned.\n\n5. Keep scope small at first. One dataset, one question, one model. You can always expand later.\n\nProject ideas based on what you already know:\n\n\\- Churn prediction (classification ‚Äî trees, XGB)\n\n\\- House price prediction (regression ‚Äî linear, random forest)\n\n\\- Customer segmentation (clustering ‚Äî add KMeans to your toolkit)\n\n\\- Loan default prediction (classification + imbalanced data)\n\n\\- Demand forecasting (time series ‚Äî stretch goal)\n\nPick one that sounds interesting and finish it completely. A finished simple project teaches more than five half-built complex ones.\n\nOn your learning being \"all over the place\":\n\nThat's normal. Most people bounce around early on. The fix is committing to one project and seeing it through. You'll fill in gaps as you go.\n\n\n\nI put together 15 portfolio projects with end-to-end structure ‚Äî churn, forecasting, segmentation, fraud detection, and more. Each has code, documentation, and a case study. Might help you see how to frame and complete projects.\n\n$5.99 if useful: [https://whop.com/codeascend/the-portfolio-shortcut/](https://whop.com/codeascend/the-portfolio-shortcut/)\n\n\n\nEither way, pick one project and finish it this week. That momentum will tell you what to learn next better than any roadmap.",
          "score": -6,
          "created_utc": "2026-02-06 06:05:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uvm13",
              "author": "Busy-Drag-7906",
              "text": "Bru if I wanted to ask chat I would've and I don't want to buy your course üò≠üò≠",
              "score": 5,
              "created_utc": "2026-02-06 06:10:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3uwapm",
                  "author": "Acceptable-Eagle-474",
                  "text": "Fair enough, no course, just a project bundle, but I hear you. The advice stands either way. Good luck with the projects.",
                  "score": -3,
                  "created_utc": "2026-02-06 06:16:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3v9d0z",
              "author": "AmbitiousPattern7814",
              "text": "his reply lookalike he copy paste all that from chat gpt just to make some commision\n\n",
              "score": 2,
              "created_utc": "2026-02-06 08:11:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3wykvt",
                  "author": "Acceptable-Eagle-474",
                  "text": "Didn't use GPT, but I'll take that as a compliment, means the advice is clear. Either way, the points still stand.",
                  "score": 1,
                  "created_utc": "2026-02-06 15:24:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}