{
  "metadata": {
    "last_updated": "2026-01-24 16:49:57",
    "time_filter": "week",
    "subreddit": "learnmachinelearning",
    "total_items": 20,
    "total_comments": 163,
    "file_size_bytes": 152189
  },
  "items": [
    {
      "id": "1qk4s91",
      "title": "Leetcode for ML",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/jlvluyfqgyeg1",
      "author": "Big-Stick4446",
      "created_utc": "2026-01-22 19:51:27",
      "score": 687,
      "num_comments": 39,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qk4s91/leetcode_for_ml/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o151eqx",
          "author": "Door_Number_Three",
          "text": "Nice and neat when its a convex function",
          "score": 55,
          "created_utc": "2026-01-22 23:25:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a7twk",
              "author": "ea2ox0",
              "text": "yeah this is good for learning purposes, real applications of gradient descent optimization more complex than just a parabola.",
              "score": 6,
              "created_utc": "2026-01-23 18:29:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1aat3p",
                  "author": "Hopeful-Ad-607",
                  "text": "It's supposed to be the basic introduction to the \\*idea\\* of gradient descent. I think we all implemented a very basic gradient with the basic derivative formula for N1 and N2 functions with very simple step size calculation based on the slope angle when we learned about finding local minima. Then we learn the chain-rule matrix formulas for back propagating errors to compute the slope, and its a more intuitive transition.",
                  "score": 5,
                  "created_utc": "2026-01-23 18:42:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o15037f",
          "author": "aonro",
          "text": "Damn this is kinda epic",
          "score": 23,
          "created_utc": "2026-01-22 23:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1587t7",
          "author": "Icy_Wishbone8649",
          "text": "very cool man, ive been learning it and wanted to get better; if you want ill be glad to help.",
          "score": 10,
          "created_utc": "2026-01-23 00:00:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15a1u5",
          "author": "DatabaseKindly919",
          "text": "I checked it out.loved it!",
          "score": 6,
          "created_utc": "2026-01-23 00:10:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15kojb",
          "author": "Sudain",
          "text": "!remindme 7 days",
          "score": 6,
          "created_utc": "2026-01-23 01:07:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15ktp5",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-01-30 01:07:29 UTC**](http://www.wolframalpha.com/input/?i=2026-01-30%2001:07:29%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/learnmachinelearning/comments/1qk4s91/leetcode_for_ml/o15kojb/?context=3)\n\n[**12 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Flearnmachinelearning%2Fcomments%2F1qk4s91%2Fleetcode_for_ml%2Fo15kojb%2F%5D%0A%0ARemindMe%21%202026-01-30%2001%3A07%3A29%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qk4s91)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 2,
              "created_utc": "2026-01-23 01:08:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o14wxx4",
          "author": "Any-Seaworthiness770",
          "text": "DAAAAAYYUUUUUUMMMMMMMMM",
          "score": 8,
          "created_utc": "2026-01-22 23:02:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17zyr5",
          "author": "SigismundsWrath",
          "text": "Hi, is there some way to turn off the main page animations? Just trying to log in spikes my GPU to ~80% and causes horrible jittery lag. Even the problems page is using ~30%-50% GPU, and it's not even animated...\n\n\nOtherwise looks really cool, I'll be checking it out!",
          "score": 3,
          "created_utc": "2026-01-23 11:41:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1848hn",
              "author": "Big-Stick4446",
              "text": "Good suggestion! Will see this issue.",
              "score": 3,
              "created_utc": "2026-01-23 12:13:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1au76e",
                  "author": "Proud_Fox_684",
                  "text": "Nice work otherwise :)",
                  "score": 1,
                  "created_utc": "2026-01-23 20:12:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o15pzie",
          "author": "Pleasant-Sample800",
          "text": "cheers!",
          "score": 2,
          "created_utc": "2026-01-23 01:37:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15t9u5",
          "author": "gabe_dos_santos",
          "text": "I checked it out, reallyyyyy coolllll.",
          "score": 2,
          "created_utc": "2026-01-23 01:56:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15ukln",
          "author": "Human-Computer4161",
          "text": "Good one brother",
          "score": 2,
          "created_utc": "2026-01-23 02:03:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15zi0i",
          "author": "Background-Barber667",
          "text": "this looks so good. big fan of codewars too.",
          "score": 2,
          "created_utc": "2026-01-23 02:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17dka8",
          "author": "vamshi_k_2004",
          "text": "This will be seriously helpful...",
          "score": 2,
          "created_utc": "2026-01-23 08:21:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17jp4t",
          "author": "nonameagainagain",
          "text": "you should add problem in computer vision\n\nanyway this is great i created an account just now",
          "score": 2,
          "created_utc": "2026-01-23 09:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1801zg",
          "author": "WlmWilberforce",
          "text": "Pretty cool -- Good job.  (Also shows why I hate gradient decent -- Raphson-Newton for the win)",
          "score": 2,
          "created_utc": "2026-01-23 11:42:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18gzuu",
          "author": "StillBodybuilder9137",
          "text": "I tried it, and I had fun working on niche AI topics. Definitely looking for more ..",
          "score": 2,
          "created_utc": "2026-01-23 13:32:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18jrga",
          "author": "ethanael",
          "text": "This looks like an incredibly useful resource. I'll dig into it this weekend! Thanks a ton for the energy put into it!",
          "score": 2,
          "created_utc": "2026-01-23 13:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1975l3",
          "author": "C_Ardan05",
          "text": "I was first place on your platform for a long time. Dropped a few places now I think as I have been busy with other projectsðŸ˜… But I can absolutely recommend it to anyone. Great way to learn ML. Thank you!",
          "score": 2,
          "created_utc": "2026-01-23 15:43:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19n7mr",
          "author": "Infinite_Benefit_335",
          "text": "Damn nice",
          "score": 2,
          "created_utc": "2026-01-23 16:55:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19sel8",
          "author": "Vrn08",
          "text": "Waaaaooo.. It's really amazing. Thought to build something similar when I was a beginner but couldn't achieve. Nice that you have achieved it.",
          "score": 2,
          "created_utc": "2026-01-23 17:19:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19vavz",
          "author": "kanashiku",
          "text": "Love this omg",
          "score": 2,
          "created_utc": "2026-01-23 17:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19vxzv",
          "author": "Ok_Promise_9470",
          "text": "Insane work!",
          "score": 2,
          "created_utc": "2026-01-23 17:35:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15qfq2",
          "author": "Pleasant-Sample800",
          "text": "!remindme 7 days",
          "score": 1,
          "created_utc": "2026-01-23 01:40:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17m7vx",
          "author": "throwwwawwway1818",
          "text": "Application error: a clientside exception has occurred",
          "score": 1,
          "created_utc": "2026-01-23 09:42:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17rblg",
              "author": "Big-Stick4446",
              "text": "which browser are you using",
              "score": 1,
              "created_utc": "2026-01-23 10:29:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o19pmn9",
                  "author": "throwwwawwway1818",
                  "text": "Firefox",
                  "score": 1,
                  "created_utc": "2026-01-23 17:06:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19wigx",
          "author": "Sudain",
          "text": "I'm curious why accounts are needed on it if it's just showing different algorithms.",
          "score": 1,
          "created_utc": "2026-01-23 17:38:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1a6h4r",
          "author": "gvime",
          "text": "Hello buddy, can I use your graphs in my assignments for my Machine Learning course at university? Of course I will do the proper referencing for your work.",
          "score": 1,
          "created_utc": "2026-01-23 18:23:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a7wsz",
              "author": "Big-Stick4446",
              "text": "yes",
              "score": 2,
              "created_utc": "2026-01-23 18:29:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1a9go8",
                  "author": "gvime",
                  "text": "thanks",
                  "score": 1,
                  "created_utc": "2026-01-23 18:36:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1fm9cu",
          "author": "Soggy_Annual_6611",
          "text": "Can you create a Playlist for SQL and Data analysis as well, and for ML also can we implement things using pytorch or tensorflow as well.",
          "score": 1,
          "created_utc": "2026-01-24 14:52:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fn0an",
              "author": "Big-Stick4446",
              "text": "yes thats coming soon",
              "score": 1,
              "created_utc": "2026-01-24 14:56:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1fok5g",
                  "author": "Soggy_Annual_6611",
                  "text": "That's great news, now we have one complete platform for ML tutorials.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:04:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o15np32",
          "author": "Zealousideal_Tie_426",
          "text": "Nice dude",
          "score": 1,
          "created_utc": "2026-01-23 01:24:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qko719",
      "title": "Just started Machine Learning",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/0s7ugkzy13fg1.jpeg",
      "author": "Dark_Syntax_",
      "created_utc": "2026-01-23 11:19:22",
      "score": 349,
      "num_comments": 5,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qko719/just_started_machine_learning/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o180dw7",
          "author": "Bulky-Top3782",
          "text": "Yeah you better make sure the fabric is linearly separable",
          "score": 29,
          "created_utc": "2026-01-23 11:44:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o181mrs",
              "author": "Dark_Syntax_",
              "text": "SureðŸ˜ƒ",
              "score": 7,
              "created_utc": "2026-01-23 11:54:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a28uj",
          "author": "Xerxys",
          "text": "Havenâ€™t the robots already stolen this job?",
          "score": 4,
          "created_utc": "2026-01-23 18:04:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1cm9da",
              "author": "SnooCapers9708",
              "text": "Still not in india, in india it's a good paying business and job",
              "score": 2,
              "created_utc": "2026-01-24 01:40:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1f5lqs",
          "author": "Radiant-Rain2636",
          "text": "ðŸ¤£",
          "score": 1,
          "created_utc": "2026-01-24 13:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg6q1w",
      "title": "I implemented a VAE in Pure C for Minecraft Items",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qg6q1w",
      "author": "Boliye",
      "created_utc": "2026-01-18 11:53:54",
      "score": 286,
      "num_comments": 34,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qg6q1w/i_implemented_a_vae_in_pure_c_for_minecraft_items/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0a2iu3",
          "author": "Cybyss",
          "text": "Damn. That is really cool! \n\nYou basically reinvented your own PyTorch from scratch in plain C and used that to create your own variational autoencoder? Ambitious. I also love the creativity of training on Minecraft images instead of the usual MNIST or CIFAR. \n\nWell done!",
          "score": 34,
          "created_utc": "2026-01-18 12:17:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a36ye",
              "author": "Boliye",
              "text": "Thank you!",
              "score": 5,
              "created_utc": "2026-01-18 12:22:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a1xnh",
          "author": "Palmquistador",
          "text": "I donâ€™t think I understand. You created your own image generator specific to Minecraft images?",
          "score": 24,
          "created_utc": "2026-01-18 12:12:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a35l0",
              "author": "Boliye",
              "text": "Yeah, sort of! A VAE is a type of network that can be used for image generation. And I created and trained one of these with Minecraft images. But as a VAE is also an autoencoder, something you can also do is play with the embeddings and ask the network stuff like \"what's at the middle point between this and that?\" \"What would happen if you took this and subtracted that?\". If the network was successful in learning meaningful concepts, these averages won't be nonsense, and stuff like what I show in the images will happen.",
              "score": 36,
              "created_utc": "2026-01-18 12:22:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0acap7",
                  "author": "LumpyWelds",
                  "text": "Is this like word2vec?\n\n\"dog\" - \"puppy\" + \"kitten\" = \"cat\"",
                  "score": 20,
                  "created_utc": "2026-01-18 13:28:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0f0ys1",
              "author": "irekit_",
              "text": "A variational auto-encoder is something that encodes data like images into the latent space, it uses probabilities and outputs a gaussian distribution of where the data is likely to be in the latent space.",
              "score": 3,
              "created_utc": "2026-01-19 03:50:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0f29ye",
                  "author": "Palmquistador",
                  "text": "So like RAG? But the VAE is just one step in the image generation process, right? Thatâ€™s what ComfyUI implies with their connectors at least.",
                  "score": 1,
                  "created_utc": "2026-01-19 03:59:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a6v1n",
          "author": "gocurl",
          "text": "Doing the \"- concept 1 + concept 2\" and having a relevant result is a very cool way to confirm your model understood key concept. Very well done!\nOut of curiositÃ©, in that \"- x + x\" step, what is the input you provides? Do you start from the middle layer?",
          "score": 11,
          "created_utc": "2026-01-18 12:50:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a95uo",
              "author": "Boliye",
              "text": "Yeah I use the encoder and decoder parts separately:  \n\nEncode iron\\_chestplate -> Latent for iron\\_chestplate  \n\nEncode all items that contain 'iron' in their name and average them out -> Latent for iron concept  \n\nEncode all items that contain 'diamond' in their name and average them out -> Latent for diamond concept  \n\nLiterally do the operation \"Latent for iron\\_chestplate\" - \"Latent for iron concept\" + \"Latent for diamond concept\"  \n\nFinally, pass this result to the decoder (second half of the network).",
              "score": 12,
              "created_utc": "2026-01-18 13:07:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0arh78",
                  "author": "gocurl",
                  "text": "It seems so clear now youâ€™ve said it, but I've never thought about it this way, thanks!",
                  "score": 4,
                  "created_utc": "2026-01-18 14:55:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0a81f9",
          "author": "JanBitesTheDust",
          "text": "Very cool idea! How did you find the latent vector for the concept of iron? Is it just averaging latent vectors for all iron related minecraft textures?",
          "score": 8,
          "created_utc": "2026-01-18 12:59:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a8q6v",
              "author": "Boliye",
              "text": "Yes! it is just the average",
              "score": 6,
              "created_utc": "2026-01-18 13:04:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0dtqkf",
                  "author": "possiblyquestionabl3",
                  "text": "This is a pretty cool trick!\n\nA couple of assumptions:\n\n1. your set of iron related items form some concept vector space like `v_{iron_sword} \\approx v_{iron} + v_{sword}`\n2. it's sufficiently large in dimension, so that different concepts tend to be naturally orthogonal (e.g. v\\_{sword} and v\\_{bar} are nearly orthogonal to each other)\n\nlet `z_{iron}` be the mean vector over all iron related vectors, then\n\n    z_{iron} = 1/N \\sum_{type} v_{iron type} = v_{iron} + 1/N \\sum_{type} v_{type}\n\nif N, the number of distinct iron X items, is large enough, and if we assume v_{type} are generally orthogonal to each other, then `\\sum_{type} v_{type}` can be seen as an isotropic ball of noise with a spherical radius of `||v_{type}|| * sqrt(N)`. As a result, you're essentially computing\n\n    z_{iron} = v_{iron} + noise ||v_{type}||/sqrt(N)\n\nnormalizing v, you're basically computing the actual concept vector for `v_{iron}`, plus noise of O(n^(-1/2)). E.g. if you can provide 100 `iron X` samples, your noise goes down to ~10%.\n\nIf structurally, iron and diamond items have the exact same types (e.g. swords, bars, etc), then the noise term will be structurally similar (same general direction), so `- z_{iron} + z_{diamond}` should be able to cancel the noise out almost perfectly. However, adding/subtracting concepts together without cancellation will amplify the noise, and categories with low # of types to average will have proportionally sqrt(N) times more noise.\n\nIt might be worthwhile to do a few power-iterations on the 2nd-moment operator `M = 1/N \\sum_{type} v_{iron type} v_{iron type}^T` using the mean `z_{iron}` direction to get to the real `v_{iron}` direction (probably converges in just 1-2 steps since the mean `z_{iron}` is already dominated in the `v_{iron}` direction). It's fairly cheap and would allow you to avoid the sqrt(N) noise term.",
                  "score": 3,
                  "created_utc": "2026-01-18 23:53:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0aus8u",
          "author": "ToSAhri",
          "text": "To what extent did this latent arithmetic operation rely on the convenience of the iron and diamond items being very similar (if not identical save for the color)?\n\nI guess Iâ€™m confused on how the latent arithmetic has inherent use of that method. If we only had a random sample of half of the iron items and half of the diamond items would it still work well? Cause then we could use it to generate diamond versions of iron pieces we donâ€™t have and vice versa.\n\nItâ€™s possible I just donâ€™t grasp the use case of VAEs in general and thatâ€™s where my confusion comes from.",
          "score": 3,
          "created_utc": "2026-01-18 15:12:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0b06wb",
              "author": "Boliye",
              "text": "You are right this is just a toy project, and the model is not that powerful to do anything really useful. If I ask it to generate new items, the quality is meh and I wouldn't be surprised if we did that experiment and asked it to generate something that did not exist in its training data, the VAE would struggle to generate something out of distribution like that. I am definetly making the task easier by trying to generate something that I know was present in the training data.\n\nTake the second example (the one where we turn a gold horse armor to a golden shovel). The fact that the generated shovel is yellow, shows that somewhere in the latent space, color of the object is one of the compressed features it learned to be useful for reconstructing.\n\nUltimately, the essence of the latents is that they are just 32 numbers trying to compress the information of a 3\\*16\\*16 = 768 pixel image. So the VAE has to find the most useful high-level features that characterize each image.",
              "score": 3,
              "created_utc": "2026-01-18 15:39:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ahb3j",
          "author": "Anas0101",
          "text": "so cool",
          "score": 2,
          "created_utc": "2026-01-18 13:59:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0al3sb",
              "author": "Boliye",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-01-18 14:20:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0bkd64",
          "author": "Poleski69",
          "text": "Thats really cool! \n\nIt's a variational autoencoder, so what happens if you sample the latent space with a normal distribution? I know var autoencoders aren't the best at generation but I'm really curious to see what your implementation thinks the 'average' minecraft item is!",
          "score": 2,
          "created_utc": "2026-01-18 17:15:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cl97x",
              "author": "Boliye",
              "text": "Here are you go:  \n[https://imgur.com/a/TNYgQ32](https://imgur.com/a/TNYgQ32)\n\nFor convinience, for these extra generations I didn't use the C VAE, but the proof of concept in Python that I also created (it can be found in the folder poc\\_python in the git repo). It implements the exact same architecture and achieves the same loss.\n\nIn addition to \"the average item\", and some generations, I also added interpolations between a few items like a diamond chestplate turning into a diamond sword.",
              "score": 1,
              "created_utc": "2026-01-18 20:09:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0kqbj5",
                  "author": "Poleski69",
                  "text": "Super cool!\n\nAm I understanding correctly that the top image is the output of a latent tensor filled with zeros, and the ones under are from normally distributed \"noise\" latents (torch.randn ..)?\n\nInterpolations are really cool too, makes me wonder how hard it would be to implement latent ddpm in pure c and fully make use of the autoencoder.",
                  "score": 1,
                  "created_utc": "2026-01-20 00:13:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0dszkw",
          "author": "ami98",
          "text": "Super cool! Your code is very easy to understand, and it's neat that your python proof of concept matches your C results!\n\nBy any chance, do you know of a good textbook that discusses the mathematics behind these algorithms? Thanks:)",
          "score": 2,
          "created_utc": "2026-01-18 23:49:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hun4t",
              "author": "Boliye",
              "text": "Thank you! Yeah at first I was sure there would be some kind of difference I wouldn't be able to find between the trained PyTorch model and my C implementation, I was pretty happy when the numbers matched up :)\n\nI honestly don't feel informed enough to recommend good textbooks. I personally enjoyed a lot these lectures on youtube about \"Deep Generative Models\" from Stanford [https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8](https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8) . It does cover the mathematics behind it to a degree I find satisfying. But yeah, if you prefer textbooks, I can't really advise any better than other students.",
              "score": 1,
              "created_utc": "2026-01-19 16:01:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0e7fqu",
          "author": "Fickle_Lettuce_2547",
          "text": "How long have you used C to be able to make something like this??",
          "score": 2,
          "created_utc": "2026-01-19 01:06:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hzdp8",
              "author": "Boliye",
              "text": "C is a surprisingly simple language really! It has very few keywords and features. What is tricky and it will take some studying if you have never seen it before is memory management. Memory management can become a mess if you aren't thoughtful about it.\n\nLuckily, for this project the memory management is quite simple. So the code is not that different from programing in any other language.\n\nAlso, you need to be careful about bugs and test things as you go. For many mistakes you could make, the code could keep running in invalid states and do who-knows-what. Ultimately crashing without giving any insight on where's the bug.",
              "score": 2,
              "created_utc": "2026-01-19 16:22:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0h9kcq",
          "author": "arsenic-ofc",
          "text": "cool, i love VAEs, helped me do similar stuff with dance videos.",
          "score": 2,
          "created_utc": "2026-01-19 14:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r01np",
          "author": "Scary-Opportunity848",
          "text": "Really cool stuff. For the latent space for iron you may be able to run svd over the matrix of all iron vectors. And instead of taking the average, take the top eigen values/vectors and whatever vector that creates. It should hold more iron since it is meant to capture the most common/consistent aspects across all of that batch. Really cool work btw",
          "score": 2,
          "created_utc": "2026-01-20 22:21:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mcgex",
          "author": "MeticulousBioluminid",
          "text": "sick",
          "score": 1,
          "created_utc": "2026-01-20 05:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qnzjw",
          "author": "Lupoferrin",
          "text": "This is a fascinating project! Building a VAE from scratch in C is a deep dive into the fundamentals. It highlights how understanding core algorithms can lead to innovative applications, even in areas like game asset generation.",
          "score": 1,
          "created_utc": "2026-01-20 21:24:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qiguai",
      "title": "SVM from scratch in JS",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/8s2nuomc6leg1",
      "author": "Ok-Statement-3244",
      "created_utc": "2026-01-20 23:10:56",
      "score": 217,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qiguai/svm_from_scratch_in_js/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0rcgp4",
          "author": "0uchmyballs",
          "text": "Looking forward to more ML in JS",
          "score": 5,
          "created_utc": "2026-01-20 23:25:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0slpwd",
          "author": "rshah4",
          "text": "Karpathy did a version of this as well: [https://cs.stanford.edu/\\~karpathy/svmjs/demo/](https://cs.stanford.edu/~karpathy/svmjs/demo/)",
          "score": 3,
          "created_utc": "2026-01-21 03:42:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rp1nw",
          "author": "sodapopenski",
          "text": "Now THIS is machine learning.",
          "score": 2,
          "created_utc": "2026-01-21 00:34:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y24gy",
          "author": "pacukluka",
          "text": "\"Show Meth :3\" ðŸ§",
          "score": 1,
          "created_utc": "2026-01-21 22:59:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qib764",
      "title": "[Cheat Sheet] I summarized the 10 most common ML Algorithms for my interview prep. Thought I'd share.",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qib764/cheat_sheet_i_summarized_the_10_most_common_ml/",
      "author": "IT_Certguru",
      "created_utc": "2026-01-20 19:41:10",
      "score": 176,
      "num_comments": 21,
      "upvote_ratio": 0.9,
      "text": "Hi everyone,\n\nIâ€™ve been reviewing the basics for upcoming interviews, and I realized I often get stuck trying to explain simple concepts without using jargon.\n\nI wrote down a summary for the top 10 algorithms to help me memorize them. I figured this might help others here who are just starting out or refreshing their memory.\n\nHere is the list:\n\n# 1. Linear Regression\n\n* **The Gist:** Drawing the straightest possible line through a scatter plot of data points to predict a value (like predicting house prices based on size).\n* **Key Concept:** Minimizing the \"error\" (distance) between the line and the actual data points.\n\n# 2. Logistic Regression\n\n* **The Gist:** Despite the name, it's for **classification**, not regression. It fits an \"S\" shaped curve (Sigmoid) to the data to separate it into two groups (e.g., \"Spam\" vs. \"Not Spam\").\n* **Key Concept:** It outputs a probability between 0 and 1.\n\n# 3. K-Nearest Neighbors (KNN)\n\n* **The Gist:** The \"peer pressure\" algorithm. If you want to know what a new data point is, you look at its 'K' nearest neighbors. If most of them are Blue, the new point is probably Blue.\n* **Key Concept:** It doesn't actually \"learn\" a model; it just memorizes the data (Lazy Learner).\n\n# 4. Support Vector Machine (SVM)\n\n* **The Gist:** Imagine two groups of data on the floor. SVM tries to put a wide street (hyperplane) between them. The goal is to make the street as wide as possible without touching any data points.\n* **Key Concept:** The \"Kernel Trick\" allows it to separate data that isn't easily separable by a straight line by projecting it into higher dimensions.\n\n# 5. Decision Trees\n\n* **The Gist:** A flowchart of questions. \"Is it raining?\" -> Yes -> \"Is it windy?\" -> No -> \"Play Tennis.\" It splits data into smaller and smaller chunks based on simple rules.\n* **Key Concept:** Easy to interpret, but prone to \"overfitting\" (memorizing the data too perfectly).\n\n# 6. Random Forest\n\n* **The Gist:** A democracy of Decision Trees. You build 100 different trees and let them vote on the answer. The majority wins.\n* **Key Concept:** Reduces the risk of errors that a single tree might make (Ensemble Learning).\n\n# 7. K-Means Clustering\n\n* **The Gist:** You have a messy pile of unlabelled data. You want to organize it into 'K' number of piles. The algorithm randomly picks centers for the piles and keeps moving them until the groups make sense.\n* **Key Concept:** Unsupervised learning (we don't know the answers beforehand).\n\n# 8. Naive Bayes\n\n* **The Gist:** A probabilistic classifier based on Bayes' Theorem. It assumes that all features are independent (which is \"naive\" because in real life, things are usually related).\n* **Key Concept:** Surprisingly good for text classification (like filtering emails).\n\n# 9. Principal Component Analysis (PCA)\n\n* **The Gist:** Data compression. You have a dataset with 50 columns (features), but you only want the 2 or 3 that matter most. PCA combines variables to reduce complexity while keeping the important information.\n* **Key Concept:** Dimensionality Reduction.\n\n# 10. Gradient Boosting (XGBoost/LightGBM)\n\n* **The Gist:** Similar to Random Forest, but instead of building trees at the same time, it builds them one by one. Each new tree tries to fix the mistakes of the previous tree.\n* **Key Concept:** Often the winner of Kaggle competitions for tabular data.\n\nIf you want to connect these concepts to real production workflows, one helpful resource is a hands-on course on Machine Learning on Google Cloud. It shows how algorithms like Linear/Logistic Regression, PCA, Random Forests, and Gradient Boosting: [Machine Learning on Google Cloud](https://www.netcomlearning.com/course/machine-learning-on-google-cloud)\n\nLet me know if I missed any major ones or if you have a better analogy for them!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qib764/cheat_sheet_i_summarized_the_10_most_common_ml/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o0qieow",
          "author": "Disastrous_Room_927",
          "text": ">Despite the name, it's for **classification**, not regression. It fits an \"S\" shaped curve (Sigmoid) to the data to separate it into two groups (e.g., \"Spam\" vs. \"Not Spam\").\n\nThis isn't correct: regression is descriptive of the model being fit, classification is one use case for it. It isn't fitting an s-shaped curve directly, the fit is actually linear with respect to the log-odds, not the probability itself. The s-curve arises when you convert the output of the model back to probabilities.\n\nUnderstanding that the output people normally work with \"lives\" in a different space than the model is important if you're interpreting coefficients, or if you want to use a linear model with other types of responses. You can use Poisson/Negative Binomial regression for count data, beta regression for continuous proportions, gamma regression for data that is positive continuous and skewed, etc. All of these (and logistic regression) are types of Generalized Linear Models that differ by the function used to go from the original scale of the data to the scale the model is being fit on. Interestingly enough, this is an avenue for modeling probabilities in alternative ways - you get different shaped s-curves if you use probit, Chauchit, Cloglog functions instead of logit, for example. Not super common but worth knowing about.\n\n>**The Gist:** Data compression. You have a dataset with 50 columns (features), but you only want the 2 or 3 that matter most. PCA combines variables to reduce complexity while keeping the important information.\n\nAlso worth noting that this is just one thing PCA is particularly useful for. What you're doing is making new variables that \"explain\" the variance of the data independently of one another (they're uncorrelated/orthogonal). The first one captures the most variability, the second one captures the most variance in the absence of the first, and so on and so forth. You end up with 50 new columns containing the same information as the original data, but past a certain point they're just capturing the leftovers.\n\nPCA doesn't necessarily reduce complexity (in terms of information) directly, it allows you to cut out as much of it as you can without sacrificing fidelity - past the first few components, the only thing being captured is smaller and smaller chunks of noise. Sort of like discarding pixels in a region of an image that appears purely black to the naked eye and probably only differs due to camera sensor noise - you could use interpolation to reconstruct most of them and nobody would be the wiser. Note: a fun idea to play with here is to actually use PCA for compression. You can start with a dataset that has a column for each color channel and a row for each pixel, and then see what happens if you start pooling information for nearby pixels. \n\nComplexity is also reduced in a practical sensed because correlated variables end up getting decomposed into variables that contain shared and unique information. If they're highly correlated, that unique information isn't contributing much and may end up getting discarded - you're effectively collapsing dimensions.",
          "score": 36,
          "created_utc": "2026-01-20 20:58:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rjdcy",
              "author": "Disastrous_Room_927",
              "text": "Follow up comment: I got side tracked by this comment and made an image compression script with PCA. The image on the left is 55% of the size of the one on the right: [https://imgur.com/a/mrjir5o](https://imgur.com/a/mrjir5o)",
              "score": 3,
              "created_utc": "2026-01-21 00:03:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0s3oqp",
              "author": "FancyEveryDay",
              "text": "PCA is useful for all sorts of things, lately I've been using it to do Total Least Squares regression, but I've also used it for Factor Analysis where you apply varimax or other rotations to group correlated variables together, and PCR which is ordinary linear regression performed using the Principal Components as variables.",
              "score": 1,
              "created_utc": "2026-01-21 01:57:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0sh4t7",
                  "author": "Disastrous_Room_927",
                  "text": "It's also useful for connecting the dots between concepts. What do you get when you you add a non-linear transformation in to the outputs of PCA in PCR? The exact functional form of a neural network with one hidden layer. It doesn't work like a neural net when you train it, but if you set yourself to the task of gluing together statistical models to make them work like one you end up learning a lot. like why backprop isn't magic but is super useful.",
                  "score": 2,
                  "created_utc": "2026-01-21 03:14:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qgwm1",
          "author": "Suspicious-Beyond547",
          "text": "You write just like my best friend Chad! What are the odds?!",
          "score": 49,
          "created_utc": "2026-01-20 20:51:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0re5kp",
              "author": "Nerdly_McNerd-a-Lot",
              "text": "Wait. Is this Chad??",
              "score": 6,
              "created_utc": "2026-01-20 23:35:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0uey6w",
                  "author": "sunil2000_babu",
                  "text": "Chat, who is Chad?",
                  "score": 1,
                  "created_utc": "2026-01-21 12:35:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0r9w24",
          "author": "EvilWrks",
          "text": "CNN and RNN would be good one to keep in mind.",
          "score": 4,
          "created_utc": "2026-01-20 23:12:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tujbu",
          "author": "NotMyRealName778",
          "text": "Ngl if I asked someone to explain linear regression and they answered with what you wrote as the gist I wouldn't hire them. Same goes for the other explanations.\n\nI think you need to read some textbooks. You understand something but this is way too surface level to be meaningful.",
          "score": 3,
          "created_utc": "2026-01-21 09:47:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tgyp5",
          "author": "swastik_K",
          "text": "Wait, you guys are still using SVM?",
          "score": 2,
          "created_utc": "2026-01-21 07:38:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sht6r",
          "author": "MathProfGeneva",
          "text": "Ugh sorry, but logistic regression is ABSOLUTELY a regression. It's one part of the general linear models family with a logit link function. In ML it is generally turned into a classifier by applying a threshold, but it's used a lot without that.",
          "score": 1,
          "created_utc": "2026-01-21 03:18:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0svk5z",
          "author": "aibyzee",
          "text": "Thankyou for sharing this! A valueable info.",
          "score": 1,
          "created_utc": "2026-01-21 04:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0uxmk0",
          "author": "heggiepau",
          "text": "Linear regression does not mean a straight line through the data, it requires that the model is linear in the parameters. y = x1 + x2^2 is a curve but linear in the parameters. On the other hand y = x1 + 2^x2 is not linear in the parameters",
          "score": 1,
          "created_utc": "2026-01-21 14:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0v0hn2",
          "author": "TMHDD_TMBHK",
          "text": "Thumbs up my Chad, reliable as always. Prompto!",
          "score": 1,
          "created_utc": "2026-01-21 14:37:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vbpng",
          "author": "KaleAnxious2863",
          "text": "Thanks for sharing",
          "score": 1,
          "created_utc": "2026-01-21 15:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wjlio",
          "author": "equqe",
          "text": "great summary",
          "score": 1,
          "created_utc": "2026-01-21 18:47:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0zeaga",
          "author": "BryanBeau27",
          "text": "Great, Thank you for sharing it. Appreciated.",
          "score": 1,
          "created_utc": "2026-01-22 03:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o101q7r",
          "author": "animalmad72",
          "text": "The analogies actually make sense instead of being overly technical. Saved for when I inevitably blank on explaining KNN in an interview.",
          "score": 1,
          "created_utc": "2026-01-22 06:05:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r0olb",
          "author": "Charming_Elk_9058",
          "text": "Great summary!",
          "score": 1,
          "created_utc": "2026-01-20 22:24:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0sdu5a",
          "author": "CorpusculantCortex",
          "text": "Particle swarm optimization",
          "score": 1,
          "created_utc": "2026-01-21 02:55:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk3nl3",
      "title": "I built a tiny language model (52M params) for English -> Spanish translation!",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/gd5kg5sy4yeg1",
      "author": "Right-Ad691",
      "created_utc": "2026-01-22 19:10:37",
      "score": 141,
      "num_comments": 6,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qk3nl3/i_built_a_tiny_language_model_52m_params_for/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o13v0dd",
          "author": "brojeriadude",
          "text": "The bottom two are wrong. Colocar means to place/put something somewhere and the last one is saying until the next train. But still super impressive.",
          "score": 24,
          "created_utc": "2026-01-22 19:55:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13yij6",
              "author": "Right-Ad691",
              "text": "Hi! Yea, I think there is still a lot to be improved upon. Color and colocar are quite close gramatically so I see why this error could've happened. For the second one, while I know the translation is wrong, I would interpret the phrase \"hasta el proximo tren\" as like, I'll catch you when the next train comes, or something along those lines, which is almost like a \"see you next time\" variation (although if judging this model by translation capabilities, then it's completely wrong)",
              "score": 8,
              "created_utc": "2026-01-22 20:12:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o14bnbn",
          "author": "Key_Internal5305",
          "text": "Good job man!",
          "score": 5,
          "created_utc": "2026-01-22 21:13:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17svx0",
              "author": "Right-Ad691",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-01-23 10:43:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ekoq3",
          "author": "Jumbledsaturn52",
          "text": "Nice ,I am  just starting llms , are you using transformer?",
          "score": 1,
          "created_utc": "2026-01-24 10:26:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1g030f",
              "author": "Right-Ad691",
              "text": "Yes! This is the most simple form of a Transformer (encoder-decoder) that reflects the original architecture proposed by Google in 2017",
              "score": 1,
              "created_utc": "2026-01-24 16:00:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjgqcw",
      "title": "Building an ML runtime from scratch, Day 1 - visualizing tensors in memory",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/u2bceocvyseg1.jpeg",
      "author": "RefrigeratorFirm7646",
      "created_utc": "2026-01-22 01:23:35",
      "score": 117,
      "num_comments": 11,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qjgqcw/building_an_ml_runtime_from_scratch_day_1/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0znrvo",
          "author": "-CawmunGames",
          "text": "This is so good, there are literally no articles on this, at least none that i could find.\n\n\nYou did a really good job here.\n\n\nKeep it up! Looking forward to day 2.\n\n\nBtw, just out of curiosity, how old are you?",
          "score": 11,
          "created_utc": "2026-01-22 04:25:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zooc3",
              "author": "RefrigeratorFirm7646",
              "text": "Thanks! I really appreciate that. Im 17 and honestly i only made this post because i had the same issue as you, lack of resources on niche topics like these...",
              "score": 6,
              "created_utc": "2026-01-22 04:31:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o117enj",
                  "author": "frivoflava29",
                  "text": "Let me know if you'd like help with infographics, writing, etc! I'd love to work on a collaborative tutorial like this with you on my website sometime. Something like this would be perfect.",
                  "score": 3,
                  "created_utc": "2026-01-22 12:09:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o114qqb",
                  "author": "Moist-Matter5777",
                  "text": "Dude, that's super impressive for 17! It's great that you're tackling these complex topics early on. Keep pushing through, and donâ€™t hesitate to share your findings; itâ€™ll help a lot of others!",
                  "score": 2,
                  "created_utc": "2026-01-22 11:49:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o104qzy",
          "author": "JohnYellow333",
          "text": "what a coinsidance, I ahve decided same, now I am making an ai snake game, I finished game yet but I am planning to develop a brain too",
          "score": 1,
          "created_utc": "2026-01-22 06:29:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o106e09",
              "author": "RefrigeratorFirm7646",
              "text": "By 'developing a brain', do you mean you're working on a Reinforcement Learning agent or a specific Neural Network architecture? Working on projects you actually enjoy is the best way to learn complex topics like these",
              "score": 2,
              "created_utc": "2026-01-22 06:43:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o108lyw",
                  "author": "JohnYellow333",
                  "text": "Yes I am working on reinforcement learning, dqn, I found a lot sources, which confuses me, because hard to focus one of them, also I decreased my gemini usage, because I see that when I finished the tasks with ai, yes it works but I dont learn",
                  "score": 1,
                  "created_utc": "2026-01-22 07:02:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qgvit5",
      "title": "(End to End) 20 Machine Learning Project in Apache Spark",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qgvit5/end_to_end_20_machine_learning_project_in_apache/",
      "author": "bigdataengineer4life",
      "created_utc": "2026-01-19 05:27:56",
      "score": 114,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "Hi Guys,\n\nI hope you are well.\n\nFree tutorial on Machine Learning Projects (End to End) in **Apache Spark and Scala with Code and Explanation**\n\n1. [Life Expectancy Prediction using Machine Learning](https://projectsbasedlearning.com/apache-spark-machine-learning/life-expectancy-prediction-using-machine-learning/)\n2. [Predicting Possible Loan Default Using Machine Learning](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-possible-loan-default-using-machine-learning/)\n3. [Machine Learning Project - Loan Approval Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-loan-approval-prediction/)\n4. [Customer Segmentation using Machine Learning in Apache Spark](https://projectsbasedlearning.com/apache-spark-machine-learning/customer-segmentation-using-machine-learning-in-apache-spark/)\n5. [Machine Learning Project - Build Movies Recommendation Engine using Apache Spark](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-creating-movies-recommendation-engine-using-apache-spark/)\n6. [Machine Learning Project on Sales Prediction or Sale Forecast](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-on-sales-prediction-or-sale-forecast/)\n7. [Machine Learning Project on Mushroom Classification whether it's edible or poisonous](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-on-mushroom-classification-whether-its-edible-or-poisonous-part-1/)\n8. [Machine Learning Pipeline Application on Power Plant.](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-pipeline-application-on-power-plant/)\n9. [Machine Learning Project â€“ Predict Forest Cover](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-predict-forest-cover-part-1/)\n10. [Machine Learning Project Predict Will it Rain Tomorrow in Australia](https://projectsbasedlearning.com/apache-spark-machine-learning/machine-learning-project-predict-will-it-rain-tomorrow-in-australia/)\n11. [Predict Ads Click - Practice Data Analysis and Logistic Regression Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/predict-ads-click-practice-data-analysis-and-logistic-regression-prediction/)\n12. [Machine Learning Project -Drug Classification](https://projectsbasedlearning.com/apache-spark-machine-learning/drug-classification/)\n13. [Prediction task is to determine whether a person makes over 50K a year](https://projectsbasedlearning.com/apache-spark-machine-learning/prediction-task-is-to-determine-whether-a-person-makes-over-50k-a-year/)\n14. [Machine Learning Project - Classifying gender based on personal preferences](https://projectsbasedlearning.com/apache-spark-machine-learning/classifying-gender-based-on-personal-preferences/)\n15. [Machine Learning Project - Mobile Price Classification](https://projectsbasedlearning.com/apache-spark-machine-learning/mobile-price-classification/)\n16. [Machine Learning Project - Predicting the Cellular Localization Sites of Proteins in Yest](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-the-cellular-localization-sites-of-proteins-in-yest/)\n17. [Machine Learning Project - YouTube Spam Comment Prediction](https://projectsbasedlearning.com/apache-spark-machine-learning/youtube-spam-comment-prediction/)\n18. [Identify the Type of animal (7 Types) based on the available attributes](https://projectsbasedlearning.com/apache-spark-machine-learning/identify-the-type-of-animal-7-types-based-on-the-available-attributes/)\n19. [Machine Learning Project - Glass Identification](https://projectsbasedlearning.com/apache-spark-machine-learning/glass-identification/)\n20. [Predicting the age of abalone from physical measurements](https://projectsbasedlearning.com/apache-spark-machine-learning/predicting-the-age-of-abalone-from-physical-measurements-part-1/)\n\nI hope you'll enjoy these tutorials.",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qgvit5/end_to_end_20_machine_learning_project_in_apache/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o0gpeaf",
          "author": "RohanVipin",
          "text": "The code is in scala , I only know python",
          "score": 6,
          "created_utc": "2026-01-19 12:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hs8of",
              "author": "anal_pudding",
              "text": "Sounds like a personal problem.",
              "score": 3,
              "created_utc": "2026-01-19 15:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0kkzkf",
                  "author": "pm_me_your_smth",
                  "text": "Not so personal since scala is very rarely used anywhere and vast majority of ML learners are using python",
                  "score": 3,
                  "created_utc": "2026-01-19 23:44:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0l3x1k",
          "author": "Effective_Forever585",
          "text": "Thanks very much",
          "score": 1,
          "created_utc": "2026-01-20 01:26:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fi22w",
          "author": "Pretend-Pangolin-846",
          "text": "Thanks, will take a look later!",
          "score": 1,
          "created_utc": "2026-01-19 05:49:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fqed4",
          "author": "fnehfnehOP",
          "text": "Spark",
          "score": 1,
          "created_utc": "2026-01-19 06:57:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h3ft5",
          "author": "padakpatek",
          "text": "saved",
          "score": 1,
          "created_utc": "2026-01-19 13:45:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhs23q",
      "title": "Curated list of actually free AI courses (no hidden paywalls) - with time commitment for eac",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qhs23q/curated_list_of_actually_free_ai_courses_no/",
      "author": "Bubbly_Ad_2071",
      "created_utc": "2026-01-20 05:07:31",
      "score": 103,
      "num_comments": 10,
      "upvote_ratio": 0.98,
      "text": "I got tired of \"free\" courses that lock certificates or key content behind paywalls. So I went through the major platforms and put together a list of courses that are genuinely free toÂ complete:Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ  1. Elements of AI at Univ. Helsinki - 6 hrs  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ  2. OpenAI Academy at OpenAI - 5 hrs  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ 3. Prompt Engineering at [DeepLearning.AI](http://DeepLearning.AI) \\- 5 hrs  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ 4. Salesforce AI at Trailhead - 5 hrs Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ  5. Google AI Essentials at Coursera - 10 hrs; Audit free, cert $49 Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ  6. Microsoft AI Fundamentals at MS Learn - 8 hrs; Content free, exam $165Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â \n\nÂ  Full breakdown with what each covers:  [ https://boredom-at-work.com/best-free-ai-courses/ ](https://boredom-at-work.com/best-free-ai-courses/)\n\nÂ  What other free resources would you add? Always looking to expand the list.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qhs23q/curated_list_of_actually_free_ai_courses_no/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o0nf87h",
          "author": "diegoasecas",
          "text": "all of huggingface courses are free\n\nhttps://huggingface.co/learn",
          "score": 10,
          "created_utc": "2026-01-20 11:36:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m9lni",
          "author": "Holiday_Lie_9435",
          "text": "This is a great list, thank you for putting it together! I would add the [fast.ai](http://fast.ai) courses (Practical Deep Learning for Coders) for something more hands-on and teaches practical skills. The structure is more top-down, and personally found it helpful for getting started on some beginner-friendly [AI/ML projects](https://www.interviewquery.com/p/ai-project-ideas).",
          "score": 9,
          "created_utc": "2026-01-20 05:31:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p9bf7",
              "author": "famous_chalupa",
              "text": "Is the Practical Deep Learning for Coders still relevant material? It seems like it, but that course has been around for a while.\n\nI'm planning on starting it this week.",
              "score": 1,
              "created_utc": "2026-01-20 17:32:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mep1f",
          "author": "JasperTesla",
          "text": "Thanks! This is gold!",
          "score": 4,
          "created_utc": "2026-01-20 06:10:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mmfks",
          "author": "Jesus_is_King_agreed",
          "text": "Good",
          "score": 3,
          "created_utc": "2026-01-20 07:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mu93a",
          "author": "equqe",
          "text": "thank you a lot!",
          "score": 2,
          "created_utc": "2026-01-20 08:25:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mv9hl",
          "author": "Sharp_Level3382",
          "text": "Thanks!",
          "score": 2,
          "created_utc": "2026-01-20 08:34:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0py939",
          "author": "Thin-Chart4124",
          "text": "This is helpful, thank u!",
          "score": 2,
          "created_utc": "2026-01-20 19:25:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qzstr",
          "author": "Charming_Elk_9058",
          "text": "Thank you! I've been looking for something like this.",
          "score": 2,
          "created_utc": "2026-01-20 22:19:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rswo2",
          "author": "dv11JUN",
          "text": "I really appreciate it !",
          "score": 2,
          "created_utc": "2026-01-21 00:55:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qixrtx",
      "title": "If you had to learn AI/LLMs from scratch again, what would you focus on first?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qixrtx/if_you_had_to_learn_aillms_from_scratch_again/",
      "author": "EngineerLoose5042",
      "created_utc": "2026-01-21 13:23:34",
      "score": 97,
      "num_comments": 38,
      "upvote_ratio": 0.98,
      "text": "Iâ€™m a web developer with about two years of experience. I recently quit my job and decided to spend the next 15 months seriously upskilling to land an AI/LLM role â€” focused on building real products, not academic research.  \nIf you already have experience in this field, Iâ€™d really appreciate your advice on what I should start learning first. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qixrtx/if_you_had_to_learn_aillms_from_scratch_again/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o0uq03x",
          "author": "frivoflava29",
          "text": "Probabilities and statistics. I also wouldn't get into AI. You will find most people here are into machine learning (which has been studied for many decades) and not so much the current trend with transformers.",
          "score": 69,
          "created_utc": "2026-01-21 13:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0uy85r",
              "author": "3n91n33r",
              "text": "Any recommended resources on those?",
              "score": 6,
              "created_utc": "2026-01-21 14:26:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0v2rcv",
                  "author": "frivoflava29",
                  "text": "Geron's PyTorch book",
                  "score": 23,
                  "created_utc": "2026-01-21 14:49:14",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0v4wjh",
                  "author": "Annual-Beginning-352",
                  "text": "I'm a maths and stats student in Uni, our intro to machine learning started with simple linear regression before moving onto more complicated regression techniques like logarithmic. We also worked a bit with classification techniques like decision trees and random forests. Be warned regression is very limited when compared to the type of operations neural nets can do since, in regression you have to specify all the relationships between variables. But I think it can be a good jumping off point if you want to see what it means for a computer to come up with its own weights that relate the training data to the variable of interest.",
                  "score": 13,
                  "created_utc": "2026-01-21 14:59:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o13g772",
              "author": "numice",
              "text": "I've learned mostly on the math and a bit of statistics and algorithms side, never done a real project except of couple of tutorials. But the thing is that from what I can observe nowdays it's all about transformers. Is that true?",
              "score": 1,
              "created_utc": "2026-01-22 18:49:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1477di",
                  "author": "frivoflava29",
                  "text": "For LLMs but not ML as a whole",
                  "score": 1,
                  "created_utc": "2026-01-22 20:52:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0vijcw",
          "author": "Vedranation",
          "text": "I graduated as Robotics engineer so I had some AI background, but it didn't really prepare me for how diverse it's in production compared to uni coursework. \n\nHonestly unpopular opinion but I'd have spent more time figuring out exactly why things do what they do and how. Like instead of jist writing Conv2D figuring out what a filter or kernel is, how they actually work, math behind SDG etc. I found myself in a lot of soft pits struggling with improving model performance because I didn't know stuff like that, like what BatchNorm actually does instead of automatically applying it after Conv2D because that's how I was taught. \n\nOh also Seq2Seq and RAG. Nobody told me I'd be doing so much RAG.",
          "score": 20,
          "created_utc": "2026-01-21 16:02:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vo0dt",
          "author": "thinking_byte",
          "text": "I would start by building end to end things before going deep on theory. Get comfortable with data in, model out, and something users actually touch. A lot of people over index on model internals early and never learn where things break in practice. Focus on prompting, retrieval, evals, and failure modes first because that is where real products live right now. You can always go deeper on training and architecture later once you know why you need it. The fastest signal for roles is showing you can ship something imperfect and iterate.",
          "score": 9,
          "created_utc": "2026-01-21 16:27:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zurrp",
              "author": "EngineerLoose5042",
              "text": "This really resonates â€” it matches exactly the mindset Iâ€™m trying to follow (ship end-to-end, learn where things break, iterate). Iâ€™m starting my first 100 days focusing on just three basics: English, Python, and â€œjust enoughâ€ math for ML. After that, do you think I should jump straight into building products, or is there anything else youâ€™d prioritize before going all-in on shipping? Would love your thoughts.",
              "score": 2,
              "created_utc": "2026-01-22 05:12:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o15bztp",
                  "author": "thinking_byte",
                  "text": "That plan already sounds solid. I would not wait for some imaginary â€œreadyâ€ point before building. Shipping is what exposes the gaps anyway.\n\nIf I had to add one thing before going all in, it would be getting comfortable with evaluation and debugging early. Not math heavy stuff, but how you tell if an LLM feature is actually working, where it fails, and why users get confused. Most people skip that and just eyeball outputs.\n\nOtherwise I would build immediately, even if the first versions are ugly. Pick boring, real problems, wire the whole loop, then improve one piece at a time. The learning compounds way faster once real users or real constraints are involved.",
                  "score": 2,
                  "created_utc": "2026-01-23 00:20:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0xgwvt",
          "author": "drrednirgskizif",
          "text": "Thereâ€™s no need anymore. Itâ€™s so commoditized you either need to go get a PhD and work for one of the big model builders, or just learn more software engineering.",
          "score": 6,
          "created_utc": "2026-01-21 21:17:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zvazl",
              "author": "EngineerLoose5042",
              "text": "thank you !",
              "score": 1,
              "created_utc": "2026-01-22 05:16:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0yz8sm",
          "author": "Ok_Stranger8980",
          "text": "Probability, linear algebra..",
          "score": 5,
          "created_utc": "2026-01-22 02:00:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zuu2m",
              "author": "EngineerLoose5042",
              "text": "This is really helpful, thanks!",
              "score": 1,
              "created_utc": "2026-01-22 05:13:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uqvob",
          "author": "QuiteMischief",
          "text": "Start with Transformers, then gradually move into Generative AI. Once you have that foundation, deep dive into RAG, how LLMs work, LLM fine-tuning, and agentic systems, and then explore the latest frameworks like A2A and MCP.\n\nThe key is to start from one end - once you begin, youâ€™ll naturally understand what you need to learn next. What matters most is starting now.",
          "score": 8,
          "created_utc": "2026-01-21 13:47:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0v9ecu",
              "author": "Imaginary_Tower_5518",
              "text": "Do you have any recommendations for books or content?",
              "score": 1,
              "created_utc": "2026-01-21 15:21:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0veqr6",
                  "author": "QuiteMischief",
                  "text": "Give this a read -AI Engineering by Chip Huyen",
                  "score": 3,
                  "created_utc": "2026-01-21 15:45:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0y4i4y",
                  "author": "rlNewbie",
                  "text": "This article from x has some good steps to follow https://x.com/i/status/2013608521900683765",
                  "score": 3,
                  "created_utc": "2026-01-21 23:11:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0vbau9",
              "author": "unknowntrail20",
              "text": "Hey l need your help check your DMs",
              "score": -1,
              "created_utc": "2026-01-21 15:30:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0y3er8",
          "author": "PeeVee_",
          "text": "Great question. If I had to start again, Iâ€™d focus much earlier on grounding understanding in a single source instead of hopping between explanations.\n\nOne thing I keep running into is that long-form content like lectures or podcasts is dense but hard to retrieve from later. Anyone know how would they would approach retaining and querying that kind of material?",
          "score": 3,
          "created_utc": "2026-01-21 23:05:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zwdni",
              "author": "EngineerLoose5042",
              "text": "This is a great point â€” I definitely struggle with hopping between sources too",
              "score": 1,
              "created_utc": "2026-01-22 05:24:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w7pyt",
          "author": "Similar-Kangaroo-223",
          "text": "I am not from a technical background, but I also started to build and ship products since last year. Personally, I think using trying out different tools like Cursor, Claude Code, Kiro, and Antigravity while building a product is definitely very helpful.\n\nI think the hard part might be verification, which is that I know I am definitely learning after shipping the first product, but after shipping 3 different products, I can't really know if I am still learning new things or I am just repeating things over and over again.",
          "score": 2,
          "created_utc": "2026-01-21 17:55:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yyx37",
          "author": "Disastrous_Room_927",
          "text": ">focused on building real products, not academic research.\n\nI studied statistics and ML in grad school, and one thing people got tripped up on was the difference between applied and theoretical. They had the impression that \"applied statistics\" was more about applying statistics to things, but the program was 90% derivations and proofs. The distinction is in what kind of theory is used and how: you need statistical theory to learn how the things people use work, which requires a fair bit of math. If you want to do academic research, this shifts to learning how the theory itself works.  \n\nAll of that is to say that if you want to get serious about building things with ML, approach it like engineering. Engineers need to take physics because their work depends on understanding it, but they don't need to understand it at the level of a physicist. For ML that might like being able to reason quantitatively about the tools you're using - you don't need to study the theory of optimization super deeply, but you should have an understanding of optimization as it pertains to what you're working with.",
          "score": 2,
          "created_utc": "2026-01-22 01:58:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0zwh40",
              "author": "EngineerLoose5042",
              "text": "I really like this framing â€” treating ML as engineering rather than pure theory makes a lot of sense to me.",
              "score": 1,
              "created_utc": "2026-01-22 05:25:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o109viy",
          "author": "AccordingWeight6019",
          "text": "I would start by getting very clear on what problem you want models to solve in a system, not which models to learn. A lot of people jump straight into LLM tooling and miss fundamentals like data quality, evaluation, and failure modes, which end up dominating real products. If your goal is shipping, spend time understanding how models degrade, how you detect that, and how you iterate safely. LLMs make demos easy, but production work is mostly about constraints and trade-offs. the fastest progress usually comes from building small end-to-end things and being honest about where they break, and that intuition transfers better than chasing the latest architecture.",
          "score": 2,
          "created_utc": "2026-01-22 07:13:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12oj10",
              "author": "EngineerLoose5042",
              "text": "This honestly feels like an enlightenment moment for me â€” thank you so much for sharing this.",
              "score": 2,
              "created_utc": "2026-01-22 16:45:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o18gqey",
                  "author": "AccordingWeight6019",
                  "text": "Glad it resonates. One follow up that helped me early on was deliberately choosing small, constrained projects where failure is visible quickly. That way, you get feedback loops on data issues, evaluation gaps, and even system limitations without investing months in something that ultimately doesnâ€™t teach you much. Over time, those lessons accumulate faster than reading papers or tutorials alone.",
                  "score": 2,
                  "created_utc": "2026-01-23 13:31:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o11jnk9",
          "author": "DataCamp",
          "text": "What we've seen work best for learners is building small projects early and learning things as you actually need them in the projects. Pick a simple end-to-end thing (data in â†’ model/LLM â†’ output you can test), get it working, and let the breakpoints tell you what to learn next. Tutorials are most useful as reference when youâ€™re stuck, not something to binge. Ship small, fix what breaks, repeat!",
          "score": 2,
          "created_utc": "2026-01-22 13:26:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12okpn",
              "author": "EngineerLoose5042",
              "text": "This genuinely feels like a lightbulb moment. Thanks a ton for this.",
              "score": 2,
              "created_utc": "2026-01-22 16:45:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhuy6z",
      "title": "The Space Warper (Matrices)",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/i1hbr85llgeg1",
      "author": "No_Skill_8393",
      "created_utc": "2026-01-20 07:48:11",
      "score": 78,
      "num_comments": 10,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qhuy6z/the_space_warper_matrices/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ng5qz",
          "author": "Habsu",
          "text": "Oh no, is AI.",
          "score": 3,
          "created_utc": "2026-01-20 11:43:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nfy19",
          "author": "Habsu",
          "text": "Who's this guy? I like this.",
          "score": 1,
          "created_utc": "2026-01-20 11:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0py1mm",
          "author": "notionocean",
          "text": "Would be nice if this explained how it actually works mathematically.",
          "score": 1,
          "created_utc": "2026-01-20 19:24:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tdn0s",
              "author": "Reclaimer2401",
              "text": "Honestly, you don't want that. Its best to explain what the numbers really are before you start manipulating the matrixs.Â \n\n\nThere's a lot of stuff in linear algebra, and it was a pain for me until i actually understand wtf I was doing and why.Â \n\n\nThis video sucks thoughÂ ",
              "score": 1,
              "created_utc": "2026-01-21 07:08:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ulqtu",
                  "author": "notionocean",
                  "text": "I'm in Calc 3. It's disappointing how the video just handwaves the numbers like 'See these numbers? Look what it does!' with no indication of how it actually works mathematically.",
                  "score": 1,
                  "created_utc": "2026-01-21 13:18:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0q5y5w",
          "author": "Door_Number_Three",
          "text": "Ah yes, the hello world of math for ML. How many people crash and burn when learning linear transformations.",
          "score": 1,
          "created_utc": "2026-01-20 20:01:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tdrsr",
              "author": "Reclaimer2401",
              "text": "I did at first.Â \n\n\nI just kept at it until it all clicked. It was slow and painful, but then I ended up with an A in the class and for fun used linear algebra to calculate the volume of a tesseract",
              "score": 1,
              "created_utc": "2026-01-21 07:09:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ncix0",
          "author": "bingbestsearchengine",
          "text": "I love his voice",
          "score": 0,
          "created_utc": "2026-01-20 11:14:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ne7g4",
              "author": "Archtarius",
              "text": "NotebookLM",
              "score": 1,
              "created_utc": "2026-01-20 11:28:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjozwj",
      "title": "how do you move past toy machine learning projects?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qjozwj/how_do_you_move_past_toy_machine_learning_projects/",
      "author": "TeedyDelyon",
      "created_utc": "2026-01-22 08:18:59",
      "score": 74,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "i am comfortable with sklearn, basic neural nets, and common workflows, but everything i build feels like a demo. how do you start working on projects that feel closer to real use cases? what changed for you when you hit that point?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qjozwj/how_do_you_move_past_toy_machine_learning_projects/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o10iz00",
          "author": "burntoutdev8291",
          "text": "Use real life unclean data, usually your local government should publish some stats.",
          "score": 41,
          "created_utc": "2026-01-22 08:35:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10jgh7",
          "author": "RefrigeratorFirm7646",
          "text": "In real world ML, you dont always have clean kaggle datasets... try writing a data scraper, then write an algorithm to clean up the \"edge case\" data.\n\nNext, try to optimize your models, then optimize them again, and again, until you are milking for milliseconds of performance. This will teach you a lot about the underlying logic of the frameworks you might be using.\n\nKeep pushing the boundaries of your knowledge with every new project that you start, you cannot just \"skip\" making toy projects, you have to actively \"outgrow\" them.\n\nI hope my advice helps...",
          "score": 28,
          "created_utc": "2026-01-22 08:40:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10phnk",
          "author": "Aidalon",
          "text": "1. Sometimes you donâ€™t have the capacity to evaluate performance. The domain knowledge is so complex that it requires experts you donâ€™t have to label data or define targets. So the capacity to assess becomes very hard. \n\n2. Explainability, if some fields you cannot use a model unless you can audit it. Why did it choose this and not that. \n\n3. Metric biases and data bias. This is a big one. \n\n4. Data centric ai. \n\n5. Active learning approach\n\n- Also quick question, when you want to solve a problem, what do you chose first, the metric or the models and why ?\n\nIf your answer is the model, you still have to learn the processus of solving problems.\n\n- What is train, test validation ? \n\n- At which step do you split dataset into train test validation?\n\n- do you know why some models will require normalization, which will not require it?\n\n- how do you handle feature reduction, correlations in the data?\n\n- do you know which models does classification which does regression? (Many does both) SVM for example can be used for regression, same for decision tree. \n\n- Between two classification model, do you understand how the boundary are made ? What the actual difference between logistic regression and SVM classification in the boundary decision ?\n\nThere are other questions. \n\nWhen presented with a problem, you have many options to choose from. What defines a good project is how you will answer many aspects of how you treat data, what metrics you chose, which models to try for. And then there is the actual use of those models in real cases. Will you experience model drift ? Etc. \n\nToy project a very simple in nature because they do not adresse many of those questions.",
          "score": 9,
          "created_utc": "2026-01-22 09:37:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12jtv6",
              "author": "luffygrows",
              "text": "Why is choosing the model first before the metric a bad thing? What if i wanna test specific models in specific scenarios? Imo it doesnt matter when u do what. I think lots of people dont define their metric correctly or assume perfect dataset and not long running processes, edge cases and all that. Or i misunderstood what u meant with that specific point",
              "score": 0,
              "created_utc": "2026-01-22 16:24:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o12wg3y",
                  "author": "Aidalon",
                  "text": "The metric encodes business or domain constraints (false positives vs false negatives, imbalance, risk, relative error).\n\nModel choice, loss function, thresholds, and tuning all depend on the metric.",
                  "score": 1,
                  "created_utc": "2026-01-22 17:21:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10vq0q",
          "author": "Holiday_Lie_9435",
          "text": "A big shift for me was focusing on industry-specific problems. Instead of just using standard datasets, I started looking at real-world data related to specific fields (like finance, healthcare, or manufacturing). This immediately makes the projects feel more relevant, and datasets are easy to find too! For example, this list of [AI/ML project ideas](https://www.interviewquery.com/p/ai-project-ideas) from Interview Query can help you get started. It categorizes projects not only by skills but also by domain, like doing a disease prediction model for healthcare or a trading bot for finance. Most projects also has the datasets linked, but you can also find them on government websites.",
          "score": 3,
          "created_utc": "2026-01-22 10:35:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11l9sy",
          "author": "DataCamp",
          "text": "Typically this shift kind of jumps you when the problem starts to matter more than the model.\n\nToy projects usually stop at â€œtrain a model and report accuracy.â€ Real-feeling projects force you to deal with messy data, unclear targets, and uncomfortable questions like what happens when this is wrong or who pays for the mistakes. You end up spending more time on evaluation, edge cases, and iteration than on model selection.\n\nA good signal youâ€™re moving past demos is when youâ€™re thinking about things like thresholds, failure modes, drift, and how youâ€™d explain results to someone who isnâ€™t technical.",
          "score": 3,
          "created_utc": "2026-01-22 13:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1366pc",
          "author": "Soccerrocks8",
          "text": "To move past toy projects, try tackling real-world problems where messy data is the norm; the chaos will teach you more than any pristine dataset ever could.",
          "score": 3,
          "created_utc": "2026-01-22 18:05:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10rn55",
          "author": "mandevillelove",
          "text": "Start small with real world data problems or collaborations, making an impact changes it from toy to actual use.",
          "score": 2,
          "created_utc": "2026-01-22 09:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10wt1j",
          "author": "divided_capture_bro",
          "text": "Try building a tool you can actually use.",
          "score": 2,
          "created_utc": "2026-01-22 10:44:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16c7tt",
          "author": "BackpackingSurfer",
          "text": "Whatâ€™s your industry? Solve a problem in your industry. At least try. Full pipeline from cleaning to eval. Really search for the idea. When you have a fire idea, itâ€™s so much easier to go all in on a project and learn a lot while doing it.",
          "score": 2,
          "created_utc": "2026-01-23 03:42:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13ahzv",
          "author": "Long_Foundation435",
          "text": "The shift happens when you stop optimizing for **models** and start optimizing for **constraints**.\n\nReal projects force you to deal with messy data, unclear objectives, trade-offs, deployment, monitoring, and failure cases. What changed for me was picking a **real problem with a real user**, even if that user was just me or a small team and then living with the system over time.\n\nToy projects end when accuracy looks good.  \nReal projects begin when accuracy isnâ€™t enough.",
          "score": 1,
          "created_utc": "2026-01-22 18:24:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkzhxc",
      "title": "Salary Gap between \"Model Training\" and \"Production MLE\"",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qkzhxc/salary_gap_between_model_training_and_production/",
      "author": "IT_Certguru",
      "created_utc": "2026-01-23 18:56:11",
      "score": 65,
      "num_comments": 11,
      "upvote_ratio": 0.86,
      "text": "Hey everyone,\n\nIâ€™ve been tracking the market for a while, and the salary data on this sub usually swings between \"I can't find a job\" and \"Influencers say I should make $300k starting.\"\n\nI wanted to open a discussion on the real salary tiers right now, because it feels like the market has split into two completely different realities. From what Iâ€™m seeing in job descriptions vs. actual offers, here is the breakdown.\n\nIâ€™d love for the Seniors here to weigh in and correct me if this matches your experience.\n\nTier 1: The \"Jupyter Notebook\" Engineer\n\n* Role: You can train models, clean data, and use Scikit-Learn/PyTorch in a notebook environment.\n* Reality: This market is oversaturated.\n\nTier 2: The \"Production\" MLE (Where the money is)\n\n* Role: You don't just train models; you serve them. You know Docker, Kubernetes, CI/CD, and how to optimize inference latency.\n* The Jump: The salary often jumps 40-50% here. The gap isn't about better math; itâ€™s about Software Engineering.\n\nTier 3: The \"Specialized\" Engineer\n\n* Role: Custom CUDA kernels, distributed training systems, or novel LLM architecture.\n* Comp: Outlier salaries.\n\nThe Question for the Community: For those of you who broke past the $150k mark: What was the specific technical skill that got you the raise? Was it System Design? MLOps? Or just YOE?\n\nWhile researching benchmarks, I found this breakdown on [**machine learning engineer salary**](https://www.netcomlearning.com/blog/machine-learning-engineer-salary) trends helpful to get a baseline, but the discussion on this sub often tells a different story.\n\nLet's get a realistic thread going. Comment your Role, YOE, and Stack below.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qkzhxc/salary_gap_between_model_training_and_production/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o1b79ci",
          "author": "dokabo",
          "text": "These 3 buckets don't really exist as tiers. You'll find that that within each bucket, there are multiple levels of complexity, each with their own compensation tiers. For example at Meta, GPU engineers, infra engineers, and modeling scientists of the same levels will all get roughly the same pay, with the exception of some scientists with phds getting high pay. The same is true at most other large tech companies.",
          "score": 35,
          "created_utc": "2026-01-23 21:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cy98y",
          "author": "shockdrop15",
          "text": "This reads almost exactly like a genAI LinkedIn post hahaha",
          "score": 12,
          "created_utc": "2026-01-24 02:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1by344",
          "author": "Mehdi2277",
          "text": "I think the main factors is mostly company/level. There are engineers that do work closer to 1 at my company and others closer to 2. 3 is rather rare where I work although some exist. Pay is not particularly different across the 3 within my company. They often overlap a lot in titles too.\n\nIf you want money then the answer is aim for top paying companies and work up career ladder. Job hopping is fine early on, itâ€™s hard to make staff+ by job hopping and for that you tend to need to get promoted.\n\nMy current place pays seniors (5+ years experience) in ml around 500-600ish before bonus. Bonus are very variable with many getting little and some getting another 200k. Staff/senior staff/principal exist too as levels and I think staff is 800k roughly while senior staff is low million (unsure principal is, thatâ€™s quite rare).\n\nTop places are basically few ai startups, openai, finance. Those can pay close to a million for senior level. Unsure where openai sits for people that join today but a couple years ago I had a friend join as a senior for ~1.5 million comp there.",
          "score": 5,
          "created_utc": "2026-01-23 23:26:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1be5bn",
          "author": "BellyDancerUrgot",
          "text": "Foundational and narrow specialized Research + engineering ; my first job was 180k base , Toronto",
          "score": 7,
          "created_utc": "2026-01-23 21:46:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c0rtj",
          "author": "Sebastiao_Rodrigues",
          "text": "I dunno, why don't you ask the AI that wrote this and let us know what it thinks?",
          "score": 5,
          "created_utc": "2026-01-23 23:40:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bmi8b",
          "author": "RepresentativeBee600",
          "text": "Isn't there \"levels.fyi\" for this? I do realize it might be hard to disentangle who really has what job based on title.",
          "score": 3,
          "created_utc": "2026-01-23 22:26:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bnp77",
          "author": "Palmquistador",
          "text": "I appreciate this post, OP, and I hope we both get some valuable data from this.",
          "score": 1,
          "created_utc": "2026-01-23 22:32:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1d2pxv",
          "author": "dayeye2006",
          "text": "At my company ML engineers just do config change (to get a different model or data) and its easy to get promoted very fast as long as you get solid AB test win signals and make 500k+",
          "score": 1,
          "created_utc": "2026-01-24 03:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dib0n",
          "author": "dash_bro",
          "text": "A lot of it is very employer focused, honestly. I've had the same job where I was making 100k then moved employers to go 250k. Really depends.\n\nThen again it's also because of the YoE and shipping software. Definitely not straight out of college.",
          "score": 1,
          "created_utc": "2026-01-24 04:57:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e3l4t",
          "author": "MutedComputer7494",
          "text": "Senior folks reading my comment, I have a question.\n\nIs knowing how to ship at scale and able to reduce latency (more SWE, speed and reliability) more valuable skill financially than being able to code in cuda (or low level) or know distributed llm training and stuff?\n\nWhich of two skills is more transferrable, non-transient and widely applicable?",
          "score": 1,
          "created_utc": "2026-01-24 07:49:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c66om",
          "author": "PeeVee_",
          "text": "This gap makes sense to me. Training models is intellectually flashy, but production work carries long-term responsibility and risk.\n\nFrom what Iâ€™ve seen, the salary difference often reflects ownership over failure modes and system reliability, not just model quality. Curiousâ€”do you think this gap will shrink as tooling around deployment matures, or widen as systems get more complex?",
          "score": 1,
          "created_utc": "2026-01-24 00:10:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjc5xm",
      "title": "Information theory fundamentals for Machine Learning",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/96e7jgwr1seg1",
      "author": "Big-Stick4446",
      "created_utc": "2026-01-21 22:16:56",
      "score": 57,
      "num_comments": 3,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qjc5xm/information_theory_fundamentals_for_machine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0zoeva",
          "author": "whiteorb",
          "text": "Pretty rad",
          "score": 2,
          "created_utc": "2026-01-22 04:29:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o113zd0",
          "author": "Grumlyly",
          "text": "Very cool! Can we play online with it? Do you a link please?",
          "score": 2,
          "created_utc": "2026-01-22 11:44:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11y15e",
              "author": "Big-Stick4446",
              "text": "[Tensortonic](https://tensortonic.com)",
              "score": 2,
              "created_utc": "2026-01-22 14:42:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qklxks",
      "title": "Following up on my last post, hereâ€™s the squat part of the app",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/48e8n1rmd2fg1",
      "author": "Few_Homework_8322",
      "created_utc": "2026-01-23 09:01:14",
      "score": 53,
      "num_comments": 1,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qklxks/following_up_on_my_last_post_heres_the_squat_part/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1daven",
          "author": "drinkyourdinner",
          "text": "Now do a squat like a drunk dizzy person. Show me how it adapts.",
          "score": 2,
          "created_utc": "2026-01-24 04:07:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhfh2a",
      "title": "Learning ML is clear but applying it to real problems feels overwhelming",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qhfh2a/learning_ml_is_clear_but_applying_it_to_real/",
      "author": "Waltace-berry59004",
      "created_utc": "2026-01-19 20:19:51",
      "score": 51,
      "num_comments": 12,
      "upvote_ratio": 0.96,
      "text": "Courses and tutorials make sense, but once I try to apply ML to a real problem, everything explodes: data quality, problem definition, deployment, and user needs.\n\nIâ€™m not trying to publish papers, I want to build something useful. How do beginners move from I understand the algorithms to this actually solves a problem?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qhfh2a/learning_ml_is_clear_but_applying_it_to_real/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o0jyulc",
          "author": "RickSt3r",
          "text": "You donâ€™t, you find a problem then design a solution. Sometimes itâ€™s a ML sometimes itâ€™s good old fashion software development.",
          "score": 27,
          "created_utc": "2026-01-19 21:51:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jh6q2",
          "author": "Password-55",
          "text": "Yes, that is why I think AI is too hyped right now. Making actual useful products is key and I think itâ€˜s quite hard, if not sometimes the wrong tool in many applications.\n\nI do not have the answer. Tell me if you find it.",
          "score": 11,
          "created_utc": "2026-01-19 20:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kfbec",
          "author": "Commercial_Note_210",
          "text": "> How do beginners move from I understand the algorithms to this actually solves a problem?\n\nDepends on your area of work, but largely it's flipped. You have a business problem and you work backwards towards a solution.\n\nSomething like... \"I want personalized recommendations on this page -> I have access to the users, items. I can build a label from clicks. I can build feature profiles for users, items -> I can frame this as a (user, item, context, label) recommendation task -> there's a bunch of approaches; next click prediction, CTR prediction, etc -> stop and do research and decide on exact problem framing -> do some research on modeling approaches -> learn about FTTransformer, AutoInt, XGBoost, SLIM, etc -> build a model -> iterate\"\n\nHowever, if \"there's a bunch of approaches\" lands on something like binary click prediction, Ill just use my textbook knowledge and just chuck AutoGluon or XGBoost at it, but as you iterate youll learn more modern approaches, if appropriate.",
          "score": 5,
          "created_utc": "2026-01-19 23:13:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kj2b0",
          "author": "Jaded_Individual_630",
          "text": "That's because there's a cottage industry that benefits from \"boot camping\" people with toolchains and tech stacks. This requires them to minimize the complexity of the task in all of their materials.Â \n\n\nReal cutting edge ML is never going to come off the back of \"import py-machinelearningplease\" and a $5 udemy course.Â \n\n\nNot saying that's what you did, but that is a big predatory industry.",
          "score": 5,
          "created_utc": "2026-01-19 23:33:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0l6dhl",
          "author": "Important_Sundae1632",
          "text": "Have you looked at Kaggle competitions? Theyâ€™re full of concrete examples showing how ML is actually applied.\n\nWhat youâ€™re describing is already most of real-world ML: defining the problem, cleaning data, deploying. You donâ€™t need a complex model to start, and most effort usually goes into those steps anyway. Keep the scope small, start with the simplest approach that works, and walk through one complete example to see how everything connects. If you have a specific problem in mind, feel free to share it or DM me",
          "score": 2,
          "created_utc": "2026-01-20 01:40:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kz21d",
          "author": "Palmquistador",
          "text": "Amen to that.",
          "score": 1,
          "created_utc": "2026-01-20 00:59:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lig1n",
          "author": "Ty4Readin",
          "text": "Machine learning is a lot more than just understanding the algorithms. I think understanding the algorithms is ironically one of the least practically useful skills that you need.\n\nIf you have decent stats, CS, and domain knowledge then everything becomes a lot more straightforward. \n\nIf you run into problems, it's often because you are lacking in one of these areas, and learning more about the algorithms behind some models won't help much unfortunately.\n\nFor example, problem formulation? Thats entirely stats & domain knowledge.\n\nDeployment? Almost entirely CS.\n\nUser workflow/needs? Mostly domain knowledge.\n\nThe best way to learn is to actually try to solve problems as side projects, and make the problems that you actually care about personally.",
          "score": 1,
          "created_utc": "2026-01-20 02:46:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lydfb",
          "author": "Dark-Maverick",
          "text": "If you want to practice to build confidence and put projects in resume, then pick datasets from kaggle and practice it.\n\nThink of anything whatever you like football - there is a football dataset available, cricket - cricket dataset available, tv shows dataset ,movie dataset games dataset these are available just for starting building some projects.\n\nAfter that find innovative ideas explore different datasets on internet and try to find solutions.",
          "score": 1,
          "created_utc": "2026-01-20 04:16:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m4gxm",
          "author": "Adept_Carpet",
          "text": "Data management is often where 90% of the effort is spent and that's assuming the data you need exists. It's generally futile if the organization wasn't managing data well to begin with.\n\n\nThen model deployment (and everything post-deployment like monitoring and debugging and updating and security) is really an unsolved problem. It reminds me of how web app deployment was 20+ years ago. Editing the production site with vi, having to recompile the webserver, old versions of files scattered everywhere, no backups, etc.",
          "score": 1,
          "created_utc": "2026-01-20 04:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0m8ese",
          "author": "patternpeeker",
          "text": "This feeling is normal, because tutorials hide the hardest parts on purpose. In real projects the algorithm is usually the easy piece, and everything around it is where time goes. What helps is scoping problems way down, pick something where a dumb baseline is acceptable and iterate from there. Focus on data first, then evaluation that matches what a user actually cares about, even if it is a rough metric. Deployment and feedback loops can be ugly and manual at the start, and that is fine. You get comfortable by shipping small, imperfect things and seeing where they break.",
          "score": 1,
          "created_utc": "2026-01-20 05:22:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0merqp",
          "author": "AccordingWeight6019",
          "text": "This feeling is very common, and it is usually the gap between toy problems and real systems that shows up. Most real ML work is not about the algorithm at all, but about turning a vague goal into a concrete, testable question and accepting imperfect data. One way to reduce the overwhelm is to start by stripping the problem down to the smallest version that would still be useful, even if it feels almost trivial. Build something that works end to end, even if it is naive, and then iterate. Over time, you realize the messiness is the work, not a sign that you are doing it wrong.",
          "score": 1,
          "created_utc": "2026-01-20 06:10:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thvlz",
          "author": "stairwayfromheaven",
          "text": "Iâ€™ve noticed some studios like thedreamers.us focus on helping people frame ML problems around real business or user needs, which can be helpful when youâ€™re past theory but unsure how to apply it in practice.",
          "score": 1,
          "created_utc": "2026-01-21 07:46:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjra5o",
      "title": "Finished Google Interviews L5 SWE ML",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qjra5o/finished_google_interviews_l5_swe_ml/",
      "author": "rem_dreamer",
      "created_utc": "2026-01-22 10:40:22",
      "score": 46,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "Here's the original post where I described the 4 interviews I would have for the onsite rounds: [https://www.reddit.com/r/learnmachinelearning/comments/1pdytz5/interview\\_google\\_aiml/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/learnmachinelearning/comments/1pdytz5/interview_google_aiml/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n\nOverall, from my self-evaluation, I managed pretty well the ML domain and ML systems interviews; I suggested the right modelling tools and covered many engineering constraints that the reviewers expected; ML domain was a question about designing a model to perform document search based on a query; ML systems was about designing a classifier to add a navigable links to google search.  \nThe Leetcode interview was more chaotic; similar to the \"group anagrams\" problem but overall harder; once I saw the pattern I managed to code an efficient solution but that was towards the end and after some back and forth trying to understand the problem.  \nGoogleyness went ok, nothing special\n\nNow waiting for the verdict, it's been almost a week, but I stay patient and I focus on my current job. Feel free to ask me more questions, DM if you also want more details.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qjra5o/finished_google_interviews_l5_swe_ml/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o16oen4",
          "author": "arena_one",
          "text": "I donâ€™t really understand the classifier for navigable links in google search.. could you elaborate a bit more?",
          "score": 5,
          "created_utc": "2026-01-23 04:59:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14stya",
          "author": "rJedditor",
          "text": "I thought ML domain questions will be more like back and forth on fundamentals, but this seems more like lite version of ML system design",
          "score": 4,
          "created_utc": "2026-01-22 22:40:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14x1b4",
              "author": "rem_dreamer",
              "text": "I thought so too, I guess at this point itâ€™s really random haha",
              "score": 2,
              "created_utc": "2026-01-22 23:02:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o16lidu",
          "author": "Cipher_Lock_20",
          "text": "Weâ€™re rooting for you!! Get it!",
          "score": 3,
          "created_utc": "2026-01-23 04:40:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o176ick",
              "author": "rem_dreamer",
              "text": "Thank you! Just received feedback from recruiter who said that the only critical part for the decision would be the leetcode one that wasnâ€™t that good but the rest is in my favor - letâ€™s see",
              "score": 1,
              "created_utc": "2026-01-23 07:18:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11zz1m",
          "author": "NailTop3719",
          "text": "Can you tell your preparation process and what topics you covered?",
          "score": 2,
          "created_utc": "2026-01-22 14:52:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11yy8t",
          "author": "JuJeu",
          "text": "thanks for sharing! hope youâ€™ll score an offer. keep us updated. can i dm you for the resume tips? (or maybe you can share yours) thanks.",
          "score": 2,
          "created_utc": "2026-01-22 14:47:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11x4hx",
          "author": "anurag1210",
          "text": "Can you tell me how did you prepare for the interview ?",
          "score": 1,
          "created_utc": "2026-01-22 14:37:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkomnp",
      "title": "Machine Learning resources for MATHEMATICIANS (no baby steps, please)",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qkomnp/machine_learning_resources_for_mathematicians_no/",
      "author": "teoreds",
      "created_utc": "2026-01-23 11:43:35",
      "score": 40,
      "num_comments": 16,
      "upvote_ratio": 0.84,
      "text": "I have a solid background in pure mathematics (and also a bit of applied mathematics): linear algebra, probability, measure theory, calculus, ...\n\n\n\nIâ€™m looking for Machine Learning resources aimed at people who already know the math and want to focus on models, optimization, statistical assumptions, theory / generalization, use cases of algorithms\n\nNot looking for beginner courses or step-by-step derivations of gradients or matrix calculus.\n\nDo you guys know good books, lecture notes, or advanced courses (coursera?) that is suitable given my background?\n\nAny help would be very appreciated.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qkomnp/machine_learning_resources_for_mathematicians_no/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o184dyy",
          "author": "entarko",
          "text": "I would recommend two books:\n- Pattern Recognition and Machine Learning, by Bishop\n- Elements of Statistical Learning, by Friedman\n\nIt is more geared towards classical ML rather than modern DL, but it's also more math focused.",
          "score": 15,
          "created_utc": "2026-01-23 12:14:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1880na",
              "author": "JanBitesTheDust",
              "text": "Bishopâ€™s recent book on Deep Learning is also really good",
              "score": 8,
              "created_utc": "2026-01-23 12:38:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18f2x9",
                  "author": "entarko",
                  "text": "I have not read it, but given how much I liked PRML, I am sure it's great. I'm adding it to my reading list.",
                  "score": 3,
                  "created_utc": "2026-01-23 13:21:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1aca4k",
                  "author": "wjholden",
                  "text": "Is this the right book? https://www.bishopbook.com/",
                  "score": 1,
                  "created_utc": "2026-01-23 18:49:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18eqd1",
              "author": "pratzzai",
              "text": "PRML is the right starting point. It gives one a solid, rigorous foundation and then one can cover ESL for additional depth. I wouldn't recommend starting with ESL because the exposition isn't great and a lot of things are left unsaid, which one needs to step out of the book to collect.",
              "score": 2,
              "created_utc": "2026-01-23 13:20:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a3hd0",
          "author": "Lower_Improvement763",
          "text": "Thereâ€™s a lot of books. Some of them are based more on ML practitioners . â€œMathematics of Machine Learningâ€, â€œArtifucial Intelligence: A Modern Approachâ€, â€œNeural Network Designâ€ are good ones not mentioned yet.",
          "score": 3,
          "created_utc": "2026-01-23 18:10:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1a3jrm",
          "author": "DemonCat4",
          "text": "Advanced books proof based:\n               Understanding machine learning: from theory to algorithms by  shai shalev-shwartz and shai ben-david\n               Introduction to online convex optimization by elad hazan\n\nFor courses look at ut austin, it has an online master of science in artificial inteligence, in fact the book of shai ben David is used for machine learning and generative ai courses.",
          "score": 2,
          "created_utc": "2026-01-23 18:10:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1a57mm",
          "author": "neslef",
          "text": "Any ML course that is taught at a university will have prob/stat, calc, LA and intro cs courses as prerequisites so that's what you'll want to look for.\n\nStanford cs 229 is a good option. There are multiple iterations of the course but I'd recommend the version of Fall 2018. Here is a link to the course page: [https://github.com/maxim5/cs229-2018-autumn?tab=readme-ov-file](https://github.com/maxim5/cs229-2018-autumn?tab=readme-ov-file) Many of the other iterations don't have the course materials published for public access.\n\nHere is a link to a youtube playlist of the course: [https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) \n\nStanford has a good collection of other courses as well for Deep Learning.\n\nOther commenters have already mentioned many good books.",
          "score": 2,
          "created_utc": "2026-01-23 18:17:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1adwc7",
          "author": "bobbyfairfox",
          "text": "The mathematical foundation for ML is basically some statistics and learning theory. For the first, a good book is Dejiver&Kittler, and for the second thereâ€™s vapnik or kearns&vazirani. These are suitable if ur math and stats are at a graduate level. A good combination of the material is the recent Foundation of Machine Learning. \n\nBut my own perspective on this is: just because you know the math, doesnâ€™t mean you need to use it. You could read all of what I suggested and not know a thing about what people are working on today. If instead thatâ€™s ur goal, then u should just do what everyone else is doing: ie do online courses on machine learning and deep learning and RL from top universities (Berkeley and Stanford are good starting points to look). If ur math is advanced then you can run thru some problems quite quickly but you will probably still find a good amount of things to be non trivial. Also if ur comfortable with research level math the theoretical research for ML should not be daunting once you have done the courses, and you can go from there.",
          "score": 2,
          "created_utc": "2026-01-23 18:56:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1beqck",
          "author": "jsh_",
          "text": "ignore all of the other suggestions. pick up murphy - probabilistic machine learning vol 1 and 2. for learning you should use vol 1 but vol 2 is significantly more detailed and expansive. I'm from a math background and work in ML research and I routinely use vol 2 as a reference. it's literally sitting next to me on my desk right now",
          "score": 2,
          "created_utc": "2026-01-23 21:48:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1818ld",
          "author": "teoreds",
          "text": "Oh and, forgot to mention, I also have experience with python (been building simple apps for years, like mini-games and telegram bots), so programming is not a problem at all.",
          "score": 2,
          "created_utc": "2026-01-23 11:51:12",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o196l7m",
          "author": "JuJeu",
          "text": "new bishop book as already suggested",
          "score": 1,
          "created_utc": "2026-01-23 15:40:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1d94bt",
          "author": "dbred2309",
          "text": "Probabilistic ML by Kevin Murphy, available online.",
          "score": 1,
          "created_utc": "2026-01-24 03:56:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1874hd",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -11,
          "created_utc": "2026-01-23 12:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18bn1f",
              "author": "teoreds",
              "text": "Thank you for your very useful contribution",
              "score": 9,
              "created_utc": "2026-01-23 13:01:39",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o19a8aw",
              "author": "Datashot",
              "text": "bad bot",
              "score": 2,
              "created_utc": "2026-01-23 15:57:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qfkal8",
      "title": "Which subfields of ML can I realistically achieve PhD level mastery of by self study at home with limited budget?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qfkal8/which_subfields_of_ml_can_i_realistically_achieve/",
      "author": "Proof-Bed-6928",
      "created_utc": "2026-01-17 18:08:35",
      "score": 39,
      "num_comments": 43,
      "upvote_ratio": 0.73,
      "text": "Suppose you have somehow managed to generate 25k disposable income and only work 20hours a week so you have plenty of free time. You want to dedicate the remaining time to the mastery of one small but important ML niche just for the sake of it. To the level where you can theoretically waltz into a room full of FAANG level ML engineers and impress them with your contributions.\n\nIt will have to be a subfields where your competitive advantage plateaus with capital after some number (so not some compute arms race like LLM). \n\nWhich subfields in ML is this possible? What kind of benchmarks can you use to validate? How do you know youâ€™ve learned something without being in a university surrounded by academics?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qfkal8/which_subfields_of_ml_can_i_realistically_achieve/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o07bjun",
          "author": "notsofastaicoder",
          "text": "I think you are over estimating FAANG level ML engineers, and you don't need to a Phd to impress people either.\n\nSince most of these engineers do applied engineering, they are looking for solutions to current problems.\n\nMy experience has been in applied software engineering, worked in FAANG and AI startups. So advice from a non PhD guy:\n\nAfter you establish the base skills for ML, focus on an area that truly excites you, then make a meaningful contribution. Either by proving a hypothesis, or making an incremental improvement to existing solutions.\n\nBeing able to do that, in your own time, is really impressive.",
          "score": 61,
          "created_utc": "2026-01-18 00:24:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o09evq5",
              "author": "belabacsijolvan",
              "text": "also [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)",
              "score": 4,
              "created_utc": "2026-01-18 08:43:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0dqr71",
              "author": "ChillmanITB",
              "text": "read an academic paper everyday, lots of books on theory, do all the free courses on calculus and linear algebra, probability and statistics (This is where you will develop an actual understanding), learn to code if you have not already and try and come up with new methods of improving current algorithms or create new ones all together.",
              "score": 3,
              "created_utc": "2026-01-18 23:38:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0zqbgy",
              "author": "taichi22",
              "text": "Honestly it depends more on the room youâ€™re talking about cause some FAANG level engineers are basically impossible to impress â€” theyâ€™ve seen it all. A lot of FAANG engineers, in addition, are really more impressed by real stuff youâ€™ve built rather than pure research. Thereâ€™s some overlap there â€” if your research artifacts are commonly used as state of the art industrial benchmarks then your name will carry weight, but at that point youâ€™ll probably be leading a team of FAANG engineers. \n\nAnyways, to OOP your benchmarks and directions are sort of misaligned, to be honest. As the saying goes, â€œhow do you climb a mountain? Why, one step at a time, of course.â€",
              "score": 1,
              "created_utc": "2026-01-22 04:42:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o06dtfy",
          "author": "williamkotoco_",
          "text": "anything related to efficient ml techniques such as pruning, quantization,  nas, efficient architectures and edge ai in general",
          "score": 19,
          "created_utc": "2026-01-17 21:32:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06slmz",
              "author": "Altruistic_Basis_69",
              "text": "My PhD was in DL optimization and I agree with this (though I am a little biased tbf). Compared to other niches, Iâ€™d argue that architecture optimization is one of the more intuitive areas to look into as opposed to some of the faster growing fields where you wonâ€™t even get a chance to catch-up.",
              "score": 9,
              "created_utc": "2026-01-17 22:45:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o06gpd8",
              "author": "Annual-Salamander-85",
              "text": "These are all pretty deep, why do you say that?",
              "score": 2,
              "created_utc": "2026-01-17 21:46:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0zqhem",
              "author": "taichi22",
              "text": "I do have to agree here on this point that I was suitably impressed by the work done on RF-DETR.",
              "score": 1,
              "created_utc": "2026-01-22 04:43:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o077s6k",
          "author": "Playful-Score-67",
          "text": "PhD level? It takes 5+ years of intense studying, independent research, mentoring from someone who is an expert on the field and contact with an academic community that can support and answer questions. It's not only about \"self study\".\nSo, realistically? Nah.",
          "score": 42,
          "created_utc": "2026-01-18 00:04:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08wtuv",
              "author": "BreadBrowser",
              "text": "Wellâ€¦ I donâ€™t think I learned a single god damned thing from my advisor. Fuck that guy. Why I didnâ€™t leave Iâ€™ll never know. But yeah, you need a good five intense years.",
              "score": 5,
              "created_utc": "2026-01-18 06:04:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09d6yl",
                  "author": "digiorno",
                  "text": "Thatâ€™s a tragedy, if someone wants to be an advisor then they should take that role seriously and genuinely try to improve the next generation of researchers.",
                  "score": 5,
                  "created_utc": "2026-01-18 08:27:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o08nsh8",
              "author": "arihoenig",
              "text": "Nonsense, Faraday was self taught as was Galileo and Joule. All of their contributions are PhD level in the fields in which they contributed.",
              "score": -5,
              "created_utc": "2026-01-18 04:57:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08tzoo",
                  "author": "RatKnees",
                  "text": "Ah yes, people born 200+ years ago. \n\nI don't disagree that anyone can make a contribution, but listing people from pre-electricity feels disingenuous",
                  "score": 21,
                  "created_utc": "2026-01-18 05:42:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0zqyiy",
                  "author": "taichi22",
                  "text": "This is comparing apples to oranges. Nobody in this thread is as brilliant as Faraday â€” people like that are so different than you or I that the paths that they walk canâ€™t even serve as guidance for us. It would be like asking Einstein how to become a professor; thereâ€™s nothing useful to really be gleaned from his answer because the ways he got there are inaccessible to us. \n\nThose kinds of people wonâ€™t be on reddit asking how to do it â€” they just do it, because they are the type of people who cannot imagine doing anything else. You and I and many others in this subreddit may qualify as â€œgiftedâ€ or â€œregular geniusesâ€, but the gulf between people like us and people like Faraday or Joule is as wide â€” probably wider â€” than the gulf between us and an average person.",
                  "score": 2,
                  "created_utc": "2026-01-22 04:46:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o07b6gd",
          "author": "nickpsecurity",
          "text": "Any of the older techniques that are still widely used in industry. Then, smaller NN's, GA's, and LLM's. Also, techniques for things like time series and tabukar data which are highly important in industry but get little press or investment like GPT. That's the answer to your title.\n\nFar as FAANG, this [person](https://www.trybackprop.com/blog/top_ml_learning_resources) shares what they studied to do something like that.",
          "score": 10,
          "created_utc": "2026-01-18 00:22:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0awr63",
              "author": "iamevpo",
              "text": "What is a GA here?",
              "score": 1,
              "created_utc": "2026-01-18 15:22:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0bde7w",
                  "author": "NightmareLogic420",
                  "text": "Genetic Algorithms, I believe",
                  "score": 3,
                  "created_utc": "2026-01-18 16:42:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0btu0u",
                  "author": "nickpsecurity",
                  "text": "Genetic algorithms. They call the broader field evolutionary algorithms because they claim to use a highly-simplifies version of its principles. It's an optimization technique capable of working with non-differentiable data without getting stuck in local minima or maxima. It has heavier computation, though.\n\nIIRC, the top methods are differentiable evolution (in SciPy, too) and evolution strategies. If you use GA's, try tournament selection with tournament size of 7. Coevolution, or fitness tests evolving with the population, historically outperformed static, fitness measures. Such methods can be combined with NN's (neuroevolution) to find architectures, weights, hyperparameters, etc.",
                  "score": 2,
                  "created_utc": "2026-01-18 18:00:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o06rxw3",
          "author": "seriousgourmetshit",
          "text": "I don't think its possible to reach the level you are thinking of tbh",
          "score": 27,
          "created_utc": "2026-01-17 22:42:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08n6md",
              "author": "arihoenig",
              "text": "George Boole was an autodidact. LLMs are just large assemblies of the logic he proposed.",
              "score": 4,
              "created_utc": "2026-01-18 04:53:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0b1060",
                  "author": "jonsca",
                  "text": "Found the guy who knows nothing about nothingÂ ",
                  "score": 5,
                  "created_utc": "2026-01-18 15:43:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o08ks4e",
          "author": "Complex_Medium_7125",
          "text": "a PhD teaches you how to do novel research, is that what you want to do?  \nif not, taking some grad courses in ml from stanford/berkeley/cmu gets you the foundations of solid ml engineer level\n\ncheck out [https://stanford-cs336.github.io/spring2025/](https://stanford-cs336.github.io/spring2025/) and do the homeworks",
          "score": 6,
          "created_utc": "2026-01-18 04:36:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o06x83c",
          "author": "UngratefulSheeple",
          "text": "Thatâ€™s not gonna happen bro ðŸ˜‚ðŸ˜‚\n\nSincerely, someone doing a phd in ai right now.",
          "score": 9,
          "created_utc": "2026-01-17 23:09:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o09cfu5",
          "author": "digiorno",
          "text": "For actual ML research and not just application, you need math skills. And sure those can be self taught but it could be incredibly difficult to get good at without the guidance of professors. \n\nSecondly for cutting edge stuff, a lot of that so done via collaborative efforts with other theorists in an academic setting.\n\nIf you get good enough at the math and have some novel ideas then a school or research would likely give you admittance to a PhD program so that you could work with them, learn from them and join their ranks. And they would pay you a bit more than the amount you mentioned.",
          "score": 2,
          "created_utc": "2026-01-18 08:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e9h02",
          "author": "mpaes98",
          "text": "Iâ€™ll be real with you, a PhD is basically self studying while also having to juggle 1-2 exploitative jobs where you report to different tiers of narcissistic individuals who have no proper management experience, and donâ€™t even get me started on how bad teaching duties have gotten (overbloated classes, unprepared undergrads/grads).\n\nI had a decent experience, but itâ€™s a rough time and now weâ€™re in a terrible market.",
          "score": 2,
          "created_utc": "2026-01-19 01:18:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o07fihm",
          "author": "strangeanswers",
          "text": "Iâ€™d argue that this is possible in the operationalization of LLMs to address business problems such as automated customer support, sentiment scraping or any other forms of information retrieval and programmatic decision-making. \n\nyou need a firm grasp of how LLMs work, strong software engineering technicals, LLMOps/DevOps, prompt & context engineering skills and good product reasoning. each of these skills is difficult to develop but Iâ€™d argue that itâ€™s feasible to become elite in this problem space through lots of self study and practice and very solid applied projects where you actually develop and deploy cloud infrastructure that can handle high throughput.",
          "score": 2,
          "created_utc": "2026-01-18 00:45:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05bvvp",
          "author": "tewmuchdrama",
          "text": "Reinforcement Learning",
          "score": -9,
          "created_utc": "2026-01-17 18:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o080svj",
              "author": "jsh_",
              "text": "?",
              "score": 1,
              "created_utc": "2026-01-18 02:39:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o05udrd",
              "author": "pb_syr",
              "text": "Why",
              "score": 0,
              "created_utc": "2026-01-17 19:52:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjqqmz",
      "title": "Turned my phone into a real-time push-up tracker using computer vision",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/v1dgx4onkveg1",
      "author": "Few_Homework_8322",
      "created_utc": "2026-01-22 10:08:07",
      "score": 39,
      "num_comments": 3,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qjqqmz/turned_my_phone_into_a_realtime_pushup_tracker/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o138yxu",
          "author": "Double_Sherbert3326",
          "text": "Zero zero zero terminated.",
          "score": 2,
          "created_utc": "2026-01-22 18:17:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13hv8z",
          "author": "nnirmalll",
          "text": "Does it shout the counts?",
          "score": 2,
          "created_utc": "2026-01-22 18:56:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dh598",
          "author": "Aromatic-Employee-71",
          "text": "Really nice!",
          "score": 1,
          "created_utc": "2026-01-24 04:49:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}