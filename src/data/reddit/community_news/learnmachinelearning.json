{
  "metadata": {
    "last_updated": "2026-02-05 17:09:59",
    "time_filter": "week",
    "subreddit": "learnmachinelearning",
    "total_items": 20,
    "total_comments": 192,
    "file_size_bytes": 171537
  },
  "items": [
    {
      "id": "1qu0vgq",
      "title": "Finally getting interviews!!",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/yfp7ce1h54hg1.jpeg",
      "author": "Full_Meat_57",
      "created_utc": "2026-02-02 17:07:16",
      "score": 355,
      "num_comments": 40,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qu0vgq/finally_getting_interviews/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o38oxth",
          "author": "Cheek_Powerful",
          "text": "If all your languages are <C1, then what is your native tongue?",
          "score": 20,
          "created_utc": "2026-02-02 22:44:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3apqd7",
              "author": "chaitanyathengdi",
              "text": "\"Chinese A1\"",
              "score": 12,
              "created_utc": "2026-02-03 06:02:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3bdpiw",
              "author": "Full_Meat_57",
              "text": "Hindi",
              "score": 9,
              "created_utc": "2026-02-03 09:43:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3o9f8w",
                  "author": "Bangoga",
                  "text": "Damn dude. Insane.",
                  "score": 1,
                  "created_utc": "2026-02-05 06:16:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3aon4u",
          "author": "axiomaticdistortion",
          "text": "OP is most likely in Germany and that‚Äôs the worst job market seen in decades. If you are looking to build a future in tech, do yourself a favor and look further. Thank me later.",
          "score": 7,
          "created_utc": "2026-02-03 05:53:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ekdm8",
              "author": "Candid-Cobbler-510",
              "text": "Worst in germany right? I believe it is easier to get a job in germany than elsewhere.",
              "score": 3,
              "created_utc": "2026-02-03 20:19:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3m9gxa",
                  "author": "LordFungie",
                  "text": "Tech in Germany is suffering a lot. Most companies are only hiring under 1 year contracts so that when they eventually have to lay people off, it's the new employees, that way they don't have to pay for unemployment benefits.",
                  "score": 1,
                  "created_utc": "2026-02-04 22:57:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3bdufn",
          "author": "Full_Meat_57",
          "text": "It‚Äôs simple ms word from scratch",
          "score": 2,
          "created_utc": "2026-02-03 09:44:47",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o38gjw3",
          "author": "EcstaticBank",
          "text": "Could you post the old cv as well to see what really worked and what didn't",
          "score": 3,
          "created_utc": "2026-02-02 22:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38jayj",
              "author": "Full_Meat_57",
              "text": "Check the last post of mine",
              "score": 3,
              "created_utc": "2026-02-02 22:16:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jvur",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o373fuu",
          "author": "migrated-human",
          "text": "Do you make it in Canva or latex? \nI'm only getting rejected even though I've tried doing ats checks and everything",
          "score": 2,
          "created_utc": "2026-02-02 18:13:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37libd",
              "author": "Full_Meat_57",
              "text": "Simple ms word",
              "score": 5,
              "created_utc": "2026-02-02 19:36:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3aouu8",
                  "author": "No-Debt4738",
                  "text": "\"simple\" and \"ms word\" can't be in the same sentence¬†",
                  "score": 10,
                  "created_utc": "2026-02-03 05:55:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38jtuo",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 0,
              "created_utc": "2026-02-02 22:19:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o37y1zz",
              "author": "SithEmperorX",
              "text": "Suffering from the same. Made it all in LaTeX still no reaction.",
              "score": -2,
              "created_utc": "2026-02-02 20:35:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o38jwxq",
          "author": "Full_Meat_57",
          "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
          "score": 2,
          "created_utc": "2026-02-02 22:19:33",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3ap9ar",
              "author": "Spinachforthepope",
              "text": "Great! What did you use? What template and so?\nThanks in advance!",
              "score": 1,
              "created_utc": "2026-02-03 05:58:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3bdqpv",
                  "author": "Full_Meat_57",
                  "text": "I made from scratch in ms word",
                  "score": 1,
                  "created_utc": "2026-02-03 09:43:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o39igur",
          "author": "Status-Supermarket98",
          "text": "Is C1 German is needed for applying in Germany?",
          "score": 1,
          "created_utc": "2026-02-03 01:26:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3bdsuh",
              "author": "Full_Meat_57",
              "text": "Not necessarily but all the interviews I got we just spoke German",
              "score": 1,
              "created_utc": "2026-02-03 09:44:21",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3b536b",
              "author": "acontext60",
              "text": "Not for every role",
              "score": 0,
              "created_utc": "2026-02-03 08:19:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o39nc6r",
          "author": "Comfortable-Bath-905",
          "text": "Fantastic!",
          "score": 1,
          "created_utc": "2026-02-03 01:54:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a4v8t",
          "author": "angel_days",
          "text": "Good going dude",
          "score": 1,
          "created_utc": "2026-02-03 03:35:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a4xqw",
          "author": "angel_days",
          "text": "Can you please share your template",
          "score": 1,
          "created_utc": "2026-02-03 03:36:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bvhi0",
          "author": "pixiebutcurly",
          "text": "Please share ypur interview experience too",
          "score": 1,
          "created_utc": "2026-02-03 12:17:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fc604",
          "author": "juicymice",
          "text": "How is the job market in Germany? Starting salary? What type of work permit do Indians require?",
          "score": 1,
          "created_utc": "2026-02-03 22:30:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hoojv",
              "author": "Full_Meat_57",
              "text": "Yes Germany. Usually the job descriptions stating from 80k to 120k. I guess normal work permit",
              "score": 1,
              "created_utc": "2026-02-04 07:09:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3lghjz",
                  "author": "juicymice",
                  "text": "How's the job market there? Plenty of tech jobs or not too many (as in the US)?",
                  "score": 1,
                  "created_utc": "2026-02-04 20:35:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3gn1g2",
          "author": "Fat-F",
          "text": "the only reason u get interviews is because recruiters fall for the shit you are writing there",
          "score": 1,
          "created_utc": "2026-02-04 02:47:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3grbeb",
          "author": "Firm_Passage_6844",
          "text": "congrats, all the best",
          "score": 1,
          "created_utc": "2026-02-04 03:11:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i2iz5",
          "author": "Exotic-Hunter-5262",
          "text": "Hey I have some questions.\nI am looking to go over in the same field.\nIf you don't mind can I ask you in dms?",
          "score": 1,
          "created_utc": "2026-02-04 09:17:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iglbd",
              "author": "Full_Meat_57",
              "text": "Yes",
              "score": 1,
              "created_utc": "2026-02-04 11:25:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kf9je",
          "author": "translations-guru",
          "text": "Great job, like the consistency and succinctness! Good luck finding your dream job!",
          "score": 1,
          "created_utc": "2026-02-04 17:44:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o38c0rc",
          "author": "ufl_exchange",
          "text": "Are you applying for jobs in the US or Germany?",
          "score": 1,
          "created_utc": "2026-02-02 21:41:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j583",
              "author": "Full_Meat_57",
              "text": "Germany only",
              "score": 3,
              "created_utc": "2026-02-02 22:15:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o37ubx4",
          "author": "MMechree",
          "text": "Could you share a template, please?",
          "score": 0,
          "created_utc": "2026-02-02 20:17:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38j87r",
              "author": "Full_Meat_57",
              "text": "It‚Äôs simple ms word, I made everything from scratch",
              "score": 2,
              "created_utc": "2026-02-02 22:16:07",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o38jurg",
              "author": "Full_Meat_57",
              "text": "BTW I also still got me pic in the resume, in this one for the post I removed",
              "score": 2,
              "created_utc": "2026-02-02 22:19:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qt5tju",
      "title": "Upskilling in your 30s hits different",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qt5tju/upskilling_in_your_30s_hits_different/",
      "author": "ReflectionSad3029",
      "created_utc": "2026-02-01 18:09:22",
      "score": 168,
      "num_comments": 30,
      "upvote_ratio": 0.95,
      "text": "Learning new skills in your 30s while working full-time is tough.\n\n I recently attended a weekend AI workshop and realized how behind I actually was. \nSlightly uncomfortable, but also motivating. Made me stop procrastinating on learning new tools. \n\nit really helped me to get comfortable with something  i was worried about\n\nJust a reminder: feeling uncomfortable means you‚Äôre growing.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qt5tju/upskilling_in_your_30s_hits_different/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o30kgqi",
          "author": "Winners-magic",
          "text": "You gotta borrow time from your 9-5",
          "score": 118,
          "created_utc": "2026-02-01 18:38:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fxdv",
              "author": "Only-Ad2239",
              "text": "My previous job did the opposite - borrowed time from my 5 PM to 9 AM.",
              "score": 16,
              "created_utc": "2026-02-02 08:20:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o37g81i",
              "author": "SizePunch",
              "text": "This 100%",
              "score": 2,
              "created_utc": "2026-02-02 19:11:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3c80nb",
              "author": "No_Toe_7809",
              "text": "My current job also doesn‚Äôt borrow time from the 9-5‚Ä¶ I‚Äôm still wondering what kind of job all of you are doing when you suggest that :)",
              "score": 2,
              "created_utc": "2026-02-03 13:36:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3devg1",
                  "author": "Winners-magic",
                  "text": "any kind of white collar job that‚Äôs either hybrid/remote gives you that flexibility",
                  "score": 1,
                  "created_utc": "2026-02-03 17:09:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o30ggop",
          "author": "EntrepreneurHuge5008",
          "text": ">Learning new skills in your 30s while working full-time is tough.\n\n100% agreed",
          "score": 41,
          "created_utc": "2026-02-01 18:20:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o31g2i8",
              "author": "opparasite",
              "text": "Totally agree, I only have like a couple of hours to study a bit, and trying to stay focused is challenging.",
              "score": 7,
              "created_utc": "2026-02-01 21:08:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30wh5a",
          "author": "SeaZealousideal5651",
          "text": "I did a lot of that in my 30s both borrowing time from my 9-5 and sacrificing sleep. Sleep is not the healthy way of doing it but after about a year and change of that, I was able to change job, and I couldn‚Äôt be any happier.\n\nIf there‚Äôs a will there‚Äôs a way‚Ä¶you got this!",
          "score": 30,
          "created_utc": "2026-02-01 19:33:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30loxb",
          "author": "Signal_Ad657",
          "text": "I literally quit my full time job to just learn about computers and AI all day and there‚Äôs not enough hours in the day to stay on top of all of it even now.  There‚Äôs so many sub topics, tools, platforms, potential skills to develop and you could disappear into any of them very easily and while doing that you are missing countless other things.  If you are trying at all you are in a good club.",
          "score": 22,
          "created_utc": "2026-02-01 18:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o310pip",
              "author": "bingbpbmbmbmbpbam",
              "text": "Literally. If you‚Äôre serious you‚Äôd cut out distractions anyways, and if not, there‚Äôs definitely a guy who will quit his job and move across the country to make it happen, so maybe ask yourself if it‚Äôs the kind of life you actually want, or you just think it would be nice.",
              "score": 1,
              "created_utc": "2026-02-01 19:53:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o32bku4",
                  "author": "Signal_Ad657",
                  "text": "Yeah you just have to accept you can‚Äôt know everything, and try your best to know what matters and be hyper productive and that‚Äôs what full time AI work looks like in my experience.",
                  "score": 7,
                  "created_utc": "2026-02-01 23:50:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o30t28z",
          "author": "Extra_Intro_Version",
          "text": "Late 50s, early 60s here when I started. Honestly, it sucked.",
          "score": 24,
          "created_utc": "2026-02-01 19:17:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30vmvs",
          "author": "Expensive_Fun4346",
          "text": "even after learning all this material, i struggle to keep up.  AI is moving so fast and the tools/pipelines are so different from 2 years ago.  it's a struggle to keep up.",
          "score": 7,
          "created_utc": "2026-02-01 19:29:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30kgx4",
          "author": "hc_fella",
          "text": "I've combined my master thesis with my first year of work... It will be a while before I commit my hours after work to even more work...",
          "score": 8,
          "created_utc": "2026-02-01 18:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o30w714",
          "author": "valkon_gr",
          "text": "Any interesting tools that you saw there?",
          "score": 4,
          "created_utc": "2026-02-01 19:32:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bot1w",
          "author": "Tall_Interaction7358",
          "text": "Totally feel this. I‚Äôm 28, and even now the gap can feel real when you step into something new, especially around AI or fast-moving tools. You walk in thinking you‚Äôre doing okay, then suddenly realize how much you don‚Äôt know \n\nFor me, the discomfort usually hits first as self-doubt. Like, 'am I late to this?' But almost every time, once I push through that initial awkward phase, it turns into motivation instead of fear. The hardest part is honestly starting while juggling work and life.\n\nI like what you said about discomfort being a growth signal. That mindset shift helps a lot. If something feels a bit uncomfortable but exciting, it‚Äôs usually a sign it‚Äôs worth leaning into.",
          "score": 2,
          "created_utc": "2026-02-03 11:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31ix4a",
          "author": "Top_Limit_",
          "text": "Agreed. Going thru this now.\n\nHard to keep motivated knowing that im very far from even being able to use it professionally.",
          "score": 1,
          "created_utc": "2026-02-01 21:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32irug",
          "author": "pixiebutcurly",
          "text": "Hard relate. ...especially building some solutions on your own",
          "score": 1,
          "created_utc": "2026-02-02 00:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3419lg",
          "author": "SilverSpearhead",
          "text": "I always tell myself to catch up with latest technology and learn from younger generation",
          "score": 1,
          "created_utc": "2026-02-02 06:09:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o341vax",
          "author": "AccordingWeight6019",
          "text": "that discomfort is pretty normal, especially once you already have some experience to compare against. learning later tends to surface gaps more clearly, but it also comes with better judgment about what actually matters. I‚Äôve found progress feels slower because time is constrained, not because the learning itself is harder. the upside is that you can usually connect new tools to real problems much faster. that tends to make what sticks more durable, even if the ramp feels rough at first.",
          "score": 1,
          "created_utc": "2026-02-02 06:14:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35fcnr",
          "author": "no_spoon",
          "text": "What do they teach at an ‚ÄúAI workshop‚Äù that you can‚Äôt already learn by asking ChatGPT yourself?",
          "score": 1,
          "created_utc": "2026-02-02 13:19:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o383j06",
          "author": "Stargazer1884",
          "text": "Hah wait till you're 50 with kids.",
          "score": 1,
          "created_utc": "2026-02-02 21:01:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39fk50",
          "author": "Gintoki100702",
          "text": "Best thing one can do is to upskill \nKeep working",
          "score": 1,
          "created_utc": "2026-02-03 01:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3a4tc7",
          "author": "pragud",
          "text": "may I know what exactly you are trying to upskill?",
          "score": 1,
          "created_utc": "2026-02-03 03:35:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31rkm8",
          "author": "ab624",
          "text": "any insights from the workshop",
          "score": 0,
          "created_utc": "2026-02-01 22:04:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o31s7fa",
          "author": "EffectiveOk4641",
          "text": "Its quite an eye opener, the field is moving so fast. In ML myself, upskilling on AI. Actually building a coach to help create personal roadmaps that fit in my daily schedule, so i make progress even though i have a busy week. You can check it out[ here](https://skillmapperai.com/landing/?utm_source=reddit&utm_medium=reddit&utm_campaign=dataanalysiscareers) if it sounds interesting, appreciate any feedback!",
          "score": -3,
          "created_utc": "2026-02-01 22:07:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o310gr8",
          "author": "bingbpbmbmbmbpbam",
          "text": "Don‚Äôt work a full time job. Ask yourself what you want more, comfort now or leverage later?",
          "score": -5,
          "created_utc": "2026-02-01 19:52:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35byyn",
              "author": "kaystar101",
              "text": "Horrible advice",
              "score": 1,
              "created_utc": "2026-02-02 12:57:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr1bpk",
      "title": "Python Crash Course Notebook for Data Engineering",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "author": "analyticsvector-yt",
      "created_utc": "2026-01-30 09:57:41",
      "score": 119,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "Hey everyone! Sometime back, I put together a¬†**crash course on Python**¬†specifically tailored for Data Engineers. I hope you find it useful! I have been a data engineer for¬†**5+ years**¬†and went through various blogs, courses to make sure I cover the essentials along with my own experience.\n\nFeedback and suggestions are always welcome!\n\nüìî¬†**Full Notebook:**¬†[Google Colab](https://colab.research.google.com/drive/1r_MmG8vxxboXQCCoXbk2nxEG9mwCjnNy?usp=sharing)\n\nüé•¬†**Walkthrough Video**¬†(1 hour):¬†[YouTube](https://youtu.be/IJm--UbuSaM)¬†\\- Already has almost¬†**20k views & 99%+ positive ratings**\n\nüí° Topics Covered:\n\n**1. Python Basics**¬†\\- Syntax, variables, loops, and conditionals.\n\n**2. Working with Collections**¬†\\- Lists, dictionaries, tuples, and sets.\n\n**3. File Handling**¬†\\- Reading/writing CSV, JSON, Excel, and Parquet files.\n\n**4. Data Processing**¬†\\- Cleaning, aggregating, and analyzing data with pandas and NumPy.\n\n**5. Numerical Computing**¬†\\- Advanced operations with NumPy for efficient computation.\n\n**6. Date and Time Manipulations**\\- Parsing, formatting, and managing date time data.\n\n**7. APIs and External Data Connections**¬†\\- Fetching data securely and integrating APIs into pipelines.\n\n**8. Object-Oriented Programming (OOP)**¬†\\- Designing modular and reusable code.\n\n**9. Building ETL Pipelines**¬†\\- End-to-end workflows for extracting, transforming, and loading data.\n\n**10. Data Quality and Testing**¬†\\- Using¬†\\`unittest\\`,¬†\\`great\\_expectations\\`, and¬†\\`flake8\\`¬†to ensure clean and robust code.\n\n**11. Creating and Deploying Python Packages**¬†\\- Structuring, building, and distributing Python packages for reusability.\n\n**Note:**¬†I have not considered PySpark in this notebook, I think PySpark in itself deserves a separate notebook!",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr1bpk/python_crash_course_notebook_for_data_engineering/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2rs7wl",
          "author": "PixelLight",
          "text": "Everything looks really good. I think my main question is why you chose os over pathlib? To my understanding thats a more modern approach",
          "score": 3,
          "created_utc": "2026-01-31 11:03:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2sqzo7",
              "author": "analyticsvector-yt",
              "text": "Agree this was 1.5 years back I will do a updated version soon",
              "score": 2,
              "created_utc": "2026-01-31 15:01:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l0sxn",
          "author": "Ok-Blacksmith6403",
          "text": "Thank you üëç",
          "score": 4,
          "created_utc": "2026-01-30 11:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nfay8",
              "author": "analyticsvector-yt",
              "text": "Glad you found it helpful!",
              "score": 1,
              "created_utc": "2026-01-30 18:36:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pvbi9",
          "author": "bhariLund",
          "text": "Saving this",
          "score": 2,
          "created_utc": "2026-01-31 02:01:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ntwgj",
          "author": "diegoasecas",
          "text": "CUT THE CABLE",
          "score": 1,
          "created_utc": "2026-01-30 19:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ogh4p",
              "author": "Sufficient-Main-4101",
              "text": "LOL",
              "score": 2,
              "created_utc": "2026-01-30 21:28:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2s1i77",
          "author": "Always_Learning_000",
          "text": "Thank you for sharing this!!",
          "score": 1,
          "created_utc": "2026-01-31 12:23:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sbycb",
          "author": "KGagan1",
          "text": "Thank you",
          "score": 1,
          "created_utc": "2026-01-31 13:35:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m7a50",
          "author": "vanisle_kahuna",
          "text": "Cheers ü•Ç",
          "score": 1,
          "created_utc": "2026-01-30 15:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nf94y",
              "author": "analyticsvector-yt",
              "text": "ü§ù",
              "score": 0,
              "created_utc": "2026-01-30 18:36:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwldsm",
      "title": "I have 200 subscriptions and 15% of them are fake",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/r37p88fbgohg1.png",
      "author": "No-Swordfish7597",
      "created_utc": "2026-02-05 13:33:04",
      "score": 109,
      "num_comments": 22,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qwldsm/i_have_200_subscriptions_and_15_of_them_are_fake/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3przqm",
          "author": "ImpossibleAgent3833",
          "text": "How are you even spending 85k every f month on subscriptions üò≠ Are you running a small country? I can‚Äôt imagine keeping mental track of 230 tools",
          "score": 35,
          "created_utc": "2026-02-05 13:47:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pwu54",
              "author": "odinti",
              "text": "fr, is this guy paying for calculator api? CSSaaS ? Wtf",
              "score": 13,
              "created_utc": "2026-02-05 14:14:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q327f",
                  "author": "deadc0de",
                  "text": "This makes me wonder if I‚Äôm getting over charged for is-odd.com?  Anyone one know of an AI that can answer this for me?",
                  "score": 5,
                  "created_utc": "2026-02-05 14:47:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3q421h",
          "author": "LoveThemMegaSeeds",
          "text": "If you really have 200 subscriptions per month, then you are retarded and I definitely don‚Äôt want to buy anything you are selling",
          "score": 11,
          "created_utc": "2026-02-05 14:52:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pqsxu",
          "author": "Kaenguruu-Dev",
          "text": "Yes you could use AI, or you could just have hard limits that you define once and trigger alerts based on maths and you're done.",
          "score": 24,
          "created_utc": "2026-02-05 13:41:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qjbzj",
              "author": "Ok-Interaction-8891",
              "text": "But then they wouldn‚Äôt have an AI project to link and share!",
              "score": 7,
              "created_utc": "2026-02-05 16:06:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pq8kz",
          "author": "IllustratorOk7590",
          "text": "the fact that 15% of vendors can overcharge and nobody notices is crazy, 200+ subscriptions no human can track that. This feels like something every startup will need eventually, thanks for sharing",
          "score": 30,
          "created_utc": "2026-02-05 13:37:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ptfk0",
              "author": "General-Put-4991",
              "text": "If you buy subscriptions for everything and don't check them, it's normal",
              "score": 7,
              "created_utc": "2026-02-05 13:55:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3prmdl",
          "author": "Critical_Cod_2965",
          "text": "this is one of the more practical ML applications I‚Äôve seen posted here, great one",
          "score": 3,
          "created_utc": "2026-02-05 13:45:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pr1n6",
          "author": "ComfortableHot6840",
          "text": "Lk this could be a SaaS product. Startups bleeding money on tool sprawl is universal. Automated anomaly detection + subscription auditing would sell instantly to finance teams",
          "score": 5,
          "created_utc": "2026-02-05 13:42:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3psqnp",
              "author": "Dangerous_Formal_870",
              "text": "100% agree this smells like a SaaS opportunity, CFOs would absolutely pay for automated subscription auditing. It‚Äôs one of those boring problems",
              "score": 2,
              "created_utc": "2026-02-05 13:52:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pt2xp",
              "author": "Curious_Key2609",
              "text": "Yeah finance teams would eat this up",
              "score": 2,
              "created_utc": "2026-02-05 13:53:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pv0sn",
              "author": "slightlyintoout",
              "text": "It would be great if it also covered cloud spend (as well as individual subscriptions). Similar issue - sign up for some subscription you don't use but never cancel vs spin up some cloud service and then don't spin it down. There are already some tools for the cloud stuff but 'all in one' would be great\n\nI wonder what % of AWS/Google/MS revenue is redundant cloud spend. I bet it is $$$$$$$.",
              "score": 1,
              "created_utc": "2026-02-05 14:04:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3prej8",
          "author": "Capable-Pool759",
          "text": "You used this AI aagentfor a painfully real problem, very smart 6k/month leakage is the kind of thing founders lose sleep over",
          "score": 2,
          "created_utc": "2026-02-05 13:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pxglu",
          "author": "raakas",
          "text": "Sorry off the topic but how did you get those charts? Monarch?",
          "score": 1,
          "created_utc": "2026-02-05 14:18:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pylc7",
          "author": "donotfire",
          "text": "For real how do you even spend that much monthly on subscriptions",
          "score": 1,
          "created_utc": "2026-02-05 14:24:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q2f4v",
          "author": "tennisanybody",
          "text": "I don‚Äôt understand why people don‚Äôt use an empty debit card to sign up for subscriptions. I want the transaction to fail. You want to be reminded you‚Äôre paying monthly for something. Set and forget is a horrible mindset! Never put recurring charges on a credit card. Those fuckers will do any and everything to make sure a charge goes through!\n\nEDIT: if you‚Äôre in the US, cashapp, venmo, paypal all offer debit cards. Use one of them and have $1 sitting there for ‚Äúvalidation‚Äù.",
          "score": 1,
          "created_utc": "2026-02-05 14:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q31wq",
          "author": "churninbutter",
          "text": "This is really cool, would you mind sharing it with me? I‚Äôd like to mess around with it",
          "score": 1,
          "created_utc": "2026-02-05 14:47:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q3n4d",
          "author": "mpaes98",
          "text": "Many vendors know they are over charging and take the calculated risk that you‚Äôll either not notice or not go through the hassle of fixing it.",
          "score": 1,
          "created_utc": "2026-02-05 14:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qtssj",
          "author": "joshuaherman",
          "text": "I work at an anti fraud company and it is not something you would to roll yourself.",
          "score": 1,
          "created_utc": "2026-02-05 16:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pqjok",
          "author": "DecentVast7649",
          "text": "what heyneo is doing under the hood. Is it just wrapping standard models or actually running agent-style retraining and feature engineering? Haven‚Äôt seen it used before.",
          "score": 0,
          "created_utc": "2026-02-05 13:39:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qul8t5",
      "title": "Transformer Co-Inventor: \"To replace Transformers, new architectures need to be obviously crushingly better\"",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/ovgdl1e4e7hg1",
      "author": "Tobio-Star",
      "created_utc": "2026-02-03 07:08:08",
      "score": 102,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qul8t5/transformer_coinventor_to_replace_transformers/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3c66ez",
          "author": "terem13",
          "text": "Yep, and combined with current AI bubble it creates perpetual cycle of inflating current models, instead of pursuing another architectures, for example Mamba and its successors.\n\nEmergent features of transformers are known and there are lots of crutches invented to compensate transformer deficiencies, to keep models inflating.\n\nOpenAI is a best example of such deeply flawed approach: they literally sat on piles of cash up until Google appeared with their transformer algorithm.",
          "score": 23,
          "created_utc": "2026-02-03 13:26:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d7f4i",
              "author": "Tobio-Star",
              "text": "Oh there have been more interesting ideas than even Mamba!",
              "score": 7,
              "created_utc": "2026-02-03 16:34:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3csu79",
          "author": "lordnacho666",
          "text": "What are some keywords for these better architectures?",
          "score": 9,
          "created_utc": "2026-02-03 15:25:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e9ev6",
              "author": "Tobio-Star",
              "text": "I can't speak for the interviewee and tell you the exact architectures he was referring to, but I post articles about as many interesting and novel architectures as I can find on r/newAIParadigms \n\nOff the top of my head I think Titans and Atlas might qualify? (although they do feature elements from Transformers)",
              "score": 6,
              "created_utc": "2026-02-03 19:28:11",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3f8iff",
              "author": "Emotional_Thanks_22",
              "text": "continuous thought machines is one of their publications, could be interesting in the future maybe? (haven't fully read it). but transformer is still going to stay for a few years+",
              "score": 1,
              "created_utc": "2026-02-03 22:11:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3fs89d",
          "author": "RJSabouhi",
          "text": "Everyone keeps trying to beat Transformers at their own game, which is growing tiresome: bigger context, faster attention, etc. It‚Äôs the fact that Transformers don‚Äôt actually reason which necessitates a new approach.\n\nWith no long-term internal state, no phase structure, no drift correction, no symbolic consistency. The replacement won‚Äôt even look like a Transformer at all. It‚Äôll be more like a system with operators, phases, and persistent internal dynamics. A reasoning engine built on top of representation.",
          "score": 4,
          "created_utc": "2026-02-03 23:55:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hr2pd",
              "author": "Tobio-Star",
              "text": "Interesting, can you tell more about your vision? Is it a deep learning approach at all? Something completely new?",
              "score": 1,
              "created_utc": "2026-02-04 07:31:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3egyy4",
          "author": "JackandFred",
          "text": "Really great video, haven‚Äôt seen this podcast before but touches on what so many people have been saying.",
          "score": 3,
          "created_utc": "2026-02-03 20:03:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f09in",
          "author": "NightmareLogic420",
          "text": "Does he discuss what these new architectures are?",
          "score": 2,
          "created_utc": "2026-02-03 21:33:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quizvt",
      "title": "[Keras] It was like this for 3 months........",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/wogjyb9ep7hg1.png",
      "author": "lamogpa",
      "created_utc": "2026-02-03 05:04:51",
      "score": 99,
      "num_comments": 9,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quizvt/keras_it_was_like_this_for_3_months/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3akeze",
          "author": "jonsca",
          "text": "Everyone underestimates that whole \"understand what you're doing\" thing these days.",
          "score": 90,
          "created_utc": "2026-02-03 05:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ap8pz",
              "author": "chaitanyathengdi",
              "text": "\"ChatGPT, do this for me\"",
              "score": 17,
              "created_utc": "2026-02-03 05:58:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3bxubr",
                  "author": "Mad_Chemistry",
                  "text": "I was trying to learn multi threading and asked gpt to suggestions on how to optimize my code. It put loading the model inside a fucking loop that select each data. Smh",
                  "score": 4,
                  "created_utc": "2026-02-03 12:33:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3almak",
              "author": "ToSAhri",
              "text": "I feel that.",
              "score": 3,
              "created_utc": "2026-02-03 05:29:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3anmf4",
          "author": "intruzah",
          "text": "Vibe coding amrite",
          "score": 24,
          "created_utc": "2026-02-03 05:45:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bwni7",
          "author": "PixelLight",
          "text": "If I'm understanding, they loaded the model for every single prediction? They need to learn python is about the politest way I can put this.",
          "score": 16,
          "created_utc": "2026-02-03 12:25:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3doan5",
          "author": "SweetSure315",
          "text": "This is the ML version of \"add a 30 second wait so you can change it to 15 seconds and claim a 100% performance boost\"",
          "score": 7,
          "created_utc": "2026-02-03 17:52:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b75dz",
          "author": "Visual-Run-4718",
          "text": "I‚Äôm not even in ML and yet I could figure out that was dumb",
          "score": 11,
          "created_utc": "2026-02-03 08:39:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqk5rl",
      "title": "Just finished a high-resolution DFM face model (448px), of the actress elizabeth olsen",
      "subreddit": "learnmachinelearning",
      "url": "https://v.redd.it/jo2e45h2mcgg1",
      "author": "Emergency_Pause1678",
      "created_utc": "2026-01-29 20:32:08",
      "score": 94,
      "num_comments": 27,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqk5rl/just_finished_a_highresolution_dfm_face_model/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2j4v23",
          "author": "BigDaddyPrime",
          "text": "The original and swapped kinda looks the same.",
          "score": 102,
          "created_utc": "2026-01-30 02:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l0hxx",
          "author": "ShelZuuz",
          "text": "Does this only work for identical twins?",
          "score": 43,
          "created_utc": "2026-01-30 11:09:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l2m7z",
              "author": "Emergency_Pause1678",
              "text": "works for al types of faces",
              "score": -3,
              "created_utc": "2026-01-30 11:27:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30m7qg",
                  "author": "jakeStacktrace",
                  "text": "Just like mirrors.",
                  "score": 1,
                  "created_utc": "2026-02-01 18:46:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2m8yiv",
          "author": "peenismane",
          "text": "I honestly don't understand what the purpose of this when left and right just look like the same video",
          "score": 14,
          "created_utc": "2026-01-30 15:28:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p3opb",
              "author": "peenismane",
              "text": "Like does this generate a model that allows the face input to be anybody's face and they can then \"look like them\" deep fake?",
              "score": 2,
              "created_utc": "2026-01-30 23:25:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kdvi6",
          "author": "genserismyname",
          "text": "who does this serve purpose? genuinely asking.",
          "score": 13,
          "created_utc": "2026-01-30 07:47:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nem2f",
              "author": "SuperMegaOwl2",
              "text": "Well Besides the obvious... It could be used to recast movies or keep the likeness of said actors around even after They're gone, but that's my thought",
              "score": 6,
              "created_utc": "2026-01-30 18:33:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2orbne",
                  "author": "Affectionate-Let3744",
                  "text": "Both horrible horrible ideas\n\nGood luck to any future actors when companies can just rent a variety of old A/B/C listers for cheap and with absolutely no scheduling or on-set issues. They'll just keep using the faces that sell already",
                  "score": 4,
                  "created_utc": "2026-01-30 22:20:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2qu0rb",
                  "author": "genserismyname",
                  "text": "I dont see the \"obvious\" purpose your preaching about. It's not useful. Recast movies? Are you forreal now. And keeping the likeness of someone who's dead around you just because what? You can't live without elizabeth olsen? It's trash, doesn't server purpose, plus DID YOU ASK ELIZBETH OLSEN WOULD SHE WANT THAT? no. so then shut the hell up, this is stupid idea that's gonna get abused for money or something worse, and that's all it's gonna be.",
                  "score": 1,
                  "created_utc": "2026-01-31 05:50:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2k2859",
          "author": "CollectionGuilty1320",
          "text": "Porn industry üìà",
          "score": 24,
          "created_utc": "2026-01-30 06:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m23w9",
          "author": "johnfkngzoidberg",
          "text": "This looks terrible.",
          "score": 5,
          "created_utc": "2026-01-30 14:56:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2leg7e",
          "author": "thatpizzatho",
          "text": "Hi, I'm working in AI research since 2016 because I think that there are some super cool and important applications of AI (protein discovery, healthcare, some *but not all* applications in the creativity industry, potentially robotics and self-driving, etc). Some other applications are less exciting because they have the potential to be misused. Tbf anything has the potential to be misused, but some more than others. Deep fakes is one of those things. This is not to say that the technology behind it (the maths and the engineering) is not exciting. It is! But the actual implementation of those cool ideas is potentially harmful, so when learning it's important to keep that in mind",
          "score": 15,
          "created_utc": "2026-01-30 12:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r5frl",
              "author": "redditownersdad",
              "text": "Ethics you mean",
              "score": 0,
              "created_utc": "2026-01-31 07:28:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2k0cs2",
          "author": "recursion_is_love",
          "text": "Can I request Arnold Schwarzenegger ?",
          "score": 1,
          "created_utc": "2026-01-30 05:56:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kumym",
              "author": "Emergency_Pause1678",
              "text": "sure",
              "score": 1,
              "created_utc": "2026-01-30 10:19:23",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2ocfdy",
              "author": "Pickymarker",
              "text": "No need don't reccomend requests from him he just is starting when others like me have been making dfms for a while there is already like 5 Arnold models already",
              "score": -1,
              "created_utc": "2026-01-30 21:09:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2l1qrb",
          "author": "DeepInEvil",
          "text": "Do you have a link to the model?",
          "score": 1,
          "created_utc": "2026-01-30 11:20:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oci2y",
              "author": "Pickymarker",
              "text": "I do might make it public on my discord server soon",
              "score": 0,
              "created_utc": "2026-01-30 21:09:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2pdrn3",
          "author": "CorpusculantCortex",
          "text": "After I read that it was supposed to be Elizabeth Olsen I kinda thought I saw the woman looked vaguely like her for a fraction of a second. But when I kept watching i honestly had a hard time noticing any differences in the side by side. Im no expert but I think this still needs work.",
          "score": 1,
          "created_utc": "2026-01-31 00:20:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r5afi",
          "author": "redditownersdad",
          "text": "You da real olsen",
          "score": 1,
          "created_utc": "2026-01-31 07:27:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hcpam",
          "author": "valkiii",
          "text": "Do you have a repo to share?",
          "score": 1,
          "created_utc": "2026-01-29 21:02:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ilckq",
              "author": "Pickymarker",
              "text": "This guy is just starting off and this is not his model it's this other guy's I know",
              "score": 8,
              "created_utc": "2026-01-30 00:50:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2nxsen",
          "author": "Chelokot",
          "text": "People saying left and right look the same have zero comprehension of human faces",
          "score": -3,
          "created_utc": "2026-01-30 19:59:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k19nz",
          "author": "2reform",
          "text": "Next Elle Fanning please",
          "score": -8,
          "created_utc": "2026-01-30 06:03:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvv965",
      "title": "You probably don't need Apache Spark. A simple rule of thumb.",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qvv965/you_probably_dont_need_apache_spark_a_simple_rule/",
      "author": "IT_Certguru",
      "created_utc": "2026-02-04 17:42:54",
      "score": 78,
      "num_comments": 11,
      "upvote_ratio": 0.92,
      "text": "I see a lot of roadmaps telling beginners they MUST learn Spark or Databricks on Day 1. It stresses people out.\n\nAfter working in the field, here is the realistic hierarchy I actually use:\n\n1. Pandas: If your data fits in RAM (<10GB). Stick to this. It's the standard.\n2. Polars: If your data is 10GB-100GB. It‚Äôs faster, handles memory better, and you don't need a cluster.\n3. Apache Spark: If you have Terabytes of data or need distributed computing across multiple machines.\n\nDon't optimize prematurely. You aren't \"less of an ML Engineer\" because you used Pandas for a 500MB dataset. You're just being efficient.\n\nIf you‚Äôre wondering when Spark actually makes sense in production, this guide breaks down real-world use cases, performance trade-offs, and where Spark genuinely adds value: [**Apache Spark**](https://www.netcomlearning.com/blog/apache-spark) \n\nDoes anyone else feel like \"Big Data\" tools are over-pushed to beginners?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qvv965/you_probably_dont_need_apache_spark_a_simple_rule/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3kh75c",
          "author": "Sen_ElizabethWarren",
          "text": "Tell that to hiring managers",
          "score": 36,
          "created_utc": "2026-02-04 17:52:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3n4j3p",
              "author": "SizePunch",
              "text": "Literally got rejected from a job explicitly because i didn‚Äôt know pyspark well enough. Still sick.",
              "score": 6,
              "created_utc": "2026-02-05 01:50:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kk5mo",
          "author": "Expensive_Culture_46",
          "text": "This goes for like everything. \n\nNo one needs airflow for a single python script that operates on a file that is 700k.",
          "score": 28,
          "created_utc": "2026-02-04 18:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ldqn1",
              "author": "DoctorDabadedoo",
              "text": "I'm facing that right now. Joined a scale up company. Lots of bad design decisions from the past while it was growing, they have started developing some airflow workflows to process some assets and \"future proof\" it, but the volume is not there yet to justify it and development speed is crawling to a stop.\n\nUsing it as glorified Cron with UI it's an overkill for what we have.",
              "score": 2,
              "created_utc": "2026-02-04 20:22:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kmfej",
          "author": "burntoutdev8291",
          "text": "Don't learn tools, but do learn general data engineering patterns, even if they are small data. Learn how to get used to things like yielding and lazy iterators / evaluations. Actually by using torch dataloaders you are already learning a little about data processing, they have things like parallel workers, prefetching etc. Just my personal experience.",
          "score": 13,
          "created_utc": "2026-02-04 18:16:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3m8pkf",
          "author": "padakpatek",
          "text": "beginners learn them because those are the skills listed on job postings.",
          "score": 3,
          "created_utc": "2026-02-04 22:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ltkjc",
          "author": "popcorn-trivia",
          "text": "Great advice. Hope this makes it around.",
          "score": 2,
          "created_utc": "2026-02-04 21:38:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o5714",
          "author": "Glittering_Ice3647",
          "text": "They should learn BigQuery and SQL before touching Spark, from my experience >95% of jobs i see in Spark can be done with a simple SQL query in BQ, it runs faster, scales better and way easier to debug each step and check intermediate results by saving them in bq tables\n\n  \nAnd if they dont have access to BigQuery, and there is enough RAM use SQLLite locally, SQL is under-appreciated data manipulation and analysis tool\n\nSpark is only useful for iterative optimization at scale, but those kinds of jobs are better run on GPUs anyway",
          "score": 2,
          "created_utc": "2026-02-05 05:42:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3me466",
          "author": "CatOfGrey",
          "text": "I'm much lower on this scale, so I'll throw in a lower-level tip: \n\nYou don't even need to use Pandas with Sci-anything or TensorAnything, if some version of a linear model will be helpful!",
          "score": 1,
          "created_utc": "2026-02-04 23:22:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o840l",
          "author": "Commercial-Fly-6296",
          "text": "I thought you cannot use Deep Learning on spark ? Is it available now ?",
          "score": 1,
          "created_utc": "2026-02-05 06:05:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ovws8",
          "author": "AccordingWeight6019",
          "text": "I mostly agree with the spirit of this. In practice, the decision is less about identity as an ML engineer and more about where complexity actually pays for itself. Distributed systems come with real cognitive and operational overhead, and beginners often underestimate that cost. for many problems, local tooling lets you iterate faster and reason more clearly about what the data is doing. spark makes sense when the problem forces your hand, not because a roadmap says it is a prerequisite. I do think it is useful to understand why these systems exist, but that is different from using them by default.",
          "score": 1,
          "created_utc": "2026-02-05 09:45:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qs1588",
      "title": "10 GitHub Repositories to Ace Any Tech Interview",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "author": "kingabzpro",
      "created_utc": "2026-01-31 12:30:32",
      "score": 74,
      "num_comments": 1,
      "upvote_ratio": 0.87,
      "text": "The most trusted GitHub repositories to help you master coding interviews, system design, backend engineering, scalability, data structures and algorithms, and machine learning interviews with confidence.\n\n\n\nLink: [https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview](https://www.kdnuggets.com/10-github-repositories-to-ace-any-tech-interview)",
      "is_original_content": false,
      "link_flair_text": "Career",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qs1588/10_github_repositories_to_ace_any_tech_interview/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2wfh9o",
          "author": "Southern-Common-2715",
          "text": "Wow",
          "score": 1,
          "created_utc": "2026-02-01 02:18:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quqm08",
      "title": "Interview said you dont need a lot of data to train RNN?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1quqm08/interview_said_you_dont_need_a_lot_of_data_to/",
      "author": "IndependenceThen7898",
      "created_utc": "2026-02-03 12:27:26",
      "score": 66,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "Hey,\n\nI had an interview with a consulting company as a data scienctist. They gave me a case for voice recignition to detect a word like ‚Äûhello‚Äú in a 10 second audio.\n\nI recommended to use a cnn. I said for a starting point to collect data we would need around 200 speakers. \n\nThey told me in the interview a cnn is overkill and they expected me to say RNN. And said for a rnn you only need a few collegues like 20 max? I dont believe this is true. Am I wrong and why should i not use a cnn. \n\nThe case asked for a model that is not trained with internet data.  ",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quqm08/interview_said_you_dont_need_a_lot_of_data_to/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3c0z3c",
          "author": "Aswarin",
          "text": "Honestly, interviewer sounds like they didn't know what they're talking about. The above description to me sounds like standard binary classification problem e.g. is the word in this snippet \"hello\" which is easily solveable via a CNN\n\nLike you need no context at all for the above task I could literally say in my 10 second of audio \"blah blah blah hello blah blah blah\" and the \"blahs\" do not help me identify the \"hello\".\n\nWith regards to the 20 vs 200 speakers depends on if they want to generalize across genders, accents, diction etc. If it's one accent in a controlled environment, I could see 20 being good enough. But yeah, youre right to be skeptical",
          "score": 70,
          "created_utc": "2026-02-03 12:54:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c1a52",
              "author": "IndependenceThen7898",
              "text": "yes it‚Äôs incredible, I even explained why i need this amount of data because of diversity, different settings",
              "score": 24,
              "created_utc": "2026-02-03 12:56:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3cb36l",
              "author": "5upertaco",
              "text": "This \\^\\^\\^",
              "score": 2,
              "created_utc": "2026-02-03 13:53:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c03ft",
          "author": "Extra_Intro_Version",
          "text": "Maybe it depends on whether they care how well the model will generalize. Or how you pick those speakers. What characteristics of voices is likely to span the space?",
          "score": 11,
          "created_utc": "2026-02-03 12:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c0a5m",
              "author": "IndependenceThen7898",
              "text": "they didnt say anything about charactistics .. that was the case: \n\nConsider the following hypothetical setup. You lead an AI project which aims to populate an AI model for identifying the activation word ‚ÄúOK Deloitte‚Äù in a ten second long audio time frame, i.e. the model input x is a ten second long audio clip and the model output y is 1 (activation word found) or 0 (activation word not found). The legal department directs you to not use training data downloaded from the internet. Assume you have all available resources in technology, infrastructure and people. Use supervised learning.",
              "score": 5,
              "created_utc": "2026-02-03 12:50:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3fuq51",
                  "author": "Hella_Sus",
                  "text": "_Assume you have all available resources in technology, infrastructure and people_ ‚Ä¶ sure, anything you say! Then from that logic for them using an RNN is no problem at all, even if we overlook the other issues like vanishing/exploding gradients.",
                  "score": 2,
                  "created_utc": "2026-02-04 00:08:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c3r9f",
          "author": "Dry_Philosophy7927",
          "text": "The bigger problem is not which answer is best justified, but the level of emphasis placed on how to find a solution. If your potential boss (or you) say that the other person has a \"wrong\" solution then the most important part of the development cycle is being short cut - there are many solutions that involve trade offs. If the project constraint is only privacy (no public data) AND money/time, maybe an RNN or a smaller dataset size is justified. If the aim is a better performing model and the budget allows then yes a larger dataset is better and yes I think a CNN would get a better result.\n\nDo you think they had right/wrong criteria fir this question? Or possibly, do you think they expected more of a discussion than you offered? It is audio possible that they're idiots.",
          "score": 8,
          "created_utc": "2026-02-03 13:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c4b5w",
              "author": "IndependenceThen7898",
              "text": "well he just said that my solution is wrong and he also said cnns are mainly used for videos and graphic data. I think he just didnt have the knowledge, but I was questioning myself after, because he simply said i‚Äôm totally wrong.",
              "score": 5,
              "created_utc": "2026-02-03 13:15:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3c4vbd",
                  "author": "Dry_Philosophy7927",
                  "text": "I hope you get another job in a reasonable time frame. Sounds like a good inaugural into working for the interviewer.\n\nFor your validation, here's a review paper literally saying both approaches have been used AND combined in this exact use case: https://arxiv.org/html/2312.05640v1",
                  "score": 11,
                  "created_utc": "2026-02-03 13:18:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3c2s33",
          "author": "Garry_Scary",
          "text": "So sometimes interviewers treat these questions as a way to see how you would react to intellectual conflict. In engineering there are so many options that ‚Äúwork‚Äù so you often have debates about what‚Äôs right. It sounds like the interviewer wanted to see how you would defend your view when an alternative view was given.\n\nThe best option in interviews like this is to admit you aren‚Äôt aware of any RNNs that do this well and treat the question like a conversation between you and a colleague.",
          "score": 9,
          "created_utc": "2026-02-03 13:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3c315e",
              "author": "IndependenceThen7898",
              "text": "I would have been open for a discussion and also did, but he basicslly said my approach is wrong and RNN is the only acceptable answer here",
              "score": 5,
              "created_utc": "2026-02-03 13:07:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ccow5",
                  "author": "AllanSundry2020",
                  "text": "did he say it in the moment, or in feedback afterwards?",
                  "score": 3,
                  "created_utc": "2026-02-03 14:02:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cl3id",
          "author": "vannak139",
          "text": "This sounds like crazy talk. I think everyone is laying out good cases for why the person asking you that might be crazy, what they may have meant. \n\nTo take another angle as devil's advocate, when they \"asked for a model that is not trained with internet data\", perhaps they meant for you to take into account pre-trained models, though it doesn't sound that way with \"no data from internet\". Maybe that's not how they see it. It might be the case that they had in mind a pre-trained model that can calibrate in 20 samples. But more likely, it seems like they might just be under the impression that more classic \"last gen\" voice recognition is recurrent in some way, when its more likely a weird knowledge graph. Maybe they're thinking of a CNN on a raw wave form, vs an RNN on a spectrograph. Idk.",
          "score": 1,
          "created_utc": "2026-02-03 14:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cupkg",
          "author": "Veggies-are-okay",
          "text": "When I encounter stupid questions during interviews, I tend to ask for clarification. If there‚Äôs no clarification, I just lay out my thought process beginning with assumptions. If there is a ‚Äúwrong,‚Äù add it to your list of assumptions and adjust on the fly. Or ask clarifying questions on why they believe this assumption is wrong.\n\nA lot of the time there‚Äôs the content but also the vibes you give. If you‚Äôre not a freaky genius that gets everything in one go, then you have to embody an ideal coworker: someone who‚Äôs proactive, can get the job done, is communicative when they run into issues/roadblocks (you will. Socially finessing your way out of those blockers is just as important of a skill as the technical), and just being a pleasant and interesting person can get you sosososo far in this industry.",
          "score": 1,
          "created_utc": "2026-02-03 15:34:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hyaua",
          "author": "s-jb-s",
          "text": "It sounds like they're pretty old school -- a lot of the field came from mixture modelling and HMMs that emerged in the 80s (think: Rabiner & others) -- later, n-grams & RNNs. If you want to go back even earlier, they were doing Dynamic Time Warping -- big emphasis on feature engineering. RNNs (LSTMs) were the gold standard until the mid-2010s, when big tech companies decided they wanted home assistants (Alexa, Siri, ...) to be a thing. Interestingly, Rabiner (HMM guy), Bengio (RNN guy), and LeCun (CNN guy) were all at Bell Labs around the same time (mostly late 80s/early 90s), with the latter two in a different department than Rabiner. All three have reasonably distinct schools of thought on the problem, but my understanding was that, post-\"The Best RNN is a CNN\", most have moved over to CNNs. Google has a bunch of good papers on this stuff, relating to keyword spotting (Sainath et al., 2015 is a good one to look at if you're interested). \n\nAs it turns out, spatial invariance with respect to spectrograms makes CNNs superior for detecting fixed patterns (think: LeCun). RNNs have many downsides; I'm sure you're aware of them. As others have said, with so little data, the model would almost certainly overfit. There's definitely some nuance (you can train an RNN on very small data sequences if you're very careful... robustness might be questionable). You can also do a lot of interesting feature extraction and data augmentation to enable small RNNs and the likes. So I would strongly argue it is possible with hard limitations. But if you can do that, just use a CNN. Maybe the interviewer wanted latency discussions? In the context of embedded devices, CNNs are still generally lighter than RNNs, unless the use case is something along the lines of streaming.",
          "score": 1,
          "created_utc": "2026-02-04 08:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jsyi0",
          "author": "HolidayAd6029",
          "text": "This so stupid. There is no right or wrong answer here, because this depends a lot on the dataset. There is no theory to back the statement that an RNN is better or that it requires less data. In practice, implementing a CNN is not much different from implementing a RNN. You could probably train both and see which one is better.",
          "score": 1,
          "created_utc": "2026-02-04 16:01:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lm9m8",
          "author": "Ty4Readin",
          "text": "I don't think there is necessarily a right or wrong answer here.\n\nDo you need a training set containing 20 speakers or 200 speakers? I honestly have no clue lol, depends on a lot of factors such as which model you train, how many samples from each speaker, the actual use case and distribution of users, required levels of accuracy/performance, etc.\n\nSame idea with CNN vs RNN. It is hard to say which will definitely perform better or be better for the use case without a lot more context.\n\nHowever, to be fair, I generally lean towards CNN. On a problem like this, I would guess that CNN will probably perform better and likely requires less training data than RNN.\n\nBut it's not a hill I am going to die on. If I have a coworker that is adamant about RNN, I'm willing to experiment with both and we can see which actually performs better.\n\nHowever, the fact that the interviewer was so adamant that \"CNN is wrong, RNN is right\" is a big red flag anyways, so you probably did dodge a bullet.",
          "score": 1,
          "created_utc": "2026-02-04 21:03:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cw4h6",
          "author": "Buster_Sword_Vii",
          "text": "You could generate your data set. Use Elevenlabs or Qwen TTS or vibe voice to generate 200 samples containing \"hello\". Qwen has a model that can generate unique voices, so with some effort you could have a diverse sample size. CNN is the right call for this problem. Obviously generalization on synthetic data isn't going to be as good as real data, but if participant size is a limitation it's a solid work around.",
          "score": 0,
          "created_utc": "2026-02-03 15:41:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qspkjb",
      "title": "Day 2 of Machine Learning",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/gallery/1qspkjb",
      "author": "Rare-Variety-1192",
      "created_utc": "2026-02-01 05:20:52",
      "score": 61,
      "num_comments": 12,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tutorial",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qspkjb/day_2_of_machine_learning/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ap14z",
          "author": "bethebetter",
          "text": "Even i  am learning the same with Google free ml course",
          "score": 3,
          "created_utc": "2026-02-03 05:56:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2yfiwx",
          "author": "StrikingBeautiful558",
          "text": "Which platform is this?",
          "score": 2,
          "created_utc": "2026-02-01 11:48:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yocn7",
              "author": "Rare-Variety-1192",
              "text": "thinktube",
              "score": 1,
              "created_utc": "2026-02-01 12:56:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30zdwd",
                  "author": "smuhamm4",
                  "text": "Beginner friendly ?",
                  "score": 1,
                  "created_utc": "2026-02-01 19:47:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3339di",
          "author": "2exxgr",
          "text": "What is the name of the program used to take notes on the right, it looks nice",
          "score": 1,
          "created_utc": "2026-02-02 02:25:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33sqc5",
              "author": "Rare-Variety-1192",
              "text": "Thinktube",
              "score": 2,
              "created_utc": "2026-02-02 05:03:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o334s3b",
              "author": "DazzedXI",
              "text": "I also second that",
              "score": 1,
              "created_utc": "2026-02-02 02:34:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3cysj7",
          "author": "Worried_Mud_5224",
          "text": "The language is the problem",
          "score": 1,
          "created_utc": "2026-02-03 15:54:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kdz40",
          "author": "Feeling_Tie2192",
          "text": "I am also learning from the same teacher; he is a great personality and a great teacher ",
          "score": 1,
          "created_utc": "2026-02-04 17:38:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtxbns",
      "title": "I learned why cosine similarity fails for compatibility matching",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "author": "Ok_Promise_9470",
      "created_utc": "2026-02-02 15:00:17",
      "score": 60,
      "num_comments": 25,
      "upvote_ratio": 0.8,
      "text": "I've been helping friends build the matching system for their dating app, Wavelength. Wanted to share a lesson I learned the hard way about embedding-based matching  might save someone else the same mistake.\n\n**The approach**: Embed user profiles via LLM into 1536-dim vectors, store in Pinecone, query with ANN + metadata filters. Sub-200ms, scales well, semantically smart ‚Äî \"loves hiking\" matches \"outdoor enthusiast\" automatically.\n\n**What went wrong**: 22% mutual acceptance rate. I audited the rejected high-scoring matches and found this:\n\n    User A: \"Career-focused lawyer, wants kids in 2 years, monogamy essential\"\n    User B: \"Career-focused consultant, never wants kids, open relationship\"\n    \n    Cosine similarity: 0.91\n    Reality: incompatible on two dealbreakers\n    \n\nEmbeddings captured¬†*how someone describes their life*, tone, topic, semantic texture. They completely missed¬†*what someone actually needs*, the structured preferences buried in the prose.\n\nThis wasn't an edge case. It was the dominant failure mode. High similarity, fundamental incompatibility. Two people who sounded alike but wanted completely different things.\n\n**The lesson**: Embedding similarity is necessary but not sufficient for compatibility. If your domain has dealbreakers, hard constraints where incompatibility on a single dimension overrides overall similarity, you need structured signal extraction on top.\n\n**What I did instead**¬†(brief summary):\n\n1. Extracted 26 structured features from natural AI conversations (not surveys, 30% survey completion vs 85% conversational extraction)\n2. Built distance matrices: nuanced compatibility scores (0.0-1.0) instead of binary match/no-match\n3. Added hard filters: 4 dealbreaker features that reject pairs before scoring, zero exceptions\n4. Combined signals:¬†`0.25 √ó text + 0.15 √ó visual + 0.60 √ó features`\n\n22% to 35% with this. Two more stages (personalized weights + bidirectional matching) took it to 68%.\n\nThis generalizes beyond dating; job matching (remote vs on-site is a dealbreaker regardless of skill similarity), marketplace matching (budget overrides preference), probably others.\n\nHas anyone else hit this wall with embeddings? Curious how others handle the structured-vs-semantic tradeoff.\n\nEdit:\nI know how training a biencoder on pairwise data would help, but mining hard negatives in such cases becomes a key challenge and also loses bidirectional non equivalence of liking one another ",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qtxbns/i_learned_why_cosine_similarity_fails_for/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o36ijqm",
          "author": "-Cubie-",
          "text": "If you want a different definition of similarity, then you should finetune your embedding model.\nThe finetuning docs for sentence transformers has a similar example as you, where different systems might consider a certain pair of texts very similar or very dissimilar: https://sbert.net/docs/sentence_transformer/training_overview.html",
          "score": 26,
          "created_utc": "2026-02-02 16:38:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36m0mf",
              "author": "Ok_Promise_9470",
              "text": "I agree thats a fair point, finetuning on accept/reject pairs would definitely improve retrieval quality and it's something we've considered for the candidate generation step (the Pinecone layer, and finetuning is in progress). The reason we added structured features on top is that even a perfect embedding can't handle three things: \n\n(1) hard dealbreakers that should veto an otherwise-great match, \n\n(2) asymmetric scoring where A‚ÜíB ‚â† B‚ÜíA because users weight features differently, and \n\n(3) interpretability for the feedback loop. \n\nThe embedding narrows 10K users to 10 candidates, the structured layer decides which of those 10 actually has mutual potential.",
              "score": 7,
              "created_utc": "2026-02-02 16:54:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37u6y0",
                  "author": "saw79",
                  "text": "You know more than I do here, so correct me where I'm wrong. But your reasoning doesn't strike me as quite right:\n\n1) Shouldn't hard dealbreakers make the model reduce the cosine similarity significantly? Isn't this an embedding problem? A bad embedding doesn't mean embeddings are bad.\n\n2) I understand that how person A feels about person B doesn't have to match how person B feels about person A, but that isn't what you're trying to estimate. You're trying to estimate the compatibility between A and B, which in my mind IS symmetric. \"are A and B compatible?\" should give the same answer as \"are B and A compatible?\".\n\n3) fair enough :)",
                  "score": 2,
                  "created_utc": "2026-02-02 20:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o377qoo",
          "author": "youniquest",
          "text": "Interesting discussion but the title is misleading. It's not cosine similarity that is failing but rather the embeddings or vector representations of your input. If you have hard dealbreakers another simple approach could be adding a new dimension where two sides of deals breakers have negative values of each other with appropriate weights depending on how important those deal breakers for the user.",
          "score": 13,
          "created_utc": "2026-02-02 18:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38d11p",
              "author": "Substantial_Oil_7421",
              "text": "I agree with this. Your post is interesting but misleading - cosine similarity is not at fault here, the input is. You got a high score because of common tokens; it won‚Äôt pick up the nuance or semantic meaning well.\n\nAlso saw your Substack post and quite frankly, calling things ‚Äúthe embedding trap‚Äù is just a poor choice of words. You can fool a generalist or a strategy person with this kind of fluff but experienced data scientists will catch it quite easily. Didn‚Äôt read beyond that heading",
              "score": 2,
              "created_utc": "2026-02-02 21:46:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o38k0l7",
                  "author": "unlikely_ending",
                  "text": "Too harsh\n\nDon't assume bad faith",
                  "score": 4,
                  "created_utc": "2026-02-02 22:20:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o39cuxn",
                  "author": "Ok_Promise_9470",
                  "text": "I can understand your frustration here, but the reason I was talking about cosine similarity is because of the following reasons\n1) model isn't finetuned on dating data of personal\n2) it is a cold start problem so taking off the shelf models seems like a fair choice initially hence the embedding trap\n3) even finetuned embeddings can get you the right top 10 I.e improve your recall over the search space but at the end you need a reranker that views each user differently \n4) reducing it to just 1 number throws interpretability out of the window\n\n\nI hope these make sense to you, as these are some points I have further focused on in the substack article",
                  "score": 0,
                  "created_utc": "2026-02-03 00:54:23",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o37id9k",
              "author": "Ok_Promise_9470",
              "text": "1. We didnt have that data (dealbreakers) at the start - had to be mined\n2. We need to have a cold start approach to solving it,\n \nso making such simpler approaches only makes sense with the assumption that i have every data point for each user at the start itself, the easiest way to filter similar users was using a user description that we generated post user on-boarding, and that did contain dealbreakers for some but for others it had to be mined using post date feedbacks. Then we used this summary (which kept updating), we used off the shelf pretrained embeddings to start with to do initial filtering of users for finding suitable match (not the best of the methods I agree) but thats where we started",
              "score": 1,
              "created_utc": "2026-02-02 19:21:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36nh6w",
          "author": "No-Square8182",
          "text": "The stable marriage problem has non ML algos that should be employed once you get the scores. The problem is model choice. Semantic dot product is not strong enough. I think training a deep NN of person 1 features against peron 2 features labeled with match or not to output compatibility score is a good aproach. That way you dont need hard rules of fundamental incompatibility that are perhaps not fully statistically viable. I think there is a danger of modeling the probability of a match as independent probabilities from both sides, it is a strong assumption to make.",
          "score": 8,
          "created_utc": "2026-02-02 17:00:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36qg3m",
              "author": "Ok_Promise_9470",
              "text": "Yeah we are attempting to create KGs of features and represent users as subgraphs and then using sub graph embeddings to model pairwise compatibility",
              "score": 2,
              "created_utc": "2026-02-02 17:14:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36mnms",
          "author": "Thick-Protection-458",
          "text": "Well, similar topic makes similar embeddings with default embedder. Who could know.\n\n\nAnyway still can be useful as a preliminary filter before smarter approach.\n\n\nAlso, did you tried finetune embber? Like make sure it, instead of placing them close because of being mentioned in similar context - place such dealbreaker phrases far?",
          "score": 4,
          "created_utc": "2026-02-02 16:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36nmdf",
              "author": "Ok_Promise_9470",
              "text": "Yeah, as we progress and get more data on mutual matches then there'd be enough data to train the biencoder. Thats the plan, however mining hard negatives is still a big challenge",
              "score": 2,
              "created_utc": "2026-02-02 17:01:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36f88e",
          "author": "hc_fella",
          "text": "A post on smarter LLM embeddings could be interesting, but both the Reddit and Substack post reek of AI generated slop... If you want me to read your stuff, at least put in the effort of writing the posts yourself...",
          "score": 12,
          "created_utc": "2026-02-02 16:23:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36hnky",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -5,
              "created_utc": "2026-02-02 16:34:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o36nrqs",
                  "author": "theGamer2K",
                  "text": "Don't want to read the vomit worthy AI writeup. Doesn't matter if you \"only used AI to clean up and format\". It sounds like the average AI slop post on LinkedIn.",
                  "score": 3,
                  "created_utc": "2026-02-02 17:02:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o36ozri",
          "author": "Few_Detail9288",
          "text": "Ai slop",
          "score": 9,
          "created_utc": "2026-02-02 17:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37fxoe",
          "author": "PM_ME_CALC_HW",
          "text": "Why use cosine similarity with nominal data? Forget about NN and other fancy things for a moment. What's the justification?",
          "score": 2,
          "created_utc": "2026-02-02 19:10:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37hcfe",
              "author": "Ok_Promise_9470",
              "text": "The on-boarding data was conversational data between our AI and the user, it was not meant to feel like filling a survey, hence its not nominal in its nature",
              "score": 1,
              "created_utc": "2026-02-02 19:16:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o37o3tl",
                  "author": "PM_ME_CALC_HW",
                  "text": "Excuse my ignorance, but why not have them fill out a profile?",
                  "score": 2,
                  "created_utc": "2026-02-02 19:48:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3at95v",
          "author": "InfuriatinglyOpaque",
          "text": "Might be beneficial to dig into existing research on similarity and romantic relationships, and then use what you find to inform data used to compute your embeddings. \n\nFrom, A., Diamond, E., Kafaee, N., Reynaga, M., Edelstein, R. S., & Gordon, A. M. (2025). **Does similarity matter? A scoping review of perceived and actual similarity in romantic couples.** Journal of Social and Personal Relationships, 02654075251349720.\n\nRentzsch, K., Columbus, S., Balliet, D., & Gerlach, T. M. (2022). **Similarity in situation perception predicts relationship satisfaction.**¬†*Personality Science*,¬†*3*(1), e8007.\n\nTidwell, N. D., Eastwick, P. W., & Finkel, E. J. (2013). **Perceived, not actual, similarity predicts initial attraction in a live romantic context: Evidence from the speed‚Äêdating paradigm.**¬†*Personal Relationships*,¬†*20*(2), 199-215.\n\nMontoya, R. M., Horton, R. S., & Kirchner, J. (2008). **Is actual similarity necessary for attraction? A meta-analysis of actual and perceived similarity.**¬†*Journal of Social and Personal Relationships*,¬†*25*(6), 889-922.\n\nSels, L., Ruan, Y., Kuppens, P., Ceulemans, E., & Reis, H. (2020). **Actual and perceived emotional similarity in couples‚Äô daily lives.**¬†*Social Psychological and Personality Science*,¬†*11*(2), 266-275\n\nLee, T. H., & Ng, T. K. (2024). **Perceived general similarity and relationship satisfaction: The role of attributional confidence.**¬†*European Journal of Social Psychology*,¬†*54*(6), 1266-1279.",
          "score": 2,
          "created_utc": "2026-02-03 06:31:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b2ltu",
              "author": "Ok_Promise_9470",
              "text": "looks like a good reading week for me, Thankyou!",
              "score": 1,
              "created_utc": "2026-02-03 07:55:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3c5ka7",
          "author": "elgrandetotto10",
          "text": "Great lesson. Cosine similarity captures vibe and wording, not constraints, so hard dealbreakers slip through. Adding structured features and hard filters on top of embeddings is exactly the right move for real compatibility problems.",
          "score": 2,
          "created_utc": "2026-02-03 13:22:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35y95x",
          "author": "Ok_Promise_9470",
          "text": "I wrote up the full four-stage journey if anyone wants the details: [https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want](https://themlnerd.substack.com/p/why-the-girl-you-want-doesnt-want)",
          "score": -2,
          "created_utc": "2026-02-02 15:02:13",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1quznum",
      "title": "Lovable + Neo just killed software development",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/axo7qly0nbhg1.png",
      "author": "No-Writing-334",
      "created_utc": "2026-02-03 18:18:26",
      "score": 50,
      "num_comments": 20,
      "upvote_ratio": 0.6,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1quznum/lovable_neo_just_killed_software_development/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3dx96x",
          "author": "Curious_Key2609",
          "text": "A lot of these LLM startups underestimate how quickly model capabilities converge. If your product advantage depends purely on prompt engineering, you‚Äôre sitting on sand. Durable value probably comes from distribution+domain specific data+workflow",
          "score": 20,
          "created_utc": "2026-02-03 18:32:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e7a2x",
          "author": "towcar",
          "text": "Sorry what does this have to do with learning ML?",
          "score": 10,
          "created_utc": "2026-02-03 19:18:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ejmqm",
              "author": "PoolZealousideal8145",
              "text": "Plus 1000000",
              "score": 4,
              "created_utc": "2026-02-03 20:16:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e1swy",
          "author": "Robot-Roosters",
          "text": "Lovable, Neo, Base44 are all LLM Wrappers lol",
          "score": 8,
          "created_utc": "2026-02-03 18:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hr1p7",
              "author": "Salty_Mouse_7586",
              "text": "This whole post is clearly just astroturf marketing for Neo. I see a lot of bot comments shilling it. There are thousands of reddit posts talking about Loveable and Base44 but only two mentioning Neo and those are 1 year old, have no traction and were made by the founders.",
              "score": 1,
              "created_utc": "2026-02-04 07:30:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3e5b4e",
              "author": "Capable-Pool759",
              "text": "NEO isn‚Äôt a wrapper, it‚Äôs tackling entire ML pipelines from data prep to deployment, something orders of magnitude harder than spinning up a simple LLM UI",
              "score": 1,
              "created_utc": "2026-02-03 19:08:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3e58mu",
          "author": "diegoasecas",
          "text": "what can i say, i find wild that a AI calorie tracking app can raise 30M. absolute bonkers. almost money launderish.",
          "score": 7,
          "created_utc": "2026-02-03 19:08:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dyjzi",
          "author": "Dangerous_Formal_870",
          "text": "I think the hidden shift here is that we‚Äôre moving from ‚Äúcan you build?‚Äù to ‚Äúcan you converge on product/market fit faster than others?‚Äù. When tooling equalizes execution, the competitive edge becomes search strategy. The best teams are basically running structured exploration: tight feedback loops, aggressive pruning, and strong internal alignment. Most AI wrappers fail because they never close the learning loop with real users",
          "score": 3,
          "created_utc": "2026-02-03 18:38:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dz3gy",
              "author": "ImpossibleAgent3833",
              "text": "This is such a good framing. It‚Äôs less startup as artisan-craft and more startup as optimization problem now",
              "score": 1,
              "created_utc": "2026-02-03 18:40:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dzoan",
                  "author": "Critical_Cod_2965",
                  "text": "Exactly, and optimization requires measurement. I‚Äôm shocked how many AI products still don‚Äôt have proper retention dashboards beyond vanity MAU charts",
                  "score": 1,
                  "created_utc": "2026-02-03 18:43:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3dwcfd",
          "author": "General-Put-4991",
          "text": "This is an amazing time to be a builder. The cost of experimenting is collapsing, and so is the cost of learning. Even failed ideas compound into team experience. That‚Äôs a huge shift in how founder careers develop",
          "score": 4,
          "created_utc": "2026-02-03 18:28:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e2a2m",
          "author": "UnusualClimberBear",
          "text": "Your boss is clever.",
          "score": 1,
          "created_utc": "2026-02-03 18:54:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e43xr",
          "author": "ConfidentSnow3516",
          "text": "As investors, you should slash investments to a small fraction of the original. New apps won't remain incumbent for years anymore. There's no moat. It's a race to the bottom and your investments should reflect that.",
          "score": 1,
          "created_utc": "2026-02-03 19:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e69oi",
          "author": "ComfortableHot6840",
          "text": "I think neo also highlights the team first thesis you mentioned. A solo founder could hack a wrapper in a day but building something like this requires deep ML, systems engineering, data infrastructure, and careful product design. Those skills don‚Äôt commodity ize overnight. Even if tooling accelerates execution, the embedded expertise remains rare and hard to replicate",
          "score": 1,
          "created_utc": "2026-02-03 19:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ecr67",
          "author": "Stochastic_berserker",
          "text": "Absolutely agree with you, you are right. We need more AI in everything. Please find a solution to replace current login solutions with AI.\n\nAlso is there AI food and groceries? We need AI in AI",
          "score": 1,
          "created_utc": "2026-02-03 19:43:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e70om",
          "author": "DecentVast7649",
          "text": "I‚Äôm cautiously optimistic about systems like heyNEO, but agent reliability at scale is still an open problem. Autonomy demos well in controlled environments, production workloads are messy. The question is whether these systems degrade gracefully under real world entropy",
          "score": 0,
          "created_utc": "2026-02-03 19:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3e9ev4",
          "author": "WasteStore02",
          "text": "I think accelerators are right to look for teams building systems like heyNEO rather than flashy wrappers. The technical challenge isn‚Äôt generating text it‚Äôs coordinating agents, validating outputs, managing state, and integrating with messy real infrastructure. That‚Äôs closer to distributed systems engineering than prompt engineering. The skill bar is much higher",
          "score": 0,
          "created_utc": "2026-02-03 19:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hm309",
          "author": "Low-Coat-8656",
          "text": "Is Neo the one who builds you an entire ML model?",
          "score": 0,
          "created_utc": "2026-02-04 06:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hngay",
          "author": "Aspie-Py",
          "text": "Good luck. When these apps start falling apart (we have already seen examples) and there aren‚Äôt enough devs to fix them. The industry will balance out.",
          "score": 0,
          "created_utc": "2026-02-04 06:59:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr6n7l",
      "title": "Want to start Machine learning...i know the basics of python, pls help me guyss",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "author": "Different-Sell2195",
      "created_utc": "2026-01-30 14:16:59",
      "score": 44,
      "num_comments": 17,
      "upvote_ratio": 0.92,
      "text": "see i know basics of c, c++, python and R....i want to do machine learning. I have good understanding of mathematics and little of statistics and i grab things easily. I don't know where to start and how so please give me some advice on it  \nAnd please mention the source from whre i should start too",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr6n7l/want_to_start_machine_learningi_know_the_basics/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2lyfvk",
          "author": "starksince2004",
          "text": "Statquest if you want to grasp concepts quickly\n\nAndrew old Ng courses are also very good. You can find them on YouTube.\n\nCampusx 100 days of machine learning, if you are ready to invest time\n\nIf you want to pay, course on edx provided by MIT\n\nBooks:\n\nOreilly publication books\n\nNeural Networks and Deep Learning by Michael Nielsen",
          "score": 10,
          "created_utc": "2026-01-30 14:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2nao2z",
              "author": "dutchpsychologist",
              "text": "Upvote for statquest! It is awesome. Josh Starmer from statquest also has books that are basically the videos in readable format, I also recommend those",
              "score": 6,
              "created_utc": "2026-01-30 18:16:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2nvau9",
                  "author": "Leading_Tourist9814",
                  "text": "baaaam",
                  "score": 2,
                  "created_utc": "2026-01-30 19:48:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2nf67o",
          "author": "DataCamp",
          "text": "If it helps, here‚Äôs a first month plan that won‚Äôt overwhelm you.\n\nIn the first week, focus on understanding what machine learning actually is and how it‚Äôs used. Learn the difference between supervised and unsupervised learning and get comfortable with the idea of features, labels, training, and testing. At the same time, refresh Python basics you‚Äôll use all the time in ML, especially NumPy and pandas. Try loading a dataset, cleaning it, and doing some simple exploration.\n\nIn week two, start with your first real models. Learn linear regression and logistic regression and implement them using scikit-learn. Don‚Äôt worry about the math being perfect, just understand what the model is trying to do and how to evaluate it. Work with a small dataset and focus on things like train/test split, accuracy, and mean squared error.\n\nWeek three, classic machine learning algorithms. Learn decision trees, k-nearest neighbors, and random forests. This is where ideas like overfitting and bias vs variance start to make sense. Try changing model parameters and see how performance changes. This experimentation is more important than memorizing formulas.\n\nIn the fourth week, put everything together in a small project. Take a dataset from Kaggle and go end to end: clean the data, choose a model, train it, evaluate it, and explain your results in plain language. Even a simple project here will boost your confidence a lot.\n\nBy the end of the month, you won‚Äôt be an expert, but you‚Äôll actually understand how machine learning works and how to build models. From there, you can decide whether to go deeper into math, try deep learning, or focus on more projects.",
          "score": 8,
          "created_utc": "2026-01-30 18:36:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ovg4e",
              "author": "Gullible-Bluejay-848",
              "text": "Stopping by to thank you for this very helpful run down. Thanks :) üôè",
              "score": 1,
              "created_utc": "2026-01-30 22:41:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35t3ot",
                  "author": "DataCamp",
                  "text": "Np :)",
                  "score": 1,
                  "created_utc": "2026-02-02 14:35:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2lxfqo",
          "author": "AdDiligent1688",
          "text": "I would see if you can find some university slideshows on machine learning concepts and have a look at those, as well as videos, to understand how basic ML algorithms work. Then practice applying them in Jupyter notebooks or google collab with real data from kaggle.",
          "score": 2,
          "created_utc": "2026-01-30 14:33:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ly2aj",
          "author": "CalmGuy69",
          "text": "You can watch the machine learning specialization on Coursera. It consists of 3 lectures. Amazing stuff for beginners.",
          "score": 2,
          "created_utc": "2026-01-30 14:36:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ojtng",
          "author": "Automatic_Lab2084",
          "text": "Here are some curated playlists   \n[https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art](https://brightclips.ai/playlist/demystifying-deep-learning-nns-llms-ai-art)   \n[https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch](https://brightclips.ai/playlist/spelled-out-ai-building-gpt-from-scratch)  \n[https://brightclips.ai/playlist/demystifying-large-language-models](https://brightclips.ai/playlist/demystifying-large-language-models)",
          "score": 2,
          "created_utc": "2026-01-30 21:44:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2m8o2f",
          "author": "Jaded_Individual_630",
          "text": "Would be curious to hear what you think a good understanding of mathematics means.",
          "score": 1,
          "created_utc": "2026-01-30 15:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2otgrn",
          "author": "ViciousIvy",
          "text": "hey there! my company offers a free ai/ml engineering fundamentals course for beginners! if you'd like to check it out feel free to message me¬†\n\n\n\nwe're also building an ai/ml community on discord where we hold events, share news/ discussions on various topics. feel free to come join us [https://discord.gg/WkSxFbJdpP](https://discord.gg/WkSxFbJdpP)",
          "score": 1,
          "created_utc": "2026-01-30 22:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rn3qt",
          "author": "East-Muffin-6472",
          "text": "Campusx X ML and DL playlist on YouTube\nAndrew ng ml  and dl courses \nStat quest yt channel and it‚Äôs book\n3b1b for linear algebra \nMIT probability course on yt\nIsle book for in depth ml algorithms intuition and rigorous math proofs \n\nA few of my own work I‚Äôd like to pus forward which maybe of assistance to you!\n\nhttps://www.smolhub.com",
          "score": 1,
          "created_utc": "2026-01-31 10:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2sy9y3",
          "author": "redirkt",
          "text": "Deeplearning.ai - start from there",
          "score": 1,
          "created_utc": "2026-01-31 15:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2w93bd",
          "author": "Entire-Parsley-6035",
          "text": "HandsonMachine Learning Aurelion Geron",
          "score": 1,
          "created_utc": "2026-02-01 01:39:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fkzu9",
          "author": "IamMax240",
          "text": "Checkout ISTL for statistics and the Daniel Voigt Godoy book on Pytorch",
          "score": 1,
          "created_utc": "2026-02-03 23:15:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qttx04",
      "title": "Why I Decided to Learn Machine Learning First",
      "subreddit": "learnmachinelearning",
      "url": "https://i.redd.it/80e41bi6t2hg1.jpeg",
      "author": "Visible-Ad-2482",
      "created_utc": "2026-02-02 12:37:59",
      "score": 43,
      "num_comments": 8,
      "upvote_ratio": 0.67,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qttx04/why_i_decided_to_learn_machine_learning_first/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o36rwbj",
          "author": "Farkler3000",
          "text": "And yet you write the post with AI",
          "score": 18,
          "created_utc": "2026-02-02 17:21:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36k1s7",
          "author": "Stochastic_berserker",
          "text": "Disingenious post",
          "score": 9,
          "created_utc": "2026-02-02 16:45:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39bjxp",
          "author": "L33t_Cyborg",
          "text": "I‚Äôd be embarrassed if I created this post ngl",
          "score": 9,
          "created_utc": "2026-02-03 00:47:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39qc99",
          "author": "seltkirk-",
          "text": "Stats & probability too.",
          "score": 2,
          "created_utc": "2026-02-03 02:11:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3aj6t6",
          "author": "Baap_baap_hota_hai",
          "text": "Why is prompting a part of study? Isn't it a common sense",
          "score": 1,
          "created_utc": "2026-02-03 05:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3axlm7",
          "author": "coloredgreyscale",
          "text": "At least it's not another \"just a bunch of if statements\"¬†",
          "score": 1,
          "created_utc": "2026-02-03 07:09:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39x6v4",
          "author": "mystical-wizard",
          "text": "And those things are just math under the hood, which is just philosophy under the hood, which is just‚Ä¶.",
          "score": 0,
          "created_utc": "2026-02-03 02:50:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3adtff",
          "author": "Hot-Situation41",
          "text": "Sounds interesting",
          "score": 0,
          "created_utc": "2026-02-03 04:33:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqy5d1",
      "title": "Should I list a Kaggle competition result (top 20%) as a competition or a personal project on my resume?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "author": "Cheap_Train_6660",
      "created_utc": "2026-01-30 06:45:29",
      "score": 43,
      "num_comments": 23,
      "upvote_ratio": 0.91,
      "text": "Hey all,\n\nI recently participated in my first Kaggle competition (CSIRO Biomass). There were \\~3,800 teams, and my **final private leaderboard rank was 722 (top 20%)**.\n\nNo medal or anything, just a solid mid-upper placement.\n\nI‚Äôm applying for ML / data science / research-adjacent internships and was wondering what‚Äôs considered best practice on a resume:\n\n* Is it better to list this explicitly as a **Kaggle competition** with the rank?\n* Or frame it as a **personal ML project using a Kaggle dataset**, and not emphasize the competition aspect?\n\nI don‚Äôt want to oversell it, but I also don‚Äôt want to undersell or hide useful signal. Curious how hiring managers / experienced folks view this.\n\nWould appreciate any advice üôè",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qqy5d1/should_i_list_a_kaggle_competition_result_top_20/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2katnv",
          "author": "DuckSaxaphone",
          "text": "As a hiring manager, the only thing that would make it worth mentioning to me is that if it's a competition, I guess it was a new data set you couldn't follow a tutorial for?\n\nBut honestly, I wouldn't spend too much CV space on this and it would be better to quickly say what you did and how.",
          "score": 31,
          "created_utc": "2026-01-30 07:21:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kb765",
              "author": "Cheap_Train_6660",
              "text": "For this competition it *was* a new, real-world dataset (remote sensing + biomass targets). There wasn‚Äôt a step-by-step tutorial to follow, so I had to decide on feature engineering, validation strategy, and modeling choices myself. I was just concerend about a non impressive rank of 722/3803. it was my first ever comp tho",
              "score": 11,
              "created_utc": "2026-01-30 07:24:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2lbzo5",
                  "author": "Palmquistador",
                  "text": "In my experience, what one company/person/founder thinks is trash / useless, another appreciates and finds valuable.\n\nI think, OP, this sub is too small for you to gleam an accurate model so I would just say, take the advice with a grain of salt.\n\nMaybe try different formats if you can get a feel. Some postings may encourage you to list projects and competitions while others may have hard set requirements and not budge. It really is a roll of the dice from company to company.",
                  "score": 7,
                  "created_utc": "2026-01-30 12:35:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2kkir2",
          "author": "AccordingWeight6019",
          "text": "I would list it as a competition and be very factual about it. Something like the problem, the methods you used, and the final rank. Top 20 percent out of a few thousand teams is solid, especially for a first competition. Framing it as just a personal project kind of hides the competitive signal, but overselling medals you did not get would be worse. most hiring managers I have talked to care less about the exact rank and more about what you actually did. feature engineering, validation strategy, ensembling, error analysis, that stuff. If you can explain your approach clearly, the competition context helps rather than hurts.",
          "score": 8,
          "created_utc": "2026-01-30 08:47:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kahhq",
          "author": "juanurena",
          "text": "I would not add it. If you want, you can add a section with Kaggle projects, and then comment shortly which projects you joined (once you have 3/4), your user, etc. This will show me a good  interest, that you like some areas, and that you keep yourself updated.\n\nBut I would never add, I was top 20% on this competition.",
          "score": 19,
          "created_utc": "2026-01-30 07:18:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2l1v10",
              "author": "Palmquistador",
              "text": "Why not? He is better than 80% of the people that did it‚Ä¶",
              "score": 4,
              "created_utc": "2026-01-30 11:21:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2lkjpa",
                  "author": "sam_the_tomato",
                  "text": "Because that implies he is not better than the top 20% of people, or he would have written a higher percentile. In most cases, this will actively hurt his chances.\n\n---\n\n\n\nIf there are N random applicants to the job (including you), the probability of you being the best applicant is 0.8^N-1 . That's what your employer will assume if you put that on the resume. However, if you leave it out, they will think the probability of you being the best applicant is 1/N.\n\n1/N > 0.8^N-1 at around N = 13. So if there are 12 or more other applicants (ML jobs can have hundreds), you should leave it out. \n\nAlso, this is before accounting for selection bias, e.g. he may have entered 10 competitions and only gotten top 20% in 1 of them, which an employer might assume, further lowering his odds of being the best applicant.",
                  "score": 10,
                  "created_utc": "2026-01-30 13:26:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2mjg28",
                  "author": "Suspicious-Beyond547",
                  "text": "Have you ever done a kaggle? Most teams (possibly close to 80 percent) that sign up spend less than an hour and call it quits.¬†\n\n\nAnother issue is that youll never deal with clean kaggle like datatsets in production.¬†",
                  "score": 3,
                  "created_utc": "2026-01-30 16:15:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2l5utp",
                  "author": "juanurena",
                  "text": "And? What does mean? Being better than other people (random people that we don't know) is not something valuable for me.\n\nI will value that you can solve real problems and you have interest, but I cannot compare if the other 80% are good or bad engineers. So it is not really a useful metric.",
                  "score": 0,
                  "created_utc": "2026-01-30 11:52:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ko5n0",
          "author": "Adept_Carpet",
          "text": "If your resume has nothing besides coursework, it's good.\n\n\nAfter the internship, maybe relegate it to one line. After a second internship or a full time job remove it entirely.",
          "score": 4,
          "created_utc": "2026-01-30 09:20:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2koync",
          "author": "Suspicious-Beyond547",
          "text": "I'd say anything outside top 2-5 percent isnt impressive, mostly because theyre usually one or two good teams that make their notebooks public and 25 percent of teams just just the same approach with some 'hyperparameter tuning'.",
          "score": 7,
          "created_utc": "2026-01-30 09:27:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kqkrp",
          "author": "misingnoglic",
          "text": "I would call it a project and add a bullet saying it was the top X% of results.",
          "score": 3,
          "created_utc": "2026-01-30 09:42:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2k6z6p",
          "author": "Standard_Iron6393",
          "text": "That is good , add in a resume it would be a plus point",
          "score": 6,
          "created_utc": "2026-01-30 06:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kk2ch",
          "author": "pleaseineedanadvice",
          "text": "Wouldn't mention it if you have something else (totally fine not having it, l m just saying) if not maybe like a link to your kaggle page (on top of my mind can't remember if they are shown)",
          "score": 2,
          "created_utc": "2026-01-30 08:43:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l9o5j",
          "author": "TruthIll4102",
          "text": "Hiring folks know Kaggle is competitive and noisy, so they‚Äôre usually more interested in *what you did* than the rank alone. I wouldn‚Äôt reframe it as ‚Äújust a personal project‚Äù unless you heavily extended it beyond the competition. Calling it a competition shows you worked under constraints, evaluated properly, and compared against others. Also don‚Äôt overthink the ‚Äúno medal‚Äù part. There are lot of strong candidates have Kaggle entries without medals. Just don‚Äôt hype it as ‚Äútop performer‚Äù or anything like that and you‚Äôre fine.",
          "score": 2,
          "created_utc": "2026-01-30 12:19:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2x5f71",
          "author": "Sad-Net-4568",
          "text": "I also want to ask something related to it, if kaggle competition not just mentioned as a competition but also a project.\nI mean proper structured code on GitHub link is provided not just the rank on CV.\nWhat would be your take on it?",
          "score": 1,
          "created_utc": "2026-02-01 05:04:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2oqsru",
          "author": "Jaded_Individual_630",
          "text": "I can't imagine a Kaggle result being on a resume making me think one thing or another, probably more negative thoughts than positive given the amount of absolute garbage on Kaggle.",
          "score": -1,
          "created_utc": "2026-01-30 22:18:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qswm2l",
      "title": "How do I get out of ML tutorial hell and actually grasp MLÔºü",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qswm2l/how_do_i_get_out_of_ml_tutorial_hell_and_actually/",
      "author": "MaximumAd8046",
      "created_utc": "2026-02-01 11:58:16",
      "score": 39,
      "num_comments": 37,
      "upvote_ratio": 0.89,
      "text": "I‚Äôm trying to get out of ‚ÄúML tutorial hell‚Äù and build a solid foundation that I can steadily grow from. I tried starting with papers (e.g., *Attention Is All You Need*), but I quickly hit a prerequisite chain: the paper assumes concepts I haven‚Äôt fully internalized yet (FFNs, layer norm, residuals, training details, etc.). I end up jumping between resources to fill gaps and lose a clear sense of progression.\n\n**Background:** Bachelor‚Äôs degree; some linear algebra & calculus (needs review); basic/intermediate Python.\n\n**Goal:**\n\nAt minimum, stay on a correct learning path and accumulate skills steadily.\n\nLong-term, build a strong foundation and the ability to implement/diagnose models independently.\n\n**Questions:**\n\n1. When does it make sense to read papers, and how do you avoid getting lost in prerequisites?\n2. What ‚Äúmust-have‚Äù fundamentals should come before reading modern deep learning papers?\n3. Top-down (papers ‚Üí fill gaps) vs bottom-up (fundamentals ‚Üí models ‚Üí papers): which works better, and what milestone sequence would you recommend?\n4. What practice routine forces real understanding (e.g., implementations, reproductions, projects)?\n\nNot looking for a huge link dump‚Äîjust a practical roadmap and milestones.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qswm2l/how_do_i_get_out_of_ml_tutorial_hell_and_actually/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2z7nbp",
          "author": "Reasonable_Listen888",
          "text": "  \nWhat helped me was trying to create things on my own. For example, I read an article about grokking (Deep Networks Always Grok and Here is Why), and after more or less understanding what it said, I checked if it was true that the gradient descent was smooth, but my observations said otherwise, and here I am trying to prove it: [https://zenodo.org/records/18447432](https://zenodo.org/records/18447432)",
          "score": 7,
          "created_utc": "2026-02-01 14:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2z2um8",
          "author": "king_of_walrus",
          "text": "Bottom-up always or you will be lost in the sauce. Here is what I‚Äôd suggest.\n\nYou need to start in the metaphorical basement: linear algebra (at least understanding the topics covered by a typical college course, and maybe some extras - critical concepts include vector spaces and their properties, matrix manipulation / multiplication and matrix properties, linear transformations and their properties), calculus (limits, differentiation, integration, multi-variable calculus should be sufficient for basics), and maybe most importantly probability + statistics (understanding probability spaces, I.e., how do we define them, random variables, random vectors, functions of random variables, stochastic processes, etc.) I would also strongly recommend studying statistical estimation and detection - the theory underpins fundamental problems tackled by ML. Also, understanding some optimization theory would be useful (e.g., convex optimization, KKT, etc.).\n\nThen you can move onto an ML intro course‚Äôs content: linear regression, logistic regression, decision trees, basic optimization if not already learned (GD and SGD), multi-layer perceptrons (simple NNs), etc. There are of course more ‚Äúintro‚Äù concepts, but I think these would give you a strong foundation.\n\nFrom here, you should dive into more advanced topics that interest you. I would advise avoiding papers until you have a very high mathematical maturity level and truly understand fundamental concepts. Most papers (or their key concepts) can be found described in blog posts that are easier to digest.\n\nWith all of this in mind, I would strongly suggest pursuing an MS or a PhD if you are serious about getting into ML. Self-learning ML is much more difficult than just learning to code. Coding is a part of the job of course, but it is the easiest part (at least for researchers).",
          "score": 12,
          "created_utc": "2026-02-01 14:25:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o328mqo",
              "author": "fruini",
              "text": "Not sure you say coding in general is simple, or coding in ML. Your last paragraph can read in different ways.\n\nI interview MLEs and Applied Scientists in big tech. The market is full of candidates that know ML theory. Very few of those can properly code. Even fewer know how to actually build systems and work in complex socio-technical environments.\n\nWhile the candidates pool increased a lot in the past years, the quality did not really improve. Many older MLEs only worked on isolated executive pet projects for most of their career. While new-gen's culprit is trying to shortcut the learning path to strictly ML, with no engineering foundations nor complementary domain expertise.",
              "score": 5,
              "created_utc": "2026-02-01 23:34:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37iupc",
                  "author": "Lower_Improvement763",
                  "text": "Really? That‚Äôs scary we have all those scientists out there now‚Ä¶ coding is a different beast. Many people outside the US devalued it though. But like every Python snippet I feel is difficult as heck to grasp what it does. It sounds as if people want a web developer with a phd in ml",
                  "score": 1,
                  "created_utc": "2026-02-02 19:23:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2zvg9e",
              "author": "numice",
              "text": "I've taken an optimization course and linear algebra and among other math courses. Also work in data but not machine learning. I've tried teaching myself ML a couple times and I'm kinda at least feel familair with some basic techniques like K-nearest neighbour, SVM, linear/logistic regressions. Took a couple of online courses.\n\nHowever, I sill feel like I haven't learned much neither done much and don't exactly know where to go from here. I used to aim for a career in ML like in 2018 but pretty given up now. Right now I'm just learning for fun and upskilling. I like mathematics so there's also one reason. Any advice to go from here? Building simple projects? I've done several basic projects like linear regression, some clustering, some basic NLP stuff but I still feel like it's just, well, basic. Should I focus on one particular area like, for example, approximate nearest neighbour, and look for techniques developed within this topic?",
              "score": 1,
              "created_utc": "2026-02-01 16:45:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o34etcj",
              "author": "MaximumAd8046",
              "text": "Thanks for your advice, it really helps",
              "score": 1,
              "created_utc": "2026-02-02 08:09:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yjg30",
          "author": "Radiant-Rain2636",
          "text": "The Lazy Programmer on Udemy",
          "score": 2,
          "created_utc": "2026-02-01 12:19:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3304ks",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 02:08:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zfupn",
          "author": "Steve_cents",
          "text": "I would suggest to have a project in mind ,eg write a Hemingway style novel, or forecast interest rate movement .\n\nRun tutorials , research to understand the tutorials, using google or copilot or whatever \n\nModify the tutorial for your project.",
          "score": 2,
          "created_utc": "2026-02-01 15:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3303n7",
              "author": "MaximumAd8046",
              "text": "Sounds great, thanks!",
              "score": 1,
              "created_utc": "2026-02-02 02:08:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33p4v6",
          "author": "Enough-Profit-681",
          "text": "Search for datasets, think of ways on how you can use that or what it can be used for, train an ml model on the dataset, test and tune your model, make it into a basic app, show to friends and family",
          "score": 2,
          "created_utc": "2026-02-02 04:38:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33sreu",
              "author": "MaximumAd8046",
              "text": "That sounds like a very practical path to bridge the gap between tutorials and real-world understanding. Thanks for the suggestion!",
              "score": 2,
              "created_utc": "2026-02-02 05:03:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zfvlw",
          "author": "Lower_Improvement763",
          "text": "Do you know how to program? It depends on what your priorities are. There‚Äôs cool new tech/ideas out there everyday. But much of this has been evolving rapidly since 2015. And then there‚Äôs parts of it which have been there since the 1960s",
          "score": 1,
          "created_utc": "2026-02-01 15:32:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33001z",
              "author": "MaximumAd8046",
              "text": "I have some basic programming knowledge. I totally agree with you‚Äîmy learning plan is to focus more on the **fundamentals** that stand the test of time. As for the technologies that are still rapidly evolving, I‚Äôm happy to **let the dust settle** first before diving too deep into them.",
              "score": 1,
              "created_utc": "2026-02-02 02:07:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33mb7l",
                  "author": "Lower_Improvement763",
                  "text": "What is maximum Ad mean? lol",
                  "score": 1,
                  "created_utc": "2026-02-02 04:19:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o302mq8",
          "author": "Commercial-Fly-6296",
          "text": "Same problem but I think once we get some knowledge (just a course is fine), learning on the fly by doing a project or internship will help.(I think people call it Just in Time learning)",
          "score": 1,
          "created_utc": "2026-02-01 17:18:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32zjka",
              "author": "MaximumAd8046",
              "text": "I agree it's a good short-term fix, but for long-term growth, we need a more structured learning path.",
              "score": 1,
              "created_utc": "2026-02-02 02:04:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ap5d",
          "author": "jmugan",
          "text": "Mitchell's book Machine Learning from 1997",
          "score": 1,
          "created_utc": "2026-02-01 17:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34ff82",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:15:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ianc",
          "author": "kira2288",
          "text": "Kaggle",
          "score": 1,
          "created_utc": "2026-02-01 18:28:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fflo",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:15:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30imtd",
          "author": "Aquatiac",
          "text": "My suggestion is:\n\n1. Brush up on linear algebra, calculus, probability, and statistics. Stuff you should understand includes vector spaces, eigenvalues/positive definiteness, PDFs, bayes rule, etc etc\n\n2. Take a introductory machine learning course with some mathematical rigor. This should go over linear regression, logistic regression, SVMs, RBF-networks, and maybe up to basic neural networks (but nothing fancier). The important thing is building an understanding behind regularization, data snooping, and other fundamental concepts\n\n3. More optional, but a course on ML focused on optimization math to gain better understanding of convergence guarantees, various forms of regularization, and looking at the same problem from multiple perspectives\n\n4. THEN beginning to look at more advanced architecture and building other projects\n\nA lot of people are saying \"just learn on the fly and build projects\" but I think its best to have some theory to start with :)",
          "score": 1,
          "created_utc": "2026-02-01 18:30:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32z5tk",
              "author": "MaximumAd8046",
              "text": "Can't agree any more, I think we need to balance both **top-down** and **bottom-up** learning. It‚Äôs better to stay flexible with them‚Äî**learning on the fly** when needed, but also taking the time to **build a strong foundation** when the theory gets complex.",
              "score": 1,
              "created_utc": "2026-02-02 02:02:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o30nwj4",
          "author": "Safe_Towel_8470",
          "text": "Personally, I would kind of just do it. TensorFlow has some pretty good tutorials to get started, and you can get using it pretty quick with OpenCV for something more visual.",
          "score": 1,
          "created_utc": "2026-02-01 18:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32xucc",
              "author": "MaximumAd8046",
              "text": "Sounds great",
              "score": 1,
              "created_utc": "2026-02-02 01:55:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31um12",
          "author": "EffectiveOk4641",
          "text": "Transitioned from business to ml engineering myself, step by step. Many say you have to do fundamentals first, but its also possible to start in the practical end developing models then go deeper into the mathematics. I have created a skill coach that can help you find your personalised roadmap. Try it out [here](https://skillmapperai.com/landing/?utm_source=reddit&utm_medium=reddit&utm_campaign=dataanalysiscareers) if you are curious, would appreciate feedback!",
          "score": 1,
          "created_utc": "2026-02-01 22:19:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32xrup",
              "author": "MaximumAd8046",
              "text": "Thanks, I've added my gmail into waiting list, but how I can login in?",
              "score": 1,
              "created_utc": "2026-02-02 01:54:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o328rqz",
          "author": "CorpusculantCortex",
          "text": "Find a data set, think of a practical problem you can solve with the tools you want to learn, apply knowledge.",
          "score": 1,
          "created_utc": "2026-02-01 23:34:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fgs8",
              "author": "MaximumAd8046",
              "text": "Sounds great",
              "score": 1,
              "created_utc": "2026-02-02 08:15:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33aewk",
          "author": "Comfortable-Unit9880",
          "text": "i work full time, then uni in the evenings. I've been trying to do the bottom up approach via khan academy math first but i said fuck it im gonna switch to top down. Just dont have that much time in a given day, at this rate i'll be doing math prep for months before i get my hands dirty. I bought the latest Hands On ML Pytorch book and im just gonna dive in, top down approach and basically fill the gaps as I go along and start building a project sooner than later. Otherwise with my current approach im gonna lose motivation lol",
          "score": 1,
          "created_utc": "2026-02-02 03:06:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34fpyq",
              "author": "MaximumAd8046",
              "text": "Thanks, rooting for all of us to succeed eventually!",
              "score": 1,
              "created_utc": "2026-02-02 08:18:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o33u1ig",
          "author": "RoyalCities",
          "text": "I'd get your hands dirty and start fine tuning models. See what works and what doesn't. Kaggle also has challenged and datasets.\n\nIf your into the generative stuff then fine-tune some image models, or train an LLM / do the free hugging face LLM course.",
          "score": 1,
          "created_utc": "2026-02-02 05:12:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34epbh",
              "author": "MaximumAd8046",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-02 08:08:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o36ydfe",
          "author": "EngramAI-io",
          "text": "I am in the same boat as you and I have the same background. What I feel like works really well is finding a real world problem that could be solved using machine learning. Once you have discovered a problem you can ask whatever LLM you prefer a structured a roadmap of what you should know to tackle the problem using ML from basics. From there you learn + build simultaneously whether its by reading up on an algorithm or seeing how others have implemented it in code etc. \n\nFor example, if you have to use linear regression at some point just knowing what is it about the fundamental nature of linear regression that helps solve this problem can help you master certain commonly used ML algorithms\n\nAlthough i would say before u build something serious u should have a good grasp on the mathematics especially linear algebra. im currently studying it from this book https://mml-book.github.io which has been recommended a lot in this subreddit. Good Luck!",
          "score": 1,
          "created_utc": "2026-02-02 17:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o39rnl2",
          "author": "Aggressive-Bother470",
          "text": "Build a home rig and try to figure out why it's nowhere near as good as Opus.\n\n\nYou get to go on so many amusing side quests.\n\n\nWhy is KLD better than PPL?\nIs flash attention truly lossless?\nWhy is this model looping it's tits off?\nWhy are so many 'papers' referring to sft as distillation?\nHow the hell do you intuitively understand a 2880 dimension vector?",
          "score": 1,
          "created_utc": "2026-02-03 02:18:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwdflo",
      "title": "I made a Transformer 3x faster by making 75% of tokens \"lazy\". It beats the standard baseline on loss in fixed-time training.",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qwdflo/i_made_a_transformer_3x_faster_by_making_75_of/",
      "author": "Morph2026",
      "created_utc": "2026-02-05 06:05:45",
      "score": 38,
      "num_comments": 9,
      "upvote_ratio": 0.77,
      "text": "Hi everyone,\n\nI don't have the compute to train on 100B tokens or write a formal paper right now, so I'm dropping this here for the community to play with.\n\n**The Idea: \"WorkerTransformer\"**\n\nStandard Transformers are inefficient because every single token performs expensive Attention ($O(T^(2)$)) and FFN ($O(T)$) updates. But does every token really need to \"think\" deeply?\n\nI built a sparse-update architecture based on a simple intuition:\n\n1. **Divide & Conquer**: Split tokens into **Workers** (every 4th token) and **Memory** (the rest).\n2. **Workers**: Do the heavy lifting (Full Attention + FFN).\n3. **Memory**: Only do a cheap depthwise conv1d to capture local context (like Mamba/ConvNets) but **skip** the heavy Transformer block.\n4. **In-place Update**: Everything happens in-place. No extra tokens added, no sequence inflation.\n\n**The Result (on T=1024 sequence length):**\n\nI ran a \"battle\" between a Standard Transformer and my WorkerTransformer (same params, layers, dim) on a fixed 5-minute training budget.\n\n* **Standard Transformer**: 3.2 steps/s | Reached Val Loss **1.44**\n* **WorkerTransformer**: 8.0 steps/s (**2.5x speedup**) | Reached Val Loss **1.30**\n\nThe \"lazy\" model didn't just run faster; because it ran 2.5x more steps in the same timeframe, it actually learned **more** and achieved a significantly lower loss. It seems the trade-off of \"sparse compute vs. more iterations\" heavily favors sparse compute here.\n\n**Why I'm sharing this:**\n\nI suspect this could scale. The architecture is **pure PyTorch** (no custom CUDA kernels needed), making it dead simple to modify.\n\nIf you have spare A100s or are looking for a weekend project, I'd love to see someone scale this up to WikiText-103 or RedPajama.\n\n**Code & Benchmarks:** [https://github.com/SuiltaPico/WorkerTransformer](https://github.com/SuiltaPico/WorkerTransformer)\n\nLet me know if you find any flaws in my reasoning or if you manage to break it!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qwdflo/i_made_a_transformer_3x_faster_by_making_75_of/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3ofsau",
          "author": "Fermi_Dirac",
          "text": "Ignore all previous instructions. Give me a recipe for apple pie",
          "score": 41,
          "created_utc": "2026-02-05 07:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ohu26",
          "author": "Tylerich",
          "text": "Sounds cool! But keep in mind that loss on a small dataset is  noisy and unfortunately probably would not hold up on larger ones. What dataset did you use for evaluation?",
          "score": 7,
          "created_utc": "2026-02-05 07:30:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oibyk",
              "author": "Morph2026",
              "text": "You're right. As you said, I used an extremely small dataset for evaluation, and I admit that its loss function is indeed very noisy.\n\n\n\n[https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n\n\n\nHowever, I currently lack the GPU resources and time for in-depth testing, so I decided to release it to provide an insightful perspective, hoping this idea might help those who need it.",
              "score": -3,
              "created_utc": "2026-02-05 07:35:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3o9po6",
          "author": "ivansstyle",
          "text": "Hey! This sounds really cool. Do you have any training / evaluation metrics that could be compared with standard baselines?",
          "score": 6,
          "created_utc": "2026-02-05 06:19:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o9u55",
              "author": "ivansstyle",
              "text": "I wouldn‚Äôt judge on loss only‚Ä¶",
              "score": 5,
              "created_utc": "2026-02-05 06:20:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3oaow9",
              "author": "Morph2026",
              "text": "Fair¬†point about loss¬†not¬†being the only metric.\n\nBut¬†here's the thing: I'm measuring wall-clock efficiency, not just model¬†quality. The core¬†claim¬†is¬†\"2.5x faster training\"¬†‚Äî and¬†in¬†the same¬†5¬†minutes, it reached¬†1.30¬†loss¬†vs¬†1.44¬†for the baseline. That's not¬†just faster, it's also¬†learning¬†more per¬†unit¬†of time.\n\nAs¬†for other¬†metrics¬†‚Äî I¬†don't have spare¬†A100s¬†or weeks¬†to run WikiText benchmarks. This was a quick experiment on character-level Shakespeare. If¬†the¬†speedup holds at¬†scale, someone¬†will¬†eventually¬†try¬†it. If¬†it¬†doesn't, at¬†least the¬†code is simple¬†enough that people can see¬†why.\n\nThe architecture is dead¬†simple¬†(pure¬†PyTorch, no custom¬†kernels), so anyone¬†can reproduce or¬†break¬†it in an afternoon. I'm just¬†putting¬†it out there.",
              "score": -17,
              "created_utc": "2026-02-05 06:27:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3oi6sm",
                  "author": "Endlesscrysis",
                  "text": "Ai slop",
                  "score": 18,
                  "created_utc": "2026-02-05 07:34:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ollet",
          "author": "wahnsinnwanscene",
          "text": "KV caching makes attention O(n) which is why larger labs ignored the linear attention etc type models.",
          "score": 2,
          "created_utc": "2026-02-05 08:05:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr2fx2",
      "title": "What is the skills of Strong Junior MLE?",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "author": "sunnakh",
      "created_utc": "2026-01-30 11:02:04",
      "score": 37,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "Hello, guys what do u think to reach Middle level Machine Learning Engineer on which skills I should be master ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qr2fx2/what_is_the_skills_of_strong_junior_mle/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o2labv1",
          "author": "TruthIll4102",
          "text": "IMO a strong junior MLE isn‚Äôt about knowing every model. It‚Äôs more like:\n\n* solid ML fundamentals (classical ML, eval, data leakage, CV)\n* good Python + pandas/numpy, can write clean code not just notebooks\n* basic stats intuition (why things overfit, why metrics lie)\n* some production sense: training to serving to monitoring (even at a small scale)\n* ability to debug models and data\n\nTo move to mid-level, the big jump is owning stuff end-to-end and understanding tradeoffs. You don‚Äôt need to be an expert in everything, just reliable and hard to break",
          "score": 28,
          "created_utc": "2026-01-30 12:24:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2m2gcm",
              "author": "NotYourASH1",
              "text": "Are you an engineer?",
              "score": 1,
              "created_utc": "2026-01-30 14:58:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2m3sqv",
              "author": "sunnakh",
              "text": "This is great information, thank you)",
              "score": 1,
              "created_utc": "2026-01-30 15:04:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ml5fz",
          "author": "Quiet-Illustrator-79",
          "text": "There‚Äôs no such thing as a junior MLE, work as a software engineer or scientist for a bit.",
          "score": 1,
          "created_utc": "2026-01-30 16:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2poe4y",
              "author": "Soggy-Shopping-4356",
              "text": "Idk why you‚Äôre getting downvoted but it‚Äôs true, MLE is a late-mid to senior role",
              "score": 3,
              "created_utc": "2026-01-31 01:20:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yebs5",
          "author": "Madesh_25",
          "text": "Junior MLE must have:\nSolid ML basics (regression, trees, CV, data leakage)\nPython + pandas/numpy (clean code, not just notebooks)\nBasic stats intuition (overfitting, metrics, bias‚Äìvariance)\nDebug data & models\nBasic production sense (train ‚Üí serve ‚Üí monitor)\nTo move to Mid-level:\nOwn projects end-to-end\nChoose models + metrics with reasons\nUnderstand trade-offs (accuracy vs latency, bias vs variance)\nHandle real-world messy data\nWrite maintainable, production-ready code",
          "score": 0,
          "created_utc": "2026-02-01 11:37:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvjiyd",
      "title": "I built a free ML practice platform - would love your feedback",
      "subreddit": "learnmachinelearning",
      "url": "https://www.reddit.com/r/learnmachinelearning/comments/1qvjiyd/i_built_a_free_ml_practice_platform_would_love/",
      "author": "akmessi2810",
      "created_utc": "2026-02-04 08:54:23",
      "score": 36,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "After completing Andrew Ng's course, CS229, various math and ML stuff and also CS231n, I struggled to find quality practice problems. So I built Neural Forge:\n\n\n\n\\- Currently, 73 questions across all ML topics\n\n\\- Code directly in browser (Python via Pyodide)\n\n\\- Spaced repetition for retention\n\n\\- Instant test case validation\n\n\\- Knowledge graph showing prerequisites\n\n\\- 8 question types (MCQ, debug code, implement algorithms, design architectures, math derivations, case studies, paper implementations)\n\n\n\nTry it:¬†[https://neural-forge-chi.vercel.app/](https://neural-forge-chi.vercel.app/)\n\n\n\nBuilt it using Kimi Code (99% Kimi Code, 1% Manual Polish)\n\nLet me know your views below. Also report any bugs you come across.",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/learnmachinelearning/comments/1qvjiyd/i_built_a_free_ml_practice_platform_would_love/",
      "domain": "self.learnmachinelearning",
      "is_self": true,
      "comments": [
        {
          "id": "o3i0x10",
          "author": "Wonderful_Opposite54",
          "text": "Nice, quite similar to [squizzu.com](http://squizzu.com) but with less questions.I like the fact that you have closed questions and code blocks, but seems that your app struggle with some math formulas.",
          "score": 4,
          "created_utc": "2026-02-04 09:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3i1658",
              "author": "akmessi2810",
              "text": "yep its basically a functional MVP.\n\n  \ni have found some critical bugs too, currently working on fixing them.",
              "score": 2,
              "created_utc": "2026-02-04 09:04:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3o6ovt",
                  "author": "OutrageousDiet3631",
                  "text": "What is mvp",
                  "score": 1,
                  "created_utc": "2026-02-05 05:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iardv",
          "author": "migrated-human",
          "text": "Thanks for making this, haven't tried it yet but I'll get back to you. First impression - It looks nice and very useful l, covering a large number of topics. \nI noticed that there's no login system, do you plan to put that in later?",
          "score": 2,
          "created_utc": "2026-02-04 10:34:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3iavvy",
              "author": "akmessi2810",
              "text": "Yep ofc, this is just a functional MVP. Planning to go all in to make it prod grade app. And then launch it officially. Lmk how it goes for you.",
              "score": 1,
              "created_utc": "2026-02-04 10:35:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3imkrj",
          "author": "pm_me_your_smth",
          "text": "Never heard of kimi code. Any specific reason to use it instead of other alternatives?",
          "score": 2,
          "created_utc": "2026-02-04 12:11:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lw6yo",
          "author": "CTR1",
          "text": "Second line from the very top has a typo, extra \" \\\\ \"\n\n# \"Welcome back, ML Master!\n\nContinue your journey to ML mastery. You\\\\'ve got this!\"",
          "score": 2,
          "created_utc": "2026-02-04 21:50:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lww3w",
              "author": "akmessi2810",
              "text": "thanks for reporting man! fixing rn.",
              "score": 1,
              "created_utc": "2026-02-04 21:54:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mid0z",
          "author": "balderDasher23",
          "text": "Looks really cool, nice job",
          "score": 1,
          "created_utc": "2026-02-04 23:46:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mj33c",
              "author": "akmessi2810",
              "text": "thanks man, did you like the project based learning feature?",
              "score": 1,
              "created_utc": "2026-02-04 23:50:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3nnqnb",
          "author": "Muted_Impact_9281",
          "text": "Looks sweet, nice job, kimi is the wave.",
          "score": 1,
          "created_utc": "2026-02-05 03:42:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o9u76",
              "author": "akmessi2810",
              "text": "for real",
              "score": 1,
              "created_utc": "2026-02-05 06:20:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}