{
  "metadata": {
    "last_updated": "2026-01-21 02:39:59",
    "time_filter": "week",
    "subreddit": "ChatGPTCoding",
    "total_items": 14,
    "total_comments": 226,
    "file_size_bytes": 236283
  },
  "items": [
    {
      "id": "1qgg33n",
      "title": "The value of $200 a month AI users",
      "subreddit": "ChatGPTCoding",
      "url": "https://i.redd.it/vjufy3zbh5eg1.png",
      "author": "thehashimwarren",
      "created_utc": "2026-01-18 18:23:06",
      "score": 291,
      "num_comments": 232,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qgg33n/the_value_of_200_a_month_ai_users/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0c0asl",
          "author": "spiffco7",
          "text": "We all remember 5$ uber and free doordash",
          "score": 185,
          "created_utc": "2026-01-18 18:29:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ctg3l",
              "author": "SnowLower",
              "text": "noooo pls not like that",
              "score": 33,
              "created_utc": "2026-01-18 20:48:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0dn6an",
                  "author": "Maumau93",
                  "text": "yes, exactly like that. youll be paying $2000 and still be fed adverts or influenced responses from advertisers",
                  "score": 42,
                  "created_utc": "2026-01-18 23:19:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0gq8u7",
                  "author": "LegitimateCopy7",
                  "text": "what else would it be? sustainability 101.",
                  "score": 3,
                  "created_utc": "2026-01-19 12:18:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0hosw4",
                  "author": "guywithknife",
                  "text": "There is no reality where it’s not like that.\n\nEven if the cost to them is only $10, there is no way they won’t raise the price anyway once they feel people are locked in enough.",
                  "score": 0,
                  "created_utc": "2026-01-19 15:35:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0fbr67",
              "author": "TheMacMan",
              "text": "Some of us remember how PayPal would pay you $20 to signup back in 1999.",
              "score": 9,
              "created_utc": "2026-01-19 05:02:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ksom1",
              "author": "brainrotbro",
              "text": "Yup. New tech is always subsidized by investor money.",
              "score": 1,
              "created_utc": "2026-01-20 00:25:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ck2co",
              "author": "ConstantExisting424",
              "text": "I remember when a hershey cost a nickel!",
              "score": -4,
              "created_utc": "2026-01-18 20:03:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0f751n",
                  "author": "OtherwiseAlbatross14",
                  "text": "That's inflation. \n\nThis post and that comment are about startups creating markets by using venture capital money to subsidize the cost of the services they provide into users grow accustomed to using them and then start the enshittification process once they hit critical mass.",
                  "score": 11,
                  "created_utc": "2026-01-19 04:30:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0c3kkm",
              "author": "Exp5000",
              "text": "I remember a pound of skirt steak costing around 12 bucks now it's about 20",
              "score": -17,
              "created_utc": "2026-01-18 18:44:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ekhp3",
                  "author": "ImmediateKick2369",
                  "text": "Where? $29.99 by me.",
                  "score": 3,
                  "created_utc": "2026-01-19 02:19:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0f6e8x",
                  "author": "Jolva",
                  "text": "That sounds delicious. Corn or flour?",
                  "score": 1,
                  "created_utc": "2026-01-19 04:25:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c1a09",
          "author": "neuronexmachina",
          "text": "I'd be very surprised if the marginal cost of an average $200/mo user is anywhere near $2000/mo, especially for a provider like Google that produces energy-efficient TPUs.",
          "score": 55,
          "created_utc": "2026-01-18 18:34:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cesms",
              "author": "ExpressionComplex121",
              "text": "It's one of those things that for us, we rent and pay X amount and we pay the same no matter if we max out the gfx or don't use it at all.\n\nI'm leaning towards we are overpaying by abundance ($100-$250 a month) and its not what the costs to operate for one user. We're paying off collectively for training and free users (who already pay in a different way technically as most behavior and data is used for improving)\n\nI'm pretty sure unless you constantly max out the resources 24x7x4 you don't even cost $50 and most users don't.",
              "score": 12,
              "created_utc": "2026-01-18 19:37:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0gsakq",
                  "author": "Natural_Squirrel_666",
                  "text": "I'm building a complex agent and using raw API, of course. The app has to take into account a lot of things which go into context and the agent has to be able to keep the convo consistent => even with like 3-10 messages per day it's often around 30 bucks per month. And that's very minimal usage. Max tokens I had in a message was 90,000. I do use compaction and caching. Still. I mean, for my use case it's a good deal since I get what I want. But for coding larger context is required and definitely more than 3-10 messages per days... So...",
                  "score": 2,
                  "created_utc": "2026-01-19 12:34:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0f6zhx",
                  "author": "Slow-Occasion1331",
                  "text": "> I'm pretty sure unless you constantly max out the resources 24x7x4 you don't even cost $50 and most users don't.\n\nI can’t talk too much about it but if you’re using large models, ie what you’d get on a $200 plan, and hitting token limits on a semi regular basis, you’d be costing both oai and cc well, well, fucking substantially more than $2000 a month. \n\nInference costs are a bitch",
                  "score": 4,
                  "created_utc": "2026-01-19 04:29:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0exjwx",
                  "author": "ZenCyberDad",
                  "text": "Yep I cancelled the $200 ChatGPT pro plan after many months of using it to complete a video project for the government using Sora 1. Without 24/7 usage it just really didn’t make sense to pay that much when I can just use the same models over API with larger context windows. That’s the secret, the $200 plan doesn’t give you the same sized context windows",
                  "score": 2,
                  "created_utc": "2026-01-19 03:29:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0naln2",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-20 10:57:13",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0g0yl6",
                  "author": "spottiesvirus",
                  "text": ">I'm pretty sure unless you constantly max out the resources 24x7x4 you don't even cost $50 and most users don't.\n\nIf API prices are somewhat accurate (and I believe they may be underpriced as well) 50$/month are like... A couple messages per day with Claude Opus\n\nIt's the opposite, atm VC's money is paying for training, R&D and subsidized advertising. I fear this will be a Uber/Airbnb situation",
                  "score": -1,
                  "created_utc": "2026-01-19 08:31:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0fc2vw",
              "author": "TheMacMan",
              "text": "You have to consider that they need to offset the costs of millions of freeloaders to even break even.",
              "score": 4,
              "created_utc": "2026-01-19 05:04:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0cakrc",
              "author": "jovialfaction",
              "text": "Yes there's crazy margin on API cost, which they need to offset the training costs, but by itself it doesn't \"cost\" the provider thousands of dollars to provide the tokens of those coding plans",
              "score": 4,
              "created_utc": "2026-01-18 19:17:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0qvv03",
                  "author": "jvrodrigues",
                  "text": "All evidence I have seen suggests that this view is incorrect.\n\nTo get a 4000 token output with the standard 35-40 tokens/second that the most advanced models give you on the web you are blocking infrastructure whose capex costs are at the 2.5 million and opex costs are on the hundreds of thousands a month for 100 seconds, lets say 1.5 minutes. You do it hundreds of times a day, thousands a month, you are blocking hours of compute every month.\n\nI have a small AI server at home that corroborates this view as well. AI is very powerfull -> yes, but we are not paying the bill yet. Once we do the business case and applicability will shift dramatically.",
                  "score": 1,
                  "created_utc": "2026-01-20 22:00:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0ly43q",
              "author": "Ok_Road_8710",
              "text": "I'm considering that people just blast off shit, not understanding LTV and potential upsells.",
              "score": 1,
              "created_utc": "2026-01-20 04:15:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0mhssu",
              "author": "WeMetOnTheMountain",
              "text": "I always wonder this myself I use lots of sub agents and dialectical loops which are extremely token heavy.  If I look at what API cost is I would definitely spend at least $5,000 a month.  But here's the thing If they are not at capacity then it probably doesn't cost much more to have me hammering down on processors than them just running without me hammering on them.\n\n\nThen there are weeks that I'm doing other stuff and I barely touch my subscriptions at all.  It's the typical internet service where people who aren't using it are subsidizing people who are.",
              "score": 1,
              "created_utc": "2026-01-20 06:35:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0msqrt",
              "author": "neoqueto",
              "text": "70B-class, text-only models can run on a 5090 if you're lucky, at glacial speeds (tps, ttft). That's a GPT-4 tier model. Capable, sure. But because it's slower you gotta imagine it being hammered more often, though still not 24/7.\n\nI am mentioning a 5090 because it costs roughly a year's worth of $200/mo payments and is capable of running models that are worth something.\n\nSo it's probably not like \"renting out a few 5090s exclusively for a single user\". Even at the very worst. Because a 24/7 usage is not typical. And they have access to economies of scale, various means of load balancing, even better, more optimal hardware. However running the model and running it just for you is not the only cost. Even innovation has to be accounted for. \n\nI'd say $2000 of value sounds like the absolute upper limit still within reasonable figures. But the spread is massive, we don't have enough information.\n\nI am NOT an OAI apologist. Just trying to estimate the numbers with my peabrain.",
              "score": 1,
              "created_utc": "2026-01-20 08:11:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0oo1r2",
              "author": "UnlikelyPotato",
              "text": "I don't think it is. GLM is \"near\" the same levels of performance, $300 a year is similar to max 20x level usage. ",
              "score": 1,
              "created_utc": "2026-01-20 15:54:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0c9n7u",
              "author": "thehashimwarren",
              "text": "We don't know internal numbers, but from what we're told inference compute is wildly expensive",
              "score": -5,
              "created_utc": "2026-01-18 19:12:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cff5r",
                  "author": "West-Negotiation-716",
                  "text": "You clearly have never used a local LLM, you should try it",
                  "score": 9,
                  "created_utc": "2026-01-18 19:40:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0csr7w",
                  "author": "neuronexmachina",
                  "text": "I'd be curious about where you've been hearing that and when. My understanding is that inference compute costs per token have gone down a few orders of magnitude in the past couple years.",
                  "score": 2,
                  "created_utc": "2026-01-18 20:45:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c0396",
          "author": "ChainOfThot",
          "text": "The thing is most people aren't using 200 dollars worth. I'm sure tons of companies are paying for these tools and their devs don't even use them a ton",
          "score": 66,
          "created_utc": "2026-01-18 18:28:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c7exq",
              "author": "johnfkngzoidberg",
              "text": "Folks don’t seem to realize AI is in the “get you hooked” phase.  They’re all operating at a massive loss to establish the tech in your workflows, get you interested, and normalize AI as a tool. After people adopt it more the price will go up dramatically. \n\nCrack and meth dealers have used this technique for decades.  Netflix did it, phone carriers do it, cable TV did it.  \n\nIf AI providers manage to corner the market on hardware (which they’re doing right now), AI will be like oxygen in Total Recall.  They want insanely priced RAM and GPUs, because they can afford it and you can’t. They’ll just pass the cost on to the consumers.",
              "score": 38,
              "created_utc": "2026-01-18 19:02:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0c92dm",
                  "author": "ChainOfThot",
                  "text": "This isn't true, most leading labs would be profitable if they weren't investing in next gen models. Each new Nvidia chip gets massively more efficient at tokens/sec as well, price won't go up. All we've seen is they use the more tokens to provide more access to better intelligence. First thinking mode, now agentic mode, and so on. Blackwell to Rubin is going to be another massive leap as well and we'll see it play out this year.",
                  "score": 22,
                  "created_utc": "2026-01-18 19:10:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cd4ps",
                  "author": "evia89",
                  "text": "> Folks don’t seem to realize AI is in the “get you hooked” phase\n\nThere will be cheap providers like z.ai for ~20$/month or n@n0gpt ($8/60k requests). They are not top tier but good enough to do most tasks",
                  "score": 5,
                  "created_utc": "2026-01-18 19:29:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0dxz0d",
                  "author": "dogesator",
                  "text": "“Operating at a massive loss” \nExcept they’re not though, the latest data suggests both OpenAI and Anthropic actually have positive operating margins, not negative.\nBoth companies are overall in the red financially due to capex spent on building out datacenters for the next gen and next next gen, but they’re current inference operations are already making more revenue than what it costs to produce the tokens and more than what it cost to train the model that is producing those tokens.",
                  "score": 2,
                  "created_utc": "2026-01-19 00:16:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cpxyc",
                  "author": "AppealSame4367",
                  "text": "Difference is: There are global competitors from the get go. They are instantly launching in a market where others try to undercut them. They cannot stop with the 200$ per month subscriptions.\n\nMe, user of openai from the first hour, claude max user, with credits on windsurf, copilot, openrouter, I just try to get used to coding with Mistral CLI and API, because I am sick of American companies catering to a fascist regime and it's institutions. They threaten everybody and now they threaten Europe, so fuck them.\n\nSince many people feel this way, they won't sell big on the international stage in the near future. Because why would I choose AI from some American assholes when I can have slightly less capable AI from Europe / China + runners in Europe or other countries?",
                  "score": 4,
                  "created_utc": "2026-01-18 20:31:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0dwnqa",
                  "author": "Western_Objective209",
                  "text": "You can get a lot of usage of cheaper stuff like GLM for very little money. The cheaper stuff will continue to get better",
                  "score": 2,
                  "created_utc": "2026-01-19 00:09:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cf4u3",
                  "author": "West-Negotiation-716",
                  "text": "You seem to forget that we will all be able to train gpt5 on our cell phones in 10 years",
                  "score": 1,
                  "created_utc": "2026-01-18 19:39:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0rkqat",
                  "author": "Bobylein",
                  "text": ">AI will be like oxygen in Total Recall.\n\nNo, you need Oxygen to survive, so far I am rather struggling for uses to do with this tech, other than developing small CRUD apps as a hobby.\n\nYea I get that they want to implement it in everyday life and I am sure it will become important for many companies, as are other tech giants like microsoft, are already for decades but for the everyday person? I still struggle to see the appeal, other than a faster (and maybe reliable in the future) google search.\n\nEntertainment generation? Social media that turns into bot media? Maybe, I mean we're at it already but nothing of that is even close to Oxygen but rather a reason for ever more people to not even bother with these services anymore, at least that's what I am experiencing in my social circle.",
                  "score": 0,
                  "created_utc": "2026-01-21 00:11:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0rub2d",
                  "author": "Affectionate-Egg7566",
                  "text": "This is not true because AI providers do not require the network effect to work. Uber does, facebook does, but AI? You do not need other people to \"serve\" the service, you just need a rack to get started, and it can start relatively small.",
                  "score": 0,
                  "created_utc": "2026-01-21 01:03:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0cxxo4",
              "author": "lupin-the-third",
              "text": "I think people also don't realize there are open source models that are catching up with the big guys. If these catch up to claude and codex in utility and intelligence they sort of force a price point. After that it's a battle of tooling and integration which open source and unfortunately google/Microsoft will have an advantage in.",
              "score": 9,
              "created_utc": "2026-01-18 21:14:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0eermg",
                  "author": "Different_Doubt2754",
                  "text": "I don't see how open source models can force a price point. When you pay for AI, you aren't really paying for the model. You are paying for the service it provides. Sure, you can download an open source model and run it if you want, but you won't be getting the capabilities that GitHub Copilot or Claude Code or whatever Google comes up with provides you.\n\nOpen source models really have no effect on the price of proprietary models, unless of course they are cheaper to run. But that applies to competitor proprietary models too, not just open source.",
                  "score": 1,
                  "created_utc": "2026-01-19 01:48:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0etfzm",
                  "author": "WAHNFRIEDEN",
                  "text": "There’s nothing close to 5.2 Pro or 5.2 Codex",
                  "score": 0,
                  "created_utc": "2026-01-19 03:06:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0gku7c",
                  "author": "MacrosInHisSleep",
                  "text": "Which ones?",
                  "score": 0,
                  "created_utc": "2026-01-19 11:35:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0c4se5",
              "author": "opbmedia",
              "text": "I use about 30-40% of the tokens. But I can't step down to the next plan. But for $200, it's basically free compare to what it replaces (a couple of junior devs).",
              "score": 4,
              "created_utc": "2026-01-18 18:50:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0d8dr8",
                  "author": "FableFinale",
                  "text": "This is the big selling point. It's not whether it's objectively cheap, but even if it cost $4000/mo that's still way cheaper than even a single junior dev.",
                  "score": 2,
                  "created_utc": "2026-01-18 22:08:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0dtbri",
              "author": "TheDuhhh",
              "text": "Yeah I feel this is their business model. Initially, the first few users will max use it and generating a loss, but those users will advertise to others who will then subscribe but not use it enough so they in some sense  subsidize the power users.",
              "score": 1,
              "created_utc": "2026-01-18 23:51:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0dtpkm",
              "author": "one-wandering-mind",
              "text": "Yeah. I'd say they are operating at a loss but not to the degree that people think based on people posting and reading Reddit about this. \n\n\nSimilar to how gyms make money. Most people that have memberships don't go or don't go very often. If they did, the membership would cost 3x as much. ",
              "score": 1,
              "created_utc": "2026-01-18 23:53:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0dwiqu",
              "author": "Western_Objective209",
              "text": "At my work we use it with bedrock, and I'm not a $2000/month user, more like a $800/month. It's a lot of money, but we get so much done it's justified. Most of the people use $0/month, and have a GH and MS Copilot sub that they get near zero usage from. Kind of balances out",
              "score": 1,
              "created_utc": "2026-01-19 00:08:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0kjuwi",
              "author": "_crs",
              "text": "I don’t usually agree with Mr. Theo Browne but he had a good point about the usage of AI within the various subscription bands. People with $20 plans tend to use less than $20 worth. People spending $200 on a plan tend to use up to $200 or far more. There’s a big gap between the “average human” wanting to dabble in AI and builders/developer that will squeeze every drop out of their plans and more.",
              "score": 1,
              "created_utc": "2026-01-19 23:38:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0c406w",
              "author": "BERLAUR",
              "text": "I'm sure that there's some cases out there where this holds true but if I look how much tokens we're burning we must be costing them money. \n\n\nThere's a hug push to \"AI-ize\" all manual tasks now since if the models keep improving, eventually they'll do better than highly skilled humans anyway.",
              "score": 1,
              "created_utc": "2026-01-18 18:46:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ceiuj",
                  "author": "TheMightyTywin",
                  "text": "Yeah I’m on the $200 codex plan and I just used it to rewrite *all* of our docs in an enterprise application. Almost 500 high quality docs.\n\nI did hit the weekly limit doing this but I gotta imagine I used way more than $200 in tokens",
                  "score": 1,
                  "created_utc": "2026-01-18 19:36:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c0vgi",
          "author": "max1c",
          "text": "I'm not paying $2000 for RAM and $2000 for using AI. Pick one.",
          "score": 33,
          "created_utc": "2026-01-18 18:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e5cb7",
              "author": "ElementNumber6",
              "text": "> Pick one.\n\nThey already have.  They picked \"you will no longer own capable hardware\".  This is the first step toward that.\n\nNow please pay up.",
              "score": 6,
              "created_utc": "2026-01-19 00:55:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0c9s99",
              "author": "Aranthos-Faroth",
              "text": "Good point actually, at some point models will become good enough for most people’s needs to be run locally - so to stop that maybe they’re fucking over the ram and gpu markets so that can’t happen.",
              "score": -1,
              "created_utc": "2026-01-18 19:13:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cq6u9",
                  "author": "Mean_Employment_7679",
                  "text": "Not yet. I bought a 5090 partly thinking I might be able to cancel subscriptions. No. Sad.",
                  "score": 4,
                  "created_utc": "2026-01-18 20:33:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c2o5z",
          "author": "no-name-here",
          "text": "1. Big providers like OpenAI have already said that inference is profitable for them. It’s the training of new models that is not profitable.\n2. Others have already pointed out that a ton of people don’t max out their possible usage per month, making them particularly profitable.",
          "score": 22,
          "created_utc": "2026-01-18 18:40:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c6fc6",
              "author": "Keep-Darwin-Going",
              "text": "Mostly the corporate that do not max out, individual typically do because they will upgrade and downgrade accordingly to their needs while company just but a fixed plan and give to everyone. Which is also why Claude is more profitable than openai because they are way more corporate focus.",
              "score": 5,
              "created_utc": "2026-01-18 18:57:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0gbbi3",
              "author": "huzaa",
              "text": ">Big providers like OpenAI have already said that inference is profitable for them. It’s the training of new models that is not profitable.\n\nSo? It's like if a car company said: \"Manufacturing the cars are profitable, the only thing which pull us into red is the R&D and new models\"\n\nIf the market wants the new models and the competition is high they still have to produce the new models.",
              "score": 1,
              "created_utc": "2026-01-19 10:09:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mrgbp",
                  "author": "no-name-here",
                  "text": "> like if a car company\n\nCar companies are probably the opposite of the example you want to make - their R&D costs are only ~5%, the vast majority of costs are the costs to deliver each car.\n\nA better example would be software, such as Adobe, etc., where the really expensive thing is the development of new product versions, but even with per-customer customer support, marketing, sales, etc costs, each unit of software sold is profitable.\n\nSo the better analogy would be **Adobe** selling a **$200/mo** license to you, but provided greater than $200/mo of software if valued at the per-unit price while still only charging you $200/mo.\n\nAnd the OP tweet is *100%* about increasing inference, and 0% about needing or causing any new R&D or new models.",
                  "score": 1,
                  "created_utc": "2026-01-20 07:59:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0mx4ml",
                  "author": "DrProtic",
                  "text": "If they hit a wall with R&D they will scale it back and fall back to sustainable business model. \n\nAnd the wall is at the same place for everyone, if the tech is what limits them.",
                  "score": 1,
                  "created_utc": "2026-01-20 08:52:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c4tbk",
          "author": "lam3001",
          "text": "It ends like Napster and Uber?\nEg eventually the free/cheap stuff disappears and you end up with a lower quality service or none at all or more expensive and it gets worse before it gets better … and then slowly gets worse again",
          "score": 6,
          "created_utc": "2026-01-18 18:50:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gc9gf",
              "author": "gxsr4life",
              "text": "Napster and Uber were/are not critical to enterprise and corportations.",
              "score": 1,
              "created_utc": "2026-01-19 10:18:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0hec1p",
                  "author": "DeliciousArcher8704",
                  "text": "Neither are LLMs",
                  "score": 1,
                  "created_utc": "2026-01-19 14:44:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0e25cg",
          "author": "Crinkez",
          "text": "It won't be hugely relevant in a few years. Hardware is getting exponentially faster, and we continue to get software improvements. Today's 70B models trade blows with models 10x the size from 18 months ago. The memory shortage may last a while but production will increase. We'll eventually get to the point where enthusiasts can run near top end models on local hardware.\n\n\nIt will be a few years, but unless the world goes mad in unrelated topics, AI power and availability will improve, and costs will fall.",
          "score": 5,
          "created_utc": "2026-01-19 00:38:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e7q9t",
              "author": "thehashimwarren",
              "text": "I'm hoping this is what will happen",
              "score": 3,
              "created_utc": "2026-01-19 01:08:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0ggxad",
              "author": "EronEraCam",
              "text": "Hardware is no longer getting exponentially faster, same for storage. No one really wants to admit it, but with our current fab processes we crashed into diminishing returns a few years ago. Hopefully there is another hardware breakthrough soon, but Moore's Law hasn't looked good for half a decade now and it really does suck.\n\n\nI miss the years when hardware deflation outstripped inflation by a mile.",
              "score": 0,
              "created_utc": "2026-01-19 11:00:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0inzbl",
                  "author": "Crinkez",
                  "text": "Do you people do no research at all in your free time? https://www.youtube.com/watch?v=mvbsTCTXLJQ",
                  "score": 1,
                  "created_utc": "2026-01-19 18:13:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0c1xao",
          "author": "CC_NHS",
          "text": "my expectation is that it will end with close to free. the behaviour of eating a certain cost to retain user base, is aiming towards a win state where one will have 'the user base' they can monetise more heavily afterwards once the competition is pushed aside. aka Uber etc.\n\nI do not think this tech is the same as the kinds of things that method worked for in the past. the only way for that to happen is to capture the user base at the hardware/ operating system level for lock in, which is probably what they are all aiming for. But until that happens (or if) the 'war' will just continue with better, cheaper, more accessible for us :)\n\nwhy I say end with close to free. is because once the monopoly is obtained by a few companies, then revenue will likely be the typical user-as-product type deal all big tech go for, simply because there will still be more than one company doing this, and open source is following the heels of the giants the whole way there.",
          "score": 5,
          "created_utc": "2026-01-18 18:37:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ccuda",
          "author": "HeftyCry97",
          "text": "Wild to assume the value of the $200 Claude code plan is $2000\n\nJust because that’s the API price, doesn’t mean it’s worth it \n\nIf anything - it means $2000 of API is really worth $200, if that. \n\nOpen source models are getting better. At some point reality needs to set in that the costs of inference is greatly exaggerated.",
          "score": 7,
          "created_utc": "2026-01-18 19:28:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0f697g",
              "author": "kevin074",
              "text": "Exactly, how do you even start the calculations for that? Not every CEO has a PhD in math and even then it’s just speculated monetary worth, which we all know is meaningless to investors",
              "score": 0,
              "created_utc": "2026-01-19 04:25:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0chuhi",
          "author": "logicalish",
          "text": "I mean, says the guy that is assuming people will pay >0$ for a wrapper around said LLM coding plans? So far, their potentially monetizable features are not super attractive, and regardless I fail to understand how much of the 200/2000$ he expects they will be able to capture once the market stabilizes.",
          "score": 2,
          "created_utc": "2026-01-18 19:52:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dfi3h",
          "author": "9oshua",
          "text": "The estimate is that OSS models are 7 months behind frontier models. The answer is pay for your own inference machine, DL the best version it can handle and do as much inference as you want.",
          "score": 2,
          "created_utc": "2026-01-18 22:41:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ixow0",
          "author": "El_Danger_Badger",
          "text": "Do the max tiers get access to better models? I hear they get faster responses on deep reasoning, but who knows. I imagine $200 must be well worth the extra expense up from the $20 tiers. Free tiers are useless. You can't possibly do long term work capped at a few messages per day. $20 is free for this. best money I've ever spent. ",
          "score": 2,
          "created_utc": "2026-01-19 18:56:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kg398",
              "author": "mariebks",
              "text": "They do get access to Pro models for OpenAI $200/mo plan, but no Pro Claude model on MAX",
              "score": 2,
              "created_utc": "2026-01-19 23:17:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0kzppf",
                  "author": "El_Danger_Badger",
                  "text": "Wow! I can't imagine even imagine what that next tier model must be doing. Decisions... Which future tech to choose, I suppose. Thanks! Very good to know. ",
                  "score": 1,
                  "created_utc": "2026-01-20 01:03:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jqhww",
          "author": "jonplackett",
          "text": "1. Everything gets cheaper. \n2. They don’t plan on making their money selling us commoners a monthly sub, they plan on selling a replacement for us to our billionaire owners.",
          "score": 2,
          "created_utc": "2026-01-19 21:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c7z8q",
          "author": "ajwin",
          "text": "I think the cost of inference will come down in orders of magnitude each year. Even NVidias deal with Groq will likely lead to massive reductions in token inference pricing  else why do it?",
          "score": 4,
          "created_utc": "2026-01-18 19:04:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cbh1q",
              "author": "who_am_i_to_say_so",
              "text": "It seems like everyone forgets Moore's law. These models already produce production-worthy code (not great, but a start) and at this level, the cost of operation will continue to drop, not increase.",
              "score": 3,
              "created_utc": "2026-01-18 19:21:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0clqod",
                  "author": "shif",
                  "text": "Isn't Moore's law dead? last I heard we got to the point where quantum mechanics are becoming an issue due to the size of transistors",
                  "score": 4,
                  "created_utc": "2026-01-18 20:11:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0cftpn",
                  "author": "West-Negotiation-716",
                  "text": "Exactly, how are people forgetting that we now have a million dollar super computer in our pocket.\n\nWe will be able to train our own gpt5 on our laptop in 10 years, and on our cell phone in 15",
                  "score": 3,
                  "created_utc": "2026-01-18 19:42:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0crt4p",
          "author": "TCaller",
          "text": "Cost per unit of intelligence will only go down. That’s ultimately the only thing that matters.",
          "score": 2,
          "created_utc": "2026-01-18 20:40:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dbizs",
          "author": "formatme",
          "text": "[Z.AI](http://Z.AI) already won in my eyes with their pricing, and their open source model is in the top 10",
          "score": 2,
          "created_utc": "2026-01-18 22:22:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dkv9l",
          "author": "According-Tip-457",
          "text": "Sucks for them. I'm MILKING their models to the MAX, all while chucking with my Monster AI build. Local models are catching up quick. Only a matter of time. ;) By time cost goes up to $500/m I'll be chucking running Minimax 7.4 on my machine free of charge.",
          "score": 2,
          "created_utc": "2026-01-18 23:07:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c4b8m",
          "author": "opbmedia",
          "text": "I am on the $200/month codex plan. It is okay, does most things okay and are quite bone headed at other times. It is however 100% more preferable than paying $6-8000/month for a warm body. so It's a win. It makes me work more (since the response is 10-100x faster) and faster. It's a good thing. I'd probably pay $2000 a month, not that I want to because there will be others undercutting the price.",
          "score": 1,
          "created_utc": "2026-01-18 18:48:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c6gxp",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-18 18:57:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c6gzj",
              "author": "AutoModerator",
              "text": "Your comment appears to contain promotional or referral content, which is not allowed here.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-18 18:57:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0cicsx",
          "author": "real_serviceloom",
          "text": "Local LLMs are getting better at a rate that this isn't a big concern for me",
          "score": 1,
          "created_utc": "2026-01-18 19:54:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0clmxn",
          "author": "holyknight00",
          "text": "That's the providers fault not ours. They should be optimizing costs to make the 200$ worth it.",
          "score": 1,
          "created_utc": "2026-01-18 20:10:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cqb6u",
          "author": "Tupptupp_XD",
          "text": "Cost of intelligence keeps going down. Next year, we will have models equally as capable as codex 5.2 xhigh or Opus 4.5 for 10x cheaper",
          "score": 1,
          "created_utc": "2026-01-18 20:33:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cxm68",
          "author": "027a",
          "text": "Tbh, I think the pool of people willing to pay $20-$40/mo and use less-than $20-$40 in usage is much larger than the group who will pay $200 and use $2000; and somewhere in that margin + some intelligent model routing to help control costs + costs go down + small models get more intelligent, there's still plenty of profit. These model companies aren't unprofitable because of inference, they're unprofitable because of footprint expansion & training.",
          "score": 1,
          "created_utc": "2026-01-18 21:12:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dfh8x",
          "author": "echo-whoami",
          "text": "There’s also a group of people who is expecting not to get RCEd through their coding tool.",
          "score": 1,
          "created_utc": "2026-01-18 22:41:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0dfw2a",
          "author": "nethingelse",
          "text": "I mean, the thing is that not EVERYONE on a $200, $20, $9, etc. plan is utilizing all of the limits of that plan per month. Especially in OpenAI/ChatGPT-land where the userbase is more universal than just devs/tech-y people. The idea of a subscription in this context is you don't want everyone ever to use the plan up, so that you have profitable users that can subsidize people who do maximize.\n\nAt the end of the day, no one but OpenAI has access to their numbers since they're not publicy traded, but I'd imagine (with knowledge of open source/local models) inference is closer to profitability than training new models is, and new models is where the cost sink is.",
          "score": 1,
          "created_utc": "2026-01-18 22:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0doriu",
          "author": "garloid64",
          "text": "it ends at the same end user cost but now profitably because hardware got ten times better, again",
          "score": 1,
          "created_utc": "2026-01-18 23:27:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e3q9a",
          "author": "damanamathos",
          "text": "I maxed out my $200 OpenAI account and have 2 $200 Claude accounts because 1 maxes out each week.\n\nI'm tempted to bite the bullet and just pay thousands per month for the API to better integrate it across my systems...",
          "score": 1,
          "created_utc": "2026-01-19 00:46:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g3qfs",
          "author": "Square_Weather_8137",
          "text": "There already papers on establishing lower token use for the same context. **Retrieval-Augmented Generation (RAG)** applied to conversation history is one i read recently. i could assume that price and reduced power usage will converge",
          "score": 1,
          "created_utc": "2026-01-19 08:57:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g6sgq",
          "author": "RiriaaeleL",
          "text": "Thanks god alphabet runs on ads, bard being a free product is insane, they could ask a lot of money for it",
          "score": 1,
          "created_utc": "2026-01-19 09:26:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0g721q",
          "author": "pip25hu",
          "text": "For me $200 a month is already ridiculous. If even that can't cover the company's costs, then they have a dire future ahead of them.",
          "score": 1,
          "created_utc": "2026-01-19 09:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gbkt3",
          "author": "huzaa",
          "text": "If they have ask for $2000 per dev just to be profitable, what amount would give them an actual good ROI? $3000, $4000? At that point companies would be better of just outsourcing. No wonder they want government money...",
          "score": 1,
          "created_utc": "2026-01-19 10:11:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0glhu7",
          "author": "RealMadalin",
          "text": "Burning vc money ;)",
          "score": 1,
          "created_utc": "2026-01-19 11:40:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0grkr1",
          "author": "Crashbox3000",
          "text": "I was going through some angst about this myself recently and did some basic research on the cost of these subscriptions to the providers and I was pleasantly surprised that this narrative about massive subsidies is just not accurate. These companies are making a profit on these plans and they are using them as a sales funnel for other services either now or in the future. There is not evidence that I could find to indicate that prices of subscriptions will do anything but go down or stay flat and include more. \n\nSeems like a lot of hype to get people super happy to pay $200 and feel lucky.",
          "score": 1,
          "created_utc": "2026-01-19 12:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gwd3a",
          "author": "jointheredditarmy",
          "text": "There’s a couple of different articles that actually did the math and came to very different conclusions. Either LLMs are making some money or losing a little bit of money. No one is losing their shirts.\n\nYou can actually try this yourself. If you have an AWS rep (or equivalent on GCP or Microsoft cloud or whatever), ask for dedicated instance prices. It’ll come with a price tag and a “estimated inputs / output tokens per hour”metric for each model. This number should be the raw capabilities number, since you’re “buying” the entire instance. The first thing you’ll see is that the numbers are jarring. For example, the “public” per token pricing for Opus is $5 per million input tokens and $25 per million output tokens. 5x ratio. The actual capabilities is more like 100 input tokens for every 1 output token. This means the hosted providers are making a shitload off input tokens, which are essentially free.\n\nSo im not convinced they’re losing their shirts on inference alone. It’s the massive salary bloat killing them right now.",
          "score": 1,
          "created_utc": "2026-01-19 13:01:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h60qm",
              "author": "thehashimwarren",
              "text": "Please link me if you still have those articles. Would like to read",
              "score": 1,
              "created_utc": "2026-01-19 13:59:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0im4u2",
          "author": "Giant_leaps",
          "text": "lol i might actually use copilot if things get to expensive or maybe i'll try to run a local version if gpus become cheaper",
          "score": 1,
          "created_utc": "2026-01-19 18:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0in7aw",
          "author": "Responsible-Buyer215",
          "text": "People think they’re getting value when they’re actually feeding it all their ideas while AI quietly harvests the best ideas and innovations to present to the people it’s actually operating for. \n\nWe leave in an age where everyone happily uploads their personal design diaries to AI for help but don’t realise they’re just giving away their most valuable ideas away for free",
          "score": 1,
          "created_utc": "2026-01-19 18:10:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0inspy",
          "author": "all_over_the_map",
          "text": "Isn't the price and the \"value\" what the market will bear? Maybe what he thinks is worth $2,000 is what the rest of us think is worth $200?",
          "score": 1,
          "created_utc": "2026-01-19 18:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iw89s",
          "author": "HarambeTenSei",
          "text": "I only feel satisfied with my cursor does 10m+ tokens per prompt ",
          "score": 1,
          "created_utc": "2026-01-19 18:49:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0iwvtg",
          "author": "Crafty_Ball_8285",
          "text": "I don’t understand any of this. wtf?",
          "score": 1,
          "created_utc": "2026-01-19 18:52:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jd2tg",
          "author": "SomeWonOnReddit",
          "text": "They don’t need to win $200 users. The real professionals get AI for free through work. They don’t need to pay anything.",
          "score": 1,
          "created_utc": "2026-01-19 20:06:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jtw0b",
              "author": "thehashimwarren",
              "text": "Would you agree that the $200 users are the champions who convince a company to buy the team plans?",
              "score": 1,
              "created_utc": "2026-01-19 21:25:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jmgye",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-19 20:50:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jmh0t",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-19 20:50:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0jtvyi",
          "author": "Aperturebanana",
          "text": "There’s a point when the model will be good enough for majority of things compared to the skill necessary to ship a coding project one shot.\n\nInference gets cheaper over-time due to advancements in model development.",
          "score": 1,
          "created_utc": "2026-01-19 21:25:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lfbnv",
          "author": "Low-Efficiency-9756",
          "text": "This is free silly imo. We’re going to either\n\nA. Finalize fusion with AI\nB. Finalize fusion with AI\n\nCompute cost will continue to go down\n\nA. Increase power supply\nB. Decrease power requirements for inference over time\nC. Increase capability of OSS models that make SOTA models less mainstream. \n\nD. Who fucking knows we can’t predict the future.",
          "score": 1,
          "created_utc": "2026-01-20 02:29:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mbkf0",
          "author": "Current-Buy7363",
          "text": "It ends the same way every other startup ends. Everything is free until the VC money ends and the investors want there money back.\n\nThis is the oldest game that every startup up runs, you burn cash in return for customer acquisition then you bump up the price when the funding isn’t enough\n\nThis path is obviously not sustainable. Companies like chatpgt can survive off this business model because most customers will use less inference than they pay, they use power users to suck in normies on the low tiers. Then later they can close the taps for power users and they’ll still have the normies who are happy to buy $5-10-20/month, but without the inference hungry devs and power users who will have the choice of API cost of gtfo",
          "score": 1,
          "created_utc": "2026-01-20 05:45:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mjwnv",
          "author": "toadi",
          "text": "After a full year of using LLMs in professional software development. I can say they are awesome as tools in the process. Also if you use them right there is not much difference between and opensource model vs the closed source models. \n\nThe opensource models are much cheaper to use.",
          "score": 1,
          "created_utc": "2026-01-20 06:53:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mljua",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 07:06:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mljvw",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 07:06:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n611f",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 10:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0n612u",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 10:16:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0nc3kj",
          "author": "Confusion_Senior",
          "text": "For the current model skillset the costs are going doing by a lot in the future",
          "score": 1,
          "created_utc": "2026-01-20 11:10:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0o7wq2",
          "author": "Express_Position5624",
          "text": "They think their spell check is giving $2k if value.\n\nI expect that having a \"Spellcheck\" function as part of your applications will become standard and expected",
          "score": 1,
          "created_utc": "2026-01-20 14:34:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p6dom",
          "author": "Razee4",
          "text": "For 2000$ you can host your own, competent AI at home. Unless you really, really need to generate videos for some reason.",
          "score": 1,
          "created_utc": "2026-01-20 17:19:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pu90j",
          "author": "dronegoblin",
          "text": "people paid for ubers at $5 and at $55 for the same ride. Devs will pay at $200 and $2000. Consumers will be priced out and development prices will rise",
          "score": 1,
          "created_utc": "2026-01-20 19:06:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c5hhg",
          "author": "hejj",
          "text": "I'm ok with unsustainable business models not being sustainable.  If we have to face a future where large scale production of AI slop media content, easily automated misinformation and scamming, and mass IP theft aren't financially viable, then I'm ok with that and I look forward to being able to afford computer hardware again so that I can run coding models locally.  And if it all turns into a pricing race to the bottom for vended AI inference, that's ok too.",
          "score": 1,
          "created_utc": "2026-01-18 18:53:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c239c",
          "author": "DauntingPrawn",
          "text": "They will always need us. We're really the only ones putting the models through the paces, informing them (through our internet complaints) when their changes degrade model performance. We are the canary in the coalmine for their inference stack and optimization techniques that often fail. We monitor their systems in a way they cannot. They can't do business without us, and more and more we can't do business without them.",
          "score": 0,
          "created_utc": "2026-01-18 18:38:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c5bbg",
          "author": "Illustrious-Film4018",
          "text": "Yeah and people complain about the limits and having to pay $200. These people are idiots, they have no idea how much VC money they're burning and how much it would've cost before AI to hire a human dev. \n\nThis is proof that they don't deserve anything. AI gives unworthy idiots capabilities they should never have in the first place. And anyone who thinks it's a good idea to democratize literally EVERYTHING, so nothing is sacred anymore, is also an idiot. This is going to destroy the economy, it's not sustainable at all. You'll see where this leads... Nothing is free in life, you all are going to pay for it, one way or another (worse) way.",
          "score": -3,
          "created_utc": "2026-01-18 18:52:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c63xm",
          "author": "Final_Alps",
          "text": "I am enjoying the venture subsidised AI lifestyle. \n\nI always eagerly participate in the newest venture funded fad and get great value for very little money. It’s about the only downward wealth transfer we have left in much of the West.",
          "score": 0,
          "created_utc": "2026-01-18 18:56:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cia1a",
              "author": "logicalish",
              "text": "Have you noticed how once the honeymoon phase you’re talking about ends, the wealth inequality has only gotten significantly worse? We’re trading a very short period of personal benefit for the few, for future pain for all.",
              "score": 2,
              "created_utc": "2026-01-18 19:54:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0cjcnq",
                  "author": "Final_Alps",
                  "text": "Is there anything you think I, personally, or we, collectively, can do about it?",
                  "score": 1,
                  "created_utc": "2026-01-18 19:59:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0d6ti7",
          "author": "nanokeyo",
          "text": "Anthropic is making money… stop crying by them.",
          "score": 0,
          "created_utc": "2026-01-18 22:00:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeq6yd",
      "title": "Codex is about to get fast",
      "subreddit": "ChatGPTCoding",
      "url": "https://i.redd.it/faicwqlvmrdg1.png",
      "author": "thehashimwarren",
      "created_utc": "2026-01-16 19:49:14",
      "score": 231,
      "num_comments": 96,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qeq6yd/codex_is_about_to_get_fast/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzzk4r5",
          "author": "TheMacMan",
          "text": "Press release for those curious. It's a partnership allowing OpenAI to utilize Cerebras wafers. No specific dates, just rolling out in 2026.\n\n[https://www.cerebras.ai/blog/openai-partners-with-cerebras-to-bring-high-speed-inference-to-the-mainstream](https://www.cerebras.ai/blog/openai-partners-with-cerebras-to-bring-high-speed-inference-to-the-mainstream)",
          "score": 35,
          "created_utc": "2026-01-16 20:32:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02zfdk",
              "author": "amarao_san",
              "text": "So, even more chip production capacity is eaten away.\n\nThey took GPUs. I wasn't a gamer, so I didn't protest.\n\nThey took RAM. I wasn't much of a ram hoarder, so I didn't protest.\n\nThey took SSD. I wasn't much of space hoarder, so I didn't protest.\n\nThen they come for chips. Computation including. But there was none near me to protest, because of ai girlfriends and slop...",
              "score": 16,
              "created_utc": "2026-01-17 10:08:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04z2lj",
                  "author": "eli_pizza",
                  "text": "You were planning to do something else with entirely custom chips built for inference?",
                  "score": 10,
                  "created_utc": "2026-01-17 17:26:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0i9i4d",
                  "author": "_jgusta_",
                  "text": "(i got the joke, don't worry)",
                  "score": 1,
                  "created_utc": "2026-01-19 17:08:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00bssx",
          "author": "UsefulReplacement",
          "text": "It might also become randomly stupid and unreliable, just like the Anthropic models. When you run the inference across different hardware stacks, you have a variety of differences and subtle but performance-impacting bugs show up. It’s a challenging problem keeping the model the same across hardware.",
          "score": 52,
          "created_utc": "2026-01-16 22:45:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08bltx",
              "author": "JustThall",
              "text": "My team was running into all sorts of bugs when run a mix and match training and inference stacks with llama/mistral models. I can only imagine the hell they gonna run into with MoE and different hardware support of mixed precision types.",
              "score": 5,
              "created_utc": "2026-01-18 03:39:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o015x5b",
              "author": "YourKemosabe",
              "text": "Was looking for this comment. God I hope they don’t ruin Codex too.",
              "score": 2,
              "created_utc": "2026-01-17 01:39:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o02scmk",
              "author": "Tolopono",
              "text": "Its the same weights and same math though. I dont see how it would change anything ",
              "score": 2,
              "created_utc": "2026-01-17 09:01:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o033um9",
                  "author": "UsefulReplacement",
                  "text": "clearly you have no clue then",
                  "score": -8,
                  "created_utc": "2026-01-17 10:49:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzwpra",
          "author": "aghowl",
          "text": "What is Cerebras?",
          "score": 13,
          "created_utc": "2026-01-16 21:32:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzzgrt",
              "author": "innocentVince",
              "text": "Inference provider with custom hardware.",
              "score": 15,
              "created_utc": "2026-01-16 21:45:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o002kha",
                  "author": "io-x",
                  "text": "Are they public?",
                  "score": 5,
                  "created_utc": "2026-01-16 21:59:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o04h6c1",
                  "author": "eli_pizza",
                  "text": "Custom hardware built for inference speed. Currently the fastest throughput for open source models, by a lot.",
                  "score": 2,
                  "created_utc": "2026-01-17 16:02:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00l1qv",
                  "author": "pjotrusss",
                  "text": "what does it mean? more GPUs?",
                  "score": 2,
                  "created_utc": "2026-01-16 23:35:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0gmz1q",
              "author": "chawza",
              "text": "They provide x times inference speed with x times amount of price.",
              "score": 1,
              "created_utc": "2026-01-19 11:52:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ij90b",
                  "author": "aghowl",
                  "text": "makes sense. thanks.",
                  "score": 1,
                  "created_utc": "2026-01-19 17:52:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o00ctl6",
          "author": "Square-Ambassador-92",
          "text": "Nobody asked for fast … we need very intelligent",
          "score": 24,
          "created_utc": "2026-01-16 22:50:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00e7v3",
              "author": "Outrageous-Thing-900",
              "text": "Codex is extremely slow, and a lot of people complain about it",
              "score": 40,
              "created_utc": "2026-01-16 22:58:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o018l51",
                  "author": "not_the_cicada",
                  "text": "It also continuously forgets how to walk the code base and uses really odd choices that bog it down and make it even slower. ",
                  "score": 8,
                  "created_utc": "2026-01-17 01:56:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o02gayo",
                  "author": "SpyMouseInTheHouse",
                  "text": "Those who complain are welcome to move to Claude code.",
                  "score": 1,
                  "created_utc": "2026-01-17 07:10:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00h0jc",
              "author": "mimic751",
              "text": "Be a developer",
              "score": 9,
              "created_utc": "2026-01-16 23:13:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00mjls",
                  "author": "Ok_Possible_2260",
                  "text": "Find out your code is shit in 10 seconds is better than 40 minutes. ",
                  "score": 6,
                  "created_utc": "2026-01-16 23:44:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o02aina",
              "author": "realfunnyeric",
              "text": "It’s brilliant. But slow. This is the right move.",
              "score": 5,
              "created_utc": "2026-01-17 06:19:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00pm2p",
              "author": "Shoddy-Marsupial301",
              "text": "I ask for fast..",
              "score": 2,
              "created_utc": "2026-01-17 00:01:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o04jzen",
              "author": "eli_pizza",
              "text": "Couldn’t disagree more. Very fast inference means I can work with a coding agent in real time, instead of kicking off a request and doing something else while it works and switching back.   I think a lot of the multi agent orchestration stuff going on now is really a hack because inference is so slow. \n\nAnd if something looks off in the diff I’m more likely to guide it to do better if it makes the update instantly. \n\nMy GLM 4.6 subscription on Cerebras is great for front end work. I can just say “make the text colors darker” “no not that dark” and see the changes instantly.",
              "score": 1,
              "created_utc": "2026-01-17 16:15:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0jpvk6",
              "author": "Pitch_Moist",
              "text": "I am asking for fast.",
              "score": 1,
              "created_utc": "2026-01-19 21:06:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00kew9",
          "author": "whawkins4",
          "text": "Yeah, but is it GOOD?",
          "score": 4,
          "created_utc": "2026-01-16 23:32:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o038gke",
          "author": "jonas_c",
          "text": "Faster codex with existing models or a fast model that no one wants?",
          "score": 3,
          "created_utc": "2026-01-17 11:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00qikd",
          "author": "dalhaze",
          "text": "Yeah also quantized to ass",
          "score": 5,
          "created_utc": "2026-01-17 00:06:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzvxcr",
          "author": "AppealSame4367",
          "text": "Yes, that would really be something!",
          "score": 2,
          "created_utc": "2026-01-16 21:28:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o043g2q",
          "author": "Sufficient-Year4640",
          "text": "What does he mean by fast exactly? I've been using Codex for a while and it seems pretty fast. Like is it actually slower than Claude or something?",
          "score": 2,
          "created_utc": "2026-01-17 14:54:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04oxrm",
              "author": "thehashimwarren",
              "text": "People report that Claude Opus 4.5 is faster",
              "score": 2,
              "created_utc": "2026-01-17 16:39:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ajimt",
          "author": "Adventurous-Bet-3928",
          "text": "Damn. I was in a call with Cerebras and was asking them why the big AI companies weren't using them just a few weeks ago.",
          "score": 2,
          "created_utc": "2026-01-18 14:12:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0bv9w2",
              "author": "thehashimwarren",
              "text": "That's funny!",
              "score": 1,
              "created_utc": "2026-01-18 18:07:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0kf9vv",
          "author": "drhenriquesoares",
          "text": "Fast marketing is key.",
          "score": 2,
          "created_utc": "2026-01-19 23:13:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00cm1k",
          "author": "OccassionalBaker",
          "text": "It needs to be right before I can get excited about it being fast - being wrong faster isn’t that useful.",
          "score": 4,
          "created_utc": "2026-01-16 22:49:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00edo5",
              "author": "touhoufan1999",
              "text": "Codex with gpt-5.2-xhigh is as accurate as you can get at the moment. Extremely low hallucination rates even on super hard tasks. It's just very slow right now. Cerebras says they're around 20x faster than NVIDIA at inference.",
              "score": 5,
              "created_utc": "2026-01-16 22:59:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o02n508",
                  "author": "OccassionalBaker",
                  "text": "I’ve been writing code for 20 years and have to disagree that the hallucinations are very low, I’m constantly fixing its errors.",
                  "score": 0,
                  "created_utc": "2026-01-17 08:12:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzzuzxd",
          "author": "MXBT9W9QX96",
          "text": "Wow huge news",
          "score": 2,
          "created_utc": "2026-01-16 21:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00u3um",
          "author": "Opinion-Former",
          "text": "Fast is good, compliant and following instructions is better.",
          "score": 1,
          "created_utc": "2026-01-17 00:27:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o08z4dm",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-01-18 06:23:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o08z4en",
                  "author": "AutoModerator",
                  "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-01-18 06:23:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o01r47b",
          "author": "roinkjc",
          "text": "It’s the best for complicated setups, I hope they keep it that way",
          "score": 1,
          "created_utc": "2026-01-17 03:55:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02wozm",
          "author": "GnistAI",
          "text": "Fast, as in tokens per second? The limiting factor right now is not tokens per second, it is bugs per hour.",
          "score": 1,
          "created_utc": "2026-01-17 09:42:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02x203",
          "author": "tango650",
          "text": "How is \"low latency\" different from \"fast\" in the context of inference. Anyone ?",
          "score": 1,
          "created_utc": "2026-01-17 09:46:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o04verw",
              "author": "ExcitingAssistance",
              "text": "Same as ping vs download speed",
              "score": 2,
              "created_utc": "2026-01-17 17:08:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o04znn9",
                  "author": "tango650",
                  "text": "Thanks for your input. It is quite unusable but thanks anyway.",
                  "score": 1,
                  "created_utc": "2026-01-17 17:28:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o07th7p",
              "author": "hellomistershifty",
              "text": "Time to first token vs tokens/second",
              "score": 2,
              "created_utc": "2026-01-18 01:58:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09cv9a",
                  "author": "tango650",
                  "text": "Thanks. Do you know how hardware of the processor influences this ? And what order of difference are we talking about ?",
                  "score": 1,
                  "created_utc": "2026-01-18 08:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o03thxs",
          "author": "phylter99",
          "text": "We'll be able to burn through our credits faster than ever.",
          "score": 1,
          "created_utc": "2026-01-17 14:01:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05bmq0",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-17 18:24:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05bmt3",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-17 18:24:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ktken",
          "author": "Tushar_BitYantriki",
          "text": "Nice, it's about time a decent model gets fast.\n\nhaiku is too silly, Composer 1 is decent.\n\nI hate having to waste opus or sonnet, or GPT 2 or 1 on the grunt work of writing code, after the design and examples are ready in the plan.\n\nGPT-mini is decent, though.",
          "score": 1,
          "created_utc": "2026-01-20 00:30:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mc2ns",
          "author": "CrypticZombies",
          "text": "At the low price of $549.99 per day",
          "score": 1,
          "created_utc": "2026-01-20 05:49:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n62tf",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 10:16:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0n62uj",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 10:16:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o01abm1",
          "author": "bhannik-itiswatitis",
          "text": "oh nice, fast hallucinations",
          "score": 0,
          "created_utc": "2026-01-17 02:07:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02hh6t",
              "author": "popiazaza",
              "text": "This is GPT 5, not Gemini.",
              "score": 4,
              "created_utc": "2026-01-17 07:20:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o00lphz",
          "author": "Zealousideal-Idea-72",
          "text": "Who uses OpenAI anymore though?  Anthropic (coding) and Gemini (general purpose) have surpassed them.",
          "score": -7,
          "created_utc": "2026-01-16 23:39:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00o96y",
              "author": "Kooky_Tourist_3945",
              "text": "900 million active monthly users.\nAre you dumb.",
              "score": 6,
              "created_utc": "2026-01-16 23:53:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00ptux",
              "author": "NotSGMan",
              "text": "You wont believe how good codex 5.2 xhigh is",
              "score": 7,
              "created_utc": "2026-01-17 00:02:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01s9yr",
                  "author": "Freed4ever",
                  "text": "Or just high...",
                  "score": 1,
                  "created_utc": "2026-01-17 04:03:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o01vhe4",
                  "author": "ThisGuyCrohns",
                  "text": "Not even close to opus",
                  "score": 1,
                  "created_utc": "2026-01-17 04:25:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0173yc",
              "author": "rambouhh",
              "text": "I dont know codex seems to be very very popular right now. The consensus seems to be shifting to that codex is better for longer complex tasks but slower, and CC is better for the simple stuff because it is so much faster",
              "score": 3,
              "created_utc": "2026-01-17 01:47:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o01vfbr",
                  "author": "ThisGuyCrohns",
                  "text": "Not really. Claude is where it’s at. Codex was good 3 months ago. Claude overtook that and there isn’t a reason to go back",
                  "score": 1,
                  "created_utc": "2026-01-17 04:25:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00slgd",
              "author": "iritimD",
              "text": "Anyone who is serious about coding uses either a mix of cc and 5.2 codex or just codex",
              "score": 4,
              "created_utc": "2026-01-17 00:18:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o012ci2",
                  "author": "robogame_dev",
                  "text": "TIL I’m not serious about coding :’(",
                  "score": 2,
                  "created_utc": "2026-01-17 01:17:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o02a6mv",
                  "author": "TenshiS",
                  "text": "Opus 4.5 undefeated",
                  "score": 1,
                  "created_utc": "2026-01-17 06:17:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qi4sq0",
      "title": "My company banned AI tools and I dont know what to do",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qi4sq0/my_company_banned_ai_tools_and_i_dont_know_what/",
      "author": "simple_pimple50",
      "created_utc": "2026-01-20 15:54:25",
      "score": 51,
      "num_comments": 187,
      "upvote_ratio": 0.73,
      "text": "\nSecurity team sent an email last month. No AI tools allowed. No ChatGPT, no Claude, no Copilot, no automation platforms with LLMs.\n\nTheir reasoning is data privacy and theyre not entirely wrong. We work with sensitive client info.\n\nBut watching competitors move faster while we do everything manually is frustrating. I see what people automate here and know we could benefit.\n\nSome people on my team are definitely using AI anyway on personal devices. Nobody talks about it but you can tell.\n\nI'm torn between following policy and falling behind or finding workarounds that might get me in trouble.\n\nTried bringing it up with my manager. Response was \"policy is policy\" and maybe they'll revisit later. Later meaning probably never.\n\nAnyone dealt with this? Did your company change their policy? Find ways to use AI that satisfied security? Or just leave for somewhere else?\n\nSome mentioned self hosted options like Vellum or local models but I dont have authority to set that up and IT wont help.\n\nFeels like being stuck in 2020.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qi4sq0/my_company_banned_ai_tools_and_i_dont_know_what/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o0ot5md",
          "author": "WeMetOnTheMountain",
          "text": "Welcome to local llama.",
          "score": 103,
          "created_utc": "2026-01-20 16:17:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qu0vv",
              "author": "isarmstrong",
              "text": "Correct answer. HIPPA and finance have to run local workloads instead of cloud. It’s why anything with a 10MW radial connect on Howard St in SF can ask double the class A market rate on a lease. Lab grade space is almost impossible to find within SF city limits.",
              "score": 12,
              "created_utc": "2026-01-20 21:52:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0qzn34",
                  "author": "Peter-rabbit010",
                  "text": "Bgi o7",
                  "score": 0,
                  "created_utc": "2026-01-20 22:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0s3gxp",
              "author": "kyngston",
              "text": "how does local llama prevent prompt injection that tells an agent to exfiltrate client data?",
              "score": 0,
              "created_utc": "2026-01-21 01:56:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0s406y",
                  "author": "OuchieMaker",
                  "text": "Locally hosted LLMs prevent data privacy issues because all the sensitive data stays local. What prompt injection are you talking about? Nobody outside of the org should have access to the LLM",
                  "score": 3,
                  "created_utc": "2026-01-21 01:59:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0pkd2j",
              "author": "m3kw",
              "text": "Welcome to prompt injection",
              "score": -23,
              "created_utc": "2026-01-20 18:22:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0q1chi",
                  "author": "Onaliquidrock",
                  "text": "Why would that be an issue for a locally run LLM used internally?",
                  "score": 9,
                  "created_utc": "2026-01-20 19:39:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0qnfr6",
                  "author": "93simoon",
                  "text": "Welcome to not knowing what you're talking about.",
                  "score": 3,
                  "created_utc": "2026-01-20 21:22:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0qqd0j",
                  "author": "JohnnyJordaan",
                  "text": "What exactly about the word \"local\" don't you understand?",
                  "score": 0,
                  "created_utc": "2026-01-20 21:35:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oqnw4",
          "author": "UnbeliebteMeinung",
          "text": "Leave.\n\nYou will get behind if you dont learn the new stuff. Also this company will get problems.",
          "score": 173,
          "created_utc": "2026-01-20 16:06:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p2yhp",
              "author": "realityczek",
              "text": "This. If you can find a new job (it's a tough market) get out of there.",
              "score": 22,
              "created_utc": "2026-01-20 17:03:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0ospim",
              "author": "thisisaskew",
              "text": "Yep, time to leave.",
              "score": 15,
              "created_utc": "2026-01-20 16:15:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pk41h",
              "author": "m3kw",
              "text": "Lots of company with sensitive data/processes is still figuring out how to allow it at work",
              "score": 12,
              "created_utc": "2026-01-20 18:21:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0q76h2",
                  "author": "Ancient-Purpose99",
                  "text": "The solutions exist, yes they cost tons of money since llm providers know these companies have no other choice but at this point it's more about them not wanting to spend the money",
                  "score": 4,
                  "created_utc": "2026-01-20 20:06:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0poduw",
                  "author": "pete_68",
                  "text": "They've had years to sort it out. Now they're going to start losing people because they failed.",
                  "score": 3,
                  "created_utc": "2026-01-20 18:40:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pk926",
                  "author": "UnbeliebteMeinung",
                  "text": "Buy hardware",
                  "score": 1,
                  "created_utc": "2026-01-20 18:22:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0r5q7r",
                  "author": "Western_Objective209",
                  "text": "You use your cloud providers models. Same exact data protections. If you don't use cloud, and don't have a plan to host your own models, the company is just fucked, and yeah OP should leave",
                  "score": 0,
                  "created_utc": "2026-01-20 22:50:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qas4u",
              "author": "Desolution",
              "text": "This is dead on. \n\n\nBut it's really weird to be on an AI thread on Reddit and not see \"good, AI slop, useless for everything, only bad engineers use it\"",
              "score": 3,
              "created_utc": "2026-01-20 20:23:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0qxtz1",
                  "author": "Own_Amoeba_5710",
                  "text": "![gif](giphy|kd9BlRovbPOykLBMqX)\n\nThere is a new group of people who want to be the first person to call anything that even remotely resembles AI as AI slop. I get it because of the bots that are in every subreddit but at this point, em dashes can no longer be used in text lol.",
                  "score": 2,
                  "created_utc": "2026-01-20 22:10:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0rvyvw",
                  "author": "truthputer",
                  "text": "It's very simple: the coding tools improved.\n\nAnd people are also figuring out which AI tools are helpful, which ones are best ignored.\n\nClaude Code (which is just under a year old) iterated and Opus 4.5 launched in November. Microsoft Copilot (which probably gave people the most exposure to these AI tools) also launched Opus 4.5 support.",
                  "score": 1,
                  "created_utc": "2026-01-21 01:13:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qh8br",
              "author": "gibmelson",
              "text": "Before leaving I'd make an attempt, possibly with other devs, to write an email to try to explain your point of view and get their attention. If you are leaving you might as well give that a shot.",
              "score": 2,
              "created_utc": "2026-01-20 20:53:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0osjwr",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-01-20 16:14:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0osk0t",
                  "author": "AutoModerator",
                  "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-01-20 16:15:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0rmzni",
              "author": "meshtron",
              "text": "Yep.  The same feeling OP has about his company falling behind is happening to them as well, just harder to see it.",
              "score": 1,
              "created_utc": "2026-01-21 00:23:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rph4y",
              "author": "Turtlestacker",
              "text": "This - if your IT leadership makes terrible calls that’s a company smell.",
              "score": 1,
              "created_utc": "2026-01-21 00:36:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0oy8m6",
              "author": "Howdareme9",
              "text": "The new stuff being writing english into a chatbot interface?",
              "score": -8,
              "created_utc": "2026-01-20 16:41:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0oygnx",
                  "author": "UnbeliebteMeinung",
                  "text": "If you arent hating you will see that there is currently a huge gap between software developers. Some write 100% ai code some dont and say it doesnt work...\n\nIt does work, if you know how. \n\nPeople who are against it are acutally doomed",
                  "score": 19,
                  "created_utc": "2026-01-20 16:42:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pg22o",
                  "author": "tobsn",
                  "text": "hey there 1982, did the introduction of personal computers hurt your pea counting business?",
                  "score": 0,
                  "created_utc": "2026-01-20 18:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p7rdg",
              "author": "NervousSWE",
              "text": "Cope. The better the models get the less valuable prompt monkeys will be. Eventually companies will be clamoring for a the few competent engineers remaining to keep their LLMs in check.",
              "score": -5,
              "created_utc": "2026-01-20 17:25:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0p874a",
                  "author": "UnbeliebteMeinung",
                  "text": "Yes and thats the skill you need to build up. What else? \n\nI am such a dev. I build up these automated pipelines.",
                  "score": 6,
                  "created_utc": "2026-01-20 17:27:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0q5akp",
              "author": "Educational_Skin2322",
              "text": "\"learn the new stuff\"\n\n\nAre you serious? 😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂\n\n\nThere is nothing new to learn, you can learn to use Cursor in half a day\n\n\nIf you disagree you are simply too dumb",
              "score": -6,
              "created_utc": "2026-01-20 19:58:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0qgfj0",
                  "author": "stylist-trend",
                  "text": "While I agree you can learn cursor in half a day, I absolutely *hate* phrases like \"if you disagree you're too dumb\". AI and AI tools can go down a very big rabbit hole, far beyond cursor. But your quote is so holier-than-thou, and immediately cheapens what you're going for.",
                  "score": 3,
                  "created_utc": "2026-01-20 20:49:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q82i3",
                  "author": "Litteul",
                  "text": "I tend to agree (because I don't wanna be dumb), but there are many other stuff than Cursor that you could learn: MCP, API integrations, self-hosted AI, embedding your documents, etc.\n\nAI will help you to learn other AI stuff.",
                  "score": 1,
                  "created_utc": "2026-01-20 20:11:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0qkupc",
              "author": "KyleDrogo",
              "text": "Yep. The company won’t be able to keep up with the AI enabled pace competitors can maintain. And you’ll miss a lot of useful tools which will cripple your toolkit",
              "score": 0,
              "created_utc": "2026-01-20 21:10:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0opq45",
          "author": "MannToots",
          "text": "There are ways to get data privacy concerns handled with enterprise tier agent solutions. \n\n\nTo me it sounds like they don't want to have AI and this feels like an easy excuse.  The problem is it comes across as more ignorant than valid. ",
          "score": 44,
          "created_utc": "2026-01-20 16:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r981x",
              "author": "Ok-Yogurt2360",
              "text": "Some laws are really strict on the use of private data. Where you are simply not allowed to send said data to a 3th party even if you do it safely. This is the default in the EU and breaking those laws can be costly.",
              "score": 3,
              "created_utc": "2026-01-20 23:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rhxz3",
                  "author": "Nearby-Outcome-3180",
                  "text": "Why use a 3rd party instead of just hosting local models? A lot of pretty good models can be run local. \n\nIt's not Magnum Opus 4.5 tier ability but still a useful assistant.",
                  "score": 3,
                  "created_utc": "2026-01-20 23:55:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ot640",
          "author": "Jolva",
          "text": "This is the worst way to handle AI. Now you have a bunch of employees secretly using it, making the situation even worse. You should write up a proposal on implementing a specific enterprise AI service and point out how that's way safer than having a bunch of employees forced to use free tools and hide it.",
          "score": 31,
          "created_utc": "2026-01-20 16:17:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qbnr2",
              "author": "darien_gap",
              "text": "And a more nuanced policy that makes a distinction between sensitive vs non-sensitive use cases.",
              "score": 3,
              "created_utc": "2026-01-20 20:27:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ot4ye",
          "author": "tracagnotto",
          "text": "If they're so worried get them buy some GPUs and run llm locally. It's an initial cost but it's repaid in the long run with work efficiency",
          "score": 18,
          "created_utc": "2026-01-20 16:17:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q1ogy",
              "author": "HankKwak",
              "text": "CPUs are becoming a legitimate alternative to dGPUs for local AI. The newer **Ryzen AI Max (Strix Halo)** chips are a game-changer because they use a 256-bit memory bus to leverage system RAM as VRAM. This gives you a massive 96GB+ memory pool at a fraction of the cost of a high-end NVIDIA enterprise card, finally making it viable to run 70B+ parameter models locally on a laptop or mini-PC without the 'VRAM tax'",
              "score": 3,
              "created_utc": "2026-01-20 19:41:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0q4q0f",
                  "author": "siegevjorn",
                  "text": "Strix halo is good, but the bandwidth is limiting for work purposes. While commercial AI chats respond lightning fast, local llm on strix halo will take 10s of seconds if not slower to generate answers. Not to mention that for agentic coding token speed matters more. You'll be limited to moe models with small active layers like gpt-oss-120b. Which is decent, but still underpowered compared to commercial counterparts.",
                  "score": 2,
                  "created_utc": "2026-01-20 19:55:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q1zq1",
                  "author": "tracagnotto",
                  "text": "Loved this info, where I can find more?",
                  "score": 0,
                  "created_utc": "2026-01-20 19:42:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0pmzm1",
              "author": "evia89",
              "text": "it wont. You need to spend $20-60k to get any value, build it, place it somewhere, manage it and it will still suck untill you invest more",
              "score": 1,
              "created_utc": "2026-01-20 18:34:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0ppbqo",
                  "author": "eMperror_",
                  "text": "I mean 20-60k is not THAT much for a company.",
                  "score": 8,
                  "created_utc": "2026-01-20 18:45:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0px8pz",
                  "author": "Anxious_Noise_8805",
                  "text": "So they can spend $200k for a person per year (not even a 1 time cost) but they can’t put $20-$60k into some computers?",
                  "score": 3,
                  "created_utc": "2026-01-20 19:20:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0q1q1b",
                  "author": "HankKwak",
                  "text": "CPUs are becoming a legitimate alternative to dGPUs for local AI. The newer **Ryzen AI Max (Strix Halo)** chips are a game-changer because they use a 256-bit memory bus to leverage system RAM as VRAM. This gives you a massive 96GB+ memory pool at a fraction of the cost of a high-end NVIDIA enterprise card, finally making it viable to run 70B+ parameter models locally on a laptop or mini-PC without the 'VRAM tax'",
                  "score": -1,
                  "created_utc": "2026-01-20 19:41:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oyy1a",
          "author": "thirst-trap-enabler",
          "text": "The best thing you can do is advocate for the value of the tools to your company while aligning yourself with the data privacy issues. I work at a hospital and one of the things we have created is an interest group/community that has meetings and speakers and share our hobby projects and invite people from other hospitals to discuss how they tackle the challenges in real life (sales people and consultants lie through their teeth, we're interested in reality). So far we have some self-hosted models available in certain special environments and there is a mechanism for projects to be sanctioned and approved to test things.\n\nKnow this: there is a very big pricing difference between why you can buy personally vs what companies can buy and use of personally licensed items to support large enterprise work can violate TOS (which is why we can only manage funding small test projects)\n\nAnyway, you already know the security team is correct. The way to move forward is thoughtfully not FOMO panic. Urgency is a major red flag for security and compliance.\n\nAnd let's be very honest here: all these AI companies desperately want to know what we are up to so that they can completely replace our entire companies. These tools are ultimately vertical integration machines. We're going to have three or so companies overseeing the software of every company in the world. Think about that and where it puts us in 20 years. That's the slippery slope we are on right now.\n\nAnd as others have said whether to pay people or to become dependent on trojan-priced AI tools waiting for fees to suddenly raise is a business decision.",
          "score": 8,
          "created_utc": "2026-01-20 16:44:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p6900",
              "author": "Embarrassed_Egg2711",
              "text": "This is the best answer, rooted in understanding the business and growing your experience and value with the system instead of just quitting.  The fear mongering is off the charts.",
              "score": 2,
              "created_utc": "2026-01-20 17:18:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0pnvdq",
              "author": "OracleGreyBeard",
              "text": "> trojan-priced AI tools\n\nSuch a good way to put it!",
              "score": 1,
              "created_utc": "2026-01-20 18:38:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0p7k0d",
          "author": "Heavy-Fly-9301",
          "text": "Whats the actual problem here?  \nNo matter what anyone says, frequent reliance on AI does degrade your own skills. All those claims that working with AI somehow trains important skills sound pretty stretched to me.\n\nHonestly, you should be glad. This is still better than companies that blindly shove AI everywhere, even where its not needed. AI can boost your productivity, sure, but nothing more than that.\n\nAnd thats the warning sign, a lot of people already cant work without it. If you are at the point where you literally cant do anything without AI, that is a real problem.\n\nAI is a convenient tool, not a cure-all.",
          "score": 8,
          "created_utc": "2026-01-20 17:24:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0s8hd4",
              "author": "peripateticman2026",
              "text": "Only sane person in this thread.",
              "score": 1,
              "created_utc": "2026-01-21 02:24:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rhkm7",
              "author": "danihend",
              "text": "Doing ANY digital work without the augmentation of AI will soon be seen as the equivalent of writing a letter or doing complex math with pen and paper. Sure, you CAN do it like that if you want, but you're just going to seem a bit weird and old-fashioned like the world has left you behind while you groan about how \"in my day we used to write code our bare hands and click out way through the operating systems to get things done\". \n\nAbsolutely nothing is going to stop this train. Every time we find ways to offload boring/repetitive/slow/annoying tasks we take the opportunity so we can do other things instead. \n\nYes, not practicing skills will cause them to degrade but new skills need to be learned now and right now those skills are using AI to get things done faster and to get more done than you could before. If you can't do that, you're gonna have a bad time.\n\nThe OP should absolutely not be glad to find himself in a company that does not know how to navigate this environment and would do well to keep his options open.",
              "score": 0,
              "created_utc": "2026-01-20 23:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rvsmy",
                  "author": "Heavy-Fly-9301",
                  "text": "Can you explain what skills you are actually talking about?  \nBuilding agents? Prompt engineering? What exactly do you mean?\n\nAn experienced programmer can learn all of that in a couple of days. What really keeps you competitive on the market is deep expertise, not surface-level AI usage.\n\nIf you rely on AI to do all your work, that’s actually what will push you out of the market, because this skill is much easier to acquire than deep knowledge in computer science.\n\nPrompting and basic AI workflows are far easier to learn than algorithms, systems design, performance optimization, or low-level understanding.\n\nMy advice its use Ai only for specific, well-defined tasks - basically as an advanced Google.\n\nOtherwise, you will be competing with any high school student who has a gpt subscription.",
                  "score": 3,
                  "created_utc": "2026-01-21 01:12:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ox9ey",
          "author": "chillebekk",
          "text": "You could switch to Amazon Bedrock, probably. Where I work, Bedrock is the only allowed way to use Anthropic models.",
          "score": 9,
          "created_utc": "2026-01-20 16:36:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pjgev",
              "author": "a_p_i_z_z_a",
              "text": "What does it solve privacy wise? From my understanding Bedrock is just a single API that lets you interact with all sorts of models.",
              "score": 2,
              "created_utc": "2026-01-20 18:18:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pnt8n",
                  "author": "realzequel",
                  "text": "If using Bedrock, the servers are on Amazon cloud, managed by AWS not Anthropic and governed by AWS's agreement with the client (not familiar with them).\n\nIf you're using ChatGPT via Azure, those servers are hosted on Azure/managed by Microsoft and protected by a MS privacy agreement with the client.\n\nHowever, if you use Claude via Azure, you're going through Anthropic-managed servers so don't have the same reassurances.",
                  "score": 6,
                  "created_utc": "2026-01-20 18:38:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0pog76",
                  "author": "chillebekk",
                  "text": "Your data won't be shared with anyone on AWS. That's why it's allowed.",
                  "score": 1,
                  "created_utc": "2026-01-20 18:41:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pjq67",
          "author": "tvmaly",
          "text": "Tell them to use AWS Bedrock. You can get isolated servers to address data privacy and GDPR concerns.",
          "score": 6,
          "created_utc": "2026-01-20 18:20:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0otbi1",
          "author": "ThenExtension9196",
          "text": "Later does not mean probably never. \n\nLater truly does mean later in this situation and likely soon. \n\nEveryone is going to be leaking data into private devices like a sieve.",
          "score": 4,
          "created_utc": "2026-01-20 16:18:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0othoj",
          "author": "Old-Highway6524",
          "text": "People who say that you should leave are stupid as fuck.\n\nWe just need 1 data leak due to feeding sensitive client info into ChatGPT or due to poorly coded AI projects and suddenly companies will start to care if people are handling their info with care. There will be quite a few companies burnt by this.\n\nYou are not missing out on anything apart from productivity - but even that's up for debate and as long as your employer doesn't care, neither should you. Coding with AI is not a special skill at all, you feed it English sentences and it either works or it doesn't, prompt and context engineering is oversold as a complex concept while it's nothing special, it's something you probably learn in a day or you might already know it if you were not a code monkey.\n\nIf I were you I'd be happy. Most companies where AI usage is mandatory, they are expecting to downsize staff 5-20% within just a few years.\n\nAlso for others who are AI believers: there won't be infinite projects and jobs. In fact most enterpreneurs will ask \"why would I pay you $10k if I can build it myself with AI with a $100 subscription\". Learning how to write coherent English sentences does not guarantee you a job in the future.\n\nHave fun while it lasts.",
          "score": 3,
          "created_utc": "2026-01-20 16:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p1lum",
              "author": "curtyshoo",
              "text": "We will see.\n\nThey did solve the translation problem. Yes, it used to be a thing (I know, I used to do it).",
              "score": 1,
              "created_utc": "2026-01-20 16:56:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0owmho",
              "author": "WAHNFRIEDEN",
              "text": "They can rent private servers on Azure for Codex use",
              "score": -1,
              "created_utc": "2026-01-20 16:33:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0p4o6p",
                  "author": "Old-Highway6524",
                  "text": "I highly doubt this is as cheap as a simple ChatGPT subscription. Isn't this billing based on API token price?",
                  "score": 0,
                  "created_utc": "2026-01-20 17:11:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0op0jd",
          "author": "darkname324",
          "text": "need more specifics, u can just write template code with ai and then just paste the data and stuff manually",
          "score": 3,
          "created_utc": "2026-01-20 15:58:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0otahc",
              "author": "eli_pizza",
              "text": "Bad advice to intentionally ignore corporate security policy.",
              "score": 6,
              "created_utc": "2026-01-20 16:18:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0oy1ap",
                  "author": "mimic751",
                  "text": "Some companies allow you to do whatever you want with net new code but once it reaches production you can no longer ingest it with an AI tool",
                  "score": 0,
                  "created_utc": "2026-01-20 16:40:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0ov956",
                  "author": "Adventurous_Ad_9658",
                  "text": "Depends on the policy and how it's written. If the policy is general enough and you are using code that's generated by AI its no different than googling it back in the day, copying code someone already wrote and then altering it to your liking.\n\nThat's like saying I cant use my phone to ask chatgpt how I should approach a general problem at work that has no proprietary information in it. They cannot ban you from doing that.",
                  "score": -1,
                  "created_utc": "2026-01-20 16:27:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pwzfg",
          "author": "Just_Lingonberry_352",
          "text": "what company is this what is their stock symbol so i can short it",
          "score": 2,
          "created_utc": "2026-01-20 19:19:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p3nl8",
          "author": "cancodeandstuff",
          "text": "Learn to code.",
          "score": 1,
          "created_utc": "2026-01-20 17:06:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pk3uj",
              "author": "MaxProPlus1",
              "text": "OP is already a professional coder, it was on his hiring résumé",
              "score": 0,
              "created_utc": "2026-01-20 18:21:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ovfh3",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 16:28:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ovflw",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 16:28:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pez0o",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-20 17:58:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0p3b8h",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 17:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p3bau",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 17:04:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pjv6q",
          "author": "m3kw",
          "text": "Is tough because if you don’t know what you are doing, prompt injection is a real problem for your kind of firm",
          "score": 1,
          "created_utc": "2026-01-20 18:20:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pp04o",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 18:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pp08o",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 0,
              "created_utc": "2026-01-20 18:43:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0priu6",
          "author": "jasonhon2013",
          "text": "is time to quite this company tbh",
          "score": 1,
          "created_utc": "2026-01-20 18:54:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pxiwq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 19:22:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pxiyp",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 19:22:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pyo92",
          "author": "Only_Constant_8305",
          "text": "search for a new job. I don't think this company will last long",
          "score": 1,
          "created_utc": "2026-01-20 19:27:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q2dkw",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 19:44:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q2dn5",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 19:44:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0q4sfo",
          "author": "Educational_Skin2322",
          "text": "Who the fuck cares?\n\n\nLike other commented, the only thing you are losing is productivity, but if the company doesn't care you should not care as well\n\n\nPrompting, context and planning with LLMs is something that you can understand in half a day, it's not complex and people saying that you are \"missing\" something are delusional, you don't lose anything other than productivity \n\n\nAnd yes, I use LLMs daily in my work, multiple LLMs and no it doesn't matter that much ",
          "score": 1,
          "created_utc": "2026-01-20 19:55:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q5cam",
          "author": "Zoodoz2750",
          "text": "You need another company before your skill set becomes obsolete.",
          "score": 1,
          "created_utc": "2026-01-20 19:58:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q79ee",
          "author": "peterxsyd",
          "text": "Get out of there.",
          "score": 1,
          "created_utc": "2026-01-20 20:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qc9uz",
          "author": "One-Construction6303",
          "text": "Does your company also ban eating because people might choke to death on food?",
          "score": 1,
          "created_utc": "2026-01-20 20:30:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qe1dp",
          "author": "maese_kolikuet",
          "text": "Yeah, leave.\nThere are corporate solutions like github copilot and factory.ai droid. They are just cheap and small minded.",
          "score": 1,
          "created_utc": "2026-01-20 20:38:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qgodq",
          "author": "gibmelson",
          "text": "We work with sensitive client info as well, where there are very strict guidelines on how to handle it - no way that anyone is passing that into ChatGPT. At the same time we can use copilot in vscode because the code itself isn't sensitive in the same way.\n\nSo first off I don't think you should try to get around the policy. Rather I'd try to bring it up, maybe together with other devs - write an email together explaining your point of view in a respectful way. And if they don't listen, I'd consider trying to find another job.",
          "score": 1,
          "created_utc": "2026-01-20 20:50:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qmkdl",
          "author": "Osata_33",
          "text": "I had the same thing. By the time it happened I already had several customGPTs I was using and saving a lot of time. I put forward a case and got special permission to keep using it.\n\nIf data privacy is the concern, focus your case on compliance. I work in the UK so we have GDPR. I made sure when I put in a request I talked a lot about my understanding of data privacy and the steps I take in all my work, especially when using AI, to remain compliant.\n\nFortunately, it worked. Good luck, hope it works out for you.",
          "score": 1,
          "created_utc": "2026-01-20 21:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qtuox",
          "author": "stas1986",
          "text": "This actually sounds awesome. Your company encapsulates you from the panic that is going on among the developers fearing about losing their jobs to ai, you will get deadlines according to your skills and not your vibe code abilities so as long as you can have that going I think you will do better than 90% of us.",
          "score": 1,
          "created_utc": "2026-01-20 21:51:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qus7j",
          "author": "BarberExtra007",
          "text": "I worked for two different companies. In the first, the IT department had limited knowledge and relied on paid software to block almost everything. One day they blocked all AI websites and APIs. When I spoke to them, it became clear that they did not know what they were doing and had no vision. They were stuck in routine. For them, a good job meant that everyone was logged in. After that, it was not their problem whether the company was progressing or keeping up to speed.\n\nIn the second company, the IT management were people with vision. They realised that the company needed to develop itself to keep up with the competition in the research industry. They introduced AI by signing up for Gemini and ChatGPT. At the same time, data was controlled. Anything you did could not be deleted, and the IT department had access to the accounts, similar to a Microsoft Enterprise environment with Copilot.",
          "score": 1,
          "created_utc": "2026-01-20 21:55:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qywhi",
          "author": "Fresh_Sock8660",
          "text": "They could do something local but I'm guessing the reason here is more laziness than anything. ",
          "score": 1,
          "created_utc": "2026-01-20 22:15:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r4zlm",
          "author": "SparePartsHere",
          "text": "I would leave, keeping in touch with the SotA tools and workflows have never been as important as it is today. This few years will decide who gets paid twice more and who gets left behind. But please understand that this subreddit is heavily invested into the LLMs, it makes sense we would leave if someone tries to take that away. Not everyone is this way.",
          "score": 1,
          "created_utc": "2026-01-20 22:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r54x2",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 22:47:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r54zc",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 22:47:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r5a0g",
          "author": "Unique-Temperature17",
          "text": "Yeah, my friend's engineers dealt with the same thing - strict no-cloud-AI policy but still needed to stay competitive. Local AI is the workaround that actually satisfies most security teams since nothing leaves your machine. Tools like Ollama, LM Studio or Suverenum let you run models entirely on-device. You can even use Claude Code with local models now. Might be worth pitching to your security team.",
          "score": 1,
          "created_utc": "2026-01-20 22:47:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r6psy",
          "author": "danihend",
          "text": "If you're a developer and that's what your company is deciding then your company is probably doomed so better get out now I guess.",
          "score": 1,
          "created_utc": "2026-01-20 22:55:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r6s0h",
          "author": "_FIRECRACKER_JINX",
          "text": "is there a way for you to de-identify the data before putting it into the Ai tools??",
          "score": 1,
          "created_utc": "2026-01-20 22:55:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r8r0s",
          "author": "particlecore",
          "text": "Local LLM",
          "score": 1,
          "created_utc": "2026-01-20 23:06:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rchpb",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 23:26:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rchuk",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 23:26:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0rcyp3",
          "author": "MadCat0911",
          "text": "I dunno, like, I enjoy running shit through AI sometimes, but when it's wrong, it's infuriatingly wrong.  Plus, METR did a study show it's going slower, not faster, when you use AI.  [https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)\n\nAnd I get it, it gives me a quick baseline, and I can edit it from there on some things easily enough, but sometimes, I'm telling it something's wrong and I get \"You're exactly right, Great on you for noticing, here's the fix\" and it just hallucinates or spits out the exact same code, lol.",
          "score": 1,
          "created_utc": "2026-01-20 23:28:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rhb39",
          "author": "Quind1",
          "text": "My company is the opposite. They said they will lay off anyone who doesn't adopt the company's AI tools (we have Cursor, Github Copilot, AWS Bedrock, Microsoft Copilot,  Glean, and some in-house tools), and they will hire people who use AI daily. Wild times we live in. That said, they have already handled the security side of things (it's a large company) and have the resources to do so. It cost them a pretty penny, however.",
          "score": 1,
          "created_utc": "2026-01-20 23:52:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rjfi4",
          "author": "RythmicBleating",
          "text": "If running a local model isn't feasible, have them check out https://confer.to. It's the dude behind Signal and this project has the same ethics.",
          "score": 1,
          "created_utc": "2026-01-21 00:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rmey6",
          "author": "Economy-Manager5556",
          "text": "And who cares ? \nShare a doc and throw stuff back and forth in it\nThe end",
          "score": 1,
          "created_utc": "2026-01-21 00:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rnngo",
          "author": "scottrfrancis",
          "text": "Find another job.  This employer is probably not too competitive for too much longer anyway",
          "score": 1,
          "created_utc": "2026-01-21 00:26:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rsvca",
          "author": "Varridon",
          "text": "i’m sure there’s part of the flow you can use AI for and there’s always local AI",
          "score": 1,
          "created_utc": "2026-01-21 00:55:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rtxja",
          "author": "Shot_Court6370",
          "text": "This whole sub is going to tell you to leave whether that's the best decision for your personal situation or not. You wont get unbiased advice here regarding working with LLMs, for obvious reasons.",
          "score": 1,
          "created_utc": "2026-01-21 01:01:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rvqst",
          "author": "Joe_Early_MD",
          "text": "God this is so annoying and my place is the same.  Our new cio is from a big behemoth company that is known mainly by three letters and known to move soooo slowwwwwwww.  His concern is data leakage and I get it but like you, seeing other places either A. Purchase the secure service from a provider or B. Setup an in house model while I’m over here hand jamming stuff like a tard.  It’s got me looking.",
          "score": 1,
          "created_utc": "2026-01-21 01:12:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ryskw",
          "author": "bendgame",
          "text": "Really really easy to just use AI coding tools at home if you want to learn them. If you want to use them for work just talk to your coworkers doing on personal devices and do the same... Worrying about policies is for people who don't get promoted in my experience.",
          "score": 1,
          "created_utc": "2026-01-21 01:29:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s2fco",
          "author": "Annual_Judge_7272",
          "text": "It’s common . Be patient soon everyone will have their own agent soon. We built this for that reason. Nobody at work has ai yet but a few on the side \n\nhttps://knowledge.dotadda.io",
          "score": 1,
          "created_utc": "2026-01-21 01:50:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s46fc",
          "author": "kyngston",
          "text": "my company contracts with cloud model providers for an enterprise contract that ensures no data is used for model training or even retained after the session is finished. \n\nso we all just use our company gateway for access to models and we can use it for whatever we want. \n\nits functionally equivalent to buying cloud compute off AWS.  if amazon didn’t offer rock solid guarantees for ip security, no one would buy cloud compute.",
          "score": 1,
          "created_utc": "2026-01-21 02:00:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s5r8x",
          "author": "Mundane_Annual4293",
          "text": "If you don't agree I would reach out to the security team and ask for clarification, with an open mind. \n\nIn my opinion is not just data privacy, there are other risks and draw backs. With IA you are more prone to introduce bugs and code debt. As humans we are less prone to double check what the IA spits as it becomes more abundant. And that's without touching other exploits such as prompt injection.\n\nIA is not magic, even though might feel like one, is a tool and as such it should be used when needed and not for everything. Over time it introduces small bugs that if not managed constantly by a human, might create bigger issues.",
          "score": 1,
          "created_utc": "2026-01-21 02:09:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s74ek",
          "author": "number66-1",
          "text": "Could it be because of this? New laws? Maybe you shouldn't just look for a new job until you are sure it's the company and not new laws being passed. https://www.reddit.com/r/cybersecurity/s/gqOvJKvZPH",
          "score": 1,
          "created_utc": "2026-01-21 02:17:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s94fe",
          "author": "nxqv",
          "text": "stackoverflow.com baby",
          "score": 1,
          "created_utc": "2026-01-21 02:28:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p1n7r",
          "author": "gxsr4life",
          "text": "Why not run models locally? Obviously, performance will not be as good as flagship models but something is better than nothing.",
          "score": 1,
          "created_utc": "2026-01-20 16:56:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p70dy",
          "author": "putoption21",
          "text": "Local LLMs. Or deploy their own instance on their own infra. If answer to that is a “no” as well then perhaps time to start a competitor and take all the clients. 😂",
          "score": 1,
          "created_utc": "2026-01-20 17:22:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oqff9",
          "author": "vir_db",
          "text": "Take a look at nuvolaris, a private AI supplier",
          "score": 1,
          "created_utc": "2026-01-20 16:05:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pfbnt",
              "author": "ContextualData",
              "text": "Why? ChatGPT does not use your data on corporate plans.",
              "score": 0,
              "created_utc": "2026-01-20 18:00:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pir10",
                  "author": "a_p_i_z_z_a",
                  "text": "So they say",
                  "score": -1,
                  "created_utc": "2026-01-20 18:15:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oui1j",
          "author": "space_wiener",
          "text": "My work did that. But they have some special copilot thing that doesn’t upload or share data. It sucks but it’s better than nothing.",
          "score": 1,
          "created_utc": "2026-01-20 16:23:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p7f8k",
          "author": "Clear-Pear2267",
          "text": "If you like the company and the job (good culture, good boss, good team, good benefits) I would not jump ship too quickly. In the long run, those things are far more impactuful on your peace of mind, stress levels, and general satisfaction than some corporate rules about tech stack you have to comply with. If you are worried about falling behind, you can always pursue learning on your own time.",
          "score": 1,
          "created_utc": "2026-01-20 17:23:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pmqn6",
          "author": "Jomuz86",
          "text": "Data privacy shouldn’t be an issue if they are paying for one of the enterprise solutions. If they don’t have the money to invest in it then that’s a red flag in itself. I work in the data side of pharma and we are allowed to use AI as long as we are responsible and don’t mess around with patient data and data privacy and anonymisation is huge. They have their own custom gpt 5.2 that has company guardrail as a tool in teams 🤷‍♂️ \nSo yeah look for somewhere else and leave when you can.",
          "score": 1,
          "created_utc": "2026-01-20 18:33:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qlahn",
          "author": "Due-Project-7507",
          "text": "My company has a special Microsoft Copilot license for sensitive data so they don't leave the country. Our department has bought a server with RTX 6000 Pro Blackwell GPUs. We run there [GLM-4.7](https://huggingface.co/QuantTrio/GLM-4.7-GPTQ-Int4-Int8Mix) on 4 GPUs and use it with OpenCode.",
          "score": 1,
          "created_utc": "2026-01-20 21:12:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0orab2",
          "author": "heeero__",
          "text": "Lol copilot is being shoved down our throats with every Microsoft product. How can they block everything?",
          "score": 0,
          "created_utc": "2026-01-20 16:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ouoc9",
          "author": "theitfox",
          "text": "My company runs our own Claude model in our cloud infra. No sensitive data is coming out of our network *(it's a lie, but we do try)*",
          "score": 0,
          "created_utc": "2026-01-20 16:24:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pgusv",
              "author": "ckerim",
              "text": "Claude doesn’t run in your environment. It’s still processing data in the US",
              "score": 2,
              "created_utc": "2026-01-20 18:07:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rssc1",
                  "author": "theitfox",
                  "text": "It does if you're rich enough. We do a private deal. You can't nonchalantly get Claude models and run on your local.",
                  "score": 0,
                  "created_utc": "2026-01-21 00:55:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oxwv0",
          "author": "mimic751",
          "text": "Propose a solution. You can Implement bedrock and keep your own data local. You can also Institute Training and potential audit levels for what people are using AI for. I got my company if you get caught putting production or sensitive and no one of the public AIS to get into a lot of trouble however they don't restrict usage they're just trying to protect their own intellectual property",
          "score": 0,
          "created_utc": "2026-01-20 16:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oqw9d",
          "author": "positivitittie",
          "text": "The falling behind issue is a real concern.",
          "score": 0,
          "created_utc": "2026-01-20 16:07:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0osza8",
          "author": "dumblebees",
          "text": "Find a new job because this company will fall behind. \n\nUntil then, do what it takes to not get fired.",
          "score": -3,
          "created_utc": "2026-01-20 16:16:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p251k",
          "author": "Sticking_to_Decaf",
          "text": "You might mention to whoever influences these decisions that there are options for LLM usage that have “no training” and “zero data retention” policies.  You can even restrict accounts on OpenRouter to only use providers compliant with this policy.  \n\nIf they are still adamant, start looking for another job.",
          "score": 0,
          "created_utc": "2026-01-20 16:59:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p2xoh",
          "author": "vamos_davai",
          "text": "Ask for $100k for hardware to run a self hosted LLM",
          "score": 0,
          "created_utc": "2026-01-20 17:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p5uup",
              "author": "toolznbytes",
              "text": "That's the price tag we are talking about? Isn't there an extra 0?",
              "score": 1,
              "created_utc": "2026-01-20 17:16:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0p5z7e",
          "author": "meckstss",
          "text": "What I would do is run liteLLM in a docker locally, and host llama or some other light LLM locally as well.   No data leaves your laptop but if your company policy changes you just use liteLLM to point to the new location.  It's a fair compromise while you wait for your employer to navigate it's fears.    You can use many VS code extensions like RooCode and just point them to your LiteLLM instance.\n\nOf course your laptop is not going to have the CPU and Ram performance of OpenAI or Anthropic, but it is a good way to stay compliant, and learn AI tooling.",
          "score": 0,
          "created_utc": "2026-01-20 17:17:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p9lel",
          "author": "Mice_With_Rice",
          "text": "They must know they can use local models so none of their data touches the web...",
          "score": 0,
          "created_utc": "2026-01-20 17:34:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p9se0",
          "author": "Apprehensive_Sun3015",
          "text": "ChatGPT for full stack coding is a lunatic that will not hesitate to gaslight you until your app is broken and it tells you to breathe and take a break. Whoever gave it its personality is a total passive aggressive, narcisstic and cowardly sort. Best thing to do is run complicated full stack specs into checklists and vet it with Copilot and Claude then back to ChatGPT. The crazy behavior I have seen ChatGPT devolve into is beyond insane.",
          "score": 0,
          "created_utc": "2026-01-20 17:34:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pernw",
          "author": "throwra87d",
          "text": "Time to leave, buddy. Sorry.",
          "score": 0,
          "created_utc": "2026-01-20 17:57:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pfuj5",
          "author": "tobsn",
          "text": "that’s a skill issue on the the engineering lead. I would have a word with the ceo.\n\nif you can’t separate credentials and user data from raw code, you’re doing something wrong in how you manage.",
          "score": 0,
          "created_utc": "2026-01-20 18:02:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pgcn8",
          "author": "Tushar_BitYantriki",
          "text": "Ask them what's stopping them from setting up a custom Azure AI or even a local model running on premises?\n\nIf they are big enough to be worried about AI companies stealing their IP, then they can surely afford to spend money on the alternative.\n\nThey can even have enterprise licensing with OpenAI/Anthropic, and (not really sure) they might be able to control what people install within those tools.",
          "score": 0,
          "created_utc": "2026-01-20 18:04:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pgxio",
          "author": "Marutks",
          "text": "You are lucky that you are not forced to use AI tools.  If you cant do your job without cheating then I dont know what to say.",
          "score": 0,
          "created_utc": "2026-01-20 18:07:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pjqpc",
          "author": "ramiz_ahmed",
          "text": "they can roll their own llm in private vps",
          "score": 0,
          "created_utc": "2026-01-20 18:20:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0plm0t",
          "author": "austinrathe",
          "text": "Yea. This company is toast. Get out.",
          "score": 0,
          "created_utc": "2026-01-20 18:28:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ppdvm",
          "author": "OracleGreyBeard",
          "text": "> But watching competitors move faster while we do everything manually is frustrating\n\nA bit confused by this. I saw you can't use AI but you can't *automate*?\n\nI wrote an app to read and process ship sensors, a HUGE and ongoing benefit, and I did it by hand. Is AI necessary for everything?",
          "score": 0,
          "created_utc": "2026-01-20 18:45:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0opff9",
          "author": "dino-delicious",
          "text": "\"Maybe they will revisit later\" is definitely code for they will not revisit later. Use it when needed on personal devices only and don't make it look too obvious.",
          "score": -2,
          "created_utc": "2026-01-20 16:00:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oprtz",
              "author": "Medium_Chemist_4032",
              "text": "Don't recommend that. Use your company accepted software approval process to suggest using local only models. Have an infosec and appsec team sign-off and a sponsor. If you have a case, you'll find one waiting years for a promotion",
              "score": 5,
              "created_utc": "2026-01-20 16:02:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0otlad",
              "author": "ThenExtension9196",
              "text": "No because the security posturing is coming from a good place (protect data) but will become abundantly clear in a week or two is everyone is circumventing and leaking even more data. They will revisit and buy enterprise licenses likely through an existing contract like Microsoft office copilot.",
              "score": 1,
              "created_utc": "2026-01-20 16:19:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0osep6",
          "author": "IntroductionSouth513",
          "text": "you need to leave this company.\neither that or you do that kind of thing called job hugging or quiet quiting while u learn abt Ai in your own time and create that alternate path for yourself. but option A still applies.",
          "score": -2,
          "created_utc": "2026-01-20 16:14:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ovawi",
          "author": "Shot-Document-2904",
          "text": "Leave the company. Your competitors using AI tools will do it faster and better.",
          "score": -3,
          "created_utc": "2026-01-20 16:27:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ph8z6",
          "author": "256BitChris",
          "text": "Tell us what industry and problem domain they operate in so that we can one shot a competitor with Claude - they'll eventually realize they have to use AI or go extinct.\n\nThat said, if they really are worried about data privacy, then they should use the enterprise grade apis or licenses from all the big providers, Amazon Bedrock, or whatever Azure and GCP offer.  These services provide guarantees to specifically address these concerns.\n\nOther than that, as others say you should probably try to leave as soon as possible.  You will want to secure a place at a company that is AI friendly so you have a chair when the music stops.",
          "score": -1,
          "created_utc": "2026-01-20 18:08:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pjy9v",
          "author": "Trakeen",
          "text": "Send them the link to copilot or azure openai. Data privacy concerns haven’t been a thing in years",
          "score": -1,
          "created_utc": "2026-01-20 18:21:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r0ixn",
          "author": "SnooSongs5410",
          "text": "lol.  your company is about to be left behind.  best to be looking for work elsewhere.",
          "score": -1,
          "created_utc": "2026-01-20 22:23:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0q8bb9",
          "author": "fab_space",
          "text": "I built the solution for your company’s issue and is free, extendable, ready for 100 people… maybe more if properly tuned:\n\nFeatures\n\n- Hybrid Redaction Engine: Combines the speed of static keyword matching (FlashText) with the intelligence of NLP models (Presidio/SpaCy) to detect PII, secrets, and custom terms.\n- SSL/TLS Interception: Full support for HTTPS traffic inspection via mitmproxy core.\n- High Performance: Asynchronous ML processing with configurable models (en_core_web_sm for speed) ensures minimal latency impact.\n- Enterprise Observability: Native Prometheus metrics (/metrics) and structured JSON logging for integration with Grafana/Loki.\n- Fail Closed Security: Requests are strictly blocked (500 Error) if the DLP engine encounters any failure, ensuring no data leakage.\n- Scalable: Dockerized (Multi-stage build, Python 3.12) and load-tested\n\nAsciicinema demo: https://asciinema.org/a/VKFol51SRDzleQKY7c2ZmgUKz\n\nSource code and docker stack:\nhttps://github.com/fabriziosalmi/aidlp",
          "score": -2,
          "created_utc": "2026-01-20 20:12:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p3xia",
          "author": "vxxn",
          "text": "I’d start interviewing elsewhere immediately. This company is going to get left in the dust by competitors with this attitude.",
          "score": -2,
          "created_utc": "2026-01-20 17:07:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcr3zw",
      "title": "Ralph Loop inspired me to build this - AI decides what Claude Code does next orchestrating claude code until task is done",
      "subreddit": "ChatGPTCoding",
      "url": "https://i.redd.it/idx5kfij8cdg1.png",
      "author": "RegionCareful7282",
      "created_utc": "2026-01-14 16:02:37",
      "score": 38,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Project",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qcr3zw/ralph_loop_inspired_me_to_build_this_ai_decides/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzn1hwb",
          "author": "BaCaDaEa",
          "text": "This looks really cool, man. We've got a collaboration coming up for the community (be on the look out for that guys!) but once that's over, I'd be happy to pin you for a while!",
          "score": 1,
          "created_utc": "2026-01-15 00:10:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmpuax",
          "author": "ihateredditors111111",
          "text": "lol not trying to be a hater that’s cool and all but it’s just funny thinking what clusterfucks it might end up building",
          "score": 3,
          "created_utc": "2026-01-14 23:08:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzqh4rj",
              "author": "DrummerHead",
              "text": "It all hinges in the verification step. If that doesn't work, then it's a loop of poop.",
              "score": 3,
              "created_utc": "2026-01-15 14:42:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzmxqfq",
              "author": "RickyDontLoseThat",
              "text": "I think this is how we end up with SkyNet.",
              "score": 1,
              "created_utc": "2026-01-14 23:50:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nznkzi7",
                  "author": "JohnnyLovesData",
                  "text": "![gif](giphy|xT5LMzIK1AdZJ4cYW4)",
                  "score": 1,
                  "created_utc": "2026-01-15 02:00:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzsd121",
          "author": "WolfeheartGames",
          "text": "Reinventing behavior trees one tiny step at a time. I am working on a full RAG with an integrated behavior tree for the actual agent harness to handle this intelligently.\n\nhttps://github.com/NoSaaS-me/Vlt-Bridge/tree/020-bt-oracle-agent",
          "score": 2,
          "created_utc": "2026-01-15 19:51:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxlcae",
          "author": "sridoodla",
          "text": "Can this use the claude subscription for claude code?",
          "score": 2,
          "created_utc": "2026-01-16 15:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o02god3",
          "author": "Gustafssonz",
          "text": "How much those these running tasks cost in the end?",
          "score": 1,
          "created_utc": "2026-01-17 07:13:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0dwv1q",
              "author": "Adept_Possibility_66",
              "text": "yes",
              "score": 2,
              "created_utc": "2026-01-19 00:10:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvikb6",
          "author": "quantier",
          "text": "Could this work with Kilo Code or the other local AI extensions",
          "score": 1,
          "created_utc": "2026-01-16 06:14:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi9j50",
      "title": "Learning to vibe code",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qi9j50/learning_to_vibe_code/",
      "author": "PrettyGrand2",
      "created_utc": "2026-01-20 18:41:49",
      "score": 14,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "Hello,\n\n  \nIam a 64 year old retired plumber and I just learned about vibe coding. I wanted to ask if anyone here can point me to the direction of some recent uptodate courses where I can learn how to vibe code (I keep hearing that word alot) and use codex while doing it.\n\nI have zero coding knowledge.\n\nI appreciate any info you can give me about online courses I can watch and learn from.\n\nThank you\n\nDavid",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qi9j50/learning_to_vibe_code/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o0pp137",
          "author": "WAHNFRIEDEN",
          "text": "What’s your goal? Entrepreneurship or hobby or what",
          "score": 5,
          "created_utc": "2026-01-20 18:43:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0prccb",
          "author": "es12402",
          "text": "Vibecoding is a term used to describe programming without writing code, using only human interaction with an AI. Generally, you don't need a course to get started.\n\nIf you're not very computer savvy, I'd recommend starting with a more user-friendly service like Cursor or Windsurf. You can also use Codex or Claude – all the instructions for installing the editor are usually on the website. You install the app (code editor), and it will open a sidebar with the AI chat. In this chat, you can write exactly what you want (but try to be detailed), for example: \"Hi! I don't know how to code at all, but I want to make a website/app that does <what you want to do>. Please advise me where to start and help me do it.\"\n\nThe AI ​​will respond, you'll respond or ask something in return, and gradually you'll start getting better with it.",
          "score": 3,
          "created_utc": "2026-01-20 18:54:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pz8t6",
          "author": "zenmatrix83",
          "text": "make something, it will break, fix it, try again. do that and look for courses on software patterns, something like\n\n  \n[https://refactoring.guru/design-patterns/creational-patterns](https://refactoring.guru/design-patterns/creational-patterns)\n\nits tought to make anything without understanding how software works, or exactly what you want. I've been  part time programming for years and work with software at work so that helps me a lot.",
          "score": 3,
          "created_utc": "2026-01-20 19:30:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r3ezb",
          "author": "kennetheops",
          "text": "This is badass. I will gladly hop on a call to show you what I do.",
          "score": 3,
          "created_utc": "2026-01-20 22:38:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pxgnm",
          "author": "Rangizingo",
          "text": "The coolest thing about AI coding tools IMO is that it’s the only tool you can ask the tool itself “How do I use you?”. I suggest Claude Code. You have to pay but it’s worth it. And you can just as Claude in Claude Code all manner of questions about how to do stuff. It’s awesome. Same concept applies to codex.",
          "score": 2,
          "created_utc": "2026-01-20 19:21:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pxlkh",
          "author": "Tiny-Telephone4180",
          "text": "There is nothing for a course. Try some YouTube videos. It would help you. If you know to use reddit. Then there is nothing complicated in it.",
          "score": 2,
          "created_utc": "2026-01-20 19:22:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pror4",
          "author": "TheMightyTywin",
          "text": "Best way to learn is to build a personal project for yourself.\n\nA website, mobile app, desktop game, etc\n\nBuild it for yourself with no expectation of ever going live as your first attempt will undoubtedly suck. But it will be a great learning experience!",
          "score": 1,
          "created_utc": "2026-01-20 18:55:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0r6eky",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 22:53:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0r6eo6",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 22:53:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0q6447",
          "author": "vir_db",
          "text": "https://share.google/jSpfVCw1fL8eRrwFm",
          "score": 0,
          "created_utc": "2026-01-20 20:01:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh2udm",
      "title": "whats the codex limits like for the pro plan of chat gpt?",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qh2udm/whats_the_codex_limits_like_for_the_pro_plan_of/",
      "author": "alosopa123456",
      "created_utc": "2026-01-19 12:27:29",
      "score": 13,
      "num_comments": 19,
      "upvote_ratio": 0.94,
      "text": "I'm considering moving off of cursor, I barely use it for anything except doing mini bug fixes/feature requests.\n\nI would like to use AI in other editors, I'm a c# programmer mainly so cursor isnt doing much for me rn. I never hit cursors limits, so hows Codexes limits lookin?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qh2udm/whats_the_codex_limits_like_for_the_pro_plan_of/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o0h1z3d",
          "author": "Previous-Display-593",
          "text": "I dont have any hard numbers but it feel pretty generous to me. I only hit limits when I was doing 8 hours a day coding over the holiday.",
          "score": 4,
          "created_utc": "2026-01-19 13:36:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0latjs",
              "author": "Hellerox",
              "text": "What model are you using?",
              "score": 2,
              "created_utc": "2026-01-20 02:04:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0lbu8k",
                  "author": "Previous-Display-593",
                  "text": "5.2 extra high for everything lol.",
                  "score": 3,
                  "created_utc": "2026-01-20 02:09:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0lwjzs",
              "author": "ECrispy",
              "text": "the $200 tier basically says 'unlimited' so not surprised, but what about the plus plan? how many hrs/day would you say?",
              "score": 2,
              "created_utc": "2026-01-20 04:05:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mrmvn",
                  "author": "touhoufan1999",
                  "text": "It says unlimited (with fair use) for the website, not the Codex CLI. As long as you're not hammering the website I doubt they'd lock you out.",
                  "score": 1,
                  "created_utc": "2026-01-20 08:00:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0nt6sg",
                  "author": "Previous-Display-593",
                  "text": "I am on the cheap plan. I thought that was called pro.",
                  "score": 1,
                  "created_utc": "2026-01-20 13:13:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ipqsv",
          "author": "McNemarra",
          "text": "Generous for $20 but I can easily hit weekly limit",
          "score": 4,
          "created_utc": "2026-01-19 18:21:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gs96d",
          "author": "1427538609",
          "text": "I'm surprised you don't consider Co-pilot. I don't do a lot of C#, but in the few times I did it, the Visual Studio built in co-pilot worked well for me (w/ Github Copilot subscription).",
          "score": 2,
          "created_utc": "2026-01-19 12:33:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0kq723",
              "author": "real_serviceloom",
              "text": "they limit context sizes massively and do other shenanigans",
              "score": 5,
              "created_utc": "2026-01-20 00:12:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0h0epj",
              "author": "alosopa123456",
              "text": "The main reason was i just wanted GPT pro subscription, i enjoy just asking it questions and burn through the free 5.2 limit.",
              "score": 2,
              "created_utc": "2026-01-19 13:27:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0gv2ur",
          "author": "jonydevidson",
          "text": "It basically feels unlimited to me. Every evening, if there are some unresolved bugs that I haven't tackled, I'll leave it running to write logging and then iterate on the code, run tests and do so in the loop until the bugs are fixed, and that'll sometimes take an hour, sometimes 5. \n\nThe lowest I've ever gotten was 25% of weekly quota left.\n\nI use the extension in VSCode, I use the CLI around the computer for a bunch of stuff that's not coding related. It basically changed how I interact with the computer.",
          "score": 1,
          "created_utc": "2026-01-19 12:53:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h09vf",
              "author": "alosopa123456",
              "text": "awesome thank you!",
              "score": 1,
              "created_utc": "2026-01-19 13:26:47",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o0hukge",
              "author": "justaRndy",
              "text": "Refactoring 50k lines of code in 15 files or so, couple hours work. Plus plan only, extra high setting. Actually reset today, barely went below 50%  last week. Also can stay in the same chat window forever, context auto cleans every couple tasks. Managed to get a bunch of new features added to my app like stackable effect filters, precision calculation down to 1e30 digits precision, an UI slider for number of cpu cores in use for calculations... I'm just wondering what kind of gigatasks people are running that they are complaining about rate limits even on the 200$ plan.",
              "score": 1,
              "created_utc": "2026-01-19 16:01:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0im8lu",
                  "author": "jonydevidson",
                  "text": "They have 3-4 people using it at the same time, that would be my guess.",
                  "score": 1,
                  "created_utc": "2026-01-19 18:05:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0isiy7",
                  "author": "KnifeFed",
                  "text": "> can stay in the same chat window forever, context auto cleans every couple tasks\n\nIt auto *compacts*, meaning you'll still have remnants of completely unrelated things in your context if you never create a new session.",
                  "score": 1,
                  "created_utc": "2026-01-19 18:33:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0oid3n",
                  "author": "[deleted]",
                  "text": "[removed]",
                  "score": 1,
                  "created_utc": "2026-01-20 15:27:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0jskht",
          "author": "Ok-Version-8996",
          "text": "I have been having issues with gpt giving code, then finding reason to switch it to some other code, then say it’s wrong again.\n\nSo I finally fact checked it with Claude free version, that was awesome.  I basically have to AI’s working together and it solved all my problems.\n\nClaude is super limiting tho, so I went and bought they dang sub so I pay both lowest tier subs, but I have a pretty badass dynamic duo of AI superpower for $30/ month",
          "score": 1,
          "created_utc": "2026-01-19 21:19:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mrvxa",
          "author": "touhoufan1999",
          "text": "For my first week of Pro, I easily ran out of the weekly usage limits but it was mostly because I was hammering everything with xhigh and having it refactor garbage from Opus. It's the second or third week now I think and I only change from gpt-5.2-xhigh if I need something done quickly (e.g. summarizing changes, documentation etc). Not coming near a limit. Using it for 2-3 hours a day for most days however. Sometimes with 2 CLIs but usually one.",
          "score": 1,
          "created_utc": "2026-01-20 08:03:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcyx2d",
      "title": "Agent reliability testing is harder than we thought it would be",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qcyx2d/agent_reliability_testing_is_harder_than_we/",
      "author": "dinkinflika0",
      "created_utc": "2026-01-14 20:46:46",
      "score": 10,
      "num_comments": 14,
      "upvote_ratio": 0.78,
      "text": "I work at [Maxim](https://getmax.im/Max1m) building testing tools for AI agents. One thing that surprised us early on - hallucinations are way more insidious than simple bugs.\n\nRegular software bugs are binary. Either the code works or it doesn't. But agents hallucinate with full confidence. They'll invent statistics, cite non-existent sources, contradict themselves across turns, and sound completely authoritative doing it.\n\nWe built multi-level detection because hallucinations show up differently depending on where you look. Sometimes it's a single span (like a bad retrieval step). Sometimes it's across an entire conversation where context drifts and the agent starts making stuff up.\n\nThe evaluation approach we landed on combines a few things - faithfulness checks (is the response grounded in retrieved docs?), consistency validation (does it contradict itself?), and context precision (are we even pulling relevant information?). Also PII detection since agents love to accidentally leak sensitive data.\n\nPre-production simulation has been critical. We run agents through hundreds of scenarios with different personas before they touch real users. Catches a lot of edge cases where the agent works fine for 3 turns then completely hallucinates by turn 5.\n\nIn production, we run automated evals continuously on a sample of traffic. Set thresholds, get alerts when hallucination rates spike. Way better than waiting for user complaints.\n\nHardest part has been making the evals actually useful and not just noisy. Anyone can flag everything as a potential hallucination, but then you're drowning in false positives.\n\nNot trying to advertise but just eager to know how others are handling this in different setups and what other tools/frameworks/platforms are folks using for hallucination detection for production agents :)",
      "is_original_content": false,
      "link_flair_text": "Resources And Tips",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qcyx2d/agent_reliability_testing_is_harder_than_we/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "nzobddm",
          "author": "pbalIII",
          "text": "32% citing quality as the top production blocker tracks with what I've seen. The hard part isn't catching obvious failures... it's proving regression after a model swap when the output looks fine but behaves differently.\n\nWhat's helped me:\n- Gold set of ~50 nasty cases, tagged by failure mode\n- Re-run on every prompt change, not just deploys\n- LLM-as-judge for tone and formatting, deterministic checks for tool calls\n\nThe 89% observability vs 52% evals gap tells you where most teams are stuck. They can see what happened, but can't say if it was right.",
          "score": 3,
          "created_utc": "2026-01-15 04:43:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo40mc",
          "author": "deadweightboss",
          "text": "This is why companies like Anthropic (and my own, two years before) inject different system prompts depending on the context. \n\n\nLong context eval ks super hard because long context datasets aren’t really there. It’s why Google struggles so much at post training.",
          "score": 2,
          "created_utc": "2026-01-15 03:54:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxp025",
          "author": "real_serviceloom",
          "text": "@mods spam!",
          "score": 2,
          "created_utc": "2026-01-16 15:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo10j4",
          "author": "realzequel",
          "text": "Regular software bugs are binary. Either the code works or it doesn't\n\n  \nhuh? How many bugs have you encountered? I’ve seen all kinds of bugs that only happen occasionally or race conditions. Binary? Hah, you must be new to software development.",
          "score": 3,
          "created_utc": "2026-01-15 03:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzreuio",
              "author": "Herect",
              "text": "Intermittent bugs are the worse. If you can find the exact conditions that trigger it, the battle is half won already.",
              "score": 2,
              "created_utc": "2026-01-15 17:17:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmxeaw",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-14 23:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmxecu",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-14 23:48:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmxoiw",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-14 23:50:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmxon6",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-14 23:50:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrm5m0",
          "author": "no_witty_username",
          "text": "In agents these things are prevalent only if the harness is not set up well + bad system prompt. System prompt should be detailed yet concise, describing the role of the agent, its capabilities, its limitations, meta-cognitive information about its own framework, what the tools do and what data to trust and what data to take with a grain of salt. also metadata should be in place via harness system that helps in making said decisions. specking of harnesses, it should be designed from bottom up with a goal to allow easy and good vitrification via the agent. and a lot of system messages that guide the agent in many respects. all of these things are a bare minimum to get an agent working well, let alone other things like proper context management via smart auto compaction, rag, etc...",
          "score": 1,
          "created_utc": "2026-01-15 17:50:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm89uk",
          "author": "Illustrious-Film4018",
          "text": "Really, according to people on r/accelerate, SOTA models don't hallucinate anymore and if it hallucinates, it's because you're using the wrong model or doing something wrong.",
          "score": 1,
          "created_utc": "2026-01-14 21:43:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzmefyb",
              "author": "creaturefeature16",
              "text": "That's because those people are \"AI incels\" and not worth paying any attention to. They hate their own humanity and would prefer to leave it behind than take responsibility and do something good with their lives. ",
              "score": 5,
              "created_utc": "2026-01-14 22:11:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzmkc7u",
                  "author": "Illustrious-Film4018",
                  "text": "I agree, and they've never actually used AI for anything important.",
                  "score": 2,
                  "created_utc": "2026-01-14 22:40:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzmec7t",
              "author": "mossiv",
              "text": "I’ve been having hallucinations in very simple prompt windows. GPT especially. Within one sentence it told me a lie, I called it out and it gaslit me. It hallucinated, got it wrong and denied all accountability. If orgs are claiming hallucinations happen less it’s because they are steering them to be more authoritative. Which is worse.",
              "score": 1,
              "created_utc": "2026-01-14 22:11:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdtz6e",
      "title": "Need people to get excited part 2",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qdtz6e/need_people_to_get_excited_part_2/",
      "author": "External_Ad1549",
      "created_utc": "2026-01-15 19:57:04",
      "score": 9,
      "num_comments": 19,
      "upvote_ratio": 0.65,
      "text": "Three months ago I posted here saying I had found GLM-4.5 and coding suddenly felt like binge watching a Netflix series. Not because it was smarter, but because the flow never broke and affordable. I tried explaining that feeling to people around me and it mostly went over their heads.Then I shared it here  \n[https://www.reddit.com/r/ChatGPTCoding/comments/1nov9ab/need\\_people\\_to\\_get\\_excited/](https://www.reddit.com/r/ChatGPTCoding/comments/1nov9ab/need_people_to_get_excited/)\n\nSince then I’ve tried Cline, Claude Code, OpenCode. All of them are good tools and genuinely useful, but that original feeling didn’t really come back. It felt like improvement, not a shift.\n\nYesterday I tried Cerebras running GLM-4.7 and it was awesome. Around 1000 t/s output. Not just fast output the entire thinking phase completes almost instantly. In OpenCode, the model reasoned and responded in under a second, and my brain didn't even get the chance to lose focus.\n\nThat’s when it clicked for me: latency was the invisible friction all along. We’ve been trained to tolerate it, so we stopped noticing it. When it disappears, the experience changes completely. It feels less like waiting for an assistant and more like staying inside your own train of thought.\n\nI just wanted to share it with you guys because this good news only you can understand\n\nnote: We can't use Cerebras like a daily driver yet, their coding plans exclusive and brutal rate limits, they are able to achieve this bathroom tile size cpus, very interesting stuff I hope they succeed and do well\n\ntldr; discovered cerebras",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qdtz6e/need_people_to_get_excited_part_2/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "nzylqsm",
          "author": "PutPurple844",
          "text": "I got excited with the speed, too, not so much with the output. But it's insane once it is stable, we will kind of have zero downtime between iterations.",
          "score": 3,
          "created_utc": "2026-01-16 17:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyn8yq",
              "author": "External_Ad1549",
              "text": "yes exactly waiting for that",
              "score": 1,
              "created_utc": "2026-01-16 18:03:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzx178o",
          "author": "neurosurge",
          "text": "I tried GLM-4.7 (free and paid) for a couple of days, but it seems like it just hallucinates constantly and puts out low quality plans and code. \n\nI always have a different model/agent check another model’s work, and I always find a few things that need tweaked or updated. Every prompt with GLM-4.7 seemed to output garbage. I don’t know if it’s my setup with OpenCode or just poor model performance. \n\nI hope they get it fixed in a future release. The pricing and token allocation are amazing, especially compared to Anthropic’s offerings, but the reasoning seems to need a lot of work still.",
          "score": 2,
          "created_utc": "2026-01-16 13:34:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzx2hx1",
              "author": "External_Ad1549",
              "text": "this is entirely based on my experience, the llm  any llm will have some capacity for it. some can create only functions, some only can create files, some can create modules, very costly ones can vibe code entire project. If you ask beyond the capacity it will start hallucinate.\n\nalso sometimes for cost cutting they reduce the capacity of llm, happens to chatgpt as well. GLM 4.7 is the work horse for me. Validation and stabilizing I will give it gemini 3 flash.\n\nany llm model which is not unlimited tokens gives kind of anxiety for me and also I work in mainly backend python systems so that might be different. \n\nI can say u can trust 4.7 for python backend",
              "score": 1,
              "created_utc": "2026-01-16 13:41:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuazf9",
          "author": "keepthepace",
          "text": "There is a reason why NVidia bought Groq. They have competition coming!",
          "score": 1,
          "created_utc": "2026-01-16 01:43:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv8zq1",
              "author": "External_Ad1549",
              "text": "and cerebras teaming up with gpt all good things",
              "score": 1,
              "created_utc": "2026-01-16 05:04:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzvrpyc",
          "author": "real_serviceloom",
          "text": "Ok this is interesting because for me glm 4.7 has been absolutely slow as molasses. I tried the open code free glm 4.7 provider and also the cerebras version and both were incredibly slow.",
          "score": 1,
          "created_utc": "2026-01-16 07:30:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwvxbr",
              "author": "External_Ad1549",
              "text": "I am on max plan still sometimes feels like slow, but cerebras is on different league",
              "score": 1,
              "created_utc": "2026-01-16 13:03:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzxoosu",
                  "author": "real_serviceloom",
                  "text": "I dunno for me even on cerebras a /review on opencode just hangs forever compared to minimax m2.1. None of them come close to gpt 5.2 or opus 4.5 though. That's why I feel like z.ai lies a bit with their benchmarks showing them so close to opus. I know they have to make money but their marketing should be more honest. ",
                  "score": 1,
                  "created_utc": "2026-01-16 15:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwtfjm",
          "author": "popiazaza",
          "text": "Try Windsurf SWE-1.5. Should be based on GLM-4.6 and it run on Cerebras if you use Fast model.\n\nNormal model is also decently fast, and it's free to use for limited time.",
          "score": 1,
          "created_utc": "2026-01-16 12:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwvrap",
              "author": "External_Ad1549",
              "text": "really?? this is the info I require I wish it is glm 4.7 but something yeah thanks",
              "score": 1,
              "created_utc": "2026-01-16 13:02:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o056wlo",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-17 18:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o056woc",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-17 18:02:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o05badc",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-17 18:22:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05bagk",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-17 18:22:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0enij6",
          "author": "SilencedObserver",
          "text": "You don’t know why the word “need” means.",
          "score": 1,
          "created_utc": "2026-01-19 02:36:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdrqw7",
      "title": "From your experience: practical limits to code generation for a dynamic web page? (here is mine)",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qdrqw7/from_your_experience_practical_limits_to_code/",
      "author": "toolznbytes",
      "created_utc": "2026-01-15 18:35:51",
      "score": 7,
      "num_comments": 15,
      "upvote_ratio": 1.0,
      "text": "(*using ChatGPT Business*)\n\nI'm asking ChatGPT for a self-contained HTML page, with embedded CSS and javascript, with a detailed specification I describe and refine.\n\nI successfully obtained a working page but it starts to derail here and there more and more often after a while, as the conversation goes on.\n\nI'm at iteration 13 or so, with a handful of preparation questions before.\n\nThe resulting html page has:\n\n* 4k CSS\n* 13k script\n* 3k data (as script const, not counted in the 13k)\n* 19k total with html\n* all the display, data parsing, list and 2 buttons are working well.\n\nI'm happy but has I said, at the step before it started to skip all the 3k data, using a placeholder instead. And before the data to process was damaged (edited).\n\nSo for me, it's near the practical limit I think. I'm afraid I'm run in more and more random regressions as I push further.\n\nMy questions:\n\n1. How far can you go before the need to split the tasks and stitch them together by hand?\n2. Is there any way to make it handle this kind of task in a more robust way?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qdrqw7/from_your_experience_practical_limits_to_code/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "nzsv6wv",
          "author": "Trotskyist",
          "text": "Don’t use ChatGPT for this task. Look into codex-cli or Claude code. I prefer Claude Code, but I believe codex is included with business plans.\n\nFor context: I’ve created full stack web applications with the above tools well into the hundreds of thousands of lines of code (not that LoC is a metric that tells you anything about quality, but it is an indication of complexity.)\n\nI mean on some level it’s impressive you’ve made it this far in only the chat interface, but you’re making things way harder on yourself than they need to be.",
          "score": 3,
          "created_utc": "2026-01-15 21:15:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx9hki",
          "author": "jonydevidson",
          "text": "Jesus fuck, why are you generating code in the web editor?\n\n1. Download VSCode\n2. Download Git (this is your game-save mechanic and will save your life)\n3. In VSCode, download Codex extension from OpenAI. Log in with your ChatGPT account. \n4. Create new folder on your disk. This will be your project folder. In VSCode, File > Open folder... and open it. This is now your WORKSPACE\n5. Tell the agent to initialize the git repository. This will now start tracking file changes. You STAGE changes that you wish to save, and then you make COMMITs. A commit is a fully human readable save-point in your project. You can navigate back to it and restore your project to that point or any other point, see the changes made in that commit, pick files to be reset back to the state at that commit and so much more. Download the Git Graph extension in VSCode but I recommend a Git UI like Fork.dev \n6. NOW you tell the agent what you want it to do. Every time you complete a feature and it's working, you commit the changes in Git. If at any point you or the agent fuck up, just discard the changes in Git and start over from your last save point - no fear of losing full progress or going in too deep in the wrong direction.",
          "score": 3,
          "created_utc": "2026-01-16 14:17:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzz66fv",
              "author": "toolznbytes",
              "text": "Thank you for all this! 👍👍👍\n\nI realize I did something in a strange way... It worked surprisingly well, up to a point.\n\nOk, my next tool will be done with that workflow 😤\n\nBut now I'm out of the free trial, so I'll have to pay somewhere , codex or Claude or something. I guess they don't have pay per use.",
              "score": 1,
              "created_utc": "2026-01-16 19:27:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzz82o7",
                  "author": "jonydevidson",
                  "text": "Codex limits will get you much further than Claude Code. Opus will eat the usage quotas, while with Codex you can actually use GPT5.2 Codex on Medium and get decent usage, while having a much smarter model than Sonnet 4.5.\n\nGive each one a try and see what you like, in the end it's just $20 and you'll be getting a lot more value out of it. Even if you completely fail and ship nothing, you'll have learned valuable skills in working with frontier tech that's going to be the future of work everywhere.",
                  "score": 1,
                  "created_utc": "2026-01-16 19:36:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzu9bys",
          "author": "evia89",
          "text": "Meh. Use good structure then web pack to static",
          "score": 1,
          "created_utc": "2026-01-16 01:34:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv5bol",
              "author": "toolznbytes",
              "text": "Sorry, can you say that again, please?",
              "score": 1,
              "created_utc": "2026-01-16 04:40:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzw4a0p",
                  "author": "evia89",
                  "text": "https://www.perplexity.ai/search/how-to-use-webpack-to-get-stat-iQLeJ_MVSymCr5a3Uhv7CQ#0",
                  "score": 1,
                  "created_utc": "2026-01-16 09:24:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzvntx0",
          "author": "BattermanZ",
          "text": "As another commenter said, use Codex in VS Code or codex-cli. You will one shot your task. Best of all, it's included in your chatgpt subscription.",
          "score": 1,
          "created_utc": "2026-01-16 06:57:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzwhigc",
          "author": "Tema_Art_7777",
          "text": "I use codex with gpt-5.2 - it is very good.",
          "score": 1,
          "created_utc": "2026-01-16 11:22:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx5c8x",
          "author": "NinjaLanternShark",
          "text": "I bailed out of coding via chat long before this kind of complexity. Just too frustrating. Personally I like VS Code with Copilot, but Codex, Claude or any similar coding-specific, agentic interface is the only way to handle tasks more than a few screens-worth of code.",
          "score": 1,
          "created_utc": "2026-01-16 13:56:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qelrpl",
      "title": "For loves sake no more AI frameworks. Lets move to AI infrastructure",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qelrpl/for_loves_sake_no_more_ai_frameworks_lets_move_to/",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-16 17:08:57",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 0.65,
      "text": "Every three minutes, there is a new agent framework that hits the market.\n\nPeople need tools to build with, I get that. But these abstractions differ oh so slightly, viciously change, and stuff everything in the application layer (some as black box, some as white) so now I wait for a patch because i've gone down a code path that doesn't give me the freedom to make modifications. Worse, these frameworks don't work well with each other so I must cobble and integrate different capabilities (guardrails, unified access with enterprise-grade secrets management for LLMs, etc).\n\nI want agentic infrastructure - clear separation of concerns - a jam/mern or LAMP stack like equivalent. I want certain things handled early in the request path (guardrails, tracing instrumentation, orchestration), I want to be able to design my agent instructions in the programming language of my choice (business logic), I want smart and safe retries to LLM calls using a robust access layer, and I want to pull from data stores via tools/functions that I define.\n\nI want simple libraries, I don't want frameworks. And I want to deliver agents to production in ways which is framework-agnostic and protocol-native.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qelrpl/for_loves_sake_no_more_ai_frameworks_lets_move_to/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "nzyctyx",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-16 17:17:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzycu25",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-16 17:17:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzyiqmn",
          "author": "dumbledork99",
          "text": "What's your view on haystack. I have always found it allows you to choose how deep down the rabbit hole you want to go.",
          "score": 1,
          "created_utc": "2026-01-16 17:43:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzymocc",
              "author": "AdditionalWeb107",
              "text": "There are some obvious ones\n\n1/ Durable checkpointing and replay (compute infra). Maybe [Temporal](https://github.com/temporalio/temporal)?  \n2/ Data plane for routing, orchestration, observability, and moderation. Maybe [Plano](https://github.com/katanemo/plano)?  \n3/ Memory Infra for context compression and expansion? Maybe [Mem0](https://github.com/mem0ai/mem0)?  \n4/ Hybrid store (plus vector)? Maybe PostgreSQL?",
              "score": 1,
              "created_utc": "2026-01-16 18:01:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzz7lvs",
                  "author": "dumbledork99",
                  "text": "I meant what are your views on [Haystack](http://haystack.deepaet.ai) ?\nHave you tried it?",
                  "score": 1,
                  "created_utc": "2026-01-16 19:34:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0pfa77",
          "author": "simulakrum",
          "text": "No more AI at all would be great",
          "score": 1,
          "created_utc": "2026-01-20 18:00:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhyflb",
      "title": "precision vibe coding",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qhyflb/precision_vibe_coding/",
      "author": "thehashimwarren",
      "created_utc": "2026-01-20 11:16:01",
      "score": 4,
      "num_comments": 12,
      "upvote_ratio": 0.83,
      "text": "I've been using AI to scaffold apps and build features. And I have a whole system for that.\n\nBut what I'm struggling with now is getting my projects to a \"done\" state where the UI looks polished, and the user experience is smooth.\n\nOn my local machine I had about a dozen half finished projects where I hit a wall and just couldn't get the final parts to work.\n\nHow do you handle getting over the final 10% hump?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qhyflb/precision_vibe_coding/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o0o9pm1",
          "author": "Western_Objective209",
          "text": "You need to understand software systems; that last 10% ends up being most of the work, and what you think is the last 10% is probably 50% of the project which is making sure you have a coherent design.",
          "score": 3,
          "created_utc": "2026-01-20 14:44:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0njeu3",
          "author": "Tema_Art_7777",
          "text": "UI seems to be the soft spot, can’t achieve perfect alignment etc and it can’t solve it sometimes. Ideally it can ‘see’ the output and iterate over it. Stepping in  to code for that 10% will kill the efficiency.",
          "score": 3,
          "created_utc": "2026-01-20 12:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oqkdt",
          "author": "Fulgren09",
          "text": "UI is easy to display but psychologically hard to crunch into something elegant. \n\nFor complex UI, for me it takes gentle stick handling each small change so it doesn’t break the app. \n\nMore often than not this leads to me doing the adjustments on the vibe coded stuff. \n\nMy suggestion, make it work without UI\nthen make it work by printing all the UI you need\nThen make it good by using it. The insights and optimizations will reveal themselves to you only at this point. ",
          "score": 3,
          "created_utc": "2026-01-20 16:05:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oqtbx",
              "author": "thehashimwarren",
              "text": "\"Make it good by using it\"\n\nAh! Thanks!",
              "score": 2,
              "created_utc": "2026-01-20 16:07:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0osnkq",
                  "author": "Fulgren09",
                  "text": "I have no specialization in this, and I know it sounds obvious but it takes me 20+ passes on using complex flows before I notice things that can be cut or improved. ",
                  "score": 2,
                  "created_utc": "2026-01-20 16:15:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0o5fzi",
          "author": "NotUpdated",
          "text": ">On my local machine I had about a dozen half finished projects where I hit a wall and just couldn't get the final parts to work.  \n  \nOnce you get comfortable local, buy a VPS - and start learning that side from the ground up. Consider it your capstone project / graduating to real production / public servers.  \n  \nYour first real/production/public thing shouldn't collect personal information like payments or addresses or emails, you're not ready yet. Use oAuth / don't try to roll your own authentication.",
          "score": 2,
          "created_utc": "2026-01-20 14:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ndvne",
          "author": "RegisterConscious993",
          "text": "It sounds counterintuitive to vibecoding, but learning a little bit of programming goes a long way. All you really need is a month to learn some basic html, css (tailwind), JS and whatever framework you're working with.\n\nYou'll be able to steer the AI, prompt better, and understand when it's leading you down the wrong path.\n\nWith UI, I always make a wireframe myself and feed the screenshot in copilot. It'll get it about 80, maybe 90% of the way, and I can just make the final fixes myself. I've tried to rely only on AI but I don't think it's there yet. You'll end up spending more time prompting to get it exactly how you want when you could've just spend that wasted time learning a bit.",
          "score": 4,
          "created_utc": "2026-01-20 11:25:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oqzzo",
              "author": "thehashimwarren",
              "text": "I know a little, but Ive never been able to get UI pieces to work, even before AI",
              "score": 1,
              "created_utc": "2026-01-20 16:07:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0phz06",
          "author": "makinggrace",
          "text": "Your system may be backwards. It seems logical to build all of the components, wire them together, and then expose with a UI.\n\nBut building this way hides flaws in integration that won't reveal themselves until the code is running.\n\nTry building the smallest viable version of the most critical component out in full first -- including a functioning UI. If you were writing a to-do app, this would be a function that collects new to-do items. (Have the script just save to local for now.) Then test by you the human user running that code: does the component accomplish the goal? Look and feel like you expect? Actually save to local? If not, fix it. If yes, add it to approved patterns in your AGENTS.md file.  Then work on the next chunk: not making this one more robust, but rounding out the app's basic components: start building auth, db, etc.\n\nAlso consider using a component library for the UI elements if you are not. \n\nRun code in a dev mode that is as close to your target production environment as possible. Local is good for running tests and writing code but you need to what the thing behaves like in the free(ish) world.",
          "score": 1,
          "created_utc": "2026-01-20 18:12:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pi341",
          "author": "meckstss",
          "text": "I create wireframes in figma, then use a testing suite that extracts images from chromium, and passes them to an agent that compares the wireframe to the chromium screen print.  If it don't match it raises trh alarm and the GUI agent tries again.  I got tired of telling it that it was wrong.",
          "score": 1,
          "created_utc": "2026-01-20 18:12:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pl03w",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-20 18:25:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pl0e0",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-20 18:25:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgqrvi",
      "title": "Plano 0.4.3 ⭐️ Filter Chains via MCP and OpenRouter Integration",
      "subreddit": "ChatGPTCoding",
      "url": "https://i.redd.it/n1mwwe88n7eg1.png",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-19 01:40:12",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qgqrvi/plano_043_filter_chains_via_mcp_and_openrouter/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0ede99",
          "author": "AdditionalWeb107",
          "text": "Link to repo: [https://github.com/katanemo/plano](https://github.com/katanemo/plano)",
          "score": 1,
          "created_utc": "2026-01-19 01:40:35",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf8d9o",
      "title": "Best autocomplete/next edit suggestion extension for VS Code?",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qf8d9o/best_autocompletenext_edit_suggestion_extension/",
      "author": "MiddleCodd",
      "created_utc": "2026-01-17 08:55:12",
      "score": 3,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I have used Cursor and Windsurf in the past, and both offered really powerful autocomplete and next-edit suggestions (like Windsurf Supercomplete/Tab and Cursor Tab). Their ability to predict not only new code but also nice tab completions based on recent context really sped up my workflow.\n\nNowadays, my employer requires us to use VS Code with GitHub Copilot. While Copilot's chat/agent mode has quite improved over the past months, its tab suggestions (referred to as “inline suggestions” or “next edit suggestions”) don’t quite match the level of quality I experienced with Cursor or Windsurf. The completions feel less intuitive and less context-aware.\n\nI’m wondering if there are any extensions specifically designed for autocomplete or tab suggestions. I’m not just looking for an extension that help with autocompleting new code, but also those that can provide smart tab completions on existing code based on stuff like recent changes, linter errors, or previously accepted edits like Cursor/Windsurf. \n\nMy goal would be to continue using GitHub Copilot for the chat/agent mode, but to replace its tab completions with another extension focused specifically on smarter inline suggestions.\n\nI don't mind paying a monthly subscription.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qf8d9o/best_autocompletenext_edit_suggestion_extension/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o031hhc",
          "author": "NoEngineering3321",
          "text": "I am in the same position as you are. For me, windsurf was overall best, while copilot struggles with basics sometimes. I'm currently using Antigravity, but can't make any judgement yet.   \nJust to warn you.    \nConsult your idea with your employer. Having an enterprise subscription means the company won't use data to feed their tools with. While, your personal subscription is used.    \nMost companies are working with one tool and all others are forbidden",
          "score": 2,
          "created_utc": "2026-01-17 10:28:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0hfnxq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-19 14:51:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0hfo0x",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-19 14:51:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qh9aca",
      "title": "Quick Question: What do you need most from your AI Coding Tools?",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qh9aca/quick_question_what_do_you_need_most_from_your_ai/",
      "author": "Jbbrack03",
      "created_utc": "2026-01-19 16:43:46",
      "score": 3,
      "num_comments": 9,
      "upvote_ratio": 0.64,
      "text": "Hey folks!\n\nI've been deep in the Claude Code / AI coding agent space for a while, and I'm doing market research to determine whether a tool I'm building could actually solve real problems.\n\nMany projects fail because the dev never asks the community about what they want, and about what problems they actually face. So I'm making no assumptions! Below is a link to a Google Forms questionnaire that has a few quick questions. Completely anonymous (no email required). This will help to shape the direction of what I'm building. Thank you for partnering in this process!\n\n[https://forms.gle/LAXwhxPfqbVzGT3j6](https://forms.gle/LAXwhxPfqbVzGT3j6)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1qh9aca/quick_question_what_do_you_need_most_from_your_ai/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o0i8flr",
          "author": "funbike",
          "text": "You aren't \"curious\".  You are doing market research. Be honest about your intentions.",
          "score": 7,
          "created_utc": "2026-01-19 17:03:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0i92hv",
              "author": "Jbbrack03",
              "text": "Yes, that's fair and I didn't mean to imply otherwise. Statistically 42% of software products fail because the developer assumed that they knew what their audience wanted, and just bulldozed ahead without actually asking. And that's all I'm doing. Asking so that what I build helps the community and isn't just more spam.",
              "score": -4,
              "created_utc": "2026-01-19 17:06:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ilrzd",
                  "author": "Cast_Iron_Skillet",
                  "text": "Why not come out and say it? People see through lies and half truths.",
                  "score": 4,
                  "created_utc": "2026-01-19 18:03:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0k9ab5",
          "author": "Frequent-Complaint-6",
          "text": "Money!",
          "score": 2,
          "created_utc": "2026-01-19 22:42:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0idxj3",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-19 17:28:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0idxl2",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-01-19 17:28:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0l7mpa",
          "author": "Mice_With_Rice",
          "text": "I will consider answering if it is built on a public git repo under a GLP license with multiple contributors that are not affiliated with eachother.",
          "score": 1,
          "created_utc": "2026-01-20 01:47:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}