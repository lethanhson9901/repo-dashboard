{
  "metadata": {
    "last_updated": "2026-02-19 09:09:59",
    "time_filter": "week",
    "subreddit": "ChatGPTCoding",
    "total_items": 8,
    "total_comments": 85,
    "file_size_bytes": 84530
  },
  "items": [
    {
      "id": "1r7j5bi",
      "title": "The Opus vs Codex horse race in one poll",
      "subreddit": "ChatGPTCoding",
      "url": "https://i.redd.it/a2bcz17ag4kg1.png",
      "author": "thehashimwarren",
      "created_utc": "2026-02-17 21:20:15",
      "score": 97,
      "num_comments": 30,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r7j5bi/the_opus_vs_codex_horse_race_in_one_poll/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5zkljo",
          "author": "ww_crimson",
          "text": "I've been using both for a week and I think Codex is a lot better. Haven't done a controlled test but the way I saw people talking about Opus I thought it was going to be some galaxy brain shit. It has the worst rate limits I've ever seen and it still makes plenty of mistakes on medium sized projects.",
          "score": 16,
          "created_utc": "2026-02-18 03:09:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o605719",
          "author": "colbyshores",
          "text": "I'm using Gemini 3 flash in antigravity because it's cheap",
          "score": 7,
          "created_utc": "2026-02-18 05:25:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61cx4m",
              "author": "DottorInkubo",
              "text": "My God dude, is it producing anything working, even 20% of the time?",
              "score": 10,
              "created_utc": "2026-02-18 11:47:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o66tqy5",
                  "author": "durable-racoon",
                  "text": "yes for very repetitive and clearly-defined tasks, large scale refactoring, digging\\\\ through to find a specific piece of code and so on. very cheap and effective too. small models are great unless your only way of interacting is \"build me feature X, go.\"",
                  "score": 1,
                  "created_utc": "2026-02-19 04:45:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61gliv",
                  "author": "sannysanoff",
                  "text": "it is really good.",
                  "score": 1,
                  "created_utc": "2026-02-18 12:13:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o66spfa",
              "author": "recigar",
              "text": "The one thing I struggle with is the agent manager being a separate window so I can‚Äôt just switch to antigravity and immediately do what I want to do.. if there‚Äôs a way to dock it in the main window please tell me ü•∫",
              "score": 1,
              "created_utc": "2026-02-19 04:38:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xrjcs",
          "author": "nekronics",
          "text": "Needs to update with Sonnet 4.6 now",
          "score": 6,
          "created_utc": "2026-02-17 21:26:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62mar9",
          "author": "WriterAgreeable8035",
          "text": "Opus=God",
          "score": 2,
          "created_utc": "2026-02-18 15:56:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62sqnl",
          "author": "StravuKarl",
          "text": "I consistently find Codex to be significantly worse than Claude Code Opus.  I keep going back and trying given comments here and on X.  Any suggestions?",
          "score": 2,
          "created_utc": "2026-02-18 16:25:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65bif8",
              "author": "Money-Calligrapher28",
              "text": "What‚Äôs X?",
              "score": 1,
              "created_utc": "2026-02-18 23:24:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6726xq",
                  "author": "unfathomably_big",
                  "text": "Twitter",
                  "score": 1,
                  "created_utc": "2026-02-19 05:47:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o67b1lc",
              "author": "xbt_",
              "text": "Curious - What kind of coding is it worse at for you? I find front end its design taste can be better but only marginally and often comes with more bugs.",
              "score": 1,
              "created_utc": "2026-02-19 07:01:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o666u9b",
              "author": "poop_harder_please",
              "text": "Likely that you‚Äôve just invested heavily in instructions and skills for Claude but not Codex, which is an easy fix by symlinking your skills folder.\n\nOr you‚Äôre not giving it enough autonomy. It‚Äôs meant to be used as a tool, not a collaborator, in the sense that it‚Äôs not meant to execute in a constant back and forth as it goes through a feature, but instead is meant to just keep going until a well defined problem is solved.¬†",
              "score": 1,
              "created_utc": "2026-02-19 02:22:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xsyoz",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-17 21:32:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xsyr6",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-17 21:32:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5y2vyz",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-17 22:20:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5y2w1p",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-17 22:20:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o61k0va",
          "author": "LurkerBigBangFan",
          "text": "Anyone have experience with 5.2/5.3 conducting PR reviews on code it wrote? Good enough?",
          "score": 1,
          "created_utc": "2026-02-18 12:37:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o659ldv",
          "author": "geronimosan",
          "text": "Who?",
          "score": 1,
          "created_utc": "2026-02-18 23:14:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67h4ll",
          "author": "8aller8ruh",
          "text": "5.3-Codex is absolute dogshit compared to 5.2-Codex ‚Ä¶When using the OpenAI‚Äôs default agent in their VS Code extension it creates a todo of 6-8 items & then stops itself before doing any of them asking if you want to continue.\n\n5.2 & Claude-4.5 did workthrough the problem, I previously upped the limit to 500 internal questions per request but I am missing somewhere to set other-such related settings within VS Code as inside the built-in OpenAI agent: You cannot modify:\n\n* max tool calls per turn\n* max file edits per turn\n* auto-continue behavior\n* yield-after-plan\n* execution timeout\n\nThese are hard-coded in the agent service layer. (I can create a custom agent of course but it seems like this is the primary usecase of this default build-in coding agent would be to make such code changes, they claim this was done to encourage intentionality & to avoid run-away implementations, which I am all for but not even suggesting a single code change is far too small a step.  Claude & GPT-5.2-Codex both one-shot this writing \\~1400 new lines & creating multiple files, just seems like a huge step back even if other things about 5.3 were improved‚Ä¶).  >!‚Ä¶This leads to 5.2 implementing wrong assumptions on things that could have easily been clarified by the user or verified with code.  eg. 5.2 made up a giant table of potential API attributes names it would attempt to query when these attributes were already known & it had been given the API swagger documentation with an API call that listed all existing attributes‚Ä¶which I would have expected it to run if it was trying to determine this on its own‚Ä¶not just guess at names that sounded right but to be based in reality even if it needed to create & run a utility script to gain this knowledge.!<\n\nusecase: I was extracting functionality into a separate application where I had working code that I wanted to take specific parts of & simplify them into their own solution.  Provided the existing implementation (4 C# files) & an empty boilerplate C# project with the dependencies & configs already setup in the same way as the last project.  It did not write a single line.  It would talk about what it planned on doing & then stop itself.\n\nProblem with 5.3-Codex:\n\nhttps://preview.redd.it/mxd20iw6pekg1.jpeg?width=1125&format=pjpg&auto=webp&s=835ed349346f425df3a81e8fe6e35b2f98c1231a\n\nQ: Why is GPT-5.3-Codex pausing instead of implementing code iteratively?  It made its own Todo & then stopped after the very first action.  GPT-5.2-Codex agent would have worked continuously until it had modified all the files it needed to.\n\nA: [https://chatgpt.com/s/t\\_6996ab2a85a881919a5cb470a26a70be](https://chatgpt.com/s/t_6996ab2a85a881919a5cb470a26a70be)\n\nThis was one Plan up above this & then switching to Agent mode for the rest of the failed chat.",
          "score": 1,
          "created_utc": "2026-02-19 07:56:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yhsvq",
          "author": "MK_L",
          "text": "If I could have voted it would have been codex. I do use claude but its very limited compared. Codex performed 9 out of 10 for me. Where it didn't I used claude. Very small cases. Most of the time codex could have btw. But more iterations so I used claude knowing it would have been less passes",
          "score": 1,
          "created_utc": "2026-02-17 23:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zu7pm",
          "author": "djosephwalsh",
          "text": "Both. Claude at work, Codex on my personal computer. Both are great",
          "score": 1,
          "created_utc": "2026-02-18 04:08:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666fdk",
          "author": "poop_harder_please",
          "text": "Hot take: 4.6 is for the normies who want to *feel* like they‚Äôre SWEing but are actually vibing, and Codex is for the SWEers who want to get the job done with as much leverage as possible.¬†",
          "score": 1,
          "created_utc": "2026-02-19 02:20:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3c6a5",
      "title": "ChatGPT 5.3-Codex-Spark has been crazy fast",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r3c6a5/chatgpt_53codexspark_has_been_crazy_fast/",
      "author": "tta82",
      "created_utc": "2026-02-13 01:45:25",
      "score": 57,
      "num_comments": 42,
      "upvote_ratio": 0.96,
      "text": "I am genuinely impressed and I was thinking to actually leave to Claude again for their integration with other tools, but looking at 5.3 codex and now Spark, I think OpenAI might just be the better bet.  \nWhat has been your experience with the new model? I can say it is BLAZING fast.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r3c6a5/chatgpt_53codexspark_has_been_crazy_fast/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o53s3mj",
          "author": "goldenfrogs17",
          "text": "New model comes out. AI company allocates resources to new model. New model impresses. Company de-allocates, or resources get spread thin. People become disappointed.\n\nCould it happen again?",
          "score": 59,
          "created_utc": "2026-02-13 03:46:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56vg7h",
              "author": "vipw",
              "text": "5.3-codex-spark is not running on the same hardware platform as the other models; the inference is done on Cerebras chips. While demand might saturate the hardware resources leading to delay because of requests being queued, it is a separate pool of resources.",
              "score": 9,
              "created_utc": "2026-02-13 16:44:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o576wx8",
                  "author": "Pleasant-Today60",
                  "text": "Interesting, didn't realize it was running on Cerebras. That explains the speed difference. Curious how it'll hold up once more people discover it and the queue gets longer.",
                  "score": 4,
                  "created_utc": "2026-02-13 17:40:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5657i9",
              "author": "Dilligentslave",
              "text": "yeah its basically inevitable like they pump resources into the shiny new thing and suddenly your previous favorite model gets slower updates and less attention until someone else is faster and then theyre chasing again its just the cycle",
              "score": 4,
              "created_utc": "2026-02-13 14:37:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54xysk",
              "author": "-IoI-",
              "text": "I've suspected this often, particularly for OAI, but haven't seen anyone talking about it. Is it widely known to be occurring?",
              "score": 1,
              "created_utc": "2026-02-13 09:32:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55lzds",
                  "author": "Santamunn",
                  "text": "Us three know about it.",
                  "score": 2,
                  "created_utc": "2026-02-13 12:50:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o59ai0e",
                  "author": "MikeFromTheVineyard",
                  "text": "It‚Äôs not what‚Äôs happening here. They‚Äôre running spark on Cerebras which is know to be faster than GPUs",
                  "score": 1,
                  "created_utc": "2026-02-14 00:06:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o564uoe",
          "author": "FickleSwordfish8689",
          "text": "i'm sure they made a trade off between speed and smartness of the model?",
          "score": 9,
          "created_utc": "2026-02-13 14:35:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56hg8t",
          "author": "xplode145",
          "text": "It‚Äôs not the Sam as gpt5.2 or codex 5.3. ¬†It‚Äôs smaller and makes mistakes. ¬†A lot. ¬†Won‚Äôt use it for production grade software¬†",
          "score": 6,
          "created_utc": "2026-02-13 15:38:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o559ocg",
          "author": "SatoshiNotMe",
          "text": "Only 128K context though",
          "score": 4,
          "created_utc": "2026-02-13 11:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5b6gyj",
              "author": "MoneyStatistician311",
              "text": "Is more really needed for a model like this? I would expect it to be used in very targeted changes (where no more than a couple of files would be needed)",
              "score": 3,
              "created_utc": "2026-02-14 08:27:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55f9hg",
          "author": "Sea-Sir-2985",
          "text": "the speed is genuinely impressive but i keep coming back to the same question with every new model drop... fast at what quality level? like codex spark feels snappy for straightforward tasks but i've noticed it starts making subtle mistakes on anything involving cross-file dependencies or complex state management\n\nmy current setup is still claude for the heavy architectural stuff and planning, then faster models for the implementation grunt work. the model switching in claude code is actually great for this, you can run haiku agents for the simple file edits and save the bigger model for decisions that actually matter. speed is nice but i'd rather wait 10 extra seconds than spend 30 minutes debugging a hallucinated import etc",
          "score": 3,
          "created_utc": "2026-02-13 12:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54b1g3",
          "author": "scrod",
          "text": "Is spark a dumbed-down smaller model? How does it actually compare in terms of intelligence?",
          "score": 4,
          "created_utc": "2026-02-13 06:04:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54t0wj",
              "author": "AppealSame4367",
              "text": "It's not as good in tau bench or something. read their announcement, they even show it themselves. it's super fast but quite a bit less capable",
              "score": 3,
              "created_utc": "2026-02-13 08:45:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54yxi8",
                  "author": "tta82",
                  "text": "It‚Äôs been doing things ok for me and fast. It‚Äôs for ‚Äúsimpler‚Äù tasks but blazing fast.",
                  "score": 2,
                  "created_utc": "2026-02-13 09:42:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56hln6",
              "author": "xplode145",
              "text": "Yes it‚Äôs much smaller version of codex. Probably sonnet 4.5 type¬†",
              "score": -1,
              "created_utc": "2026-02-13 15:38:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o552he9",
          "author": "UsefulReplacement",
          "text": "It's been also crazy useless. Tried to run a code review with it, got stuck into a context compact loop.\n\nFor coding, what's the point of using a fast model, if it will slop my codebase and I have to spend 5x the amount of time running code reviewers with better and slower models. Saving me a few mins generating the first draft of the code, only to add hours in follow up reviews.",
          "score": 2,
          "created_utc": "2026-02-13 10:15:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5576jq",
              "author": "tta82",
              "text": "Your code must be huge - this model isn‚Äôt for that I suppose - rather for smaller changes",
              "score": 2,
              "created_utc": "2026-02-13 10:58:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55ib8m",
                  "author": "UsefulReplacement",
                  "text": "28,523 total lines of PHP + 4,180 total lines of JS\n\nAll agent coded (with gpt-5+ models) and works super well. But, as I said, spark has been useless on it.",
                  "score": 1,
                  "created_utc": "2026-02-13 12:25:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55qrjv",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-13 13:19:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55qrlp",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-13 13:19:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5656uy",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-13 14:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5656x8",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-13 14:37:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56pn5r",
          "author": "shaonline",
          "text": "The context window is really rough, 128k minus the reserved portion for the response is tiny for any real use case other than the showcased \"HTML snake game\".",
          "score": 1,
          "created_utc": "2026-02-13 16:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cq05l",
          "author": "Prince_ofRavens",
          "text": "If I could make 5.3 codex control spark I I would use it\n\nBut for me so far if I even just\n\n\"Go get this repo <>\nClone it\nCreate a pip env for it \nRun pip installs\n\"\n\nI'll come back and it will be like \n\n\"Yeah I found that repo! Ready to clone it? Just say the word!\"\n\nIf it keeps coming back for overwhelming simple tasks it doesn't matter how fast it is",
          "score": 1,
          "created_utc": "2026-02-14 15:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5er0zn",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-14 21:52:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5er127",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-14 21:52:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f35e1",
          "author": "calben99",
          "text": "The speed improvements with the new Codex models are impressive, especially for iterative debugging workflows. One tip: use the agent mode for multi-file refactoring rather than single-prompt generation. It handles cross-file dependencies much better and maintains consistency across your codebase. Also, the context window increase means you can paste entire error traces and logs for more targeted fixes.",
          "score": 1,
          "created_utc": "2026-02-14 23:01:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f5w9l",
              "author": "tta82",
              "text": "I actually never tried multi agent yet - how do you initiate it?",
              "score": 1,
              "created_utc": "2026-02-14 23:17:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gw64p",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 06:40:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5gw65x",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 06:40:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5n575w",
          "author": "Furry_Eskimo",
          "text": "How do you access it? I don't see it in the app.",
          "score": 1,
          "created_utc": "2026-02-16 06:42:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nbgft",
              "author": "tta82",
              "text": "only if you are in Codex and if you are on the highest 200 USD/month plan",
              "score": 1,
              "created_utc": "2026-02-16 07:39:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5odygg",
                  "author": "Furry_Eskimo",
                  "text": "Dang,, okay, thanks for the info.",
                  "score": 2,
                  "created_utc": "2026-02-16 13:11:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5e1ek4",
          "author": "oh_jaimito",
          "text": "> I was thinking to actually leave to Claude again\n\nWhy do so many people say this!?\n\nUse ALL the tools!\n- Pay for Claude.\n- Pay for ChatGPT.\n- Pay for Gemini.\n\nThey will always have their own strengths and weaknesses. Learn what they are. Leverage them and use them. \n\nIf you keep abandoning one tool for another, and then come back because they released something new and the benchmarks review better scores, and some AI Influencer says _\"it's game changing\"_. You are just gonna waste time chasing the next big thing.\n\nWe are barely a month and a half into 2026. And we've had OpenClaw distupt the AI world. Codex 5.3. Opus 4.6. and there will be MORE goodies later this month.\n\nJust sharing my opinion amigo üëç",
          "score": 0,
          "created_utc": "2026-02-14 19:33:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ezwiu",
              "author": "tta82",
              "text": "Paying 200$ x2 isn‚Äôt worth it. Claude costs a lot for opus. And ChatGPT codex is great. Either of them is fine but 400$ monthly is too much.",
              "score": 0,
              "created_utc": "2026-02-14 22:42:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5fahtr",
                  "author": "oh_jaimito",
                  "text": "Who said anything about paying $400???\n\nYou clearly did not read nor did you understand my comment.",
                  "score": 0,
                  "created_utc": "2026-02-14 23:46:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r64agl",
      "title": "Minimax M2.5 vs. GLM-5 vs. Kimi k2.5: How do they compare to Codex and Claude for coding?",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r64agl/minimax_m25_vs_glm5_vs_kimi_k25_how_do_they/",
      "author": "East-Stranger8599",
      "created_utc": "2026-02-16 08:33:46",
      "score": 42,
      "num_comments": 29,
      "upvote_ratio": 0.98,
      "text": "Hi everyone,\n\nI‚Äôm looking for community feedback from those of you who have hands-on experience with the recent wave of coding models:\n\n1. **Minimax M2.5**\n2. **GLM-5**\n3. **Kimi k2.5**\n\nThere are plenty of benchmarks out there, but I‚Äôm interested in your subjective opinions and day-to-day experience.\n\n**If you use multiple models:** Have you noticed significant differences in their \"personality\" or logic when switching between them? For example, is one noticeably better at scaffolding while another is better at debugging or refactoring?\n\n**If you‚Äôve mainly settled on one:** How does it stack up against the major incumbents like **Codex** or **Anthropic‚Äôs Claude** models?\n\nI‚Äôm specifically looking to hear if these newer models offer a distinct advantage or feel different to drive, or if they just feel like \"more of the same.\"\n\nThanks for sharing your insights!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r64agl/minimax_m25_vs_glm5_vs_kimi_k25_how_do_they/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o5niuge",
          "author": "fredkzk",
          "text": "I‚Äôve been chat coding for about a year and ended up sorting my ai chat chrome tabs by order of preference (from left to right tab):\n1. GLM\n\n2. Qwen\n\n3. Minimax / deepseek\n\n4. Kimi \n\nOf course, for hard problems, I still use the 3 ‚Äúmasters‚Äù.",
          "score": 9,
          "created_utc": "2026-02-16 08:48:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nuoux",
              "author": "Radmiel",
              "text": "The three masters?",
              "score": 2,
              "created_utc": "2026-02-16 10:40:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nux6k",
                  "author": "fredkzk",
                  "text": "GPT5.2, Opus 4.6, Gemini 3",
                  "score": 10,
                  "created_utc": "2026-02-16 10:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ni28l",
          "author": "Low-Clerk-3419",
          "text": "I did a great personal benchmark where I did exactly this. Minimax m2.5, glm 5, kimi 2.5, opus 4.6, sonnet 4.5, codex 5.3 etc were given exact same detailed task.\n\nCodex came on top, opus next. Glm and kimi afterwards. Minimax failed horribly. Lots of hallucinations here and there. Glm was a bit slow but result was good. Kimi in between.\n\nConclusion wasn't generated by me directly. It was Claude and Codex that decided this result, together, weighted. Which means Claude decided the solution generated by codex were better than the opus.\n\nI suggest you try same thing in multiple models, and decide for yourself. Everyone has their own style and benchmark that won't match others.",
          "score": 13,
          "created_utc": "2026-02-16 08:41:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nogt9",
              "author": "DifferenceTimely8292",
              "text": "What was your PRD or prompt?",
              "score": 3,
              "created_utc": "2026-02-16 09:42:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5o2k2b",
              "author": "Vozer_bros",
              "text": "+1 same view, real task with reasonable context from me for coding task:\nOpenAI top tier (5.2 & 5.3 codex) > Opus 4.6 > GLM 5 > the rest.\n\nGLM can heal it issue pretty good, Opus feel more natual when working, OpenAI bros talking like nerd jerk bug did the job the best IMO.\n\nOther models from Kimi and Minimax are great for oneshot prompt, but they are not going to be my agent member for now cause when the context gettin bigger, they non of my shit is done.",
              "score": 2,
              "created_utc": "2026-02-16 11:49:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nrat5",
          "author": "typhon88",
          "text": "Why don‚Äôt you try them.  Everyone is using them for different things",
          "score": 3,
          "created_utc": "2026-02-16 10:08:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5orxgs",
          "author": "popiazaza",
          "text": "Codex 5.3 > Opus 4.5 > Kimi K2.5 = Sonnet 4.5 = Gemini 3.0 Flash > GLM 5 > Minimax M2.5.\n\nPersonally I would not use GLM or Minimax unless it's free.\n\nKimi is pretty good for the price and could easily replace Sonnet 4.5 for me.\n\nCodex do much better job at try the hardest to solve the problem. Opus has more knowledge and ideas. GLM is mid. Minimax is outright stupid. Not sure why Minimax benchmark score it that high, but it still act just like usual small model.\n\nGemini 3.0 Flash is also pretty good for it's price and could be similar to bigger model in most case.",
          "score": 2,
          "created_utc": "2026-02-16 14:29:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r6u04",
              "author": "FiredAndBuried",
              "text": "Interesting. Can you elaborate on Codex do much better job at try the hardest to solve the problem?",
              "score": 1,
              "created_utc": "2026-02-16 21:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rd0zd",
                  "author": "popiazaza",
                  "text": "Previous version is much more stupid, but 5.3 is pretty good. If it doesn't have enough context it would scan for more (both code and online) until it has enough. Implement and verify the result all by itself. If the result broke it could even revert to original state and ask for more information instead of keep attempting like older one. Opus doesn't need that much scanning, of course.",
                  "score": 1,
                  "created_utc": "2026-02-16 21:54:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5w6wva",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-17 16:59:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w6wx6",
                  "author": "AutoModerator",
                  "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-02-17 16:59:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5o77fo",
          "author": "Michaeli_Starky",
          "text": "They fail fast on larger codebases.",
          "score": 2,
          "created_utc": "2026-02-16 12:24:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r6po3",
              "author": "FiredAndBuried",
              "text": "Claude doesn't",
              "score": -1,
              "created_utc": "2026-02-16 21:23:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5r7bn0",
                  "author": "Michaeli_Starky",
                  "text": "?",
                  "score": 3,
                  "created_utc": "2026-02-16 21:26:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ozr80",
          "author": "Magnus114",
          "text": "I use \n\nStandard: Kimi\n\nSpeedy for simple tasks: Step 3.5 Flash\n\nArchitecture: Opus\n\nI‚Äôm really impressed with Step 3.5. Really fast, cheap, and usually does a great job.",
          "score": 1,
          "created_utc": "2026-02-16 15:10:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w6dwg",
              "author": "[deleted]",
              "text": "[removed]",
              "score": 1,
              "created_utc": "2026-02-17 16:57:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w6e15",
                  "author": "AutoModerator",
                  "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
                  "score": 1,
                  "created_utc": "2026-02-17 16:57:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5w8g42",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-17 17:07:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w8g67",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-17 17:07:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5wcvsw",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-17 17:29:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wcvuw",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-17 17:29:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o657ib9",
          "author": "niado",
          "text": "Codex5.3. The end.",
          "score": 1,
          "created_utc": "2026-02-18 23:03:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nmjr5",
          "author": "ianxiao",
          "text": "\\- Mimimax not smart enough  \n\\- GLM 5 unusable speed  \n\\- Okish",
          "score": 1,
          "created_utc": "2026-02-16 09:24:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qshsl",
          "author": "Tema_Art_7777",
          "text": "5.3 codex rules followed by opus 4.6",
          "score": 0,
          "created_utc": "2026-02-16 20:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sbely",
          "author": "segmond",
          "text": "Why don't you try it and tell us?",
          "score": 0,
          "created_utc": "2026-02-17 01:03:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3kkl0",
      "title": "When did we go from 400k to 256k?",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r3kkl0/when_did_we_go_from_400k_to_256k/",
      "author": "lightsd",
      "created_utc": "2026-02-13 09:14:14",
      "score": 10,
      "num_comments": 20,
      "upvote_ratio": 0.73,
      "text": "I‚Äôm using the new Codex app with GPT-5.3-codex and it‚Äôs constantly having to retrace its steps after compaction.\n\nI recall that earlier versions of the 5.x codex models had a 400k context window and this made such a big deterrence in the quality and speed of the work.\n\nWhat was the last model to have the 400k context window and has anyone backtracked to a prior version of the model to get the larger window?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r3kkl0/when_did_we_go_from_400k_to_256k/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o57l4g0",
          "author": "mike34113",
          "text": "Thats not a downgrade, just how the math works. The 400k context window is the model's total capacity. What you see in the app (256k) is the input limit, with the rest reserved for output.",
          "score": 10,
          "created_utc": "2026-02-13 18:47:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o587351",
              "author": "lightsd",
              "text": "Ah. Interesting that I am seeing much more frequent compacting and what *appears to be* (could be my misconception) more ‚Äúconfusion‚Äù (as evidenced by re-reading docs, etc. and going on tangents) after compaction. With prior models in the codex CLI I perceived better sustained focus and less frequent compacts. Maybe it‚Äôs just circumstantial‚Ä¶",
              "score": 1,
              "created_utc": "2026-02-13 20:36:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5fuzsm",
                  "author": "ChanceShatter",
                  "text": "I have consistently experienced the same since 5.2, using primarily the Pro model in chat.",
                  "score": 1,
                  "created_utc": "2026-02-15 01:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56b01z",
          "author": "YexLord",
          "text": "272+128",
          "score": 8,
          "created_utc": "2026-02-13 15:06:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o576wsw",
          "author": "Pleasant-Today60",
          "text": "The compaction loop is so frustrating. It rewrites the same file three times because it forgot what it already did. I've been breaking tasks into smaller chunks and feeding more explicit instructions upfront to avoid hitting the wall, but it's a workaround not a fix.",
          "score": 4,
          "created_utc": "2026-02-13 17:40:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58vhh7",
          "author": "smurf123_123",
          "text": "Because RAAAAAAMMMM, (ranch).",
          "score": 1,
          "created_utc": "2026-02-13 22:38:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58zr2n",
              "author": "Paraphrand",
              "text": "Isn‚Äôt the author of the source of that meme a creep?",
              "score": 1,
              "created_utc": "2026-02-13 23:02:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cvetn",
                  "author": "smurf123_123",
                  "text": "I did not know that.  Glad you pointed it out. ",
                  "score": 1,
                  "created_utc": "2026-02-14 16:02:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bv3jc",
          "author": "joey2scoops",
          "text": "Maybe persistent memory would be helpful.",
          "score": 1,
          "created_utc": "2026-02-14 12:21:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5njs0x",
              "author": "kennetheops",
              "text": "i‚Äôm working on something here",
              "score": 1,
              "created_utc": "2026-02-16 08:57:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5njsck",
              "author": "kennetheops",
              "text": "i‚Äôm working on something here",
              "score": 1,
              "created_utc": "2026-02-16 08:57:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5o2r7t",
                  "author": "joey2scoops",
                  "text": "It's like deja-vu, all over again.",
                  "score": 1,
                  "created_utc": "2026-02-16 11:50:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5l08w2",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 22:14:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5l08yh",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 22:14:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5y28rl",
          "author": "Hir0shima",
          "text": "Today, it compacted before 256k tokens.¬†",
          "score": 1,
          "created_utc": "2026-02-17 22:16:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yhrse",
              "author": "lightsd",
              "text": "I expect it to need some headroom to do the compaction.",
              "score": 1,
              "created_utc": "2026-02-17 23:39:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o54xk4b",
          "author": "Unlucky_Studio_7878",
          "text": "ü§£ü§£. My god man.. this is Sam's OAI we are talking about.. you know.. old \"bait and Switch\" Altman..  you thought you were going to keep what they gave you?  ü§£ü§£ü§£. Oh, so adorable...   Forget it .  Name a single thing Sam promised that we got?  Nothing..  absolutely nothing..  except, hype and lies..  and this is coming from a 2+ year Plus user..  good luck with your issues.  Maybe you want to send a message to OAI supporta d actually see what they say ..  I would love to bear their response to you..  please follow up.. seriously..",
          "score": -5,
          "created_utc": "2026-02-13 09:28:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o550vmq",
              "author": "Kat-",
              "text": "Fuck Sam Altman",
              "score": 3,
              "created_utc": "2026-02-13 10:00:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5bibv",
      "title": "Self Promotion Thread",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r5bibv/self_promotion_thread/",
      "author": "AutoModerator",
      "created_utc": "2026-02-15 10:35:43",
      "score": 10,
      "num_comments": 20,
      "upvote_ratio": 1.0,
      "text": "Feel free to share your projects! This is a space to promote whatever you may be working on. It's open to most things, but we still have a few rules:\n\n1. No selling access to models\n2. Only promote once per project\n3. Upvote the post and your fellow coders!\n4. No creating Skynet\n\nAs a way of helping out the community, interesting projects may get a pin to the top of the sub :)\n\nFor more information on how you can better promote, see our wiki:\n\n[www.reddit.com/r/ChatGPTCoding/about/wiki/promotion](http://www.reddit.com/r/ChatGPTCoding/about/wiki/promotion)\n\nHappy coding!",
      "is_original_content": false,
      "link_flair_text": "Community",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r5bibv/self_promotion_thread/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o5hljlg",
          "author": "opendadorSRB",
          "text": "Hey so I made an AI Wellness Companion, out of pure need for one for myself, maybe it can help someone [https://sanctumly.space/](https://sanctumly.space/), I currently have one person doing QA work and also one therapist modeling its responses in backend , hope it helps someone \n\nhttps://preview.redd.it/rqiwmdxw0njg1.jpeg?width=971&format=pjpg&auto=webp&s=a629353c48852725759e949d0a4d113208918c4c\n\n",
          "score": 3,
          "created_utc": "2026-02-15 10:45:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ilky7",
          "author": "wouldacouldashoulda",
          "text": "[Context Lens](https://github.com/larsderidder/context-lens), a tool to inspect wat is exactly in your context when using an agent. Supports Codex (which was the hardest too, needs additional dependency), but also claude and gemini.",
          "score": 4,
          "created_utc": "2026-02-15 15:02:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hq8oa",
          "author": "FickleSwordfish8689",
          "text": "I built this mostly because I was getting massive \"text fatigue\" from LLMs. I wanted a research agent that actually shows me the shape of the data instead of just dumping a 10-page report on me.\n\nIt's called Prism AI. It's an open-source agent that generates interactive 2D/3D knowledge graphs while it researches. I used Python (LangGraph) for the brain and Go for the streaming side of things to keep it fast.\n\nIt‚Äôs totally open source and easy to run locally if you‚Äôre into that. Hope it helps someone else who's tired of reading walls of text.\n\n**Repo:**[https://github.com/precious112/prism-ai-deep-research](https://github.com/precious112/prism-ai-deep-research)",
          "score": 3,
          "created_utc": "2026-02-15 11:28:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hyt8q",
          "author": "Neat-Veterinarian-42",
          "text": "Hey,  \nI made [ChatSight](https://chromewebstore.google.com/detail/chatsight-chatgpt-prompt/aamihahiiogceidpbnfgehacgiecephe), a ChatGPT chome extension that adds a neat sidebar to ChatGPT chats which lists all the prompts you‚Äôve asked in a chat. Also it adds the option to bulk delete your chats.  \n\n\nhttps://preview.redd.it/gfptyuvvlnjg1.png?width=1280&format=png&auto=webp&s=918bbf098d6a84e52e8166dfa6e03152671ed9ba\n\n",
          "score": 2,
          "created_utc": "2026-02-15 12:41:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j8fte",
          "author": "Dangerous-Impact-558",
          "text": "I am building a launch directory and discovery website for builders. Check it out here - [https://www.launchdir.com](https://www.launchdir.com)",
          "score": 2,
          "created_utc": "2026-02-15 16:54:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ju879",
          "author": "Constant_Marketing18",
          "text": "Make your website LLM ready and track your AI visibility.\n\n  \n[https://coolwebtool.com/](https://coolwebtool.com/)",
          "score": 2,
          "created_utc": "2026-02-15 18:41:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ifn2z",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 14:29:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ifn5h",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 14:29:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ijrbo",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 14:52:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ijre0",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 14:52:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jc4qd",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 17:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jc4s9",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-15 17:12:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5msilj",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-16 04:58:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5msitg",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-16 04:58:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qqooy",
          "author": "Training_Bet_2747",
          "text": "Build an expense tracker where all you‚Äôve to do is type an expense in telegram chat. \n\nNo need to install new app or type of excel small cells. Just telegram, chats, and your expenses. \n\nEncrypted at state and in transit: https://revexos.com/spend",
          "score": 1,
          "created_utc": "2026-02-16 20:05:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u4ipj",
          "author": "Tytanidze",
          "text": "Hello, I'm building [Pocket Links](https://play.google.com/store/apps/details?id=com.nofutureapps.pocketlinks)¬†a minimalist Android app to save and organize your links for movies/anime, recipes or articles from Medium or any other digital publication.\n\nI use chatGPT to translate into different languages. The app currently supports 35 languages ‚Äã‚Äãwith fairly high-quality translation.",
          "score": 1,
          "created_utc": "2026-02-17 09:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62qfig",
          "author": "earlydayrunnershigh",
          "text": "Made a way to unify all the work being done across different agents and later track/search. It'a simple MCP you can add on to your clients like Claude, Cursor, OpenClaw, etc. and will aggregate all the logged work :)\n\nCustom schema for what you want to record is supported too!\n\nhttps://preview.redd.it/bqi2lugo2akg1.png?width=2898&format=png&auto=webp&s=ed4116b551cafdf5fce16fd82ba8f62f4ddfe59f\n\n[https://github.com/ejcho623/agent-breadcrumbs](https://github.com/ejcho623/agent-breadcrumbs)",
          "score": 1,
          "created_utc": "2026-02-18 16:15:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63fu55",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-18 18:09:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63fu8o",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-18 18:09:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7jdga",
      "title": "Single question llm comparison",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r7jdga/single_question_llm_comparison/",
      "author": "Magnus114",
      "created_utc": "2026-02-17 21:28:39",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I asked this question to open code:\n\n*Is commit 889fb6bc included in any commits that were merged or squashed into main?*\n\nThe answer was yes (was part or a branch that was squashed into main), but to my surprise the answer I got was no. I asked the same question to a bunch of different llm.\n\n**Failed:**  \nGrok 4  \nQwen 3 Coder  \nQwen 3.5  \nDeepseek 3.2  \nStep 3.5 Flash  \nGlm 4.7  \nGlm 5  \nMiniMax 2.5  \nKimi 2.5  \nHaiku 4.5\n\n**Succeded:**  \nGemini 3 Flash Preview  \nSonnet 4.5  \nOpus 4.6",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r7jdga/single_question_llm_comparison/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o656tji",
          "author": "niado",
          "text": "That‚Äôs a tough one because a specific identifier like that will get lost in rag or summarization. So the model will never see it in the data, because it only receives data through rag or summarization. \n\nThe ones who succeeded used some other method to find that specific identifier. They must use a different architecture for data ingestion.",
          "score": 1,
          "created_utc": "2026-02-18 22:59:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r71hcl",
      "title": "Web/Desktop code responses are better than IDE based responses.",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r71hcl/webdesktop_code_responses_are_better_than_ide/",
      "author": "_DB009",
      "created_utc": "2026-02-17 09:25:28",
      "score": 7,
      "num_comments": 17,
      "upvote_ratio": 0.82,
      "text": "Is it just me or are the responses from chat GPT desktop/web better than the ones given by IDE's? im currently running AI tests with vscode and cursor to find a \"Modern\" workflow. I gave the same prompt to various models in vscode, and currently testing on cursor but I got curious and fed the same prompt to the web based  chat and the code it gave me was much better (functional atleast).\n\nI am going to complete the test for the most part but since the LLM's are more or less the same across IDE's i dont know how different the results will be.\n\nLogicially it makes sense I guess because  IDE's are mostly going for speed/productivity so they dont think quite as long as web.   \n  \n I guess the real modern workflow will be using the agent for boiler plate code, changes to an existing system and using the web/desktop flow to create the initial boiler plate for large systems and just over all planning.   \n  \nFor reference im a game dev the prompt was to make a simple spawn a list of objects into rows and columns flat on the ground using their bounding boxes.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r71hcl/webdesktop_code_responses_are_better_than_ide/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o5u7o44",
          "author": "nova-new-chorus",
          "text": "It produces better code when I tell it to debug \"Like a Harvard 4.0 nerd\"",
          "score": 3,
          "created_utc": "2026-02-17 09:32:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vzlrf",
          "author": "SM373",
          "text": "I noticed this with Gemini 3 as well.  The gemini 3 pro model in the web is actually really good vs the one you can use in the agent.  My guess was exactly what you said, it's a web request so the model knows it can think longer",
          "score": 2,
          "created_utc": "2026-02-17 16:22:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zsdtw",
          "author": "AxeSlash",
          "text": "Given that OAI just nerfed reasoning time for 5.2 Thinking, this may not be the case for long.\n\n5.2T has been shite since the update a few days ago. They're clearly in cost-minimisation mode at the moment, output quality be damned.",
          "score": 2,
          "created_utc": "2026-02-18 03:56:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6087ax",
              "author": "_DB009",
              "text": "oh gosh what a bad one, theyve back tracked before due to customer complaints but since this is connected directly to cost they may or may not. ",
              "score": 1,
              "created_utc": "2026-02-18 05:48:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6571jv",
          "author": "niado",
          "text": "Use codex5.3. There‚Äôs no reason to use any other model, codex5.3 is a monster.",
          "score": 2,
          "created_utc": "2026-02-18 23:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w6sfo",
          "author": "Tropiux",
          "text": "It depends on the model. What models are you using?",
          "score": 1,
          "created_utc": "2026-02-17 16:59:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5z1vzf",
              "author": "_DB009",
              "text": "In vs code I used haiku, gpt codex, gpt5 mini. On cursor i have it set to auto and can't choose currently not sure if I'm going to pay for cursor yet as I'm thinking of using Claude code.",
              "score": 1,
              "created_utc": "2026-02-18 01:29:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5zfib6",
                  "author": "Unique-Drawer-7845",
                  "text": "Opus 4.6 in Copilot is worse than Sonnet 4.5 in Claude Code because GitHub gimps context windows and caps reasoning effort. GitHub gets by on brand recognition, being in every IDE, and being affordable. They are not trying to provide the smartest AI, just sufficient AI at a ~competitive price.  \n\nContrast that to OpenAI and Anthropic whose business literally rides or dies on the quality of their model-related offerings.  GitHub can always just ... fall back on being GitHub. Cursor's niche has been 1) beating Copilot in features in the early days (Copilot has since caught up), and 2) having one of the best autocompletes (more recently). Not really leading chat or agentic.\n\nThere are 3 things that matter almost equally:\n\n1) What tool you're using to access the model \n2) What model you're accessing\n3) Who is selling the model to you\n\nIf you want something as smart as ChatGPT 5.2 Web but in your IDE, you have two main choices (IMO): Codex or Claude Code.",
                  "score": 2,
                  "created_utc": "2026-02-18 02:40:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61yq4g",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-18 14:01:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61yq6h",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-18 14:01:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o66ah8m",
          "author": "manummasson",
          "text": "They have different system prompts. Coding agents are told to be more concise and give shorter responses.",
          "score": 1,
          "created_utc": "2026-02-19 02:43:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o66kfyp",
              "author": "_DB009",
              "text": "I get that but the quality of the code suffers. I think planning core architecture concepts is better in the web/desktop based chats then taking detailed notes to the ide might be the best bet.",
              "score": 1,
              "created_utc": "2026-02-19 03:44:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2q3km",
      "title": "Self Promotion Thread",
      "subreddit": "ChatGPTCoding",
      "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1r2q3km/self_promotion_thread/",
      "author": "AutoModerator",
      "created_utc": "2026-02-12 10:35:28",
      "score": 6,
      "num_comments": 31,
      "upvote_ratio": 0.88,
      "text": "Feel free to share your projects! This is a space to promote whatever you may be working on. It's open to most things, but we still have a few rules:\n\n1. No selling access to models\n2. Only promote once per project\n3. Upvote the post and your fellow coders!\n4. No creating Skynet\n\nAs a way of helping out the community, interesting projects may get a pin to the top of the sub :)\n\nFor more information on how you can better promote, see our wiki:\n\n[www.reddit.com/r/ChatGPTCoding/about/wiki/promotion](http://www.reddit.com/r/ChatGPTCoding/about/wiki/promotion)\n\nHappy coding!",
      "is_original_content": false,
      "link_flair_text": "Community",
      "permalink": "https://reddit.com/r/ChatGPTCoding/comments/1r2q3km/self_promotion_thread/",
      "domain": "self.ChatGPTCoding",
      "is_self": true,
      "comments": [
        {
          "id": "o4yzgzf",
          "author": "Migo1",
          "text": "FingerJoint-Cutter is a FreeCAD macro that carves interlocking finger joints between the solids inside a selected Part/App::Part container, then flattens and packs them into labeled layouts per detected material thickness for laser cutting.\n\nAbout 95% vibe-coded.\n\nhttps://github.com/migo1001/FingerJoint-Cutter/",
          "score": 4,
          "created_utc": "2026-02-12 12:41:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z0naj",
              "author": "GrrasssTastesBad",
              "text": "That looks dope!",
              "score": 2,
              "created_utc": "2026-02-12 12:49:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z60nl",
          "author": "merrach",
          "text": "Ok so here's what kept happening to me... I'd get an idea for an app, open Cursor, type something like \"build me a task management app with a clean UI\" and then spend the next 3 hours fighting the AI because it picked some random stack, invented features I didn't ask for, and made everything look like a Bootstrap template from 2019.\n\nThe problem wasn't the coding agent. It was me. I was giving it garbage specs.\n\nSo over the past couple weeks I built this thing I'm calling Vibe Architect. It's basically a structured brainstorming tool where an AI architect proposes stuff and you just say yes/no/change this. You don't have to come up with anything from scratch.\n\nIt goes through phases:\n\nFirst it figures out your MVP scope (what to build, what to cut)\n\nThen it proposes design system options with actual live previews you can see in the browser\n\nThen tech stack\n\nThen it spits out markdown spec files you can feed directly to Cursor/Claude/whatever\n\nThe thing that I think actually makes this useful is that the AI doesn't ask you dumb questions like \"what font do you want?\" it just proposes 3 options and you pick one. Way faster.\n\nAlso you can stop at any step. Like if you just need help figuring out your MVP scope, cool, you don't have to go through the whole thing.\n\nIt's fully client side, your API keys stay in your browser, and it works with OpenAI, Gemini, and Claude.\n\nAnyway it's free and open source:\n\nGitHub: [https://github.com/mohdhd/vibe-architect](https://github.com/mohdhd/vibe-architect)\n\nLive demo: [https://specs-gen.vercel.app](https://specs-gen.vercel.app)\n\nCurious what you guys think. Also open to PRs if anyone wants to contribute.",
          "score": 2,
          "created_utc": "2026-02-12 13:22:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ev6cy",
              "author": "WimbashBagel",
              "text": "How is this any different to pasting your system prompt into any agent's instructions?",
              "score": 1,
              "created_utc": "2026-02-14 22:15:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yqd44",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-12 11:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yqd72",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-12 11:32:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z0j2j",
          "author": "GrrasssTastesBad",
          "text": "I built [getloupe.io](http://getloupe.io) to solve a problem that was driving me crazy. Every time I shipped a change, I had no idea if it actually helped my metrics or just looked better. Loupe watches your site and connects every deploy to what happened with signups, revenue, whatever you care about.\n\nIt's for founders who ship fast and want to know what's working without setting up a bunch of tracking. If you're constantly wondering whether that new landing page actually converted better, this is for you.",
          "score": 1,
          "created_utc": "2026-02-12 12:48:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z4o23",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-12 13:14:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z4o45",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-12 13:14:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52l9i4",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-12 23:27:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52l9k8",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-12 23:27:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52t52x",
          "author": "ShagBuddy",
          "text": "I created a universal MCP server that maps codebases to symbols that represent various aspects of the code. The result is an average 70% savings on input tokens, which allows you to get more use out of your subscriptions. It also improves context and has various tools built into the server for various code operations. It currently supports TypeScript, JavaScript, Python, Go, Java, C#, C, C++, PHP, Rust, Kotlin, and Shell languages.\n\nI have been using it for a couple weeks now and finally got it packaged up for other people to use. It is designed to save, at a minimum, at least 50% tokens for any code operation. Most operations are be reduced by 80+%. A real-world workflow session gets an average of 70% savings on input tokens.\n\nSymbol Delta Ledger MCP¬†[https://github.com/GlitterKill/sdl-mcp](https://github.com/GlitterKill/sdl-mcp)\n\n",
          "score": 1,
          "created_utc": "2026-02-13 00:12:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o566z9m",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-13 14:46:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o566zcq",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-13 14:46:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5670z2",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-13 14:47:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o567110",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-13 14:47:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o59b6x4",
          "author": "debba_",
          "text": "My lightweight open source db tool: tabularis \n\nhttps://github.com/debba/tabularis",
          "score": 1,
          "created_utc": "2026-02-14 00:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ew188",
              "author": "WimbashBagel",
              "text": "Clone of VaultSQL?",
              "score": 1,
              "created_utc": "2026-02-14 22:20:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ew7yb",
                  "author": "debba_",
                  "text": "Never heard about it",
                  "score": 1,
                  "created_utc": "2026-02-14 22:21:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5c4n22",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-14 13:30:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5c4n3w",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-14 13:30:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ny9fu",
          "author": "HalfNo8161",
          "text": "You know that feeling when you're deep into a ChatGPT conversation and you want to ask \"wait, can you explain that part again?\" or \"show me an example\" but you don't want to derail the whole thing?\n\nI kept running into this. My threads would start focused and then turn into spaghetti because I'd ask 5 follow-up questions that weren't really part of the main flow.\n\nSo I added a feature to my extension ([GPT Threads](https://chromewebstore.google.com/detail/fdmnglmekmchcbnpaklgbpndclcekbkg?utm_source=item-share-cb)) where you can ask side questions in a collapsible panel. The response shows up there without cluttering your main chat. The turn still exists in ChatGPT's history (so context is preserved) but it's visually hidden so your main thread stays clean.\n\nIt's honestly changed how I use ChatGPT. I can explore tangents, ask for clarifications, or test variations without turning my chat into chaos.\n\nIf you're someone who has 50+ turn conversations that become unreadable halfway through, this might help.\n\nHappy to answer questions or hear if anyone's solved this differently!\n\n[https://chromewebstore.google.com/detail/fdmnglmekmchcbnpaklgbpndclcekbkg?utm\\_source=item-share-cb](https://chromewebstore.google.com/detail/fdmnglmekmchcbnpaklgbpndclcekbkg?utm_source=item-share-cb)",
          "score": 1,
          "created_utc": "2026-02-16 11:12:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u4fep",
          "author": "Tytanidze",
          "text": "Hello, I'm building [Pocket Links](https://play.google.com/store/apps/details?id=com.nofutureapps.pocketlinks)¬†a minimalist Android app to save and organize your links for movies/anime, recipes or articles from Medium or any other digital publication.\n\nI use chatGPT to translate into different languages. The app currently supports 35 languages ‚Äã‚Äãwith fairly high-quality translation.",
          "score": 1,
          "created_utc": "2026-02-17 09:00:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o646f4h",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-18 20:08:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o646f6w",
              "author": "AutoModerator",
              "text": "Sorry, your submission has been removed due to inadequate account karma.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ChatGPTCoding) if you have any questions or concerns.*",
              "score": 1,
              "created_utc": "2026-02-18 20:08:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}