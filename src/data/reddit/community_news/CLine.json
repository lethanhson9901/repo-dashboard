{
  "metadata": {
    "last_updated": "2026-01-30 08:59:57",
    "time_filter": "week",
    "subreddit": "CLine",
    "total_items": 8,
    "total_comments": 17,
    "file_size_bytes": 21657
  },
  "items": [
    {
      "id": "1qqiaq1",
      "title": "Was Cline just acqui-hired by OpenAI?",
      "subreddit": "CLine",
      "url": "https://blog.kilo.ai/p/cline-just-acqui-hired",
      "author": "Square-Yak-6725",
      "created_utc": "2026-01-29 19:24:30",
      "score": 29,
      "num_comments": 15,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qqiaq1/was_cline_just_acquihired_by_openai/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o2gvqjg",
          "author": "Diligent_Net4349",
          "text": "I sure have seen a lot of ads from Kilo about it. lol",
          "score": 19,
          "created_utc": "2026-01-29 19:41:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h2s2d",
              "author": "Square-Yak-6725",
              "text": "Yeah, they are milking it for all it's worth!",
              "score": 5,
              "created_utc": "2026-01-29 20:15:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2h4mgm",
                  "author": "Shivacious",
                  "text": "U know what milks better ?\n\n![gif](giphy|LSe24LjQdbBOo)\n\n/s not gae",
                  "score": 2,
                  "created_utc": "2026-01-29 20:23:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hoq1o",
          "author": "Mr_Hyper_Focus",
          "text": "I wonder if the Roo team said no.",
          "score": 4,
          "created_utc": "2026-01-29 21:59:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kbvpo",
              "author": "bias_guy412",
              "text": "They may have said ‚ÄúMoo, don‚Äôt milk us‚Äù",
              "score": 1,
              "created_utc": "2026-01-30 07:30:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2h5r36",
          "author": "mosmondor",
          "text": "I have flat rate gpt 5.2 through cline.\n\nFor me, that's a free lunch and then some.",
          "score": 3,
          "created_utc": "2026-01-29 20:29:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hmpr7",
              "author": "cs_cast_away_boi",
              "text": "wait, really? how much are you paying? My requests always range from .05 cents to 80 cents and it‚Äôs completely random using gpt 5.2. I would love to have a steady low rate. can you explain what you have to do üòì",
              "score": 1,
              "created_utc": "2026-01-29 21:50:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hxmbd",
                  "author": "quincycs",
                  "text": "https://cline.bot/blog/introducing-openai-codex-oauth",
                  "score": 2,
                  "created_utc": "2026-01-29 22:43:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2hv3ug",
              "author": "Steve_OH",
              "text": "Please elaborate, how do you have it set up?",
              "score": 1,
              "created_utc": "2026-01-29 22:31:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hxl8o",
                  "author": "quincycs",
                  "text": "https://cline.bot/blog/introducing-openai-codex-oauth",
                  "score": 1,
                  "created_utc": "2026-01-29 22:43:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2h4nq2",
          "author": "Shivacious",
          "text": "I was checking the same",
          "score": 2,
          "created_utc": "2026-01-29 20:24:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hrqbu",
          "author": "who_am_i_to_say_so",
          "text": "Funny, I‚Äôve always used Claude with Cline. \n\nGood for the Cline team, though. What a windfall!",
          "score": 1,
          "created_utc": "2026-01-29 22:14:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iky81",
          "author": "hannesrudolph",
          "text": "Nope",
          "score": 0,
          "created_utc": "2026-01-30 00:48:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpl2fk",
      "title": "Cline 3.55.0: Arcee Trinity Large and Kimi K2.5 now available",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qpl2fk/cline_3550_arcee_trinity_large_and_kimi_k25_now/",
      "author": "juanpflores_",
      "created_utc": "2026-01-28 19:19:11",
      "score": 12,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hey everyone!\n\nCline 3.55 adds two open models worth paying attention to.\n\nArcee Trinity Large is free, US-built, and Apache 2.0 licensed. It's a 400B parameter MoE model (13B active at inference) with 128K context. Benchmarks: MMLU Pro 82, GPQA Diamonds 75. Good for general coding, refactoring, and working with large codebases without worrying about API costs.\n\nhttps://preview.redd.it/jsuctple45gg1.png?width=3200&format=png&auto=webp&s=dc7f6d67ebb8220a272b861d2d72122487111318\n\n\n\nKimi K2.5 is open source and competitive with closed-source options. 1T parameter MoE, 256K context. Scores 76.8% on SWE-bench and beats Opus 4.5 on Humanity's Last Exam (50.2%). Particularly strong for visual coding: drop a screenshot and get working UI code with layout, animations, and interactions. It can also inspect its own output and self-correct.\n\nhttps://preview.redd.it/c40qpg3e45gg1.png?width=1974&format=png&auto=webp&s=22379d0ec8b9a51d7062863ee3eb2518f892ccd4\n\n\n\nAlso a reminder in this release: ChatGPT Plus/Pro subscribers can use GPT-5 models in Cline via OAuth (no API key needed) and¬†**Grok Code Fast 1**¬†and¬†**Devstral**¬†free promotions have ended.\n\nFull details:¬†[https://cline.bot/blog/cline-3-55-0-arcee-trinity-and-kimi-k2-5-now-in-cline](https://cline.bot/blog/cline-3-55-0-arcee-trinity-and-kimi-k2-5-now-in-cline)",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/CLine/comments/1qpl2fk/cline_3550_arcee_trinity_large_and_kimi_k25_now/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkr1do",
      "title": "Less feedback in recent versions",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkr1do/less_feedback_in_recent_versions/",
      "author": "Signal_Response1489",
      "created_utc": "2026-01-23 13:38:40",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "It seems like Cline no longer provides insight into what the model is doing. And it seems to be running much more slowly. I admit that may be just an issue of perception caused by the lack of information on the UI. Cline spend many **minutes(!)** on ‚ÄúThinking‚Ä¶‚Äù or ‚ÄúPlanning‚Ä¶‚Äù with no feedback. \n\nI have really enjoyed using Cline, but I find this to be a big enough problem that I‚Äôm looking for a new tool to replace it with.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkr1do/less_feedback_in_recent_versions/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1ayuuj",
          "author": "saoudriz",
          "text": "Hey thank you for the feedback, we've heard this from other users as well. The team is working on improving the UX and should address a lot of what you mentioned in the next release.",
          "score": 2,
          "created_utc": "2026-01-23 20:34:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qntc6x",
      "title": "How to use Cline Memory Bank in a mono-repo",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "author": "curiousbheja",
      "created_utc": "2026-01-26 21:20:00",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 0.85,
      "text": "I have successfully used Cline‚Äôs memory-bank in a single-project repository, primarily to preserve context across multiple Cline tasks in a large codebase. In practice, when I notice the LLM context window approaching its token limit, I ask Cline to ‚Äúupdate memory bank,‚Äù then start a new task and instruct it to ‚Äúfollow your custom instructions,‚Äù allowing work to resume from where it previously stopped.\n\nHowever, I am unclear on the best way to apply memory-bank in a monorepo setup. Our repository is structured as follows:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n    \n\nMultiple teams will be working on different services concurrently.\n\n**Question 1:**  \nIn this scenario, what is the recommended memory-bank structure?\n\nOption A ‚Äî a centralized memory-bank at the repo root, partitioned by service:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n      - memory-bank\n          - serviceA\n              - projectBrief.md\n              - techContext.md\n          - serviceB\n              - projectBrief.md\n              - techContext.md\n    \n\nOption B ‚Äî a dedicated memory-bank within each service:\n\n    mono-repo\n      - serviceA\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceB\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceZ\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n    \n\n**Question 2:**  \nOnce a task is complete, should all memory-bank markdown files be committed? My understanding is that files such as [`activeContext.md`](http://activeContext.md) and [`progress.md`](http://progress.md) are task-specific and primarily used to track in-flight work, so I do not see a strong reason to commit them after task completion.\n\n**Question 3:**  \nIf we implement multiple features on the same service (e.g., `feature1`, `feature2` on `serviceA`), is the expectation that memory-bank will continuously evolve? Specifically, should files like [`projectBrief.md`](http://projectBrief.md) and [`productContext.md`](http://productContext.md) be incrementally updated after each completed task to reflect the current state of the service?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1y7jsj",
          "author": "RazMake",
          "text": "I am no expert so take my answers with a grain of salt.\n\nI think you probably want to use a memory-bank folder at repository level, with sub-folders for each project. In my experience cline can work with this structure, and saves you from having to update cline config all the time to tell it which memory-bank to use.\n\nMy understanding is similar for the context files you mention, I decided to let cline handle updating context and check them in, but I think you got something there. I don't see the value in having them versions.\n\nYeah, I think the memory-bank is supposed to continue to evolve. Also I think cline updates it from time to time.",
          "score": 1,
          "created_utc": "2026-01-27 03:17:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d49d",
              "author": "curiousbheja",
              "text": "üëç",
              "score": 1,
              "created_utc": "2026-01-27 21:22:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yxgel",
          "author": "quincycs",
          "text": "I think Cline‚Äôs docs recommend OptionB but you have to selectively copy the relevant pieces into the memory bank that‚Äôs appropriate for the conversation.\n\nSo I‚Äôd say, selectively create the relevant pieces of context for the conversation from OptionB into OptionA before invoking the model.",
          "score": 1,
          "created_utc": "2026-01-27 06:07:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d6jj",
              "author": "curiousbheja",
              "text": "üëç",
              "score": 1,
              "created_utc": "2026-01-27 21:23:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkthnz",
      "title": "feature request: Allow for queues, so we can send multiple requests without needing to wait .",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkthnz/feature_request_allow_for_queues_so_we_can_send/",
      "author": "Working-Solution-773",
      "created_utc": "2026-01-23 15:16:10",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.82,
      "text": "Replit has a queue feature. \n\nI can submit a prompt, and then submit another one. When the first one is done, it starts working on the second one. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkthnz/feature_request_allow_for_queues_so_we_can_send/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1di6hp",
          "author": "user29919202",
          "text": "This is a great idea.  So is it like you type in a prompt to begin a task, press enter to let Cline start working on it, and then type a follow-up that you know you'll need after Cline finishes the first prompt?  For example, \"build xyz\" and then \"assess xyz to see what you can improve about it\" and then \"simplify the code\" and then \"code review it\", etc.?  Do you have a better example than this?",
          "score": 2,
          "created_utc": "2026-01-24 04:56:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cmte1",
          "author": "bobthearsonist",
          "text": "So does the client who shall not be named, and open code. Would really love to see this in Claude.",
          "score": 1,
          "created_utc": "2026-01-24 01:43:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkq4ja",
      "title": "Tried Kat Coder Pro and it's surprisingly good for free",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkq4ja/tried_kat_coder_pro_and_its_surprisingly_good_for/",
      "author": "SawOnGam",
      "created_utc": "2026-01-23 12:58:38",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "Just tried out Kat Coder Pro (free model) in Cline while messing around with different models and honestly it's pretty solid for being free.\n\nAnyone else using it? What do you guys mainly use it for and how's it been working out? Also is this thing actually free forever or is it like a limited time deal?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkq4ja/tried_kat_coder_pro_and_its_surprisingly_good_for/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o18ztpp",
          "author": "gunnersmate_sc2",
          "text": "Companies offering coding models need them to have users in order to be able to keep improving the models further. As paying users are piling into Claude code, githhub copilot etc, smaller firms will always have to offer free or very cheap models just to get the users they need to stay in the game and keep up with the competition.",
          "score": 2,
          "created_utc": "2026-01-23 15:09:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1abtw6",
              "author": "SawOnGam",
              "text": "Sounds about all right",
              "score": 1,
              "created_utc": "2026-01-23 18:47:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1hl9a9",
          "author": "lalamax3d",
          "text": "Another Chinese model... Right?",
          "score": 1,
          "created_utc": "2026-01-24 20:12:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o23eoit",
          "author": "productman2217",
          "text": "I'm just checking it out rn and its pretty good., my Claude has hit weekly limit and its able to surf through complex code base and pretty much fix all the issues so far. Not sure if it can create new features I'm excited to try this out till claude is back.",
          "score": 1,
          "created_utc": "2026-01-27 21:29:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o25nau4",
              "author": "SawOnGam",
              "text": "Yeah, felt the same.",
              "score": 1,
              "created_utc": "2026-01-28 04:25:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnsk1a",
      "title": "Multiple Projects?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "author": "majesticjg",
      "created_utc": "2026-01-26 20:52:19",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 0.86,
      "text": "I often have multiple VS Code windows open working on a couple of projects at once. \n\nThat creates a few problems:\n1. The recent activities displayed in Cline shows both projects intermingled. It's hard to look at what you've done recently for just that project.\n\n2. I'd love to set different models for each instance. Sometimes, I'm multitasking a personal project in which I don't want to use an employer's API key.\n\n3. Sometimes there are issues when one window is asking for execution permission, it tends to make the other window unable to ask. \n\nSo, generally, it works, but there are caveats I'm hoping someday to resolve.",
      "is_original_content": false,
      "link_flair_text": "üêû Bug: New",
      "permalink": "https://reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1ynewb",
          "author": "user29919202",
          "text": "This is great feedback.",
          "score": 2,
          "created_utc": "2026-01-27 04:54:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z9cwd",
          "author": "zzzwx",
          "text": "Same experience.\n\nI was hopeful that configuring different VScode profiles would segregate the cline extension config. Sadly there is only one global cline conf which is impacted by whichever vscode instance/profile made a change last.",
          "score": 2,
          "created_utc": "2026-01-27 07:46:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o29dzrt",
          "author": "Aylees",
          "text": "fwiw for point 1 - you can filter your history to show only chats from the current workspace, which helps a bit.\nTotally valid points though",
          "score": 2,
          "created_utc": "2026-01-28 18:25:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlalcx",
      "title": "Provider errors more common -- intentional sabatogeing of tools like cline?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qlalcx/provider_errors_more_common_intentional/",
      "author": "throwawaycanc3r",
      "created_utc": "2026-01-24 02:22:57",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "I am conspiratorially-minded, mind you. But I've just noticed a huge uptick in problems with specific providers right when gemini and anti-gravity are going through some massive changes. If they're using sly methods to corner gemini users into their IDE and onto their subscriptions, i wouldnt be surprised.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qlalcx/provider_errors_more_common_intentional/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": []
    }
  ]
}