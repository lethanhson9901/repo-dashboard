{
  "metadata": {
    "last_updated": "2026-01-28 16:59:58",
    "time_filter": "week",
    "subreddit": "CLine",
    "total_items": 8,
    "total_comments": 25,
    "file_size_bytes": 25952
  },
  "items": [
    {
      "id": "1qj6k23",
      "title": "Cline is so good with Z.AI GLM plan",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qj6k23/cline_is_so_good_with_zai_glm_plan/",
      "author": "Mayanktaker",
      "created_utc": "2026-01-21 18:51:10",
      "score": 51,
      "num_comments": 15,
      "upvote_ratio": 0.96,
      "text": "I tried every single way to make my [Z.Ai](http://Z.Ai) GLM subscription worthy but failed. I tried opencode, claude code, kilo, roo, vs code github copilot with openAi extension, zed, cline everything to make it working and worthy.  \nEveryone failed but only Cline is the champion. Second is Copilot.  \nCopilot is good for debugging, small tasks, planning etc. but not for full stack development with GLM 4.7.  \nZed is also good, but stuck on long tasks. And eats your quota fast.  \nBut with Cline, I can create complete full stacks apps in Laravel, Vue etc. No problem at all.  \nWasted so much tiem with many IDEs and CLIs.  \nITs so compatible. So good. It makes my subscription worth and I now subscibed to yearly plan for [Z.Ai](http://Z.Ai)\n\nGLM itself is so good, its like Claude Sonnet 4.5 but with no image support. I wish [Z.Ai](http://Z.Ai) release GLM 4.7v and I wish Cline add GLM 4.7 Flash support.  <3\n\n  \nThanks Cline team for making such a good software. Its so underrated.  \nAnyone looking for perfect way to use GLM, try Cline. You will thank me.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qj6k23/cline_is_so_good_with_zai_glm_plan/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o0x1xph",
          "author": "saoudriz",
          "text": "thank you so much for posting this, we shared it in our #cline-wins slack channel haha! there's a ton of credit due to the zai team as well, they've told us they even train their model to work super well with cline and its prompts so the good experience is a testament to their efforts too.",
          "score": 11,
          "created_utc": "2026-01-21 20:09:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xnpxc",
              "author": "Mayanktaker",
              "text": "It is so nice to know that the model providers are also contributing with Cline. I am glad I found the perfect combination. And I want to tell you that I found zero bugs in Cline so far. Kudos to the team. Looking forward to try other models also via cline credits. ðŸ¥°",
              "score": 2,
              "created_utc": "2026-01-21 21:48:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0xo5rm",
          "author": "mosmondor",
          "text": "This looks like a total scam...  What do you think?",
          "score": 5,
          "created_utc": "2026-01-21 21:50:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0x6aon",
          "author": "evia89",
          "text": "I prefer CC for z.ai since that endpoint is faster. I measured it for RP (open ai and athropic) but coding is same shit\n\nAnd I can start CC with opus do design + plan (super powers skill), then load it in second CLI with GLM",
          "score": 2,
          "created_utc": "2026-01-21 20:29:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0xmnxj",
              "author": "Mayanktaker",
              "text": "For me, the planning works so well with GLM also. I chat and interact more with cline plan and act more. I feel so connected and involved with Cline. Not with CC.",
              "score": 1,
              "created_utc": "2026-01-21 21:44:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0xsvbs",
          "author": "iongion",
          "text": "I am using [z.ai](http://z.ai) to automate a lot of things in my well established project, not developed by ai.  \nI use cc and an extension for vscode called claude unbound, I never opened cc cli / terminal except for login.  \nI use cc a lot with LM Studio and it was a pain but with recent proxies/routers, it is really nice.\n\nI don't know why [z.ai](http://z.ai) gets so much gripe, they are doing excellent work.  \nI have a full-stack project, whatever I develop, I develop only based on schemas and templates / it is more DSL like expressing than actual lucrative components chains for frontend. Much like my style CRUD and my style whatever forks away from CRUD, but I was building such systems for ages, I know every pain in them.\n\nIt is easy to use a set of predefined recipes to explain these 4:  \nwhat to do, where too look, how to do and pitfalls - small context for each, concrete example based.\n\nBecause sometimes glm just writes bad code(good logic, but just syntax error/broken/missing), I have all sorts of linters and formatters hooks to run when relevant, plus big rule enforced expression in the codebase.\n\n[z.ai](http://z.ai) / glm keep going, you are doing beyond amazing work, this will sprout very soon outside of programming, this logical flow oriented systems are to be used for anything planned in life!",
          "score": 2,
          "created_utc": "2026-01-21 22:13:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0y8pa5",
          "author": "NewVehicle1108",
          "text": "Yea, I actually use Cline and CC with GLM plan, and all works perfectly at the moment",
          "score": 1,
          "created_utc": "2026-01-21 23:34:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yo9bl",
          "author": "majesticjg",
          "text": "I seem to run GLM out of context a lot. I end up going back to Claude Sonnet for it's big context.",
          "score": 1,
          "created_utc": "2026-01-22 00:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z6ko5",
          "author": "kritoke",
          "text": "Have they fixed the excessive crash issue?  I had moved on to roo and now kilo code.  Kilo is kind of winning for me since it has code indexing and some other niceties.  Though it feels like every week or two Iâ€™m trying something new",
          "score": 1,
          "created_utc": "2026-01-22 02:41:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10hjg7",
          "author": "lucasbennett_1",
          "text": "I often run out of contexts for GLM or some other models as i have tried, here claude sonnet 4.5 works good for me with the large context window",
          "score": 1,
          "created_utc": "2026-01-22 08:22:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10x5ld",
              "author": "evia89",
              "text": "GLM requires special handling. Better keep it at <40% context. I am not sure how to do it cline/roo/kilo\n\nFor example OPUS generates me detailed 2000 lines plan with 20+ steps and /clear when implementing after each batch (3-5 tasks). Most of the times context stays below 25%",
              "score": 1,
              "created_utc": "2026-01-22 10:47:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o10sr5s",
          "author": "WSATX",
          "text": "Happy to see you've found the right tool for you.\n\nStill I'd suggest maybe you dig deeper into the prompt / tooling aspect of your judgement. I have been using all the tools you quoted and (apart from the fact that GHCP has a default vscode integration) I do think that that they can all achieve 99% the same. This is just a question of how you configure sys/user prompt, agents files and how you prompt it and if they have access to the same tool.\n\nTL;DR: good news, if next time Cline doesn't seems to fit, dig the prompts & tools.",
          "score": 1,
          "created_utc": "2026-01-22 10:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19cudx",
          "author": "CharmingAioli3228",
          "text": "What setting? I actually got convinced with all the posts to go for the zai subscription, and I am stuck constantly pasting the corrections from gemini3 pro chat. Skill issue I am sure, but makes me wonder what settings do people use it with it to get it to work well.\n[Edit] so far with temp of 1, it burns through tokens like crazy, reaches 200k very fast, just to compress it, but it also makes small syntax errors like crazy, which it is not able to resolve on its own. So farn gemini3in chat, but then in cline, devstral2, works away better",
          "score": 1,
          "created_utc": "2026-01-23 16:08:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1apdrb",
          "author": "AIxBitcoin",
          "text": "Bullshit. The IDE doesnâ€™t help as much as you claim. The LLM is what matters most.",
          "score": 1,
          "created_utc": "2026-01-23 19:49:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk4cyr",
      "title": "Sign in with your OpenAI account on Cline",
      "subreddit": "CLine",
      "url": "https://v.redd.it/57ix2h0rdyeg1",
      "author": "juanpflores_",
      "created_utc": "2026-01-22 19:35:50",
      "score": 14,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/CLine/comments/1qk4cyr/sign_in_with_your_openai_account_on_cline/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o13znb0",
          "author": "Wgrins",
          "text": "Does this work with the go subscription as well?",
          "score": 1,
          "created_utc": "2026-01-22 20:17:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o174txf",
          "author": "mosmondor",
          "text": "Flat rate? What is the fair use cutoff?",
          "score": 1,
          "created_utc": "2026-01-23 07:04:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o176zyx",
          "author": "quincycs",
          "text": "Beautiful work.  Works on my ChatGPT business subscription. \n\nNow Iâ€™ve got,\n\nClaude Pro ( flat rate ) \n\nChatGPT Business ( flat rate )\n\nand the Cline provider",
          "score": 1,
          "created_utc": "2026-01-23 07:23:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18k7nf",
          "author": "BamaGuy61",
          "text": "Very nice! However, whatâ€™s the benefit of using Cline in VScode vs. Codex extension? Cline was my daily driver before Claude Code came along and itâ€™s a huge deal being able to use the OpenAI subscription over openRouter pay as you go token usage.  I currently run CC in a WSL terminal and codex via the extension beside it.  I use codex for code reviews that keep CC honest and on track.",
          "score": 1,
          "created_utc": "2026-01-23 13:49:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qntc6x",
      "title": "How to use Cline Memory Bank in a mono-repo",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "author": "curiousbheja",
      "created_utc": "2026-01-26 21:20:00",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 0.93,
      "text": "I have successfully used Clineâ€™s memory-bank in a single-project repository, primarily to preserve context across multiple Cline tasks in a large codebase. In practice, when I notice the LLM context window approaching its token limit, I ask Cline to â€œupdate memory bank,â€ then start a new task and instruct it to â€œfollow your custom instructions,â€ allowing work to resume from where it previously stopped.\n\nHowever, I am unclear on the best way to apply memory-bank in a monorepo setup. Our repository is structured as follows:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n    \n\nMultiple teams will be working on different services concurrently.\n\n**Question 1:**  \nIn this scenario, what is the recommended memory-bank structure?\n\nOption A â€” a centralized memory-bank at the repo root, partitioned by service:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n      - memory-bank\n          - serviceA\n              - projectBrief.md\n              - techContext.md\n          - serviceB\n              - projectBrief.md\n              - techContext.md\n    \n\nOption B â€” a dedicated memory-bank within each service:\n\n    mono-repo\n      - serviceA\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceB\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceZ\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n    \n\n**Question 2:**  \nOnce a task is complete, should all memory-bank markdown files be committed? My understanding is that files such as [`activeContext.md`](http://activeContext.md) and [`progress.md`](http://progress.md) are task-specific and primarily used to track in-flight work, so I do not see a strong reason to commit them after task completion.\n\n**Question 3:**  \nIf we implement multiple features on the same service (e.g., `feature1`, `feature2` on `serviceA`), is the expectation that memory-bank will continuously evolve? Specifically, should files like [`projectBrief.md`](http://projectBrief.md) and [`productContext.md`](http://productContext.md) be incrementally updated after each completed task to reflect the current state of the service?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1y7jsj",
          "author": "RazMake",
          "text": "I am no expert so take my answers with a grain of salt.\n\nI think you probably want to use a memory-bank folder at repository level, with sub-folders for each project. In my experience cline can work with this structure, and saves you from having to update cline config all the time to tell it which memory-bank to use.\n\nMy understanding is similar for the context files you mention, I decided to let cline handle updating context and check them in, but I think you got something there. I don't see the value in having them versions.\n\nYeah, I think the memory-bank is supposed to continue to evolve. Also I think cline updates it from time to time.",
          "score": 1,
          "created_utc": "2026-01-27 03:17:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d49d",
              "author": "curiousbheja",
              "text": "ðŸ‘",
              "score": 1,
              "created_utc": "2026-01-27 21:22:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yxgel",
          "author": "quincycs",
          "text": "I think Clineâ€™s docs recommend OptionB but you have to selectively copy the relevant pieces into the memory bank thatâ€™s appropriate for the conversation.\n\nSo Iâ€™d say, selectively create the relevant pieces of context for the conversation from OptionB into OptionA before invoking the model.",
          "score": 1,
          "created_utc": "2026-01-27 06:07:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d6jj",
              "author": "curiousbheja",
              "text": "ðŸ‘",
              "score": 1,
              "created_utc": "2026-01-27 21:23:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qkr1do",
      "title": "Less feedback in recent versions",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkr1do/less_feedback_in_recent_versions/",
      "author": "Signal_Response1489",
      "created_utc": "2026-01-23 13:38:40",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "It seems like Cline no longer provides insight into what the model is doing. And it seems to be running much more slowly. I admit that may be just an issue of perception caused by the lack of information on the UI. Cline spend many **minutes(!)** on â€œThinkingâ€¦â€ or â€œPlanningâ€¦â€ with no feedback. \n\nI have really enjoyed using Cline, but I find this to be a big enough problem that Iâ€™m looking for a new tool to replace it with.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkr1do/less_feedback_in_recent_versions/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1ayuuj",
          "author": "saoudriz",
          "text": "Hey thank you for the feedback, we've heard this from other users as well. The team is working on improving the UX and should address a lot of what you mentioned in the next release.",
          "score": 2,
          "created_utc": "2026-01-23 20:34:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkthnz",
      "title": "feature request: Allow for queues, so we can send multiple requests without needing to wait .",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkthnz/feature_request_allow_for_queues_so_we_can_send/",
      "author": "Working-Solution-773",
      "created_utc": "2026-01-23 15:16:10",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.82,
      "text": "Replit has a queue feature. \n\nI can submit a prompt, and then submit another one. When the first one is done, it starts working on the second one. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkthnz/feature_request_allow_for_queues_so_we_can_send/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1di6hp",
          "author": "user29919202",
          "text": "This is a great idea.  So is it like you type in a prompt to begin a task, press enter to let Cline start working on it, and then type a follow-up that you know you'll need after Cline finishes the first prompt?  For example, \"build xyz\" and then \"assess xyz to see what you can improve about it\" and then \"simplify the code\" and then \"code review it\", etc.?  Do you have a better example than this?",
          "score": 2,
          "created_utc": "2026-01-24 04:56:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cmte1",
          "author": "bobthearsonist",
          "text": "So does the client who shall not be named, and open code. Would really love to see this in Claude.",
          "score": 1,
          "created_utc": "2026-01-24 01:43:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkq4ja",
      "title": "Tried Kat Coder Pro and it's surprisingly good for free",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qkq4ja/tried_kat_coder_pro_and_its_surprisingly_good_for/",
      "author": "SawOnGam",
      "created_utc": "2026-01-23 12:58:38",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "Just tried out Kat Coder Pro (free model) in Cline while messing around with different models and honestly it's pretty solid for being free.\n\nAnyone else using it? What do you guys mainly use it for and how's it been working out? Also is this thing actually free forever or is it like a limited time deal?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qkq4ja/tried_kat_coder_pro_and_its_surprisingly_good_for/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o18ztpp",
          "author": "gunnersmate_sc2",
          "text": "Companies offering coding models need them to have users in order to be able to keep improving the models further. As paying users are piling into Claude code, githhub copilot etc, smaller firms will always have to offer free or very cheap models just to get the users they need to stay in the game and keep up with the competition.",
          "score": 2,
          "created_utc": "2026-01-23 15:09:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1abtw6",
              "author": "SawOnGam",
              "text": "Sounds about all right",
              "score": 1,
              "created_utc": "2026-01-23 18:47:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1hl9a9",
          "author": "lalamax3d",
          "text": "Another Chinese model... Right?",
          "score": 1,
          "created_utc": "2026-01-24 20:12:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o23eoit",
          "author": "productman2217",
          "text": "I'm just checking it out rn and its pretty good., my Claude has hit weekly limit and its able to surf through complex code base and pretty much fix all the issues so far. Not sure if it can create new features I'm excited to try this out till claude is back.",
          "score": 1,
          "created_utc": "2026-01-27 21:29:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o25nau4",
              "author": "SawOnGam",
              "text": "Yeah, felt the same.",
              "score": 1,
              "created_utc": "2026-01-28 04:25:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qlalcx",
      "title": "Provider errors more common -- intentional sabatogeing of tools like cline?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qlalcx/provider_errors_more_common_intentional/",
      "author": "throwawaycanc3r",
      "created_utc": "2026-01-24 02:22:57",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 0.81,
      "text": "I am conspiratorially-minded, mind you. But I've just noticed a huge uptick in problems with specific providers right when gemini and anti-gravity are going through some massive changes. If they're using sly methods to corner gemini users into their IDE and onto their subscriptions, i wouldnt be surprised.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qlalcx/provider_errors_more_common_intentional/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qnsk1a",
      "title": "Multiple Projects?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "author": "majesticjg",
      "created_utc": "2026-01-26 20:52:19",
      "score": 2,
      "num_comments": 2,
      "upvote_ratio": 0.63,
      "text": "I often have multiple VS Code windows open working on a couple of projects at once. \n\nThat creates a few problems:\n1. The recent activities displayed in Cline shows both projects intermingled. It's hard to look at what you've done recently for just that project.\n\n2. I'd love to set different models for each instance. Sometimes, I'm multitasking a personal project in which I don't want to use an employer's API key.\n\n3. Sometimes there are issues when one window is asking for execution permission, it tends to make the other window unable to ask. \n\nSo, generally, it works, but there are caveats I'm hoping someday to resolve.",
      "is_original_content": false,
      "link_flair_text": "ðŸž Bug: New",
      "permalink": "https://reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1ynewb",
          "author": "user29919202",
          "text": "This is great feedback.",
          "score": 1,
          "created_utc": "2026-01-27 04:54:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z9cwd",
          "author": "zzzwx",
          "text": "Same experience.\n\nI was hopeful that configuring different VScode profiles would segregate the cline extension config. Sadly there is only one global cline conf which is impacted by whichever vscode instance/profile made a change last.",
          "score": 1,
          "created_utc": "2026-01-27 07:46:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}