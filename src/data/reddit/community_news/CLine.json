{
  "metadata": {
    "last_updated": "2026-02-01 16:49:57",
    "time_filter": "week",
    "subreddit": "CLine",
    "total_items": 5,
    "total_comments": 13,
    "file_size_bytes": 16958
  },
  "items": [
    {
      "id": "1qqiaq1",
      "title": "Was Cline just acqui-hired by OpenAI?",
      "subreddit": "CLine",
      "url": "https://blog.kilo.ai/p/cline-just-acqui-hired",
      "author": "Square-Yak-6725",
      "created_utc": "2026-01-29 19:24:30",
      "score": 39,
      "num_comments": 18,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qqiaq1/was_cline_just_acquihired_by_openai/",
      "domain": "blog.kilo.ai",
      "is_self": false,
      "comments": [
        {
          "id": "o2gvqjg",
          "author": "Diligent_Net4349",
          "text": "I sure have seen a lot of ads from Kilo about it. lol",
          "score": 20,
          "created_utc": "2026-01-29 19:41:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h2s2d",
              "author": "Square-Yak-6725",
              "text": "Yeah, they are milking it for all it's worth!",
              "score": 7,
              "created_utc": "2026-01-29 20:15:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2h4mgm",
                  "author": "Shivacious",
                  "text": "U know what milks better ?\n\n![gif](giphy|LSe24LjQdbBOo)\n\n/s not gae",
                  "score": 2,
                  "created_utc": "2026-01-29 20:23:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hoq1o",
          "author": "Mr_Hyper_Focus",
          "text": "I wonder if the Roo team said no.",
          "score": 5,
          "created_utc": "2026-01-29 21:59:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kbvpo",
              "author": "bias_guy412",
              "text": "They may have said ‚ÄúMoo, don‚Äôt milk us‚Äù",
              "score": 2,
              "created_utc": "2026-01-30 07:30:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2h4nq2",
          "author": "Shivacious",
          "text": "I was checking the same",
          "score": 2,
          "created_utc": "2026-01-29 20:24:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2h5r36",
          "author": "mosmondor",
          "text": "I have flat rate gpt 5.2 through cline.\n\nFor me, that's a free lunch and then some.",
          "score": 2,
          "created_utc": "2026-01-29 20:29:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2hmpr7",
              "author": "cs_cast_away_boi",
              "text": "wait, really? how much are you paying? My requests always range from .05 cents to 80 cents and it‚Äôs completely random using gpt 5.2. I would love to have a steady low rate. can you explain what you have to do üòì",
              "score": 1,
              "created_utc": "2026-01-29 21:50:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hxmbd",
                  "author": "quincycs",
                  "text": "https://cline.bot/blog/introducing-openai-codex-oauth",
                  "score": 2,
                  "created_utc": "2026-01-29 22:43:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2lnv5y",
                  "author": "mosmondor",
                  "text": "Flat rate.",
                  "score": 1,
                  "created_utc": "2026-01-30 13:44:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2hv3ug",
              "author": "Steve_OH",
              "text": "Please elaborate, how do you have it set up?",
              "score": 1,
              "created_utc": "2026-01-29 22:31:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2hxl8o",
                  "author": "quincycs",
                  "text": "https://cline.bot/blog/introducing-openai-codex-oauth",
                  "score": 2,
                  "created_utc": "2026-01-29 22:43:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2hrqbu",
          "author": "who_am_i_to_say_so",
          "text": "Funny, I‚Äôve always used Claude with Cline. \n\nGood for the Cline team, though. What a windfall!",
          "score": 1,
          "created_utc": "2026-01-29 22:14:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kugrt",
          "author": "FormerKarmaKing",
          "text": "Kilo‚Äôs ads on this seem heavy handed but the blog is worth a read. TL;DR they want the Cline contributors.\n\nBut I don‚Äôt see how Kilo is going to survive in the long run either. Both companies picked one of the worst markets possible in that they‚Äôre competing Open AI, Anthrophic, Google, Microsoft and Amazon all at once for developer mindshare and spend.",
          "score": 1,
          "created_utc": "2026-01-30 10:17:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iky81",
          "author": "hannesrudolph",
          "text": "Nope",
          "score": 0,
          "created_utc": "2026-01-30 00:48:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2oyse5",
              "author": "AdIllustrious436",
              "text": "Any insight ? I've seen at least 3 major Cline contributor announcing their on-boarding in OpenAI Codex team.",
              "score": 1,
              "created_utc": "2026-01-30 22:58:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpl2fk",
      "title": "Cline 3.55.0: Arcee Trinity Large and Kimi K2.5 now available",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qpl2fk/cline_3550_arcee_trinity_large_and_kimi_k25_now/",
      "author": "juanpflores_",
      "created_utc": "2026-01-28 19:19:11",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 0.94,
      "text": "Hey everyone!\n\nCline 3.55 adds two open models worth paying attention to.\n\nArcee Trinity Large is free, US-built, and Apache 2.0 licensed. It's a 400B parameter MoE model (13B active at inference) with 128K context. Benchmarks: MMLU Pro 82, GPQA Diamonds 75. Good for general coding, refactoring, and working with large codebases without worrying about API costs.\n\nhttps://preview.redd.it/jsuctple45gg1.png?width=3200&format=png&auto=webp&s=dc7f6d67ebb8220a272b861d2d72122487111318\n\n\n\nKimi K2.5 is open source and competitive with closed-source options. 1T parameter MoE, 256K context. Scores 76.8% on SWE-bench and beats Opus 4.5 on Humanity's Last Exam (50.2%). Particularly strong for visual coding: drop a screenshot and get working UI code with layout, animations, and interactions. It can also inspect its own output and self-correct.\n\nhttps://preview.redd.it/c40qpg3e45gg1.png?width=1974&format=png&auto=webp&s=22379d0ec8b9a51d7062863ee3eb2518f892ccd4\n\n\n\nAlso a reminder in this release: ChatGPT Plus/Pro subscribers can use GPT-5 models in Cline via OAuth (no API key needed) and¬†**Grok Code Fast 1**¬†and¬†**Devstral**¬†free promotions have ended.\n\nFull details:¬†[https://cline.bot/blog/cline-3-55-0-arcee-trinity-and-kimi-k2-5-now-in-cline](https://cline.bot/blog/cline-3-55-0-arcee-trinity-and-kimi-k2-5-now-in-cline)",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/CLine/comments/1qpl2fk/cline_3550_arcee_trinity_large_and_kimi_k25_now/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qntc6x",
      "title": "How to use Cline Memory Bank in a mono-repo",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "author": "curiousbheja",
      "created_utc": "2026-01-26 21:20:00",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I have successfully used Cline‚Äôs memory-bank in a single-project repository, primarily to preserve context across multiple Cline tasks in a large codebase. In practice, when I notice the LLM context window approaching its token limit, I ask Cline to ‚Äúupdate memory bank,‚Äù then start a new task and instruct it to ‚Äúfollow your custom instructions,‚Äù allowing work to resume from where it previously stopped.\n\nHowever, I am unclear on the best way to apply memory-bank in a monorepo setup. Our repository is structured as follows:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n    \n\nMultiple teams will be working on different services concurrently.\n\n**Question 1:**  \nIn this scenario, what is the recommended memory-bank structure?\n\nOption A ‚Äî a centralized memory-bank at the repo root, partitioned by service:\n\n    mono-repo\n      - serviceA\n      - serviceB\n      - serviceZ\n      - memory-bank\n          - serviceA\n              - projectBrief.md\n              - techContext.md\n          - serviceB\n              - projectBrief.md\n              - techContext.md\n    \n\nOption B ‚Äî a dedicated memory-bank within each service:\n\n    mono-repo\n      - serviceA\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceB\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n      - serviceZ\n          - memory-bank\n              - projectBrief.md\n              - techContext.md\n    \n\n**Question 2:**  \nOnce a task is complete, should all memory-bank markdown files be committed? My understanding is that files such as [`activeContext.md`](http://activeContext.md) and [`progress.md`](http://progress.md) are task-specific and primarily used to track in-flight work, so I do not see a strong reason to commit them after task completion.\n\n**Question 3:**  \nIf we implement multiple features on the same service (e.g., `feature1`, `feature2` on `serviceA`), is the expectation that memory-bank will continuously evolve? Specifically, should files like [`projectBrief.md`](http://projectBrief.md) and [`productContext.md`](http://productContext.md) be incrementally updated after each completed task to reflect the current state of the service?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qntc6x/how_to_use_cline_memory_bank_in_a_monorepo/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1y7jsj",
          "author": "RazMake",
          "text": "I am no expert so take my answers with a grain of salt.\n\nI think you probably want to use a memory-bank folder at repository level, with sub-folders for each project. In my experience cline can work with this structure, and saves you from having to update cline config all the time to tell it which memory-bank to use.\n\nMy understanding is similar for the context files you mention, I decided to let cline handle updating context and check them in, but I think you got something there. I don't see the value in having them versions.\n\nYeah, I think the memory-bank is supposed to continue to evolve. Also I think cline updates it from time to time.",
          "score": 1,
          "created_utc": "2026-01-27 03:17:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d49d",
              "author": "curiousbheja",
              "text": "üëç",
              "score": 1,
              "created_utc": "2026-01-27 21:22:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1yxgel",
          "author": "quincycs",
          "text": "I think Cline‚Äôs docs recommend OptionB but you have to selectively copy the relevant pieces into the memory bank that‚Äôs appropriate for the conversation.\n\nSo I‚Äôd say, selectively create the relevant pieces of context for the conversation from OptionB into OptionA before invoking the model.",
          "score": 1,
          "created_utc": "2026-01-27 06:07:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o23d6jj",
              "author": "curiousbheja",
              "text": "üëç",
              "score": 1,
              "created_utc": "2026-01-27 21:23:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qnsk1a",
      "title": "Multiple Projects?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "author": "majesticjg",
      "created_utc": "2026-01-26 20:52:19",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 0.78,
      "text": "I often have multiple VS Code windows open working on a couple of projects at once. \n\nThat creates a few problems:\n1. The recent activities displayed in Cline shows both projects intermingled. It's hard to look at what you've done recently for just that project.\n\n2. I'd love to set different models for each instance. Sometimes, I'm multitasking a personal project in which I don't want to use an employer's API key.\n\n3. Sometimes there are issues when one window is asking for execution permission, it tends to make the other window unable to ask. \n\nSo, generally, it works, but there are caveats I'm hoping someday to resolve.",
      "is_original_content": false,
      "link_flair_text": "üêû Bug: New",
      "permalink": "https://reddit.com/r/CLine/comments/1qnsk1a/multiple_projects/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o1ynewb",
          "author": "user29919202",
          "text": "This is great feedback.",
          "score": 2,
          "created_utc": "2026-01-27 04:54:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1z9cwd",
          "author": "zzzwx",
          "text": "Same experience.\n\nI was hopeful that configuring different VScode profiles would segregate the cline extension config. Sadly there is only one global cline conf which is impacted by whichever vscode instance/profile made a change last.",
          "score": 2,
          "created_utc": "2026-01-27 07:46:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o29dzrt",
          "author": "Aylees",
          "text": "fwiw for point 1 - you can filter your history to show only chats from the current workspace, which helps a bit.\nTotally valid points though",
          "score": 2,
          "created_utc": "2026-01-28 18:25:12",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr08s6",
      "title": "[Moonshot AI subscription X Cline not working]",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qr08s6/moonshot_ai_subscription_x_cline_not_working/",
      "author": "ChickenShieeeeeet",
      "created_utc": "2026-01-30 08:51:27",
      "score": 3,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hi there,\n\nSomehow I can't be able to use Moonshot AI coding subscription with Cline? It looks like the right API is not (yet) supported. On other tools such as KiloCode, there is a dedicated API connection for moonshot coding.\n\nAny suggestions here?",
      "is_original_content": false,
      "link_flair_text": "‚ùì Question: New",
      "permalink": "https://reddit.com/r/CLine/comments/1qr08s6/moonshot_ai_subscription_x_cline_not_working/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o2qqfsk",
          "author": "Foreign-Specific-604",
          "text": "your can use base url on openai compatibleÔºåif you buy their api",
          "score": 1,
          "created_utc": "2026-01-31 05:22:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}