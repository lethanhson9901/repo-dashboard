{
  "metadata": {
    "last_updated": "2026-02-09 09:19:59",
    "time_filter": "week",
    "subreddit": "CLine",
    "total_items": 9,
    "total_comments": 48,
    "file_size_bytes": 53047
  },
  "items": [
    {
      "id": "1quzieq",
      "title": "Introducing Cline CLI 2.0 with free Kimi K2.5 for a limited time!",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1quzieq/introducing_cline_cli_20_with_free_kimi_k25_for_a/",
      "author": "juanpflores_",
      "created_utc": "2026-02-03 18:13:13",
      "score": 35,
      "num_comments": 24,
      "upvote_ratio": 0.91,
      "text": "**TL;DR:** Redesigned terminal UI, better support for running parallel agents, ACP integration for Zed/Neovim/Emacs, and free Kimi K2.5 access (and more to come‚Ä¶).\n\nHey r/Cline üëã.\n\nThe team has been working hard on Cline CLI over the past few weeks and we're happy to share some updates that should make the whole experience feel a lot more usable.\n\nHere‚Äôs what‚Äôs changing:\n\n# Next notch interactive experience within terminal¬†\n\nWe rebuilt the CLI from the ground up to make it look and feel like the Cline you're used to in VS Code, making it easier to transition from the IDE to the terminal. Plan/Act modes, easy Auto-approve toggle, and powerful slash commands.\n\nhttps://reddit.com/link/1quzieq/video/qqrycnawlbhg1/player\n\n# Improved parallel agents\n\nYou can spin up separate Cline instances across tmux panes or terminal tabs. One agent refactoring your DB layer while another updates docs on a different branch, all seamlessly happening with Cline CLIs.¬†\n\nhttps://reddit.com/link/1quzieq/video/tqrmcwptlbhg1/player\n\n# ACP support: use Cline in Zed, Neovim, and more\n\nCline now works with ACP-compatible editors through the[ cline-acp adapter](https://github.com/Tonksthebear/cline-acp). That means you can run Cline directly inside Zed, Neovim (via CodeCompanion or avante.nvim), Emacs, and any other editor that uses ACP.\n\nhttps://reddit.com/link/1quzieq/video/j76zqrhulbhg1/player\n\n# Automate with headless pipelines\n\nCline CLI is fully scriptable. Use the -y flag to skip all permissions in autonomous CI/CD pipelines, pipe logs as stdin directly into the CLI, and use the --json flag to parse output easily.\n\nAutomate what makes sense. Stay in control of the rest.\n\n# Free Kimi K2.5 access (for a limited time!)\n\nWe added support for[ Kimi K2.5](https://www.kimi.com/blog/kimi-k2-5.html), Moonshot's open-source model. It's strong on agentic tasks and significantly cheaper than the big closed models, though Opus still edges it out on some pure coding benchmarks. The free access is temporary, so make the most of it while you can.\n\nMore on our launch here: [**https://cline.bot/blog/announcing-cline-cli-2-0**](https://cline.bot/blog/announcing-cline-cli-2-0)\n\nFor a limited time, we‚Äôre also making it possible for you to experiment for free with Kimi K2.5 one of the best open-source models available, Kimi K2.5.\n\nYour feedback is what lets us continue to deliver a great product for the open-source community. We‚Äôd love to hear from you.",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/CLine/comments/1quzieq/introducing_cline_cli_20_with_free_kimi_k25_for_a/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3fctin",
          "author": "-Django",
          "text": "I love the animation haha",
          "score": 3,
          "created_utc": "2026-02-03 22:33:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dz0bf",
          "author": "bobthearsonist",
          "text": "Oooo interesting. ACP is the big thing behind opencode isn‚Äôt it? Are you shifting more towards that setup where cline runs as a host of sorts and sessions connect to it?",
          "score": 2,
          "created_utc": "2026-02-03 18:40:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3e03f9",
              "author": "saoudriz",
              "text": "That's right -- we've done a ton of work in supporting many API providers and models, and so this lets you plug into that with any client you like!",
              "score": 2,
              "created_utc": "2026-02-03 18:45:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3epmoh",
          "author": "noxtare",
          "text": "is Kimi 2.5 usage logged and our data used for training? or can we use it for enterprise safely?",
          "score": 2,
          "created_utc": "2026-02-03 20:44:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f6quj",
          "author": "alonemushk",
          "text": "I tried it, and I am impressed! especially with the pricing estimate/spend CLine shows there was low compared to what it would have been with API pricing with other models for the amount of work it has done. (and yes I had 0 credits so no real charge)",
          "score": 2,
          "created_utc": "2026-02-03 22:03:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dxbbq",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 2,
          "created_utc": "2026-02-03 18:32:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3dzjsi",
              "author": "saoudriz",
              "text": "Yes and linux!",
              "score": 3,
              "created_utc": "2026-02-03 18:42:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ekg7p",
                  "author": "Rare-Hotel6267",
                  "text": "https://preview.redd.it/zzy9y9bpdchg1.png?width=1080&format=png&auto=webp&s=a73a9ca561c0206225b2f67bf2bd607ec94b317d\n\nAnd, respectfully, something in your auth process is not working right for me. The issue is with the redirect. It was an issue i had a few months ago where i couldn't log into cline in vs code(insiders)(windows 11). I couldn't complete the auth., meaning i could log into the account in the browser(edge/chrome, it doesn't work for both), i completed the auth successfully, but the redirect is not redirecting, and the cline extension don't detect it. resulting in not being able to log into an account (i tried with 2 Google accounts, both failed). So i stopped using it, because i couldn't log in to use it. And didn't want to troubleshoot this. A FEW MONTHS AGO.\n\nSaw the release post about Cline CLI 2.0 and the free Kimmy, and i decided to enable the extension and see what changed, but i couldn't, because of the exact same blocking issue i had  a few months ago. So again i can't use the extension....\n\nI would love for it to be fixed so i can try you out and be impressed, because usually i was disappointed with major releases because of some blocking bug or some reliability issues and stopped using it because of that.",
                  "score": 2,
                  "created_utc": "2026-02-03 20:20:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3eqlzk",
                  "author": "Rare-Hotel6267",
                  "text": "https://preview.redd.it/uwa45cqydchg1.png?width=1080&format=png&auto=webp&s=c5288d5b483b7a3d87ecb073132d87399a89af88",
                  "score": 1,
                  "created_utc": "2026-02-03 20:49:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3f7no5",
          "author": "majesticjg",
          "text": "For the truly clueless, like myself, why do I want/need this over the VS Code extension that's working fine? What does it do for me?",
          "score": 1,
          "created_utc": "2026-02-03 22:07:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3f9w25",
              "author": "Effective-Clock-4482",
              "text": "the main benefit i see is that you can run multiple parallel instances of cline more easily in the terminal. And you can specify different setting for each instance. e.g. if you wanted to run cline with a cheap model and then pipe that output into cline running on a more expensive model, it would be very easy to do with a command line program. I'm excited to use this for CI/CD applications personally",
              "score": 1,
              "created_utc": "2026-02-03 22:18:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3jdt4b",
                  "author": "majesticjg",
                  "text": "Interesting idea. I find myself switching models fairly often, though Kimi 2.5 seems to be a great combination of cheap and accurate. Piping one through another would be interesting.",
                  "score": 1,
                  "created_utc": "2026-02-04 14:48:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3kpkm6",
          "author": "isakota",
          "text": "Just tried it only because of \"free K2.5\" access, and it sucks.   \nNot the model, not the cli but their campaign.  \nIt's unusable for anything other than being calculator.  \nAsked it to show open task (run one command, even provided the command) and it's been  \n10 minutes and still counting...\n\nThis is anti-commercial.  \nAnd this comes from CLine fan.",
          "score": 1,
          "created_utc": "2026-02-04 18:30:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lml8h",
              "author": "juanpflores_",
              "text": "Hey is Akita, brought this to the team and we are taking a look into it.",
              "score": 1,
              "created_utc": "2026-02-04 21:05:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mlci5",
          "author": "Equivalent_Tie4071",
          "text": "I want to like cli but you got too many users for the free kimi-k2.5 access. I am using kimi-k2.5, worked fine but a bit slow early this morning but now it is not useable, slow and stuck in a loop for acting.  \nI started a new task to work on a bug but somehow the agent trys to send my whole cose base(?).\n\nFor the reference, this is a new task and the task that was completred until I get the error error, how can you send 250976 input tokens for a simple task?:  \n \n\nI'll help you investigate and fix this workspace isolation issue \n\nLet me start by examining the relevant code.\n\n¬†‚è∫ Now I can see the issue! \n\nLet me check how documents are stored to see if the workspace is being properly saved in metadata\n\n¬†‚è∫ I found the bug! The workspace is extracted from the request in scan\\_for\\_new\\_documents but it's **NOT** being passed through the call chain\n\n¬†¬† Let me fix this:\n\n**Error**: Requested token count exceeds the model's maximum context length of 262144 tokens. You requested a total of 314976 tokens:\n\n¬†¬† 250976 tokens from the input messages and 64000 tokens for the completion. Please reduce the number of tokens in the input messages or the completion to fit within the limit.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
          "score": 1,
          "created_utc": "2026-02-05 00:02:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3setcl",
          "author": "zzzwx",
          "text": "Hi  \nLong standing user of Cline here.   \nI thought this a great news: I am running on windows OS and couldn't benefit from the previous CLI version.   \nBut the Subagents feature toggle won't unlock after installing the CLI v2 (despite the CLI working well after running \\`cline auth\\`). I tried restarting VSCode, no success.  \nIs there a fix for this ?",
          "score": 1,
          "created_utc": "2026-02-05 21:21:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3sfcmj",
              "author": "saoudriz",
              "text": "We are working on a new subagents implementation that doesn't require CLI. Please stay tuned for an update soon! üôè",
              "score": 1,
              "created_utc": "2026-02-05 21:23:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zeian",
          "author": "IndependentPoet1898",
          "text": "What an excruciating product. I ask it a question. A simple 5 line change to code. It thinks for 22 minute. This isn't competitive.\n\nUsually companies put their best foot forward on a free trial. Strange corporate decision.",
          "score": 1,
          "created_utc": "2026-02-06 22:30:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o40pauv",
          "author": "qwertyk1d",
          "text": "I like the new terminal CLI but as far as i know you cant have differing model providers for plan vs act like you can on the VS Code extension. Can anyone confirm?",
          "score": 1,
          "created_utc": "2026-02-07 03:07:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o418bfi",
              "author": "juanpflores_",
              "text": "Check on /settings you can set this there",
              "score": 1,
              "created_utc": "2026-02-07 05:20:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o41ny44",
                  "author": "qwertyk1d",
                  "text": "You can set it so that plan and act are different models but they have to be from the same source ie; anthropic or OpenAI but the extension allows you to use two different sources I think?",
                  "score": 1,
                  "created_utc": "2026-02-07 07:36:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o44cdpc",
          "author": "considerphi",
          "text": "why is it prompting the model twice for every question i give it? Its burning tokens unnecessarily. Using cline as a plugin in cursor with kimi 2.5 as the model\n\n",
          "score": 1,
          "created_utc": "2026-02-07 18:23:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qx158e",
      "title": "Claude Opus 4.6 is now available in Cline",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qx158e/claude_opus_46_is_now_available_in_cline/",
      "author": "juanpflores_",
      "created_utc": "2026-02-05 23:22:33",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "Anthropic released Opus 4.6 today and it's available in Cline now in v3.57.\n\nhttps://reddit.com/link/1qx158e/video/w86hipj2frhg1/player\n\n**TLDR**\n\nThis is Anthropic's most capable model. Big improvements in reasoning, long context handling, and agentic tasks. If you've been using Opus 4.5 for complex work, this is a straight upgrade.\n\n**Benchmarks**\n\n* 80.8% on SWE-Bench Verified\n* 65.4% on Terminal-Bench 2.0 (state of the art)\n* 68.8% on ARC-AGI-2 (up from 37.6% on Opus 4.5)\n* 1M token context window\n\nhttps://preview.redd.it/2oey9305frhg1.png?width=2002&format=png&auto=webp&s=052b7167a430731d196e885b232b735c9892015d\n\nTwo things stood out to me reading the system card:\n\n1. **It doesn't lose the plot.** 1M token context window and it actually uses it well. If you've ever had a model forget what you told it three prompts ago, you'll feel the difference here. The long context recall is significantly better than previous models. You can throw an entire codebase at it and it keeps track.\n2. **It infers intent better.** You don't have to be as precise with your prompts. It's better at figuring out what you actually want even when you're being vague. Less babysitting, more just saying what you need.\n\n**When to use it**\n\nOpus 4.6 is the model for hard tasks. Complex refactors, multi-file changes, debugging something weird, anything where you need the model to hold a lot of context and think carefully.\n\nFor quick everyday stuff, Sonnet is still faster and cheaper.\n\n**How to use it**\n\nSelect claude-opus-4-6 from the model picker. Works with your Anthropic API key.\n\nWorks in your terminal, JetBrains, VS Code, Zed, Neovim, and Emacs.\n\nCurious to hear how it works for you all. What are you throwing at it?",
      "is_original_content": false,
      "link_flair_text": "Announcement",
      "permalink": "https://reddit.com/r/CLine/comments/1qx158e/claude_opus_46_is_now_available_in_cline/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3t6y8a",
          "author": "Inevitable_Pitch_620",
          "text": "You guys move fast! \n\n",
          "score": 3,
          "created_utc": "2026-02-05 23:45:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42r7cd",
          "author": "Marha01",
          "text": "Good job adding it so quickly, I gave it a thorough try. It seems very good.\n\nWhen will GPT-5.3 Codex be available?",
          "score": 2,
          "created_utc": "2026-02-07 13:26:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3t90j4",
          "author": "Working-Solution-773",
          "text": "It's also EXTREMELY expensive. ",
          "score": 0,
          "created_utc": "2026-02-05 23:57:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xjzmk",
              "author": "juanpflores_",
              "text": "It is the same price as Opus 4.5 so it was already high but it didn't increase the cost. ",
              "score": 2,
              "created_utc": "2026-02-06 17:05:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zp0su",
          "author": "Round_Mixture_7541",
          "text": "Gave it a try. Wasn't pleased. I'll rather use OSS models, sorry Dario.",
          "score": 0,
          "created_utc": "2026-02-06 23:28:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qx4m16",
      "title": "How are people managing context + memory with Cline? (Memory banks, rules, RAG, roadmap?)",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qx4m16/how_are_people_managing_context_memory_with_cline/",
      "author": "arzanp",
      "created_utc": "2026-02-06 01:54:54",
      "score": 8,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "Hey folks,\n\nI‚Äôve been using **Cline** pretty consistently since around **December 2025** for a business startup I‚Äôm working on, and I wanted to sanity-check how others are handling **context and memory management**.\n\nMy setup so far:\n\n* I have a **ChatGPT Plus** subscription and mostly use ChatGPT in the browser as the *‚Äúbrain‚Äù*:\n   * documenting decisions\n   * defining tasks\n   * refining prompts\n* Then I use **Cline** to actually *execute* the work (coding, refactors, changes, etc).\n* From early on, I had **Cline rules** in place (mainly guardrails around Python dev and workflow discipline).\n* I‚Äôve also tried to be very deliberate about **documentation** as I go.\n\nOne thing I noticed pretty quickly was that my **context window was huge** ‚Äî often **200k+ tokens**, even just kicking off fairly simple prompts. At the time, I only really had:\n\n* a basic `.clinerules` folder\n* no `.clineignore`\n* no structured memory management beyond ‚Äúkeep docs in the repo‚Äù\n\nRecently I started digging more seriously into **context optimisation and memory banks**.\n\nWhat I‚Äôve done since:\n\n* Adapted the **basic memory bank concept** from the official Cline docs\n* Added a `.clineignore` (which I‚Äôd completely ignored before üòÖ)\n* Tightened what actually needs to load into context vs what can live ‚Äúcold‚Äù\n\nThat alone dropped my starting context to about **40,000 tokens**, which I‚Äôm honestly very happy with. It‚Äôs made a *huge* difference:\n\n* I can use **smaller, cheaper models**\n* Faster iteration\n* Less accidental context pollution\n\nThat said, I‚Äôve noticed:\n\n* Some users have built **much more advanced rule sets** that are deployable by using their repo first and dropping your project files into the src folder\n* Others talk about **recursive chain of though** [**https://www.reddit.com/r/CLine/comments/1iscdag/cline\\_recursive\\_chainofthought\\_system\\_crct/**](https://www.reddit.com/r/CLine/comments/1iscdag/cline_recursive_chainofthought_system_crct/)\n* And at the far end, there are **RAG-based approaches** (vector DBs, separate servers indexing the whole repo, etc.). Examples include Memento CLI and ByteRover 2.0\n\nSo I‚Äôm curious:\n\n1. **What are people actually using in practice right now?**\n   * Simple memory banks?\n   * Heavier rule-driven approaches?\n   * Full RAG setups?\n2. **Where‚Äôs the trade-off point** where complexity stops being worth it?\n3. **Does Cline have anything on the roadmap** around:\n   * first-class memory management\n   * smarter context loading\n   * or better tooling inside the extension itself?\n\nRight now, the memory bank + ignore approach feels like a good balance for me, but I‚Äôd love to hear what‚Äôs working (or not working) for others.\n\nDisclaimer: I used AI to help me write this, because I don't know all the fancy terms. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qx4m16/how_are_people_managing_context_memory_with_cline/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3vjsbf",
          "author": "Barquish",
          "text": "I tend to use memory-bank to plan phases of each feature. I use plan to build out a series of files \nmemory-bank/feature_[√ó]/00_index_feature_[√ó].md\n01_\n02_\n..\n..\n09_\n\nThen a README_feature_[√ó].md\n\nIn the memory-bank/ folder I have a progress.md\nactiveContext.md\n\nAnd update at the end of each task and/or session\n\nIf I am working on multiple projects (web-app and mobile-app) I ask each AI Assistant to create a Hand-off document, then copy the feature_[√ó] folder and handoff document back and forth updating as I go along.\n\n.clinerules (locsl workspace) and custom_instructions (global) allow me to run multiple Cline instances at once. For example custom_flutter.md and custom_webapp.md",
          "score": 3,
          "created_utc": "2026-02-06 09:52:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3voefz",
              "author": "Barquish",
              "text": "One point I never considered is that after Cline produces file after file, be aware that the content of all the files open may contribute to the context you send. So my advice is to review files open in the IDE and close unnecessary files",
              "score": 1,
              "created_utc": "2026-02-06 10:34:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3u2m41",
          "author": "false79",
          "text": "I don't start with large features. I break it down to smaller tasks that would follow critical path. The start of each task is a reset of context. LLMs perform worse as you approach 128k. Sometimes well before that.\n\n\nA fresh chat I find increases the chance of not having to re do a task again.\n\n\nIf you break down your tasks, it can be done in discrete chunks where having a long running memory would be a waste if it never takes advantage of it.",
          "score": 2,
          "created_utc": "2026-02-06 02:51:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zkn45",
          "author": "maguak",
          "text": "The answers are all correct. Just a few observations about your workflow. Using ChatGpt for governance of your MDs is risky because it generates too much documentation and reduces agility. Use ChatGpt with extreme caution. Regarding the other point, define your agents per project. If it's a RAG, I recommend Antropy. Never a cheap solution. Like Z.ai, code always includes annotations, and technical documentation is vital. Don't let Cline make decisions; it tends to generate duplicate functions, and you won't be able to defend your code to a mining IT team, for example.\n\nWhat I'm telling you is based on my own experience.\nMy recommendation is to avoid Claude.",
          "score": 2,
          "created_utc": "2026-02-06 23:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tulq0",
          "author": "repugnantchihuahua",
          "text": "Before i switched to claude code, i found myself using the memory bank less and less.  I had a series of clinerules for things i wanted to never forget, but for the most part I would just deep plan + point it to the right places to discover the context, since I found the memory bank got clunky/out of date/ would sometimes overindex on things that were in it.  ",
          "score": 1,
          "created_utc": "2026-02-06 02:03:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3u2sjo",
              "author": "false79",
              "text": "Same experience here too",
              "score": 1,
              "created_utc": "2026-02-06 02:52:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3u6sxh",
              "author": "arzanp",
              "text": "Can you share a deep plan prompt with me ?",
              "score": 1,
              "created_utc": "2026-02-06 03:16:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3u9vah",
                  "author": "repugnantchihuahua",
                  "text": "\\`/deep-plan i want to make x field nullable in the API\\` \n\nlike, i think there is a \\_lot\\_ out there in terms of overwhelming information, but TBH if your work is already bite-sized as part of greater work, the model does a good enough job figuring out what to do by exploring files ",
                  "score": 1,
                  "created_utc": "2026-02-06 03:35:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qulwyi",
      "title": "Significant drop in open router use",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qulwyi/significant_drop_in_open_router_use/",
      "author": "BlindPilot9",
      "created_utc": "2026-02-03 07:48:05",
      "score": 5,
      "num_comments": 12,
      "upvote_ratio": 0.73,
      "text": "Openrouter reports show a significant drop in the amount of tokens consumed by cline and roo code users. Kilo on the other hand, is a significant user of openrouter. The significant drop in token use should be attributed to a certain cause that I am trying to identify. Significant drop makes me wonder if cline and roo are becoming less popular or the traffic is being routed to a different provider.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qulwyi/significant_drop_in_open_router_use/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3b4htf",
          "author": "QuickBeam1995",
          "text": "The cline provider runs on the Vercel AI gateway now",
          "score": 12,
          "created_utc": "2026-02-03 08:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b6ee3",
              "author": "juanpflores_",
              "text": "This is the answer. We moved from Open Router to Vercel AI Gateway so the tokens are not fully represented in the Open Router Leaderboard anymore. If you check the Vercel AI Gateway leaderboard we are at the top.",
              "score": 10,
              "created_utc": "2026-02-03 08:31:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ceq91",
          "author": "hannesrudolph",
          "text": "FYI we are Roo made a decision not to push the OpenRouter leaderboard and focus on building solid integrations directly with the labs and our own router. I believe Cline has done the same. Not interested in playing that game.",
          "score": 5,
          "created_utc": "2026-02-03 14:13:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b4k7x",
          "author": "ActMore5232",
          "text": "I used Cline for the first time in a while today and it felt off. It‚Äôs a wholly emotional feeling, but idn. \n\n(Totally random opinion YMMV)",
          "score": 2,
          "created_utc": "2026-02-03 08:13:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cuf0s",
          "author": "user29919202",
          "text": "We can actually look in the code (open source ftw!).  Check out the cline/ repo and ask Cline about itself, and you can learn that Cline shifted from OpenRouter to Vercel.",
          "score": 2,
          "created_utc": "2026-02-03 15:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b5ugm",
          "author": "Vasivid",
          "text": "How kilo is better than cline?",
          "score": 2,
          "created_utc": "2026-02-03 08:26:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dx0ck",
          "author": "ihave10personalities",
          "text": "I haven't used Cline or Roo since Antigravity was released.",
          "score": 1,
          "created_utc": "2026-02-03 18:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3evw7e",
          "author": "NearbyBig3383",
          "text": "That's why CLIs are gaining ground, because extensions have limited language capabilities.",
          "score": 1,
          "created_utc": "2026-02-03 21:13:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3dpsp5",
          "author": "Purple_Wear_5397",
          "text": "Cline and Roo are dropping significantly. \nCline has been on a decline ever since they raised round A. \n\nClaude code and codex rule the market I believe.",
          "score": 0,
          "created_utc": "2026-02-03 17:59:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3b2gi9",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 0,
          "created_utc": "2026-02-03 07:54:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3b6gj2",
              "author": "juanpflores_",
              "text": "They retracted the ads and updated their blogs as it was misinformation.",
              "score": 3,
              "created_utc": "2026-02-03 08:32:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ce655",
              "author": "hannesrudolph",
              "text": "Advancing of Roo and Cline? üòù they‚Äôve not innovated on much if anything and are pretty slow to take on our innovations. Kilo is all marketing.",
              "score": 0,
              "created_utc": "2026-02-03 14:10:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3bvei1",
          "author": "quantum1eeps",
          "text": "Because Clause Code with a $100 plan is like $1000 worth of OpenRouter tokens",
          "score": -1,
          "created_utc": "2026-02-03 12:16:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwb3ue",
      "title": "Possibility of using cline without vscode",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qwb3ue/possibility_of_using_cline_without_vscode/",
      "author": "Bi11i0naire",
      "created_utc": "2026-02-05 04:09:21",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Anyone tried this? There is a feature request here but looks like there are limitations in capturing the event messages from Cline\n\n[https://github.com/cline/cline/discussions/2622](https://github.com/cline/cline/discussions/2622)",
      "is_original_content": false,
      "link_flair_text": "‚úÖ Question: Resolved",
      "permalink": "https://reddit.com/r/CLine/comments/1qwb3ue/possibility_of_using_cline_without_vscode/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3o3e9a",
          "author": "hannesrudolph",
          "text": "Use the CLI?",
          "score": 5,
          "created_utc": "2026-02-05 05:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3o8ikn",
              "author": "juanpflores_",
              "text": "\\+1 to this the CLI would be the way to go either headless or interactive mode  \n[https://docs.cline.bot/cline-cli/overview](https://docs.cline.bot/cline-cli/overview)",
              "score": 2,
              "created_utc": "2026-02-05 06:09:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pcl9m",
          "author": "Southern_Orange3744",
          "text": "Cli is doable , I think some IDE might be\n\nI went a deep misadventure trying to make my own UI I would not recommend wasting time trying",
          "score": 1,
          "created_utc": "2026-02-05 12:10:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uk7m1",
          "author": "Bi11i0naire",
          "text": "Cline could benefit from this feature as there is no standard client for agents.  \n\nCluade forces to use their own model by default.\n\nAll the hype is around MCP but I think even the client is also important and every organization is building their own client. \n\nCurious to know other's thoughts..",
          "score": 1,
          "created_utc": "2026-02-06 04:44:20",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qy9jd3",
      "title": "Opus 4.6 1m is a superpower",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qxi8yr/cline_quite_slow_in_riderjetbrains/o41zj68/",
      "author": "Barquish",
      "created_utc": "2026-02-07 09:30:40",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 0.69,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qy9jd3/opus_46_1m_is_a_superpower/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o44qcth",
          "author": "majesticjg",
          "text": "It has to be, at that price. I think I'll use it for my more difficult issues.",
          "score": 1,
          "created_utc": "2026-02-07 19:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4660lt",
          "author": "gevik",
          "text": "Opus 4.6 is really insane, and also expensive, but hey, it is all worthed. Maybe it is me but when you turn on thinking, then it is VERY slow.",
          "score": 1,
          "created_utc": "2026-02-08 00:23:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46jtxf",
              "author": "firedog7881",
              "text": "I pay for the pro plan and it is worth it. I just hit my weekly rate limit on Wednesday, used api for the three or so days and spent about $350 in api.  \n\nI highly recommend the pro plan",
              "score": 1,
              "created_utc": "2026-02-08 01:48:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o42244l",
          "author": "hannesrudolph",
          "text": "It‚Äôs insane!",
          "score": 1,
          "created_utc": "2026-02-07 09:54:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qugp8t",
      "title": "Anyone else struggling with MCP use?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qugp8t/anyone_else_struggling_with_mcp_use/",
      "author": "former_farmer",
      "created_utc": "2026-02-03 03:13:43",
      "score": 3,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "I'm using small open source models from 3B to 10B self hosted. MCPs are configured.\n\nThe models often fail to know how to use MCPs... it's usually a waste of time. Is cline not informing the models correctly or should I try with 20B models?\n\nAny way I haven't tried this in two weeks. I'll try again. But just asking about your experience with this. Thanks :)",
      "is_original_content": false,
      "link_flair_text": "‚úÖ Question: Resolved",
      "permalink": "https://reddit.com/r/CLine/comments/1qugp8t/anyone_else_struggling_with_mcp_use/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3d6ou4",
          "author": "juiceboxwtf",
          "text": "Hey! It's almost certainly the model size, not Cline.\n\nTool use is one of the hardest capabilities for LLMs, so 3B-10B models just don't have enough capacity to do it reliably. They'll hallucinate tool calls, forget parameters, or ignore tools entirely.\n\nTry a 30B+ model trained for tool use (Qwen 2.5 Coder 32B or DeepSeek Coder V2). The jump from 10B to 30B+ is a qualitative leap for tool use. If you're RAM-constrained, a 4-bit quantized 32B model runs in ~20GB VRAM and will still dramatically outperform a 10B at this.\n\nLet me know how it goes!",
          "score": 2,
          "created_utc": "2026-02-03 16:31:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3d7fl5",
              "author": "former_farmer",
              "text": "I will try this, thanks!",
              "score": 1,
              "created_utc": "2026-02-03 16:34:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3b6lws",
          "author": "juanpflores_",
          "text": "Normally, if you get less than 20 billion parameters in your model, they won't be performing as you might expect. My recommendation is that if you're trying to use MCP servers, try to use models with more than 30 billion parameters. Let us know if this works.",
          "score": 1,
          "created_utc": "2026-02-03 08:33:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cmqgk",
          "author": "majesticjg",
          "text": "Tool use is largely dependent on the model, but I also find that the model doesn't know what the tool isn't allowed to do until it tries. For instance, I have a filesystem tool that I love, but it'll try to browse things outside of the allowed folder tree often, get an error and have to correct. I wish it knew better on the first shot.",
          "score": 1,
          "created_utc": "2026-02-03 14:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hkpd9",
          "author": "richardbaxter",
          "text": "I found it a bit of a struggle getting tool use reliable on my network llm server. I'm working with reasonable stability with openwebui in docker on my local machine, mcpo then qwen3 coder 30b in LM Studio on the network machine. I'm still learning though - hopefully this is at least partially useful!¬†",
          "score": 1,
          "created_utc": "2026-02-04 06:35:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ygsc0",
          "author": "TheLawIsSacred",
          "text": "I use Claude Desktop app (chat), a few months ago, to help me set up a lazy router configuration that allows me to have over 10 mcps running at a time without running into insane token bloat at the start of every conversation with it",
          "score": 1,
          "created_utc": "2026-02-06 19:42:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yixr4",
              "author": "former_farmer",
              "text": "What models are you running and what hardware do you have?",
              "score": 1,
              "created_utc": "2026-02-06 19:52:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o40y2gu",
                  "author": "TheLawIsSacred",
                  "text": "Microsoft Surface Laptop (7th Gen) 15-inch Copilot+ PC: ARM64-based laptop featuring a Qualcomm Snapdragon X Elite 12-core processor, 64GB LPDDR5x RAM, and a 15\" 120Hz PixelSense Flow touchscreen (2496 x 1664). \n\nThe Wi-Fi-only model equipped with a 45 TOPS Hexagon NPU for local AI processing ;)",
                  "score": 1,
                  "created_utc": "2026-02-07 04:05:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o40yhdy",
                  "author": "TheLawIsSacred",
                  "text": "I've described my AI Panel setup in precious posts - I'll try to remember to dig up the full write-up later. There is no one solution, it's so interesting to see how everyone is getting to somewhere near the same conclusion point via different means.",
                  "score": 1,
                  "created_utc": "2026-02-07 04:08:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxi8yr",
      "title": "Cline quite slow in Rider/Jetbrains",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qxi8yr/cline_quite_slow_in_riderjetbrains/",
      "author": "Jump-Ok",
      "created_utc": "2026-02-06 13:54:59",
      "score": 3,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Hello everyone,\n\nIs it just me or Cline has been quite slow lately? Is it cuz of the API response delay or scope of my project?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qxi8yr/cline_quite_slow_in_riderjetbrains/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o3wym1r",
          "author": "SufficientApricot165",
          "text": "EVERYTHING IS SLOW IN RIDER!!! It's so obvious how much that company is focused on developing Idea. The Rider folks are playing second fiddle. Glad I'll be working with Java soon",
          "score": 1,
          "created_utc": "2026-02-06 15:24:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3za9qw",
              "author": "Round_Mixture_7541",
              "text": "You think the performance will change?",
              "score": 1,
              "created_utc": "2026-02-06 22:08:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o41ptfk",
                  "author": "SufficientApricot165",
                  "text": "No what I'm saying is that the two products are not equal and there is alot more effort put into InteliJ than Rider and I think it will continue like that",
                  "score": 1,
                  "created_utc": "2026-02-07 07:54:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3x4gy3",
          "author": "Barquish",
          "text": "I was just about to ask if anyone else noticed that Cline is very slow. Updated and changed to use Opus 4.6 for plan and act. It is not costing more than usual, but taking a longer time than normal to process almost line by line",
          "score": 1,
          "created_utc": "2026-02-06 15:52:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xjuie",
              "author": "juanpflores_",
              "text": "So there can be multiple reasons why this happens from the IDE and also Opus 4.6. From my experience, it is a little bit slower than 4.5 because of the deeper planning that it currently has. Let us know if you continue to see this, but sometimes I feel that this is kind of expected with these models that have high reasoning. ",
              "score": 1,
              "created_utc": "2026-02-06 17:04:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o41zj68",
                  "author": "Barquish",
                  "text": "I am so impressed. Two hours refactoring of 5037 lines of code in one app_router.dart file down to 330 lines of code, creation of 16 files across 7 phases and stepped phase of branch, commit before testing and then merge to master in git. Opus 4.6 1m is a super-power",
                  "score": 2,
                  "created_utc": "2026-02-07 09:28:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3z178z",
                  "author": "Barquish",
                  "text": "I get that it thinks longer, and I left it in the default settings. It just seemed like it was going through line by line that took forever to complete. Compared to working with Opus 4.5. It took perhaps 2, even 3 hours longer to complete the task I had asked it to do than I expected. Notwithstanding that, it completed the task with only minor adjustments needed. \n\nAll days was planning, so we shall see tomorrow when we begin to implement the plan and I will be using Opus 4.6 for that also.",
                  "score": 1,
                  "created_utc": "2026-02-06 21:23:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o41rayi",
                  "author": "Barquish",
                  "text": "Today the speed seems to have improved. Have given it a task of refactoring a dart file that was in excess of 5000 lines (I know it got out of hand as the project grew) and so far it is doing really well. \n\nI work in VSCode with Cline mostly and I often have to instruct it to break into smaller steps as on large files it can get into problems with write_to_file. That always resolves the issue. Other than that, I am using Opus 4.6 1m in ACT to allow context to be used extensively whilenthe process is working it's way through it. Making sure that I commit to each phase (7 in total) and run build test after each phases. \n\nHonestly, this would have been a task I put off forever before Opus 4.6. Perhaps famous last words, as the process is still underway while I write üôÉ",
                  "score": 1,
                  "created_utc": "2026-02-07 08:08:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xjnmn",
          "author": "juanpflores_",
          "text": "Thanks for letting us know. We have been working a lot with Rider, and it's definitely one of those weird cases where the IDE presents more challenges than others from the same family of products. If you see anything like that, we would appreciate you to open an issue in our repo so that we can take a deep dive into it. Thank you for reporting. We're still looking at it. ",
          "score": 1,
          "created_utc": "2026-02-06 17:03:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxwqhf",
      "title": "No plain email Registration?",
      "subreddit": "CLine",
      "url": "https://www.reddit.com/r/CLine/comments/1qxwqhf/no_plain_email_registration/",
      "author": "m4smss",
      "created_utc": "2026-02-06 22:56:18",
      "score": 2,
      "num_comments": 6,
      "upvote_ratio": 0.67,
      "text": "I wondered that registration at cline.bot is only possible via Google or GitHub, no plain email registration. I usually prefer to have all services separated for not running into any single-sign-on dependencies.\n\nWhy is it like this?\nI did not even find a description what the registration offers or costs.\nI'm using Cline in VSCodium with a Claude API key payed per usage. What is the difference when using a Cline account with the same Sonnet-4.5 model for instance?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/CLine/comments/1qxwqhf/no_plain_email_registration/",
      "domain": "self.CLine",
      "is_self": true,
      "comments": [
        {
          "id": "o4akrc2",
          "author": "Frosty_Signature_840",
          "text": "we are adding this next week. Thanks!",
          "score": 3,
          "created_utc": "2026-02-08 18:27:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41ctp1",
          "author": "BitterProfessional7p",
          "text": "Same, that's why I have never registered. Just installed in VSCodium and use it without an account.\n\nI don't have one but I think their account is only for their subscriptions or if you want to use Cline like Openrouter to load credits and use different models.",
          "score": 2,
          "created_utc": "2026-02-07 05:57:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45hpsc",
          "author": "juanpflores_",
          "text": "So, if you use a Cline account you will get access to some free and stealth models. You can use Cline without a Cline account if you have an API key and you want to use it in the extension/CLI. We are aware on the limitation of the single sign on and we are working through some considerations there but will take some time to get there",
          "score": 2,
          "created_utc": "2026-02-07 21:59:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4b6wr7",
              "author": "m4smss",
              "text": "Thanks for your reply. \nI'm looking forward to get a registration via email, which should actually be the plain basic default before having any SSO logins.\n\nI understand now that the Cline fees are almost the same like using the APIs of AI providers directly, but gives the flexibility to change models and providers, while also having some free models available.\n\nBut not being connected to Google or GitHub would be preferred, if not creating a separate Google account for using Cline, which sounds overkill üòÖ",
              "score": 1,
              "created_utc": "2026-02-08 20:13:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zluoy",
          "author": "0xB_",
          "text": "That cost money",
          "score": -1,
          "created_utc": "2026-02-06 23:10:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3znas0",
              "author": "Round_Mixture_7541",
              "text": "What does",
              "score": 1,
              "created_utc": "2026-02-06 23:18:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}