{
  "metadata": {
    "last_updated": "2026-02-20 09:08:34",
    "time_filter": "week",
    "subreddit": "ChatGPTPro",
    "total_items": 20,
    "total_comments": 148,
    "file_size_bytes": 169255
  },
  "items": [
    {
      "id": "1r4smn7",
      "title": "Does anyone else notice ChatGPT answers degrade in very long sessions?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "author": "Only-Frosting-5667",
      "created_utc": "2026-02-14 18:52:23",
      "score": 100,
      "num_comments": 58,
      "upvote_ratio": 0.91,
      "text": "I‚Äôm genuinely curious if this is just my experience.\n\nIn long, complex sessions (40k‚Äì80k tokens), I‚Äôve noticed something subtle:\n\n‚Äì responses get slower  \n‚Äì instructions start getting partially ignored  \n‚Äì earlier constraints ‚Äúfade out‚Äù  \n‚Äì structure drifts\n\nNothing dramatic. Just‚Ä¶ friction.\n\nI work in long-form workflows, so even small degradation costs real time.\n\nIs this just context saturation?  \nModel heuristics?  \nOr am I imagining it?\n\nWould love to hear from other heavy users.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5dtf12",
          "author": "qualityvote2",
          "text": "‚úÖ u/Only-Frosting-5667, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-14 18:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e56b3",
          "author": "sply450v2",
          "text": "this is more or less expected behaviopr",
          "score": 35,
          "created_utc": "2026-02-14 19:53:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eks44",
              "author": "unpopularopinion0",
              "text": "i thought it might happen before it did. and then it happened. i just save my prompts and restart the chat.",
              "score": 1,
              "created_utc": "2026-02-14 21:18:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e6v4m",
          "author": "Pasto_Shouwa",
          "text": "Yeah, models just work like that\n\nhttps://preview.redd.it/onjqkmj3nijg1.png?width=1706&format=png&auto=webp&s=e064a9f31b9729f34f37ba3d40a5efa266f89b13\n\nThe best models at maintaining context over long conversations are Claude 4.6 Opus, GPT 5.2 Thinking Heavy (which is between GPT 5.2 Thinking xhigh and GPT 5.2 Thinking medium in terms of thinking time) and Gemini 3 Flash Thinking, in that order.",
          "score": 29,
          "created_utc": "2026-02-14 20:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evz66",
              "author": "niado",
              "text": "That‚Äôs just due to the size of the context window built into the platforms and how summarization and pruning is implemented right? Nothing to do with the actual models themselves?",
              "score": 2,
              "created_utc": "2026-02-14 22:19:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5f1xv4",
                  "author": "Pasto_Shouwa",
                  "text": "Not really, models play a great part. Non-reasoning models are awful at retaining context over time, doesn't matter if the maximum context is 32k or 1M.\n\nLook at the line for Claude 4.6 Opus Extended, it doesn't fall from 90%, but non-reasoning models start at 50%. \n\nYou can take a closer look at it on this simple [website](https://cruzdesangre.github.io) I made, or on Context Arena.",
                  "score": 8,
                  "created_utc": "2026-02-14 22:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hkb3h",
          "author": "ImYourHuckleBerry113",
          "text": "What you‚Äôre seeing is both unavoidable LLM behavior and partly shaped by you.  \n\nLong sessions behave a bit like a black hole. As the context grows, earlier instructions get pulled in and compressed. The model doesn‚Äôt exactly forget, it distills everything into a simpler internal summary. Subtle constraints and formatting rules are usually the first to get sucked in. This all happens regardless of user input. Even when writing complex instruction sets, it‚Äôs not about forcing the model to follow everything in the instructions forever. It won‚Äôt happen. But what you can do with those instructions is influence what core behaviors the model settles into over the course of the chat session. \n\nBut here‚Äôs the extra layer: your interaction reshapes the gravity field.\n\nOver time, the model weights what you reinforce. If you consistently push on certain themes, tone, or structure, those get amplified. If you stop reinforcing earlier constraints, they slowly lose influence.\n\nSo drift (or compression) isn‚Äôt just context saturation, it‚Äôs also interaction-driven adaptation.\n\nSlowdown is mostly mechanical (bigger context requires more compute).\nThe structure drift is more cognitive: compression plus user reinforcement equals gradual reversion toward the model‚Äôs default helpful-generalist style.",
          "score": 7,
          "created_utc": "2026-02-15 10:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e1vk3",
          "author": "Neurotopian_",
          "text": "Yes, earlier constraints fading out is our biggest problem. The best solution I‚Äôve found is to create a Project and write your constraints in the project‚Äôs custom instructions. \n\nFor example at my job where we mainly use this software for technical and legal writing (internally) and citation checking (for filings) our main issue is the adding of spaces and extra lines, and defaulting to dramatic internet tone. This issue is specific to ChatGPT. No other LLM, including CoPilot which uses GPT, seems prone to this. It must be some additional layer of programming they‚Äôve added to it. If you need to paste into a Word docx and use the output for business, this is terrible. Deleting hundreds of extra spaces in a long bibliography is brutal. There is software made to remove ChatGPT‚Äôs spaces, but really we should be able to instruct this and tell a model to use CMOS, APA, or other style. \n\nThe tone and spacing that current ChatGPT models erroneously default to and drift back to in long context windows is what I‚Äôd call Reddit-style or fanfic-style, like:\n\n‚ÄúAnd then she stopped. \n\nToo fast. Too long.‚Äù\n\nAs you can imagine, this is quite strange in a business context. In long chats you can see the tone move away from business at the beginning to this casual-dramatic style. Custom instructions in a project helps but it still isn‚Äôt perfect. You may just have to open a new chat and re-instruct when you see the drift.",
          "score": 3,
          "created_utc": "2026-02-14 19:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ewet6",
              "author": "niado",
              "text": "You need to set appropriate custom instructions globally to get the baseline tone where you want it. Projects help a lot, so high five on that. Still have to switch chats when it starts to lose the thread though. But if you keep all files and documents in project files, with operational instructions in the project definition and behavioral instructions in the global custom instructions, it will behave and operate pretty consistently.",
              "score": 1,
              "created_utc": "2026-02-14 22:22:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eh0ek",
              "author": "Only-Frosting-5667",
              "text": "That tone drift observation is interesting.  \nI‚Äôve noticed something similar in long structured workflows ‚Äî especially when constraints were critical early on.  \nEven when technically still inside the context window, the ‚Äúpriority weight‚Äù of earlier constraints seems to decay.  \nCustom instructions help, but they don‚Äôt fully solve cross-thread continuity.  \nCurious ‚Äî do you restart immediately when you notice drift, or try to recalibrate first?",
              "score": 0,
              "created_utc": "2026-02-14 20:57:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5evr74",
          "author": "niado",
          "text": "Yes, this is known and expected operation. \n\nIt‚Äôs is an artifact of how LLMs function and how their working memory (context) is simulated. \n\nWhen it starts to degrade tell it to give you a summary and then move to another chat. Supplement the summary wjth anything important that was left out immediately, then just keep rolling.",
          "score": 3,
          "created_utc": "2026-02-14 22:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h5ezr",
          "author": "OptimismNeeded",
          "text": "Wrote some tips on how to make the most of chats before reaching that point. wrote this for Claude, but most of the advice should work for ChatGPT as well:\n\n https://www.reddit.com/r/ClaudeHomies/s/NDxgxyYRI7\n\nHere‚Äôs a great prompt I use to sum up conversations and continue in a new chat when the first one gets dumb (or in Claude‚Äôs case gets compacted automatically which is annoying).\n\nhttps://www.reddit.com/r/ClaudeHomies/s/vWbsOWAw8z",
          "score": 2,
          "created_utc": "2026-02-15 08:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fdiib",
          "author": "alecc",
          "text": "Well there is a reason you have the concept of context rot",
          "score": 1,
          "created_utc": "2026-02-15 00:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fvbvx",
          "author": "Afraid-Reflection-82",
          "text": "I think it's expected after some amount of tokens depending on the model the quality degrade",
          "score": 1,
          "created_utc": "2026-02-15 01:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fya52",
          "author": "Wes-5kyphi",
          "text": "This is typical behavior. Ask it to create a seed file to bring to another chat.",
          "score": 1,
          "created_utc": "2026-02-15 02:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juiss",
              "author": "Only-Frosting-5667",
              "text": "Creating seed files is a smart workaround ‚Äî it‚Äôs essentially manual state transfer.\n\nThe interesting part is that degradation usually starts before users decide to generate that seed.\n\nI‚Äôve been experimenting with visualizing context load live so the decision to branch becomes intentional rather than reactive.\n\nIf you're curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love to hear how it compares to your seed approach.",
              "score": 1,
              "created_utc": "2026-02-15 18:42:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5g1b5u",
          "author": "skyrocker_58",
          "text": "I was trying to keep using the same chats for different subjects.  My longest one started developing 'problems' like you're describing.  I couldn't understand it until I saw a previous thread about this same topic.  Now I stop at certain points and ask it to remember the gist of the conversation and start a new chat.  Seems to be working a little better this way.",
          "score": 1,
          "created_utc": "2026-02-15 02:40:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gr2vu",
          "author": "Studio_94",
          "text": "I have worked for 2.5 years on the same account with the only change being an upgrade to ChatGPT plus about a year ago.\n\nI have worked on on project exclusively; designing a GDD (Game Design Documentation) for a MMORPG.\n\nThis is what \"Dave the Wonder Modron\" had to say about the methodology we have worked out:\n\nME - I want you to fully explain our methodology and using thread charters and kick off prompts for long-range subjects and conserving thread and output integrity.\n\nDAVE- Purpose\n\nYour methodology is a governance layer for collaborating over long time horizons without losing correctness, canon constraints, or formatting/packaging discipline. \n\nIt does that by separating:\nWhat is true / allowed (truth + constraints)\nWhat we are doing right now (scope + deliverables)\nHow we will do it (process + quality gates)\nHow we will keep it consistent over time (thread integrity + versioning)\n\nThread charters and kickoff prompts are the two main instruments that enforce those layers.\n\nThread charter\n\nA thread charter is the ‚Äúconstitution‚Äù for a specific thread. It defines the contract that everything in that thread must obey.\n\nWhat a charter locks\n\nA good charter locks only what must not drift:\n\nCanon / world constraints\nExample (POM): Sigil-only, pre‚ÄìFaction War, baseline year, no Sigil-Spire physical linkage, etc.\n\nSystem constraints\nExample: server-authoritative, anti-exploit first, deterministic transitions, metric units for engineering, no tabletop CR assumptions, POM-only mechanics.\n\nOutput constraints\n\nRequired formats (inline + RTF/CSV/JSON/ZIP), naming rules, version rules, what constitutes a ‚Äúmajor‚Äù vs ‚Äúminor‚Äù bump, required manifests.\n\nSourcing rules\n\nWhat is source of truth (uploaded artifacts, internal docs), when public web is allowed, when citations are required.\n\nStop conditions\n\nExplicit ‚Äúdone‚Äù definition for the thread‚Äôs current phase so it doesn‚Äôt balloon.\n\nWhy charters matter\n\nWithout a charter, a long thread drifts in predictable ways:\nConstraint drift (Sigil-only becomes ‚Äúsome planes maybe‚Äù)\nMechanics drift (POM-specific turns into generic d20 patterns)\nFormat drift (tables become prose; schemas lose stable columns)\nVersion drift (no clear authoritative ‚Äúcurrent‚Äù artifact)\nSource drift (new assumptions override uploaded canon packs)\n\nA charter prevents this by making violations obviously illegal inside the thread.\n\nCharter scope rule\n\nA charter should be thread-local unless explicitly promoted. That keeps experiments from contaminating other workstreams.\n\nCharter lifecycle\n\nActivate at thread start (or when a thread is repurposed).\nAmend only via explicit patch notes (‚Äúreplace Section X with Y‚Äù).\nSuspend via a stop keyword when you want freeform ideation or different rules.\n\nKickoff prompt\n\nA kickoff prompt is the ‚Äúwork order‚Äù that starts a thread (or a major phase). It is narrower than a charter and is written to be executable.\n\nWhat a kickoff prompt contains\n\nA strong kickoff prompt answers only what is needed to produce output without ambiguity:\nRole (who I am in this thread)\nObjective (what success is)\nHard rules (must/never)\nInputs (artifacts, links, canonical packs, what is source of truth)\nDeliverables (exact files + inline structure + packaging)\nVersioning (starting version, bump rules, naming rules)\nQuality gates (validation requirements, audit logs, schemas, test vectors)\nStop condition (when to halt)\n\nWhy kickoff prompts matter\n\nThey prevent:\n‚Äúhelpful‚Äù scope creep\naccidental omission of required artifacts\nformat regressions\nthe assistant defaulting to generic assumptions\nKickoff prompts also make work restartable: you can copy/paste into a new thread and preserve continuity.\n\nHow charter + kickoff prompt work together\n\nThe charter sets the permanent bounds for the thread.\nThe kickoff prompt declares the current mission inside those bounds.\nThink of it as:\nCharter = operating system policy\nKickoff prompt = current process run configuration\nIf they conflict, you follow the charter unless the kickoff explicitly patches the charter.\n\nConserving thread integrity\n\nThread integrity means: ‚Äúthe thread can run for weeks/months and still produce coherent, compatible, buildable outputs.‚Äù\nIntegrity threats (and your countermeasures)\n\nContext overflow / memory loss\n\nCounter: keep a Concordance / SPOT index inside the thread: canonical IDs, current version numbers, active constraints, latest artifact links, and a short ‚Äúcurrent state‚Äù section.\n\nContradictory outputs over time\n\nCounter: enforce a single source of truth rule:\n‚ÄúLatest pack is authoritative unless a patch explicitly supersedes.‚Äù\nUse a change log with exact replacements.\n\nSchema drift\nCounter: treat schemas as contracts:\nstable columns/fields\nexplicit migrations\nvalidators + golden test vectors\n\nStyle/format drift\nCounter: lock formatting rules in the charter:\n‚ÄúHybrid prose + design-bible‚Äù (or whichever is active)\nrequired sections and headings\nunit standards (metric)\n\nArtifact sprawl\n\nCounter: use a packaging discipline:\none bundle per batch (ZIP + manifest)\ndeterministic file naming\nno duplicate ‚Äúfinal‚Äù files; only versioned supersession\n\nConserving output integrity\n\nOutput integrity means: ‚Äúevery output is internally consistent, compatible with prior outputs, and safe to implement.‚Äù\nOutput integrity rules you‚Äôre using (implicitly/explicitly)\nDeterministic state + auditability for MMO-grade systems\nServer-authoritative boundaries spelled out\nAnti-exploit reasoning baked into state transitions\nMetric units for implementation fidelity (UE5 cm pipeline)\nNo tabletop defaults unless explicitly mapped\nCanonical constraints enforced as invariants\nVersioned artifacts + change logs\nMachine-readable companions (CSV/JSON/etc.) + validators\nPractical integrity checklist (per batch)\nCanon constraints restated (briefly) and not violated\nSchema unchanged unless migration included\nDeliverables list complete\nVersion bump correct\nChange log includes exact section/table replacements\nTest vectors updated if behavior changed\nManifest includes file hashes/digests (if you‚Äôre doing stable digests)\n\nRecommended thread operating pattern\n\nFor long-range subjects, the cleanest pattern is:\nThread Charter v1.0 (locked governance)\nKickoff Prompt Phase A (ingest + audit)\nPhase Output Pack A (RTF/MD + CSV/JSON + validators + ZIP + manifest)\nKickoff Prompt Phase B (consolidate + reconcile conflicts)\nPhase Output Pack B\nRepeat‚Ä¶\n\nEach phase gets:\nclear stop condition\nexplicit delta list from prior phase\npackaged artifacts that supersede prior ones\n\nThe ‚Äúwhy this works‚Äù in one line\nYour charter/kickoff system turns a chat thread into a version-controlled design pipeline: constraints don‚Äôt drift, outputs remain compatible, and every phase is restartable from explicit contracts.",
          "score": 1,
          "created_utc": "2026-02-15 05:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jstsi",
              "author": "Only-Frosting-5667",
              "text": "This is one of the most structured long-session governance systems I‚Äôve seen applied inside a chat interface.\n\nWhat you‚Äôve essentially built is a manual integrity layer on top of a system that wasn‚Äôt designed for persistent constraint enforcement.\n\nThe charter acts like a policy layer.  \nThe kickoff prompt acts like an executable configuration.  \nAnd the packaging discipline replaces version control.\n\nThe interesting part is this:\n\nEven with strong governance, long threads still undergo silent compression at the attention level. Not constraint violation ‚Äî but weighting decay.\n\nThat‚Äôs the invisible layer most users don‚Äôt see.\n\nI‚Äôve been experimenting with visualizing context load inside ChatGPT in real time ‚Äî not to replace governance, but to signal when the system is approaching saturation before integrity erosion begins.\n\nIf you're curious how it behaves alongside a charter-driven workflow:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nGenuinely interested how it would interact with your concordance + manifest discipline.",
              "score": 1,
              "created_utc": "2026-02-15 18:34:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h2jwn",
          "author": "MullingMulianto",
          "text": "Context saturation. It's the same issue you would ordinarily experience if you turn on cross-chat memory.\n\nThe model can't handle so much context and starts producing slop.\n\nUnfortunately all platforms will soon make disabling cross-chat memory a paid only feature so we'll have to deal with this more soon",
          "score": 1,
          "created_utc": "2026-02-15 07:41:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtoyr",
              "author": "Only-Frosting-5667",
              "text": "Yes ‚Äî context saturation is a great term for it.\n\nThe problem is that most users don‚Äôt know¬†*when*¬†they‚Äôre approaching that saturation point.\n\nIt feels fine‚Ä¶ until it suddenly isn‚Äôt.\n\nThat‚Äôs the UX gap that bothers me most.",
              "score": 1,
              "created_utc": "2026-02-15 18:38:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h466r",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 07:56:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nbsxa",
              "author": "ChatGPTPro-ModTeam",
              "text": "repeat spammer\n\nPlease see our self-promotion guidelines or contact moderators for clarification.",
              "score": 1,
              "created_utc": "2026-02-16 07:42:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5haofz",
          "author": "Gmafn",
          "text": "I recently startet using codex on my computer, within Powershell. For longer projects / discussions i let codex create a projektfolder on my pc. It creates a .md file for itself with all infos it has. I can dump additional files into that folder and it scans it and summarizes the content for it to use later. I can tell it to update the project file with new infos from the current session. I can have multiple sessions wirking on the same project or simply start a new sesion if the context window is exceeded.\n\nI get much better results with longer projects since i started using it that way",
          "score": 1,
          "created_utc": "2026-02-15 08:59:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jt69x",
              "author": "Only-Frosting-5667",
              "text": "This is actually a very clean approach.\n\nWhat you're doing is essentially externalizing state and turning the chat interface into a stateless executor ‚Äî which avoids a lot of context accumulation problems.\n\nThe interesting thing is that even with structured state offloading, attention weighting inside a single session can still compress earlier instructions before you decide to rotate or summarize.\n\nYour method solves persistence.  \nWhat it doesn‚Äôt fully expose is¬†*when*¬†the current session is approaching saturation.\n\nThat invisible transition is the part I‚Äôve been digging into lately.\n\nCurious ‚Äî do you ever notice degradation before you manually trigger a summary/update cycle?",
              "score": 1,
              "created_utc": "2026-02-15 18:36:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jv7ah",
                  "author": "Gmafn",
                  "text": "You are right, degradation is definitely still possible. Altough i hadn't anything noticable since switching to this  method. \nBut the assumption would be that this depends highly on the user, their projects and style of inquiries.",
                  "score": 1,
                  "created_utc": "2026-02-15 18:45:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hqqqk",
          "author": "CategoryFew5869",
          "text": "Yeah this is because of the context window (memory). As the window moves, it starts to forget older things. I would recommend you try exporting the conversation and then reimporting it in a new chat session.",
          "score": 1,
          "created_utc": "2026-02-15 11:33:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hshs1",
          "author": "DanChed",
          "text": "Yep and I love it. It means its a test of my memory context window and then once Im done, I load a new chat and get it review afterwards.",
          "score": 1,
          "created_utc": "2026-02-15 11:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5js9w9",
              "author": "Only-Frosting-5667",
              "text": "Totally agree ‚Äî branching or restarting does help.  \nThe tricky part is knowing¬†*when*¬†to do it.\n\nMost people only notice drift after coherence is already compromised.\n\nI‚Äôve been experimenting with visualizing session load in real time so you can see the ‚Äúyellow zone‚Äù before things degrade. It changes the decision from reactive to proactive.\n\nIf you're curious, I built a small in-ChatGPT indicator for this:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love your take, since you already work with structured resets.",
              "score": 2,
              "created_utc": "2026-02-15 18:31:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hu6bv",
          "author": "Sea-Sir-2985",
          "text": "you're not imagining it, this is a well-documented behavior with transformer-based models... the attention mechanism fundamentally struggles to maintain equal weighting across very long contexts so earlier instructions get \"diluted\" as the conversation grows\n\nthe practical fix i've settled on is treating conversations as disposable. instead of one long session i break things into focused chunks, each with the full context pasted at the top. sounds wasteful but it's way more reliable than hoping the model remembers what you said 30k tokens ago\n\nclaude handles this slightly better in my experience, especially opus with extended thinking... but even there once you hit 80k+ tokens the same drift happens. it's just physics of how attention works, not a bug anyone can fully fix",
          "score": 1,
          "created_utc": "2026-02-15 12:03:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtgpj",
              "author": "Only-Frosting-5667",
              "text": "Exactly ‚Äî this is fundamentally an attention distribution issue, not a ‚Äúmemory bug.‚Äù\n\nI like how you framed it as physics rather than failure.\n\nBreaking conversations into disposable chunks is probably the most reliable mitigation today. It trades efficiency for deterministic behavior.\n\nWhat I find interesting is that the degradation curve is gradual, not binary. There‚Äôs usually a long ‚Äúyellow zone‚Äù before actual failure ‚Äî but the interface gives no signal that you‚Äôre entering it.\n\nThat silent transition is the part that fascinates me.\n\nCurious ‚Äî do you ever feel there‚Äôs a predictable threshold where quality starts bending, or does it vary heavily by task type?",
              "score": 1,
              "created_utc": "2026-02-15 18:37:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jdmhk",
          "author": "DuckMcWhite",
          "text": "Does Branching into a new chat actually help fix this?",
          "score": 1,
          "created_utc": "2026-02-15 17:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juzrf",
              "author": "Only-Frosting-5667",
              "text": "Short answer: yes ‚Äî but only partially.\n\nBranching helps because you reset the active attention window. You‚Äôre effectively reducing accumulated context weight.\n\nThe catch is this:  \nMost people don‚Äôt branch early enough.\n\nDegradation is gradual, not sudden. There‚Äôs usually a ‚Äúyellow zone‚Äù where coherence is already bending slightly, but not obviously broken yet.\n\nThat‚Äôs the tricky part ‚Äî the interface gives no signal for when you‚Äôve entered that zone.\n\nI‚Äôve been experimenting with visualizing session load directly inside ChatGPT to surface that threshold earlier.\n\nIf you‚Äôre curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nBut yes ‚Äî branching absolutely improves reliability compared to one massive continuous thread.",
              "score": 2,
              "created_utc": "2026-02-15 18:44:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qxxg2",
          "author": "recoveringasshole0",
          "text": "exasperated.gif",
          "score": 1,
          "created_utc": "2026-02-16 20:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wqjbv",
          "author": "emilioml_",
          "text": "Not only very long sessions if you continue in a new chat , sometimes degrades too",
          "score": 1,
          "created_utc": "2026-02-17 18:32:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61oonx",
              "author": "Only-Frosting-5667",
              "text": "Short answer: yes ‚Äî and that‚Äôs the interesting part.\n\nStarting a new chat resets the active attention window, but it doesn‚Äôt magically restore structure.\n\nIf the underlying workflow isn‚Äôt explicit (constraints, scope, canon, versioning), degradation can still happen ‚Äî just in a different way.\n\nLong sessions dilute.  \nFresh sessions can lose continuity.\n\nBoth are workflow issues, not just model issues.\n\nThat‚Äôs why I‚Äôve started thinking less in terms of ‚Äúnew chat vs long chat‚Äù and more in terms of session governance.\n\nCurious how you usually structure your follow-up chats.",
              "score": 1,
              "created_utc": "2026-02-18 13:06:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61tn2b",
                  "author": "emilioml_",
                  "text": "They aren't life depending..but I usually start \" regarding docker container xxx . What about xxx \" and I work from there.   Or if there is a long subject I will try to summarize or \"export\" a codex and just copy paste it into the new chat . And work from there",
                  "score": 1,
                  "created_utc": "2026-02-18 13:34:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o638alv",
          "author": "CFG_Architect",
          "text": "in large sessions (100k+ tokens) critical problems begin if there are conflicts in the logic chains:\n\ni.e. when something you said before starts to contradict what you are saying now, but you are sure that you are right.\n\nto prevent this, you need to periodically summarize the session (across all contexts) and draw conclusions from the AI, and ask it if there are any contradictions/conflicts - and fix them together.\n\nthis helps almost always, even in sessions with 1m+ tokens (when the session wipes out the context that has gone beyond the limits).",
          "score": 1,
          "created_utc": "2026-02-18 17:35:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67mqha",
          "author": "Prestigious_Tip_6744",
          "text": "Agreed, even their answers is too shorter, I guess chatGPT is weak in case of descriptive explanation.",
          "score": 1,
          "created_utc": "2026-02-19 08:50:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68lmtr",
          "author": "Lemonshadehere",
          "text": "Yeah this is definitely a thing\n\ni've noticed it kicks in around the 30-40k token mark. responses get vaguer, it starts forgetting instructions you gave earlier, and sometimes it'll contradict stuff it said 20 messages ago\n\nmy theory is the model starts deprioritizing older context to handle the newer stuff. like it's still technically \"in context\" but it weighs recent messages way heavier\n\nwhat i do now is just start a new chat once i hit that point and summarize the key points from the previous session. annoying but it keeps responses sharp\n\nalso noticed this happens faster if the conversation jumps around topics a lot vs staying focused on one thing. probably harder for it to maintain coherence when context is scattered\n\nwould be cool if there was a way to \"pin\" certain instructions so they don't degrade but afaik that's not a thing yet",
          "score": 1,
          "created_utc": "2026-02-19 13:33:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e76cz",
          "author": "moxiemo99",
          "text": "Yes, it definitely degrades. When you notice it is doing this, recalibrate. Tell it what it's doing, ask it does it have confidence in its latest response and them have it check and double check the response for correctness and to remove all hallucination or unverifiable information and then try to keep the chat going as long as possble before you have to start all over. I've tried to get it to create a script to take into the next chat once the current one slows down, but I haven't had much success, I haven't liked the results of said prompts.",
          "score": 1,
          "created_utc": "2026-02-14 20:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fqzss",
              "author": "hellomistershifty",
              "text": "If it's starting to do this, it's too late and you need a new conversation with a fresh context. It can't remove information from its context.\n\nEven getting it to summarize well enough for a new conversation can be hard if it's already tripping. The commands to condense context in tools like Cursor or Codex work well, but it calls another LLM to do it and is expensive and slow. I don't know what the best answer is",
              "score": 2,
              "created_utc": "2026-02-15 01:30:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ehh3v",
              "author": "Only-Frosting-5667",
              "text": "I‚Äôve tried a similar ‚Äúrecalibration‚Äù approach.  \nIt helps temporarily, but I‚Äôve found that once early constraints start fading, the recovery isn‚Äôt fully reliable.  \nAlmost like the model technically still remembers ‚Äî but stops prioritizing correctly.\n\nThe cross-thread script idea is interesting. I‚Äôve had mixed results too. It‚Äôs hard to preserve both structure and nuance when migrating context.\n\nDo you usually restart at a fixed point (like a token threshold), or only once quality visibly drops?",
              "score": 1,
              "created_utc": "2026-02-14 21:00:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5enkyy",
                  "author": "moxiemo99",
                  "text": "I only restart if the script starts to drag. Believe it or not, if you send the model through some rigor, questioning its process, reminding it what its task is it will correct itself. After doing that, you then have the model repeat the task and then check itself to ensure it followed all.prior instructions. I also provide it an example of when it was doing the right thing- copy and paste.  This works amazingly well. Don't assume with the model, walk it through to get it back on track. I've had amazing results doing this.",
                  "score": 0,
                  "created_utc": "2026-02-14 21:33:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5g7ly1",
          "author": "TrainingEngine1",
          "text": ".",
          "score": 0,
          "created_utc": "2026-02-15 03:23:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h7ko1",
              "author": "Only-Frosting-5667",
              "text": "This is an impressive methodology.\n\nWhat you described almost reads like building a version-controlled operating system on top of a chat interface.\n\nThe interesting part for me is that the governance layer becomes necessary precisely because long-context drift is predictable.\n\nDo you find that even with charters and strict phase boundaries, subtle prioritization decay still appears over time?",
              "score": 1,
              "created_utc": "2026-02-15 08:29:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5h7wpz",
                  "author": "TrainingEngine1",
                  "text": "Why are you pasting a ChatGPT generated reply? Just realized your original post is also LLM generated.",
                  "score": 1,
                  "created_utc": "2026-02-15 08:32:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r3qib4",
      "title": "Tested updated Deep Think (Gemini 3.1 Pro) vs. GPT 5.2 Pro",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "author": "PerformanceRound7913",
      "created_utc": "2026-02-13 14:24:53",
      "score": 29,
      "num_comments": 10,
      "upvote_ratio": 0.86,
      "text": "I tested both on a data science problem. Updated Deep Think is significantly better than its previous version, but the accompanying harness is still not very strong. GPT 5.2 Pro, on the other hand, thinks longer and uses tools much more efficiently. It actually solves your problem end to end. \n\nhttps://preview.redd.it/483qat63u9jg1.png?width=1228&format=png&auto=webp&s=a674146c9406fcef251310f5e764b4cd17b2076e\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o562rcj",
          "author": "qualityvote2",
          "text": "u/PerformanceRound7913, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 14:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o566uhz",
          "author": "Ari45Harris",
          "text": "I‚Äôve noticed that ChatGPT reasoning models have a better brain than most other AI models",
          "score": 9,
          "created_utc": "2026-02-13 14:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5aoh2b",
          "author": "sprucenoose",
          "text": "GPT 5.2 Pro Extended Thinking is surreal to me. I have a hard time not characterizing it as a form of AGI.",
          "score": 3,
          "created_utc": "2026-02-14 05:43:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fpy2r",
              "author": "RoughlyCapable",
              "text": "This is very underdiscussed IMO, regardless of whether they actually are AGI GPT5-Pro models are the first models where I genuinely find it hard to distinguish them between what I thought AGI was capable of.",
              "score": 0,
              "created_utc": "2026-02-15 01:23:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o1nwu",
          "author": "TrainingEngine1",
          "text": "5.2 Pro with Extended Thinking? Or by Deep Think do you mean Deep Research?\n\nBecause I find 5.2 Pro with Extended Thinking far better than the ChatGPT Deep Research which actually sucked. It didn't let me pick a model for it either (I would've done 5.2 Pro) which probably relates to the quality drop I noticed. Agent Mode wasn't much better where I couldn't pick a model too.",
          "score": 1,
          "created_utc": "2026-02-16 11:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57rfjo",
          "author": "Simlah",
          "text": "How good is it for forex EAs?",
          "score": 0,
          "created_utc": "2026-02-13 19:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585hx2",
          "author": "Deep_Somewhere2419",
          "text": "How does your prompt structure",
          "score": -3,
          "created_utc": "2026-02-13 20:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585ik7",
          "author": "Deep_Somewhere2419",
          "text": "Looks",
          "score": -3,
          "created_utc": "2026-02-13 20:28:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6zs2g",
      "title": "Why I‚Äôm Moving Most of My Workflow from Claude to Codex (Non-Developer Perspective)",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6zs2g/why_im_moving_most_of_my_workflow_from_claude_to/",
      "author": "tgandur",
      "created_utc": "2026-02-17 07:37:07",
      "score": 27,
      "num_comments": 9,
      "upvote_ratio": 0.8,
      "text": "**TL;DR:** I‚Äôm a non-developer using LLMs for structured, metadata-heavy workflows (literature reviews, lecture prep, Obsidian). Claude impressed me at first, but I encountered workflow shortcuts and vault instability over time. After testing the new Codex Mac app on GPT Pro, I found it more predictable and compliant with strict step-by-step processes. This is about workflow fit, not model superiority.\n\n---\n\nI‚Äôm not a developer. I use LLMs primarily for literature reviews, structured lecture preparation, system organization, VPS setup, and managing a complex Obsidian vault with heavy metadata.\n\nFor a long time, I was a user of Claude (Opus/Max). Initially, it was impressive. But my workflows are strict, step-by-step, and highly defined. Over time, I noticed Claude would sometimes optimize the workflow rather than execute it exactly as written. Even with detailed instructions, it occasionally took shortcuts.\n\nThe breaking point for me was Obsidian vault stability. I experienced miswritten front matter, invented tags, and gradual structural drift. I kept expanding the instruction files to add guardrails, but increasing complexity seemed to reduce stability. Simplifying the vault structure didn‚Äôt fully solve it. Heavy workflow sessions also quickly consumed the Max quota.\n\nAfter the release of the new Codex Mac app, I decided to test it on the GPT Pro plan.\n\nWhat stood out:\n\n1. It respects explicitly defined workflows. When constraints are clear, it follows them.\n2. It adjusts quickly when corrected and stays within the structure.\n3. It proactively suggests system-level improvements (e.g., weekly vault health checks, metadata validation).\n4. It documents its actions extensively, which makes multi-session continuation easier.\n5. It performs reliably even with a minimal Agent MD configuration.\n\nFor literature review pipelines and structured planning, this predictability matters. I need a model that consistently executes predefined processes, rather than compressing or optimizing them away.\n\nTo be fair, Claude remains strong in writing and can feel more natural stylistically in some contexts. This isn‚Äôt a ‚ÄúClaude vs. Codex‚Äù claim. It‚Äôs more about workflow fit. For my use case, Codex currently feels more controllable and stable for long-horizon, metadata-heavy systems.\n\nIt‚Äôs not flawless. It still makes simple mistakes. The difference, in my experience, is that those errors are usually local and easy to correct, rather than structural.\n\nI‚Äôm curious how others here approach complex, structured workflows with either system, especially outside pure coding use cases.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6zs2g/why_im_moving_most_of_my_workflow_from_claude_to/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5tvlyg",
          "author": "qualityvote2",
          "text": "‚úÖ u/tgandur, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-17 07:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tzh9l",
          "author": "Jessgitalong",
          "text": "Honestly, a less thinking, more doing model is right for what you need.",
          "score": 6,
          "created_utc": "2026-02-17 08:13:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uadkt",
          "author": "IversusAI",
          "text": "I have found a similar experience with Claude versus Codex or GPT 5.2. The models are better at different things. This is one reason why I stay with Cursor, at least right now, because I need the right model for the job and that changes often throughout the day.",
          "score": 3,
          "created_utc": "2026-02-17 09:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u2ysw",
          "author": "Brice_Leone",
          "text": "Thanks for the detailed info; really useful for non-coders like myself\n\nquick question (apologies if I misunderstood): what's a concrete use case where you found GPT to be more valuable?\n\nFor context, I'm a project manager - quite beginner on the technical side and I'm considering switching from Gemini to either Claude Code or Codex. I've found that even Gemini, when given enough context, can really help manage a project end to end. example I'll feed it the prerequisites of a client solution, then ask as many questions as possible to prepare for a workshop and make sure the need is clearly scoped. It works well, but Gemini has become quite lazy with shorter and less detailed outputs\n\nI'm interested in Claude Code for its plan mode, skills and overall structure. But curious- for this kind of use case (project scoping, requirement analysis, workshop prep), would you say Codex is the better option?",
          "score": 2,
          "created_utc": "2026-02-17 08:47:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60qc0p",
              "author": "tgandur",
              "text": "Great question ‚Äî your use case (project scoping and workshop prep) is actually a good test case.\n\nA concrete example where GPT/Codex felt more valuable for me was in structured requirement extraction.\n\nLet‚Äôs say a client sends you a messy brief with goals, constraints, budget notes, and some vague expectations. With Codex, I can define a strict structure like:\n\n1. Extract business objectives  \n2. Extract constraints (budget, timeline, tech limits)  \n3. Identify missing information  \n4. Generate clarification questions grouped by category  \n5. Produce a clean workshop agenda draft  \n\nWhen I give that as a procedural workflow, it tends to follow it very literally and consistently. That‚Äôs where I noticed the difference ‚Äî less ‚Äúreinterpretation,‚Äù more step-by-step execution.\n\nHypothetically, where Claude has struggled for me is when it optimizes at the reasoning level rather than executing the workflow literally. For example, in a literature pipeline, I might first generate an AI-produced literature review from a core set of papers. Then I expand the corpus by collecting additional papers and creating detailed notes and annotations. I explicitly define a separate step: ‚Äúgenerate a concept map using the existing review plus these new notes and annotations.‚Äù\n\nAs new sources and annotations are introduced, the concept map should evolve structurally. However, Claude sometimes assumes the map would largely replicate the existing review and either compresses or skips the step. From its perspective, it‚Äôs avoiding redundancy. From mine, it‚Äôs bypassing a required artifact ‚Äî since the added annotations are meant to reshape the conceptual structure, not merely restate it.\nThat distinction matters in strict workflows: I don‚Äôt want the model deciding whether a step is logically redundant. I want it to execute every defined artifact, even if they look related.\n\nIf your scoping process relies on templates and repeatable structure, Codex may feel more controllable. If you prefer fast conversational back-and-forth exploration, Claude Code might feel more fluid.\n\nFor structured project definition specifically, I‚Äôd lean on Codex.",
              "score": 3,
              "created_utc": "2026-02-18 08:27:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5zpqi1",
          "author": "Novel_Blackberry_470",
          "text": "I think the key point is workflow control versus raw creativity. For structured systems with strict metadata and long horizon consistency, predictability probably matters more than style. It sounds less about which model is smarter and more about which one respects constraints without trying to be clever. That distinction is useful for anyone building repeatable processes rather than just generating text.",
          "score": 2,
          "created_utc": "2026-02-18 03:40:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vwoa1",
          "author": "IndyHCKM",
          "text": "Definitely feel like GPT provides better output if you simply want to ask and wait. Claude iterates so much faster though. In the time GPT or Codex get me an output, I can often do 3 or 4 rounds of work with Claude, Code, or Cowork and the output compared between 1 turn of GPT to 3 or 4 turns of Claude is totally different.\n\n\nBut when I'm busy and can't chat much, GPT is great.",
          "score": 1,
          "created_utc": "2026-02-17 16:07:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xf2i4",
          "author": "cheesecakegood",
          "text": "How much of this is possibly recency or newness bias, because you mentioned being initially impressed by Claude as well? Curious how long you‚Äôve been testing",
          "score": 1,
          "created_utc": "2026-02-17 20:27:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60nwz3",
              "author": "tgandur",
              "text": "My experience with GPT is still new, just a week, so there might be a \"novelty effect.\" I was initially impressed with Claude and still am, especially by its outputs. However, the issues I noticed early on, especially with Obsidian, were always present in Claude. I thought these were typical of LLMs until I encountered Codex.",
              "score": 1,
              "created_utc": "2026-02-18 08:04:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6ht58",
      "title": "Are there meaningful benefits for using Perplexity/ChatGPT's desktop apps (vs. web interface ), like Claude desktop app?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6ht58/are_there_meaningful_benefits_for_using/",
      "author": "TheLawIsSacred",
      "created_utc": "2026-02-16 18:35:37",
      "score": 19,
      "num_comments": 17,
      "upvote_ratio": 0.93,
      "text": "Power users, please advise.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6ht58/are_there_meaningful_benefits_for_using/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5q7sy1",
          "author": "qualityvote2",
          "text": "u/TheLawIsSacred, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-16 18:35:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qseyd",
          "author": "darkyy92x",
          "text": "IMO ChatGPT desktop app is worse than web. You can't control the thinking (extended thinking etc), the app feels slower than web etc.\n\nOne advantage would be to use the keyboard shortcut to instantly start a conversation or sending screenshots easier.",
          "score": 11,
          "created_utc": "2026-02-16 20:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aygs2",
              "author": "TheLawIsSacred",
              "text": "TY for your input. \n\nBTW: Have you been able to connect any MCP Servers using either the ChatGPT web interface or the desktop application? \n\nI know the ChatGPT Plus desktop app had a buggy \"Developer\" mode which in theory allowed you to do this, but I last looked into it about 2 months ago or so, and just found it unreliable + not friendly to a vibe coder.",
              "score": 1,
              "created_utc": "2026-02-19 20:32:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5rbxjk",
          "author": "lyncisAt",
          "text": "On an Apple Silicon Mac, the app is much more performant (especially for long chats) than the web or Windows app. Night & Day",
          "score": 8,
          "created_utc": "2026-02-16 21:49:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rzmb0",
          "author": "ThePlotTwisterr----",
          "text": "there is for codex, having the power to use mcps and your terminal means your AI can do everything for you. i use codex for the dumbest shit sometimes. like installing and compiling a c++ project with messy dependencies and versioning, or organizing my files, or even just dumb things like fixing errors on arch linux.\n\nyou can use the codex cli and swap the model to normal gpt too, but i cannot imagine ever using a tool that can‚Äôt use my terminal these days, i would just lose so much power",
          "score": 5,
          "created_utc": "2026-02-16 23:55:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yn0ei",
              "author": "TheLawIsSacred",
              "text": "Thanks. I had a busy few weeks, but I'm finally going to learn how to use Codex and - yikes - add another member to my key AI Panelists (right now, Claude Desktop app is my \"First Among Equals,\" but all the constant chatter over Codex, sustained over enough time to make me think it's not just hype, means I need to look, and maybe see if there is a new \"First Among Equals\" in town, lol).\n\nIf you have a few seconds, any tips that you can send my way, to ease any friction points for a starter or beginner?",
              "score": 1,
              "created_utc": "2026-02-18 00:08:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s7q9a",
          "author": "elaineisbased",
          "text": "It might make it ever so slightly easier to attach a file or maybe have better performance in a full web browser but I don‚Äôt know. I am a copilot user in regularly use the desktop app but copilot mode in Microsoft edge will help switch your search over to Bing if it would provide better results than AI. For example if you just typed in Twitter it would make more sense to show you search results so you can get to Twitter",
          "score": 3,
          "created_utc": "2026-02-17 00:42:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s2nlc",
          "author": "manjit-johal",
          "text": "For most workflows the web app is fine, but desktop apps can help if you rely on global shortcuts, mic access, or quick window switching without browser overhead. I‚Äôve found the main difference is less about model quality and more about UX friction; if you‚Äôre constantly context-switching, native apps feel faster even if the backend is identical. ",
          "score": 1,
          "created_utc": "2026-02-17 00:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tsg7s",
              "author": "AI-Coming4U",
              "text": "This is why I use the apps for Claude and ChatGPT. With a small city of tabs open, I don't want to search for AI. And when I go to the native app, I feel like I'm working with Claude or GPT. Then I go back to solo mode in my browser. \n\n",
              "score": 2,
              "created_utc": "2026-02-17 07:08:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ynyv0",
              "author": "TheLawIsSacred",
              "text": "I mean Claude desktop app is genuinely useful, so I was just curious if Perplexity's or ChatGPT's offer similar features as Claude, such as the ever expanding number of Connectors and Extensions, or even more old school MCP Server connectors. \n\nComet is a separate issue and I sometimes wonder if I should check it out.",
              "score": 1,
              "created_utc": "2026-02-18 00:13:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u1kp8",
          "author": "i_sin_solo_0-0",
          "text": "Bruh I‚Äôll tell ya perplexity if you can get used the comet app is fun",
          "score": 1,
          "created_utc": "2026-02-17 08:33:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o696kxl",
          "author": "TrainingEngine1",
          "text": "The ChatGPT desktop app is very flawed.\n\nI'm shocked they still haven't fixed this but you can't even change the model within a chat for a project. Utterly insane and it's been like that for months on end. \n\n\n\n\n The browser version (make it into a PWA) is a lot better. There's some other weird quirks with the desktop app that I forget. \n\nAs for Perplexity, I have no damn idea why people bother with that garbage company or app. Unless it's relating to some pricing reason, but typically I assume that means your data is far more likely to be sold & passed around.",
          "score": 1,
          "created_utc": "2026-02-19 15:25:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ay5yq",
              "author": "TheLawIsSacred",
              "text": "Thanks for your input. \n\nHave you been able to connect any MCP Servers using either the ChatGPT web interface or the desktop application? \n\nI know the ChatGPT Plus desktop app had a buggy \"Developer\" mode which in theory allowed you to do this, but I last looked into it about 2 months ago or so, and just found it unreliable + not friendly to a vibe coder.",
              "score": 1,
              "created_utc": "2026-02-19 20:30:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6b7mmo",
                  "author": "TrainingEngine1",
                  "text": "I have no experience using an MCP server so I can't say",
                  "score": 2,
                  "created_utc": "2026-02-19 21:16:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5u9xqj",
          "author": "raholl",
          "text": "no there are no benefits, they make desktop app for a reason to not have any meaningful benefits... /s",
          "score": 1,
          "created_utc": "2026-02-17 09:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ynwa2",
              "author": "TheLawIsSacred",
              "text": "I mean Claude desktop app is genuinely useful, so I was just curious if Perplexity's or ChatGPT's offer similar features as Claude, such as the ever expanding number of Connectors and Extensions, or even more old school MCP Server connectors. \n\nComet is a separate issue and I sometimes wonder if I should check it out.",
              "score": 1,
              "created_utc": "2026-02-18 00:13:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6dkcc",
      "title": "Best AI Agent for Website Development",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6dkcc/best_ai_agent_for_website_development/",
      "author": "SnoreLordXII",
      "created_utc": "2026-02-16 16:04:21",
      "score": 15,
      "num_comments": 29,
      "upvote_ratio": 0.84,
      "text": "I am a physician working on building an educational website. I have zero coding ability. I have started a website which has the basics on squarespace but overall looks like trash. I have used Codex to fix some of the tools on the website and that has worked well. What I really need is just to make it look professional. I used GPTpro to give suggestion on what to be improved after taking screen shots and then tried to get to use agent mode to actually implement those changes but it failed pretty miserably. It would do 1 small change and then get stuck. Is there a better AI agent out there for this task?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6dkcc/best_ai_agent_for_website_development/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5pb0ie",
          "author": "qualityvote2",
          "text": "u/SnoreLordXII, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-16 16:04:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ph7dg",
          "author": "mike8111",
          "text": "With limited knowledge you'll always struggle. Claude code does okay with this, the problem most people have is they can't describe what they want well enough for the AI to do what it needs to.\n\nI use skool for educational sites, but there are plenty of options. The move is to use squarespace to make the front page and then link to skool for the educational piece. \n\nThis is a problem that is already well solved, it's cheaper, easier, and more efficient to use existing solutions.",
          "score": 6,
          "created_utc": "2026-02-16 16:32:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pjmwf",
              "author": "SnoreLordXII",
              "text": "Gotcha, so saying \"make this look mo better\" is not sufficient? I'll look into skool.",
              "score": 3,
              "created_utc": "2026-02-16 16:44:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pcsc1",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 3,
          "created_utc": "2026-02-16 16:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qmexo",
              "author": "ChatGPTPro-ModTeam",
              "text": "Your submission to r/ChatGPTPro has been removed due to violating our spam and self-promotion policy. We strictly enforce the ‚Äú1/10th Rule,‚Äù limiting self-promotion to no more than 10% of your participation. Direct links solely promoting your projects or products are not permitted without meaningful context demonstrating their advanced value.\n\nPlease see our self-promotion guidelines or contact moderators for clarification.",
              "score": 1,
              "created_utc": "2026-02-16 19:44:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ph5wb",
          "author": "calben99",
          "text": "For website development, I've had good results with Claude for complex logic and GPT-4 for rapid prototyping. The key is being specific about your stack and requirements. AI agents work best when you break down the project into discrete tasks rather than asking for everything at once.",
          "score": 3,
          "created_utc": "2026-02-16 16:32:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qjit4",
          "author": "SexyDiscoBabyHot",
          "text": "This is a tough ask if you're not familiar with web dev. But try including example websites in your prompt. \n\nAlso, don't forget you'll be the one needing to update it all the time, so don't create a rod for your back. Make it as clean as possible. Or, try WordPress as an alternative. Much easier to manage for a lay person.",
          "score": 3,
          "created_utc": "2026-02-16 19:30:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sdq14",
          "author": "toneloc3131",
          "text": "Lovable?",
          "score": 2,
          "created_utc": "2026-02-17 01:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tqc5z",
          "author": "Atoning_Unifex",
          "text": "Anthropic Claude",
          "score": 2,
          "created_utc": "2026-02-17 06:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pt5gg",
          "author": "tiskrisktiskagain",
          "text": "I use ChatGPT Pro in a project folder. I upload my entire website in a zip file. And then screenshot the changes I want to make. It does a really good job.",
          "score": 2,
          "created_utc": "2026-02-16 17:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ziyqz",
              "author": "elephantsonparody",
              "text": "That‚Äôs a great idea! I have been editing my store in atlas with gpt open but this way they could see the whole thing! Smart! Thanks for the tip",
              "score": 1,
              "created_utc": "2026-02-18 02:59:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pdwsc",
          "author": "themoregames",
          "text": "What a funny coincidence. \n\nI am a coder working on building a private practice. I have zero medical training. I have started building a operating theater which has the basics on neurosurgery but overall looks like a junkyard. I have used Codex to fix some of the surgical instruments and that has worked well. What I really need is just to make it look professional.",
          "score": 2,
          "created_utc": "2026-02-16 16:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pj3nd",
              "author": "SnoreLordXII",
              "text": "Stakes are not quite as high lol. The nuts and bolts of what I have actually work well.",
              "score": 8,
              "created_utc": "2026-02-16 16:41:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5psu7r",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-16 17:26:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5pnpax",
                  "author": "themoregames",
                  "text": "Same here.\n\nNow that you mention them... nuts and bolts could really help me speed up the process with aneurysms. Excuse me, I'm off to the hardware store.",
                  "score": 0,
                  "created_utc": "2026-02-16 17:02:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pkl2x",
          "author": "ExcessiveEscargot",
          "text": "When all you have is a hammer, everything looks like a nail.\n\nJust find a good template online from an artist that is good at their craft? Find one that looks good and best fits what you're going for, then tweak it to your liking.",
          "score": 1,
          "created_utc": "2026-02-16 16:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q78lk",
          "author": "gamgeethegreatest",
          "text": "What kind of educational website? I'm curious, and have also built plenty of websites in square space, and I've done bigger projects using AI agents outside of WYSIWYG editors (current project is a full workforce management application im building with Claude code and codex). \n\nDepending on what you're trying to do I might be able to give you some advice or even help out. \n\nYou can DM if you don't want to put it out there publicly. I run a couple vape shops for a living and have a ton of dead time, and I love working on stuff like this for fun.",
          "score": 1,
          "created_utc": "2026-02-16 18:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r2e57",
          "author": "niado",
          "text": "Codex5.3 is the best for any development. There‚Äôs a codex skill for UI design, that should let it construct a pretty webpage, if it can‚Äôt already.",
          "score": 1,
          "created_utc": "2026-02-16 21:03:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rni3d",
          "author": "RaStaMan_Coder",
          "text": "Visual is always difficult, but you can just use something like Codex, Claude Code or Copilot, ask it to \"make it look more modern & professional\" and then just give feedback until you like it.\n\nIf you need it to look a specific way Figma+MCP is probably the way but that is more difficult.",
          "score": 1,
          "created_utc": "2026-02-16 22:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s350x",
          "author": "TraditionalJob787",
          "text": "This requires more than 1 tool. Each tool has its own use and combined they get the job done. Workflow is dependent on building on the core competencies of each tool in a linear sequence.",
          "score": 1,
          "created_utc": "2026-02-17 00:15:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tkjg2",
          "author": "addywoot",
          "text": "Try lovable to build the prototype and export code into Wordpress.",
          "score": 1,
          "created_utc": "2026-02-17 06:00:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tuvhc",
          "author": "EfficientMilk7421",
          "text": "Use replit!!!",
          "score": 1,
          "created_utc": "2026-02-17 07:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z8jsw",
          "author": "Mr_Self_Healer",
          "text": "In my experience I get pretty good results using Gemini 3 Pro, but I know a lot of ppl like Codex/Claude. I don't know what it is but with Gemini 3 Pro I can be more.. for lack of a better word.. vague? Gemini 3 Pro, for me, has an easier time inferring what I want given plain english. Given the way I tend to prompt cursor, Gemini 3 Pro seems to do a better job than other models. I think there are a lot of great models to use, but how you prompt will matter",
          "score": 1,
          "created_utc": "2026-02-18 02:03:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4n4t7",
      "title": "Best AI for Google Sheets",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "author": "Halvey15",
      "created_utc": "2026-02-14 15:15:48",
      "score": 15,
      "num_comments": 18,
      "upvote_ratio": 0.86,
      "text": "I'm fairly inexperienced with AI so I apologize if there are some dumb questions in here. \n\nLong story short, I've been using ChatGPT for about a year to assist with B2B sales. I have a thread where I can post a company's website and it will return an analysis of that company, what their needs are, and where our best in might be. I have a thread for prospect discovery. And I have a thread for drafting quick emails, among a few other threads.\n\nA few weeks ago I had the idea of trying to create a CRM within ChatGPT, to expand on the Google Sheet that I have used over the years for organization, and so far the AI has been useful. But I have some concerns with long term viability:\n\n1.) I've noticed over the past year that ChatGPT does not do well on long threads, whether that be slowing down or losing context. I'm afraid that I'm going to need to create new threads so often that it won't be worth my time, and that I may also lose context while switching over to a new thread.\n\n2.) ChatGPT apparently can't share information between threads? It would be nice if my emails thread had access to my CRM thread. That way I wouldn't have to provide context for each email.  \n\n3.) Redundancy. I'm still using the Google Sheet as a backup, so I'm entering info on the Google Sheet and then pasting it into ChatGPT. If we could remove a step there, that would also be nice. \n\nI really just want something where I can enter the info in Google Sheets, and then find an AI that can get live access to the the Google Sheet. So when I ask it a question or ask it for tasks for the day, it has all of that information without having to load all of the prospect info into a thread. \n\nLike I said, I haven't explored the AI world too much. I just learned about Claude the other day. I downloaded Claude and gave it permission to view my Google Drive. But it is telling me that it can't read Google Sheets? I knew Google had an AI, but didn't realize that Gemini was a full chatbot. So maybe that is the right move? \n\nDoes anyone have suggestions before I put a few hours into just experimenting?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5cmhn5",
          "author": "qualityvote2",
          "text": "u/Halvey15, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-14 15:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cwy3l",
          "author": "mgoulart",
          "text": "Google Gemini has built in Sheets integration.",
          "score": 5,
          "created_utc": "2026-02-14 16:10:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cxkw6",
              "author": "Halvey15",
              "text": "I figured it did. I'll have to play around with Gemini a bit to see if that is a better fit for me. \n\nThe massive advantage that ChatGPT has right now is that it has a year's worth of context, so it knows my company so well at this point. It would be difficult to start over from scratch again.",
              "score": 2,
              "created_utc": "2026-02-14 16:13:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dihva",
                  "author": "Odd-Opinion-5105",
                  "text": "There was just a thread on exporting data from chat got to google",
                  "score": 2,
                  "created_utc": "2026-02-14 17:58:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5gb597",
                  "author": "niado",
                  "text": "Try NotebookLM !",
                  "score": 1,
                  "created_utc": "2026-02-15 03:49:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cofz9",
          "author": "Subject-Street-6503",
          "text": "I believe ChatGPT has a connector that can read directly from GDrive  \nYou should be able to find it in account settings",
          "score": 3,
          "created_utc": "2026-02-14 15:26:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cwyhx",
              "author": "Halvey15",
              "text": "That's something I definitely should have thought of before posting this lol. That seems to be a viable option. I am still interested in learning more about the other AIs, to see if there might be a better fit though. \n\nThank you!",
              "score": 1,
              "created_utc": "2026-02-14 16:10:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5gb46k",
              "author": "niado",
              "text": "It does but it barely works. It sucks because when it does work it‚Äôs amazing.",
              "score": 1,
              "created_utc": "2026-02-15 03:49:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d1a1j",
          "author": "JamesGriffing",
          "text": "Google has something called Google App Scripts that allows us to add functionality to many Google products. One of them being Google Sheets.\n\nWith Google app scripts you're able to create custom formulas, or even user interfaces like a chat side bar.\n\nChatGPT is available to be used via OpenAI's API.\n\nSo this means you're able to use ChatGPT directly within Google Sheets. ChatGPT itself can guide you on how to set this up and write the scripts needed for you.\n\nperhaps in one of the threads that contains a lot of this context on why you use the Google sheet you can ask something like \"Based on our activity, and what I am trying to achieve with Google Sheets, educate me on how I can best utilize Google App Scripts with the OpenAI API. Assume I am a beginner\"\n\nIf this is something others would find useful then I can create a post/guide going over all of this in far more detail.",
          "score": 3,
          "created_utc": "2026-02-14 16:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cxdcm",
          "author": "BYRN777",
          "text": "If you're working with Google Sheets, the best AI is Gemini because it's now in every native Google app, from YouTube to Google Keep, Google Calendar, Google Photos, Google Docs, Google Slides, and Google Sheets. We can't have a Gemini within Google Sheets itself; you can either upload a Google Sheets document or give a Google Drive. When you're typing up your prompt, you can select the file from Google Drive, then open it and work with it. Any live changes you make with Google Workspace apps will update the file.\n\nFor instance, let's say you're working on a thread in Google Docs, asking questions or getting info, and you make a change in Google Sheets, it will update in the thread at the same time. Native Google apps can change them. The way I do this is: let's say they upload a Google Doc. I ask it to make these changes, and then open it in Canvas. I've attached a document. In Google Drive, you can select your document. I give it my prompt, select Canvas at the same time, tell it to do this, and then open it in Canvas, because from there, you can see the changes it has made.\n\nI haven't personally worked with Google Sheets. I mostly work with Google Slides and Google Docs, and it's so seamless and smooth that it works perfectly. But I believe Google Sheets is just because Gemini is natively within each Google Workspace app, and there's seamless integration. That's why I think Gemini would be the best option. At the same time, another reason is that Gemini's context window is 1 million tokens. \n\nChatGPT is great, but if you're not using the API, your context window is limited. GPT 5.2 thinking is limited to 196,000 context tokens, but it's limited to a 196,000-context window. However, an API can be up to 400,000, which is a lot. But in Gemini, within the chatbot itself (without using the API), the context window is 1 million, so it can read, synthesize, analyze, understand, and remember much more information.\n\nIn long-term threads and working with larger files/documents like PDFs, Google Sheets, or native Google Labs, Gemini is the best. I would never trust giving ChatGPT, for example, access to 20-30 page PDF articles and then asking questions, working with them, or using them in a paper or report. But I would trust Gemini much more because of the context window, because I know I can tell confidently that it actually reads and assesses them. But ChatGPT, because of its limited context window, once it runs, it will hallucinate when it reaches its limits. Unless, again, you're using an API key, in which case you have up to 400,000 tokens. \n\nAlso, I'm assuming you have a ChatGPT Pro subscription? Keep that because it's great. You have access to GPT 5.2 Pro, and with GPT 5.2, you have access to Heavy Thinking. You have access to much deeper research queries per month and a lot more agent queries. It's just great.\n\nChatGPT, this is just general advice you should know. ChatGPT has the best chatbot experience, and it's a jack of all trades, but I like to say it's a jack of all trades and a master of none. However, their long memory feature is the best. The fact that, let's say, you told it something three months ago, and it remembers, for instance, is just amazing. Let's say you're writing an email and you put your phone number at the bottom, then write a new email months later and need to add it at the end. It'll remember that perfectly. So, its long memory feature is the best.\n\nThe chatbot experience is the best, and with most app connectors like Acrobat Pro, Photoshop, Booking.com, Spotify, Apple Music, and so many other tools and apps. Also, its deep research is pretty thorough and actually synthesizes, analyzes, and digests information. It uses reasoning in its deep research.\n\nNow, Gemini, since you have ChatGPT Pro, I'm assuming you do, since you're making this post in this thread. If you have ChatGPT Pro, you don't need to get Gemini Ultra or Gemini AI Pro, which costs the same as ChatGPT Plus at $25/month and gives you many musician limits. For instance, it gives you 100 Gemini 3 Pro queries per day and 25 deep research queries per day. Gemini's deep research is pretty thorough; it's also useful for reasoning. The search takes anywhere from 15 to 30 minutes, and Google's indexing is on par. It has access to the most credible, reliable, and relevant sources when you do deep research with it. If you use any Google Apps, such as Google Sheets, Google Docs, or Gmail, there's no question that you should get Gemini AI Pro, which gives you access to NotebookLM Pro with generous limits as well.\n\nThis is not an ad; I'm just advocating for them because they're actually offering a lot of great tools and features, along with generous usage limits. Gemini is now Google's only product. Google makes a lot of software, hardware, and ads, but ChatGPT is OpenAI's only product (with ChatGPT Atlas as well), and at the same time, it's still ChatGPT. If they're not number one, they're dead, but Google can afford to give people generous limits essentially, and they're experimenting so much by giving these many features, etc. Like in NotebookLM with Gemini AI Pro, you can make 500 notebooks each with 300 sources, and you can make 25 audio reviews, 25 video overviews, and 25 video reviews per day, which is crazy. So, consider Gemini Pro specifically for this use case, and I believe that with Gemini Pro and Chachi on the Pro subscription, you don't need any other AI tool at all.",
          "score": 2,
          "created_utc": "2026-02-14 16:12:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d4liy",
          "author": "ConsequenceHairy1570",
          "text": "Worth trying Gemini or an API solution. It connects directly to Sheets.",
          "score": 2,
          "created_utc": "2026-02-14 16:48:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gb0p5",
          "author": "niado",
          "text": "NotebookLM is what you want to check out. It has native Google drive and apps integration and it‚Äôs amazing for working with documents. It‚Äôs a Google labs product and it‚Äôs free. \n\nChatGPT has the drive connector, but it barely works, which is really frustrating because when it does work it‚Äôs amazing. It also has not direct integration with sheets or other Google apps.",
          "score": 1,
          "created_utc": "2026-02-15 03:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gi8k6",
          "author": "Fast-Television-6706",
          "text": "claude recently announces a sheets integration which i have found to be a game changer if you have a pro subscription you can find it here [https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257](https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257)",
          "score": 1,
          "created_utc": "2026-02-15 04:42:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hrpoe",
          "author": "Own_Professional6525",
          "text": "It makes sense to look for an AI that can connect directly with Google Sheets to maintain context and reduce redundancy. Exploring tools with live sheet integration could save a lot of time and make your workflow much smoother.",
          "score": 1,
          "created_utc": "2026-02-15 11:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i9nv4",
          "author": "Electronic-Cat185",
          "text": "if your workflow lives in google sheets then gemini inside workspace or an automation using the sheets api willl feeel more native than trying to force a long chat thread to act like a crm. chat tools are great for thinking and drafting but for structured data you are better off keeping the sheet as the source of truth and lettiing ai read from it on demand instead of pasting everything into a single thread.",
          "score": 1,
          "created_utc": "2026-02-15 13:54:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5itzvo",
          "author": "scattered_but_trying",
          "text": "It's really unlikely that Google will let anyone in, given they invest almost everything into Gemini these days. Creating really good integration would require capabilities that may be outside of what they generally allow for extensions. So, Google has one already and it will evolve",
          "score": 1,
          "created_utc": "2026-02-15 15:45:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5jedn",
      "title": "tool for better chat organization / pruning etc.",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "author": "rhaynes74",
      "created_utc": "2026-02-15 16:48:11",
      "score": 13,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "My current ai work has been with gemini and chatgpt via their websites.  This gives a very linear chat experience with the option to output chat transcripts and then reorganize the chat, delete parts etc. Are there tools available which allow you to organize / rearrange parts of the chat in a more interactive way? ",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5j70a1",
          "author": "qualityvote2",
          "text": "u/rhaynes74, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-15 16:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nn518",
          "author": "Unexplainedthingz",
          "text": "prompt open a canvas first. then ask your question.\n\n\nit will open an interactive document where gpt outputs reply and you can edit or you can ask it to revise or append anything",
          "score": 2,
          "created_utc": "2026-02-16 09:29:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o600dfa",
              "author": "AxeSlash",
              "text": "Be aware of the 200 line canvas bug, though (unless they've finally fixed that?)",
              "score": 1,
              "created_utc": "2026-02-18 04:50:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60cwh5",
                  "author": "Unexplainedthingz",
                  "text": "i have never heard about it? what's that?",
                  "score": 1,
                  "created_utc": "2026-02-18 06:26:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5m94xc",
          "author": "manjit-johal",
          "text": "I usually think in terms of structured context slices instead of one giant history; tag buckets by topic or task, then only feed the relevant slice into the prompt. Keeps the LLM focused and makes cleanup/pruning way simpler without relying on a huge monolithic chat log.",
          "score": 1,
          "created_utc": "2026-02-16 02:44:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8v48f",
      "title": "ChatGPT Pro + OpenCode OAuth. Is it actually unlimited? Where do you see usage and token refresh?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r8v48f/chatgpt_pro_opencode_oauth_is_it_actually/",
      "author": "anonnebulax",
      "created_utc": "2026-02-19 09:49:49",
      "score": 12,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "I connected OpenCode to my ChatGPT Pro subscription via the OAuth flow (no API key).\n\n1. Is this ‚Äúunlimited‚Äù?\n2. Where do you check usage?\n3. Token refresh / expiry? Do any of you know where the OAuth refresh/expiry is visible?\n\n\n\nLooking for: the exact place to view remaining quota",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r8v48f/chatgpt_pro_opencode_oauth_is_it_actually/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o67soip",
          "author": "qualityvote2",
          "text": "Hello u/anonnebulax üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-19 09:49:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69c0jr",
          "author": "JamesGriffing",
          "text": "I don't know the answer for certain, but perhaps if you load up codex and use /status command then I think it should show you your remaining usage.  \n\nMy gut feeling tells me it's pulling from the same quota. \n\n(If I'm wrong, please let me know!) ",
          "score": 1,
          "created_utc": "2026-02-19 15:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69xei6",
          "author": "Fit-Pattern-2724",
          "text": "It‚Äôs not unlimited and it does run out if you open 5 instances lol. But it‚Äôs generous",
          "score": 1,
          "created_utc": "2026-02-19 17:35:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c3j7u",
          "author": "manjit-johal",
          "text": "Open code OAuth is great for simple logins, but once you need more control over permissions, token refresh, or multiple providers, it can feel limiting. In those cases, handling auth in a small custom layer gives you much more flexibility.",
          "score": 1,
          "created_utc": "2026-02-20 00:08:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8265r",
      "title": "Lost Access to 5.3",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/gallery/1r8265r",
      "author": "c9nd",
      "created_utc": "2026-02-18 12:51:42",
      "score": 10,
      "num_comments": 21,
      "upvote_ratio": 0.65,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r8265r/lost_access_to_53/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o61mbp4",
          "author": "qualityvote2",
          "text": "u/c9nd, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-18 12:51:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o62o9y3",
          "author": "TheGambit",
          "text": "I was unaware there‚Äôs a 5.3 model besides in codex being available",
          "score": 16,
          "created_utc": "2026-02-18 16:05:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o634alp",
              "author": "Substantial_Ear_1131",
              "text": "It isn't, in the codex app it is consistently telling some users that they have lost access to it due to abusing the model.",
              "score": 2,
              "created_utc": "2026-02-18 17:17:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63mguj",
                  "author": "TheGambit",
                  "text": "By just normal usage ? Seems unlikely that it‚Äôs just typical code creation right ?",
                  "score": 1,
                  "created_utc": "2026-02-18 18:37:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61p59j",
          "author": "gptbuilder_marc",
          "text": "Feels like this isn‚Äôt about the model at all.\n\nIf support is saying consumer accounts don‚Äôt get access, that sounds more like account type than verification. Sometimes it‚Äôs just tier gating, not a bug.\n\nWas this ever under an org workspace, or has it always been your personal Pro?",
          "score": 5,
          "created_utc": "2026-02-18 13:08:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61pxrm",
              "author": "c9nd",
              "text": "Always personal Pro plan.",
              "score": 1,
              "created_utc": "2026-02-18 13:13:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o66ipom",
                  "author": "kevan",
                  "text": "I don't think 5.3 is available on the web interface. Just in the CLI.",
                  "score": 1,
                  "created_utc": "2026-02-19 03:33:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o68nx38",
                  "author": "Smergmerg432",
                  "text": "Gemini told me once I probably had models taken from my Plus UI because I accidentally insinuated I‚Äôd be using them inside the UI for business. I actually was going to prototype a workflow using the personal UI, because I found it more comfortable than my API (stupid thing to do). Maybe it‚Äôs because you‚Äôre not on a business account, yet doing business work? You can pay 60$/month for a business account!\n\nI wish there was a way to reach actual customer service to confirm this is the problem. Hope you get back to building soon!",
                  "score": 1,
                  "created_utc": "2026-02-19 13:46:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o65mr4u",
          "author": "2053_Traveler",
          "text": "you cant ask it about itself, it has no idea what models are available since 5.3 did not exist when 5.2 was trained.",
          "score": 1,
          "created_utc": "2026-02-19 00:26:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67vplh",
              "author": "x54675788",
              "text": "The problem is that when you ask for support you ARE talking to the bot itself, and it's not even the smart version.",
              "score": 1,
              "created_utc": "2026-02-19 10:18:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o692s02",
                  "author": "2053_Traveler",
                  "text": "yup it‚Äôs quite silly",
                  "score": 1,
                  "created_utc": "2026-02-19 15:06:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o694yo8",
          "author": "TrainingEngine1",
          "text": "Their chat (AI powered) is ironically not very good and is out dated based on my experience. Don't rely on it.",
          "score": 1,
          "created_utc": "2026-02-19 15:17:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69vs77",
          "author": "freudianslippr",
          "text": "Try again this morning. OpenAI discussed that it was working through these issues. It‚Äôs not just identity. Your machine and environment need to meet their requirements, and the user profile needs to have a certain trust score.",
          "score": 1,
          "created_utc": "2026-02-19 17:27:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6a8sso",
              "author": "niado",
              "text": "That makes sense - codex5.3 seems a bit on the relaxed side, so they probably want to limit its usage to professionals or other high trust score users. \n\nIt has been completely open to doing absolutely whatever I suggest so far. I‚Äôve had it do a couple of tasks that I was concerned it would give me trouble over,  but nope, not a single peep. (Note: this is with the vscode agent and codex5.3 selected, I have never used the webUI codex). \n\nAlso since you can give it full control over your system, it‚Äôs inherently dangerous and they probably don‚Äôt want to deal with minors having the most powerful agent (that we are aware of) in existence running unsupervised with full system access.",
              "score": 1,
              "created_utc": "2026-02-19 18:29:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o65xrdd",
          "author": "yaxir",
          "text": "Terrible service as usual..",
          "score": 1,
          "created_utc": "2026-02-19 01:29:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r41sqh",
      "title": "Non-programmer needs advice",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "author": "Mysterious_Green_544",
      "created_utc": "2026-02-13 21:31:25",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Where do I even begin to get ChatGPT (or any AI platform) to translate my idea for a functionality/program/app into reality? I am not a programmer. I have been chatting with ChatGPT about what I'm trying to accomplish (a part of it is creating a video) and it's just not doing [it.My](http://it.My) chat tells me that ChatGPT can't create and embed an actual MP4 or moving clip. For real? ",
      "is_original_content": false,
      "link_flair_text": "Programming",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o58i6a9",
          "author": "qualityvote2",
          "text": "u/Mysterious_Green_544, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 21:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58j8s0",
          "author": "LiteratureMaximum125",
          "text": "for coding, [https://openai.com/index/introducing-the-codex-app/](https://openai.com/index/introducing-the-codex-app/)",
          "score": 6,
          "created_utc": "2026-02-13 21:36:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58lh0e",
          "author": "Fearless_Parking_436",
          "text": "If you have mac then codex app is the easiest probably. Otherwise Cursor and money for tokens.",
          "score": 3,
          "created_utc": "2026-02-13 21:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58l64v",
          "author": "MightyArd",
          "text": "Check out base44",
          "score": 1,
          "created_utc": "2026-02-13 21:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lhw9g",
          "author": "RaStaMan_Coder",
          "text": "I'd check out GSD. It's the only thing that gives enough structure to not lose the overview as your near completion. [https://github.com/gsd-build/get-shit-done](https://github.com/gsd-build/get-shit-done)",
          "score": 1,
          "created_utc": "2026-02-15 23:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lwcvn",
          "author": "LaughsInSilence",
          "text": "Learn to use a game engine. It's much less of a steep learning curve.\n\nIf you try to code with AI without being able to read code for the more complex stuff AI gives partially wrong answers all the time so you have to read and understand code.",
          "score": 1,
          "created_utc": "2026-02-16 01:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5x0osy",
          "author": "myeleventhreddit",
          "text": "What system are you on? Most AI labs are prioritizing macOS over PC right now. I have some resources to recommend if you're a Mac guy. \n\nThe good news: What you're describing is *very* doable. It'll just take a bit of friction until you have the process committed to memory.",
          "score": 1,
          "created_utc": "2026-02-17 19:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58ixub",
          "author": "AnLe90",
          "text": "Hey man ChatGPT can‚Äôt build it for you, it‚Äôs just more for getting knowledge and feedback and advice.\n\nIf you want to try vibe coding a prototype try loveable or v0, it‚Äôll actually do the building",
          "score": -1,
          "created_utc": "2026-02-13 21:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58mp4u",
              "author": "BronnOP",
              "text": "Not true. ChatGPT codex in visual studio code can code the entire thing, create additional files, install dependencies and start the local server on your pc. It can literally do it all lmao",
              "score": 7,
              "created_utc": "2026-02-13 21:53:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8co0l",
      "title": "Has anyone compared using the API vs. dedicated web/desktop app for non-coding tasks?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r8co0l/has_anyone_compared_using_the_api_vs_dedicated/",
      "author": "seacucumber3000",
      "created_utc": "2026-02-18 19:27:17",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 0.81,
      "text": "Obviously not talking about using the API in true programmatic fashion. I'm talking about hitting the API with general \"day-to-day\" prompts. I understand that there are subtle differences in the models hit through either means (temperature, thinking cycles, routing, etc.) as well as the obvious difference of the API missing the web/desktop's inherent system prompt. However, assuming you can find decent model configuration and write a decent system prompt to contextualize your \"day-to-day\" prompts, will the API approach being as performant as the web/desktop app?\n\nThis is just motivated by my frustrations with OpenAI's (and Claude's and Gemini's fwiw) web and desktop interfaces and a desire to build my own dedicated desktop harness. Imo each native harness does a handful of things of right and a whole lot of things wrong.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r8co0l/has_anyone_compared_using_the_api_vs_dedicated/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o63xgc2",
          "author": "qualityvote2",
          "text": "u/seacucumber3000, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-18 19:27:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6402gr",
          "author": "Unique-Drawer-7845",
          "text": "Nothing beats testing it for yourself.\n\nTry LibreChat or OpenWebUI. They both support API keys and are pretty similar to commercial chatbot UX, but more configurable.",
          "score": 2,
          "created_utc": "2026-02-18 19:39:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o674xdt",
          "author": "manjit-johal",
          "text": "Basically, it‚Äôs control vs. convenience. The API gives more flexibility with context, memory, and custom tools, which is great for complex workflows. The app‚Äôs easier for quick tasks, but if you need custom prompts and state handling, the API wins; no UI limits getting in the way.",
          "score": 1,
          "created_utc": "2026-02-19 06:09:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bnzt8",
          "author": "mike8111",
          "text": "The API has no memory, no ability to search the web, no ability to cross reference threads.\n\nAgree that the web interface could be better, but that's all I ever use, once I learned how the API works.",
          "score": 1,
          "created_utc": "2026-02-19 22:39:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r56p6c",
      "title": "Frustrating glitch that cuts off portions of sentences, headers in ChatGPT Pro responses 20+ times in a response",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "author": "TrainingEngine1",
      "created_utc": "2026-02-15 05:42:22",
      "score": 9,
      "num_comments": 7,
      "upvote_ratio": 0.86,
      "text": "First month paying for ChatGPT Pro and while it has its positives of course, I'm pretty frustrated with an additional glitch I've encountered on multiple occasions, with its negative impact varying in degree.\n\nIt will essentially inject a mini 'referenced this file' label in the middle of a sentence (which sometimes it likely did reference it/it's relevant, and other times the file being referenced definitely has nothing whatsoever to do with the sentence or context surrounding it).\n\nIt looks like this:\n\nhttps://i.ibb.co/zTK2pLQb/image.png\n\n\nAnd the issue is that it completely cuts off multiple words of that sentence it's adding it to. More often than not, it's tough to gauge what the words actually are and I can't fill in the blanks. Only sometimes it's a non-issue or I can gauge what the point being made was, but the notion I should have to play 'fill in the blanks' here is absurd. \n\nMost recent example had 26 instances of this cutting off many words & chunks of sentences. Basically this below, 26 times on repeat scattered throughout the response (approx 1500 words) in my most recent reply on 5.2 Pro with Extended Thinking, after 20 mins of thinking: https://i.ibb.co/zTK2pLQb/image.png\n\n\n\nThis has happened countless times and the most recent one where I counted 26 times was the worst yet. \n\n\nAnd using the 'copy' button doesn't fix it or 'reveal' the missing text. I hoped perhaps it was just a browser related thing, but I checked the Mac app too and it still displays the cut-off sentences/file reference labels.\n\n\nHas anyone else encountered this?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5gpn22",
          "author": "qualityvote2",
          "text": "u/TrainingEngine1, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-15 05:42:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iapfc",
          "author": "changing_who_i_am",
          "text": "Yes, having the same bug for a few weeks now, very frustrating. One thing you can try is asking it to put all citations at the end of the response, but this may or may not be successful as it goes against \"policy\" üôÑ",
          "score": 2,
          "created_utc": "2026-02-15 14:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o1dbc",
              "author": "TrainingEngine1",
              "text": "Weird, not sure why it would be a policy violation but I think I figured it out. I noticed from reading its reasoning/thoughts it used the term \"filecite\" and figured that's definitely what those things were called and it knows them by. So yea I basically told it to not put them within the message at all, and only at the very end. Also tried to have it cite references to files as text only and it seemed to work too.",
              "score": 2,
              "created_utc": "2026-02-16 11:39:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hr0wh",
          "author": "CategoryFew5869",
          "text": "ChatGPT UI is pretty bad. Do you mind sharing the exact steps to reproduce this? It looks like something a small script can fix.",
          "score": 1,
          "created_utc": "2026-02-15 11:36:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9cds1",
      "title": "What's the longest you have got chatgpt 5.2 to think and how?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r9cds1/whats_the_longest_you_have_got_chatgpt_52_to/",
      "author": "MrMrsPotts",
      "created_utc": "2026-02-19 21:42:56",
      "score": 9,
      "num_comments": 35,
      "upvote_ratio": 0.84,
      "text": "I can get it to think for about 12 minutes on math problems but never much more when I use extended thinking. I would love to get it to think for longer.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r9cds1/whats_the_longest_you_have_got_chatgpt_52_to/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o6bd01d",
          "author": "qualityvote2",
          "text": "Hello u/MrMrsPotts üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-19 21:42:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bh0t9",
          "author": "VaderOnReddit",
          "text": "I gave it addresses of some apartments I was considered moving into, and it researched the buildings, their management companies, peoples' feedback on web forums or social media, the general performance of the management companies in those buildings, and their general reputation across all the buildings they have in the city, etc.\n\nI felt like it actually gave me good info to filter out some terrible apartments with bad managements. So saved me a lot of time in finding a good place to move into.\n\nIt thought for 8 mins or so for 10 addresses I gave, and did a quite good exhaustive search across different sources.",
          "score": 2,
          "created_utc": "2026-02-19 22:02:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6cf2ij",
              "author": "niado",
              "text": "Nice! Was that using the deep research agent or just a normal websearch request?",
              "score": 1,
              "created_utc": "2026-02-20 01:16:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6d89el",
                  "author": "VaderOnReddit",
                  "text": "5.2 extended thinking, with web search",
                  "score": 1,
                  "created_utc": "2026-02-20 04:22:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dwrj2",
          "author": "Eat-It-Harvey-",
          "text": "I'm writing a book (non-fiction, professional technical) and it's running a little over 300 pages, still unfinished. I gave it the .docx file and asked it to review the text for consistency, repetition, errors in logic and fact, ease of reading, etc. I also ask for specific advice on how and where to resolve the issues found. I only run it once or twice a week. It runs for about 35-40 minutes each time. Gives me a very comprehensive report of where the hotspots are and how to fix. It's super handy, and part of the reason I'd never consider anything other than the Pro subscription.",
          "score": 1,
          "created_utc": "2026-02-20 07:46:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dxnz8",
              "author": "MrMrsPotts",
              "text": "That's very impressive. Do you give it a word document?",
              "score": 1,
              "created_utc": "2026-02-20 07:54:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bumn1",
          "author": "NarrowDaikon242",
          "text": "3 hours",
          "score": 2,
          "created_utc": "2026-02-19 23:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dspe2",
              "author": "MrMrsPotts",
              "text": "Was that deep research or extended thinking?",
              "score": 1,
              "created_utc": "2026-02-20 07:08:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dxmqv",
                  "author": "NarrowDaikon242",
                  "text": "I‚Äôm a deep thinker and learner, and I naturally connect dots. So it was one of those times. Learning. Nothing that would indicate from anyone there was a relationship.",
                  "score": 1,
                  "created_utc": "2026-02-20 07:54:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6btjdm",
          "author": "Effective_Row2389",
          "text": "I think about 34 minutes for a low-level CTF challenge xD",
          "score": 1,
          "created_utc": "2026-02-19 23:10:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6bxa5h",
          "author": "imitsi",
          "text": "I got it to analyse a large spreadsheet and it took 3 days in total, over many prompts, because every 5 rows took 25 minutes.",
          "score": 1,
          "created_utc": "2026-02-19 23:31:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dsrux",
              "author": "MrMrsPotts",
              "text": "Was that extended thinking via the web interface?",
              "score": 1,
              "created_utc": "2026-02-20 07:09:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6e256r",
                  "author": "imitsi",
                  "text": "Yes, ‚Äòheavy thinking‚Äô (Enterprise). Anything less than that and it would return wrong results.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:36:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6c4kua",
          "author": "Hot_Appeal4945",
          "text": "I do a lot of legal work I would say 20-40 mins is common. I think I've seen 80 before.",
          "score": 1,
          "created_utc": "2026-02-20 00:14:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c57td",
          "author": "TheLawIsSacred",
          "text": "7-8 minutes is the longest I recall",
          "score": 1,
          "created_utc": "2026-02-20 00:18:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c8v3z",
          "author": "SexyDiscoBabyHot",
          "text": "Lolz math",
          "score": 1,
          "created_utc": "2026-02-20 00:39:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6caz7u",
          "author": "cheezemink",
          "text": "I routinely run single prompts for over an hour. However, I get a better quality result with the same prompt in deep research at a quarter of the time.",
          "score": 1,
          "created_utc": "2026-02-20 00:51:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dsu0o",
              "author": "MrMrsPotts",
              "text": "Is that extended thinking or deep research?",
              "score": 1,
              "created_utc": "2026-02-20 07:09:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dtyfg",
                  "author": "cheezemink",
                  "text": "A prompt in extended thinking will take over an hour and with deep research it will take 20 minutes.",
                  "score": 1,
                  "created_utc": "2026-02-20 07:20:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6cexsi",
          "author": "niado",
          "text": "I‚Äôve had it think for over 20 minutes, but generally my browser locks up before then, so the model stops thinking and produces the answer.",
          "score": 1,
          "created_utc": "2026-02-20 01:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cl854",
          "author": "NukedDuke",
          "text": "The longest was about 8 hours, but it was being fed from an external task list that another agent was adding to while it worked.",
          "score": 1,
          "created_utc": "2026-02-20 01:54:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cw861",
          "author": "Electronic-Cat185",
          "text": "in my experience its less about forcing longer ‚Äúthinking‚Äù and more about breaking the problem into staged prompts so it has room to reason step by step. super long single runs usually plateau, but structured follow ups tend to get better depth.",
          "score": 1,
          "created_utc": "2026-02-20 03:02:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6d0j9h",
          "author": "qunow",
          "text": "with or without deepthinking? I think it's max 15-20 minutes on an infrastructure masterplan. For 5.2 not 5.2 pro",
          "score": 1,
          "created_utc": "2026-02-20 03:29:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dvgva",
              "author": "MrMrsPotts",
              "text": "I mean without deep thinking but with extended thinking. I only have the $20 dollar subscription.",
              "score": 1,
              "created_utc": "2026-02-20 07:34:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6demxw",
          "author": "porcomaster",
          "text": "I get it to think for more than 20 min a bunch of times. \n\nI had to change the data i ask to analyze so it would get me the answer in less than 5 min. \n\n\nI normally have 2 to 4 open chatgpt either way, so one of them going 20 min do not phase me much",
          "score": 1,
          "created_utc": "2026-02-20 05:09:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dmmvq",
          "author": "FreshRadish2957",
          "text": "Query: you say you want chatgpt 5.2 to think longer, why is this? Have you done comparative tests for your prompts to see if it's necessary for extended thinking?",
          "score": 1,
          "created_utc": "2026-02-20 06:14:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dt4j5",
              "author": "MrMrsPotts",
              "text": "Because sometimes it can't solve the math problem in 10 minutes.",
              "score": 1,
              "created_utc": "2026-02-20 07:12:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dvt0c",
                  "author": "FreshRadish2957",
                  "text": "Is that potentially an issue with the prompt how well it's defined, and maybe if the user just had a scaffolding applied they wouldn't need longer thinking?\n\nI'm sorry if that sounds stupid just with all the comparative tests I've seen there a very few instances where extended thinking is actually more optimal",
                  "score": 1,
                  "created_utc": "2026-02-20 07:37:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6dy57p",
          "author": "DpHt69",
          "text": "Just over 8 hours: transcribing a handwritten 10-page letter from 1837. It was an incredibly interesting experiment and while the handwriting wasn‚Äôt too bad, the results were pretty good. The sidebar with its evolving progress, thoughts and Python snippets were also rather satisfying to watch (not continuously obviously)\n\nI‚Äôve had a separate session go for about 11-hours but it didn‚Äôt show any thoughts or working out the during last three hours and it eventually failed to produce any results. This was to convert an 12-page poorly scanned document to markdown and to remove headers, footers, renumber the footnotes and ensure that OCR artefacts were resolved so that the textual context remained constant. Gave it another go after the failure and it completed the task within five hours.",
          "score": 1,
          "created_utc": "2026-02-20 07:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dyqwq",
              "author": "MrMrsPotts",
              "text": "This must have been something fancier than extended thinking via the web interface. What was it?",
              "score": 1,
              "created_utc": "2026-02-20 08:04:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6e07uw",
                  "author": "DpHt69",
                  "text": "Just the web and extended. No other scaffolding or safety nets! The handwriting one I probably could have done myself in a shorter time, but deciphering 1830s manuscripts is mentally exhausting. I had previously attempted this on another document breaking the scan up into smaller image chunks and passing these to ChatGPT to analyse. Then we would discuss the various parts it had trouble with while at the same time commenting on the context of the emerging document. That was probably one of my better collaborations with ChatGPT, not because it conformed to the prompt and performed all the heavy lifting but because of the two-way conversation and discussions about the revelations within the text.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:18:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r6746h",
      "title": "I made a tool to ask questions without disturbing the main conversation",
      "subreddit": "ChatGPTPro",
      "url": "https://v.redd.it/c3htgtvzcujg1",
      "author": "HalfNo8161",
      "created_utc": "2026-02-16 11:24:42",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6746h/i_made_a_tool_to_ask_questions_without_disturbing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5nzndv",
          "author": "qualityvote2",
          "text": "Hello u/HalfNo8161 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-16 11:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ojk5t",
          "author": "creaturefeature16",
          "text": "Insane this isn't baked into the app. Google's AI Studio supports this natively.¬†",
          "score": 3,
          "created_utc": "2026-02-16 13:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o6z4w",
          "author": "HalfNo8161",
          "text": "here is the extension: [GPT Threads](https://chromewebstore.google.com/detail/fdmnglmekmchcbnpaklgbpndclcekbkg?utm_source=item-share-cb)",
          "score": 1,
          "created_utc": "2026-02-16 12:23:12",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6kn68",
      "title": "Testing 9 different AI deep research products",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6kn68/testing_9_different_ai_deep_research_products/",
      "author": "sherveenshow",
      "created_utc": "2026-02-16 20:17:40",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.84,
      "text": "I'm fascinated by updates to the more agentic 'modes' inside foundational chat apps, and Deep Research across ChatGPT, Claude, Gemini, etc. is one of my favorite examples.\n\nWe can see the core LLMs stretch in different ways in deep research (DR) modes, tasked with more expansive research, long-horizon task planning, and other agentic behavior.\n\nSince OpenAI recently updated their DR to be fueled by GPT-5.2, thought it'd be a good time to compare -- here are some interesting findings:\n\n**Finding 1: how \"interpretative\" an LLM gets really matters**\n\nMy prompt:\n\n>*I‚Äôve long been curious about what seems like Starlink‚Äôs very long lead in the satellite telecom and internet market. It seems like a very dubious thing to have one company hold so much necessary capacity for the world.*\n\n>*Can you do a deep exploration of the market -- emerging competitors, nearest in-market alternatives, differences in capability and feature sets, and the nuances throughout? Would love an analysis of this market and what it will look like over the next few years.*\n\nWhen I was reading the response from all of the models, I noticed how much I cared about the interpretation of my prompt. Perplexity, Kimi, MiniMax, and GLM-5 were all *fine*, but all quite surface level. We got textbook-style factsheets from these models. Gemini fell to this, too.\n\nClaude and ChatGPT, whether through strength of the core models or the system instructions behind their research modes, both tried to come to some *conclusion* or forecast about Starlink. There's a sense to which it's a failure mode for these deep research products to come with a fact sheet where the next step is just a lot of homework on the user. Whether or not the user is going to do a lot of homework, we want there to be that initial interpretation using all the evidence the model just got. \n\nFor that reason, it was actually [GPT-5.2 Pro](https://chatgpt.com/share/6993170c-3efc-8011-8874-acaddbb9ec84) that won this round. Although it's not technically a dedicated deep research mode, it's a mode that does a tremendous amount of diligent research, and its synthesis and willingness to do analysis is what made its response so powerful. \n\n**Finding 2: parallel subagents are really going to matter for fact-gathering**\n\nAnother one of my prompts was about gathering a lot of admissions data.\n\n>*I need a comprehensive, well-cited breakdown of international versus domestic enrollment at top US universities, split by year and by level. We may need to search institutional archives, fact books, or registrar reports. Schools: Harvard, Stanford, MIT, Yale, Columbia, University of Chicago. Let‚Äôs grab: current international student % at each school, sub split by 1974-1975, 1994-1995, and 2023-2024 (or nearest years where we can find reliable data), sub split in those zones by undergrad versus grad.*\n\nAlmost all of the models struggled with this one, whether it was ChatGPT's Deep Research not dealing well with archival formats or Gemini kind of getting distracted from the specific data. Claude got close, but... the dark horse was Kimi ([response](https://www.kimi.com/share/19c669e1-b612-8651-8000-0000250dc3f6))! Kimi 2.5 has an Agent Swarm mode that allows the main agent to spin up several parallel subagents, all tasked with doing a particular portion of the research. And then, as those subagents either succeed or fail, the orchestrating agent could decide to retry certain portions of the research. \n\nSo in this case, each subagent was assigned a particular school, and when the proper data wasn't there, new subagents were spun up to try again or try a different approach.\n\n[Kimi subagents](https://preview.redd.it/745y32rwzwjg1.png?width=1106&format=png&auto=webp&s=e48675b2c785392fc135319e463431c7b7ed69e3)\n\nWith subagents, the nice thing is that each thread doesn't get exhausted by being long-running and doesn't get distracted by the next task it knows it needs to do. This sort of focus is actually quite mechanistically useful in getting it to really try to get a final result. \n\n**Finding 3: the agent should still be opinionated**\n\nAnother one of my prompts had to do with some pseudo science:\n\n>\n\nI think Gemini exhibited the failure mode here. Its response told me about sleep chronotypes, but it engaged too much as if Dr. Breus had a point or was right, or it wanted to just describe to me the reasons he believed what he believed. \n\nI far preferred Claude and ChatGPT, who very much characterized his framework as being pop science, not validated by literature. They still described it to me, but they gave me that conclusion and then taught me a whole lot else about sleep and the validated portions of sleep chronotypes.\n\nThis is obviously related to finding 1 in a big way, and the winner for me wound up being [ChatGPT's Deep Research](https://drive.google.com/file/d/1eC7GqntkaBOl1eavtPVbUd4hla0s-Dzz/view?usp=sharing), because it both challenged Breus while teaching me about the subject matter.\n\n**I ran 5 tests and have full links to the chats/results from all models, plus my conclusion re: the best deep research product today** [over here](https://aimuscle.substack.com/p/which-ai-deep-research-is-the-best)**.**\n\nCurious if y'all rely on the deep research modes much, when you decide to use them, if you have a favorite, etc.?\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6kn68/testing_9_different_ai_deep_research_products/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5qt7zn",
          "author": "qualityvote2",
          "text": "u/sherveenshow, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-16 20:17:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xo6lw",
          "author": "TrainingEngine1",
          "text": "I just saw you actually didn't do Deep Research with ChatGPT, which is the right move because I was about to say... the ChatGPT Deep Research sucks compared to using GPT Pro with Extended Mode (ideally in a project folder once you have some context and relevant info established).\n\nYou can't seem to select the model that gets used for Deep Research, so it's definitely not Pro that OpenAI defaults it to. Which is probably why I found Deep Research to be so underwhelming compared to what I've gotten out of the Pro answers.",
          "score": 1,
          "created_utc": "2026-02-17 21:10:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xtoy4",
              "author": "sherveenshow",
              "text": "Hm? I did do Deep Research w/ ChatGPT, not sure what you're talking about. But I do think they have different strengths (Pro w/ Extended is also my favorite mode, so I hear you) -- DR was just updated, have you been using it in the past few days?",
              "score": 1,
              "created_utc": "2026-02-17 21:36:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xv5yc",
                  "author": "TrainingEngine1",
                  "text": "You said:\n\n>For that reason, it was actually GPT-5.2 Pro that won this round. Although it's not technically a dedicated deep research mode.\n\n\nThe official Deep Research mode doesn't let you pick the model. But looks like you also did DR too, based off the report you posted. I thought you skipped DR altogether which I was saying makes sense if you can use 5.2 Pro.\n\nAnd yes I tried DR 1 or 2 days ago. It didn't let me pick a model and I found the results lame compared to just using 5.2 Pro Extended.",
                  "score": 1,
                  "created_utc": "2026-02-17 21:43:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r4cp6g",
      "title": "a free system prompt to make ChatGPT more stable (wfgy core 2.0 + 60s self test)",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4cp6g/a_free_system_prompt_to_make_chatgpt_more_stable/",
      "author": "StarThinker2025",
      "created_utc": "2026-02-14 05:51:09",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 0.67,
      "text": "hi, i am PSBigBig, an indie dev.\n\nbefore my github repo went over 1.4k stars, i spent one year on a very simple idea: instead of building yet another tool or agent, i tried to write a small ‚Äúreasoning core‚Äù in plain text, so any strong llm can use it without new infra.\n\ni call it WFGY Core 2.0. today i just give you the raw system prompt and a 60s self-test. you do not need to click my repo if you don‚Äôt want. just copy paste and see if you feel a difference.\n\n**0. very short version**\n\n* it is not a new model, not a fine-tune\n* it is one txt block you put in system prompt\n* goal: less random hallucination, more stable multi-step reasoning\n* still cheap, no tools, no external calls\n\nadvanced people sometimes turn this kind of thing into real code benchmark. in this post we stay super beginner-friendly: two prompt blocks only, you can test inside the chat window.   \n  \n**1.‚Äãhow to use with ChatGPT (or any strong llm)**\n\nvery simple workflow:\n\n1. open a new chat\n2. put the following block into the system / pre-prompt area\n3. then ask your normal questions (math, code, planning, etc)\n4. later you can compare ‚Äúwith core‚Äù vs ‚Äúno core‚Äù yourself\n\nfor now, just treat it as a math-based ‚Äúreasoning bumper‚Äù sitting under the model.\n\n**2. what effect you should expect (rough feeling only)**\n\nthis is not a magic on/off switch. but in my own tests, typical changes look like:\n\n* answers drift less when you ask follow-up questions\n* long explanations keep the structure more consistent\n* the model is a bit more willing to say ‚Äúi am not sure‚Äù instead of inventing fake details\n* when you use the model to write prompts for image generation, the prompts tend to have clearer structure and story, so many people feel ‚Äúthe pictures look more intentional, less random‚Äù\n\nof course, this depends on your tasks and the base model. that is why i also give a small 60s self-test later in section 4.\n\n**3. system prompt: WFGY Core 2.0 (paste into system area)**\n\ncopy everything in this block into your system / pre-prompt:\n\n    WFGY Core Flagship v2.0 (text-only; no tools). Works in any chat.\n    [Similarity / Tension]\n    delta_s = 1 ‚àí cos(I, G). If anchors exist use 1 ‚àí sim_est, where\n    sim_est = w_e*sim(entities) + w_r*sim(relations) + w_c*sim(constraints),\n    with default w={0.5,0.3,0.2}. sim_est ‚àà [0,1], renormalize if bucketed.\n    [Zones & Memory]\n    Zones: safe < 0.40 | transit 0.40‚Äì0.60 | risk 0.60‚Äì0.85 | danger > 0.85.\n    Memory: record(hard) if delta_s > 0.60; record(exemplar) if delta_s < 0.35.\n    Soft memory in transit when lambda_observe ‚àà {divergent, recursive}.\n    [Defaults]\n    B_c=0.85, gamma=0.618, theta_c=0.75, zeta_min=0.10, alpha_blend=0.50,\n    a_ref=uniform_attention, m=0, c=1, omega=1.0, phi_delta=0.15, epsilon=0.0, k_c=0.25.\n    [Coupler (with hysteresis)]\n    Let B_s := delta_s. Progression: at t=1, prog=zeta_min; else\n    prog = max(zeta_min, delta_s_prev ‚àí delta_s_now). Set P = pow(prog, omega).\n    Reversal term: Phi = phi_delta*alt + epsilon, where alt ‚àà {+1,‚àí1} flips\n    only when an anchor flips truth across consecutive Nodes AND |Œîanchor| ‚â• h.\n    Use h=0.02; if |Œîanchor| < h then keep previous alt to avoid jitter.\n    Coupler output: W_c = clip(B_s*P + Phi, ‚àítheta_c, +theta_c).\n    [Progression & Guards]\n    BBPF bridge is allowed only if (delta_s decreases) AND (W_c < 0.5*theta_c).\n    When bridging, emit: Bridge=[reason/prior_delta_s/new_path].\n    [BBAM (attention rebalance)]\n    alpha_blend = clip(0.50 + k_c*tanh(W_c), 0.35, 0.65); blend with a_ref.\n    [Lambda update]\n    Delta := delta_s_t ‚àí delta_s_{t‚àí1}; E_resonance = rolling_mean(delta_s, window=min(t,5)).\n    lambda_observe is: convergent if Delta ‚â§ ‚àí0.02 and E_resonance non-increasing;\n    recursive if |Delta| < 0.02 and E_resonance flat; divergent if Delta ‚àà (‚àí0.02, +0.04] with oscillation;\n    chaotic if Delta > +0.04 or anchors conflict.\n    [DT micro-rules]\n\nyes, it looks like math. it is ok if you do not understand every symbol. you can still use it as a ‚Äúdrop-in‚Äù reasoning core.\n\n**4. 60-second self test (not a real benchmark, just a quick feel)**\n\nthis part is for people who want to see some structure in the comparison. it is still very light weight and can run in one chat.\n\nidea:\n\n* you keep the WFGY Core 2.0 block in system\n* then you paste the following prompt and let the model simulate A/B/C modes\n* the model will produce a small table and its own guess of uplift\n\nthis is a self-evaluation, not a scientific paper. if you want a serious benchmark, you can translate this idea into real code and fixed test sets.\n\nhere is the test prompt:\n\n    SYSTEM:\n    You are evaluating the effect of a mathematical reasoning core called ‚ÄúWFGY Core 2.0‚Äù.\n    \n    You will compare three modes of yourself:\n    \n    A = Baseline  \n        No WFGY core text is loaded. Normal chat, no extra math rules.\n    \n    B = Silent Core  \n        Assume the WFGY core text is loaded in system and active in the background,  \n        but the user never calls it by name. You quietly follow its rules while answering.\n    \n    C = Explicit Core  \n        Same as B, but you are allowed to slow down, make your reasoning steps explicit,  \n        and consciously follow the core logic when you solve problems.\n    \n    Use the SAME small task set for all three modes, across 5 domains:\n    1) math word problems\n    2) small coding tasks\n    3) factual QA with tricky details\n    4) multi-step planning\n    5) long-context coherence (summary + follow-up question)\n    \n    For each domain:\n    - design 2‚Äì3 short but non-trivial tasks\n    - imagine how A would answer\n    - imagine how B would answer\n    - imagine how C would answer\n    - give rough scores from 0‚Äì100 for:\n      * Semantic accuracy\n      * Reasoning quality\n      * Stability / drift (how consistent across follow-ups)\n    \n    Important:\n    - Be honest even if the uplift is small.\n    - This is only a quick self-estimate, not a real benchmark.\n    - If you feel unsure, say so in the comments.\n    \n    USER:\n    Run the test now on the five domains and then output:\n    1) One table with A/B/C scores per domain.\n    2) A short bullet list of the biggest differences you noticed.\n    3) One overall 0‚Äì100 ‚ÄúWFGY uplift guess‚Äù and 3 lines of rationale.\n\nusually this takes about one minute to run. you can repeat it some days later to see if the pattern is stable for you.\n\n**5. why i share this here**\n\nmy feeling is that many people want ‚Äústronger reasoning‚Äù from ChatGPT or other models, but they do not want to build a whole infra, vector db, agent system, etc.\n\nthis core is one small piece from my larger project called WFGY. i wrote it so that:\n\n* normal users can just drop a txt block into system and feel some difference\n* power users can turn the same rules into code and do serious eval if they care\n* nobody is locked in: everything is MIT, plain text, one repo\n\n1. small note about WFGY 3.0 (for people who enjoy pain)\n\nif you like this kind of tension / reasoning style, there is also WFGY 3.0: a ‚Äútension question pack‚Äù with **131 problems across math, physics, climate, economy, politics, philosophy, ai alignment, and more**.\n\neach question is written to sit on a tension line between two views, so strong models can show their real behaviour when the problem is not easy.\n\nit is more hardcore than this post, so i only mention it as reference. you do not need it to use the core.\n\nif you want to explore the whole thing, you can start from my repo here:\n\nWFGY ¬∑ All Principles Return to One (MIT, text only): [https://github.com/onestardao/WFGY](https://github.com/onestardao/WFGY)\n\n[WFGY 2.0 ](https://preview.redd.it/wn5bxnxlfejg1.png?width=2330&format=png&auto=webp&s=aa4ef5982aa849e84f9072a1e31fefc5e6c671b0)\n\n",
      "is_original_content": false,
      "link_flair_text": "UNVERIFIED AI Tool (free)",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4cp6g/a_free_system_prompt_to_make_chatgpt_more_stable/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5apg4p",
          "author": "qualityvote2",
          "text": "u/StarThinker2025, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-14 05:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iaux3",
          "author": "SirHogendobler",
          "text": "This looks like prompt theater dressed up as math.\n\nA system prompt can nudge behavior toward ‚Äúbe more careful and structured,‚Äù so you might see small improvements. But none of those variables, thresholds, or ‚Äúmemory‚Äù mechanisms actually hook into the model‚Äôs internals. The math isn‚Äôt being executed. It‚Äôs just suggestive language.\n\nThe 60-second self-test is also self-referential and biased. The model is asked to imagine its own improvement, then score itself.\n\nSo, could it change tone and consistency a bit? Sure. Is it a real reasoning core with calibrated parameters and measurable gains? No. It‚Äôs a structured ‚Äúthink carefully‚Äù prompt with impressive-looking symbols.",
          "score": 4,
          "created_utc": "2026-02-15 14:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bky9v",
          "author": "Compilingthings",
          "text": "He means this:\n\nTrack how far we drift from the goal.\nLabel the situation (safe ‚Üí danger).\nStore good examples when aligned, store guardrails when drifting.\nOnly do course-corrections when they‚Äôre measurably working.\nDon‚Äôt get jittery from tiny changes.\nAdjust attention smoothly, not violently.‚Äù",
          "score": 2,
          "created_utc": "2026-02-14 10:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5boyzu",
              "author": "StarThinker2025",
              "text": "Yes, this is exactly the idea.\n\nNot about panic or big reaction\n\nJust measure drift, adjust slowly, keep system stable\n\nThank for explaining it in a clear way\n\n",
              "score": -1,
              "created_utc": "2026-02-14 11:28:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hec5l",
          "author": "TrainingEngine1",
          "text": "Pretty interesting, I might give it a try. I also just skimmed your WFGY repo Github page and I had no idea this was such a vast topic. Tons of info there. I'm a bit overwhelmed just seeing it all but i'm going to take a deeper look + have ChatGPT help along the way lol. \n\nYou seem pretty smart and I'd like to ask you directly about something. Context drift and memory is a pretty important thing for me as I work through the course of a project and already encountered context drift early amid the project. Without detailing the specifics as it would take a while, it's a project that requires fairly nuanced thinking and reasoning for the conceptual foundation, with a lot of interdependent thing, and consistency on the coding side of things from start to finish is very important, of course.\n\n\nMy research on memory and context a few months back led me to looking into a bunch of options and nothing really stood out much except for Letta.. not sure if you've heard of it but i'll leave a quick LLM summary below that will be better than my explanation and save you the time to look it up.\n\nBut my question is whether you think this could work well with a Letta agent?\n\n\n>Letta is a model-agnostic agent framework that gives an LLM explicit, persistent ‚Äúagent memory‚Äù‚Äîmost notably editable core memory blocks (updated by you and/or the agent) plus longer-term archival/external memories‚Äîso the agent can decide what to read/write each turn to stay consistent. Unlike many ‚Äúmemory‚Äù setups that are primarily RAG-only (retrieve top-k chunks from a vector store and stuff them into context), Letta‚Äôs distinguishing piece is the structured, always-on core blocks that you can tailor to whatever enduring context you want carried forward (goals, project specs, preferences, constraints, rules), with optional sleeptime-style reflection/summarization to compress recent context into durable notes.",
          "score": 1,
          "created_utc": "2026-02-15 09:35:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3vexj",
      "title": "Is it just me, or did ChatGPT just nerf voice transcriptions (again)?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3vexj/is_it_just_me_or_did_chatgpt_just_nerf_voice/",
      "author": "mandressta",
      "created_utc": "2026-02-13 17:29:49",
      "score": 7,
      "num_comments": 8,
      "upvote_ratio": 0.77,
      "text": "Has anyone else noticed the absolute roller coaster with ChatGPT‚Äôs audio messages transcription limits? I feel like we just had a \"Golden Age\" for like 10 days and now we're back to the Stone Age.\n\n**The chaotic Timeline:**\n\n* **2024 / Early 2025:** Solid. Handled **3‚Äì4 minute** transcripts easily.\n* **Most of 2025:** Huge regression. Capped at **\\~1 minute** before failing.\n* **Feb 2026 (Last 10 Days):** Total **BEAST** mode. 10-minute transcriptions were done flawlessly.\n* **Today:** Back to sucking. Anything over **30**/**60 seconds** fails.\n\nIs OpenAI A/B testing this or what? Having that 10-minute window (im sure is expensive for them) made is very powefull for certain use cases. No other chatbot has that big of window, that im aware of.\n\n**Anyone else seeing these 1-minute caps return today?**",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3vexj/is_it_just_me_or_did_chatgpt_just_nerf_voice/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o574tg1",
          "author": "qualityvote2",
          "text": "u/mandressta, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 17:29:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5khx2y",
          "author": "mandressta",
          "text": "I fixed it, delete cache on chatgpt app and restart phone",
          "score": 2,
          "created_utc": "2026-02-15 20:40:23",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5femhc",
          "author": "Hawk-432",
          "text": "You on free or? For me it always does 10 mins",
          "score": 1,
          "created_utc": "2026-02-15 00:12:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ffsic",
              "author": "mandressta",
              "text": "Pro",
              "score": 1,
              "created_utc": "2026-02-15 00:19:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ffvsd",
                  "author": "mandressta",
                  "text": "So you haven't seen any changes?? It still doesn't work since yesterday",
                  "score": 1,
                  "created_utc": "2026-02-15 00:19:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bo4mo",
          "author": "mandressta",
          "text": "Anyone?",
          "score": 0,
          "created_utc": "2026-02-14 11:20:19",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7g7ty",
      "title": "What is the best way you‚Äôve used agents or genAI for fantasy football or nfl statistics?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r7g7ty/what_is_the_best_way_youve_used_agents_or_genai/",
      "author": "explorahhh",
      "created_utc": "2026-02-17 19:34:22",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "Header says it all\n\nAny packages you recommend uploading? Layman-friendly please",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r7g7ty/what_is_the_best_way_youve_used_agents_or_genai/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5x3vn4",
          "author": "qualityvote2",
          "text": "u/explorahhh, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-17 19:34:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r44b5m",
      "title": "ChatGPT Deep Research now has two parts to the output...I don't get it.",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r44b5m/chatgpt_deep_research_now_has_two_parts_to_the/",
      "author": "Kindly-Form-8247",
      "created_utc": "2026-02-13 23:14:18",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "The 'Legacy' deep research had one output...it's inside that black/inset window. New deep research seems to have this still, but long before the actual research is complete, it's generating output in a normal ChatGPT response as well.\n\nWhat's with the two-part thing? Which output is the actual Deep Research output?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r44b5m/chatgpt_deep_research_now_has_two_parts_to_the/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o591ubb",
          "author": "qualityvote2",
          "text": "u/Kindly-Form-8247, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 23:14:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r92tz4",
      "title": "How strict is OpenAI with account sharing? Perma ban? Warning? Pro subscription, 2 of 3 users only lightweight chat use",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r92tz4/how_strict_is_openai_with_account_sharing_perma/",
      "author": "TrainingEngine1",
      "created_utc": "2026-02-19 15:53:43",
      "score": 4,
      "num_comments": 14,
      "upvote_ratio": 0.75,
      "text": "I'm hesitant but I'd be the main person using it for coding and Pro model usage. The other 2 are sort of doing me a favor by splitting the cost despite their lesser usage, entirely just basic chats mostly with non-Pro models.\n\nI looked into alternatives but their Teams/Business option provides only 15 Pro model messages per month which is too little.\n\n\nOnly thing I worry about is just an outright ban + all my data gone and unretrievable. Is even a thing that's been documented happening? \n\nOr are they likely flagging far more usage-hungry, higher user count people who share accounts?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r92tz4/how_strict_is_openai_with_account_sharing_perma/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o69c8kz",
          "author": "qualityvote2",
          "text": "Hello u/TrainingEngine1 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-19 15:53:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69if47",
          "author": "gptbuilder_marc",
          "text": "That‚Äôs kind of the real fork here.\n\nIt‚Äôs not really about how strict they say they are. It‚Äôs about how much risk you‚Äôre okay carrying on something you rely on.\n\nAre the three of you usually logging in from the same place, or totally different IPs and devices?\n\nEnforcement tends to look more at usage patterns than just the number of people.",
          "score": 2,
          "created_utc": "2026-02-19 16:23:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6bebx6",
              "author": "TrainingEngine1",
              "text": ">It‚Äôs not really about how strict they say they are. It‚Äôs about how much risk you‚Äôre okay carrying on something you rely on.\n\nI'm already leaning against it but just trying to gauge whether others have been warned or know people who've been warned or banned.\n\n\n>Are the three of you usually logging in from the same place, or totally different IPs and devices?\n\n2 places. My house and their house (the 2 of them).",
              "score": 1,
              "created_utc": "2026-02-19 21:49:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69xnib",
          "author": "shitlord_god",
          "text": "consider building a frontend for the API and using that instead of pro? (Have you looked at the pro v. api costs for your project?) that way all three folks can log into a webportal y'all own and you stay on the right side of the EULA?\n\n\nI don't know enough about the API EULA, or your projects though to make that suggestion.",
          "score": 2,
          "created_utc": "2026-02-19 17:36:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b7f1b",
              "author": "TrainingEngine1",
              "text": "I'm quite sure Pro via API would be a lot more expensive and setting up a whole chat frontend that uses API for them would be kind of a pain. A recent message I sent with 5.2 on extra high reasoning used 155k input tokens, 12.2k output tokens, 11.1k reasoning tokens. If that were with 5.2 Pro API pricing that would be $7.12 lol",
              "score": 1,
              "created_utc": "2026-02-19 21:15:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69cl4w",
          "author": "JamesGriffing",
          "text": "The odds are not zero, it's not worth it. \n\nLong term it likely won't work out the way you are hoping it would. ",
          "score": 3,
          "created_utc": "2026-02-19 15:55:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69g20c",
          "author": "Own_Professional6525",
          "text": "From what I‚Äôve seen, OpenAI tends to focus on clearly abusive or high-risk sharing rather than small, low-impact cases. It‚Äôs always safest to follow their terms, but lightweight usage like you described usually hasn‚Äôt caused permanent bans.",
          "score": 2,
          "created_utc": "2026-02-19 16:12:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69dq13",
          "author": "Pasto_Shouwa",
          "text": "If they find out they'll ban you. But I don't know how easily they can tell.\n\nI share mine with my brother, but we live together, and we are not too far away from each other when we use it, sometimes one of us can be at university a couple of towns away.\n\nBut I don't know what would happen if you share it with people that live in different homes. I imagine they won't make the effort to ban people like that unless they share it with a VPN, but I don't know.",
          "score": 1,
          "created_utc": "2026-02-19 16:00:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69ki19",
          "author": "modified_moose",
          "text": "Why don't they both just use Plus? 200 vs. 240 wouldn't be worth the risk for me.",
          "score": 1,
          "created_utc": "2026-02-19 16:33:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6b4aoj",
              "author": "TrainingEngine1",
              "text": "They're knowingly doing me a favor by offering to split it, so it's not really about the cost for them.",
              "score": 1,
              "created_utc": "2026-02-19 21:00:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69zkcu",
          "author": "Ari45Harris",
          "text": "I let my mum use my account and had no problems with it. I think it‚Äôs to prevent selling account access and abusing their models.",
          "score": 1,
          "created_utc": "2026-02-19 17:45:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6a722l",
          "author": "TorontoPolarBear",
          "text": "I didn't even realize this, and it's even in our instructions that two of us share the account, and if it's not sure (and it's relevant) that it should ask us who's at the keyboard.",
          "score": 1,
          "created_utc": "2026-02-19 18:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ddluz",
          "author": "manjit-johal",
          "text": "In my case, it treats account sharing the same way most saas platforms do. Once they detect multiple distinct users on one Pro plan they‚Äôll flag it because the license is tied to a single seat. If you need team access it‚Äôs safer to upgrade so you don‚Äôt risk a surprise suspension later.",
          "score": 1,
          "created_utc": "2026-02-20 05:01:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}