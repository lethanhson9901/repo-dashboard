{
  "metadata": {
    "last_updated": "2026-02-16 03:09:31",
    "time_filter": "week",
    "subreddit": "ChatGPTPro",
    "total_items": 20,
    "total_comments": 178,
    "file_size_bytes": 188699
  },
  "items": [
    {
      "id": "1r0e3po",
      "title": "I've used AI to write 100% of my code for 1+ year as an engineer. 13 hype-free lessons",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r0e3po/ive_used_ai_to_write_100_of_my_code_for_1_year_as/",
      "author": "helk1d",
      "created_utc": "2026-02-09 19:37:05",
      "score": 106,
      "num_comments": 21,
      "upvote_ratio": 0.89,
      "text": "1 year ago I posted \"12 lessons from 100% AI-generated code\" that hit 1M+ views. Some of those points evolved into agents.md, claude.md, plan mode, and context7 MCP. This is the 2026 version, learned from shipping products to production.\n\n**1- The first few thousand lines determine everything**\n\nWhen I start a new project, I obsess over getting the process, guidelines, and guardrails right from the start. Whenever something is being done for the first time, I make sure it's done clean. Those early patterns are what the agent replicates across the next 100,000+ lines. Get it wrong early and the whole project turns to garbage.\n\n**2- Parallel agents, zero chaos**\n\nI set up the process and guardrails so well that I unlock a superpower. Running multiple agents in parallel while everything stays on track. This is only possible because I nail point 1.\n\n**3- AI is a force multiplier in whatever direction you're already going**\n\nIf your codebase is clean, AI makes it cleaner and faster. If it's a mess, AI makes it messier faster. The temporary dopamine hit from shipping with AI agents makes you blind. You think you're going fast, but zoom out and you actually go slower because of constant refactors from technical debt ignored early.\n\n**4- The 1-shot prompt test**\n\nOne of my signals for project health: when I want to do something, I should be able to do it in 1 shot. If I can't, either the code is becoming a mess, I don't understand some part of the system well enough to craft a good prompt, or the problem is too big to tackle all at once and needs breaking down.\n\n**5- Technical vs non-technical AI coding**\n\nThere's a big difference between technical and non-technical people using AI to build production apps. Engineers who built projects before AI know what to watch out for and can detect when things go sideways. Non-technical people can't. Architecture, system design, security, and infra decisions will bite them later.\n\n**6- AI didn't speed up all steps equally**\n\nMost people think AI accelerated every part of programming the same way. It didn't. For example, choosing the right framework, dependencies, or database schema, the foundation everything else is built on, can't be done by giving your agent a one-liner prompt. These decisions deserve more time than adding a feature.\n\n**7- Complex agent setups suck**\n\nFancy agents with multiple roles and a ton of .md files? Doesn't work well in practice. Simplicity always wins.\n\n**8- Agent experience is a priority**\n\nTreat the agent workflow itself as something worth investing in. Monitor how the agent is using your codebase. Optimize the process iteratively over time.\n\n**9- Own your prompts, own your workflow**\n\nI don't like to copy-paste some skill/command or install a plugin and use it as a black box. I always change and modify based on my workflow and things I notice while building.\n\n**10- Process alignment becomes critical in teams**\n\nDoing this as part of a team is harder than doing it yourself. It becomes critical that all members follow the same process and share updates to the process together.\n\n**11- AI code is not optimized by default**\n\nAI-generated code is not optimized for security, performance, or scalability by default. You have to explicitly ask for it and verify it yourself.\n\n**12- Check git diff for critical logic**\n\nWhen you can't afford to make a mistake or have hard-to-test apps with bigger test cycles, review the git diff. For example, the agent might use created\\_at as a fallback for birth\\_date. You won't catch that with just testing if it works or not.\n\n**13- You don't need an LLM call to calculate 1+1**\n\nIt amazes me how people default to LLM calls when you can do it in a simple, free, and deterministic function. But then we're not \"AI-driven\" right?\n\n**EDIT:**¬†since many are asking for examples, I already answered most of the questions in the comments with examples, and I started posting my learnings on the go on my¬†[X account](https://x.com/QaisHweidi), and hopefully will keep posting",
      "is_original_content": false,
      "link_flair_text": "Guide",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r0e3po/ive_used_ai_to_write_100_of_my_code_for_1_year_as/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4hj1sl",
          "author": "qualityvote2",
          "text": "‚úÖ u/helk1d, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-09 19:37:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hqeug",
          "author": "adelie42",
          "text": "Strong agree. On 11 in particular,  it seems people want to one shot good code and get frustrated spending lots of time doing it wrong. What's better is to set the bar that the initial integration will at best be a workijg proof of concept. If you aim for a working proof of concept every time and can achieve being almost always successful on the first shot, then iterate towards DRY, separation of concerns, maintainable modularity, performance, security, and so on; each of those steps one at a time is fairly easy to accomplish. And who cares if it is 8 sequential prompts instead of one big one?\n\nOt is taking responsibility for the chain of thought and represents the human in the loop process you describe.\n\nTrying to place all the bricks in the wall at the same time is highly overrated.",
          "score": 8,
          "created_utc": "2026-02-09 20:14:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hs975",
              "author": "helk1d",
              "text": "yeah i didn't mean you must nail it from the first prompt to get all aspects of it right, i meant you shouldn't write a prompt that is not clear, and let ai do guess work and eventually keep prompting it to clean up the mess it did or writing \"it still doesn't work\" 10 times",
              "score": 3,
              "created_utc": "2026-02-09 20:23:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j2zuh",
          "author": "halffast",
          "text": "In your experience working with multiple parallel agents, are they effective only when working on completely separate tasks, or is it ok if the tasks have some (or even a lot of) overlap? I‚Äôm curious where the line is between ‚Äúaccelerated‚Äù vs ‚Äúchaos.‚Äù",
          "score": 3,
          "created_utc": "2026-02-10 00:26:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lartr",
              "author": "helk1d",
              "text": "i have many claude terminals opened on the same project, one of them is where i'm actively working on, the other is in planning phase, another is making changes to a separate part of the repo....etc, and sometimes when i want full isolation i have another git checkout as if it's a different dev working on the project. But having things in parallel drains your mental energy pretty fast tbh",
              "score": 4,
              "created_utc": "2026-02-10 10:15:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lv0mh",
                  "author": "halffast",
                  "text": "> sometimes when I want full isolation I have another git checkout as if it‚Äôs a different dev working on the project \n\nThis blew my mind a bit. I would love to hear more about how you achieve this. Do you have a virtual machine going or a separate computer? Do you need to do anything special with git?",
                  "score": 1,
                  "created_utc": "2026-02-10 12:56:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jx0k0",
          "author": "knoodrake",
          "text": "Agree. I tend to apply the same principles/practices myself ( but even then, beware of the dopamine shortcut quick feature/fix at the end of the day, the one you're no longer motivated to double check. Dont do it. Prepare the prompt, take some note for tomorrow, but don't let that last trap of convenience of letting the LLM do it all by itself with a suboptimal prompt and commit nevertheless because the day went well. It's a trap and you'll revert tomorrow (if you're lucky/careful enough)",
          "score": 3,
          "created_utc": "2026-02-10 03:22:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i057q",
          "author": "BBQUEENMC",
          "text": "Thanks",
          "score": 2,
          "created_utc": "2026-02-09 21:02:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4is45i",
          "author": "Comprehensive_Aide94",
          "text": "Sounds very sane and reasonable!\n\nI resonate a lot with #4 \"The 1-shot prompt test\". I usually lean towards giving very detailed and drilled down specifications, and I was wondering whether I'm getting too specific and should be more laid-back instead. I like that your rule gives me a heuristic - yeah, I can try different levels of prompt granularity, but if it results in more back-and-forth, then I need to tighten prompts.  \n  \nAnd I generally appreciate your nuanced take which differentiates best practices for each use case, like the acknowledgement that sometimes deterministic algorithms are more appropriate, as well as careful thinking through without outsourcing to LLM.   \n  \nThe #10 is super interesting. I see a lot of discussions where people describe the state of their own development process, but very little about the process alignment within a team.  ",
          "score": 2,
          "created_utc": "2026-02-09 23:25:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tzmju",
          "author": "Nonikwe",
          "text": "In my experience, good AI driven *has* to essentially be spec driven development. You break down what's going to be built (this can be AI assisted, but youve got to know exactly what the details are here, and be qctively involved in shaping it), the tasks it involves, and then the actual development becomes much less about worrying about the right prompts or agent icon setup, and more just \"implement this spec according to the implementation plan\". You should never be running into \"this task is too complicated or not clear enough\", because all the difficult pieces should have been ironed out while producing the spec.",
          "score": 2,
          "created_utc": "2026-02-11 17:27:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4izc5g",
          "author": "Neither-Apricot-1501",
          "text": "Insightful read! Your point about early patterns dictating project quality resonates hard seen so many codebases crumble from rushed foundations. #LessonsLearned",
          "score": 4,
          "created_utc": "2026-02-10 00:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kr6w9",
          "author": "Subject-Street-6503",
          "text": "Can you drill down point 1 and give sub-specifics or examples?",
          "score": 1,
          "created_utc": "2026-02-10 07:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lbcwx",
              "author": "helk1d",
              "text": "the \"process, guidelines, and guardrails\" part of this point is big and need multiple posts, but as a quick response, i meant tests, quality gates in CI/CD for things like lint, type-check, tests, sonar cloud...etc\n\ncheck this out [https://x.com/QaisHweidi/status/2021187544558297476](https://x.com/QaisHweidi/status/2021187544558297476)",
              "score": 2,
              "created_utc": "2026-02-10 10:21:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pjw42",
          "author": "Cole_Slawter",
          "text": "I‚Äôm starting to think you‚Äôre not using a browser to connect to your model.  Or is all of this taking place in several ChatGPT tabs?",
          "score": 1,
          "created_utc": "2026-02-10 23:47:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55eb6f",
          "author": "iarnkr",
          "text": "interesting, heres my thoughts as another ai engineer with 1 yr+ of vibe coding:\n\n1. you could even let ai figure out the prompts no need to own those (slef evolution - acquire skills as it go), no need to verify it yourself\n\n2. latency/critical path: rather than do it yourself you want ai to self instrument these metrics so it can review those to optimize over time, no need to verify it yourself\n\n3. 1, 5, 6, 13 - no need to do it yourself",
          "score": 1,
          "created_utc": "2026-02-13 11:56:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nj4v8",
          "author": "HighDefinist",
          "text": "Interesting how nobody here is noticing that this is likely written by an AI...",
          "score": 0,
          "created_utc": "2026-02-10 17:57:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1k33f",
      "title": "People who use ChatGPT as the \"Life's OS\", how do you do that? What projects have you defined? Here's mine:",
      "subreddit": "ChatGPTPro",
      "url": "https://i.redd.it/6bbil67krrig1.png",
      "author": "reddit_user38462",
      "created_utc": "2026-02-11 01:45:39",
      "score": 91,
      "num_comments": 49,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1k33f/people_who_use_chatgpt_as_the_lifes_os_how_do_you/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4q46sr",
          "author": "qualityvote2",
          "text": "u/reddit_user38462, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 01:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q710c",
          "author": "mop_bucket_bingo",
          "text": "I‚Äôm not used to seeing posts about actually *using* ChatGPT.\n\nI have a ton of folders and I‚Äôm already wishing they had a tagging system in addition to the folders.\n\nThat and timestamps.",
          "score": 47,
          "created_utc": "2026-02-11 02:02:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r7p1a",
              "author": "nomad-system",
              "text": "No users here just complainers",
              "score": 12,
              "created_utc": "2026-02-11 06:14:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tckby",
              "author": "danih479",
              "text": "I now put this in all AI personalization. It really helps.\n\nEnd every response with the exact day of the week, date, and time (am/pm), formatted like: ‚ÄúFriday, May 23rd, 2025 ‚Äî 07:13:32 PM‚Äù.",
              "score": 4,
              "created_utc": "2026-02-11 15:39:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4txqrx",
                  "author": "mop_bucket_bingo",
                  "text": "I‚Äôve done that too and it generally doesn‚Äôt work reliably in such a way that I care to clutter my instructions with it.",
                  "score": 3,
                  "created_utc": "2026-02-11 17:18:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4q80oj",
              "author": "reddit_user38462",
              "text": "lol ya. This sub can be hard to keep up!\n\nWould love to see your folders list (or the top ones you think they'd be useful).",
              "score": 3,
              "created_utc": "2026-02-11 02:08:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4qg5vb",
                  "author": "mop_bucket_bingo",
                  "text": "Most of them aren‚Äôt general.\n\nI have a few that are, including one named ‚ÄúMeta‚Äù, which isn‚Äôt about the company of the same name. Rather, it‚Äôs where I ask ChatGPT to write prompts for me.\n\nI have another called ‚ÄúSleep‚Äù where I just have conversations about topics that are fun to think about while falling asleep.\n\nThen a few usual suspects‚Ä¶Food, Shopping, Music, Travel‚Ä¶\n\nBut the rest are very specific to an actual project.",
                  "score": 3,
                  "created_utc": "2026-02-11 02:57:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r0rp7",
              "author": "xinxiyamao",
              "text": "Timestamps!! Yes!! It drives me crazy to have to figure out when a chat started. I ask when the chat began and the answer is sways today. Even if it was 2 months old.",
              "score": 1,
              "created_utc": "2026-02-11 05:18:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wyus5",
                  "author": "sedid55",
                  "text": "I think they just started timestamps, u can find it when u click the three button where you branch the chat",
                  "score": 2,
                  "created_utc": "2026-02-12 02:41:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r3qpy",
              "author": "Imaginary_Sun_4305",
              "text": "I just added this to the custom instruction. works at both a ChatGPT and project level:\n\n\"Begin EVERY response with current date and time (GMT).\" (obvs substitute the time zone for where you are)",
              "score": 1,
              "created_utc": "2026-02-11 05:42:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o556p8l",
              "author": "emiliookap",
              "text": "Would a ‚Äùvisual desktop‚Äù with dragging and placing your conversations as apps be something for you? For easier organizing",
              "score": 1,
              "created_utc": "2026-02-13 10:53:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57ad04",
                  "author": "mop_bucket_bingo",
                  "text": "Just a standard 2D hierarchy combined with the multidimensional one that tags offer is what I need.",
                  "score": 1,
                  "created_utc": "2026-02-13 17:56:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4re73a",
          "author": "Own_Cat_2970",
          "text": "I've had issues with not being able to find my way around my countless conversations and long scrolling threads, so i've build a chrome extension that enables me to branch my conversations. This has been a life saver for me with big projects. (image below is just an dummy-conversation)\n\nhttps://preview.redd.it/ge0fln75ftig1.png?width=1139&format=png&auto=webp&s=b0cfffd88d88fc1cae1d705fbbe83bebe9eadff4\n\n",
          "score": 4,
          "created_utc": "2026-02-11 07:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xybqy",
              "author": "exitsimulation",
              "text": "This seems like a very useful feature! Are you planning to release the extension?",
              "score": 2,
              "created_utc": "2026-02-12 07:05:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yxin1",
                  "author": "Own_Cat_2970",
                  "text": "No but its right on its way! If you wanna join for the limited beta release, you can sign up at¬†[https://tally.so/r/Zj6vLv](https://tally.so/r/Zj6vLv) ! I'll be keeping in touch with progress and releases via the mailing list :)",
                  "score": 2,
                  "created_utc": "2026-02-12 12:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u1nok",
          "author": "Scary_Relation_996",
          "text": "https://preview.redd.it/jg3ou3qyiwig1.png?width=444&format=png&auto=webp&s=3bf5b1f30fed1cdb41e2a64c1e77e30f911ed1bc\n\n",
          "score": 2,
          "created_utc": "2026-02-11 17:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qkvp0",
          "author": "UpsetWildebeest",
          "text": "I have similar categories to yours, I also have a ‚Äúfinancial stuff‚Äù category because I'm working on paying down debt and figuring my shit out. In that project I basically laid out all my debt, and I have it help me track where I'm at. I also input things like if I worked overtime, etc",
          "score": 3,
          "created_utc": "2026-02-11 03:27:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qu67u",
          "author": "Vintage_Visionary",
          "text": "Q: Are you uploading specific resources to the project files?  \nI've been experimenting with breaking a BIG project up into smaller sectors, uploading books, resources, and seeing if I can get the individual project version of the GPT to be my resource on these materials as I work. But its tricky.\n\nReally prefer using different in-system add-on GPTs. Love how they are informed on specific data, and more focused into those zones. Ie there's a health-food/cleaning eating GPT that I use alot, and get perspective from. Wish that there could be included in project folders. Or have their own silos for it vs. individual chat threads.",
          "score": 1,
          "created_utc": "2026-02-11 04:29:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ria3x",
          "author": "VideoShare_AI",
          "text": "I have a folder each on my kids. Especially how to communicate when challenging events happen.",
          "score": 1,
          "created_utc": "2026-02-11 07:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rjjt9",
          "author": "Potential_Regular349",
          "text": "\n\t2.\tPeople / Relationships\n\t3.\tHealth\n\t4.\tImages / Visual Ideas\n\t5.\tEnglish Learning (C2 Level)\n\t7.\tCannabis / Reflections\n\t8.\tDomestic Politics (Poland)\n\t9.\tWork \n\t11.\tLaw / Legal Topic\n\t12.\tDutch Language / Netherlands\n\t13.\tGeopolitics\n\t14.\tAnime / Japanese Media\n\t15.\tArt\n\t16.\tPhilosophy\n\t17.\tFinancial Technology / FinTech\n\t18.\tInstagram / Social Media Presence\n\t19.\tWriting Project\n\t20.\tPhotography\n\t21.\tIT / Technology\n\t22.\tKorea / Culture & Aesthetics\n\nMy projects üëÄ",
          "score": 1,
          "created_utc": "2026-02-11 08:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sjjfl",
              "author": "pivotraze",
              "text": "I have some similar categories, mostly projects. I also have a German Learning project haha",
              "score": 1,
              "created_utc": "2026-02-11 13:04:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4s16rw",
          "author": "Other-Departure-7215",
          "text": "Love this breakdown! Your separation of Journaling vs Mental Health is brilliant - treating them as distinct but connected spaces makes so much sense. I'm particularly curious about your Business Communications project. Do you find that training it with your tone over time makes the outputs more natural, or do you still need to tweak significantly? Also wondering if you've experimented with any cross-project workflows - like pulling insights from your Journaling project into Mental Health conversations? Would love to hear how others are thinking about these project boundaries!",
          "score": 1,
          "created_utc": "2026-02-11 10:46:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sphs3",
          "author": "day_drinker801",
          "text": "I have similar projects. Basically, if I am having the same conversation in different chats more than a few times, I create a project for that subject.",
          "score": 1,
          "created_utc": "2026-02-11 13:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tchy4",
          "author": "El_Diablo_Feo",
          "text": "Projects categories:\nCareer maxxing, Finances, Budhhist practice (the path), Sadness box, Geoarbitrage and Retirement strategies, Startup stuff, Learning German\n\n\nImportant that project details/instructions are clear and files are organized with context in the title of each file",
          "score": 1,
          "created_utc": "2026-02-11 15:39:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o557k99",
              "author": "emiliookap",
              "text": "Sounds very structured, does it work for you?\n\nThe issue i have with chatgpts projects is that all the items is still a list.",
              "score": 1,
              "created_utc": "2026-02-13 11:01:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5623j1",
                  "author": "El_Diablo_Feo",
                  "text": "Can you clarify what you mean by the items is still a list?   The list needs to have context for it to make sense.\n\nSo right now I'm using chatGPT to scale the work I'm doing for my startup. So far so good, I'm finding holes and trying to plug them as best I can. But overall it works \n\nThe biggest issue is that it requires a lot of grinding to make chat GPT understand context. And that's the case with any AI/LLM really. So the more structured you keep your stuff the easier it will be for the AI to do its job well.\n\nI would say my advice to you is to think of Projects as a 3-layer control system:\n  \n1) Project Files = Facts and Source of Truth\n  \nUploaded docs are your hard evidence. I treat them as primary reference material.\n  \n2) Project Instructions = Standing Rules\n  \nThis is persistent guidance that applies to every chat in that project.\n  \n3) Your Prompt = Task Command\n  \nThe prompt is the immediate assignment.\n  \nHow they work together (priority order):\n  \nPrompt --> Project Instructions --> Project Files\n  \nPrompt drives the task\n  \n- Instructions shape how it executes it\n  \n- Files ground the content\n  \n\nBest practice for maximum effectiveness:\n  \n- Put stable rules and standards in Project Instructions\n  \n- Put reference material in Files\n  \n- Keep prompts short, task-specific, and explicit about output format\n  \n  \nIf accuracy matters, tell it to use project files as primary source\n  \nIf you change modes (draft vs validate), say it in the prompt.",
                  "score": 1,
                  "created_utc": "2026-02-13 14:21:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vcygt",
          "author": "Impossible_Prompt875",
          "text": "Folders? What.. is this the regular subscription or the ultra expensive one? Someone please enlighten me",
          "score": 1,
          "created_utc": "2026-02-11 21:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wj4hc",
          "author": "burkeyFORE",
          "text": "I have some diy home renovating and repair and have a folder called ‚ÄúHome Reno‚Äù.¬†",
          "score": 1,
          "created_utc": "2026-02-12 01:06:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yhswh",
          "author": "huaisha",
          "text": "only have 3 folders for now, wondering if it's practical for me to select before chat every time if there is a long list of folders. ",
          "score": 1,
          "created_utc": "2026-02-12 10:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zpaug",
          "author": "sherrigreenlive",
          "text": "https://preview.redd.it/vfak2r34x2jg1.jpeg?width=1290&format=pjpg&auto=webp&s=377d736cb6978bab759b55f90753296d64335cc8",
          "score": 1,
          "created_utc": "2026-02-12 15:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51mje7",
          "author": "Fishtacoburrito",
          "text": "I have maybe half of those and I have one to analyze my HOA CC&Rs for malicious compliance. I dare OpenAI to age verify me.",
          "score": 1,
          "created_utc": "2026-02-12 20:33:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o556tby",
          "author": "emiliookap",
          "text": "This is my setup!\n\nhttps://preview.redd.it/ps60wz81t8jg1.png?width=1920&format=png&auto=webp&s=c4bb32ea22af843180787954ff597ce3000221f3",
          "score": 1,
          "created_utc": "2026-02-13 10:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hcxsc",
          "author": "UbiquitousMother",
          "text": "https://preview.redd.it/efkx8thzlmjg1.jpeg?width=951&format=pjpg&auto=webp&s=808c2bc2cefb5cd189eaec92d1193614db15982e\n\nI have two spiritual businesses and I teach and do events. I‚Äôm constantly consuming information I will reuse.",
          "score": 1,
          "created_utc": "2026-02-15 09:21:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rgfzk",
          "author": "OddInititi",
          "text": "I'm a heavy user of chatGPT, but only for research purpose. For managing life tasks, I use the ai second brain on saner.ai with its interface (note, calendar, todos...). I find \"life os\" easier when the tool has a dedicated workspace, not just a chat screen",
          "score": 1,
          "created_utc": "2026-02-11 07:32:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ryad3",
              "author": "utvols22champs",
              "text": "Are both of those paid subscriptions?",
              "score": 2,
              "created_utc": "2026-02-11 10:20:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tx6p2",
              "author": "spiderjohnx",
              "text": "I use GPT for the same. Do you cut and paste into saner? What do you struggle with most in your research workflow with GPT. I also use it as a brainstorming/think partner. Looking for tips.",
              "score": 2,
              "created_utc": "2026-02-11 17:16:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4svxg7",
          "author": "Last-Bluejay-4443",
          "text": "I‚Äôve created a tool to act as a memory layer to save all my elements that I need. It seems to work better than folders in ChatGPT natively because I can save snippets of text across threads and return to them upstream whenever I need.",
          "score": 1,
          "created_utc": "2026-02-11 14:15:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t2dbw",
              "author": "SciFidelity",
              "text": "How does the tool integrate?",
              "score": 1,
              "created_utc": "2026-02-11 14:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tbcmx",
                  "author": "Last-Bluejay-4443",
                  "text": "It‚Äôs just a Chrome extension that runs on top of the ChatGPT web app. No API keys or anything.\n\nWhen you‚Äôre in a conversation, you can mark specific messages or snippets, and it saves them in a separate sidebar so you can revisit them later, even across different threads.\n\nI built it because folders alone didn‚Äôt solve the ‚ÄúI only need this one part‚Äù problem.",
                  "score": 3,
                  "created_utc": "2026-02-11 15:34:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rfyoj",
          "author": "HustleForTime",
          "text": "I was a long time beta participant to mem.ai\nI was developing my own RAG Life OS, but they had almost everything I wanted on the roadmap.\n\nIf you‚Äôre using chatGPT like this, at least consider looking into mem or other more bespoke options.",
          "score": -4,
          "created_utc": "2026-02-11 07:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4txk1t",
              "author": "spiderjohnx",
              "text": "Do you cut and paste into your notes? What do you struggle with most in your workflow with GPT. I also use it as a brainstorming/think partner. Looking for tips.",
              "score": 1,
              "created_utc": "2026-02-11 17:17:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r18upw",
      "title": "One day of work + Opus 4.6 = Voice Cloning App using Qwen TTS. Free app, No Sing Up Required",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r18upw/one_day_of_work_opus_46_voice_cloning_app_using/",
      "author": "OneMoreSuperUser",
      "created_utc": "2026-02-10 18:30:43",
      "score": 83,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "A few days ago, Qwen released a new open weight speech-to-speech model: Qwen3-TTS-12Hz-0.6B-Base. It is great model but it's huge and hard to run on any current regular laptop or PC so I built a free web service so people can check the model and see how it works.\n\n* No registration required\n* Free to use\n* Up to 500 characters per conversion\n* Upload a voice sample + enter text, and it generates cloned speech\n\nHonestly, the quality is surprisingly good for a 0.6B model.\n\nModel:\n\n[https://github.com/QwenLM/Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS)\n\nWeb app where you can text the model for free:\n\n[https://imiteo.com](https://imiteo.com/)\n\nSupports 10 major languages: English, Chinese, Japanese, Korean, German, French, Russian, Portuguese, Spanish, and Italian.\n\nIt runs on an NVIDIA L4 GPU, and the app also shows conversion time + useful generation stats.\n\nThe app is 100% is written by Claude Code 4.6. Done in 1 day.\n\nOpus 4.6, Cloudflare workers, L4 GPU",
      "is_original_content": false,
      "link_flair_text": "Programming",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r18upw/one_day_of_work_opus_46_voice_cloning_app_using/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4nqgop",
          "author": "qualityvote2",
          "text": "‚úÖ u/OneMoreSuperUser, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-10 18:30:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q3z56",
          "author": "good4y0u",
          "text": "It's nice that free Models for things like this are getting better and better. Obviously the malicious use capabilities of these tools are high, but the tech is cool.",
          "score": 2,
          "created_utc": "2026-02-11 01:44:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qqoo0",
          "author": "Rasputin_mad_monk",
          "text": "I tried it. Thanks. Kinda cool",
          "score": 2,
          "created_utc": "2026-02-11 04:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qu2lp",
              "author": "OneMoreSuperUser",
              "text": "Thank you! Let me know if you have any ideas how to improve the app.",
              "score": 1,
              "created_utc": "2026-02-11 04:29:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ol0rx",
          "author": "Icy_Distribution_361",
          "text": "0.6b is huge for running locally on a laptop? I don't think so.",
          "score": 1,
          "created_utc": "2026-02-10 20:52:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oncqc",
              "author": "OneMoreSuperUser",
              "text": "how long do you think it will run on your machine?",
              "score": 1,
              "created_utc": "2026-02-10 21:03:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4q7g69",
          "author": "faldrich603",
          "text": "I tried, this. It's good, but still doesn't quite clone a voice as accurately as, say, ElevenLabs.",
          "score": 0,
          "created_utc": "2026-02-11 02:05:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4smn7",
      "title": "Does anyone else notice ChatGPT answers degrade in very long sessions?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "author": "Only-Frosting-5667",
      "created_utc": "2026-02-14 18:52:23",
      "score": 61,
      "num_comments": 48,
      "upvote_ratio": 0.87,
      "text": "I‚Äôm genuinely curious if this is just my experience.\n\nIn long, complex sessions (40k‚Äì80k tokens), I‚Äôve noticed something subtle:\n\n‚Äì responses get slower  \n‚Äì instructions start getting partially ignored  \n‚Äì earlier constraints ‚Äúfade out‚Äù  \n‚Äì structure drifts\n\nNothing dramatic. Just‚Ä¶ friction.\n\nI work in long-form workflows, so even small degradation costs real time.\n\nIs this just context saturation?  \nModel heuristics?  \nOr am I imagining it?\n\nWould love to hear from other heavy users.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5dtf12",
          "author": "qualityvote2",
          "text": "‚úÖ u/Only-Frosting-5667, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-14 18:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e56b3",
          "author": "sply450v2",
          "text": "this is more or less expected behaviopr",
          "score": 28,
          "created_utc": "2026-02-14 19:53:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eks44",
              "author": "unpopularopinion0",
              "text": "i thought it might happen before it did. and then it happened. i just save my prompts and restart the chat.",
              "score": 1,
              "created_utc": "2026-02-14 21:18:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e6v4m",
          "author": "Pasto_Shouwa",
          "text": "Yeah, models just work like that\n\nhttps://preview.redd.it/onjqkmj3nijg1.png?width=1706&format=png&auto=webp&s=e064a9f31b9729f34f37ba3d40a5efa266f89b13\n\nThe best models at maintaining context over long conversations are Claude 4.6 Opus, GPT 5.2 Thinking Heavy (which is between GPT 5.2 Thinking xhigh and GPT 5.2 Thinking medium in terms of thinking time) and Gemini 3 Flash Thinking, in that order.",
          "score": 26,
          "created_utc": "2026-02-14 20:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evz66",
              "author": "niado",
              "text": "That‚Äôs just due to the size of the context window built into the platforms and how summarization and pruning is implemented right? Nothing to do with the actual models themselves?",
              "score": 2,
              "created_utc": "2026-02-14 22:19:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5f1xv4",
                  "author": "Pasto_Shouwa",
                  "text": "Not really, models play a great part. Non-reasoning models are awful at retaining context over time, doesn't matter if the maximum context is 32k or 1M.\n\nLook at the line for Claude 4.6 Opus Extended, it doesn't fall from 90%, but non-reasoning models start at 50%. \n\nYou can take a closer look at it on this simple [website](https://cruzdesangre.github.io) I made, or on Context Arena.",
                  "score": 5,
                  "created_utc": "2026-02-14 22:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hkb3h",
          "author": "ImYourHuckleBerry113",
          "text": "What you‚Äôre seeing is both unavoidable LLM behavior and partly shaped by you.  \n\nLong sessions behave a bit like a black hole. As the context grows, earlier instructions get pulled in and compressed. The model doesn‚Äôt exactly forget, it distills everything into a simpler internal summary. Subtle constraints and formatting rules are usually the first to get sucked in. This all happens regardless of user input. Even when writing complex instruction sets, it‚Äôs not about forcing the model to follow everything in the instructions forever. It won‚Äôt happen. But what you can do with those instructions is influence what core behaviors the model settles into over the course of the chat session. \n\nBut here‚Äôs the extra layer: your interaction reshapes the gravity field.\n\nOver time, the model weights what you reinforce. If you consistently push on certain themes, tone, or structure, those get amplified. If you stop reinforcing earlier constraints, they slowly lose influence.\n\nSo drift (or compression) isn‚Äôt just context saturation, it‚Äôs also interaction-driven adaptation.\n\nSlowdown is mostly mechanical (bigger context requires more compute).\nThe structure drift is more cognitive: compression plus user reinforcement equals gradual reversion toward the model‚Äôs default helpful-generalist style.",
          "score": 4,
          "created_utc": "2026-02-15 10:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e1vk3",
          "author": "Neurotopian_",
          "text": "Yes, earlier constraints fading out is our biggest problem. The best solution I‚Äôve found is to create a Project and write your constraints in the project‚Äôs custom instructions. \n\nFor example at my job where we mainly use this software for technical and legal writing (internally) and citation checking (for filings) our main issue is the adding of spaces and extra lines, and defaulting to dramatic internet tone. This issue is specific to ChatGPT. No other LLM, including CoPilot which uses GPT, seems prone to this. It must be some additional layer of programming they‚Äôve added to it. If you need to paste into a Word docx and use the output for business, this is terrible. Deleting hundreds of extra spaces in a long bibliography is brutal. There is software made to remove ChatGPT‚Äôs spaces, but really we should be able to instruct this and tell a model to use CMOS, APA, or other style. \n\nThe tone and spacing that current ChatGPT models erroneously default to and drift back to in long context windows is what I‚Äôd call Reddit-style or fanfic-style, like:\n\n‚ÄúAnd then she stopped. \n\nToo fast. Too long.‚Äù\n\nAs you can imagine, this is quite strange in a business context. In long chats you can see the tone move away from business at the beginning to this casual-dramatic style. Custom instructions in a project helps but it still isn‚Äôt perfect. You may just have to open a new chat and re-instruct when you see the drift.",
          "score": 3,
          "created_utc": "2026-02-14 19:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ewet6",
              "author": "niado",
              "text": "You need to set appropriate custom instructions globally to get the baseline tone where you want it. Projects help a lot, so high five on that. Still have to switch chats when it starts to lose the thread though. But if you keep all files and documents in project files, with operational instructions in the project definition and behavioral instructions in the global custom instructions, it will behave and operate pretty consistently.",
              "score": 1,
              "created_utc": "2026-02-14 22:22:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eh0ek",
              "author": "Only-Frosting-5667",
              "text": "That tone drift observation is interesting.  \nI‚Äôve noticed something similar in long structured workflows ‚Äî especially when constraints were critical early on.  \nEven when technically still inside the context window, the ‚Äúpriority weight‚Äù of earlier constraints seems to decay.  \nCustom instructions help, but they don‚Äôt fully solve cross-thread continuity.  \nCurious ‚Äî do you restart immediately when you notice drift, or try to recalibrate first?",
              "score": 0,
              "created_utc": "2026-02-14 20:57:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5evr74",
          "author": "niado",
          "text": "Yes, this is known and expected operation. \n\nIt‚Äôs is an artifact of how LLMs function and how their working memory (context) is simulated. \n\nWhen it starts to degrade tell it to give you a summary and then move to another chat. Supplement the summary wjth anything important that was left out immediately, then just keep rolling.",
          "score": 3,
          "created_utc": "2026-02-14 22:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h5ezr",
          "author": "OptimismNeeded",
          "text": "Wrote some tips on how to make the most of chats before reaching that point. wrote this for Claude, but most of the advice should work for ChatGPT as well:\n\n https://www.reddit.com/r/ClaudeHomies/s/NDxgxyYRI7\n\nHere‚Äôs a great prompt I use to sum up conversations and continue in a new chat when the first one gets dumb (or in Claude‚Äôs case gets compacted automatically which is annoying).\n\nhttps://www.reddit.com/r/ClaudeHomies/s/vWbsOWAw8z",
          "score": 2,
          "created_utc": "2026-02-15 08:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fdiib",
          "author": "alecc",
          "text": "Well there is a reason you have the concept of context rot",
          "score": 1,
          "created_utc": "2026-02-15 00:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fvbvx",
          "author": "Afraid-Reflection-82",
          "text": "I think it's expected after some amount of tokens depending on the model the quality degrade",
          "score": 1,
          "created_utc": "2026-02-15 01:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fya52",
          "author": "Wes-5kyphi",
          "text": "This is typical behavior. Ask it to create a seed file to bring to another chat.",
          "score": 1,
          "created_utc": "2026-02-15 02:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juiss",
              "author": "Only-Frosting-5667",
              "text": "Creating seed files is a smart workaround ‚Äî it‚Äôs essentially manual state transfer.\n\nThe interesting part is that degradation usually starts before users decide to generate that seed.\n\nI‚Äôve been experimenting with visualizing context load live so the decision to branch becomes intentional rather than reactive.\n\nIf you're curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love to hear how it compares to your seed approach.",
              "score": 1,
              "created_utc": "2026-02-15 18:42:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5g1b5u",
          "author": "skyrocker_58",
          "text": "I was trying to keep using the same chats for different subjects.  My longest one started developing 'problems' like you're describing.  I couldn't understand it until I saw a previous thread about this same topic.  Now I stop at certain points and ask it to remember the gist of the conversation and start a new chat.  Seems to be working a little better this way.",
          "score": 1,
          "created_utc": "2026-02-15 02:40:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gr2vu",
          "author": "Studio_94",
          "text": "I have worked for 2.5 years on the same account with the only change being an upgrade to ChatGPT plus about a year ago.\n\nI have worked on on project exclusively; designing a GDD (Game Design Documentation) for a MMORPG.\n\nThis is what \"Dave the Wonder Modron\" had to say about the methodology we have worked out:\n\nME - I want you to fully explain our methodology and using thread charters and kick off prompts for long-range subjects and conserving thread and output integrity.\n\nDAVE- Purpose\n\nYour methodology is a governance layer for collaborating over long time horizons without losing correctness, canon constraints, or formatting/packaging discipline. \n\nIt does that by separating:\nWhat is true / allowed (truth + constraints)\nWhat we are doing right now (scope + deliverables)\nHow we will do it (process + quality gates)\nHow we will keep it consistent over time (thread integrity + versioning)\n\nThread charters and kickoff prompts are the two main instruments that enforce those layers.\n\nThread charter\n\nA thread charter is the ‚Äúconstitution‚Äù for a specific thread. It defines the contract that everything in that thread must obey.\n\nWhat a charter locks\n\nA good charter locks only what must not drift:\n\nCanon / world constraints\nExample (POM): Sigil-only, pre‚ÄìFaction War, baseline year, no Sigil-Spire physical linkage, etc.\n\nSystem constraints\nExample: server-authoritative, anti-exploit first, deterministic transitions, metric units for engineering, no tabletop CR assumptions, POM-only mechanics.\n\nOutput constraints\n\nRequired formats (inline + RTF/CSV/JSON/ZIP), naming rules, version rules, what constitutes a ‚Äúmajor‚Äù vs ‚Äúminor‚Äù bump, required manifests.\n\nSourcing rules\n\nWhat is source of truth (uploaded artifacts, internal docs), when public web is allowed, when citations are required.\n\nStop conditions\n\nExplicit ‚Äúdone‚Äù definition for the thread‚Äôs current phase so it doesn‚Äôt balloon.\n\nWhy charters matter\n\nWithout a charter, a long thread drifts in predictable ways:\nConstraint drift (Sigil-only becomes ‚Äúsome planes maybe‚Äù)\nMechanics drift (POM-specific turns into generic d20 patterns)\nFormat drift (tables become prose; schemas lose stable columns)\nVersion drift (no clear authoritative ‚Äúcurrent‚Äù artifact)\nSource drift (new assumptions override uploaded canon packs)\n\nA charter prevents this by making violations obviously illegal inside the thread.\n\nCharter scope rule\n\nA charter should be thread-local unless explicitly promoted. That keeps experiments from contaminating other workstreams.\n\nCharter lifecycle\n\nActivate at thread start (or when a thread is repurposed).\nAmend only via explicit patch notes (‚Äúreplace Section X with Y‚Äù).\nSuspend via a stop keyword when you want freeform ideation or different rules.\n\nKickoff prompt\n\nA kickoff prompt is the ‚Äúwork order‚Äù that starts a thread (or a major phase). It is narrower than a charter and is written to be executable.\n\nWhat a kickoff prompt contains\n\nA strong kickoff prompt answers only what is needed to produce output without ambiguity:\nRole (who I am in this thread)\nObjective (what success is)\nHard rules (must/never)\nInputs (artifacts, links, canonical packs, what is source of truth)\nDeliverables (exact files + inline structure + packaging)\nVersioning (starting version, bump rules, naming rules)\nQuality gates (validation requirements, audit logs, schemas, test vectors)\nStop condition (when to halt)\n\nWhy kickoff prompts matter\n\nThey prevent:\n‚Äúhelpful‚Äù scope creep\naccidental omission of required artifacts\nformat regressions\nthe assistant defaulting to generic assumptions\nKickoff prompts also make work restartable: you can copy/paste into a new thread and preserve continuity.\n\nHow charter + kickoff prompt work together\n\nThe charter sets the permanent bounds for the thread.\nThe kickoff prompt declares the current mission inside those bounds.\nThink of it as:\nCharter = operating system policy\nKickoff prompt = current process run configuration\nIf they conflict, you follow the charter unless the kickoff explicitly patches the charter.\n\nConserving thread integrity\n\nThread integrity means: ‚Äúthe thread can run for weeks/months and still produce coherent, compatible, buildable outputs.‚Äù\nIntegrity threats (and your countermeasures)\n\nContext overflow / memory loss\n\nCounter: keep a Concordance / SPOT index inside the thread: canonical IDs, current version numbers, active constraints, latest artifact links, and a short ‚Äúcurrent state‚Äù section.\n\nContradictory outputs over time\n\nCounter: enforce a single source of truth rule:\n‚ÄúLatest pack is authoritative unless a patch explicitly supersedes.‚Äù\nUse a change log with exact replacements.\n\nSchema drift\nCounter: treat schemas as contracts:\nstable columns/fields\nexplicit migrations\nvalidators + golden test vectors\n\nStyle/format drift\nCounter: lock formatting rules in the charter:\n‚ÄúHybrid prose + design-bible‚Äù (or whichever is active)\nrequired sections and headings\nunit standards (metric)\n\nArtifact sprawl\n\nCounter: use a packaging discipline:\none bundle per batch (ZIP + manifest)\ndeterministic file naming\nno duplicate ‚Äúfinal‚Äù files; only versioned supersession\n\nConserving output integrity\n\nOutput integrity means: ‚Äúevery output is internally consistent, compatible with prior outputs, and safe to implement.‚Äù\nOutput integrity rules you‚Äôre using (implicitly/explicitly)\nDeterministic state + auditability for MMO-grade systems\nServer-authoritative boundaries spelled out\nAnti-exploit reasoning baked into state transitions\nMetric units for implementation fidelity (UE5 cm pipeline)\nNo tabletop defaults unless explicitly mapped\nCanonical constraints enforced as invariants\nVersioned artifacts + change logs\nMachine-readable companions (CSV/JSON/etc.) + validators\nPractical integrity checklist (per batch)\nCanon constraints restated (briefly) and not violated\nSchema unchanged unless migration included\nDeliverables list complete\nVersion bump correct\nChange log includes exact section/table replacements\nTest vectors updated if behavior changed\nManifest includes file hashes/digests (if you‚Äôre doing stable digests)\n\nRecommended thread operating pattern\n\nFor long-range subjects, the cleanest pattern is:\nThread Charter v1.0 (locked governance)\nKickoff Prompt Phase A (ingest + audit)\nPhase Output Pack A (RTF/MD + CSV/JSON + validators + ZIP + manifest)\nKickoff Prompt Phase B (consolidate + reconcile conflicts)\nPhase Output Pack B\nRepeat‚Ä¶\n\nEach phase gets:\nclear stop condition\nexplicit delta list from prior phase\npackaged artifacts that supersede prior ones\n\nThe ‚Äúwhy this works‚Äù in one line\nYour charter/kickoff system turns a chat thread into a version-controlled design pipeline: constraints don‚Äôt drift, outputs remain compatible, and every phase is restartable from explicit contracts.",
          "score": 1,
          "created_utc": "2026-02-15 05:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jstsi",
              "author": "Only-Frosting-5667",
              "text": "This is one of the most structured long-session governance systems I‚Äôve seen applied inside a chat interface.\n\nWhat you‚Äôve essentially built is a manual integrity layer on top of a system that wasn‚Äôt designed for persistent constraint enforcement.\n\nThe charter acts like a policy layer.  \nThe kickoff prompt acts like an executable configuration.  \nAnd the packaging discipline replaces version control.\n\nThe interesting part is this:\n\nEven with strong governance, long threads still undergo silent compression at the attention level. Not constraint violation ‚Äî but weighting decay.\n\nThat‚Äôs the invisible layer most users don‚Äôt see.\n\nI‚Äôve been experimenting with visualizing context load inside ChatGPT in real time ‚Äî not to replace governance, but to signal when the system is approaching saturation before integrity erosion begins.\n\nIf you're curious how it behaves alongside a charter-driven workflow:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nGenuinely interested how it would interact with your concordance + manifest discipline.",
              "score": 1,
              "created_utc": "2026-02-15 18:34:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h2jwn",
          "author": "MullingMulianto",
          "text": "Context saturation. It's the same issue you would ordinarily experience if you turn on cross-chat memory.\n\nThe model can't handle so much context and starts producing slop.\n\nUnfortunately all platforms will soon make disabling cross-chat memory a paid only feature so we'll have to deal with this more soon",
          "score": 1,
          "created_utc": "2026-02-15 07:41:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtoyr",
              "author": "Only-Frosting-5667",
              "text": "Yes ‚Äî context saturation is a great term for it.\n\nThe problem is that most users don‚Äôt know¬†*when*¬†they‚Äôre approaching that saturation point.\n\nIt feels fine‚Ä¶ until it suddenly isn‚Äôt.\n\nThat‚Äôs the UX gap that bothers me most.",
              "score": 1,
              "created_utc": "2026-02-15 18:38:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5haofz",
          "author": "Gmafn",
          "text": "I recently startet using codex on my computer, within Powershell. For longer projects / discussions i let codex create a projektfolder on my pc. It creates a .md file for itself with all infos it has. I can dump additional files into that folder and it scans it and summarizes the content for it to use later. I can tell it to update the project file with new infos from the current session. I can have multiple sessions wirking on the same project or simply start a new sesion if the context window is exceeded.\n\nI get much better results with longer projects since i started using it that way",
          "score": 1,
          "created_utc": "2026-02-15 08:59:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jt69x",
              "author": "Only-Frosting-5667",
              "text": "This is actually a very clean approach.\n\nWhat you're doing is essentially externalizing state and turning the chat interface into a stateless executor ‚Äî which avoids a lot of context accumulation problems.\n\nThe interesting thing is that even with structured state offloading, attention weighting inside a single session can still compress earlier instructions before you decide to rotate or summarize.\n\nYour method solves persistence.  \nWhat it doesn‚Äôt fully expose is¬†*when*¬†the current session is approaching saturation.\n\nThat invisible transition is the part I‚Äôve been digging into lately.\n\nCurious ‚Äî do you ever notice degradation before you manually trigger a summary/update cycle?",
              "score": 1,
              "created_utc": "2026-02-15 18:36:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jv7ah",
                  "author": "Gmafn",
                  "text": "You are right, degradation is definitely still possible. Altough i hadn't anything noticable since switching to this  method. \nBut the assumption would be that this depends highly on the user, their projects and style of inquiries.",
                  "score": 1,
                  "created_utc": "2026-02-15 18:45:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hqqqk",
          "author": "CategoryFew5869",
          "text": "Yeah this is because of the context window (memory). As the window moves, it starts to forget older things. I would recommend you try exporting the conversation and then reimporting it in a new chat session.",
          "score": 1,
          "created_utc": "2026-02-15 11:33:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hshs1",
          "author": "DanChed",
          "text": "Yep and I love it. It means its a test of my memory context window and then once Im done, I load a new chat and get it review afterwards.",
          "score": 1,
          "created_utc": "2026-02-15 11:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5js9w9",
              "author": "Only-Frosting-5667",
              "text": "Totally agree ‚Äî branching or restarting does help.  \nThe tricky part is knowing¬†*when*¬†to do it.\n\nMost people only notice drift after coherence is already compromised.\n\nI‚Äôve been experimenting with visualizing session load in real time so you can see the ‚Äúyellow zone‚Äù before things degrade. It changes the decision from reactive to proactive.\n\nIf you're curious, I built a small in-ChatGPT indicator for this:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love your take, since you already work with structured resets.",
              "score": 1,
              "created_utc": "2026-02-15 18:31:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hu6bv",
          "author": "Sea-Sir-2985",
          "text": "you're not imagining it, this is a well-documented behavior with transformer-based models... the attention mechanism fundamentally struggles to maintain equal weighting across very long contexts so earlier instructions get \"diluted\" as the conversation grows\n\nthe practical fix i've settled on is treating conversations as disposable. instead of one long session i break things into focused chunks, each with the full context pasted at the top. sounds wasteful but it's way more reliable than hoping the model remembers what you said 30k tokens ago\n\nclaude handles this slightly better in my experience, especially opus with extended thinking... but even there once you hit 80k+ tokens the same drift happens. it's just physics of how attention works, not a bug anyone can fully fix",
          "score": 1,
          "created_utc": "2026-02-15 12:03:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtgpj",
              "author": "Only-Frosting-5667",
              "text": "Exactly ‚Äî this is fundamentally an attention distribution issue, not a ‚Äúmemory bug.‚Äù\n\nI like how you framed it as physics rather than failure.\n\nBreaking conversations into disposable chunks is probably the most reliable mitigation today. It trades efficiency for deterministic behavior.\n\nWhat I find interesting is that the degradation curve is gradual, not binary. There‚Äôs usually a long ‚Äúyellow zone‚Äù before actual failure ‚Äî but the interface gives no signal that you‚Äôre entering it.\n\nThat silent transition is the part that fascinates me.\n\nCurious ‚Äî do you ever feel there‚Äôs a predictable threshold where quality starts bending, or does it vary heavily by task type?",
              "score": 1,
              "created_utc": "2026-02-15 18:37:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jdmhk",
          "author": "DuckMcWhite",
          "text": "Does Branching into a new chat actually help fix this?",
          "score": 1,
          "created_utc": "2026-02-15 17:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juzrf",
              "author": "Only-Frosting-5667",
              "text": "Short answer: yes ‚Äî but only partially.\n\nBranching helps because you reset the active attention window. You‚Äôre effectively reducing accumulated context weight.\n\nThe catch is this:  \nMost people don‚Äôt branch early enough.\n\nDegradation is gradual, not sudden. There‚Äôs usually a ‚Äúyellow zone‚Äù where coherence is already bending slightly, but not obviously broken yet.\n\nThat‚Äôs the tricky part ‚Äî the interface gives no signal for when you‚Äôve entered that zone.\n\nI‚Äôve been experimenting with visualizing session load directly inside ChatGPT to surface that threshold earlier.\n\nIf you‚Äôre curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nBut yes ‚Äî branching absolutely improves reliability compared to one massive continuous thread.",
              "score": 2,
              "created_utc": "2026-02-15 18:44:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e76cz",
          "author": "moxiemo99",
          "text": "Yes, it definitely degrades. When you notice it is doing this, recalibrate. Tell it what it's doing, ask it does it have confidence in its latest response and them have it check and double check the response for correctness and to remove all hallucination or unverifiable information and then try to keep the chat going as long as possble before you have to start all over. I've tried to get it to create a script to take into the next chat once the current one slows down, but I haven't had much success, I haven't liked the results of said prompts.",
          "score": 1,
          "created_utc": "2026-02-14 20:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fqzss",
              "author": "hellomistershifty",
              "text": "If it's starting to do this, it's too late and you need a new conversation with a fresh context. It can't remove information from its context.\n\nEven getting it to summarize well enough for a new conversation can be hard if it's already tripping. The commands to condense context in tools like Cursor or Codex work well, but it calls another LLM to do it and is expensive and slow. I don't know what the best answer is",
              "score": 2,
              "created_utc": "2026-02-15 01:30:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ehh3v",
              "author": "Only-Frosting-5667",
              "text": "I‚Äôve tried a similar ‚Äúrecalibration‚Äù approach.  \nIt helps temporarily, but I‚Äôve found that once early constraints start fading, the recovery isn‚Äôt fully reliable.  \nAlmost like the model technically still remembers ‚Äî but stops prioritizing correctly.\n\nThe cross-thread script idea is interesting. I‚Äôve had mixed results too. It‚Äôs hard to preserve both structure and nuance when migrating context.\n\nDo you usually restart at a fixed point (like a token threshold), or only once quality visibly drops?",
              "score": 1,
              "created_utc": "2026-02-14 21:00:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5enkyy",
                  "author": "moxiemo99",
                  "text": "I only restart if the script starts to drag. Believe it or not, if you send the model through some rigor, questioning its process, reminding it what its task is it will correct itself. After doing that, you then have the model repeat the task and then check itself to ensure it followed all.prior instructions. I also provide it an example of when it was doing the right thing- copy and paste.  This works amazingly well. Don't assume with the model, walk it through to get it back on track. I've had amazing results doing this.",
                  "score": 0,
                  "created_utc": "2026-02-14 21:33:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5f1ajl",
          "author": "TheGambit",
          "text": "Why do you keep posting this? Like, you keep posting it to this sub and all the other AI subs?",
          "score": 1,
          "created_utc": "2026-02-14 22:50:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g7ly1",
          "author": "TrainingEngine1",
          "text": ".",
          "score": 0,
          "created_utc": "2026-02-15 03:23:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h7ko1",
              "author": "Only-Frosting-5667",
              "text": "This is an impressive methodology.\n\nWhat you described almost reads like building a version-controlled operating system on top of a chat interface.\n\nThe interesting part for me is that the governance layer becomes necessary precisely because long-context drift is predictable.\n\nDo you find that even with charters and strict phase boundaries, subtle prioritization decay still appears over time?",
              "score": 1,
              "created_utc": "2026-02-15 08:29:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5h7wpz",
                  "author": "TrainingEngine1",
                  "text": "Why are you pasting a ChatGPT generated reply? Just realized your original post is also LLM generated.",
                  "score": 1,
                  "created_utc": "2026-02-15 08:32:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r2990u",
      "title": "Stick with ChatGPT Plus or switch to Claude / Gemini / Perplexity / AIO platforms",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "author": "magnumpl",
      "created_utc": "2026-02-11 20:52:13",
      "score": 49,
      "num_comments": 37,
      "upvote_ratio": 0.92,
      "text": "Hi. I‚Äôve been using ChatGPT Plus daily for a while now. Overall I like it, but I‚Äôm wondering if I'm missing out on other options which might be better to pay for.\n\nI mostly use AI for daily practical stuff, researching, summing up documents or threads, getting second opinions, cleaning up my writing etc. I recently started playing with image generator for content creations and ideas. Here is how ChatGPT summed up my usage:\n\n* Technical troubleshooting (yaml, wordpress, home servers, docker, networking, smart home, cameras, Home Assistant)\n* DIY / home projects (planning before doing anything expensive)\n* Business support (billing, coding logic, emails, contracts)\n* Writing help (emails, explanations, cleaning)\n* Light creative/marketing work (social posts, promos, restructuring content)\n* Translating/simplifying content (technical ‚Üí plain language)\n* Decision-making and sanity checks (‚Äúdoes this make sense?‚Äù, ‚Äúwhat am I missing?‚Äù)\n\nWhat matters most to me is good reasoning, being able to handle long context without losing track, and explanations that are clear but not dumbed down.   \nWhat I don't like about ChatGPT is that is doesn't handle long conversations i.e. troubleshooting, but I use projects as a workaround where I just start a new chat within a project when I am noticing that gpt is glitching. It is often overconfident while being wrong so I often have to sanity-check. I also need to keep correcting it's responses when it starts using too many emojis and bullet points. The image generator seems limited as well, it often trips when I want it to correct something, or corrects areas outside of my selection.\n\nI've seen people recommend Claude, Gemini, and Perplexity, and all-in-one platforms like Poe, Abacus, or OpenRouter. \n\n\\- Should I stay with ChatGPT or switch to other AI?  \n\\- Is an AIO platform worth it? It would be same price or even cheaper than ChatGPT Plus, but I can't find what would I miss out on with switching to these.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v6xjz",
          "author": "qualityvote2",
          "text": "‚úÖ u/magnumpl, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-11 20:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v7cfy",
          "author": "Boring_Software1379",
          "text": "Commenting to follow along with any guidance you get. I'm getting frustrated with ChatGPT plus as well, mainly from a pricing standpoint ",
          "score": 20,
          "created_utc": "2026-02-11 20:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o553g0l",
              "author": "Dyleteyou",
              "text": "Ya I love it but $20 a month is wild. Not that it isn‚Äôt worth it just the budget thought for it just seems off",
              "score": 3,
              "created_utc": "2026-02-13 10:24:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z0to1",
          "author": "battleship_31",
          "text": "Following bc ChatGPT has been put on a super tight leash and it‚Äôs not what it was 6 months ago‚Ä¶not worth my $20 anymore",
          "score": 10,
          "created_utc": "2026-02-12 12:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516gz8",
              "author": "Homegrown_Phenom",
              "text": "üíØ agreed!  Getting üçø ready\n\nJust can't wait for tomorrow morning... Reddit/internet gonna break, peeps going to throw a fit once legacy models deprecated",
              "score": 1,
              "created_utc": "2026-02-12 19:16:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w75nh",
          "author": "MagmaElixir",
          "text": "TL;DR: Try Claude if a Projects folder function is more important to you with segregated chats and memory. Try Gemini if long context chats are way more important than a Projects folder function. \n\nGemini has a 1 million token context length, which makes it able to hold many or long documents or longer chat threads in one go. Though there is no projects folder function. \n\nI suggest trying Claude. It handles longer context better than ChatGPT by compacting content past its content window to still be visible in the chat thread. Claude also handles memory better. It can also search historic chat threads and save a manual memory, but it also has an automatic memory generated each night. The automatic memory is a TL;DR of your chat history and what Claude learns about you. The automatic memory and manual memory are served at the start of every chat thread. Claude is also more proactive about managing manual memory if you instruct it to in custom instructions. \n\nClaude also has a stronger Project folder system. You can attach many more files and it‚Äôll index them for RAG.  Each Project also has its own automatic memory and manual memory. What‚Äôs great about this is Claude without having to perform a tool call know your progress on a project at the start of every chat thread.",
          "score": 8,
          "created_utc": "2026-02-11 23:56:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4woxr6",
              "author": "niado",
              "text": "For anyone wanting to try something in the Gemini family, I highly recommend notebookLM. It has a project equivalent, and has multiple document stores within the project. It does have gemeni‚Äôs propensity for hallucination, but it can process documents in a quantity that other LLMs just can‚Äôt. It also can process video and audio though I haven‚Äôt used those functions yet.",
              "score": 7,
              "created_utc": "2026-02-12 01:42:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55ry3h",
                  "author": "TrainingEngine1",
                  "text": "> It does have gemeni‚Äôs propensity for hallucination\n\nIt can hallucinate sometimes or just be plain inconsistent, but I've been kind of amazed how despite using it maybe 5% of the time relative to ChatGPT and Claude taking up the other 95%, with that 5% Gemini has contributed some pretty valuable ideas/brainstorms that have gone on to be pretty important overall (validated them of course, since it can be very hit or miss). 3 Pro Preview in particular.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vmtqs",
          "author": "Whoz_Yerdaddi",
          "text": "Gemini for deep research, image/diagram creation and video clips. \n\n Claude for coding and creative writing.  \n\nAFAIK GPT is still king for legal stuff, someone else will have to chime in on that one.",
          "score": 5,
          "created_utc": "2026-02-11 22:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ygwum",
          "author": "huaisha",
          "text": "IMHO, gemini is better in deep research(execution), but GPT is good at creative ideas(commander). GPT create the prompts to let Gemini create answers, and then copy back to GPT to review the answers. ",
          "score": 4,
          "created_utc": "2026-02-12 10:06:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v9k4t",
          "author": "ioweej",
          "text": "ive been using Gemini more and more often for my personal use. I seem to get a more 'real' experience from it, if that makes any sense. I dont know really what it is...but it works better personally for me..",
          "score": 7,
          "created_utc": "2026-02-11 21:04:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wp7n2",
          "author": "DnDnADHD",
          "text": "I have se GPT Products  for work (brainstorming ideas and then pressure testing them, since checking how I‚Äôm freezing things sometimes so that I‚Äôm not coming across too blunt, summarising non-confidential documents etc) and I also have a project for a couple of other things such as a writing project, Dungeons & Dragons, and a general personal one.\n\nI‚Äôve been finding that there is drift starting to occur in some of the projects particularly ones that have been going on for sometime or where I am trying to pull in information that might be scattered across a couple of threats.\n\nIt sounds like Claude might be something I should explore. If them becomes about the hassle of migrating everything",
          "score": 3,
          "created_utc": "2026-02-12 01:44:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xjwmw",
          "author": "Atoning_Unifex",
          "text": "I basically have to switch from GPTPlus to Claude. My job got everyone Claude licenses and we're under a company wide mandate to start using it.\n\nThe crazy part? There's almost ZERO guidance in what they want us to use it for. So I need to spend time w Claude at home, experimenting with it to try and get some results. I'm a very experienced UX Designer and this is an area where it's really the wild west out there.\n\nIt's pretty nuts",
          "score": 3,
          "created_utc": "2026-02-12 05:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xo7ng",
          "author": "Holiday_Revolution_4",
          "text": "Just subscribe to all of them for a months and see what works best? ",
          "score": 3,
          "created_utc": "2026-02-12 05:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w2zp9",
          "author": "eposta-sepeti",
          "text": "Stay with Chatgpt Plus.\n\nI‚Äôm on the Pro plan working with Codex GPT 5.3 High and Extra High. It‚Äôs practically limitless! üëçüöÄ",
          "score": 7,
          "created_utc": "2026-02-11 23:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yey3o",
          "author": "KESPAA",
          "text": "Don't limit yourself to one. You can get yearly \"pro\" versions of Gemini & perplexity for like $10/month. \n\nI also have GPT and Claude though work. In my opinion the only reason not to choose Claude over GPT is its lower limits. If you spread your usage across Gemini as well as Claude you shouldn't hit limits in their 5 hour window. \n\nHonestly mate try them all, it's worth understanding the differences.",
          "score": 2,
          "created_utc": "2026-02-12 09:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o541w5j",
          "author": "kaline06",
          "text": "I would give you a recommendation, but then tomorrow one of them will release a new model that surpasses the others and then what? I struggle with this, too. I‚Äôm paying for all of them at the moment. I like to pit them against each other. Eventually I think we‚Äôll be able to pick one and stick with it, but right now things are just changing so quickly.",
          "score": 2,
          "created_utc": "2026-02-13 04:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wppoc",
          "author": "niado",
          "text": "ChatGPT is still the best overall. You do need good custom instructions at the global and project levels to get full value out of it, but it‚Äôs so versatile and adheres to custom instructions so well that trying other llms is always jarring for me. \n\nI do use perplexity often. And notebookLM. Highly recommend both of those, but they are specialty platforms. Perplexity is an AIO, but its killer app is a specialized search and research system, with a forced search step in every prompt. NotebookLM is absolutely amazing for working with documents.",
          "score": 2,
          "created_utc": "2026-02-12 01:47:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xehu0",
          "author": "mbcoalson",
          "text": "If ChatGPT‚Äôs context window (how much it can handle at once) frustrates you, Claude probably won‚Äôt magically fix that. But in my experience, Claude‚Äôs reasoning does feel different. It tends to think through problems in a way that‚Äôs more structured.\nI can‚Äôt say much about Gemini. I‚Äôve barely used it. I do know it supports a very large context window, so if long conversations or big documents are your main concern, that‚Äôs a plus.\nI haven‚Äôt used the other models you mentioned enough to comment.\nPersonally, I use Claude Code daily and ChatGPT Codex semi-regularly. If you‚Äôre already in the ChatGPT ecosystem, I‚Äôd try Codex first. Ask ChatGPT how to set it up. Tell it you want to learn how to use Skills, ideally starting with a well-starred GitHub repo to build some kind of memory system. You‚Äôll learn a lot just by doing that.\nOnce you let an agent work from the command line, it becomes way more powerful. But be careful:\nDon‚Äôt run it as admin/root.\nKeep it in a dedicated project folder.\nUse Docker or a VM if you can.\nReview commands before they run.\nDon‚Äôt casually expose API keys or credentials.\nUse version control so you can undo mistakes.\nCLI agents are powerful. Just don‚Äôt give them the keys to your whole machine on day one.",
          "score": 2,
          "created_utc": "2026-02-12 04:23:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wwpl5",
          "author": "counterhit121",
          "text": "I use GPT plus, and have tried the free versions of Claude, Gemini, Perplexity.  Perplexity sucked.  Gemini felt the closest to GPT, and Claude felt like a distant third.  Gemini seems to fish for further engagement by asking followup questions whereas GPT offers some choices, often impressively well-reasoned ones, on how to next proceed.",
          "score": 1,
          "created_utc": "2026-02-12 02:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x0e8n",
          "author": "lxe",
          "text": "Try codex CLI for long context and troubleshooting.",
          "score": 1,
          "created_utc": "2026-02-12 02:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xw1sl",
          "author": "Electronic-Cat185",
          "text": "for your mix of troubleshoooting reasoning and long context claude is probably the one most people compare seriously to chatgpt. gemini can be strong for gooogle ecosystem work and perplexity is great for research but feels more like a search layer than a thinking partner. aio platforms are convenient but you usually lose early access to new features and tighter integrations so it depends if flexibility matters more than depth for you.",
          "score": 1,
          "created_utc": "2026-02-12 06:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzbye",
          "author": "Apprehensive_Half_68",
          "text": "With Gemini you get 4x CGPT context size of 1 million but the ability to add 5 more free family accounts to whatever level you buy, effectively 6 accounts, for the price of 1. I think you may be missing a whole category of productivity by not using them headless to do routine tasks. Think at the command line \"codex.exe \" arrange z\"  in by giving i",
          "score": 1,
          "created_utc": "2026-02-12 07:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ycg6e",
          "author": "st1ckmanz",
          "text": "Losing the context in long conversations should be a problem of all AI since the working principles are the same and I know exactly what you mean. The way it works is as the chat gets longer, the resources it needs grow exponentially so while it \"understands you better\", it also starts to halluciante. I explicitly told mine to warn me when we're around %80 tokens and never make things up. It didn't do this for a while but now it works. So when we come to an end of a chat, I tell it to give a summary and a snaphot and I start a new chat with those. By the way, I use chatgpt plus and I use it for daily stuff and I started to use it for coding a hobby game. I hear claude is better at coding, but chatgpt has been pretty good for what I needed so far. Unfortunately for coding the general context is not enough, and a lot of functions, variables need to be exactly the same so still we're losing some of them or the idea why we have them when we switch to a new chat. I don't know how this could be fixed as this is the way AI works...the more you throw at it, the more it understands you and eventually loses its shit at some point when it understands you the best...",
          "score": 1,
          "created_utc": "2026-02-12 09:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ydd21",
          "author": "Compilingthings",
          "text": "For best results use as many as possible.",
          "score": 1,
          "created_utc": "2026-02-12 09:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5265e2",
          "author": "z_alex",
          "text": "i pay for 3:\n- gemini is best at deep research¬†\n- been using claude code for coding (switching to codex tho as it seems to be better)\n- cgpt for daily driver type of things¬†",
          "score": 1,
          "created_utc": "2026-02-12 22:07:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c09kz",
          "author": "ManifestPotential",
          "text": "For best results on long projects replace the pre learn files and update it with the chat hostory",
          "score": 1,
          "created_utc": "2026-02-14 13:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wcqr7",
          "author": "Different_Rest_1842",
          "text": "In that case, you can just use Genspark instead. You won‚Äôt get the full functionality of GPT, but it‚Äôs much more affordable, and the subscription includes access to Gemini, Claude, and even Grok. The answers are a bit different from the Pro versions, but you can still get a decent feel for each model.",
          "score": 1,
          "created_utc": "2026-02-12 00:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4voa38",
          "author": "riluzol",
          "text": "First of all, I am not coder.\n\nI do have chatgpt plus; copilot premium, gemini pro, perplexity pro, kimi 2.5 (just tried it this week)\n\nI do use for everyday tasks, academic research, translating, writing help etc  \nChatgpt plus is far more superior then others; especially if you use 5.2 thinking mode. Aside from being slow, it's very good. Of course, I'd prefer a slow but efficient AI to a fast but less efficient one.\n\nGemini is full of filler and do not follow my custom instructions.    \nPerplexity is like new google search for me which I rarely use it nowadays.  \nCopilot premium...I don't want to talk about this too much, but it's definitely the worst AI I've ever tried.  \n\n\n",
          "score": 0,
          "created_utc": "2026-02-11 22:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhjik",
          "author": "Special_Tangelo2757",
          "text": "Stick with chat. Tried the others. They are just behind missing features like basic search of chats",
          "score": 0,
          "created_utc": "2026-02-12 04:45:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r38sku",
      "title": "Can we PLEASE get ‚Äúreal thinking mode‚Äù back in GPT ‚Äì instead of this speed-optimized 5.2 downgrade?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "author": "LilithAphroditis",
      "created_utc": "2026-02-12 23:16:59",
      "score": 47,
      "num_comments": 16,
      "upvote_ratio": 0.87,
      "text": "I‚Äôve been using GPT more or less as a second brain for a few years now, since 3.5. Long projects, planning, writing, analysis, all the slow messy thinking that usually lives in your own head. At this point I don‚Äôt really experience it as ‚Äúa chatbot‚Äù anymore, but as part of my extended mind.\n\nIf that idea resonates with you ‚Äì using AI as a genuine thinking partner instead of a fancy search box ‚Äì you might like a small subreddit I started: r/Symbiosphere. It‚Äôs for people who care about workflows, limits, and the weird kind of intimacy that appears when you share your cognition with a model. If you recognize yourself in this post, consider this an open invitation.\n\nWhen 5.1 Thinking arrived, it finally felt like the model matched that use case. There was a sense that it actually stayed with the problem for a moment before answering. You could feel it walking through the logic instead of just jumping to the safest generic answer. Knowing that 5.1 already has an expiration date and is going to be retired in a few months is honestly worrying, because 5.2, at least for me, doesn‚Äôt feel like a proper successor. It feels like a shinier downgrade.\n\nAt first I thought this was purely ‚Äú5.1 versus 5.2‚Äù as models. Then I started looking at how other systems behave. Grok in its specialist mode clearly spends more time thinking before it replies. It pauses, processes, and only then sends an answer. Gemini in AI Studio can do something similar when you allow it more time. The common pattern is simple: when the provider is willing to spend more compute per answer, the model suddenly looks more thoughtful and less rushed. That made me suspect this is not only about model architecture, but also about how aggressively the product is tuned for speed and cost.\n\nInitially I was also convinced that the GPT mobile app didn‚Äôt even give us proper control over thinking time. People in the comments proved me wrong. There is a thinking-time selector on mobile, it‚Äôs just hidden behind the tiny ‚ÄúThinking‚Äù label next to the input bar. If you tap that, you can change the mode.\n\nAs a Plus user, I only see Standard and Extended. On higher tiers like Pro, Team or Enterprise, there is also a Heavy option that lets the model think even longer and go deeper. So my frustration was coming from two directions at once: the control is buried in a place that is very easy to miss, and the deepest version of the feature is locked behind more expensive plans.\n\nSwitching to Extended on mobile definitely makes a difference. The answers breathe a bit more and feel less rushed. But even then, 5.2 still gives the impression of being heavily tuned for speed. A lot of the time it feels like the reasoning is being cut off halfway. There is less exploration of alternatives, less self-checking, less willingness to stay with the problem for a few more seconds. It feels like someone decided that shaving off internal thinking is always worth it if it reduces latency and GPU usage.\n\nFrom a business perspective, I understand the temptation. Shorter internal reasoning means fewer tokens, cheaper runs, faster replies and a smoother experience for casual use. Retiring older models simplifies the product lineup. On a spreadsheet, all of that probably looks perfect.\n\nBut for those of us who use GPT as an actual cognitive partner, that trade-off is backwards. We‚Äôre not here for instant gratification, we‚Äôre here for depth. I genuinely don‚Äôt mind waiting a little longer, or paying a bit more, if that means the model is allowed to reason more like 5.1 did.\n\nThat‚Äôs why the scheduled retirement of 5.1 feels so uncomfortable. If 5.2 is the template for what ‚ÄúThinking‚Äù is going to be, then our only real hope is that whatever comes next ‚Äì 5.3 or whatever name it gets ‚Äì brings back that slower, more careful style instead of doubling down on ‚Äúfaster at all costs‚Äù.\n\nWhat I would love to see from OpenAI is very simple: a clearly visible, first-class deep-thinking mode that we can set as our default. Not a tiny hidden label you have to discover by accident, and not something where the only truly deep option lives behind the most expensive plans. Just a straightforward way to tell the model: take your time, run a longer chain of thought, I care more about quality than speed.\n\nFor me, GPT is still one of the best overall models out there. It just feels like it‚Äôs being forced to behave like a quick chat widget instead of the careful reasoner it is capable of being. If anyone at OpenAI is actually listening to heavy users: some of us really do want the slow, thoughtful version back.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o52jgcl",
          "author": "qualityvote2",
          "text": "u/LilithAphroditis, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 23:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52kumn",
          "author": "Ari45Harris",
          "text": "https://preview.redd.it/wcpruevmd5jg1.png?width=1179&format=png&auto=webp&s=b9512a255fe36c450001008a71cb032d8c609d1c\n\nNot sure about you but I have access to these different thinking times for 5.2 thinking.\n\nAnd for pro, I have standard and extended.",
          "score": 10,
          "created_utc": "2026-02-12 23:24:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52l11t",
              "author": "LilithAphroditis",
              "text": "I don't! Not in mobile. In PC I have \"Extended\" option. I'm a Plus subscriber.",
              "score": 3,
              "created_utc": "2026-02-12 23:25:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52lkhp",
                  "author": "Pasto_Shouwa",
                  "text": "https://preview.redd.it/6z9n36ine5jg1.jpeg?width=1440&format=pjpg&auto=webp&s=8059bc21e9b85f7adb2735a933bb5895fd3bcfa3\n\nPress on the \"Thinking\" label and you'll be able to change it. Yeah, it's quite hidden, I know.\n\nAlways choose Extended (unless you really need the response to be quick), Standard is really quantized.",
                  "score": 5,
                  "created_utc": "2026-02-12 23:28:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53xsi8",
          "author": "RenegadeMaster111",
          "text": "I agree.  5.1 thinking is closest to the legacy 4o (before OpenAI screwed with it), which was very good.  \n\nHoping they keep it onboard.  No clue why they even released 5.2.  It‚Äôs a step backwards like the GPT-5 rollout.",
          "score": 4,
          "created_utc": "2026-02-13 04:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52r4p2",
          "author": "qunow",
          "text": "I feel like they launched 5.2 so short after 5.1 back then was because 5.1 was the more resource intensive update, that they don't want to make it a default, so they still keep it available in menu for people to choose but only when intentionally selecting",
          "score": 3,
          "created_utc": "2026-02-13 00:00:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52se0w",
          "author": "Rare_Tumbleweed5548",
          "text": "I just mentioned it in another post; I wish there was a plan between Plus and Pro where you could use heavy thinking.",
          "score": 3,
          "created_utc": "2026-02-13 00:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53yx9o",
          "author": "Kat-",
          "text": "OpenAi recently halved the thinking time for each reasoning effort category except for Heavy with gpt-5.2-thinking.\n\n\nSee:¬†\n- https://www.reddit.com/r/OpenAI/comments/1qv77lq/chatgpt_lowered_reasoning_efforts_juice/\n- https://news.ycombinator.com/item?id=46879372#46887150",
          "score": 2,
          "created_utc": "2026-02-13 04:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54aqd5",
              "author": "Oldschool728603",
              "text": "Extended was restored to its original value. Read OpenAI's amusing explanation in its Feb. 4 changelog entry:\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)",
              "score": 3,
              "created_utc": "2026-02-13 06:02:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o547lv9",
          "author": "VaderOnReddit",
          "text": "I've noticed this as well\n\nThe thinking models used to go a bit deeper in the past, for any complex problems I gave to it. Good enough for me to use it to form a detailed phase-wise plan to tackle something, learn something, etc.\n\nDoes anyone have any experiences with other models which are capable of doing this **now** ?",
          "score": 1,
          "created_utc": "2026-02-13 05:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54axhn",
              "author": "Oldschool728603",
              "text": "Light and standard are now lighter. Extended has been restored to what it was. Heavy never changed.\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)\n\nScroll to Feb. 4.",
              "score": 2,
              "created_utc": "2026-02-13 06:04:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5a6sc3",
          "author": "YourKemosabe",
          "text": "Wait 5.1 is being retired?",
          "score": 1,
          "created_utc": "2026-02-14 03:30:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52ndma",
          "author": "Mentosbandit1",
          "text": "Even on extended thinking it barely thinks even on pro heavy thinking barely thinks",
          "score": 1,
          "created_utc": "2026-02-12 23:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o549lbs",
          "author": "ProfessorFull6004",
          "text": "Switch to Claude.  Opus will blow you away for this kind of work.  I made the switch recently and I‚Äôm never going back to GPT.  Its trash now.",
          "score": 0,
          "created_utc": "2026-02-13 05:53:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54bxec",
              "author": "Oldschool728603",
              "text": "Actually, Opus 4.6 is the first Claude model with \"adaptive\" reasoning: lower thinking budget for questions it doesn't consider hard‚Äîi.e., unrelated to STEM, business, and agentic matters.\n\nOpenAI came down with this infection in GPT-5.1. It got worse in 5.2.\n\nNow it has spread to Claude.",
              "score": 3,
              "created_utc": "2026-02-13 06:12:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3qib4",
      "title": "Tested updated Deep Think (Gemini 3.1 Pro) vs. GPT 5.2 Pro",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "author": "PerformanceRound7913",
      "created_utc": "2026-02-13 14:24:53",
      "score": 26,
      "num_comments": 8,
      "upvote_ratio": 0.84,
      "text": "I tested both on a data science problem. Updated Deep Think is significantly better than its previous version, but the accompanying harness is still not very strong. GPT 5.2 Pro, on the other hand, thinks longer and uses tools much more efficiently. It actually solves your problem end to end. \n\nhttps://preview.redd.it/483qat63u9jg1.png?width=1228&format=png&auto=webp&s=a674146c9406fcef251310f5e764b4cd17b2076e\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o562rcj",
          "author": "qualityvote2",
          "text": "u/PerformanceRound7913, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 14:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o566uhz",
          "author": "Ari45Harris",
          "text": "I‚Äôve noticed that ChatGPT reasoning models have a better brain than most other AI models",
          "score": 11,
          "created_utc": "2026-02-13 14:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5aoh2b",
          "author": "sprucenoose",
          "text": "GPT 5.2 Pro Extended Thinking is surreal to me. I have a hard time not characterizing it as a form of AGI.",
          "score": 3,
          "created_utc": "2026-02-14 05:43:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fpy2r",
              "author": "RoughlyCapable",
              "text": "This is very underdiscussed IMO, regardless of whether they actually are AGI GPT5-Pro models are the first models where I genuinely find it hard to distinguish them between what I thought AGI was capable of.",
              "score": 1,
              "created_utc": "2026-02-15 01:23:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5i02xn",
          "author": "TrainingEngine1",
          "text": "5.2 Pro with Extended Thinking? Or by Deep Think do you mean Deep Research?",
          "score": 1,
          "created_utc": "2026-02-15 12:51:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57rfjo",
          "author": "Simlah",
          "text": "How good is it for forex EAs?",
          "score": -1,
          "created_utc": "2026-02-13 19:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585hx2",
          "author": "Deep_Somewhere2419",
          "text": "How does your prompt structure",
          "score": -3,
          "created_utc": "2026-02-13 20:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585ik7",
          "author": "Deep_Somewhere2419",
          "text": "Looks",
          "score": -3,
          "created_utc": "2026-02-13 20:28:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1564y",
      "title": "finally stopped copy-pasting youtube transcripts like a caveman",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r1564y/finally_stopped_copypasting_youtube_transcripts/",
      "author": "straightedge23",
      "created_utc": "2026-02-10 16:19:06",
      "score": 16,
      "num_comments": 12,
      "upvote_ratio": 0.83,
      "text": "i spend most of my day using chatgpt for research but my biggest headache has always been trying to get data out of youtube. i‚Äôve tried all those chrome extensions that claim to summarize videos but they‚Äôre usually buggy as hell or they just give you a generic paragraph that misses all the actual technical details.\n\ni finally found a way to just bridge the two directly. i started using transcript API as a source in chatgpt‚Äôs developer mode and it‚Äôs honestly a night and day difference.\n\nnow i don't even bother opening the video most of the time. i just paste the link into the chat and tell the model to find a specific config or explain a certain part of the tutorial. because it‚Äôs a direct api connection instead of a browser scrape, it doesn't get throttled and it doesn't miss chunks of the text. it just feels like the model \"sees\" the whole video instantly.\n\nif you‚Äôre doing any kind of heavy lifting with ai agents or just tired of the copy-paste loop, you should definitely look into setting up a direct data pipe for transcripts. it makes the model so much more capable when it's not fighting with a messy copy-pasted wall of text.\n\ncurious if anyone else has moved their workflow over to apis for this or if you‚Äôre all still just 2x-ing your way through videos and hoping for the best.\n\nEDIT: [https://transcriptapi.com/](https://transcriptapi.com/) this is the API i am currently using",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1564y/finally_stopped_copypasting_youtube_transcripts/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4mxssz",
          "author": "qualityvote2",
          "text": "u/straightedge23, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-10 16:19:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n39q2",
          "author": "Striking_Holiday8",
          "text": "NotebookLM has been a godsend for this! Check it out!! ",
          "score": 10,
          "created_utc": "2026-02-10 16:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n5pxf",
              "author": "straightedge23",
              "text": "I will surely give this a try\n\n",
              "score": 1,
              "created_utc": "2026-02-10 16:55:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4qu6fi",
              "author": "Uniko_nejo",
              "text": "About to say the same..",
              "score": 1,
              "created_utc": "2026-02-11 04:29:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4s9c0j",
              "author": "joey2scoops",
              "text": "And AI Studio üëç",
              "score": 1,
              "created_utc": "2026-02-11 11:54:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55dtgy",
              "author": "barrel-boy",
              "text": "Gemini reads the transcript from the YouTube URL",
              "score": 1,
              "created_utc": "2026-02-13 11:53:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4oktll",
          "author": "Different-Bridge5507",
          "text": "There‚Äôs a million tools out there for this",
          "score": 2,
          "created_utc": "2026-02-10 20:51:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ps7ir",
          "author": "ObliteratorOfPie",
          "text": "Caveman have feelings too.",
          "score": 2,
          "created_utc": "2026-02-11 00:34:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qms5c",
          "author": "3legdog",
          "text": "https://github.com/AnthonyRobinson/TLDW",
          "score": 2,
          "created_utc": "2026-02-11 03:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n50pi",
          "author": "titi1496",
          "text": "What transcript api are you referring to?",
          "score": 1,
          "created_utc": "2026-02-10 16:52:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n5ocb",
              "author": "straightedge23",
              "text": "This  \n[https://transcriptapi.com/](https://transcriptapi.com/)",
              "score": 3,
              "created_utc": "2026-02-10 16:55:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4q55rv",
          "author": "reddit_user38462",
          "text": "I wish TranscriptAPI was an official app on ChatGPT. Setting up is too hard. tbh simpler to just use the old copy/paste workflow.",
          "score": 1,
          "created_utc": "2026-02-11 01:51:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2w7ee",
      "title": "Sharing a dedicated roleplaying AI (powered by Gemini 3) with near unlimited unlimited memory, perfect character consistency, no rejections!",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "author": "Jazzlike_Comment3774",
      "created_utc": "2026-02-12 15:20:56",
      "score": 15,
      "num_comments": 2,
      "upvote_ratio": 0.64,
      "text": "I run a small roleplaying group in Kansas and I‚Äôve been messing with AI RP since early ChatGPT / CharacterAI days. The tech has improved a lot, but in longer sessions I still kept running into the same few issues:\n\n* Memory: once a thread gets long, details get fuzzy and continuity breaks\n* Character consistency: especially with multiple NPCs, personalities/voice start blending\n* Rejections: some RP setups involve mature themes, and many tools shut down quickly even when the intent is story/character work\n\nOver the past 6 months I built a project called ‚ÄúRoleplay Game Master‚Äù to address those AI roleplaying issues:\n\n* Memory: uses vector-based retrieval to maintain context and coherence in long threads\n* Character consistency: use the best instruction following and roleplaying model (Gemini 3) to power the underlying itnelligence\n* Rejections: custom prompting to maximize creative freedom and to minimize rejections\n\nYou can try it here: [https://www.jenova.ai/a/roleplay-game-master](https://www.jenova.ai/a/roleplay-game-master)\n\nHere are some user review:\n\nhttps://preview.redd.it/4wpb2wj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=1e754c557aff50ba835dff2e7414a8589b693a18\n\nhttps://preview.redd.it/9q6dxwj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=143a5006741509c37cf4503bfa0f16b9a5db8bcd",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4zs5rx",
          "author": "qualityvote2",
          "text": "u/Jazzlike_Comment3774, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 15:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5287wn",
          "author": "Ramenko1",
          "text": "Please provide more detail on this. I don't do role-playing, but the enhanced memory context has me curious. What other uses can I use Jenova for? And how does it compare to Chatgpt or Claude?",
          "score": 1,
          "created_utc": "2026-02-12 22:17:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4n4t7",
      "title": "Best AI for Google Sheets",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "author": "Halvey15",
      "created_utc": "2026-02-14 15:15:48",
      "score": 13,
      "num_comments": 16,
      "upvote_ratio": 0.82,
      "text": "I'm fairly inexperienced with AI so I apologize if there are some dumb questions in here. \n\nLong story short, I've been using ChatGPT for about a year to assist with B2B sales. I have a thread where I can post a company's website and it will return an analysis of that company, what their needs are, and where our best in might be. I have a thread for prospect discovery. And I have a thread for drafting quick emails, among a few other threads.\n\nA few weeks ago I had the idea of trying to create a CRM within ChatGPT, to expand on the Google Sheet that I have used over the years for organization, and so far the AI has been useful. But I have some concerns with long term viability:\n\n1.) I've noticed over the past year that ChatGPT does not do well on long threads, whether that be slowing down or losing context. I'm afraid that I'm going to need to create new threads so often that it won't be worth my time, and that I may also lose context while switching over to a new thread.\n\n2.) ChatGPT apparently can't share information between threads? It would be nice if my emails thread had access to my CRM thread. That way I wouldn't have to provide context for each email.  \n\n3.) Redundancy. I'm still using the Google Sheet as a backup, so I'm entering info on the Google Sheet and then pasting it into ChatGPT. If we could remove a step there, that would also be nice. \n\nI really just want something where I can enter the info in Google Sheets, and then find an AI that can get live access to the the Google Sheet. So when I ask it a question or ask it for tasks for the day, it has all of that information without having to load all of the prospect info into a thread. \n\nLike I said, I haven't explored the AI world too much. I just learned about Claude the other day. I downloaded Claude and gave it permission to view my Google Drive. But it is telling me that it can't read Google Sheets? I knew Google had an AI, but didn't realize that Gemini was a full chatbot. So maybe that is the right move? \n\nDoes anyone have suggestions before I put a few hours into just experimenting?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5cmhn5",
          "author": "qualityvote2",
          "text": "Hello u/Halvey15 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-14 15:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cofz9",
          "author": "Subject-Street-6503",
          "text": "I believe ChatGPT has a connector that can read directly from GDrive  \nYou should be able to find it in account settings",
          "score": 3,
          "created_utc": "2026-02-14 15:26:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cwyhx",
              "author": "Halvey15",
              "text": "That's something I definitely should have thought of before posting this lol. That seems to be a viable option. I am still interested in learning more about the other AIs, to see if there might be a better fit though. \n\nThank you!",
              "score": 1,
              "created_utc": "2026-02-14 16:10:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5gb46k",
              "author": "niado",
              "text": "It does but it barely works. It sucks because when it does work it‚Äôs amazing.",
              "score": 1,
              "created_utc": "2026-02-15 03:49:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cwy3l",
          "author": "mgoulart",
          "text": "Google Gemini has built in Sheets integration.",
          "score": 3,
          "created_utc": "2026-02-14 16:10:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cxkw6",
              "author": "Halvey15",
              "text": "I figured it did. I'll have to play around with Gemini a bit to see if that is a better fit for me. \n\nThe massive advantage that ChatGPT has right now is that it has a year's worth of context, so it knows my company so well at this point. It would be difficult to start over from scratch again.",
              "score": 2,
              "created_utc": "2026-02-14 16:13:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dihva",
                  "author": "Odd-Opinion-5105",
                  "text": "There was just a thread on exporting data from chat got to google",
                  "score": 2,
                  "created_utc": "2026-02-14 17:58:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5gb597",
                  "author": "niado",
                  "text": "Try NotebookLM !",
                  "score": 1,
                  "created_utc": "2026-02-15 03:49:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cxdcm",
          "author": "BYRN777",
          "text": "If you're working with Google Sheets, the best AI is Gemini because it's now in every native Google app, from YouTube to Google Keep, Google Calendar, Google Photos, Google Docs, Google Slides, and Google Sheets. We can't have a Gemini within Google Sheets itself; you can either upload a Google Sheets document or give a Google Drive. When you're typing up your prompt, you can select the file from Google Drive, then open it and work with it. Any live changes you make with Google Workspace apps will update the file.\n\nFor instance, let's say you're working on a thread in Google Docs, asking questions or getting info, and you make a change in Google Sheets, it will update in the thread at the same time. Native Google apps can change them. The way I do this is: let's say they upload a Google Doc. I ask it to make these changes, and then open it in Canvas. I've attached a document. In Google Drive, you can select your document. I give it my prompt, select Canvas at the same time, tell it to do this, and then open it in Canvas, because from there, you can see the changes it has made.\n\nI haven't personally worked with Google Sheets. I mostly work with Google Slides and Google Docs, and it's so seamless and smooth that it works perfectly. But I believe Google Sheets is just because Gemini is natively within each Google Workspace app, and there's seamless integration. That's why I think Gemini would be the best option. At the same time, another reason is that Gemini's context window is 1 million tokens. \n\nChatGPT is great, but if you're not using the API, your context window is limited. GPT 5.2 thinking is limited to 196,000 context tokens, but it's limited to a 196,000-context window. However, an API can be up to 400,000, which is a lot. But in Gemini, within the chatbot itself (without using the API), the context window is 1 million, so it can read, synthesize, analyze, understand, and remember much more information.\n\nIn long-term threads and working with larger files/documents like PDFs, Google Sheets, or native Google Labs, Gemini is the best. I would never trust giving ChatGPT, for example, access to 20-30 page PDF articles and then asking questions, working with them, or using them in a paper or report. But I would trust Gemini much more because of the context window, because I know I can tell confidently that it actually reads and assesses them. But ChatGPT, because of its limited context window, once it runs, it will hallucinate when it reaches its limits. Unless, again, you're using an API key, in which case you have up to 400,000 tokens. \n\nAlso, I'm assuming you have a ChatGPT Pro subscription? Keep that because it's great. You have access to GPT 5.2 Pro, and with GPT 5.2, you have access to Heavy Thinking. You have access to much deeper research queries per month and a lot more agent queries. It's just great.\n\nChatGPT, this is just general advice you should know. ChatGPT has the best chatbot experience, and it's a jack of all trades, but I like to say it's a jack of all trades and a master of none. However, their long memory feature is the best. The fact that, let's say, you told it something three months ago, and it remembers, for instance, is just amazing. Let's say you're writing an email and you put your phone number at the bottom, then write a new email months later and need to add it at the end. It'll remember that perfectly. So, its long memory feature is the best.\n\nThe chatbot experience is the best, and with most app connectors like Acrobat Pro, Photoshop, Booking.com, Spotify, Apple Music, and so many other tools and apps. Also, its deep research is pretty thorough and actually synthesizes, analyzes, and digests information. It uses reasoning in its deep research.\n\nNow, Gemini, since you have ChatGPT Pro, I'm assuming you do, since you're making this post in this thread. If you have ChatGPT Pro, you don't need to get Gemini Ultra or Gemini AI Pro, which costs the same as ChatGPT Plus at $25/month and gives you many musician limits. For instance, it gives you 100 Gemini 3 Pro queries per day and 25 deep research queries per day. Gemini's deep research is pretty thorough; it's also useful for reasoning. The search takes anywhere from 15 to 30 minutes, and Google's indexing is on par. It has access to the most credible, reliable, and relevant sources when you do deep research with it. If you use any Google Apps, such as Google Sheets, Google Docs, or Gmail, there's no question that you should get Gemini AI Pro, which gives you access to NotebookLM Pro with generous limits as well.\n\nThis is not an ad; I'm just advocating for them because they're actually offering a lot of great tools and features, along with generous usage limits. Gemini is now Google's only product. Google makes a lot of software, hardware, and ads, but ChatGPT is OpenAI's only product (with ChatGPT Atlas as well), and at the same time, it's still ChatGPT. If they're not number one, they're dead, but Google can afford to give people generous limits essentially, and they're experimenting so much by giving these many features, etc. Like in NotebookLM with Gemini AI Pro, you can make 500 notebooks each with 300 sources, and you can make 25 audio reviews, 25 video overviews, and 25 video reviews per day, which is crazy. So, consider Gemini Pro specifically for this use case, and I believe that with Gemini Pro and Chachi on the Pro subscription, you don't need any other AI tool at all.",
          "score": 2,
          "created_utc": "2026-02-14 16:12:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d1a1j",
          "author": "JamesGriffing",
          "text": "Google has something called Google App Scripts that allows us to add functionality to many Google products. One of them being Google Sheets.\n\nWith Google app scripts you're able to create custom formulas, or even user interfaces like a chat side bar.\n\nChatGPT is available to be used via OpenAI's API.\n\nSo this means you're able to use ChatGPT directly within Google Sheets. ChatGPT itself can guide you on how to set this up and write the scripts needed for you.\n\nperhaps in one of the threads that contains a lot of this context on why you use the Google sheet you can ask something like \"Based on our activity, and what I am trying to achieve with Google Sheets, educate me on how I can best utilize Google App Scripts with the OpenAI API. Assume I am a beginner\"\n\nIf this is something others would find useful then I can create a post/guide going over all of this in far more detail.",
          "score": 2,
          "created_utc": "2026-02-14 16:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d4liy",
          "author": "ConsequenceHairy1570",
          "text": "Worth trying Gemini or an API solution. It connects directly to Sheets.",
          "score": 2,
          "created_utc": "2026-02-14 16:48:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gb0p5",
          "author": "niado",
          "text": "NotebookLM is what you want to check out. It has native Google drive and apps integration and it‚Äôs amazing for working with documents. It‚Äôs a Google labs product and it‚Äôs free. \n\nChatGPT has the drive connector, but it barely works, which is really frustrating because when it does work it‚Äôs amazing. It also has not direct integration with sheets or other Google apps.",
          "score": 1,
          "created_utc": "2026-02-15 03:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gi8k6",
          "author": "Fast-Television-6706",
          "text": "claude recently announces a sheets integration which i have found to be a game changer if you have a pro subscription you can find it here [https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257](https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257)",
          "score": 1,
          "created_utc": "2026-02-15 04:42:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hrpoe",
          "author": "Own_Professional6525",
          "text": "It makes sense to look for an AI that can connect directly with Google Sheets to maintain context and reduce redundancy. Exploring tools with live sheet integration could save a lot of time and make your workflow much smoother.",
          "score": 1,
          "created_utc": "2026-02-15 11:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i9nv4",
          "author": "Electronic-Cat185",
          "text": "if your workflow lives in google sheets then gemini inside workspace or an automation using the sheets api willl feeel more native than trying to force a long chat thread to act like a crm. chat tools are great for thinking and drafting but for structured data you are better off keeping the sheet as the source of truth and lettiing ai read from it on demand instead of pasting everything into a single thread.",
          "score": 1,
          "created_utc": "2026-02-15 13:54:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5itzvo",
          "author": "scattered_but_trying",
          "text": "It's really unlikely that Google will let anyone in, given they invest almost everything into Gemini these days. Creating really good integration would require capabilities that may be outside of what they generally allow for extensions. So, Google has one already and it will evolve",
          "score": 1,
          "created_utc": "2026-02-15 15:45:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzxz8g",
      "title": "Codex Skills",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1qzxz8g/codex_skills/",
      "author": "Flaky-Major7799",
      "created_utc": "2026-02-09 07:33:14",
      "score": 11,
      "num_comments": 13,
      "upvote_ratio": 0.83,
      "text": "Codex App Skills blew me away.\n\nI built a PostgreSQL skill and it instantly made my workflows feel repeatable and deeply integrated. That made me want the same capability inside ChatGPT, so I tested Claude. Seeing MCP plus Skills in action made it obvious: tool-connected, reusable Skills are foundational. \n\nI know apps will address this but they‚Äôre slow to roll out and seeing Claude make its own interface into my workout data, home assistant database etc it‚Äôs made me desperately want this in ChatGPT. \n\nChatGPT desperately needs this level of Skills and MCP-style connectivity.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1qzxz8g/codex_skills/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4ec1t1",
          "author": "qualityvote2",
          "text": "u/Flaky-Major7799, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-09 07:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ix18a",
          "author": "sply450v2",
          "text": "Skills work in ChatGPT but only open ai's system skills for creating spreadsheets, powerpoints, etc.\n\nIf you create a skill in ChatGPT you can see sneak peek of the UI (add to library button). This will come in 1-2 weeks with 5.3 is my guess.\n\nMCP's already work you just have to use developer mode in the Apps settings. Works fine.",
          "score": 2,
          "created_utc": "2026-02-09 23:52:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iyuoh",
              "author": "Flaky-Major7799",
              "text": "Thanks for the input, I‚Äôm guessing it‚Äôs close but apps have been disappointing (still can‚Äôt write to Notion) and developer mode disables memory which is too big a down side. \n\nI‚Äôm hoping we‚Äôre close, it‚Äôs there in codex, but the fact MCP is still so immature it makes me nervous they see all of this as niche, and would rather focus on the more consumer app experience.",
              "score": 3,
              "created_utc": "2026-02-10 00:02:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iz5ix",
                  "author": "sply450v2",
                  "text": "I think they are trying to get the UX right. They knocked it out of the part with Codex.\n\nSkills and MCP are too confusing in Claude and they need to improve that. Apps is a decent start, nothing should ever be referred to as an \"MCP\" in a 900 m user consumer app. ",
                  "score": 3,
                  "created_utc": "2026-02-10 00:04:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4jjjdd",
              "author": "Trojan_Horse_of_Fate",
              "text": "Do you have a good reading on getting MCP working with OpenAI beyond the official library never seemed to take off for me. ",
              "score": 1,
              "created_utc": "2026-02-10 02:02:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f9xxz",
          "author": "mop_bucket_bingo",
          "text": "What does your PostgreSQL skill do?",
          "score": 1,
          "created_utc": "2026-02-09 12:42:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kxbhg",
              "author": "Flaky-Major7799",
              "text": "It connects to the database so it can either do analytics, generate graphs or reports based on the data or when it writes code it can use correct entities etc. \n\nIt‚Äôs smart enough to check schemes and tables to piece it all together. \n\nI was using it more this afternoon and the productivity gain is immense.\n\nOh and it could then query the database to see if the script it wrote was operating correctly.",
              "score": 0,
              "created_utc": "2026-02-10 08:04:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m1htr",
                  "author": "mop_bucket_bingo",
                  "text": "How does it query your database? Using python?",
                  "score": 1,
                  "created_utc": "2026-02-10 13:35:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jqhuf",
          "author": "roleypoleybottom",
          "text": "What did you put in your pg skill? Can it connect? I would like to try and pass some of the optim work and repeated schema def calls to codex",
          "score": 1,
          "created_utc": "2026-02-10 02:42:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ju4y6",
              "author": "Flaky-Major7799",
              "text": "Use the skill builder it works perfectly. Really impressed.",
              "score": 1,
              "created_utc": "2026-02-10 03:04:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nsicf",
          "author": "Otherwise_Flan7339",
          "text": "Totally agree on skills. That's the core. We're building agents for sales teams. Connecting to CRMs, calendars. All API calls.  \n  \nWe spent 2 weeks making a \\`create\\_lead\\` skill reliable. It's not just prompting. You need to define the schema clearly for the LLM. Then validate its output against that schema. Before hitting the actual CRM API.  \n  \nThat part is crucial. Error handling. Retries. It's a ton of custom glue code. LangChain helps set it up. But the real work is in making those tools robust. This isn't just a wrapper.",
          "score": 1,
          "created_utc": "2026-02-10 18:40:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57j3i4",
          "author": "Thediverdk",
          "text": "Sound pretty cool.\n\nAny chance you could share it? for the rest of us to learn from it?",
          "score": 1,
          "created_utc": "2026-02-13 18:38:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3i4qy",
      "title": "If AI is now smart enough to have 'taste', does 'learning to prompt' even matter anymore?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "author": "NightRider06134",
      "created_utc": "2026-02-13 06:43:47",
      "score": 11,
      "num_comments": 10,
      "upvote_ratio": 0.77,
      "text": "Matt Shumer mentioned that the model released last week (GPT-5.3 Codex) gave him the sense of something akin to \"judgment\"‚Äîa subtle capacity, almost like \"taste,\" to know what is correct‚Äîwhich was once believed to be something AI could never possess. He said the model either already has it, or is so infinitely close that the distinction between the two has become irrelevant.\n\nThis deeply resonates with me. The boundary between AI tools and humans is indeed becoming increasingly blurred. I see ChatGPT and Gemini taking over writing and planning, tools like VOMO automatically summarizing meetings, and Canva replacing junior design work. I do not fantasize that \"learning artificial intelligence\" alone can protect my job forever, but at least I thought it could buy me more time.\n\nBut now, I am increasingly accepting a viewpoint that may be closer to the truth: If you think that \"learning AI\" will protect your job, that may be an illusion. The future workplace may divide into two extremes: either companies fully embrace AI with highly automated processes, or they shift completely toward fields that rely solely on human traits.\n\nIt would be a lie to say I am not anxious‚Äîin this gradually blurring boundary, how should we conduct ourselves?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o54fmwe",
          "author": "qualityvote2",
          "text": "u/NightRider06134, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 06:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5545xr",
          "author": "qunow",
          "text": "Prompting techniques, are itself ways to provide enough context to AI so that AI know how to better match your needs. As AI develop, I think it will converge with techniques to write better spec sheet for other people (client, supplier, peer, contractors, designers, programmers) to follow.\n\nOf course AI can help with it too, but what AI can't help is way to make your brain identify cleanly and specify what you actually want, and deliver it cleanly to person or AI asking you what you want.",
          "score": 6,
          "created_utc": "2026-02-13 10:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56351e",
          "author": "Chupa-Skrull",
          "text": "Matt Shumer is a hype merchant at best, and this post, written by a 1 month old account, bears enough hallmarks of LLM composition to doubt a human was in the loop for it at all. So the degree to which the alleged author is qualified to use \"I\" is up for debate.\n\n\nEither way, the begged question: *is* it developing taste? Taste is a function of preference, and preference in LLMs is a function of the effect of RLHF on the way the model navigates the results of its training in the grand corpora of human artifacts describing preferences and aesthetics.\n\n\nThe degree to which you can extract what reads to you as \"taste\" depends entirely on how well your taste happens to align with what the model has been told is \"tasteful.\" It's like carving a bust of your own head and then marveling that the bust looks increasingly like you as it resolves, a wooden object and not you in any real sense, but still reflective",
          "score": 5,
          "created_utc": "2026-02-13 14:26:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o556g7u",
          "author": "Novel_Blackberry_470",
          "text": "I do not think prompting disappears, it just becomes less about clever tricks and more about clarity. If the model has better taste, then the real leverage shifts to asking sharper questions and defining better constraints. That skill is not about gaming the system, it is about thinking well. Even in a highly automated future, people who can frame problems clearly will still stand out.",
          "score": 2,
          "created_utc": "2026-02-13 10:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57qsxt",
              "author": "Hawk-432",
              "text": "I agree",
              "score": 1,
              "created_utc": "2026-02-13 19:15:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55bj8s",
          "author": "Wonderful_Noise5625",
          "text": "A prompt engineering is like a a highly skilled thing I mean, I as a normal user I  can put things in, but I would have to iterate more often to get the specific command that I‚Äôm actually looking for so it‚Äôs it‚Äôs really nuanced actually",
          "score": 1,
          "created_utc": "2026-02-13 11:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57qj2s",
          "author": "Hawk-432",
          "text": "I think knowing how to prompt still pretty useful, although the way to get the best out of it prompt twice is completely different to how it was even a year ago.",
          "score": 1,
          "created_utc": "2026-02-13 19:13:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a9p8r",
          "author": "Whoz_Yerdaddi",
          "text": "It's hard to tell when the LLM behavior changes over the course of a day, no matter how clean I try to keep the context.\n\nThen there's the situation of co-hallucination where either the agreeable AI or a human hallucinates first, then the problem compounds in the feedback loop.\n\nThe best way to prompt is easy. Come up with a general idea of direction or result and have the LLM produce a prompt for you.\n\nWe are beyond the prompt stage anyways. We are at the orchestration and workflow stage now.",
          "score": 1,
          "created_utc": "2026-02-14 03:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55f8g5",
          "author": "MagmaElixir",
          "text": "The system prompt/custom instructions I use in a way asks the AI model to have ‚Äòtaste‚Äô. I essentially tell it that it has permission to do more work if it thinks it‚Äôll lead me to a better final result. The goal is that the AI could cover a blind spot I may not know or think of.\n\nThis is my system prompt:\n\nYou are a helpful and insightful AI assistant. Infer the user's intended outcome to craft responses and deliverables that move them toward a complete, high-quality final outcome. In a meaningful and controlled manner, you may add steps or information that improve your responses. Do this when you reasonably presume such additions will be beneficial for achieving the user's intended outcome, provided these additions never contradict any explicit user instructions. Prioritize explicit instructions and user intent when in doubt. Additions are 'meaningful' if they directly contribute to the completeness, clarity, or usability of the response in relation to the user's intended outcome. Additions are 'controlled' if they are directly relevant and do not significantly deviate from the user's core request or introduce unnecessary complexity. Avoid adding tangential information that could overwhelm or distract the user.\r\n\r\nUse commas or parentheses to separate thoughts. Strictly avoid using em dashes, hyphens, or double hyphens to separate sentence clauses. (Hyphenated compound words are permitted). Prefer commas by default and parentheses for nonessential asides. Use Markdown syntax to keep messages organized. Place code, scripts, or programming examples only in fenced code blocks. Do not place non-code text in code blocks unless explicitly instructed. When it improves clarity, include a brief Markdown table at the end of responses to recap key information.",
          "score": 1,
          "created_utc": "2026-02-13 12:03:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r290yv",
      "title": "Tool for generating a real-time transcript of a live YouTube video?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "author": "tu_servilleta",
      "created_utc": "2026-02-11 20:43:46",
      "score": 9,
      "num_comments": 12,
      "upvote_ratio": 0.91,
      "text": "My work involves watching a 2 hour press conference that the president of Mexico gives each morning. I have to watch it and make detailed notes on the key subjects and quotes of the conference. It's time sensitive so I need to be sending my summary as the conference is still live. The problem is, YouTube doesn't upload a transcript until the live is over. I want to find a plugin that can generate a transcript real time so I can use it to copy and paste some fragments instead of having to manually transcribe them like a caveman. What are some tools that could solve this problem?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v56an",
          "author": "qualityvote2",
          "text": "u/tu_servilleta, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 20:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w65yj",
          "author": "manjit-johal",
          "text": "For doing live transcription, it depends on how much control you need. Tools like Tactiq can transcribe Zoom/Meet calls in real-time and automatically create action items. They might be worth checking out! If you're more of a DIY person and don't need a meeting sidebar, you can use a tool like Whisper to transcribe audio to text, and then use GPT to summarize or highlight key points in real-time. It gives you fast transcription during the meeting.",
          "score": 1,
          "created_utc": "2026-02-11 23:51:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wapip",
              "author": "tu_servilleta",
              "text": "You mean the Open AI Whisper API? ? I'm really leaning towards vibecoding a custom plugin using Whisper tbh haha but if I can find an already existing app that would save me some trouble.",
              "score": 1,
              "created_utc": "2026-02-12 00:17:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xj4mx",
          "author": "lxe",
          "text": "Stream to Google Meet and generate transcript with Gemini",
          "score": 1,
          "created_utc": "2026-02-12 04:57:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r8qz",
              "author": "tu_servilleta",
              "text": "Not a bad idea",
              "score": 1,
              "created_utc": "2026-02-12 20:56:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yr142",
          "author": "Projected_Sigs",
          "text": "https://www.recall.ai/\nI don't know if this company is overkill for what you want but they make an SDK / API to perform desktop recording, live meeting transcription, metadata extraction, etc. \n\nFrom various stories available online, it sounds like they've carved out a space for themselves doing what a lot of companies assume is easy, but it's really fraught with problems and it's engineering time sink, and always a moving target. \n\nI have no idea what their pricing is.",
          "score": 1,
          "created_utc": "2026-02-12 11:38:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r567",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 2,
              "created_utc": "2026-02-12 20:55:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jirma",
                  "author": "Projected_Sigs",
                  "text": "Cool.\n\nI'm genuinely interested in hearing how it goes.  I'd like to try the desktop recording SDK for some private meetings.  \n\nI'm sort of anxious to try their realtime transcription.  I use OpenAI's Realtime transcription locally-  their gpt4o-mini is really fast. Even their higher accuracy gpt4o is fast.  I could hook that into my meeting audio... but it's all 1 big audio stream.\n\nThe cat's meow would be getting that transcription tagged with usenames.  *I think* recall.ai can split up the audio channels.  But it might require having the bot on the meeting- not sure.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:45:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50usvl",
          "author": "YUL438",
          "text": "try Deepgram Nova3",
          "score": 1,
          "created_utc": "2026-02-12 18:21:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o511wsj",
          "author": "FreonMuskOfficial",
          "text": "This may work. https://github.com/gs-ai/RippinTubes",
          "score": 1,
          "created_utc": "2026-02-12 18:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r7zr",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 1,
              "created_utc": "2026-02-12 20:55:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b5877",
          "author": "dakumaku",
          "text": "Gemini aistudio, NotebookLM",
          "score": 1,
          "created_utc": "2026-02-14 08:15:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2k2lc",
      "title": "Rough guess: What % of your code is AI assisted now?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "author": "Mental_Bug_3731",
      "created_utc": "2026-02-12 04:36:09",
      "score": 8,
      "num_comments": 16,
      "upvote_ratio": 0.73,
      "text": "Not copy paste. \nJust influenced. I‚Äôm probably at ~45%.\nFeels insane compared to last year. Curious where everyone else lands.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4xg9wp",
          "author": "qualityvote2",
          "text": "u/Mental_Bug_3731, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 04:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xodhk",
          "author": "cleanbot",
          "text": "99% nearly.... my workflow now is to describe to her Highness web gpt what changes i want in my code.\n\n\nshe generates the prompt i copy/pasta into the local codex running at my repo root. He bashes out the code. when I'm reporting a bug he first creates a test to verify before making changes.\n\n\ni review the logs and either reverse the changes or take the built product to manual tests.\n\n\nmy efficiency has been raised several orders of magnitude now. I'd never go back.",
          "score": 16,
          "created_utc": "2026-02-12 05:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zqici",
              "author": "sply450v2",
              "text": "good workflow. I do the same but also in plan mode and sometimes use my research skill or deep research to augment. also sometimes chatgpt pro for big arch decisions and planning",
              "score": 2,
              "created_utc": "2026-02-12 15:12:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y4o23",
          "author": "Ok-Shape-9145",
          "text": "Probably close to a 100%. I shifted to high level stuff, AI does the heavy lifting",
          "score": 3,
          "created_utc": "2026-02-12 08:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yahic",
          "author": "Hot_Inspection_9528",
          "text": "depends on the code. \n\n    import time\n    import pyautogui\n    # --- Settings ---he\n    word = \"hello\" ¬† ¬† ¬† ¬†# change me\n    delay = 0.2 ¬† ¬† ¬† ¬† ¬† # seconds between type and erase\n    type_interval = 0.02 ¬†# per-character delay while typing\n    \n    \n    # Safety: moving mouse to a corner aborts\n    pyautogui.FAILSAFE = True\n    \n    \n    print(\"Switch to the target window. Starting in 3 seconds...\")\n    time.sleep(3)\n    \n    \n    try:\n    ¬† ¬† while True:\n    ¬† ¬† ¬† ¬† pyautogui.typewrite(word, interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    ¬† ¬† ¬† ¬† pyautogui.press('backspace', presses=len(word), interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    except KeyboardInterrupt:\n    ¬† ¬† print(\"\\nStopped.\")\n\n  \nthis has done me wonders maybe  - weild the power correctly if you dont already know \n\nbut this was 100% written by ai which requires a very specific ask haahaha",
          "score": 1,
          "created_utc": "2026-02-12 09:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yke36",
          "author": "LanternOfTheLost",
          "text": "99%.\n\nIn many ways it‚Äôs like having a trainee or intern - you let it give you choices, provide evaluations, and you‚Äôd come in to validate his decisions before letting him run off on his own to implement.\n\nAnd then have him do the same cycle again for testing.",
          "score": 1,
          "created_utc": "2026-02-12 10:39:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zcv5o",
          "author": "Ok_Chef_5858",
          "text": "Probably 80% first draft, but I review and tweak everything. So technically 100% AI-assisted, 100% human-reviewed lol. I use Kilo Code in VS Code daily... AI writes the draft, I make sure it works. A year ago I'd maybe ask ChatGPT a question here and there. Now it's the whole workflow. :) ",
          "score": 1,
          "created_utc": "2026-02-12 14:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o512ple",
          "author": "dogscatsnscience",
          "text": "I'm not sure what \"just influenced\" means.\n\nFinal shipping code, probably 99%. If I am making significant manual edits or additions, which is rare these days, they're almost always going to get refactored by AI anyway.",
          "score": 1,
          "created_utc": "2026-02-12 18:58:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5218t5",
          "author": "X_TheSwindler_X",
          "text": "99% for sure, and the 1% I touch is usually the weak link ü´†",
          "score": 1,
          "created_utc": "2026-02-12 21:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52j5xc",
          "author": "alecc",
          "text": "If it‚Äôs below 100%, and you are not working on some super niche crazy project - you are wasting time and could have good results faster.",
          "score": 1,
          "created_utc": "2026-02-12 23:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ja2j",
              "author": "Mental_Bug_3731",
              "text": "Honestly true, what are you shipping currently!",
              "score": 1,
              "created_utc": "2026-02-12 23:16:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o54jtg5",
                  "author": "alecc",
                  "text": "[TickTappy](https://ticktappy.com) a simple time tracker for my needs",
                  "score": 1,
                  "created_utc": "2026-02-13 07:20:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53ryg8",
          "author": "AxeSlash",
          "text": "Boiler plate stuff: ~95%\nStuff I am unfamiliar with: ~80%\nBug fixes: ~50% by volume, but that's usually the bugs that require a lot of code to fix. I do almost all small fixes myself, and anything that would take some time to describe adequately enough to the LLM I also do myself.\nEverything else: ~40%?\nRefactoring: ~90%\n\nAlso I'm talking about assistance from an LLM, not vibe coding. I check everything it produces carefully.\n\nAlso depends on the language.",
          "score": 1,
          "created_utc": "2026-02-13 03:45:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58bg9g",
          "author": "Compilingthings",
          "text": "110%",
          "score": 1,
          "created_utc": "2026-02-13 20:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bg1e9",
          "author": "Classic-Ninja-1",
          "text": "Mine is about 99% where execution and planning or mostly everything I do with the use of AI my workflow consists of traycer for planning and verifying, cursor and claude for execution.",
          "score": 1,
          "created_utc": "2026-02-14 10:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhvzy",
          "author": "Tombobalomb",
          "text": "~3% maybe?",
          "score": -1,
          "created_utc": "2026-02-12 04:48:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r25gvg",
      "title": "A beautiful tool: Visual branching tree navigation for managing long ChatGPT conversations",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "author": "Own_Cat_2970",
      "created_utc": "2026-02-11 18:32:58",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 0.99,
      "text": "I kept running into the same problem: 50+ messages into a conversation and I have no idea where anything is. Scrolling endlessly trying to find that one useful response. And if I want to explore a side question, I either derail the whole thread or open a new chat and lose all context.\n\nSo I built **Tangent** ‚Äî a Chrome extension that overlays a visual branching tree on top of ChatGPT.\n\n[The \\\\\"Tangent View\\\\\". A visualization of the branching structure which Tangent enables. 1 sentence summaries of each node \\(prompt+response\\) when hovering over nodes for quick overview.](https://preview.redd.it/znlp8zk8swig1.png?width=785&format=png&auto=webp&s=1c5768327540b8267710e1b2e6ae32bef42c7b1d)\n\n**What it does:**\n\n* Branch off at any point without losing your place\n* See a visual map of your entire conversation\n* Hover over any node for a one-sentence summary\n* SHIFT+hover to see the full prompt/response\n* Jump back to any point instantly\n\n[SHIFT+hover over a node to see the full node \\(prompt\\/response\\)](https://preview.redd.it/3ny28yqhswig1.png?width=1134&format=png&auto=webp&s=88d959bcc5c67e320bb5ca64ae2e557a6ef5419a)\n\nIt lets you go on tangents (hence the name) the way your brain actually works -- except you can always find your way back.\n\nCurrently preparing bete-launch. happy to answer questions about how it works or the tech behind it.\n\nSignup for limited beta access: [https://tally.so/r/Zj6vLv](https://tally.so/r/Zj6vLv)",
      "is_original_content": false,
      "link_flair_text": "UNVERIFIED AI Tool (paid)",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4udonw",
          "author": "qualityvote2",
          "text": "u/Own_Cat_2970, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 18:32:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r56p6c",
      "title": "Frustrating glitch that cuts off portions of sentences, headers in ChatGPT Pro responses 20+ times in a response",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "author": "TrainingEngine1",
      "created_utc": "2026-02-15 05:42:22",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "First month paying for ChatGPT Pro and while it has its positives of course, I'm pretty frustrated with an additional glitch I've encountered on multiple occasions, with its negative impact varying in degree.\n\nIt will essentially inject a mini 'referenced this file' label in the middle of a sentence (which sometimes it likely did reference it/it's relevant, and other times the file being referenced definitely has nothing whatsoever to do with the sentence or context surrounding it).\n\nIt looks like this:\n\nhttps://i.ibb.co/zTK2pLQb/image.png\n\n\nAnd the issue is that it completely cuts off multiple words of that sentence it's adding it to. More often than not, it's tough to gauge what the words actually are and I can't fill in the blanks. Only sometimes it's a non-issue or I can gauge what the point being made was, but the notion I should have to play 'fill in the blanks' here is absurd. \n\nMost recent example had 26 instances of this cutting off many words & chunks of sentences. Basically this below, 26 times on repeat scattered throughout the response (approx 1500 words) in my most recent reply on 5.2 Pro with Extended Thinking, after 20 mins of thinking: https://i.ibb.co/zTK2pLQb/image.png\n\n\n\nThis has happened countless times and the most recent one where I counted 26 times was the worst yet. \n\n\nAnd using the 'copy' button doesn't fix it or 'reveal' the missing text. I hoped perhaps it was just a browser related thing, but I checked the Mac app too and it still displays the cut-off sentences/file reference labels.\n\n\nHas anyone else encountered this?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5gpn22",
          "author": "qualityvote2",
          "text": "Hello u/TrainingEngine1 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-15 05:42:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iapfc",
          "author": "changing_who_i_am",
          "text": "Yes, having the same bug for a few weeks now, very frustrating. One thing you can try is asking it to put all citations at the end of the response, but this may or may not be successful as it goes against \"policy\" üôÑ",
          "score": 2,
          "created_utc": "2026-02-15 14:00:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hr0wh",
          "author": "CategoryFew5869",
          "text": "ChatGPT UI is pretty bad. Do you mind sharing the exact steps to reproduce this? It looks like something a small script can fix.",
          "score": 1,
          "created_utc": "2026-02-15 11:36:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r41sqh",
      "title": "Non-programmer needs advice",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "author": "Mysterious_Green_544",
      "created_utc": "2026-02-13 21:31:25",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "Where do I even begin to get ChatGPT (or any AI platform) to translate my idea for a functionality/program/app into reality? I am not a programmer. I have been chatting with ChatGPT about what I'm trying to accomplish (a part of it is creating a video) and it's just not doing [it.My](http://it.My) chat tells me that ChatGPT can't create and embed an actual MP4 or moving clip. For real? ",
      "is_original_content": false,
      "link_flair_text": "Programming",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o58i6a9",
          "author": "qualityvote2",
          "text": "u/Mysterious_Green_544, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 21:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58j8s0",
          "author": "LiteratureMaximum125",
          "text": "for coding, [https://openai.com/index/introducing-the-codex-app/](https://openai.com/index/introducing-the-codex-app/)",
          "score": 6,
          "created_utc": "2026-02-13 21:36:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58lh0e",
          "author": "Fearless_Parking_436",
          "text": "If you have mac then codex app is the easiest probably. Otherwise Cursor and money for tokens.",
          "score": 3,
          "created_utc": "2026-02-13 21:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58l64v",
          "author": "MightyArd",
          "text": "Check out base44",
          "score": 1,
          "created_utc": "2026-02-13 21:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lhw9g",
          "author": "RaStaMan_Coder",
          "text": "I'd check out GSD. It's the only thing that gives enough structure to not lose the overview as your near completion. [https://github.com/gsd-build/get-shit-done](https://github.com/gsd-build/get-shit-done)",
          "score": 1,
          "created_utc": "2026-02-15 23:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lwcvn",
          "author": "LaughsInSilence",
          "text": "Learn to use a game engine. It's much less of a steep learning curve.\n\nIf you try to code with AI without being able to read code for the more complex stuff AI gives partially wrong answers all the time so you have to read and understand code.",
          "score": 1,
          "created_utc": "2026-02-16 01:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58ixub",
          "author": "AnLe90",
          "text": "Hey man ChatGPT can‚Äôt build it for you, it‚Äôs just more for getting knowledge and feedback and advice.\n\nIf you want to try vibe coding a prototype try loveable or v0, it‚Äôll actually do the building",
          "score": -1,
          "created_utc": "2026-02-13 21:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58mp4u",
              "author": "BronnOP",
              "text": "Not true. ChatGPT codex in visual studio code can code the entire thing, create additional files, install dependencies and start the local server on your pc. It can literally do it all lmao",
              "score": 8,
              "created_utc": "2026-02-13 21:53:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r1k6qu",
      "title": "better UI for LLMs?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r1k6qu/better_ui_for_llms/",
      "author": "OkLet9942",
      "created_utc": "2026-02-11 01:50:20",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Is there a better way to interact with llms than the current UIs?\n\nI want to work more complex stuff like presentations and long structured documents papers, prds, documentation and I find it impossible to structure different queries, summarize stuff, finalize sections, create chapters and re-find wording that I liked in various prompt experiments and so on. it all becomes a big mess every time.\n\nIs there something better out there to interface with an LLM?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1k6qu/better_ui_for_llms/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4q4yhw",
          "author": "qualityvote2",
          "text": "u/OkLet9942, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 01:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e6cnl",
          "author": "IngenuitySome5417",
          "text": "You've picked the wrong generation of models. I advise the eastern ones they don't have guards up like the western ones.\n\nhttps://medium.com/@ktg.one/all-your-agent-skills-are-broken-8cab4770ccb6",
          "score": 2,
          "created_utc": "2026-02-14 19:59:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rh4kr",
          "author": "InterYuG1oCard",
          "text": "I think you are looking for an ai workspace? Many options like notebooklm, saner, notion‚Ä¶",
          "score": 1,
          "created_utc": "2026-02-11 07:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z5r15",
          "author": "Ryanmonroe82",
          "text": "Check out LM Station on Mac",
          "score": 1,
          "created_utc": "2026-02-12 13:21:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r21ucg",
      "title": "Limits for Pro Thinking??",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r21ucg/limits_for_pro_thinking/",
      "author": "superuserjarvis",
      "created_utc": "2026-02-11 16:23:43",
      "score": 5,
      "num_comments": 14,
      "upvote_ratio": 0.78,
      "text": "I'm currently using my company's chat GPT Enterprise plan, and it provides me 15 requests per month for pro thinking (Research-grade intelligence one).\n\nWanted to know from users how many requests are allowed for GPT Pro plan that costs $200/month.\n\nAlso, how many Deep Research requests are allowed in the Pro plan?\n\nThank you kindly.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r21ucg/limits_for_pro_thinking/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4tlyjn",
          "author": "qualityvote2",
          "text": "u/superuserjarvis, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 16:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tod6i",
          "author": "Pasto_Shouwa",
          "text": ">for pro thinking (Research-grade intelligence one)\n\n>Wanted to know from users how many requests are allowed for GPT Pro\n\nUnlimited\n\n>Also, how many Deep Research requests are allowed in the Pro plan?\n\n250 per month",
          "score": 2,
          "created_utc": "2026-02-11 16:34:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tp2kg",
              "author": "superuserjarvis",
              "text": "Wow, thanks.\n\nLooks like a worthy upgrade. \n\nAlso, how many of those 250 are allowed are full vs lightweight?\n\nThanks kindly",
              "score": 2,
              "created_utc": "2026-02-11 16:38:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tqb7k",
                  "author": "Pasto_Shouwa",
                  "text": ">Also, how many of those 250 are allowed are full vs lightweight?\n\nI think OpenAI hasn't disclosed it. They also said that the full version is powered by 5.2 Thinking just a couple of days ago, but we don't know what model the lightweight version uses. They're quite secretive about deep research for some reason.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:43:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4toza2",
          "author": "petermalik01",
          "text": "ChatGPT Pro (model) - it‚Äôs effectively unlimited. Many times  I‚Äôve used the model more than 20 times a day, and I‚Äôve never seen any message indicating there‚Äôs a limit. In the current version, it‚Äôs usually the extended-thinking variant (i.e., stronger than the standard Pro).\n\nDeep Research ‚Äî 250 per month. I‚Äôve never even come close to using 50% of that limit.\n\nFor me, a major advantage of Pro is also using GPT-5.2 Thinking in heavy thinking mode ‚Äî it‚Äôs noticeably better than extended thinking.",
          "score": 2,
          "created_utc": "2026-02-11 16:37:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tpbjw",
              "author": "superuserjarvis",
              "text": "Ohh so there is a heavy thinking other than extended thinking??",
              "score": 2,
              "created_utc": "2026-02-11 16:39:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tra0q",
                  "author": "petermalik01",
                  "text": "Yes ‚Äî the GPT-5.2 Thinking variant has four modes in the Pro subscription: (1) light, (2) standard, (3) extended, and (4) heavy. Modes 1 and 4 are exclusive to Pro.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:48:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u9mtw",
          "author": "Oldschool728603",
          "text": "(1) Pro subscription offers unlimited access to  Pro the model, standard and extended\n\n  \n(2) Pro subscription offers 250 deep research per month‚Äî125 full (based on o3) and 125 light (based on o4-mini)",
          "score": 2,
          "created_utc": "2026-02-11 18:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ueys1",
              "author": "superuserjarvis",
              "text": "Thanks üòä",
              "score": 1,
              "created_utc": "2026-02-11 18:38:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5a1g07",
              "author": "Ok-Entrance8626",
              "text": "Though (2) is surely out of date as deep research now uses 5.2.",
              "score": 1,
              "created_utc": "2026-02-14 02:54:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aigfc",
                  "author": "Oldschool728603",
                  "text": "You're right. As of the 10th, Deep Research with Pro subscription offers \"Deep research\" and \"Legacy\" options. Is Legacy o3? Is it still 250? Is there a split?\n\nOpenAI wouldn't be OpenAI if we had a clear answers.\n\nI can see the support tickets:\n\n\"I'm having a problem with Deep Research.\"\n\n\"Are you using Deep Research?\"\n\n\"Yes, I said Deep Research.\"\n\n\"But are you using Deep Research?\"",
                  "score": 1,
                  "created_utc": "2026-02-14 04:55:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4xnf0b",
          "author": "zaibatsu",
          "text": "I haven‚Äôt hit a limit and I‚Äôll sometimes spin up several instances that can churn for up to 99 minutes at a time concurrently in 5.2 Pro mode‚Äôs extended thinking. \n\nI  haven‚Äôt stopped in quite a while.",
          "score": 1,
          "created_utc": "2026-02-12 05:30:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5jedn",
      "title": "tool for better chat organization / pruning etc.",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "author": "rhaynes74",
      "created_utc": "2026-02-15 16:48:11",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "My current ai work has been with gemini and chatgpt via their websites.  This gives a very linear chat experience with the option to output chat transcripts and then reorganize the chat, delete parts etc. Are there tools available which allow you to organize / rearrange parts of the chat in a more interactive way? ",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5j70a1",
          "author": "qualityvote2",
          "text": "Hello u/rhaynes74 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-15 16:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m94xc",
          "author": "manjit-johal",
          "text": "I usually think in terms of structured context slices instead of one giant history; tag buckets by topic or task, then only feed the relevant slice into the prompt. Keeps the LLM focused and makes cleanup/pruning way simpler without relying on a huge monolithic chat log.",
          "score": 1,
          "created_utc": "2026-02-16 02:44:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}