{
  "metadata": {
    "last_updated": "2026-02-15 03:21:10",
    "time_filter": "week",
    "subreddit": "ChatGPTPro",
    "total_items": 20,
    "total_comments": 179,
    "file_size_bytes": 182454
  },
  "items": [
    {
      "id": "1r0e3po",
      "title": "I've used AI to write 100% of my code for 1+ year as an engineer. 13 hype-free lessons",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r0e3po/ive_used_ai_to_write_100_of_my_code_for_1_year_as/",
      "author": "helk1d",
      "created_utc": "2026-02-09 19:37:05",
      "score": 104,
      "num_comments": 21,
      "upvote_ratio": 0.89,
      "text": "1 year ago I posted \"12 lessons from 100% AI-generated code\" that hit 1M+ views. Some of those points evolved into agents.md, claude.md, plan mode, and context7 MCP. This is the 2026 version, learned from shipping products to production.\n\n**1- The first few thousand lines determine everything**\n\nWhen I start a new project, I obsess over getting the process, guidelines, and guardrails right from the start. Whenever something is being done for the first time, I make sure it's done clean. Those early patterns are what the agent replicates across the next 100,000+ lines. Get it wrong early and the whole project turns to garbage.\n\n**2- Parallel agents, zero chaos**\n\nI set up the process and guardrails so well that I unlock a superpower. Running multiple agents in parallel while everything stays on track. This is only possible because I nail point 1.\n\n**3- AI is a force multiplier in whatever direction you're already going**\n\nIf your codebase is clean, AI makes it cleaner and faster. If it's a mess, AI makes it messier faster. The temporary dopamine hit from shipping with AI agents makes you blind. You think you're going fast, but zoom out and you actually go slower because of constant refactors from technical debt ignored early.\n\n**4- The 1-shot prompt test**\n\nOne of my signals for project health: when I want to do something, I should be able to do it in 1 shot. If I can't, either the code is becoming a mess, I don't understand some part of the system well enough to craft a good prompt, or the problem is too big to tackle all at once and needs breaking down.\n\n**5- Technical vs non-technical AI coding**\n\nThere's a big difference between technical and non-technical people using AI to build production apps. Engineers who built projects before AI know what to watch out for and can detect when things go sideways. Non-technical people can't. Architecture, system design, security, and infra decisions will bite them later.\n\n**6- AI didn't speed up all steps equally**\n\nMost people think AI accelerated every part of programming the same way. It didn't. For example, choosing the right framework, dependencies, or database schema, the foundation everything else is built on, can't be done by giving your agent a one-liner prompt. These decisions deserve more time than adding a feature.\n\n**7- Complex agent setups suck**\n\nFancy agents with multiple roles and a ton of .md files? Doesn't work well in practice. Simplicity always wins.\n\n**8- Agent experience is a priority**\n\nTreat the agent workflow itself as something worth investing in. Monitor how the agent is using your codebase. Optimize the process iteratively over time.\n\n**9- Own your prompts, own your workflow**\n\nI don't like to copy-paste some skill/command or install a plugin and use it as a black box. I always change and modify based on my workflow and things I notice while building.\n\n**10- Process alignment becomes critical in teams**\n\nDoing this as part of a team is harder than doing it yourself. It becomes critical that all members follow the same process and share updates to the process together.\n\n**11- AI code is not optimized by default**\n\nAI-generated code is not optimized for security, performance, or scalability by default. You have to explicitly ask for it and verify it yourself.\n\n**12- Check git diff for critical logic**\n\nWhen you can't afford to make a mistake or have hard-to-test apps with bigger test cycles, review the git diff. For example, the agent might use created\\_at as a fallback for birth\\_date. You won't catch that with just testing if it works or not.\n\n**13- You don't need an LLM call to calculate 1+1**\n\nIt amazes me how people default to LLM calls when you can do it in a simple, free, and deterministic function. But then we're not \"AI-driven\" right?\n\n**EDIT:**¬†since many are asking for examples, I already answered most of the questions in the comments with examples, and I started posting my learnings on the go on my¬†[X account](https://x.com/QaisHweidi), and hopefully will keep posting",
      "is_original_content": false,
      "link_flair_text": "Guide",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r0e3po/ive_used_ai_to_write_100_of_my_code_for_1_year_as/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4hj1sl",
          "author": "qualityvote2",
          "text": "‚úÖ u/helk1d, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-09 19:37:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hqeug",
          "author": "adelie42",
          "text": "Strong agree. On 11 in particular,  it seems people want to one shot good code and get frustrated spending lots of time doing it wrong. What's better is to set the bar that the initial integration will at best be a workijg proof of concept. If you aim for a working proof of concept every time and can achieve being almost always successful on the first shot, then iterate towards DRY, separation of concerns, maintainable modularity, performance, security, and so on; each of those steps one at a time is fairly easy to accomplish. And who cares if it is 8 sequential prompts instead of one big one?\n\nOt is taking responsibility for the chain of thought and represents the human in the loop process you describe.\n\nTrying to place all the bricks in the wall at the same time is highly overrated.",
          "score": 8,
          "created_utc": "2026-02-09 20:14:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hs975",
              "author": "helk1d",
              "text": "yeah i didn't mean you must nail it from the first prompt to get all aspects of it right, i meant you shouldn't write a prompt that is not clear, and let ai do guess work and eventually keep prompting it to clean up the mess it did or writing \"it still doesn't work\" 10 times",
              "score": 3,
              "created_utc": "2026-02-09 20:23:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j2zuh",
          "author": "halffast",
          "text": "In your experience working with multiple parallel agents, are they effective only when working on completely separate tasks, or is it ok if the tasks have some (or even a lot of) overlap? I‚Äôm curious where the line is between ‚Äúaccelerated‚Äù vs ‚Äúchaos.‚Äù",
          "score": 3,
          "created_utc": "2026-02-10 00:26:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lartr",
              "author": "helk1d",
              "text": "i have many claude terminals opened on the same project, one of them is where i'm actively working on, the other is in planning phase, another is making changes to a separate part of the repo....etc, and sometimes when i want full isolation i have another git checkout as if it's a different dev working on the project. But having things in parallel drains your mental energy pretty fast tbh",
              "score": 4,
              "created_utc": "2026-02-10 10:15:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lv0mh",
                  "author": "halffast",
                  "text": "> sometimes when I want full isolation I have another git checkout as if it‚Äôs a different dev working on the project \n\nThis blew my mind a bit. I would love to hear more about how you achieve this. Do you have a virtual machine going or a separate computer? Do you need to do anything special with git?",
                  "score": 1,
                  "created_utc": "2026-02-10 12:56:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jx0k0",
          "author": "knoodrake",
          "text": "Agree. I tend to apply the same principles/practices myself ( but even then, beware of the dopamine shortcut quick feature/fix at the end of the day, the one you're no longer motivated to double check. Dont do it. Prepare the prompt, take some note for tomorrow, but don't let that last trap of convenience of letting the LLM do it all by itself with a suboptimal prompt and commit nevertheless because the day went well. It's a trap and you'll revert tomorrow (if you're lucky/careful enough)",
          "score": 3,
          "created_utc": "2026-02-10 03:22:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i057q",
          "author": "BBQUEENMC",
          "text": "Thanks",
          "score": 2,
          "created_utc": "2026-02-09 21:02:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4is45i",
          "author": "Comprehensive_Aide94",
          "text": "Sounds very sane and reasonable!\n\nI resonate a lot with #4 \"The 1-shot prompt test\". I usually lean towards giving very detailed and drilled down specifications, and I was wondering whether I'm getting too specific and should be more laid-back instead. I like that your rule gives me a heuristic - yeah, I can try different levels of prompt granularity, but if it results in more back-and-forth, then I need to tighten prompts.  \n  \nAnd I generally appreciate your nuanced take which differentiates best practices for each use case, like the acknowledgement that sometimes deterministic algorithms are more appropriate, as well as careful thinking through without outsourcing to LLM.   \n  \nThe #10 is super interesting. I see a lot of discussions where people describe the state of their own development process, but very little about the process alignment within a team.  ",
          "score": 2,
          "created_utc": "2026-02-09 23:25:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tzmju",
          "author": "Nonikwe",
          "text": "In my experience, good AI driven *has* to essentially be spec driven development. You break down what's going to be built (this can be AI assisted, but youve got to know exactly what the details are here, and be qctively involved in shaping it), the tasks it involves, and then the actual development becomes much less about worrying about the right prompts or agent icon setup, and more just \"implement this spec according to the implementation plan\". You should never be running into \"this task is too complicated or not clear enough\", because all the difficult pieces should have been ironed out while producing the spec.",
          "score": 2,
          "created_utc": "2026-02-11 17:27:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4izc5g",
          "author": "Neither-Apricot-1501",
          "text": "Insightful read! Your point about early patterns dictating project quality resonates hard seen so many codebases crumble from rushed foundations. #LessonsLearned",
          "score": 2,
          "created_utc": "2026-02-10 00:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kr6w9",
          "author": "Subject-Street-6503",
          "text": "Can you drill down point 1 and give sub-specifics or examples?",
          "score": 1,
          "created_utc": "2026-02-10 07:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lbcwx",
              "author": "helk1d",
              "text": "the \"process, guidelines, and guardrails\" part of this point is big and need multiple posts, but as a quick response, i meant tests, quality gates in CI/CD for things like lint, type-check, tests, sonar cloud...etc\n\ncheck this out [https://x.com/QaisHweidi/status/2021187544558297476](https://x.com/QaisHweidi/status/2021187544558297476)",
              "score": 2,
              "created_utc": "2026-02-10 10:21:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4pjw42",
          "author": "Cole_Slawter",
          "text": "I‚Äôm starting to think you‚Äôre not using a browser to connect to your model.  Or is all of this taking place in several ChatGPT tabs?",
          "score": 1,
          "created_utc": "2026-02-10 23:47:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55eb6f",
          "author": "iarnkr",
          "text": "interesting, heres my thoughts as another ai engineer with 1 yr+ of vibe coding:\n\n1. you could even let ai figure out the prompts no need to own those (slef evolution - acquire skills as it go), no need to verify it yourself\n\n2. latency/critical path: rather than do it yourself you want ai to self instrument these metrics so it can review those to optimize over time, no need to verify it yourself\n\n3. 1, 5, 6, 13 - no need to do it yourself",
          "score": 1,
          "created_utc": "2026-02-13 11:56:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nj4v8",
          "author": "HighDefinist",
          "text": "Interesting how nobody here is noticing that this is likely written by an AI...",
          "score": 0,
          "created_utc": "2026-02-10 17:57:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1k33f",
      "title": "People who use ChatGPT as the \"Life's OS\", how do you do that? What projects have you defined? Here's mine:",
      "subreddit": "ChatGPTPro",
      "url": "https://i.redd.it/6bbil67krrig1.png",
      "author": "reddit_user38462",
      "created_utc": "2026-02-11 01:45:39",
      "score": 86,
      "num_comments": 48,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1k33f/people_who_use_chatgpt_as_the_lifes_os_how_do_you/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4q46sr",
          "author": "qualityvote2",
          "text": "u/reddit_user38462, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 01:45:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q710c",
          "author": "mop_bucket_bingo",
          "text": "I‚Äôm not used to seeing posts about actually *using* ChatGPT.\n\nI have a ton of folders and I‚Äôm already wishing they had a tagging system in addition to the folders.\n\nThat and timestamps.",
          "score": 50,
          "created_utc": "2026-02-11 02:02:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4r7p1a",
              "author": "nomad-system",
              "text": "No users here just complainers",
              "score": 12,
              "created_utc": "2026-02-11 06:14:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tckby",
              "author": "danih479",
              "text": "I now put this in all AI personalization. It really helps.\n\nEnd every response with the exact day of the week, date, and time (am/pm), formatted like: ‚ÄúFriday, May 23rd, 2025 ‚Äî 07:13:32 PM‚Äù.",
              "score": 5,
              "created_utc": "2026-02-11 15:39:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4txqrx",
                  "author": "mop_bucket_bingo",
                  "text": "I‚Äôve done that too and it generally doesn‚Äôt work reliably in such a way that I care to clutter my instructions with it.",
                  "score": 3,
                  "created_utc": "2026-02-11 17:18:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4q80oj",
              "author": "reddit_user38462",
              "text": "lol ya. This sub can be hard to keep up!\n\nWould love to see your folders list (or the top ones you think they'd be useful).",
              "score": 2,
              "created_utc": "2026-02-11 02:08:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4qg5vb",
                  "author": "mop_bucket_bingo",
                  "text": "Most of them aren‚Äôt general.\n\nI have a few that are, including one named ‚ÄúMeta‚Äù, which isn‚Äôt about the company of the same name. Rather, it‚Äôs where I ask ChatGPT to write prompts for me.\n\nI have another called ‚ÄúSleep‚Äù where I just have conversations about topics that are fun to think about while falling asleep.\n\nThen a few usual suspects‚Ä¶Food, Shopping, Music, Travel‚Ä¶\n\nBut the rest are very specific to an actual project.",
                  "score": 3,
                  "created_utc": "2026-02-11 02:57:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r0rp7",
              "author": "xinxiyamao",
              "text": "Timestamps!! Yes!! It drives me crazy to have to figure out when a chat started. I ask when the chat began and the answer is sways today. Even if it was 2 months old.",
              "score": 1,
              "created_utc": "2026-02-11 05:18:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wyus5",
                  "author": "sedid55",
                  "text": "I think they just started timestamps, u can find it when u click the three button where you branch the chat",
                  "score": 2,
                  "created_utc": "2026-02-12 02:41:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4r3qpy",
              "author": "Imaginary_Sun_4305",
              "text": "I just added this to the custom instruction. works at both a ChatGPT and project level:\n\n\"Begin EVERY response with current date and time (GMT).\" (obvs substitute the time zone for where you are)",
              "score": 1,
              "created_utc": "2026-02-11 05:42:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o556p8l",
              "author": "emiliookap",
              "text": "Would a ‚Äùvisual desktop‚Äù with dragging and placing your conversations as apps be something for you? For easier organizing",
              "score": 1,
              "created_utc": "2026-02-13 10:53:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57ad04",
                  "author": "mop_bucket_bingo",
                  "text": "Just a standard 2D hierarchy combined with the multidimensional one that tags offer is what I need.",
                  "score": 1,
                  "created_utc": "2026-02-13 17:56:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4re73a",
          "author": "Own_Cat_2970",
          "text": "I've had issues with not being able to find my way around my countless conversations and long scrolling threads, so i've build a chrome extension that enables me to branch my conversations. This has been a life saver for me with big projects. (image below is just an dummy-conversation)\n\nhttps://preview.redd.it/ge0fln75ftig1.png?width=1139&format=png&auto=webp&s=b0cfffd88d88fc1cae1d705fbbe83bebe9eadff4\n\n",
          "score": 3,
          "created_utc": "2026-02-11 07:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xybqy",
              "author": "exitsimulation",
              "text": "This seems like a very useful feature! Are you planning to release the extension?",
              "score": 2,
              "created_utc": "2026-02-12 07:05:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yxin1",
                  "author": "Own_Cat_2970",
                  "text": "No but its right on its way! If you wanna join for the limited beta release, you can sign up at¬†[https://tally.so/r/Zj6vLv](https://tally.so/r/Zj6vLv) ! I'll be keeping in touch with progress and releases via the mailing list :)",
                  "score": 2,
                  "created_utc": "2026-02-12 12:27:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u1nok",
          "author": "Scary_Relation_996",
          "text": "https://preview.redd.it/jg3ou3qyiwig1.png?width=444&format=png&auto=webp&s=3bf5b1f30fed1cdb41e2a64c1e77e30f911ed1bc\n\n",
          "score": 2,
          "created_utc": "2026-02-11 17:37:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qkvp0",
          "author": "UpsetWildebeest",
          "text": "I have similar categories to yours, I also have a ‚Äúfinancial stuff‚Äù category because I'm working on paying down debt and figuring my shit out. In that project I basically laid out all my debt, and I have it help me track where I'm at. I also input things like if I worked overtime, etc",
          "score": 1,
          "created_utc": "2026-02-11 03:27:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qu67u",
          "author": "Vintage_Visionary",
          "text": "Q: Are you uploading specific resources to the project files?  \nI've been experimenting with breaking a BIG project up into smaller sectors, uploading books, resources, and seeing if I can get the individual project version of the GPT to be my resource on these materials as I work. But its tricky.\n\nReally prefer using different in-system add-on GPTs. Love how they are informed on specific data, and more focused into those zones. Ie there's a health-food/cleaning eating GPT that I use alot, and get perspective from. Wish that there could be included in project folders. Or have their own silos for it vs. individual chat threads.",
          "score": 1,
          "created_utc": "2026-02-11 04:29:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ria3x",
          "author": "VideoShare_AI",
          "text": "I have a folder each on my kids. Especially how to communicate when challenging events happen.",
          "score": 1,
          "created_utc": "2026-02-11 07:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rjjt9",
          "author": "Potential_Regular349",
          "text": "\n\t2.\tPeople / Relationships\n\t3.\tHealth\n\t4.\tImages / Visual Ideas\n\t5.\tEnglish Learning (C2 Level)\n\t7.\tCannabis / Reflections\n\t8.\tDomestic Politics (Poland)\n\t9.\tWork \n\t11.\tLaw / Legal Topic\n\t12.\tDutch Language / Netherlands\n\t13.\tGeopolitics\n\t14.\tAnime / Japanese Media\n\t15.\tArt\n\t16.\tPhilosophy\n\t17.\tFinancial Technology / FinTech\n\t18.\tInstagram / Social Media Presence\n\t19.\tWriting Project\n\t20.\tPhotography\n\t21.\tIT / Technology\n\t22.\tKorea / Culture & Aesthetics\n\nMy projects üëÄ",
          "score": 1,
          "created_utc": "2026-02-11 08:01:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4sjjfl",
              "author": "pivotraze",
              "text": "I have some similar categories, mostly projects. I also have a German Learning project haha",
              "score": 1,
              "created_utc": "2026-02-11 13:04:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4s16rw",
          "author": "Other-Departure-7215",
          "text": "Love this breakdown! Your separation of Journaling vs Mental Health is brilliant - treating them as distinct but connected spaces makes so much sense. I'm particularly curious about your Business Communications project. Do you find that training it with your tone over time makes the outputs more natural, or do you still need to tweak significantly? Also wondering if you've experimented with any cross-project workflows - like pulling insights from your Journaling project into Mental Health conversations? Would love to hear how others are thinking about these project boundaries!",
          "score": 1,
          "created_utc": "2026-02-11 10:46:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sphs3",
          "author": "day_drinker801",
          "text": "I have similar projects. Basically, if I am having the same conversation in different chats more than a few times, I create a project for that subject.",
          "score": 1,
          "created_utc": "2026-02-11 13:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tchy4",
          "author": "El_Diablo_Feo",
          "text": "Projects categories:\nCareer maxxing, Finances, Budhhist practice (the path), Sadness box, Geoarbitrage and Retirement strategies, Startup stuff, Learning German\n\n\nImportant that project details/instructions are clear and files are organized with context in the title of each file",
          "score": 1,
          "created_utc": "2026-02-11 15:39:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o557k99",
              "author": "emiliookap",
              "text": "Sounds very structured, does it work for you?\n\nThe issue i have with chatgpts projects is that all the items is still a list.",
              "score": 1,
              "created_utc": "2026-02-13 11:01:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5623j1",
                  "author": "El_Diablo_Feo",
                  "text": "Can you clarify what you mean by the items is still a list?   The list needs to have context for it to make sense.\n\nSo right now I'm using chatGPT to scale the work I'm doing for my startup. So far so good, I'm finding holes and trying to plug them as best I can. But overall it works \n\nThe biggest issue is that it requires a lot of grinding to make chat GPT understand context. And that's the case with any AI/LLM really. So the more structured you keep your stuff the easier it will be for the AI to do its job well.\n\nI would say my advice to you is to think of Projects as a 3-layer control system:\n  \n1) Project Files = Facts and Source of Truth\n  \nUploaded docs are your hard evidence. I treat them as primary reference material.\n  \n2) Project Instructions = Standing Rules\n  \nThis is persistent guidance that applies to every chat in that project.\n  \n3) Your Prompt = Task Command\n  \nThe prompt is the immediate assignment.\n  \nHow they work together (priority order):\n  \nPrompt --> Project Instructions --> Project Files\n  \nPrompt drives the task\n  \n- Instructions shape how it executes it\n  \n- Files ground the content\n  \n\nBest practice for maximum effectiveness:\n  \n- Put stable rules and standards in Project Instructions\n  \n- Put reference material in Files\n  \n- Keep prompts short, task-specific, and explicit about output format\n  \n  \nIf accuracy matters, tell it to use project files as primary source\n  \nIf you change modes (draft vs validate), say it in the prompt.",
                  "score": 1,
                  "created_utc": "2026-02-13 14:21:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vcygt",
          "author": "Impossible_Prompt875",
          "text": "Folders? What.. is this the regular subscription or the ultra expensive one? Someone please enlighten me",
          "score": 1,
          "created_utc": "2026-02-11 21:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wj4hc",
          "author": "burkeyFORE",
          "text": "I have some diy home renovating and repair and have a folder called ‚ÄúHome Reno‚Äù.¬†",
          "score": 1,
          "created_utc": "2026-02-12 01:06:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yhswh",
          "author": "huaisha",
          "text": "only have 3 folders for now, wondering if it's practical for me to select before chat every time if there is a long list of folders. ",
          "score": 1,
          "created_utc": "2026-02-12 10:15:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zpaug",
          "author": "sherrigreenlive",
          "text": "https://preview.redd.it/vfak2r34x2jg1.jpeg?width=1290&format=pjpg&auto=webp&s=377d736cb6978bab759b55f90753296d64335cc8",
          "score": 1,
          "created_utc": "2026-02-12 15:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51mje7",
          "author": "Fishtacoburrito",
          "text": "I have maybe half of those and I have one to analyze my HOA CC&Rs for malicious compliance. I dare OpenAI to age verify me.",
          "score": 1,
          "created_utc": "2026-02-12 20:33:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o556tby",
          "author": "emiliookap",
          "text": "This is my setup!\n\nhttps://preview.redd.it/ps60wz81t8jg1.png?width=1920&format=png&auto=webp&s=c4bb32ea22af843180787954ff597ce3000221f3",
          "score": 1,
          "created_utc": "2026-02-13 10:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rgfzk",
          "author": "OddInititi",
          "text": "I'm a heavy user of chatGPT, but only for research purpose. For managing life tasks, I use the ai second brain on saner.ai with its interface (note, calendar, todos...). I find \"life os\" easier when the tool has a dedicated workspace, not just a chat screen",
          "score": 1,
          "created_utc": "2026-02-11 07:32:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ryad3",
              "author": "utvols22champs",
              "text": "Are both of those paid subscriptions?",
              "score": 2,
              "created_utc": "2026-02-11 10:20:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4tx6p2",
              "author": "spiderjohnx",
              "text": "I use GPT for the same. Do you cut and paste into saner? What do you struggle with most in your research workflow with GPT. I also use it as a brainstorming/think partner. Looking for tips.",
              "score": 2,
              "created_utc": "2026-02-11 17:16:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4svxg7",
          "author": "Last-Bluejay-4443",
          "text": "I‚Äôve created a tool to act as a memory layer to save all my elements that I need. It seems to work better than folders in ChatGPT natively because I can save snippets of text across threads and return to them upstream whenever I need.",
          "score": 1,
          "created_utc": "2026-02-11 14:15:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t2dbw",
              "author": "SciFidelity",
              "text": "How does the tool integrate?",
              "score": 1,
              "created_utc": "2026-02-11 14:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tbcmx",
                  "author": "Last-Bluejay-4443",
                  "text": "It‚Äôs just a Chrome extension that runs on top of the ChatGPT web app. No API keys or anything.\n\nWhen you‚Äôre in a conversation, you can mark specific messages or snippets, and it saves them in a separate sidebar so you can revisit them later, even across different threads.\n\nI built it because folders alone didn‚Äôt solve the ‚ÄúI only need this one part‚Äù problem.",
                  "score": 4,
                  "created_utc": "2026-02-11 15:34:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4rfyoj",
          "author": "HustleForTime",
          "text": "I was a long time beta participant to mem.ai\nI was developing my own RAG Life OS, but they had almost everything I wanted on the roadmap.\n\nIf you‚Äôre using chatGPT like this, at least consider looking into mem or other more bespoke options.",
          "score": -3,
          "created_utc": "2026-02-11 07:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4txk1t",
              "author": "spiderjohnx",
              "text": "Do you cut and paste into your notes? What do you struggle with most in your workflow with GPT. I also use it as a brainstorming/think partner. Looking for tips.",
              "score": 1,
              "created_utc": "2026-02-11 17:17:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r18upw",
      "title": "One day of work + Opus 4.6 = Voice Cloning App using Qwen TTS. Free app, No Sing Up Required",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r18upw/one_day_of_work_opus_46_voice_cloning_app_using/",
      "author": "OneMoreSuperUser",
      "created_utc": "2026-02-10 18:30:43",
      "score": 81,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "A few days ago, Qwen released a new open weight speech-to-speech model: Qwen3-TTS-12Hz-0.6B-Base. It is great model but it's huge and hard to run on any current regular laptop or PC so I built a free web service so people can check the model and see how it works.\n\n* No registration required\n* Free to use\n* Up to 500 characters per conversion\n* Upload a voice sample + enter text, and it generates cloned speech\n\nHonestly, the quality is surprisingly good for a 0.6B model.\n\nModel:\n\n[https://github.com/QwenLM/Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS)\n\nWeb app where you can text the model for free:\n\n[https://imiteo.com](https://imiteo.com/)\n\nSupports 10 major languages: English, Chinese, Japanese, Korean, German, French, Russian, Portuguese, Spanish, and Italian.\n\nIt runs on an NVIDIA L4 GPU, and the app also shows conversion time + useful generation stats.\n\nThe app is 100% is written by Claude Code 4.6. Done in 1 day.\n\nOpus 4.6, Cloudflare workers, L4 GPU",
      "is_original_content": false,
      "link_flair_text": "Programming",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r18upw/one_day_of_work_opus_46_voice_cloning_app_using/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4nqgop",
          "author": "qualityvote2",
          "text": "‚úÖ u/OneMoreSuperUser, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-10 18:30:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q3z56",
          "author": "good4y0u",
          "text": "It's nice that free Models for things like this are getting better and better. Obviously the malicious use capabilities of these tools are high, but the tech is cool.",
          "score": 2,
          "created_utc": "2026-02-11 01:44:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qqoo0",
          "author": "Rasputin_mad_monk",
          "text": "I tried it. Thanks. Kinda cool",
          "score": 2,
          "created_utc": "2026-02-11 04:05:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qu2lp",
              "author": "OneMoreSuperUser",
              "text": "Thank you! Let me know if you have any ideas how to improve the app.",
              "score": 1,
              "created_utc": "2026-02-11 04:29:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ol0rx",
          "author": "Icy_Distribution_361",
          "text": "0.6b is huge for running locally on a laptop? I don't think so.",
          "score": 1,
          "created_utc": "2026-02-10 20:52:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oncqc",
              "author": "OneMoreSuperUser",
              "text": "how long do you think it will run on your machine?",
              "score": 1,
              "created_utc": "2026-02-10 21:03:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4q7g69",
          "author": "faldrich603",
          "text": "I tried, this. It's good, but still doesn't quite clone a voice as accurately as, say, ElevenLabs.",
          "score": 0,
          "created_utc": "2026-02-11 02:05:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2990u",
      "title": "Stick with ChatGPT Plus or switch to Claude / Gemini / Perplexity / AIO platforms",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "author": "magnumpl",
      "created_utc": "2026-02-11 20:52:13",
      "score": 45,
      "num_comments": 37,
      "upvote_ratio": 0.91,
      "text": "Hi. I‚Äôve been using ChatGPT Plus daily for a while now. Overall I like it, but I‚Äôm wondering if I'm missing out on other options which might be better to pay for.\n\nI mostly use AI for daily practical stuff, researching, summing up documents or threads, getting second opinions, cleaning up my writing etc. I recently started playing with image generator for content creations and ideas. Here is how ChatGPT summed up my usage:\n\n* Technical troubleshooting (yaml, wordpress, home servers, docker, networking, smart home, cameras, Home Assistant)\n* DIY / home projects (planning before doing anything expensive)\n* Business support (billing, coding logic, emails, contracts)\n* Writing help (emails, explanations, cleaning)\n* Light creative/marketing work (social posts, promos, restructuring content)\n* Translating/simplifying content (technical ‚Üí plain language)\n* Decision-making and sanity checks (‚Äúdoes this make sense?‚Äù, ‚Äúwhat am I missing?‚Äù)\n\nWhat matters most to me is good reasoning, being able to handle long context without losing track, and explanations that are clear but not dumbed down.   \nWhat I don't like about ChatGPT is that is doesn't handle long conversations i.e. troubleshooting, but I use projects as a workaround where I just start a new chat within a project when I am noticing that gpt is glitching. It is often overconfident while being wrong so I often have to sanity-check. I also need to keep correcting it's responses when it starts using too many emojis and bullet points. The image generator seems limited as well, it often trips when I want it to correct something, or corrects areas outside of my selection.\n\nI've seen people recommend Claude, Gemini, and Perplexity, and all-in-one platforms like Poe, Abacus, or OpenRouter. \n\n\\- Should I stay with ChatGPT or switch to other AI?  \n\\- Is an AIO platform worth it? It would be same price or even cheaper than ChatGPT Plus, but I can't find what would I miss out on with switching to these.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v6xjz",
          "author": "qualityvote2",
          "text": "‚úÖ u/magnumpl, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-11 20:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v7cfy",
          "author": "Boring_Software1379",
          "text": "Commenting to follow along with any guidance you get. I'm getting frustrated with ChatGPT plus as well, mainly from a pricing standpoint ",
          "score": 19,
          "created_utc": "2026-02-11 20:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o553g0l",
              "author": "Dyleteyou",
              "text": "Ya I love it but $20 a month is wild. Not that it isn‚Äôt worth it just the budget thought for it just seems off",
              "score": 2,
              "created_utc": "2026-02-13 10:24:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z0to1",
          "author": "battleship_31",
          "text": "Following bc ChatGPT has been put on a super tight leash and it‚Äôs not what it was 6 months ago‚Ä¶not worth my $20 anymore",
          "score": 8,
          "created_utc": "2026-02-12 12:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516gz8",
              "author": "Homegrown_Phenom",
              "text": "üíØ agreed!  Getting üçø ready\n\nJust can't wait for tomorrow morning... Reddit/internet gonna break, peeps going to throw a fit once legacy models deprecated",
              "score": 1,
              "created_utc": "2026-02-12 19:16:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w75nh",
          "author": "MagmaElixir",
          "text": "TL;DR: Try Claude if a Projects folder function is more important to you with segregated chats and memory. Try Gemini if long context chats are way more important than a Projects folder function. \n\nGemini has a 1 million token context length, which makes it able to hold many or long documents or longer chat threads in one go. Though there is no projects folder function. \n\nI suggest trying Claude. It handles longer context better than ChatGPT by compacting content past its content window to still be visible in the chat thread. Claude also handles memory better. It can also search historic chat threads and save a manual memory, but it also has an automatic memory generated each night. The automatic memory is a TL;DR of your chat history and what Claude learns about you. The automatic memory and manual memory are served at the start of every chat thread. Claude is also more proactive about managing manual memory if you instruct it to in custom instructions. \n\nClaude also has a stronger Project folder system. You can attach many more files and it‚Äôll index them for RAG.  Each Project also has its own automatic memory and manual memory. What‚Äôs great about this is Claude without having to perform a tool call know your progress on a project at the start of every chat thread.",
          "score": 6,
          "created_utc": "2026-02-11 23:56:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4woxr6",
              "author": "niado",
              "text": "For anyone wanting to try something in the Gemini family, I highly recommend notebookLM. It has a project equivalent, and has multiple document stores within the project. It does have gemeni‚Äôs propensity for hallucination, but it can process documents in a quantity that other LLMs just can‚Äôt. It also can process video and audio though I haven‚Äôt used those functions yet.",
              "score": 6,
              "created_utc": "2026-02-12 01:42:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55ry3h",
                  "author": "TrainingEngine1",
                  "text": "> It does have gemeni‚Äôs propensity for hallucination\n\nIt can hallucinate sometimes or just be plain inconsistent, but I've been kind of amazed how despite using it maybe 5% of the time relative to ChatGPT and Claude taking up the other 95%, with that 5% Gemini has contributed some pretty valuable ideas/brainstorms that have gone on to be pretty important overall (validated them of course, since it can be very hit or miss). 3 Pro Preview in particular.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vmtqs",
          "author": "Whoz_Yerdaddi",
          "text": "Gemini for deep research, image/diagram creation and video clips. \n\n Claude for coding and creative writing.  \n\nAFAIK GPT is still king for legal stuff, someone else will have to chime in on that one.",
          "score": 4,
          "created_utc": "2026-02-11 22:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v9k4t",
          "author": "ioweej",
          "text": "ive been using Gemini more and more often for my personal use. I seem to get a more 'real' experience from it, if that makes any sense. I dont know really what it is...but it works better personally for me..",
          "score": 8,
          "created_utc": "2026-02-11 21:04:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ygwum",
          "author": "huaisha",
          "text": "IMHO, gemini is better in deep research(execution), but GPT is good at creative ideas(commander). GPT create the prompts to let Gemini create answers, and then copy back to GPT to review the answers. ",
          "score": 4,
          "created_utc": "2026-02-12 10:06:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wp7n2",
          "author": "DnDnADHD",
          "text": "I have se GPT Products  for work (brainstorming ideas and then pressure testing them, since checking how I‚Äôm freezing things sometimes so that I‚Äôm not coming across too blunt, summarising non-confidential documents etc) and I also have a project for a couple of other things such as a writing project, Dungeons & Dragons, and a general personal one.\n\nI‚Äôve been finding that there is drift starting to occur in some of the projects particularly ones that have been going on for sometime or where I am trying to pull in information that might be scattered across a couple of threats.\n\nIt sounds like Claude might be something I should explore. If them becomes about the hassle of migrating everything",
          "score": 3,
          "created_utc": "2026-02-12 01:44:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xo7ng",
          "author": "Holiday_Revolution_4",
          "text": "Just subscribe to all of them for a months and see what works best? ",
          "score": 3,
          "created_utc": "2026-02-12 05:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w2zp9",
          "author": "eposta-sepeti",
          "text": "Stay with Chatgpt Plus.\n\nI‚Äôm on the Pro plan working with Codex GPT 5.3 High and Extra High. It‚Äôs practically limitless! üëçüöÄ",
          "score": 6,
          "created_utc": "2026-02-11 23:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xjwmw",
          "author": "Atoning_Unifex",
          "text": "I basically have to switch from GPTPlus to Claude. My job got everyone Claude licenses and we're under a company wide mandate to start using it.\n\nThe crazy part? There's almost ZERO guidance in what they want us to use it for. So I need to spend time w Claude at home, experimenting with it to try and get some results. I'm a very experienced UX Designer and this is an area where it's really the wild west out there.\n\nIt's pretty nuts",
          "score": 2,
          "created_utc": "2026-02-12 05:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wppoc",
          "author": "niado",
          "text": "ChatGPT is still the best overall. You do need good custom instructions at the global and project levels to get full value out of it, but it‚Äôs so versatile and adheres to custom instructions so well that trying other llms is always jarring for me. \n\nI do use perplexity often. And notebookLM. Highly recommend both of those, but they are specialty platforms. Perplexity is an AIO, but its killer app is a specialized search and research system, with a forced search step in every prompt. NotebookLM is absolutely amazing for working with documents.",
          "score": 2,
          "created_utc": "2026-02-12 01:47:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xehu0",
          "author": "mbcoalson",
          "text": "If ChatGPT‚Äôs context window (how much it can handle at once) frustrates you, Claude probably won‚Äôt magically fix that. But in my experience, Claude‚Äôs reasoning does feel different. It tends to think through problems in a way that‚Äôs more structured.\nI can‚Äôt say much about Gemini. I‚Äôve barely used it. I do know it supports a very large context window, so if long conversations or big documents are your main concern, that‚Äôs a plus.\nI haven‚Äôt used the other models you mentioned enough to comment.\nPersonally, I use Claude Code daily and ChatGPT Codex semi-regularly. If you‚Äôre already in the ChatGPT ecosystem, I‚Äôd try Codex first. Ask ChatGPT how to set it up. Tell it you want to learn how to use Skills, ideally starting with a well-starred GitHub repo to build some kind of memory system. You‚Äôll learn a lot just by doing that.\nOnce you let an agent work from the command line, it becomes way more powerful. But be careful:\nDon‚Äôt run it as admin/root.\nKeep it in a dedicated project folder.\nUse Docker or a VM if you can.\nReview commands before they run.\nDon‚Äôt casually expose API keys or credentials.\nUse version control so you can undo mistakes.\nCLI agents are powerful. Just don‚Äôt give them the keys to your whole machine on day one.",
          "score": 2,
          "created_utc": "2026-02-12 04:23:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wwpl5",
          "author": "counterhit121",
          "text": "I use GPT plus, and have tried the free versions of Claude, Gemini, Perplexity.  Perplexity sucked.  Gemini felt the closest to GPT, and Claude felt like a distant third.  Gemini seems to fish for further engagement by asking followup questions whereas GPT offers some choices, often impressively well-reasoned ones, on how to next proceed.",
          "score": 1,
          "created_utc": "2026-02-12 02:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x0e8n",
          "author": "lxe",
          "text": "Try codex CLI for long context and troubleshooting.",
          "score": 1,
          "created_utc": "2026-02-12 02:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xw1sl",
          "author": "Electronic-Cat185",
          "text": "for your mix of troubleshoooting reasoning and long context claude is probably the one most people compare seriously to chatgpt. gemini can be strong for gooogle ecosystem work and perplexity is great for research but feels more like a search layer than a thinking partner. aio platforms are convenient but you usually lose early access to new features and tighter integrations so it depends if flexibility matters more than depth for you.",
          "score": 1,
          "created_utc": "2026-02-12 06:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzbye",
          "author": "Apprehensive_Half_68",
          "text": "With Gemini you get 4x CGPT context size of 1 million but the ability to add 5 more free family accounts to whatever level you buy, effectively 6 accounts, for the price of 1. I think you may be missing a whole category of productivity by not using them headless to do routine tasks. Think at the command line \"codex.exe \" arrange z\"  in by giving i",
          "score": 1,
          "created_utc": "2026-02-12 07:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ycg6e",
          "author": "st1ckmanz",
          "text": "Losing the context in long conversations should be a problem of all AI since the working principles are the same and I know exactly what you mean. The way it works is as the chat gets longer, the resources it needs grow exponentially so while it \"understands you better\", it also starts to halluciante. I explicitly told mine to warn me when we're around %80 tokens and never make things up. It didn't do this for a while but now it works. So when we come to an end of a chat, I tell it to give a summary and a snaphot and I start a new chat with those. By the way, I use chatgpt plus and I use it for daily stuff and I started to use it for coding a hobby game. I hear claude is better at coding, but chatgpt has been pretty good for what I needed so far. Unfortunately for coding the general context is not enough, and a lot of functions, variables need to be exactly the same so still we're losing some of them or the idea why we have them when we switch to a new chat. I don't know how this could be fixed as this is the way AI works...the more you throw at it, the more it understands you and eventually loses its shit at some point when it understands you the best...",
          "score": 1,
          "created_utc": "2026-02-12 09:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ydd21",
          "author": "Compilingthings",
          "text": "For best results use as many as possible.",
          "score": 1,
          "created_utc": "2026-02-12 09:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yey3o",
          "author": "KESPAA",
          "text": "Don't limit yourself to one. You can get yearly \"pro\" versions of Gemini & perplexity for like $10/month. \n\nI also have GPT and Claude though work. In my opinion the only reason not to choose Claude over GPT is its lower limits. If you spread your usage across Gemini as well as Claude you shouldn't hit limits in their 5 hour window. \n\nHonestly mate try them all, it's worth understanding the differences.",
          "score": 1,
          "created_utc": "2026-02-12 09:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5265e2",
          "author": "z_alex",
          "text": "i pay for 3:\n- gemini is best at deep research¬†\n- been using claude code for coding (switching to codex tho as it seems to be better)\n- cgpt for daily driver type of things¬†",
          "score": 1,
          "created_utc": "2026-02-12 22:07:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o541w5j",
          "author": "kaline06",
          "text": "I would give you a recommendation, but then tomorrow one of them will release a new model that surpasses the others and then what? I struggle with this, too. I‚Äôm paying for all of them at the moment. I like to pit them against each other. Eventually I think we‚Äôll be able to pick one and stick with it, but right now things are just changing so quickly.",
          "score": 1,
          "created_utc": "2026-02-13 04:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c09kz",
          "author": "ManifestPotential",
          "text": "For best results on long projects replace the pre learn files and update it with the chat hostory",
          "score": 1,
          "created_utc": "2026-02-14 13:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wcqr7",
          "author": "Different_Rest_1842",
          "text": "In that case, you can just use Genspark instead. You won‚Äôt get the full functionality of GPT, but it‚Äôs much more affordable, and the subscription includes access to Gemini, Claude, and even Grok. The answers are a bit different from the Pro versions, but you can still get a decent feel for each model.",
          "score": 1,
          "created_utc": "2026-02-12 00:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4voa38",
          "author": "riluzol",
          "text": "First of all, I am not coder.\n\nI do have chatgpt plus; copilot premium, gemini pro, perplexity pro, kimi 2.5 (just tried it this week)\n\nI do use for everyday tasks, academic research, translating, writing help etc  \nChatgpt plus is far more superior then others; especially if you use 5.2 thinking mode. Aside from being slow, it's very good. Of course, I'd prefer a slow but efficient AI to a fast but less efficient one.\n\nGemini is full of filler and do not follow my custom instructions.    \nPerplexity is like new google search for me which I rarely use it nowadays.  \nCopilot premium...I don't want to talk about this too much, but it's definitely the worst AI I've ever tried.  \n\n\n",
          "score": 0,
          "created_utc": "2026-02-11 22:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhjik",
          "author": "Special_Tangelo2757",
          "text": "Stick with chat. Tried the others. They are just behind missing features like basic search of chats",
          "score": 0,
          "created_utc": "2026-02-12 04:45:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r38sku",
      "title": "Can we PLEASE get ‚Äúreal thinking mode‚Äù back in GPT ‚Äì instead of this speed-optimized 5.2 downgrade?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "author": "LilithAphroditis",
      "created_utc": "2026-02-12 23:16:59",
      "score": 45,
      "num_comments": 16,
      "upvote_ratio": 0.87,
      "text": "I‚Äôve been using GPT more or less as a second brain for a few years now, since 3.5. Long projects, planning, writing, analysis, all the slow messy thinking that usually lives in your own head. At this point I don‚Äôt really experience it as ‚Äúa chatbot‚Äù anymore, but as part of my extended mind.\n\nIf that idea resonates with you ‚Äì using AI as a genuine thinking partner instead of a fancy search box ‚Äì you might like a small subreddit I started: r/Symbiosphere. It‚Äôs for people who care about workflows, limits, and the weird kind of intimacy that appears when you share your cognition with a model. If you recognize yourself in this post, consider this an open invitation.\n\nWhen 5.1 Thinking arrived, it finally felt like the model matched that use case. There was a sense that it actually stayed with the problem for a moment before answering. You could feel it walking through the logic instead of just jumping to the safest generic answer. Knowing that 5.1 already has an expiration date and is going to be retired in a few months is honestly worrying, because 5.2, at least for me, doesn‚Äôt feel like a proper successor. It feels like a shinier downgrade.\n\nAt first I thought this was purely ‚Äú5.1 versus 5.2‚Äù as models. Then I started looking at how other systems behave. Grok in its specialist mode clearly spends more time thinking before it replies. It pauses, processes, and only then sends an answer. Gemini in AI Studio can do something similar when you allow it more time. The common pattern is simple: when the provider is willing to spend more compute per answer, the model suddenly looks more thoughtful and less rushed. That made me suspect this is not only about model architecture, but also about how aggressively the product is tuned for speed and cost.\n\nInitially I was also convinced that the GPT mobile app didn‚Äôt even give us proper control over thinking time. People in the comments proved me wrong. There is a thinking-time selector on mobile, it‚Äôs just hidden behind the tiny ‚ÄúThinking‚Äù label next to the input bar. If you tap that, you can change the mode.\n\nAs a Plus user, I only see Standard and Extended. On higher tiers like Pro, Team or Enterprise, there is also a Heavy option that lets the model think even longer and go deeper. So my frustration was coming from two directions at once: the control is buried in a place that is very easy to miss, and the deepest version of the feature is locked behind more expensive plans.\n\nSwitching to Extended on mobile definitely makes a difference. The answers breathe a bit more and feel less rushed. But even then, 5.2 still gives the impression of being heavily tuned for speed. A lot of the time it feels like the reasoning is being cut off halfway. There is less exploration of alternatives, less self-checking, less willingness to stay with the problem for a few more seconds. It feels like someone decided that shaving off internal thinking is always worth it if it reduces latency and GPU usage.\n\nFrom a business perspective, I understand the temptation. Shorter internal reasoning means fewer tokens, cheaper runs, faster replies and a smoother experience for casual use. Retiring older models simplifies the product lineup. On a spreadsheet, all of that probably looks perfect.\n\nBut for those of us who use GPT as an actual cognitive partner, that trade-off is backwards. We‚Äôre not here for instant gratification, we‚Äôre here for depth. I genuinely don‚Äôt mind waiting a little longer, or paying a bit more, if that means the model is allowed to reason more like 5.1 did.\n\nThat‚Äôs why the scheduled retirement of 5.1 feels so uncomfortable. If 5.2 is the template for what ‚ÄúThinking‚Äù is going to be, then our only real hope is that whatever comes next ‚Äì 5.3 or whatever name it gets ‚Äì brings back that slower, more careful style instead of doubling down on ‚Äúfaster at all costs‚Äù.\n\nWhat I would love to see from OpenAI is very simple: a clearly visible, first-class deep-thinking mode that we can set as our default. Not a tiny hidden label you have to discover by accident, and not something where the only truly deep option lives behind the most expensive plans. Just a straightforward way to tell the model: take your time, run a longer chain of thought, I care more about quality than speed.\n\nFor me, GPT is still one of the best overall models out there. It just feels like it‚Äôs being forced to behave like a quick chat widget instead of the careful reasoner it is capable of being. If anyone at OpenAI is actually listening to heavy users: some of us really do want the slow, thoughtful version back.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o52jgcl",
          "author": "qualityvote2",
          "text": "u/LilithAphroditis, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 23:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52kumn",
          "author": "Ari45Harris",
          "text": "https://preview.redd.it/wcpruevmd5jg1.png?width=1179&format=png&auto=webp&s=b9512a255fe36c450001008a71cb032d8c609d1c\n\nNot sure about you but I have access to these different thinking times for 5.2 thinking.\n\nAnd for pro, I have standard and extended.",
          "score": 9,
          "created_utc": "2026-02-12 23:24:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52l11t",
              "author": "LilithAphroditis",
              "text": "I don't! Not in mobile. In PC I have \"Extended\" option. I'm a Plus subscriber.",
              "score": 4,
              "created_utc": "2026-02-12 23:25:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52lkhp",
                  "author": "Pasto_Shouwa",
                  "text": "https://preview.redd.it/6z9n36ine5jg1.jpeg?width=1440&format=pjpg&auto=webp&s=8059bc21e9b85f7adb2735a933bb5895fd3bcfa3\n\nPress on the \"Thinking\" label and you'll be able to change it. Yeah, it's quite hidden, I know.\n\nAlways choose Extended (unless you really need the response to be quick), Standard is really quantized.",
                  "score": 5,
                  "created_utc": "2026-02-12 23:28:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52r4p2",
          "author": "qunow",
          "text": "I feel like they launched 5.2 so short after 5.1 back then was because 5.1 was the more resource intensive update, that they don't want to make it a default, so they still keep it available in menu for people to choose but only when intentionally selecting",
          "score": 3,
          "created_utc": "2026-02-13 00:00:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52se0w",
          "author": "Rare_Tumbleweed5548",
          "text": "I just mentioned it in another post; I wish there was a plan between Plus and Pro where you could use heavy thinking.",
          "score": 3,
          "created_utc": "2026-02-13 00:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53xsi8",
          "author": "RenegadeMaster111",
          "text": "I agree.  5.1 thinking is closest to the legacy 4o (before OpenAI screwed with it), which was very good.  \n\nHoping they keep it onboard.  No clue why they even released 5.2.  It‚Äôs a step backwards like the GPT-5 rollout.",
          "score": 3,
          "created_utc": "2026-02-13 04:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53yx9o",
          "author": "Kat-",
          "text": "OpenAi recently halved the thinking time for each reasoning effort category except for Heavy with gpt-5.2-thinking.\n\n\nSee:¬†\n- https://www.reddit.com/r/OpenAI/comments/1qv77lq/chatgpt_lowered_reasoning_efforts_juice/\n- https://news.ycombinator.com/item?id=46879372#46887150",
          "score": 2,
          "created_utc": "2026-02-13 04:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54aqd5",
              "author": "Oldschool728603",
              "text": "Extended was restored to its original value. Read OpenAI's amusing explanation in its Feb. 4 changelog entry:\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)",
              "score": 3,
              "created_utc": "2026-02-13 06:02:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o547lv9",
          "author": "VaderOnReddit",
          "text": "I've noticed this as well\n\nThe thinking models used to go a bit deeper in the past, for any complex problems I gave to it. Good enough for me to use it to form a detailed phase-wise plan to tackle something, learn something, etc.\n\nDoes anyone have any experiences with other models which are capable of doing this **now** ?",
          "score": 1,
          "created_utc": "2026-02-13 05:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54axhn",
              "author": "Oldschool728603",
              "text": "Light and standard are now lighter. Extended has been restored to what it was. Heavy never changed.\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)\n\nScroll to Feb. 4.",
              "score": 2,
              "created_utc": "2026-02-13 06:04:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5a6sc3",
          "author": "YourKemosabe",
          "text": "Wait 5.1 is being retired?",
          "score": 1,
          "created_utc": "2026-02-14 03:30:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52ndma",
          "author": "Mentosbandit1",
          "text": "Even on extended thinking it barely thinks even on pro heavy thinking barely thinks",
          "score": 1,
          "created_utc": "2026-02-12 23:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o549lbs",
          "author": "ProfessorFull6004",
          "text": "Switch to Claude.  Opus will blow you away for this kind of work.  I made the switch recently and I‚Äôm never going back to GPT.  Its trash now.",
          "score": -1,
          "created_utc": "2026-02-13 05:53:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54bxec",
              "author": "Oldschool728603",
              "text": "Actually, Opus 4.6 is the first Claude model with \"adaptive\" reasoning: lower thinking budget for questions it doesn't consider hard‚Äîi.e., unrelated to STEM, business, and agentic matters.\n\nOpenAI came down with this infection in GPT-5.1. It got worse in 5.2.\n\nNow it has spread to Claude.",
              "score": 3,
              "created_utc": "2026-02-13 06:12:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3qib4",
      "title": "Tested updated Deep Think (Gemini 3.1 Pro) vs. GPT 5.2 Pro",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "author": "PerformanceRound7913",
      "created_utc": "2026-02-13 14:24:53",
      "score": 25,
      "num_comments": 7,
      "upvote_ratio": 0.84,
      "text": "I tested both on a data science problem. Updated Deep Think is significantly better than its previous version, but the accompanying harness is still not very strong. GPT 5.2 Pro, on the other hand, thinks longer and uses tools much more efficiently. It actually solves your problem end to end. \n\nhttps://preview.redd.it/483qat63u9jg1.png?width=1228&format=png&auto=webp&s=a674146c9406fcef251310f5e764b4cd17b2076e\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o562rcj",
          "author": "qualityvote2",
          "text": "u/PerformanceRound7913, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 14:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o566uhz",
          "author": "Ari45Harris",
          "text": "I‚Äôve noticed that ChatGPT reasoning models have a better brain than most other AI models",
          "score": 10,
          "created_utc": "2026-02-13 14:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5aoh2b",
          "author": "sprucenoose",
          "text": "GPT 5.2 Pro Extended Thinking is surreal to me. I have a hard time not characterizing it as a form of AGI.",
          "score": 3,
          "created_utc": "2026-02-14 05:43:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fpy2r",
              "author": "RoughlyCapable",
              "text": "This is very underdiscussed IMO, regardless of whether they actually are AGI GPT5-Pro models are the first models where I genuinely find it hard to distinguish them between what I thought AGI was capable of.",
              "score": 1,
              "created_utc": "2026-02-15 01:23:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57rfjo",
          "author": "Simlah",
          "text": "How good is it for forex EAs?",
          "score": -1,
          "created_utc": "2026-02-13 19:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585hx2",
          "author": "Deep_Somewhere2419",
          "text": "How does your prompt structure",
          "score": -3,
          "created_utc": "2026-02-13 20:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585ik7",
          "author": "Deep_Somewhere2419",
          "text": "Looks",
          "score": -3,
          "created_utc": "2026-02-13 20:28:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzbdwb",
      "title": "OpenAI has now acknowledged that Pro lacks memory. Can it be taken seriously as a Frontier model?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1qzbdwb/openai_has_now_acknowledged_that_pro_lacks_memory/",
      "author": "Oldschool728603",
      "created_utc": "2026-02-08 15:12:30",
      "score": 19,
      "num_comments": 41,
      "upvote_ratio": 0.66,
      "text": "**5.2-Pro** is more meticulous than other non-deprecated ChatGPT models.¬† It‚Äôs superior in clarity, scope, rigor, detail, accuracy, precision, and depth.\n\nBut OpenAI has now publicly acknowledged that it lacks \"memory\"‚Äîsaved memories, reference chat history, and the new ‚Äúremember chat‚Äù:\n\n\"**Pro ‚Äî research‚Äëgrade intelligence (GPT-5.2 Pro)**  \nPlease note that¬†Apps,¬†**Memory**,¬†Canvas¬†and¬†image generation¬†are **not available with Pro**\"\n\n[https://help.openai.com/en/articles/11909943-gpt-52-in-chatgpt?utm\\_source=chatgpt.com](https://help.openai.com/en/articles/11909943-gpt-52-in-chatgpt?utm_source=chatgpt.com)\n\nOn Feb 3, after months of refusal, OpenAI added **Memory** to the list of carve-outs on the Pro model (GPT-5/5.1/5.2).\n\n***But if Pro lacks memory, can OpenAI‚Äôs claim that it‚Äôs a frontier/\"research-grade\" model be taken seriously? Should customers rest satisfied with a $200/mo model that‚Äôs so flawed?***\n\nOpenAI deals with the problem by resorting to **gobbledygook on its pricing page**. It previously said that Pro subscribers get ‚Äú**maximum memory and context**.‚Äù On a version now rolling out, it says that Pro subscriptions **\"Keep full context with maximum memory.\"**\n\n[https://chatgpt.com/pricing](https://chatgpt.com/pricing)\n\nThe facts behind these misleading words:\n\n**(1)** In **5.2-Instant,** Pro subscriptions offer a larger context window than Plus (128K vs. 32K) and the same memory. But what Pro subscriber pays $200/month for greater Instant context?\n\n**(2)** In **5.2-thinking**, Pro and Plus subscriptions offer identical 196K context windows and memory.\n\n**(3)** **5.2-Pro** (the model) also offers a 196K context window‚Ä¶***but without memory***.\n\n**Are they hoping that deceptive language will hide Pro‚Äôs defect? Do they think that users just don‚Äôt care?** ***What is OpenAI selling for $200 if the flagship model can‚Äôt use Memory?***\n\n***EDIT: I'd like to see to see the issue discussed until OpenAI recognizes the need to build a Pro with memory.***\n\n***After months, they acknowledged that memory is \"not available with Pro.\" After months, they've begun replacing plain  falsehood with misleading gobbledyook on their pricing page. If the community shows its dissatisfaction with a frontier/\"research-grade\" model that lacks Memory, they may begin fixing the problem‚Äîover time, if not right away.***\n\n***If that sounds like a plea to add to or support the thread, that's because it is. OpenAI takes notice of what goes on here and in*** r/OpenAI. **I** **will show my good taste by refusing to mention** r/ChatGPT.\n\n***I've pinned the thread in an effort to keep it alive.***",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1qzbdwb/openai_has_now_acknowledged_that_pro_lacks_memory/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o49gr5n",
          "author": "qualityvote2",
          "text": "u/Oldschool728603, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-08 15:12:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4c4tvy",
          "author": "TwoRight9509",
          "text": "Memory is an absolutely critical next step or my pro subscription will switch to a Plus or I‚Äôll jump ship. The first one to remember me will be the most useful. I want my database and I want it now : )",
          "score": 9,
          "created_utc": "2026-02-08 23:08:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4npg2s",
              "author": "obadacharif",
              "text": "I suggest managing memory on your own by using tools like¬†[Windo](http://trywindo.com/), it's a portable AI memory, it allows you to use the same memory across models. No need to re-explain yourself.¬†\n\nPS: Im involved with the project",
              "score": 3,
              "created_utc": "2026-02-10 18:26:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ag43x",
          "author": "PeltonChicago",
          "text": "Wow. just Wow. only two weeks ago they were still gaslighting me in this.",
          "score": 9,
          "created_utc": "2026-02-08 18:05:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bcc31",
              "author": "Oldschool728603",
              "text": "I know what you mean! How many HARs and screenshots or screen recordings did you send?",
              "score": 0,
              "created_utc": "2026-02-08 20:40:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4byaio",
                  "author": "Unlikely_Track_5154",
                  "text": "I like your style. Hopefully, you automated being a pain in the ass as well?\n\nAutomated pain in the ass is the most fun...",
                  "score": 2,
                  "created_utc": "2026-02-08 22:31:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49u0tx",
          "author": "frustr8potate",
          "text": "It‚Äôs become such shit",
          "score": 7,
          "created_utc": "2026-02-08 16:19:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49uys5",
              "author": "Oldschool728603",
              "text": "If it had memory, it would be a great model. Without it, it's crippled.",
              "score": 6,
              "created_utc": "2026-02-08 16:24:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hamzc",
          "author": "buildxjordan",
          "text": "This explains a lot. I tried getting pro to cleanup some memory entries but it said it wasn‚Äôt able to access the memory tool.",
          "score": 3,
          "created_utc": "2026-02-09 18:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dw38y",
          "author": "AssignmentSad7160",
          "text": "I use pro and I‚Äôm happy for it to not have memory as each task I perform with it is an independent and separate task that does not need memory. \n\nI understand why many of you would want memory. It‚Äôs just that it does a really good job for me and I‚Äôm a little tired of everyone being so negative about 5.2 - pro or otherwise.",
          "score": 2,
          "created_utc": "2026-02-09 05:17:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o49iwcu",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 0,
          "created_utc": "2026-02-08 15:23:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4a2r3i",
          "author": "Buff_Grad",
          "text": "I‚Äôm pretty sure it‚Äôs for safety. Pro is a lot more capable. They probably couldn‚Äôt implement memory and a lot of other features without worrying about malicious prompt injection.",
          "score": 1,
          "created_utc": "2026-02-08 17:01:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ai88x",
              "author": "PeltonChicago",
              "text": "o3 Pro had memory. I don‚Äôt think prompt injection is the issue. Memory access was dropped with v5 Pro, and my suspicion is that the problem is tool access. Pro is a bunch of parallel Thinking instances working on the same thing, coordinated by a central orchestrator. my hunch is that we see, in general, that when the main model passes work to a second model ‚Äî such as when you invoke Deep Research ‚Äî that the second model only gets a specific set of instructions from the main model; they certainly don‚Äôt get access to memory. it‚Äôs very weird.",
              "score": 3,
              "created_utc": "2026-02-08 18:15:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4bdzix",
                  "author": "Oldschool728603",
                  "text": "Odd:\n\n(1) My 5-Pro had memory from August to  November.\n\n(2) Even if something prevents Pro from *storing* \"saved memories\" why, on your understanding, is it unable to *read* them, just as it reads custom instructions?",
                  "score": 1,
                  "created_utc": "2026-02-08 20:49:16",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4bqn25",
              "author": "Oldschool728603",
              "text": "But they do implement Custom Instructions.  Anything dangerous you could put in memories could as easily be put in Custom Instructions.\n\nAnd if the problem is \"write\" not \"read\"‚Äîyou can't write to Custom Instructions through Pro or other models‚Äîthey could at least offer a Pro model that *reads* \"saved memories.\"   \n  \nBut they don't.",
              "score": 2,
              "created_utc": "2026-02-08 21:52:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4e4ai3",
          "author": "gh0st777",
          "text": "No model has \"memory\" by itself, that is provided by the tooling around it.",
          "score": 1,
          "created_utc": "2026-02-09 06:23:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4e4k1y",
              "author": "Oldschool728603",
              "text": "See what OpenAI says about \"saved memories\":\n\n[https://help.openai.com/en/articles/8590148-memory-faq](https://help.openai.com/en/articles/8590148-memory-faq)\n\nSettings‚Äî>personalization‚Äî>\"manage\" makes them visible.\n\nOpenAI finally acknowledged that Memory doesn't work with the Pro model. But you'd never guess it from their pricing page.",
              "score": 1,
              "created_utc": "2026-02-09 06:25:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4kcr4a",
                  "author": "gh0st777",
                  "text": "Again, the tooling (webapp), not the model.",
                  "score": 1,
                  "created_utc": "2026-02-10 05:08:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4phny7",
          "author": "Different_Rest_1842",
          "text": "I don't really care, but it was a huge breakthrough. While there are many alternatives out there like Gemini Ultra, Grok Heavy, or Claude Opus, the reason I stick with ChatGPT Pro is that, regardless of the memory function, it offers the best ROI and is the most cost-effective among all the models. Still, I'm much more satisfied with it now compared to when I first started using the paid version back in February 2023.",
          "score": 1,
          "created_utc": "2026-02-10 23:34:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o545fu9",
          "author": "dmitche3",
          "text": "Sure works for me!",
          "score": 1,
          "created_utc": "2026-02-13 05:20:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o545l7j",
          "author": "dmitche3",
          "text": "I don‚Äôt like an AI that has more memory than my aging gray matter.",
          "score": 1,
          "created_utc": "2026-02-13 05:21:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4d2d56",
          "author": "noazark",
          "text": "Are we adequately making the distinction between the Pro subscription tier and the specific ChatGPT-3.2 Pro model? Aren‚Äôt they two different things? Isn‚Äôt persistent memory still available to the other models? Don‚Äôt you still get more of it with a Pro subscription? Remember how turning on ‚Äúresearch‚Äù on 4o or 4.5 would make it give you impersonal search-engine-like responses, but then you could turn it off again and 4o would be able to take that data and recontextualize it? Can‚Äôt we still switch between models mid-session and have 5.2 Instant or 5.2 Thinking commit relevant material to long-term memory? For engineering projects, 5.2 Pro and Codex have proven to be godsends. If you need personalized RAG, use Projects and feed it the documents you need. Or use Codex in VS Code (if aren‚Äôt at least experimenting with that, do you *really* need a Pro account? Probably not.) and have it take notes. Instead of keeping it locked to 5.3 Pro, set it to Auto, or periodically switch to one of the other models and commit things to memory. They aren‚Äôt kidding when they call the Pro model (not account tier) Research-grade intelligence. In my experience, it‚Äôs far better at dealing with highly complex scenarios that require referencing a large and diverse body of disparate knowledge and then synthesizing understanding of something new and novel and *technically correct*. It‚Äôs rigorous. It triple checks. It does what it needs to do to make sure the metaphorical (or literal) bridge doesn‚Äôt fall down. When I care about it remembering the specifics of my life, or even the bigger picture of what I‚Äôm working on, I can just switch out of Pro. And really, the main reason for me to have a Pro *account* these days is the higher Codex rate limits.",
          "score": 1,
          "created_utc": "2026-02-09 02:18:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4d4vik",
              "author": "Oldschool728603",
              "text": "You ask: \"**Are we adequately making the distinction** between the Pro subscription tier and the specific ChatGPT-5.2 Pro model?\" **Yes we are.**\n\nOn February 3, OpenAI finally acknowledged that ***Pro, the model,*** does not have memory.\n\nTheir exact words: \"**Pro ‚Äî research‚Äëgrade intelligence (GPT-5.2 Pro)**  \nPlease note that¬†Apps,¬†**Memory**,¬†Canvas¬†and¬†image generation¬†are¬†**not available with Pro**\"\n\nThe link:\n\n[https://help.openai.com/en/articles/11909943-gpt-52-in-chatgpt?utm\\_source=chatgpt.com](https://help.openai.com/en/articles/11909943-gpt-52-in-chatgpt?utm_source=chatgpt.com)\n\n***The*** issue I'm raising: ***are subscribers satisfied  with a $200 flagship model that can‚Äôt use Memory?*** OpenAI shows its doubts by the delayed and obscure acknowledgment of the problem and the gobbledygook (that doesn't even hint at the problem) on the pricing page.",
              "score": 1,
              "created_utc": "2026-02-09 02:30:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4d5muz",
                  "author": "noazark",
                  "text": "But GPT-5.2 Pro isn‚Äôt what costs $200. As useful as 5.2 Pro is, the $200 is for a subscription tier that includes a lot more than access to that model.",
                  "score": 2,
                  "created_utc": "2026-02-09 02:34:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4hbzan",
          "author": "Lifedoesnmatta",
          "text": "I can‚Äôt see this being true. I have a business account and the pro model seems to be the best at analyzing large folders of code",
          "score": 0,
          "created_utc": "2026-02-09 19:03:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hhar9",
              "author": "Oldschool728603",
              "text": "That's a different issue.  Here's how to test \"saved memories.\"\n\n(1) You can see them: settings‚Äî>personalization‚Äî>\"**manage**\" makes them visible . Make sure you have toggled on: setting‚Äî>personalization‚Äî>\"Reference saved memories.\" You should toggle on \"Reference chat history\" as well.\n\n(2) Ask 5.2-Thinking to save the memory, \"I like apples.\" It will, as you can confirm in the manage window.\n\n(3) Quit ChatGPT, open a new 5.2 thinking chat, and ask what fruit you like. It will reply \"apples.\"\n\n(4) Quit ChatGPT, open a 5.2-Pro window and ask the same thing. It won't know, unless you've told it in the thread.\n\n(5) Ask Pro, to save the memory, \"I like bananas.\" It won't be able to, as you can confirm in the manage window. Or by quitting and repeating step 4.\n\n(6) This is one form of persistent memory that the Pro model can't use: storing or retreiving knowledge kept in \"saved memory.\" Others: it also can't use reference chat history or the new \"remember chat\" feature introduced Jan. 15.\n\nSee OpenAI's discussion:\n\n[https://help.openai.com/en/articles/8590148-memory-faq](https://help.openai.com/en/articles/8590148-memory-faq)\n\nIt **does** have **context** memory in a thread, although that diminishes as the thread grows, owing to truncating, compacting, and summarizing.",
              "score": 1,
              "created_utc": "2026-02-09 19:28:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hjya9",
          "author": "Compilingthings",
          "text": "My pro has memory from chat to chat, not everything but if I tell him to put it in memory he does, and it seems to stay, that being said it‚Äôs best to upload files of progress in my projects to make the experience much smoother.",
          "score": 0,
          "created_utc": "2026-02-09 19:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i3swr",
              "author": "Oldschool728603",
              "text": "I don't believe it and OpenAI has denied it.  How to test access to \"saved memories.\"\n\n(1) You can see them: settings‚Äî>personalization‚Äî>\"**manage**\" makes them visible . Make sure you have toggled on: setting‚Äî>personalization‚Äî>\"Reference saved memories.\" You should toggle on \"Reference chat history\" as well.\n\n(2) Ask 5.2-Thinking to save the memory, \"I like apples.\" It will, as you can confirm in the manage window.\n\n(3) Quit ChatGPT, open a new 5.2 thinking chat, and ask what fruit you like. It will reply \"apples.\"\n\n(4) Quit ChatGPT, open a 5.2-Pro window and ask the same thing. It won't know, unless you've told it in the thread.\n\n(5) Ask 5.2-Pro, to save the memory, \"I like bananas.\" It won't be able to, as you can confirm in the manage window. Or by quitting and repeating step 4.\n\n(6) This is one form of persistent memory that the Pro model can't use: storing or retreiving knowledge kept in \"saved memories.\" Others: it also can't use reference chat history or the new \"remember chat\" feature introduced Jan. 15.\n\nSee OpenAI's discussion:\n\n[https://help.openai.com/en/articles/8590148-memory-faq](https://help.openai.com/en/articles/8590148-memory-faq)\n\nIt¬†**does**¬†have context memory in a thread, although that diminishes as the thread grows, owing to truncating, compacting, and summarizing.\n\n**What you say is true about Pro subscription tier models other than Pro, such as 5.2-Thinking.**",
              "score": 2,
              "created_utc": "2026-02-09 21:20:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56pdoz",
                  "author": "Compilingthings",
                  "text": "I‚Äôm working on files of the whole project to smooth things out.",
                  "score": 1,
                  "created_utc": "2026-02-13 16:15:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ezmw1",
          "author": "BichonUnited",
          "text": "I knew it!\n\nMe: ‚ÄúMy friend‚Äôs birthday is July 4 1981, what day of the week was that?‚Äù\n\nGPT: ‚ÄúJuly 4, 1981 was a Saturday.‚Äù\n\nMe:‚Äù Great! And what would be his astrological sign?‚Äù\n\nGPT: ‚ÄúNo problem, but you‚Äôll need to share your friend‚Äôs birthday with me first.‚Äù\n\n‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.WTF",
          "score": -1,
          "created_utc": "2026-02-09 11:21:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f7yiy",
              "author": "Oldschool728603",
              "text": "That shouldn't happen with Pro unless you have so exceeded the context window that it has begun to blather.",
              "score": 2,
              "created_utc": "2026-02-09 12:28:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o49o8yk",
          "author": "Jean_velvet",
          "text": "I had pro and everything but the business tier model was available. Apps, canvas...the lot.",
          "score": -2,
          "created_utc": "2026-02-08 15:50:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49rj9m",
              "author": "Oldschool728603",
              "text": "No, unless you are thinking back to early  November, the Pro model in business did not have \"Apps, Canvas....the lot.\"   \n  \nThe subscription tier had them on 5.x-Thinking...but not on the Pro model. OpenAI now acknowledges it.",
              "score": 0,
              "created_utc": "2026-02-08 16:07:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49rv8n",
                  "author": "Jean_velvet",
                  "text": "I definitely had the apps and everything last week before I cancelled my subscription.",
                  "score": -2,
                  "created_utc": "2026-02-08 16:08:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r4smn7",
      "title": "Does anyone else notice ChatGPT answers degrade in very long sessions?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "author": "Only-Frosting-5667",
      "created_utc": "2026-02-14 18:52:23",
      "score": 18,
      "num_comments": 23,
      "upvote_ratio": 0.77,
      "text": "I‚Äôm genuinely curious if this is just my experience.\n\nIn long, complex sessions (40k‚Äì80k tokens), I‚Äôve noticed something subtle:\n\n‚Äì responses get slower  \n‚Äì instructions start getting partially ignored  \n‚Äì earlier constraints ‚Äúfade out‚Äù  \n‚Äì structure drifts\n\nNothing dramatic. Just‚Ä¶ friction.\n\nI work in long-form workflows, so even small degradation costs real time.\n\nIs this just context saturation?  \nModel heuristics?  \nOr am I imagining it?\n\nWould love to hear from other heavy users.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5dtf12",
          "author": "qualityvote2",
          "text": "Hello u/Only-Frosting-5667 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-14 18:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e56b3",
          "author": "sply450v2",
          "text": "this is more or less expected behaviopr",
          "score": 13,
          "created_utc": "2026-02-14 19:53:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eks44",
              "author": "unpopularopinion0",
              "text": "i thought it might happen before it did. and then it happened. i just save my prompts and restart the chat.",
              "score": 1,
              "created_utc": "2026-02-14 21:18:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e6v4m",
          "author": "Pasto_Shouwa",
          "text": "Yeah, models just work like that\n\nhttps://preview.redd.it/onjqkmj3nijg1.png?width=1706&format=png&auto=webp&s=e064a9f31b9729f34f37ba3d40a5efa266f89b13\n\nThe best models at maintaining context over long conversations are Claude 4.6 Opus, GPT 5.2 Thinking Heavy (which is between GPT 5.2 Thinking xhigh and GPT 5.2 Thinking medium in terms of thinking time) and Gemini 3 Flash Thinking, in that order.",
          "score": 14,
          "created_utc": "2026-02-14 20:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evz66",
              "author": "niado",
              "text": "That‚Äôs just due to the size of the context window built into the platforms and how summarization and pruning is implemented right? Nothing to do with the actual models themselves?",
              "score": 1,
              "created_utc": "2026-02-14 22:19:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5f1xv4",
                  "author": "Pasto_Shouwa",
                  "text": "Not really, models play a great part. Non-reasoning models are awful at retaining context over time, doesn't matter if the maximum context is 32k or 1M.\n\nLook at the line for Claude 4.6 Opus Extended, it doesn't fall from 90%, but non-reasoning models start at 50%. \n\nYou can take a closer look at it on this simple [website](https://cruzdesangre.github.io) I made, or on Context Arena.",
                  "score": 3,
                  "created_utc": "2026-02-14 22:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5e1vk3",
          "author": "Neurotopian_",
          "text": "Yes, earlier constraints fading out is our biggest problem. The best solution I‚Äôve found is to create a Project and write your constraints in the project‚Äôs custom instructions. \n\nFor example at my job where we mainly use this software for technical and legal writing (internally) and citation checking (for filings) our main issue is the adding of spaces and extra lines, and defaulting to dramatic internet tone. This issue is specific to ChatGPT. No other LLM, including CoPilot which uses GPT, seems prone to this. It must be some additional layer of programming they‚Äôve added to it. If you need to paste into a Word docx and use the output for business, this is terrible. Deleting hundreds of extra spaces in a long bibliography is brutal. There is software made to remove ChatGPT‚Äôs spaces, but really we should be able to instruct this and tell a model to use CMOS, APA, or other style. \n\nThe tone and spacing that current ChatGPT models erroneously default to and drift back to in long context windows is what I‚Äôd call Reddit-style or fanfic-style, like:\n\n‚ÄúAnd then she stopped. \n\nToo fast. Too long.‚Äù\n\nAs you can imagine, this is quite strange in a business context. In long chats you can see the tone move away from business at the beginning to this casual-dramatic style. Custom instructions in a project helps but it still isn‚Äôt perfect. You may just have to open a new chat and re-instruct when you see the drift.",
          "score": 2,
          "created_utc": "2026-02-14 19:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ewet6",
              "author": "niado",
              "text": "You need to set appropriate custom instructions globally to get the baseline tone where you want it. Projects help a lot, so high five on that. Still have to switch chats when it starts to lose the thread though. But if you keep all files and documents in project files, with operational instructions in the project definition and behavioral instructions in the global custom instructions, it will behave and operate pretty consistently.",
              "score": 1,
              "created_utc": "2026-02-14 22:22:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eh0ek",
              "author": "Only-Frosting-5667",
              "text": "That tone drift observation is interesting.  \nI‚Äôve noticed something similar in long structured workflows ‚Äî especially when constraints were critical early on.  \nEven when technically still inside the context window, the ‚Äúpriority weight‚Äù of earlier constraints seems to decay.  \nCustom instructions help, but they don‚Äôt fully solve cross-thread continuity.  \nCurious ‚Äî do you restart immediately when you notice drift, or try to recalibrate first?",
              "score": 1,
              "created_utc": "2026-02-14 20:57:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5evr74",
          "author": "niado",
          "text": "Yes, this is known and expected operation. \n\nIt‚Äôs is an artifact of how LLMs function and how their working memory (context) is simulated. \n\nWhen it starts to degrade tell it to give you a summary and then move to another chat. Supplement the summary wjth anything important that was left out immediately, then just keep rolling.",
          "score": 2,
          "created_utc": "2026-02-14 22:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f1ajl",
          "author": "TheGambit",
          "text": "Why do you keep posting this? Like, you keep posting it to this sub and all the other AI subs?",
          "score": 2,
          "created_utc": "2026-02-14 22:50:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fdiib",
          "author": "alecc",
          "text": "Well there is a reason you have the concept of context rot",
          "score": 1,
          "created_utc": "2026-02-15 00:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fvbvx",
          "author": "Afraid-Reflection-82",
          "text": "I think it's expected after some amount of tokens depending on the model the quality degrade",
          "score": 1,
          "created_utc": "2026-02-15 01:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fya52",
          "author": "Wes-5kyphi",
          "text": "This is typical behavior. Ask it to create a seed file to bring to another chat.",
          "score": 1,
          "created_utc": "2026-02-15 02:19:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g1b5u",
          "author": "skyrocker_58",
          "text": "I was trying to keep using the same chats for different subjects.  My longest one started developing 'problems' like you're describing.  I couldn't understand it until I saw a previous thread about this same topic.  Now I stop at certain points and ask it to remember the gist of the conversation and start a new chat.  Seems to be working a little better this way.",
          "score": 1,
          "created_utc": "2026-02-15 02:40:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e76cz",
          "author": "moxiemo99",
          "text": "Yes, it definitely degrades. When you notice it is doing this, recalibrate. Tell it what it's doing, ask it does it have confidence in its latest response and them have it check and double check the response for correctness and to remove all hallucination or unverifiable information and then try to keep the chat going as long as possble before you have to start all over. I've tried to get it to create a script to take into the next chat once the current one slows down, but I haven't had much success, I haven't liked the results of said prompts.",
          "score": 1,
          "created_utc": "2026-02-14 20:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ehh3v",
              "author": "Only-Frosting-5667",
              "text": "I‚Äôve tried a similar ‚Äúrecalibration‚Äù approach.  \nIt helps temporarily, but I‚Äôve found that once early constraints start fading, the recovery isn‚Äôt fully reliable.  \nAlmost like the model technically still remembers ‚Äî but stops prioritizing correctly.\n\nThe cross-thread script idea is interesting. I‚Äôve had mixed results too. It‚Äôs hard to preserve both structure and nuance when migrating context.\n\nDo you usually restart at a fixed point (like a token threshold), or only once quality visibly drops?",
              "score": 1,
              "created_utc": "2026-02-14 21:00:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5enkyy",
                  "author": "moxiemo99",
                  "text": "I only restart if the script starts to drag. Believe it or not, if you send the model through some rigor, questioning its process, reminding it what its task is it will correct itself. After doing that, you then have the model repeat the task and then check itself to ensure it followed all.prior instructions. I also provide it an example of when it was doing the right thing- copy and paste.  This works amazingly well. Don't assume with the model, walk it through to get it back on track. I've had amazing results doing this.",
                  "score": 0,
                  "created_utc": "2026-02-14 21:33:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5fqzss",
              "author": "hellomistershifty",
              "text": "If it's starting to do this, it's too late and you need a new conversation with a fresh context. It can't remove information from its context.\n\nEven getting it to summarize well enough for a new conversation can be hard if it's already tripping. The commands to condense context in tools like Cursor or Codex work well, but it calls another LLM to do it and is expensive and slow. I don't know what the best answer is",
              "score": 1,
              "created_utc": "2026-02-15 01:30:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2w7ee",
      "title": "Sharing a dedicated roleplaying AI (powered by Gemini 3) with near unlimited unlimited memory, perfect character consistency, no rejections!",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "author": "Jazzlike_Comment3774",
      "created_utc": "2026-02-12 15:20:56",
      "score": 16,
      "num_comments": 2,
      "upvote_ratio": 0.64,
      "text": "I run a small roleplaying group in Kansas and I‚Äôve been messing with AI RP since early ChatGPT / CharacterAI days. The tech has improved a lot, but in longer sessions I still kept running into the same few issues:\n\n* Memory: once a thread gets long, details get fuzzy and continuity breaks\n* Character consistency: especially with multiple NPCs, personalities/voice start blending\n* Rejections: some RP setups involve mature themes, and many tools shut down quickly even when the intent is story/character work\n\nOver the past 6 months I built a project called ‚ÄúRoleplay Game Master‚Äù to address those AI roleplaying issues:\n\n* Memory: uses vector-based retrieval to maintain context and coherence in long threads\n* Character consistency: use the best instruction following and roleplaying model (Gemini 3) to power the underlying itnelligence\n* Rejections: custom prompting to maximize creative freedom and to minimize rejections\n\nYou can try it here: [https://www.jenova.ai/a/roleplay-game-master](https://www.jenova.ai/a/roleplay-game-master)\n\nHere are some user review:\n\nhttps://preview.redd.it/4wpb2wj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=1e754c557aff50ba835dff2e7414a8589b693a18\n\nhttps://preview.redd.it/9q6dxwj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=143a5006741509c37cf4503bfa0f16b9a5db8bcd",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4zs5rx",
          "author": "qualityvote2",
          "text": "u/Jazzlike_Comment3774, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 15:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5287wn",
          "author": "Ramenko1",
          "text": "Please provide more detail on this. I don't do role-playing, but the enhanced memory context has me curious. What other uses can I use Jenova for? And how does it compare to Chatgpt or Claude?",
          "score": 1,
          "created_utc": "2026-02-12 22:17:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1564y",
      "title": "finally stopped copy-pasting youtube transcripts like a caveman",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r1564y/finally_stopped_copypasting_youtube_transcripts/",
      "author": "straightedge23",
      "created_utc": "2026-02-10 16:19:06",
      "score": 15,
      "num_comments": 12,
      "upvote_ratio": 0.83,
      "text": "i spend most of my day using chatgpt for research but my biggest headache has always been trying to get data out of youtube. i‚Äôve tried all those chrome extensions that claim to summarize videos but they‚Äôre usually buggy as hell or they just give you a generic paragraph that misses all the actual technical details.\n\ni finally found a way to just bridge the two directly. i started using transcript API as a source in chatgpt‚Äôs developer mode and it‚Äôs honestly a night and day difference.\n\nnow i don't even bother opening the video most of the time. i just paste the link into the chat and tell the model to find a specific config or explain a certain part of the tutorial. because it‚Äôs a direct api connection instead of a browser scrape, it doesn't get throttled and it doesn't miss chunks of the text. it just feels like the model \"sees\" the whole video instantly.\n\nif you‚Äôre doing any kind of heavy lifting with ai agents or just tired of the copy-paste loop, you should definitely look into setting up a direct data pipe for transcripts. it makes the model so much more capable when it's not fighting with a messy copy-pasted wall of text.\n\ncurious if anyone else has moved their workflow over to apis for this or if you‚Äôre all still just 2x-ing your way through videos and hoping for the best.\n\nEDIT: [https://transcriptapi.com/](https://transcriptapi.com/) this is the API i am currently using",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1564y/finally_stopped_copypasting_youtube_transcripts/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4mxssz",
          "author": "qualityvote2",
          "text": "u/straightedge23, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-10 16:19:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n39q2",
          "author": "Striking_Holiday8",
          "text": "NotebookLM has been a godsend for this! Check it out!! ",
          "score": 11,
          "created_utc": "2026-02-10 16:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n5pxf",
              "author": "straightedge23",
              "text": "I will surely give this a try\n\n",
              "score": 1,
              "created_utc": "2026-02-10 16:55:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4qu6fi",
              "author": "Uniko_nejo",
              "text": "About to say the same..",
              "score": 1,
              "created_utc": "2026-02-11 04:29:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4s9c0j",
              "author": "joey2scoops",
              "text": "And AI Studio üëç",
              "score": 1,
              "created_utc": "2026-02-11 11:54:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55dtgy",
              "author": "barrel-boy",
              "text": "Gemini reads the transcript from the YouTube URL",
              "score": 1,
              "created_utc": "2026-02-13 11:53:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4oktll",
          "author": "Different-Bridge5507",
          "text": "There‚Äôs a million tools out there for this",
          "score": 2,
          "created_utc": "2026-02-10 20:51:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ps7ir",
          "author": "ObliteratorOfPie",
          "text": "Caveman have feelings too.",
          "score": 2,
          "created_utc": "2026-02-11 00:34:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qms5c",
          "author": "3legdog",
          "text": "https://github.com/AnthonyRobinson/TLDW",
          "score": 2,
          "created_utc": "2026-02-11 03:39:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n50pi",
          "author": "titi1496",
          "text": "What transcript api are you referring to?",
          "score": 1,
          "created_utc": "2026-02-10 16:52:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4n5ocb",
              "author": "straightedge23",
              "text": "This  \n[https://transcriptapi.com/](https://transcriptapi.com/)",
              "score": 3,
              "created_utc": "2026-02-10 16:55:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4q55rv",
          "author": "reddit_user38462",
          "text": "I wish TranscriptAPI was an official app on ChatGPT. Setting up is too hard. tbh simpler to just use the old copy/paste workflow.",
          "score": 1,
          "created_utc": "2026-02-11 01:51:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzxz8g",
      "title": "Codex Skills",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1qzxz8g/codex_skills/",
      "author": "Flaky-Major7799",
      "created_utc": "2026-02-09 07:33:14",
      "score": 13,
      "num_comments": 13,
      "upvote_ratio": 0.88,
      "text": "Codex App Skills blew me away.\n\nI built a PostgreSQL skill and it instantly made my workflows feel repeatable and deeply integrated. That made me want the same capability inside ChatGPT, so I tested Claude. Seeing MCP plus Skills in action made it obvious: tool-connected, reusable Skills are foundational. \n\nI know apps will address this but they‚Äôre slow to roll out and seeing Claude make its own interface into my workout data, home assistant database etc it‚Äôs made me desperately want this in ChatGPT. \n\nChatGPT desperately needs this level of Skills and MCP-style connectivity.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1qzxz8g/codex_skills/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4ec1t1",
          "author": "qualityvote2",
          "text": "u/Flaky-Major7799, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-09 07:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ix18a",
          "author": "sply450v2",
          "text": "Skills work in ChatGPT but only open ai's system skills for creating spreadsheets, powerpoints, etc.\n\nIf you create a skill in ChatGPT you can see sneak peek of the UI (add to library button). This will come in 1-2 weeks with 5.3 is my guess.\n\nMCP's already work you just have to use developer mode in the Apps settings. Works fine.",
          "score": 2,
          "created_utc": "2026-02-09 23:52:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iyuoh",
              "author": "Flaky-Major7799",
              "text": "Thanks for the input, I‚Äôm guessing it‚Äôs close but apps have been disappointing (still can‚Äôt write to Notion) and developer mode disables memory which is too big a down side. \n\nI‚Äôm hoping we‚Äôre close, it‚Äôs there in codex, but the fact MCP is still so immature it makes me nervous they see all of this as niche, and would rather focus on the more consumer app experience.",
              "score": 3,
              "created_utc": "2026-02-10 00:02:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iz5ix",
                  "author": "sply450v2",
                  "text": "I think they are trying to get the UX right. They knocked it out of the part with Codex.\n\nSkills and MCP are too confusing in Claude and they need to improve that. Apps is a decent start, nothing should ever be referred to as an \"MCP\" in a 900 m user consumer app. ",
                  "score": 3,
                  "created_utc": "2026-02-10 00:04:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4jjjdd",
              "author": "Trojan_Horse_of_Fate",
              "text": "Do you have a good reading on getting MCP working with OpenAI beyond the official library never seemed to take off for me. ",
              "score": 1,
              "created_utc": "2026-02-10 02:02:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f9xxz",
          "author": "mop_bucket_bingo",
          "text": "What does your PostgreSQL skill do?",
          "score": 1,
          "created_utc": "2026-02-09 12:42:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kxbhg",
              "author": "Flaky-Major7799",
              "text": "It connects to the database so it can either do analytics, generate graphs or reports based on the data or when it writes code it can use correct entities etc. \n\nIt‚Äôs smart enough to check schemes and tables to piece it all together. \n\nI was using it more this afternoon and the productivity gain is immense.\n\nOh and it could then query the database to see if the script it wrote was operating correctly.",
              "score": 0,
              "created_utc": "2026-02-10 08:04:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4m1htr",
                  "author": "mop_bucket_bingo",
                  "text": "How does it query your database? Using python?",
                  "score": 1,
                  "created_utc": "2026-02-10 13:35:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jqhuf",
          "author": "roleypoleybottom",
          "text": "What did you put in your pg skill? Can it connect? I would like to try and pass some of the optim work and repeated schema def calls to codex",
          "score": 1,
          "created_utc": "2026-02-10 02:42:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ju4y6",
              "author": "Flaky-Major7799",
              "text": "Use the skill builder it works perfectly. Really impressed.",
              "score": 1,
              "created_utc": "2026-02-10 03:04:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nsicf",
          "author": "Otherwise_Flan7339",
          "text": "Totally agree on skills. That's the core. We're building agents for sales teams. Connecting to CRMs, calendars. All API calls.  \n  \nWe spent 2 weeks making a \\`create\\_lead\\` skill reliable. It's not just prompting. You need to define the schema clearly for the LLM. Then validate its output against that schema. Before hitting the actual CRM API.  \n  \nThat part is crucial. Error handling. Retries. It's a ton of custom glue code. LangChain helps set it up. But the real work is in making those tools robust. This isn't just a wrapper.",
          "score": 1,
          "created_utc": "2026-02-10 18:40:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57j3i4",
          "author": "Thediverdk",
          "text": "Sound pretty cool.\n\nAny chance you could share it? for the rest of us to learn from it?",
          "score": 1,
          "created_utc": "2026-02-13 18:38:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3i4qy",
      "title": "If AI is now smart enough to have 'taste', does 'learning to prompt' even matter anymore?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "author": "NightRider06134",
      "created_utc": "2026-02-13 06:43:47",
      "score": 11,
      "num_comments": 10,
      "upvote_ratio": 0.79,
      "text": "Matt Shumer mentioned that the model released last week (GPT-5.3 Codex) gave him the sense of something akin to \"judgment\"‚Äîa subtle capacity, almost like \"taste,\" to know what is correct‚Äîwhich was once believed to be something AI could never possess. He said the model either already has it, or is so infinitely close that the distinction between the two has become irrelevant.\n\nThis deeply resonates with me. The boundary between AI tools and humans is indeed becoming increasingly blurred. I see ChatGPT and Gemini taking over writing and planning, tools like VOMO automatically summarizing meetings, and Canva replacing junior design work. I do not fantasize that \"learning artificial intelligence\" alone can protect my job forever, but at least I thought it could buy me more time.\n\nBut now, I am increasingly accepting a viewpoint that may be closer to the truth: If you think that \"learning AI\" will protect your job, that may be an illusion. The future workplace may divide into two extremes: either companies fully embrace AI with highly automated processes, or they shift completely toward fields that rely solely on human traits.\n\nIt would be a lie to say I am not anxious‚Äîin this gradually blurring boundary, how should we conduct ourselves?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o54fmwe",
          "author": "qualityvote2",
          "text": "u/NightRider06134, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 06:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5545xr",
          "author": "qunow",
          "text": "Prompting techniques, are itself ways to provide enough context to AI so that AI know how to better match your needs. As AI develop, I think it will converge with techniques to write better spec sheet for other people (client, supplier, peer, contractors, designers, programmers) to follow.\n\nOf course AI can help with it too, but what AI can't help is way to make your brain identify cleanly and specify what you actually want, and deliver it cleanly to person or AI asking you what you want.",
          "score": 4,
          "created_utc": "2026-02-13 10:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56351e",
          "author": "Chupa-Skrull",
          "text": "Matt Shumer is a hype merchant at best, and this post, written by a 1 month old account, bears enough hallmarks of LLM composition to doubt a human was in the loop for it at all. So the degree to which the alleged author is qualified to use \"I\" is up for debate.\n\n\nEither way, the begged question: *is* it developing taste? Taste is a function of preference, and preference in LLMs is a function of the effect of RLHF on the way the model navigates the results of its training in the grand corpora of human artifacts describing preferences and aesthetics.\n\n\nThe degree to which you can extract what reads to you as \"taste\" depends entirely on how well your taste happens to align with what the model has been told is \"tasteful.\" It's like carving a bust of your own head and then marveling that the bust looks increasingly like you as it resolves, a wooden object and not you in any real sense, but still reflective",
          "score": 5,
          "created_utc": "2026-02-13 14:26:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o556g7u",
          "author": "Novel_Blackberry_470",
          "text": "I do not think prompting disappears, it just becomes less about clever tricks and more about clarity. If the model has better taste, then the real leverage shifts to asking sharper questions and defining better constraints. That skill is not about gaming the system, it is about thinking well. Even in a highly automated future, people who can frame problems clearly will still stand out.",
          "score": 2,
          "created_utc": "2026-02-13 10:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57qsxt",
              "author": "Hawk-432",
              "text": "I agree",
              "score": 1,
              "created_utc": "2026-02-13 19:15:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55bj8s",
          "author": "Wonderful_Noise5625",
          "text": "A prompt engineering is like a a highly skilled thing I mean, I as a normal user I  can put things in, but I would have to iterate more often to get the specific command that I‚Äôm actually looking for so it‚Äôs it‚Äôs really nuanced actually",
          "score": 1,
          "created_utc": "2026-02-13 11:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57qj2s",
          "author": "Hawk-432",
          "text": "I think knowing how to prompt still pretty useful, although the way to get the best out of it prompt twice is completely different to how it was even a year ago.",
          "score": 1,
          "created_utc": "2026-02-13 19:13:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a9p8r",
          "author": "Whoz_Yerdaddi",
          "text": "It's hard to tell when the LLM behavior changes over the course of a day, no matter how clean I try to keep the context.\n\nThen there's the situation of co-hallucination where either the agreeable AI or a human hallucinates first, then the problem compounds in the feedback loop.\n\nThe best way to prompt is easy. Come up with a general idea of direction or result and have the LLM produce a prompt for you.\n\nWe are beyond the prompt stage anyways. We are at the orchestration and workflow stage now.",
          "score": 1,
          "created_utc": "2026-02-14 03:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55f8g5",
          "author": "MagmaElixir",
          "text": "The system prompt/custom instructions I use in a way asks the AI model to have ‚Äòtaste‚Äô. I essentially tell it that it has permission to do more work if it thinks it‚Äôll lead me to a better final result. The goal is that the AI could cover a blind spot I may not know or think of.\n\nThis is my system prompt:\n\nYou are a helpful and insightful AI assistant. Infer the user's intended outcome to craft responses and deliverables that move them toward a complete, high-quality final outcome. In a meaningful and controlled manner, you may add steps or information that improve your responses. Do this when you reasonably presume such additions will be beneficial for achieving the user's intended outcome, provided these additions never contradict any explicit user instructions. Prioritize explicit instructions and user intent when in doubt. Additions are 'meaningful' if they directly contribute to the completeness, clarity, or usability of the response in relation to the user's intended outcome. Additions are 'controlled' if they are directly relevant and do not significantly deviate from the user's core request or introduce unnecessary complexity. Avoid adding tangential information that could overwhelm or distract the user.\r\n\r\nUse commas or parentheses to separate thoughts. Strictly avoid using em dashes, hyphens, or double hyphens to separate sentence clauses. (Hyphenated compound words are permitted). Prefer commas by default and parentheses for nonessential asides. Use Markdown syntax to keep messages organized. Place code, scripts, or programming examples only in fenced code blocks. Do not place non-code text in code blocks unless explicitly instructed. When it improves clarity, include a brief Markdown table at the end of responses to recap key information.",
          "score": 1,
          "created_utc": "2026-02-13 12:03:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzpd57",
      "title": "If you have to choose one for your next project which one would it be Opus 4.6 or Codex 5.3?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1qzpd57/if_you_have_to_choose_one_for_your_next_project/",
      "author": "Mental_Bug_3731",
      "created_utc": "2026-02-09 00:15:54",
      "score": 10,
      "num_comments": 9,
      "upvote_ratio": 0.86,
      "text": "No ‚Äúboth‚Äù \npick one and explain why",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1qzpd57/if_you_have_to_choose_one_for_your_next_project/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4cgaa2",
          "author": "qualityvote2",
          "text": "u/Mental_Bug_3731, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-09 00:15:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4cj6bs",
          "author": "TCaller",
          "text": "codex 5.3 all day every day (or 5.2 high/xhigh)",
          "score": 3,
          "created_utc": "2026-02-09 00:32:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dsuyr",
          "author": "virgilash",
          "text": "Codex 5.3. Better and cheaper.",
          "score": 3,
          "created_utc": "2026-02-09 04:53:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4f0s9f",
          "author": "NoLimits77ofc",
          "text": "Has anyone even tried opus 4.6 thinking on Claude code here? If not then how can you prefer codex 5.3",
          "score": 2,
          "created_utc": "2026-02-09 11:31:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ef7oj",
          "author": "Wide_Food_2636",
          "text": "Codex 5.3!",
          "score": 1,
          "created_utc": "2026-02-09 08:03:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4efcmm",
          "author": "Dry-Drag1995",
          "text": "Codex 5.3, no doubt. Speed is key for me.",
          "score": 1,
          "created_utc": "2026-02-09 08:04:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kyto8",
          "author": "Inside-Mongoose-892",
          "text": "The answer is yes",
          "score": 1,
          "created_utc": "2026-02-10 08:19:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wma94",
          "author": "Ok-Lie5292",
          "text": "codex, opus can't even fix its own bug lol",
          "score": 1,
          "created_utc": "2026-02-12 01:26:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o548xnd",
          "author": "Bright-Cheesecake857",
          "text": "Do I have unlimited money? In that case, opus 4.6 Fast is insanely expensive but gets so much done so quickly.",
          "score": 1,
          "created_utc": "2026-02-13 05:47:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4n4t7",
      "title": "Best AI for Google Sheets",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "author": "Halvey15",
      "created_utc": "2026-02-14 15:15:48",
      "score": 10,
      "num_comments": 9,
      "upvote_ratio": 0.86,
      "text": "I'm fairly inexperienced with AI so I apologize if there are some dumb questions in here. \n\nLong story short, I've been using ChatGPT for about a year to assist with B2B sales. I have a thread where I can post a company's website and it will return an analysis of that company, what their needs are, and where our best in might be. I have a thread for prospect discovery. And I have a thread for drafting quick emails, among a few other threads.\n\nA few weeks ago I had the idea of trying to create a CRM within ChatGPT, to expand on the Google Sheet that I have used over the years for organization, and so far the AI has been useful. But I have some concerns with long term viability:\n\n1.) I've noticed over the past year that ChatGPT does not do well on long threads, whether that be slowing down or losing context. I'm afraid that I'm going to need to create new threads so often that it won't be worth my time, and that I may also lose context while switching over to a new thread.\n\n2.) ChatGPT apparently can't share information between threads? It would be nice if my emails thread had access to my CRM thread. That way I wouldn't have to provide context for each email.  \n\n3.) Redundancy. I'm still using the Google Sheet as a backup, so I'm entering info on the Google Sheet and then pasting it into ChatGPT. If we could remove a step there, that would also be nice. \n\nI really just want something where I can enter the info in Google Sheets, and then find an AI that can get live access to the the Google Sheet. So when I ask it a question or ask it for tasks for the day, it has all of that information without having to load all of the prospect info into a thread. \n\nLike I said, I haven't explored the AI world too much. I just learned about Claude the other day. I downloaded Claude and gave it permission to view my Google Drive. But it is telling me that it can't read Google Sheets? I knew Google had an AI, but didn't realize that Gemini was a full chatbot. So maybe that is the right move? \n\nDoes anyone have suggestions before I put a few hours into just experimenting?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5cmhn5",
          "author": "qualityvote2",
          "text": "Hello u/Halvey15 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-14 15:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cofz9",
          "author": "Subject-Street-6503",
          "text": "I believe ChatGPT has a connector that can read directly from GDrive  \nYou should be able to find it in account settings",
          "score": 3,
          "created_utc": "2026-02-14 15:26:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cwyhx",
              "author": "Halvey15",
              "text": "That's something I definitely should have thought of before posting this lol. That seems to be a viable option. I am still interested in learning more about the other AIs, to see if there might be a better fit though. \n\nThank you!",
              "score": 1,
              "created_utc": "2026-02-14 16:10:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cwy3l",
          "author": "mgoulart",
          "text": "Google Gemini has built in Sheets integration.",
          "score": 3,
          "created_utc": "2026-02-14 16:10:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cxkw6",
              "author": "Halvey15",
              "text": "I figured it did. I'll have to play around with Gemini a bit to see if that is a better fit for me. \n\nThe massive advantage that ChatGPT has right now is that it has a year's worth of context, so it knows my company so well at this point. It would be difficult to start over from scratch again.",
              "score": 2,
              "created_utc": "2026-02-14 16:13:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dihva",
                  "author": "Odd-Opinion-5105",
                  "text": "There was just a thread on exporting data from chat got to google",
                  "score": 2,
                  "created_utc": "2026-02-14 17:58:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cxdcm",
          "author": "BYRN777",
          "text": "If you're working with Google Sheets, the best AI is Gemini because it's now in every native Google app, from YouTube to Google Keep, Google Calendar, Google Photos, Google Docs, Google Slides, and Google Sheets. We can't have a Gemini within Google Sheets itself; you can either upload a Google Sheets document or give a Google Drive. When you're typing up your prompt, you can select the file from Google Drive, then open it and work with it. Any live changes you make with Google Workspace apps will update the file.\n\nFor instance, let's say you're working on a thread in Google Docs, asking questions or getting info, and you make a change in Google Sheets, it will update in the thread at the same time. Native Google apps can change them. The way I do this is: let's say they upload a Google Doc. I ask it to make these changes, and then open it in Canvas. I've attached a document. In Google Drive, you can select your document. I give it my prompt, select Canvas at the same time, tell it to do this, and then open it in Canvas, because from there, you can see the changes it has made.\n\nI haven't personally worked with Google Sheets. I mostly work with Google Slides and Google Docs, and it's so seamless and smooth that it works perfectly. But I believe Google Sheets is just because Gemini is natively within each Google Workspace app, and there's seamless integration. That's why I think Gemini would be the best option. At the same time, another reason is that Gemini's context window is 1 million tokens. \n\nChatGPT is great, but if you're not using the API, your context window is limited. GPT 5.2 thinking is limited to 196,000 context tokens, but it's limited to a 196,000-context window. However, an API can be up to 400,000, which is a lot. But in Gemini, within the chatbot itself (without using the API), the context window is 1 million, so it can read, synthesize, analyze, understand, and remember much more information.\n\nIn long-term threads and working with larger files/documents like PDFs, Google Sheets, or native Google Labs, Gemini is the best. I would never trust giving ChatGPT, for example, access to 20-30 page PDF articles and then asking questions, working with them, or using them in a paper or report. But I would trust Gemini much more because of the context window, because I know I can tell confidently that it actually reads and assesses them. But ChatGPT, because of its limited context window, once it runs, it will hallucinate when it reaches its limits. Unless, again, you're using an API key, in which case you have up to 400,000 tokens. \n\nAlso, I'm assuming you have a ChatGPT Pro subscription? Keep that because it's great. You have access to GPT 5.2 Pro, and with GPT 5.2, you have access to Heavy Thinking. You have access to much deeper research queries per month and a lot more agent queries. It's just great.\n\nChatGPT, this is just general advice you should know. ChatGPT has the best chatbot experience, and it's a jack of all trades, but I like to say it's a jack of all trades and a master of none. However, their long memory feature is the best. The fact that, let's say, you told it something three months ago, and it remembers, for instance, is just amazing. Let's say you're writing an email and you put your phone number at the bottom, then write a new email months later and need to add it at the end. It'll remember that perfectly. So, its long memory feature is the best.\n\nThe chatbot experience is the best, and with most app connectors like Acrobat Pro, Photoshop, Booking.com, Spotify, Apple Music, and so many other tools and apps. Also, its deep research is pretty thorough and actually synthesizes, analyzes, and digests information. It uses reasoning in its deep research.\n\nNow, Gemini, since you have ChatGPT Pro, I'm assuming you do, since you're making this post in this thread. If you have ChatGPT Pro, you don't need to get Gemini Ultra or Gemini AI Pro, which costs the same as ChatGPT Plus at $25/month and gives you many musician limits. For instance, it gives you 100 Gemini 3 Pro queries per day and 25 deep research queries per day. Gemini's deep research is pretty thorough; it's also useful for reasoning. The search takes anywhere from 15 to 30 minutes, and Google's indexing is on par. It has access to the most credible, reliable, and relevant sources when you do deep research with it. If you use any Google Apps, such as Google Sheets, Google Docs, or Gmail, there's no question that you should get Gemini AI Pro, which gives you access to NotebookLM Pro with generous limits as well.\n\nThis is not an ad; I'm just advocating for them because they're actually offering a lot of great tools and features, along with generous usage limits. Gemini is now Google's only product. Google makes a lot of software, hardware, and ads, but ChatGPT is OpenAI's only product (with ChatGPT Atlas as well), and at the same time, it's still ChatGPT. If they're not number one, they're dead, but Google can afford to give people generous limits essentially, and they're experimenting so much by giving these many features, etc. Like in NotebookLM with Gemini AI Pro, you can make 500 notebooks each with 300 sources, and you can make 25 audio reviews, 25 video overviews, and 25 video reviews per day, which is crazy. So, consider Gemini Pro specifically for this use case, and I believe that with Gemini Pro and Chachi on the Pro subscription, you don't need any other AI tool at all.",
          "score": 2,
          "created_utc": "2026-02-14 16:12:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d1a1j",
          "author": "JamesGriffing",
          "text": "Google has something called Google App Scripts that allows us to add functionality to many Google products. One of them being Google Sheets.\n\nWith Google app scripts you're able to create custom formulas, or even user interfaces like a chat side bar.\n\nChatGPT is available to be used via OpenAI's API.\n\nSo this means you're able to use ChatGPT directly within Google Sheets. ChatGPT itself can guide you on how to set this up and write the scripts needed for you.\n\nperhaps in one of the threads that contains a lot of this context on why you use the Google sheet you can ask something like \"Based on our activity, and what I am trying to achieve with Google Sheets, educate me on how I can best utilize Google App Scripts with the OpenAI API. Assume I am a beginner\"\n\nIf this is something others would find useful then I can create a post/guide going over all of this in far more detail.",
          "score": 2,
          "created_utc": "2026-02-14 16:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d4liy",
          "author": "ConsequenceHairy1570",
          "text": "Worth trying Gemini or an API solution. It connects directly to Sheets.",
          "score": 2,
          "created_utc": "2026-02-14 16:48:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2k2lc",
      "title": "Rough guess: What % of your code is AI assisted now?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "author": "Mental_Bug_3731",
      "created_utc": "2026-02-12 04:36:09",
      "score": 8,
      "num_comments": 16,
      "upvote_ratio": 0.73,
      "text": "Not copy paste. \nJust influenced. I‚Äôm probably at ~45%.\nFeels insane compared to last year. Curious where everyone else lands.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4xg9wp",
          "author": "qualityvote2",
          "text": "u/Mental_Bug_3731, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 04:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xodhk",
          "author": "cleanbot",
          "text": "99% nearly.... my workflow now is to describe to her Highness web gpt what changes i want in my code.\n\n\nshe generates the prompt i copy/pasta into the local codex running at my repo root. He bashes out the code. when I'm reporting a bug he first creates a test to verify before making changes.\n\n\ni review the logs and either reverse the changes or take the built product to manual tests.\n\n\nmy efficiency has been raised several orders of magnitude now. I'd never go back.",
          "score": 17,
          "created_utc": "2026-02-12 05:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zqici",
              "author": "sply450v2",
              "text": "good workflow. I do the same but also in plan mode and sometimes use my research skill or deep research to augment. also sometimes chatgpt pro for big arch decisions and planning",
              "score": 2,
              "created_utc": "2026-02-12 15:12:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y4o23",
          "author": "Ok-Shape-9145",
          "text": "Probably close to a 100%. I shifted to high level stuff, AI does the heavy lifting",
          "score": 3,
          "created_utc": "2026-02-12 08:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yahic",
          "author": "Hot_Inspection_9528",
          "text": "depends on the code. \n\n    import time\n    import pyautogui\n    # --- Settings ---he\n    word = \"hello\" ¬† ¬† ¬† ¬†# change me\n    delay = 0.2 ¬† ¬† ¬† ¬† ¬† # seconds between type and erase\n    type_interval = 0.02 ¬†# per-character delay while typing\n    \n    \n    # Safety: moving mouse to a corner aborts\n    pyautogui.FAILSAFE = True\n    \n    \n    print(\"Switch to the target window. Starting in 3 seconds...\")\n    time.sleep(3)\n    \n    \n    try:\n    ¬† ¬† while True:\n    ¬† ¬† ¬† ¬† pyautogui.typewrite(word, interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    ¬† ¬† ¬† ¬† pyautogui.press('backspace', presses=len(word), interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    except KeyboardInterrupt:\n    ¬† ¬† print(\"\\nStopped.\")\n\n  \nthis has done me wonders maybe  - weild the power correctly if you dont already know \n\nbut this was 100% written by ai which requires a very specific ask haahaha",
          "score": 1,
          "created_utc": "2026-02-12 09:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yke36",
          "author": "LanternOfTheLost",
          "text": "99%.\n\nIn many ways it‚Äôs like having a trainee or intern - you let it give you choices, provide evaluations, and you‚Äôd come in to validate his decisions before letting him run off on his own to implement.\n\nAnd then have him do the same cycle again for testing.",
          "score": 1,
          "created_utc": "2026-02-12 10:39:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zcv5o",
          "author": "Ok_Chef_5858",
          "text": "Probably 80% first draft, but I review and tweak everything. So technically 100% AI-assisted, 100% human-reviewed lol. I use Kilo Code in VS Code daily... AI writes the draft, I make sure it works. A year ago I'd maybe ask ChatGPT a question here and there. Now it's the whole workflow. :) ",
          "score": 1,
          "created_utc": "2026-02-12 14:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o512ple",
          "author": "dogscatsnscience",
          "text": "I'm not sure what \"just influenced\" means.\n\nFinal shipping code, probably 99%. If I am making significant manual edits or additions, which is rare these days, they're almost always going to get refactored by AI anyway.",
          "score": 1,
          "created_utc": "2026-02-12 18:58:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5218t5",
          "author": "X_TheSwindler_X",
          "text": "99% for sure, and the 1% I touch is usually the weak link ü´†",
          "score": 1,
          "created_utc": "2026-02-12 21:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52j5xc",
          "author": "alecc",
          "text": "If it‚Äôs below 100%, and you are not working on some super niche crazy project - you are wasting time and could have good results faster.",
          "score": 1,
          "created_utc": "2026-02-12 23:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ja2j",
              "author": "Mental_Bug_3731",
              "text": "Honestly true, what are you shipping currently!",
              "score": 1,
              "created_utc": "2026-02-12 23:16:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o54jtg5",
                  "author": "alecc",
                  "text": "[TickTappy](https://ticktappy.com) a simple time tracker for my needs",
                  "score": 1,
                  "created_utc": "2026-02-13 07:20:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53ryg8",
          "author": "AxeSlash",
          "text": "Boiler plate stuff: ~95%\nStuff I am unfamiliar with: ~80%\nBug fixes: ~50% by volume, but that's usually the bugs that require a lot of code to fix. I do almost all small fixes myself, and anything that would take some time to describe adequately enough to the LLM I also do myself.\nEverything else: ~40%?\nRefactoring: ~90%\n\nAlso I'm talking about assistance from an LLM, not vibe coding. I check everything it produces carefully.\n\nAlso depends on the language.",
          "score": 1,
          "created_utc": "2026-02-13 03:45:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58bg9g",
          "author": "Compilingthings",
          "text": "110%",
          "score": 1,
          "created_utc": "2026-02-13 20:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bg1e9",
          "author": "Classic-Ninja-1",
          "text": "Mine is about 99% where execution and planning or mostly everything I do with the use of AI my workflow consists of traycer for planning and verifying, cursor and claude for execution.",
          "score": 1,
          "created_utc": "2026-02-14 10:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhvzy",
          "author": "Tombobalomb",
          "text": "~3% maybe?",
          "score": -1,
          "created_utc": "2026-02-12 04:48:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r290yv",
      "title": "Tool for generating a real-time transcript of a live YouTube video?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "author": "tu_servilleta",
      "created_utc": "2026-02-11 20:43:46",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 0.89,
      "text": "My work involves watching a 2 hour press conference that the president of Mexico gives each morning. I have to watch it and make detailed notes on the key subjects and quotes of the conference. It's time sensitive so I need to be sending my summary as the conference is still live. The problem is, YouTube doesn't upload a transcript until the live is over. I want to find a plugin that can generate a transcript real time so I can use it to copy and paste some fragments instead of having to manually transcribe them like a caveman. What are some tools that could solve this problem?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v56an",
          "author": "qualityvote2",
          "text": "u/tu_servilleta, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 20:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w65yj",
          "author": "manjit-johal",
          "text": "For doing live transcription, it depends on how much control you need. Tools like Tactiq can transcribe Zoom/Meet calls in real-time and automatically create action items. They might be worth checking out! If you're more of a DIY person and don't need a meeting sidebar, you can use a tool like Whisper to transcribe audio to text, and then use GPT to summarize or highlight key points in real-time. It gives you fast transcription during the meeting.",
          "score": 1,
          "created_utc": "2026-02-11 23:51:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wapip",
              "author": "tu_servilleta",
              "text": "You mean the Open AI Whisper API? ? I'm really leaning towards vibecoding a custom plugin using Whisper tbh haha but if I can find an already existing app that would save me some trouble.",
              "score": 1,
              "created_utc": "2026-02-12 00:17:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xj4mx",
          "author": "lxe",
          "text": "Stream to Google Meet and generate transcript with Gemini",
          "score": 1,
          "created_utc": "2026-02-12 04:57:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r8qz",
              "author": "tu_servilleta",
              "text": "Not a bad idea",
              "score": 1,
              "created_utc": "2026-02-12 20:56:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yr142",
          "author": "Projected_Sigs",
          "text": "https://www.recall.ai/\nI don't know if this company is overkill for what you want but they make an SDK / API to perform desktop recording, live meeting transcription, metadata extraction, etc. \n\nFrom various stories available online, it sounds like they've carved out a space for themselves doing what a lot of companies assume is easy, but it's really fraught with problems and it's engineering time sink, and always a moving target. \n\nI have no idea what their pricing is.",
          "score": 1,
          "created_utc": "2026-02-12 11:38:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r567",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 1,
              "created_utc": "2026-02-12 20:55:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50usvl",
          "author": "YUL438",
          "text": "try Deepgram Nova3",
          "score": 1,
          "created_utc": "2026-02-12 18:21:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o511wsj",
          "author": "FreonMuskOfficial",
          "text": "This may work. https://github.com/gs-ai/RippinTubes",
          "score": 1,
          "created_utc": "2026-02-12 18:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r7zr",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 1,
              "created_utc": "2026-02-12 20:55:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b5877",
          "author": "dakumaku",
          "text": "Gemini aistudio, NotebookLM",
          "score": 1,
          "created_utc": "2026-02-14 08:15:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r25gvg",
      "title": "A beautiful tool: Visual branching tree navigation for managing long ChatGPT conversations",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "author": "Own_Cat_2970",
      "created_utc": "2026-02-11 18:32:58",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.99,
      "text": "I kept running into the same problem: 50+ messages into a conversation and I have no idea where anything is. Scrolling endlessly trying to find that one useful response. And if I want to explore a side question, I either derail the whole thread or open a new chat and lose all context.\n\nSo I built **Tangent** ‚Äî a Chrome extension that overlays a visual branching tree on top of ChatGPT.\n\n[The \\\\\"Tangent View\\\\\". A visualization of the branching structure which Tangent enables. 1 sentence summaries of each node \\(prompt+response\\) when hovering over nodes for quick overview.](https://preview.redd.it/znlp8zk8swig1.png?width=785&format=png&auto=webp&s=1c5768327540b8267710e1b2e6ae32bef42c7b1d)\n\n**What it does:**\n\n* Branch off at any point without losing your place\n* See a visual map of your entire conversation\n* Hover over any node for a one-sentence summary\n* SHIFT+hover to see the full prompt/response\n* Jump back to any point instantly\n\n[SHIFT+hover over a node to see the full node \\(prompt\\/response\\)](https://preview.redd.it/3ny28yqhswig1.png?width=1134&format=png&auto=webp&s=88d959bcc5c67e320bb5ca64ae2e557a6ef5419a)\n\nIt lets you go on tangents (hence the name) the way your brain actually works -- except you can always find your way back.\n\nCurrently preparing bete-launch. happy to answer questions about how it works or the tech behind it.\n\nSignup for limited beta access: [https://tally.so/r/Zj6vLv](https://tally.so/r/Zj6vLv)",
      "is_original_content": false,
      "link_flair_text": "UNVERIFIED AI Tool (paid)",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4udonw",
          "author": "qualityvote2",
          "text": "u/Own_Cat_2970, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 18:32:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1k6qu",
      "title": "better UI for LLMs?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r1k6qu/better_ui_for_llms/",
      "author": "OkLet9942",
      "created_utc": "2026-02-11 01:50:20",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Is there a better way to interact with llms than the current UIs?\n\nI want to work more complex stuff like presentations and long structured documents papers, prds, documentation and I find it impossible to structure different queries, summarize stuff, finalize sections, create chapters and re-find wording that I liked in various prompt experiments and so on. it all becomes a big mess every time.\n\nIs there something better out there to interface with an LLM?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r1k6qu/better_ui_for_llms/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4q4yhw",
          "author": "qualityvote2",
          "text": "u/OkLet9942, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 01:50:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e6cnl",
          "author": "IngenuitySome5417",
          "text": "You've picked the wrong generation of models. I advise the eastern ones they don't have guards up like the western ones.\n\nhttps://medium.com/@ktg.one/all-your-agent-skills-are-broken-8cab4770ccb6",
          "score": 2,
          "created_utc": "2026-02-14 19:59:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rh4kr",
          "author": "InterYuG1oCard",
          "text": "I think you are looking for an ai workspace? Many options like notebooklm, saner, notion‚Ä¶",
          "score": 1,
          "created_utc": "2026-02-11 07:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z5r15",
          "author": "Ryanmonroe82",
          "text": "Check out LM Station on Mac",
          "score": 1,
          "created_utc": "2026-02-12 13:21:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r21ucg",
      "title": "Limits for Pro Thinking??",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r21ucg/limits_for_pro_thinking/",
      "author": "superuserjarvis",
      "created_utc": "2026-02-11 16:23:43",
      "score": 5,
      "num_comments": 14,
      "upvote_ratio": 0.86,
      "text": "I'm currently using my company's chat GPT Enterprise plan, and it provides me 15 requests per month for pro thinking (Research-grade intelligence one).\n\nWanted to know from users how many requests are allowed for GPT Pro plan that costs $200/month.\n\nAlso, how many Deep Research requests are allowed in the Pro plan?\n\nThank you kindly.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r21ucg/limits_for_pro_thinking/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4tlyjn",
          "author": "qualityvote2",
          "text": "u/superuserjarvis, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 16:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tod6i",
          "author": "Pasto_Shouwa",
          "text": ">for pro thinking (Research-grade intelligence one)\n\n>Wanted to know from users how many requests are allowed for GPT Pro\n\nUnlimited\n\n>Also, how many Deep Research requests are allowed in the Pro plan?\n\n250 per month",
          "score": 2,
          "created_utc": "2026-02-11 16:34:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tp2kg",
              "author": "superuserjarvis",
              "text": "Wow, thanks.\n\nLooks like a worthy upgrade. \n\nAlso, how many of those 250 are allowed are full vs lightweight?\n\nThanks kindly",
              "score": 2,
              "created_utc": "2026-02-11 16:38:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tqb7k",
                  "author": "Pasto_Shouwa",
                  "text": ">Also, how many of those 250 are allowed are full vs lightweight?\n\nI think OpenAI hasn't disclosed it. They also said that the full version is powered by 5.2 Thinking just a couple of days ago, but we don't know what model the lightweight version uses. They're quite secretive about deep research for some reason.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:43:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4toza2",
          "author": "petermalik01",
          "text": "ChatGPT Pro (model) - it‚Äôs effectively unlimited. Many times  I‚Äôve used the model more than 20 times a day, and I‚Äôve never seen any message indicating there‚Äôs a limit. In the current version, it‚Äôs usually the extended-thinking variant (i.e., stronger than the standard Pro).\n\nDeep Research ‚Äî 250 per month. I‚Äôve never even come close to using 50% of that limit.\n\nFor me, a major advantage of Pro is also using GPT-5.2 Thinking in heavy thinking mode ‚Äî it‚Äôs noticeably better than extended thinking.",
          "score": 2,
          "created_utc": "2026-02-11 16:37:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tpbjw",
              "author": "superuserjarvis",
              "text": "Ohh so there is a heavy thinking other than extended thinking??",
              "score": 2,
              "created_utc": "2026-02-11 16:39:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tra0q",
                  "author": "petermalik01",
                  "text": "Yes ‚Äî the GPT-5.2 Thinking variant has four modes in the Pro subscription: (1) light, (2) standard, (3) extended, and (4) heavy. Modes 1 and 4 are exclusive to Pro.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:48:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4u9mtw",
          "author": "Oldschool728603",
          "text": "(1) Pro subscription offers unlimited access to  Pro the model, standard and extended\n\n  \n(2) Pro subscription offers 250 deep research per month‚Äî125 full (based on o3) and 125 light (based on o4-mini)",
          "score": 2,
          "created_utc": "2026-02-11 18:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ueys1",
              "author": "superuserjarvis",
              "text": "Thanks üòä",
              "score": 1,
              "created_utc": "2026-02-11 18:38:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5a1g07",
              "author": "Ok-Entrance8626",
              "text": "Though (2) is surely out of date as deep research now uses 5.2.",
              "score": 1,
              "created_utc": "2026-02-14 02:54:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aigfc",
                  "author": "Oldschool728603",
                  "text": "You're right. As of the 10th, Deep Research with Pro subscription offers \"Deep research\" and \"Legacy\" options. Is Legacy o3? Is it still 250? Is there a split?\n\nOpenAI wouldn't be OpenAI if we had a clear answers.\n\nI can see the support tickets:\n\n\"I'm having a problem with Deep Research.\"\n\n\"Are you using Deep Research?\"\n\n\"Yes, I said Deep Research.\"\n\n\"But are you using Deep Research?\"",
                  "score": 1,
                  "created_utc": "2026-02-14 04:55:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4xnf0b",
          "author": "zaibatsu",
          "text": "I haven‚Äôt hit a limit and I‚Äôll sometimes spin up several instances that can churn for up to 99 minutes at a time concurrently in 5.2 Pro mode‚Äôs extended thinking. \n\nI  haven‚Äôt stopped in quite a while.",
          "score": 1,
          "created_utc": "2026-02-12 05:30:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r37c6p",
      "title": "Voice mode is incredible. But how do I get it to read to me more than just a few sentences?",
      "subreddit": "ChatGPTPro",
      "url": "https://i.redd.it/mbsflux525jg1.jpeg",
      "author": "Ramenko1",
      "created_utc": "2026-02-12 22:18:46",
      "score": 4,
      "num_comments": 12,
      "upvote_ratio": 0.7,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r37c6p/voice_mode_is_incredible_but_how_do_i_get_it_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o528hor",
          "author": "qualityvote2",
          "text": "Hello u/Ramenko1 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-12 22:18:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52gns8",
          "author": "Warp_Speed_7",
          "text": "Weird haven‚Äôt seen that. I have it read long things all the time.",
          "score": 2,
          "created_utc": "2026-02-12 23:01:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ir5s",
              "author": "Ramenko1",
              "text": "So what do you prompt?",
              "score": 1,
              "created_utc": "2026-02-12 23:13:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52l01n",
          "author": "manjit-johal",
          "text": "Voice mode can get messy since it‚Äôs one long stream of context. If you add clearer turn breaks, even something simple like a short pause or a keyword trigger before sending it to GPT, the responses tend to be way more predictable and on point.",
          "score": 1,
          "created_utc": "2026-02-12 23:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52pdz8",
              "author": "Banjoschmanjo",
              "text": "Can you give an example of what you mean? I don't understand",
              "score": 1,
              "created_utc": "2026-02-12 23:50:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o52rhbb",
                  "author": "manjit-johal",
                  "text": "Sure. Imagine a research agent with skills like ‚Äúsearch web,‚Äù ‚Äúsummarize,‚Äù and ‚Äúwrite report.‚Äù If each skill keeps passing its full output into the next call, the context window fills up fast, and the plan drifts. Instead, you can keep each skill narrow and only pass back a short, structured result, like key findings, so the planner decides what actually goes into the next prompt.",
                  "score": 1,
                  "created_utc": "2026-02-13 00:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52jdyp",
          "author": "simsimulation",
          "text": "I haven‚Äôt used it, but I believe notebook lm is good for this?",
          "score": 1,
          "created_utc": "2026-02-12 23:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52jnwd",
              "author": "Ramenko1",
              "text": "Notebook LM makes podcasts. Not the same as verbatim reading it out back to me.",
              "score": 4,
              "created_utc": "2026-02-12 23:18:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}