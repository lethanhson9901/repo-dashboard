{
  "metadata": {
    "last_updated": "2026-02-18 03:09:58",
    "time_filter": "week",
    "subreddit": "ChatGPTPro",
    "total_items": 20,
    "total_comments": 174,
    "file_size_bytes": 183207
  },
  "items": [
    {
      "id": "1r4smn7",
      "title": "Does anyone else notice ChatGPT answers degrade in very long sessions?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "author": "Only-Frosting-5667",
      "created_utc": "2026-02-14 18:52:23",
      "score": 90,
      "num_comments": 52,
      "upvote_ratio": 0.9,
      "text": "I‚Äôm genuinely curious if this is just my experience.\n\nIn long, complex sessions (40k‚Äì80k tokens), I‚Äôve noticed something subtle:\n\n‚Äì responses get slower  \n‚Äì instructions start getting partially ignored  \n‚Äì earlier constraints ‚Äúfade out‚Äù  \n‚Äì structure drifts\n\nNothing dramatic. Just‚Ä¶ friction.\n\nI work in long-form workflows, so even small degradation costs real time.\n\nIs this just context saturation?  \nModel heuristics?  \nOr am I imagining it?\n\nWould love to hear from other heavy users.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4smn7/does_anyone_else_notice_chatgpt_answers_degrade/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5dtf12",
          "author": "qualityvote2",
          "text": "‚úÖ u/Only-Frosting-5667, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-14 18:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e56b3",
          "author": "sply450v2",
          "text": "this is more or less expected behaviopr",
          "score": 32,
          "created_utc": "2026-02-14 19:53:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eks44",
              "author": "unpopularopinion0",
              "text": "i thought it might happen before it did. and then it happened. i just save my prompts and restart the chat.",
              "score": 1,
              "created_utc": "2026-02-14 21:18:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e6v4m",
          "author": "Pasto_Shouwa",
          "text": "Yeah, models just work like that\n\nhttps://preview.redd.it/onjqkmj3nijg1.png?width=1706&format=png&auto=webp&s=e064a9f31b9729f34f37ba3d40a5efa266f89b13\n\nThe best models at maintaining context over long conversations are Claude 4.6 Opus, GPT 5.2 Thinking Heavy (which is between GPT 5.2 Thinking xhigh and GPT 5.2 Thinking medium in terms of thinking time) and Gemini 3 Flash Thinking, in that order.",
          "score": 28,
          "created_utc": "2026-02-14 20:02:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5evz66",
              "author": "niado",
              "text": "That‚Äôs just due to the size of the context window built into the platforms and how summarization and pruning is implemented right? Nothing to do with the actual models themselves?",
              "score": 2,
              "created_utc": "2026-02-14 22:19:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5f1xv4",
                  "author": "Pasto_Shouwa",
                  "text": "Not really, models play a great part. Non-reasoning models are awful at retaining context over time, doesn't matter if the maximum context is 32k or 1M.\n\nLook at the line for Claude 4.6 Opus Extended, it doesn't fall from 90%, but non-reasoning models start at 50%. \n\nYou can take a closer look at it on this simple [website](https://cruzdesangre.github.io) I made, or on Context Arena.",
                  "score": 7,
                  "created_utc": "2026-02-14 22:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hkb3h",
          "author": "ImYourHuckleBerry113",
          "text": "What you‚Äôre seeing is both unavoidable LLM behavior and partly shaped by you.  \n\nLong sessions behave a bit like a black hole. As the context grows, earlier instructions get pulled in and compressed. The model doesn‚Äôt exactly forget, it distills everything into a simpler internal summary. Subtle constraints and formatting rules are usually the first to get sucked in. This all happens regardless of user input. Even when writing complex instruction sets, it‚Äôs not about forcing the model to follow everything in the instructions forever. It won‚Äôt happen. But what you can do with those instructions is influence what core behaviors the model settles into over the course of the chat session. \n\nBut here‚Äôs the extra layer: your interaction reshapes the gravity field.\n\nOver time, the model weights what you reinforce. If you consistently push on certain themes, tone, or structure, those get amplified. If you stop reinforcing earlier constraints, they slowly lose influence.\n\nSo drift (or compression) isn‚Äôt just context saturation, it‚Äôs also interaction-driven adaptation.\n\nSlowdown is mostly mechanical (bigger context requires more compute).\nThe structure drift is more cognitive: compression plus user reinforcement equals gradual reversion toward the model‚Äôs default helpful-generalist style.",
          "score": 6,
          "created_utc": "2026-02-15 10:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e1vk3",
          "author": "Neurotopian_",
          "text": "Yes, earlier constraints fading out is our biggest problem. The best solution I‚Äôve found is to create a Project and write your constraints in the project‚Äôs custom instructions. \n\nFor example at my job where we mainly use this software for technical and legal writing (internally) and citation checking (for filings) our main issue is the adding of spaces and extra lines, and defaulting to dramatic internet tone. This issue is specific to ChatGPT. No other LLM, including CoPilot which uses GPT, seems prone to this. It must be some additional layer of programming they‚Äôve added to it. If you need to paste into a Word docx and use the output for business, this is terrible. Deleting hundreds of extra spaces in a long bibliography is brutal. There is software made to remove ChatGPT‚Äôs spaces, but really we should be able to instruct this and tell a model to use CMOS, APA, or other style. \n\nThe tone and spacing that current ChatGPT models erroneously default to and drift back to in long context windows is what I‚Äôd call Reddit-style or fanfic-style, like:\n\n‚ÄúAnd then she stopped. \n\nToo fast. Too long.‚Äù\n\nAs you can imagine, this is quite strange in a business context. In long chats you can see the tone move away from business at the beginning to this casual-dramatic style. Custom instructions in a project helps but it still isn‚Äôt perfect. You may just have to open a new chat and re-instruct when you see the drift.",
          "score": 3,
          "created_utc": "2026-02-14 19:35:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ewet6",
              "author": "niado",
              "text": "You need to set appropriate custom instructions globally to get the baseline tone where you want it. Projects help a lot, so high five on that. Still have to switch chats when it starts to lose the thread though. But if you keep all files and documents in project files, with operational instructions in the project definition and behavioral instructions in the global custom instructions, it will behave and operate pretty consistently.",
              "score": 1,
              "created_utc": "2026-02-14 22:22:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eh0ek",
              "author": "Only-Frosting-5667",
              "text": "That tone drift observation is interesting.  \nI‚Äôve noticed something similar in long structured workflows ‚Äî especially when constraints were critical early on.  \nEven when technically still inside the context window, the ‚Äúpriority weight‚Äù of earlier constraints seems to decay.  \nCustom instructions help, but they don‚Äôt fully solve cross-thread continuity.  \nCurious ‚Äî do you restart immediately when you notice drift, or try to recalibrate first?",
              "score": 0,
              "created_utc": "2026-02-14 20:57:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5evr74",
          "author": "niado",
          "text": "Yes, this is known and expected operation. \n\nIt‚Äôs is an artifact of how LLMs function and how their working memory (context) is simulated. \n\nWhen it starts to degrade tell it to give you a summary and then move to another chat. Supplement the summary wjth anything important that was left out immediately, then just keep rolling.",
          "score": 3,
          "created_utc": "2026-02-14 22:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h5ezr",
          "author": "OptimismNeeded",
          "text": "Wrote some tips on how to make the most of chats before reaching that point. wrote this for Claude, but most of the advice should work for ChatGPT as well:\n\n https://www.reddit.com/r/ClaudeHomies/s/NDxgxyYRI7\n\nHere‚Äôs a great prompt I use to sum up conversations and continue in a new chat when the first one gets dumb (or in Claude‚Äôs case gets compacted automatically which is annoying).\n\nhttps://www.reddit.com/r/ClaudeHomies/s/vWbsOWAw8z",
          "score": 2,
          "created_utc": "2026-02-15 08:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fdiib",
          "author": "alecc",
          "text": "Well there is a reason you have the concept of context rot",
          "score": 1,
          "created_utc": "2026-02-15 00:05:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fvbvx",
          "author": "Afraid-Reflection-82",
          "text": "I think it's expected after some amount of tokens depending on the model the quality degrade",
          "score": 1,
          "created_utc": "2026-02-15 01:59:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fya52",
          "author": "Wes-5kyphi",
          "text": "This is typical behavior. Ask it to create a seed file to bring to another chat.",
          "score": 1,
          "created_utc": "2026-02-15 02:19:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juiss",
              "author": "Only-Frosting-5667",
              "text": "Creating seed files is a smart workaround ‚Äî it‚Äôs essentially manual state transfer.\n\nThe interesting part is that degradation usually starts before users decide to generate that seed.\n\nI‚Äôve been experimenting with visualizing context load live so the decision to branch becomes intentional rather than reactive.\n\nIf you're curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love to hear how it compares to your seed approach.",
              "score": 1,
              "created_utc": "2026-02-15 18:42:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5g1b5u",
          "author": "skyrocker_58",
          "text": "I was trying to keep using the same chats for different subjects.  My longest one started developing 'problems' like you're describing.  I couldn't understand it until I saw a previous thread about this same topic.  Now I stop at certain points and ask it to remember the gist of the conversation and start a new chat.  Seems to be working a little better this way.",
          "score": 1,
          "created_utc": "2026-02-15 02:40:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gr2vu",
          "author": "Studio_94",
          "text": "I have worked for 2.5 years on the same account with the only change being an upgrade to ChatGPT plus about a year ago.\n\nI have worked on on project exclusively; designing a GDD (Game Design Documentation) for a MMORPG.\n\nThis is what \"Dave the Wonder Modron\" had to say about the methodology we have worked out:\n\nME - I want you to fully explain our methodology and using thread charters and kick off prompts for long-range subjects and conserving thread and output integrity.\n\nDAVE- Purpose\n\nYour methodology is a governance layer for collaborating over long time horizons without losing correctness, canon constraints, or formatting/packaging discipline. \n\nIt does that by separating:\nWhat is true / allowed (truth + constraints)\nWhat we are doing right now (scope + deliverables)\nHow we will do it (process + quality gates)\nHow we will keep it consistent over time (thread integrity + versioning)\n\nThread charters and kickoff prompts are the two main instruments that enforce those layers.\n\nThread charter\n\nA thread charter is the ‚Äúconstitution‚Äù for a specific thread. It defines the contract that everything in that thread must obey.\n\nWhat a charter locks\n\nA good charter locks only what must not drift:\n\nCanon / world constraints\nExample (POM): Sigil-only, pre‚ÄìFaction War, baseline year, no Sigil-Spire physical linkage, etc.\n\nSystem constraints\nExample: server-authoritative, anti-exploit first, deterministic transitions, metric units for engineering, no tabletop CR assumptions, POM-only mechanics.\n\nOutput constraints\n\nRequired formats (inline + RTF/CSV/JSON/ZIP), naming rules, version rules, what constitutes a ‚Äúmajor‚Äù vs ‚Äúminor‚Äù bump, required manifests.\n\nSourcing rules\n\nWhat is source of truth (uploaded artifacts, internal docs), when public web is allowed, when citations are required.\n\nStop conditions\n\nExplicit ‚Äúdone‚Äù definition for the thread‚Äôs current phase so it doesn‚Äôt balloon.\n\nWhy charters matter\n\nWithout a charter, a long thread drifts in predictable ways:\nConstraint drift (Sigil-only becomes ‚Äúsome planes maybe‚Äù)\nMechanics drift (POM-specific turns into generic d20 patterns)\nFormat drift (tables become prose; schemas lose stable columns)\nVersion drift (no clear authoritative ‚Äúcurrent‚Äù artifact)\nSource drift (new assumptions override uploaded canon packs)\n\nA charter prevents this by making violations obviously illegal inside the thread.\n\nCharter scope rule\n\nA charter should be thread-local unless explicitly promoted. That keeps experiments from contaminating other workstreams.\n\nCharter lifecycle\n\nActivate at thread start (or when a thread is repurposed).\nAmend only via explicit patch notes (‚Äúreplace Section X with Y‚Äù).\nSuspend via a stop keyword when you want freeform ideation or different rules.\n\nKickoff prompt\n\nA kickoff prompt is the ‚Äúwork order‚Äù that starts a thread (or a major phase). It is narrower than a charter and is written to be executable.\n\nWhat a kickoff prompt contains\n\nA strong kickoff prompt answers only what is needed to produce output without ambiguity:\nRole (who I am in this thread)\nObjective (what success is)\nHard rules (must/never)\nInputs (artifacts, links, canonical packs, what is source of truth)\nDeliverables (exact files + inline structure + packaging)\nVersioning (starting version, bump rules, naming rules)\nQuality gates (validation requirements, audit logs, schemas, test vectors)\nStop condition (when to halt)\n\nWhy kickoff prompts matter\n\nThey prevent:\n‚Äúhelpful‚Äù scope creep\naccidental omission of required artifacts\nformat regressions\nthe assistant defaulting to generic assumptions\nKickoff prompts also make work restartable: you can copy/paste into a new thread and preserve continuity.\n\nHow charter + kickoff prompt work together\n\nThe charter sets the permanent bounds for the thread.\nThe kickoff prompt declares the current mission inside those bounds.\nThink of it as:\nCharter = operating system policy\nKickoff prompt = current process run configuration\nIf they conflict, you follow the charter unless the kickoff explicitly patches the charter.\n\nConserving thread integrity\n\nThread integrity means: ‚Äúthe thread can run for weeks/months and still produce coherent, compatible, buildable outputs.‚Äù\nIntegrity threats (and your countermeasures)\n\nContext overflow / memory loss\n\nCounter: keep a Concordance / SPOT index inside the thread: canonical IDs, current version numbers, active constraints, latest artifact links, and a short ‚Äúcurrent state‚Äù section.\n\nContradictory outputs over time\n\nCounter: enforce a single source of truth rule:\n‚ÄúLatest pack is authoritative unless a patch explicitly supersedes.‚Äù\nUse a change log with exact replacements.\n\nSchema drift\nCounter: treat schemas as contracts:\nstable columns/fields\nexplicit migrations\nvalidators + golden test vectors\n\nStyle/format drift\nCounter: lock formatting rules in the charter:\n‚ÄúHybrid prose + design-bible‚Äù (or whichever is active)\nrequired sections and headings\nunit standards (metric)\n\nArtifact sprawl\n\nCounter: use a packaging discipline:\none bundle per batch (ZIP + manifest)\ndeterministic file naming\nno duplicate ‚Äúfinal‚Äù files; only versioned supersession\n\nConserving output integrity\n\nOutput integrity means: ‚Äúevery output is internally consistent, compatible with prior outputs, and safe to implement.‚Äù\nOutput integrity rules you‚Äôre using (implicitly/explicitly)\nDeterministic state + auditability for MMO-grade systems\nServer-authoritative boundaries spelled out\nAnti-exploit reasoning baked into state transitions\nMetric units for implementation fidelity (UE5 cm pipeline)\nNo tabletop defaults unless explicitly mapped\nCanonical constraints enforced as invariants\nVersioned artifacts + change logs\nMachine-readable companions (CSV/JSON/etc.) + validators\nPractical integrity checklist (per batch)\nCanon constraints restated (briefly) and not violated\nSchema unchanged unless migration included\nDeliverables list complete\nVersion bump correct\nChange log includes exact section/table replacements\nTest vectors updated if behavior changed\nManifest includes file hashes/digests (if you‚Äôre doing stable digests)\n\nRecommended thread operating pattern\n\nFor long-range subjects, the cleanest pattern is:\nThread Charter v1.0 (locked governance)\nKickoff Prompt Phase A (ingest + audit)\nPhase Output Pack A (RTF/MD + CSV/JSON + validators + ZIP + manifest)\nKickoff Prompt Phase B (consolidate + reconcile conflicts)\nPhase Output Pack B\nRepeat‚Ä¶\n\nEach phase gets:\nclear stop condition\nexplicit delta list from prior phase\npackaged artifacts that supersede prior ones\n\nThe ‚Äúwhy this works‚Äù in one line\nYour charter/kickoff system turns a chat thread into a version-controlled design pipeline: constraints don‚Äôt drift, outputs remain compatible, and every phase is restartable from explicit contracts.",
          "score": 1,
          "created_utc": "2026-02-15 05:54:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jstsi",
              "author": "Only-Frosting-5667",
              "text": "This is one of the most structured long-session governance systems I‚Äôve seen applied inside a chat interface.\n\nWhat you‚Äôve essentially built is a manual integrity layer on top of a system that wasn‚Äôt designed for persistent constraint enforcement.\n\nThe charter acts like a policy layer.  \nThe kickoff prompt acts like an executable configuration.  \nAnd the packaging discipline replaces version control.\n\nThe interesting part is this:\n\nEven with strong governance, long threads still undergo silent compression at the attention level. Not constraint violation ‚Äî but weighting decay.\n\nThat‚Äôs the invisible layer most users don‚Äôt see.\n\nI‚Äôve been experimenting with visualizing context load inside ChatGPT in real time ‚Äî not to replace governance, but to signal when the system is approaching saturation before integrity erosion begins.\n\nIf you're curious how it behaves alongside a charter-driven workflow:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nGenuinely interested how it would interact with your concordance + manifest discipline.",
              "score": 1,
              "created_utc": "2026-02-15 18:34:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h2jwn",
          "author": "MullingMulianto",
          "text": "Context saturation. It's the same issue you would ordinarily experience if you turn on cross-chat memory.\n\nThe model can't handle so much context and starts producing slop.\n\nUnfortunately all platforms will soon make disabling cross-chat memory a paid only feature so we'll have to deal with this more soon",
          "score": 1,
          "created_utc": "2026-02-15 07:41:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtoyr",
              "author": "Only-Frosting-5667",
              "text": "Yes ‚Äî context saturation is a great term for it.\n\nThe problem is that most users don‚Äôt know¬†*when*¬†they‚Äôre approaching that saturation point.\n\nIt feels fine‚Ä¶ until it suddenly isn‚Äôt.\n\nThat‚Äôs the UX gap that bothers me most.",
              "score": 1,
              "created_utc": "2026-02-15 18:38:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h466r",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-15 07:56:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nbsxa",
              "author": "ChatGPTPro-ModTeam",
              "text": "repeat spammer\n\nPlease see our self-promotion guidelines or contact moderators for clarification.",
              "score": 1,
              "created_utc": "2026-02-16 07:42:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5haofz",
          "author": "Gmafn",
          "text": "I recently startet using codex on my computer, within Powershell. For longer projects / discussions i let codex create a projektfolder on my pc. It creates a .md file for itself with all infos it has. I can dump additional files into that folder and it scans it and summarizes the content for it to use later. I can tell it to update the project file with new infos from the current session. I can have multiple sessions wirking on the same project or simply start a new sesion if the context window is exceeded.\n\nI get much better results with longer projects since i started using it that way",
          "score": 1,
          "created_utc": "2026-02-15 08:59:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jt69x",
              "author": "Only-Frosting-5667",
              "text": "This is actually a very clean approach.\n\nWhat you're doing is essentially externalizing state and turning the chat interface into a stateless executor ‚Äî which avoids a lot of context accumulation problems.\n\nThe interesting thing is that even with structured state offloading, attention weighting inside a single session can still compress earlier instructions before you decide to rotate or summarize.\n\nYour method solves persistence.  \nWhat it doesn‚Äôt fully expose is¬†*when*¬†the current session is approaching saturation.\n\nThat invisible transition is the part I‚Äôve been digging into lately.\n\nCurious ‚Äî do you ever notice degradation before you manually trigger a summary/update cycle?",
              "score": 1,
              "created_utc": "2026-02-15 18:36:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jv7ah",
                  "author": "Gmafn",
                  "text": "You are right, degradation is definitely still possible. Altough i hadn't anything noticable since switching to this  method. \nBut the assumption would be that this depends highly on the user, their projects and style of inquiries.",
                  "score": 1,
                  "created_utc": "2026-02-15 18:45:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hqqqk",
          "author": "CategoryFew5869",
          "text": "Yeah this is because of the context window (memory). As the window moves, it starts to forget older things. I would recommend you try exporting the conversation and then reimporting it in a new chat session.",
          "score": 1,
          "created_utc": "2026-02-15 11:33:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hshs1",
          "author": "DanChed",
          "text": "Yep and I love it. It means its a test of my memory context window and then once Im done, I load a new chat and get it review afterwards.",
          "score": 1,
          "created_utc": "2026-02-15 11:49:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5js9w9",
              "author": "Only-Frosting-5667",
              "text": "Totally agree ‚Äî branching or restarting does help.  \nThe tricky part is knowing¬†*when*¬†to do it.\n\nMost people only notice drift after coherence is already compromised.\n\nI‚Äôve been experimenting with visualizing session load in real time so you can see the ‚Äúyellow zone‚Äù before things degrade. It changes the decision from reactive to proactive.\n\nIf you're curious, I built a small in-ChatGPT indicator for this:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nWould love your take, since you already work with structured resets.",
              "score": 2,
              "created_utc": "2026-02-15 18:31:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hu6bv",
          "author": "Sea-Sir-2985",
          "text": "you're not imagining it, this is a well-documented behavior with transformer-based models... the attention mechanism fundamentally struggles to maintain equal weighting across very long contexts so earlier instructions get \"diluted\" as the conversation grows\n\nthe practical fix i've settled on is treating conversations as disposable. instead of one long session i break things into focused chunks, each with the full context pasted at the top. sounds wasteful but it's way more reliable than hoping the model remembers what you said 30k tokens ago\n\nclaude handles this slightly better in my experience, especially opus with extended thinking... but even there once you hit 80k+ tokens the same drift happens. it's just physics of how attention works, not a bug anyone can fully fix",
          "score": 1,
          "created_utc": "2026-02-15 12:03:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jtgpj",
              "author": "Only-Frosting-5667",
              "text": "Exactly ‚Äî this is fundamentally an attention distribution issue, not a ‚Äúmemory bug.‚Äù\n\nI like how you framed it as physics rather than failure.\n\nBreaking conversations into disposable chunks is probably the most reliable mitigation today. It trades efficiency for deterministic behavior.\n\nWhat I find interesting is that the degradation curve is gradual, not binary. There‚Äôs usually a long ‚Äúyellow zone‚Äù before actual failure ‚Äî but the interface gives no signal that you‚Äôre entering it.\n\nThat silent transition is the part that fascinates me.\n\nCurious ‚Äî do you ever feel there‚Äôs a predictable threshold where quality starts bending, or does it vary heavily by task type?",
              "score": 1,
              "created_utc": "2026-02-15 18:37:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5jdmhk",
          "author": "DuckMcWhite",
          "text": "Does Branching into a new chat actually help fix this?",
          "score": 1,
          "created_utc": "2026-02-15 17:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5juzrf",
              "author": "Only-Frosting-5667",
              "text": "Short answer: yes ‚Äî but only partially.\n\nBranching helps because you reset the active attention window. You‚Äôre effectively reducing accumulated context weight.\n\nThe catch is this:  \nMost people don‚Äôt branch early enough.\n\nDegradation is gradual, not sudden. There‚Äôs usually a ‚Äúyellow zone‚Äù where coherence is already bending slightly, but not obviously broken yet.\n\nThat‚Äôs the tricky part ‚Äî the interface gives no signal for when you‚Äôve entered that zone.\n\nI‚Äôve been experimenting with visualizing session load directly inside ChatGPT to surface that threshold earlier.\n\nIf you‚Äôre curious:  \nüëâ [https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk](https://chrome.google.com/webstore/detail/kmjccgbgafkogkdeipmaichedbdbmphk)\n\nBut yes ‚Äî branching absolutely improves reliability compared to one massive continuous thread.",
              "score": 2,
              "created_utc": "2026-02-15 18:44:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qxxg2",
          "author": "recoveringasshole0",
          "text": "exasperated.gif",
          "score": 1,
          "created_utc": "2026-02-16 20:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wqjbv",
          "author": "emilioml_",
          "text": "Not only very long sessions if you continue in a new chat , sometimes degrades too",
          "score": 1,
          "created_utc": "2026-02-17 18:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e76cz",
          "author": "moxiemo99",
          "text": "Yes, it definitely degrades. When you notice it is doing this, recalibrate. Tell it what it's doing, ask it does it have confidence in its latest response and them have it check and double check the response for correctness and to remove all hallucination or unverifiable information and then try to keep the chat going as long as possble before you have to start all over. I've tried to get it to create a script to take into the next chat once the current one slows down, but I haven't had much success, I haven't liked the results of said prompts.",
          "score": 1,
          "created_utc": "2026-02-14 20:04:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fqzss",
              "author": "hellomistershifty",
              "text": "If it's starting to do this, it's too late and you need a new conversation with a fresh context. It can't remove information from its context.\n\nEven getting it to summarize well enough for a new conversation can be hard if it's already tripping. The commands to condense context in tools like Cursor or Codex work well, but it calls another LLM to do it and is expensive and slow. I don't know what the best answer is",
              "score": 2,
              "created_utc": "2026-02-15 01:30:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ehh3v",
              "author": "Only-Frosting-5667",
              "text": "I‚Äôve tried a similar ‚Äúrecalibration‚Äù approach.  \nIt helps temporarily, but I‚Äôve found that once early constraints start fading, the recovery isn‚Äôt fully reliable.  \nAlmost like the model technically still remembers ‚Äî but stops prioritizing correctly.\n\nThe cross-thread script idea is interesting. I‚Äôve had mixed results too. It‚Äôs hard to preserve both structure and nuance when migrating context.\n\nDo you usually restart at a fixed point (like a token threshold), or only once quality visibly drops?",
              "score": 1,
              "created_utc": "2026-02-14 21:00:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5enkyy",
                  "author": "moxiemo99",
                  "text": "I only restart if the script starts to drag. Believe it or not, if you send the model through some rigor, questioning its process, reminding it what its task is it will correct itself. After doing that, you then have the model repeat the task and then check itself to ensure it followed all.prior instructions. I also provide it an example of when it was doing the right thing- copy and paste.  This works amazingly well. Don't assume with the model, walk it through to get it back on track. I've had amazing results doing this.",
                  "score": 0,
                  "created_utc": "2026-02-14 21:33:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5f1ajl",
          "author": "TheGambit",
          "text": "Why do you keep posting this? Like, you keep posting it to this sub and all the other AI subs?",
          "score": 1,
          "created_utc": "2026-02-14 22:50:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g7ly1",
          "author": "TrainingEngine1",
          "text": ".",
          "score": 0,
          "created_utc": "2026-02-15 03:23:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h7ko1",
              "author": "Only-Frosting-5667",
              "text": "This is an impressive methodology.\n\nWhat you described almost reads like building a version-controlled operating system on top of a chat interface.\n\nThe interesting part for me is that the governance layer becomes necessary precisely because long-context drift is predictable.\n\nDo you find that even with charters and strict phase boundaries, subtle prioritization decay still appears over time?",
              "score": 1,
              "created_utc": "2026-02-15 08:29:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5h7wpz",
                  "author": "TrainingEngine1",
                  "text": "Why are you pasting a ChatGPT generated reply? Just realized your original post is also LLM generated.",
                  "score": 1,
                  "created_utc": "2026-02-15 08:32:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r2990u",
      "title": "Stick with ChatGPT Plus or switch to Claude / Gemini / Perplexity / AIO platforms",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "author": "magnumpl",
      "created_utc": "2026-02-11 20:52:13",
      "score": 54,
      "num_comments": 38,
      "upvote_ratio": 0.92,
      "text": "Hi. I‚Äôve been using ChatGPT Plus daily for a while now. Overall I like it, but I‚Äôm wondering if I'm missing out on other options which might be better to pay for.\n\nI mostly use AI for daily practical stuff, researching, summing up documents or threads, getting second opinions, cleaning up my writing etc. I recently started playing with image generator for content creations and ideas. Here is how ChatGPT summed up my usage:\n\n* Technical troubleshooting (yaml, wordpress, home servers, docker, networking, smart home, cameras, Home Assistant)\n* DIY / home projects (planning before doing anything expensive)\n* Business support (billing, coding logic, emails, contracts)\n* Writing help (emails, explanations, cleaning)\n* Light creative/marketing work (social posts, promos, restructuring content)\n* Translating/simplifying content (technical ‚Üí plain language)\n* Decision-making and sanity checks (‚Äúdoes this make sense?‚Äù, ‚Äúwhat am I missing?‚Äù)\n\nWhat matters most to me is good reasoning, being able to handle long context without losing track, and explanations that are clear but not dumbed down.   \nWhat I don't like about ChatGPT is that is doesn't handle long conversations i.e. troubleshooting, but I use projects as a workaround where I just start a new chat within a project when I am noticing that gpt is glitching. It is often overconfident while being wrong so I often have to sanity-check. I also need to keep correcting it's responses when it starts using too many emojis and bullet points. The image generator seems limited as well, it often trips when I want it to correct something, or corrects areas outside of my selection.\n\nI've seen people recommend Claude, Gemini, and Perplexity, and all-in-one platforms like Poe, Abacus, or OpenRouter. \n\n\\- Should I stay with ChatGPT or switch to other AI?  \n\\- Is an AIO platform worth it? It would be same price or even cheaper than ChatGPT Plus, but I can't find what would I miss out on with switching to these.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2990u/stick_with_chatgpt_plus_or_switch_to_claude/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v6xjz",
          "author": "qualityvote2",
          "text": "‚úÖ u/magnumpl, your post has been approved by the community!  \nThanks for contributing to r/ChatGPTPro ‚Äî we look forward to the discussion.",
          "score": 1,
          "created_utc": "2026-02-11 20:52:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v7cfy",
          "author": "Boring_Software1379",
          "text": "Commenting to follow along with any guidance you get. I'm getting frustrated with ChatGPT plus as well, mainly from a pricing standpoint ",
          "score": 19,
          "created_utc": "2026-02-11 20:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o553g0l",
              "author": "Dyleteyou",
              "text": "Ya I love it but $20 a month is wild. Not that it isn‚Äôt worth it just the budget thought for it just seems off",
              "score": 3,
              "created_utc": "2026-02-13 10:24:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z0to1",
          "author": "battleship_31",
          "text": "Following bc ChatGPT has been put on a super tight leash and it‚Äôs not what it was 6 months ago‚Ä¶not worth my $20 anymore",
          "score": 9,
          "created_utc": "2026-02-12 12:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516gz8",
              "author": "Homegrown_Phenom",
              "text": "üíØ agreed!  Getting üçø ready\n\nJust can't wait for tomorrow morning... Reddit/internet gonna break, peeps going to throw a fit once legacy models deprecated",
              "score": 1,
              "created_utc": "2026-02-12 19:16:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w75nh",
          "author": "MagmaElixir",
          "text": "TL;DR: Try Claude if a Projects folder function is more important to you with segregated chats and memory. Try Gemini if long context chats are way more important than a Projects folder function. \n\nGemini has a 1 million token context length, which makes it able to hold many or long documents or longer chat threads in one go. Though there is no projects folder function. \n\nI suggest trying Claude. It handles longer context better than ChatGPT by compacting content past its content window to still be visible in the chat thread. Claude also handles memory better. It can also search historic chat threads and save a manual memory, but it also has an automatic memory generated each night. The automatic memory is a TL;DR of your chat history and what Claude learns about you. The automatic memory and manual memory are served at the start of every chat thread. Claude is also more proactive about managing manual memory if you instruct it to in custom instructions. \n\nClaude also has a stronger Project folder system. You can attach many more files and it‚Äôll index them for RAG.  Each Project also has its own automatic memory and manual memory. What‚Äôs great about this is Claude without having to perform a tool call know your progress on a project at the start of every chat thread.",
          "score": 7,
          "created_utc": "2026-02-11 23:56:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4woxr6",
              "author": "niado",
              "text": "For anyone wanting to try something in the Gemini family, I highly recommend notebookLM. It has a project equivalent, and has multiple document stores within the project. It does have gemeni‚Äôs propensity for hallucination, but it can process documents in a quantity that other LLMs just can‚Äôt. It also can process video and audio though I haven‚Äôt used those functions yet.",
              "score": 5,
              "created_utc": "2026-02-12 01:42:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55ry3h",
                  "author": "TrainingEngine1",
                  "text": "> It does have gemeni‚Äôs propensity for hallucination\n\nIt can hallucinate sometimes or just be plain inconsistent, but I've been kind of amazed how despite using it maybe 5% of the time relative to ChatGPT and Claude taking up the other 95%, with that 5% Gemini has contributed some pretty valuable ideas/brainstorms that have gone on to be pretty important overall (validated them of course, since it can be very hit or miss). 3 Pro Preview in particular.",
                  "score": 1,
                  "created_utc": "2026-02-13 13:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vmtqs",
          "author": "Whoz_Yerdaddi",
          "text": "Gemini for deep research, image/diagram creation and video clips. \n\n Claude for coding and creative writing.  \n\nAFAIK GPT is still king for legal stuff, someone else will have to chime in on that one.",
          "score": 4,
          "created_utc": "2026-02-11 22:08:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ygwum",
          "author": "huaisha",
          "text": "IMHO, gemini is better in deep research(execution), but GPT is good at creative ideas(commander). GPT create the prompts to let Gemini create answers, and then copy back to GPT to review the answers. ",
          "score": 4,
          "created_utc": "2026-02-12 10:06:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v9k4t",
          "author": "ioweej",
          "text": "ive been using Gemini more and more often for my personal use. I seem to get a more 'real' experience from it, if that makes any sense. I dont know really what it is...but it works better personally for me..",
          "score": 8,
          "created_utc": "2026-02-11 21:04:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wp7n2",
          "author": "DnDnADHD",
          "text": "I have se GPT Products  for work (brainstorming ideas and then pressure testing them, since checking how I‚Äôm freezing things sometimes so that I‚Äôm not coming across too blunt, summarising non-confidential documents etc) and I also have a project for a couple of other things such as a writing project, Dungeons & Dragons, and a general personal one.\n\nI‚Äôve been finding that there is drift starting to occur in some of the projects particularly ones that have been going on for sometime or where I am trying to pull in information that might be scattered across a couple of threats.\n\nIt sounds like Claude might be something I should explore. If them becomes about the hassle of migrating everything",
          "score": 3,
          "created_utc": "2026-02-12 01:44:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xjwmw",
          "author": "Atoning_Unifex",
          "text": "I basically have to switch from GPTPlus to Claude. My job got everyone Claude licenses and we're under a company wide mandate to start using it.\n\nThe crazy part? There's almost ZERO guidance in what they want us to use it for. So I need to spend time w Claude at home, experimenting with it to try and get some results. I'm a very experienced UX Designer and this is an area where it's really the wild west out there.\n\nIt's pretty nuts",
          "score": 3,
          "created_utc": "2026-02-12 05:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xo7ng",
          "author": "Holiday_Revolution_4",
          "text": "Just subscribe to all of them for a months and see what works best? ",
          "score": 3,
          "created_utc": "2026-02-12 05:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w2zp9",
          "author": "eposta-sepeti",
          "text": "Stay with Chatgpt Plus.\n\nI‚Äôm on the Pro plan working with Codex GPT 5.3 High and Extra High. It‚Äôs practically limitless! üëçüöÄ",
          "score": 8,
          "created_utc": "2026-02-11 23:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yey3o",
          "author": "KESPAA",
          "text": "Don't limit yourself to one. You can get yearly \"pro\" versions of Gemini & perplexity for like $10/year. \n\nI also have GPT and Claude though work. In my opinion the only reason not to choose Claude over GPT is its lower limits. If you spread your usage across Gemini as well as Claude you shouldn't hit limits in their 5 hour window. \n\nHonestly mate try them all, it's worth understanding the differences.",
          "score": 2,
          "created_utc": "2026-02-12 09:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o541w5j",
          "author": "kaline06",
          "text": "I would give you a recommendation, but then tomorrow one of them will release a new model that surpasses the others and then what? I struggle with this, too. I‚Äôm paying for all of them at the moment. I like to pit them against each other. Eventually I think we‚Äôll be able to pick one and stick with it, but right now things are just changing so quickly.",
          "score": 2,
          "created_utc": "2026-02-13 04:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wppoc",
          "author": "niado",
          "text": "ChatGPT is still the best overall. You do need good custom instructions at the global and project levels to get full value out of it, but it‚Äôs so versatile and adheres to custom instructions so well that trying other llms is always jarring for me. \n\nI do use perplexity often. And notebookLM. Highly recommend both of those, but they are specialty platforms. Perplexity is an AIO, but its killer app is a specialized search and research system, with a forced search step in every prompt. NotebookLM is absolutely amazing for working with documents.",
          "score": 4,
          "created_utc": "2026-02-12 01:47:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xehu0",
          "author": "mbcoalson",
          "text": "If ChatGPT‚Äôs context window (how much it can handle at once) frustrates you, Claude probably won‚Äôt magically fix that. But in my experience, Claude‚Äôs reasoning does feel different. It tends to think through problems in a way that‚Äôs more structured.\nI can‚Äôt say much about Gemini. I‚Äôve barely used it. I do know it supports a very large context window, so if long conversations or big documents are your main concern, that‚Äôs a plus.\nI haven‚Äôt used the other models you mentioned enough to comment.\nPersonally, I use Claude Code daily and ChatGPT Codex semi-regularly. If you‚Äôre already in the ChatGPT ecosystem, I‚Äôd try Codex first. Ask ChatGPT how to set it up. Tell it you want to learn how to use Skills, ideally starting with a well-starred GitHub repo to build some kind of memory system. You‚Äôll learn a lot just by doing that.\nOnce you let an agent work from the command line, it becomes way more powerful. But be careful:\nDon‚Äôt run it as admin/root.\nKeep it in a dedicated project folder.\nUse Docker or a VM if you can.\nReview commands before they run.\nDon‚Äôt casually expose API keys or credentials.\nUse version control so you can undo mistakes.\nCLI agents are powerful. Just don‚Äôt give them the keys to your whole machine on day one.",
          "score": 2,
          "created_utc": "2026-02-12 04:23:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wwpl5",
          "author": "counterhit121",
          "text": "I use GPT plus, and have tried the free versions of Claude, Gemini, Perplexity.  Perplexity sucked.  Gemini felt the closest to GPT, and Claude felt like a distant third.  Gemini seems to fish for further engagement by asking followup questions whereas GPT offers some choices, often impressively well-reasoned ones, on how to next proceed.",
          "score": 1,
          "created_utc": "2026-02-12 02:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x0e8n",
          "author": "lxe",
          "text": "Try codex CLI for long context and troubleshooting.",
          "score": 1,
          "created_utc": "2026-02-12 02:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xw1sl",
          "author": "Electronic-Cat185",
          "text": "for your mix of troubleshoooting reasoning and long context claude is probably the one most people compare seriously to chatgpt. gemini can be strong for gooogle ecosystem work and perplexity is great for research but feels more like a search layer than a thinking partner. aio platforms are convenient but you usually lose early access to new features and tighter integrations so it depends if flexibility matters more than depth for you.",
          "score": 1,
          "created_utc": "2026-02-12 06:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xzbye",
          "author": "Apprehensive_Half_68",
          "text": "With Gemini you get 4x CGPT context size of 1 million but the ability to add 5 more free family accounts to whatever level you buy, effectively 6 accounts, for the price of 1. I think you may be missing a whole category of productivity by not using them headless to do routine tasks. Think at the command line \"codex.exe \" arrange z\"  in by giving i",
          "score": 1,
          "created_utc": "2026-02-12 07:15:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ycg6e",
          "author": "st1ckmanz",
          "text": "Losing the context in long conversations should be a problem of all AI since the working principles are the same and I know exactly what you mean. The way it works is as the chat gets longer, the resources it needs grow exponentially so while it \"understands you better\", it also starts to halluciante. I explicitly told mine to warn me when we're around %80 tokens and never make things up. It didn't do this for a while but now it works. So when we come to an end of a chat, I tell it to give a summary and a snaphot and I start a new chat with those. By the way, I use chatgpt plus and I use it for daily stuff and I started to use it for coding a hobby game. I hear claude is better at coding, but chatgpt has been pretty good for what I needed so far. Unfortunately for coding the general context is not enough, and a lot of functions, variables need to be exactly the same so still we're losing some of them or the idea why we have them when we switch to a new chat. I don't know how this could be fixed as this is the way AI works...the more you throw at it, the more it understands you and eventually loses its shit at some point when it understands you the best...",
          "score": 1,
          "created_utc": "2026-02-12 09:23:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ydd21",
          "author": "Compilingthings",
          "text": "For best results use as many as possible.",
          "score": 1,
          "created_utc": "2026-02-12 09:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5265e2",
          "author": "z_alex",
          "text": "i pay for 3:\n- gemini is best at deep research¬†\n- been using claude code for coding (switching to codex tho as it seems to be better)\n- cgpt for daily driver type of things¬†",
          "score": 1,
          "created_utc": "2026-02-12 22:07:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c09kz",
          "author": "ManifestPotential",
          "text": "For best results on long projects replace the pre learn files and update it with the chat hostory",
          "score": 1,
          "created_utc": "2026-02-14 13:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oo7vp",
          "author": "Thommynat0r",
          "text": "tested some minutes ago: if you try to cancel your subscription, you get one month for free :P",
          "score": 1,
          "created_utc": "2026-02-16 14:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wcqr7",
          "author": "Different_Rest_1842",
          "text": "In that case, you can just use Genspark instead. You won‚Äôt get the full functionality of GPT, but it‚Äôs much more affordable, and the subscription includes access to Gemini, Claude, and even Grok. The answers are a bit different from the Pro versions, but you can still get a decent feel for each model.",
          "score": 1,
          "created_utc": "2026-02-12 00:29:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4voa38",
          "author": "riluzol",
          "text": "First of all, I am not coder.\n\nI do have chatgpt plus; copilot premium, gemini pro, perplexity pro, kimi 2.5 (just tried it this week)\n\nI do use for everyday tasks, academic research, translating, writing help etc  \nChatgpt plus is far more superior then others; especially if you use 5.2 thinking mode. Aside from being slow, it's very good. Of course, I'd prefer a slow but efficient AI to a fast but less efficient one.\n\nGemini is full of filler and do not follow my custom instructions.    \nPerplexity is like new google search for me which I rarely use it nowadays.  \nCopilot premium...I don't want to talk about this too much, but it's definitely the worst AI I've ever tried.  \n\n\n",
          "score": 0,
          "created_utc": "2026-02-11 22:15:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhjik",
          "author": "Special_Tangelo2757",
          "text": "Stick with chat. Tried the others. They are just behind missing features like basic search of chats",
          "score": 0,
          "created_utc": "2026-02-12 04:45:34",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r38sku",
      "title": "Can we PLEASE get ‚Äúreal thinking mode‚Äù back in GPT ‚Äì instead of this speed-optimized 5.2 downgrade?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "author": "LilithAphroditis",
      "created_utc": "2026-02-12 23:16:59",
      "score": 45,
      "num_comments": 16,
      "upvote_ratio": 0.85,
      "text": "I‚Äôve been using GPT more or less as a second brain for a few years now, since 3.5. Long projects, planning, writing, analysis, all the slow messy thinking that usually lives in your own head. At this point I don‚Äôt really experience it as ‚Äúa chatbot‚Äù anymore, but as part of my extended mind.\n\nIf that idea resonates with you ‚Äì using AI as a genuine thinking partner instead of a fancy search box ‚Äì you might like a small subreddit I started: r/Symbiosphere. It‚Äôs for people who care about workflows, limits, and the weird kind of intimacy that appears when you share your cognition with a model. If you recognize yourself in this post, consider this an open invitation.\n\nWhen 5.1 Thinking arrived, it finally felt like the model matched that use case. There was a sense that it actually stayed with the problem for a moment before answering. You could feel it walking through the logic instead of just jumping to the safest generic answer. Knowing that 5.1 already has an expiration date and is going to be retired in a few months is honestly worrying, because 5.2, at least for me, doesn‚Äôt feel like a proper successor. It feels like a shinier downgrade.\n\nAt first I thought this was purely ‚Äú5.1 versus 5.2‚Äù as models. Then I started looking at how other systems behave. Grok in its specialist mode clearly spends more time thinking before it replies. It pauses, processes, and only then sends an answer. Gemini in AI Studio can do something similar when you allow it more time. The common pattern is simple: when the provider is willing to spend more compute per answer, the model suddenly looks more thoughtful and less rushed. That made me suspect this is not only about model architecture, but also about how aggressively the product is tuned for speed and cost.\n\nInitially I was also convinced that the GPT mobile app didn‚Äôt even give us proper control over thinking time. People in the comments proved me wrong. There is a thinking-time selector on mobile, it‚Äôs just hidden behind the tiny ‚ÄúThinking‚Äù label next to the input bar. If you tap that, you can change the mode.\n\nAs a Plus user, I only see Standard and Extended. On higher tiers like Pro, Team or Enterprise, there is also a Heavy option that lets the model think even longer and go deeper. So my frustration was coming from two directions at once: the control is buried in a place that is very easy to miss, and the deepest version of the feature is locked behind more expensive plans.\n\nSwitching to Extended on mobile definitely makes a difference. The answers breathe a bit more and feel less rushed. But even then, 5.2 still gives the impression of being heavily tuned for speed. A lot of the time it feels like the reasoning is being cut off halfway. There is less exploration of alternatives, less self-checking, less willingness to stay with the problem for a few more seconds. It feels like someone decided that shaving off internal thinking is always worth it if it reduces latency and GPU usage.\n\nFrom a business perspective, I understand the temptation. Shorter internal reasoning means fewer tokens, cheaper runs, faster replies and a smoother experience for casual use. Retiring older models simplifies the product lineup. On a spreadsheet, all of that probably looks perfect.\n\nBut for those of us who use GPT as an actual cognitive partner, that trade-off is backwards. We‚Äôre not here for instant gratification, we‚Äôre here for depth. I genuinely don‚Äôt mind waiting a little longer, or paying a bit more, if that means the model is allowed to reason more like 5.1 did.\n\nThat‚Äôs why the scheduled retirement of 5.1 feels so uncomfortable. If 5.2 is the template for what ‚ÄúThinking‚Äù is going to be, then our only real hope is that whatever comes next ‚Äì 5.3 or whatever name it gets ‚Äì brings back that slower, more careful style instead of doubling down on ‚Äúfaster at all costs‚Äù.\n\nWhat I would love to see from OpenAI is very simple: a clearly visible, first-class deep-thinking mode that we can set as our default. Not a tiny hidden label you have to discover by accident, and not something where the only truly deep option lives behind the most expensive plans. Just a straightforward way to tell the model: take your time, run a longer chain of thought, I care more about quality than speed.\n\nFor me, GPT is still one of the best overall models out there. It just feels like it‚Äôs being forced to behave like a quick chat widget instead of the careful reasoner it is capable of being. If anyone at OpenAI is actually listening to heavy users: some of us really do want the slow, thoughtful version back.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r38sku/can_we_please_get_real_thinking_mode_back_in_gpt/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o52jgcl",
          "author": "qualityvote2",
          "text": "u/LilithAphroditis, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 23:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52kumn",
          "author": "Ari45Harris",
          "text": "https://preview.redd.it/wcpruevmd5jg1.png?width=1179&format=png&auto=webp&s=b9512a255fe36c450001008a71cb032d8c609d1c\n\nNot sure about you but I have access to these different thinking times for 5.2 thinking.\n\nAnd for pro, I have standard and extended.",
          "score": 10,
          "created_utc": "2026-02-12 23:24:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52l11t",
              "author": "LilithAphroditis",
              "text": "I don't! Not in mobile. In PC I have \"Extended\" option. I'm a Plus subscriber.",
              "score": 4,
              "created_utc": "2026-02-12 23:25:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o52lkhp",
                  "author": "Pasto_Shouwa",
                  "text": "https://preview.redd.it/6z9n36ine5jg1.jpeg?width=1440&format=pjpg&auto=webp&s=8059bc21e9b85f7adb2735a933bb5895fd3bcfa3\n\nPress on the \"Thinking\" label and you'll be able to change it. Yeah, it's quite hidden, I know.\n\nAlways choose Extended (unless you really need the response to be quick), Standard is really quantized.",
                  "score": 7,
                  "created_utc": "2026-02-12 23:28:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53xsi8",
          "author": "RenegadeMaster111",
          "text": "I agree.  5.1 thinking is closest to the legacy 4o (before OpenAI screwed with it), which was very good.  \n\nHoping they keep it onboard.  No clue why they even released 5.2.  It‚Äôs a step backwards like the GPT-5 rollout.",
          "score": 3,
          "created_utc": "2026-02-13 04:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52r4p2",
          "author": "qunow",
          "text": "I feel like they launched 5.2 so short after 5.1 back then was because 5.1 was the more resource intensive update, that they don't want to make it a default, so they still keep it available in menu for people to choose but only when intentionally selecting",
          "score": 3,
          "created_utc": "2026-02-13 00:00:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52se0w",
          "author": "Rare_Tumbleweed5548",
          "text": "I just mentioned it in another post; I wish there was a plan between Plus and Pro where you could use heavy thinking.",
          "score": 3,
          "created_utc": "2026-02-13 00:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53yx9o",
          "author": "Kat-",
          "text": "OpenAi recently halved the thinking time for each reasoning effort category except for Heavy with gpt-5.2-thinking.\n\n\nSee:¬†\n- https://www.reddit.com/r/OpenAI/comments/1qv77lq/chatgpt_lowered_reasoning_efforts_juice/\n- https://news.ycombinator.com/item?id=46879372#46887150",
          "score": 2,
          "created_utc": "2026-02-13 04:32:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54aqd5",
              "author": "Oldschool728603",
              "text": "Extended was restored to its original value. Read OpenAI's amusing explanation in its Feb. 4 changelog entry:\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)",
              "score": 3,
              "created_utc": "2026-02-13 06:02:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o547lv9",
          "author": "VaderOnReddit",
          "text": "I've noticed this as well\n\nThe thinking models used to go a bit deeper in the past, for any complex problems I gave to it. Good enough for me to use it to form a detailed phase-wise plan to tackle something, learn something, etc.\n\nDoes anyone have any experiences with other models which are capable of doing this **now** ?",
          "score": 1,
          "created_utc": "2026-02-13 05:37:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54axhn",
              "author": "Oldschool728603",
              "text": "Light and standard are now lighter. Extended has been restored to what it was. Heavy never changed.\n\n[https://help.openai.com/en/articles/6825453-chatgpt-release-notes](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)\n\nScroll to Feb. 4.",
              "score": 2,
              "created_utc": "2026-02-13 06:04:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5a6sc3",
          "author": "YourKemosabe",
          "text": "Wait 5.1 is being retired?",
          "score": 1,
          "created_utc": "2026-02-14 03:30:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52ndma",
          "author": "Mentosbandit1",
          "text": "Even on extended thinking it barely thinks even on pro heavy thinking barely thinks",
          "score": 1,
          "created_utc": "2026-02-12 23:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o549lbs",
          "author": "ProfessorFull6004",
          "text": "Switch to Claude.  Opus will blow you away for this kind of work.  I made the switch recently and I‚Äôm never going back to GPT.  Its trash now.",
          "score": 0,
          "created_utc": "2026-02-13 05:53:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54bxec",
              "author": "Oldschool728603",
              "text": "Actually, Opus 4.6 is the first Claude model with \"adaptive\" reasoning: lower thinking budget for questions it doesn't consider hard‚Äîi.e., unrelated to STEM, business, and agentic matters.\n\nOpenAI came down with this infection in GPT-5.1. It got worse in 5.2.\n\nNow it has spread to Claude.",
              "score": 3,
              "created_utc": "2026-02-13 06:12:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3qib4",
      "title": "Tested updated Deep Think (Gemini 3.1 Pro) vs. GPT 5.2 Pro",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "author": "PerformanceRound7913",
      "created_utc": "2026-02-13 14:24:53",
      "score": 30,
      "num_comments": 10,
      "upvote_ratio": 0.88,
      "text": "I tested both on a data science problem. Updated Deep Think is significantly better than its previous version, but the accompanying harness is still not very strong. GPT 5.2 Pro, on the other hand, thinks longer and uses tools much more efficiently. It actually solves your problem end to end. \n\nhttps://preview.redd.it/483qat63u9jg1.png?width=1228&format=png&auto=webp&s=a674146c9406fcef251310f5e764b4cd17b2076e\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3qib4/tested_updated_deep_think_gemini_31_pro_vs_gpt_52/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o562rcj",
          "author": "qualityvote2",
          "text": "u/PerformanceRound7913, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 14:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o566uhz",
          "author": "Ari45Harris",
          "text": "I‚Äôve noticed that ChatGPT reasoning models have a better brain than most other AI models",
          "score": 10,
          "created_utc": "2026-02-13 14:46:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5aoh2b",
          "author": "sprucenoose",
          "text": "GPT 5.2 Pro Extended Thinking is surreal to me. I have a hard time not characterizing it as a form of AGI.",
          "score": 3,
          "created_utc": "2026-02-14 05:43:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fpy2r",
              "author": "RoughlyCapable",
              "text": "This is very underdiscussed IMO, regardless of whether they actually are AGI GPT5-Pro models are the first models where I genuinely find it hard to distinguish them between what I thought AGI was capable of.",
              "score": 0,
              "created_utc": "2026-02-15 01:23:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o1nwu",
          "author": "TrainingEngine1",
          "text": "5.2 Pro with Extended Thinking? Or by Deep Think do you mean Deep Research?\n\nBecause I find 5.2 Pro with Extended Thinking far better than the ChatGPT Deep Research which actually sucked. It didn't let me pick a model for it either (I would've done 5.2 Pro) which probably relates to the quality drop I noticed. Agent Mode wasn't much better where I couldn't pick a model too.",
          "score": 1,
          "created_utc": "2026-02-16 11:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57rfjo",
          "author": "Simlah",
          "text": "How good is it for forex EAs?",
          "score": -1,
          "created_utc": "2026-02-13 19:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585hx2",
          "author": "Deep_Somewhere2419",
          "text": "How does your prompt structure",
          "score": -2,
          "created_utc": "2026-02-13 20:28:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o585ik7",
          "author": "Deep_Somewhere2419",
          "text": "Looks",
          "score": -3,
          "created_utc": "2026-02-13 20:28:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6ht58",
      "title": "Are there meaningful benefits for using Perplexity/ChatGPT's desktop apps (vs. web interface ), like Claude desktop app?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6ht58/are_there_meaningful_benefits_for_using/",
      "author": "TheLawIsSacred",
      "created_utc": "2026-02-16 18:35:37",
      "score": 16,
      "num_comments": 12,
      "upvote_ratio": 0.92,
      "text": "Power users, please advise.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6ht58/are_there_meaningful_benefits_for_using/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5q7sy1",
          "author": "qualityvote2",
          "text": "Hello u/TheLawIsSacred üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-16 18:35:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qseyd",
          "author": "darkyy92x",
          "text": "IMO ChatGPT desktop app is worse than web. You can't control the thinking (extended thinking etc), the app feels slower than web etc.\n\nOne advantage would be to use the keyboard shortcut to instantly start a conversation or sending screenshots easier.",
          "score": 11,
          "created_utc": "2026-02-16 20:13:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rbxjk",
          "author": "lyncisAt",
          "text": "On an Apple Silicon Mac, the app is much more performant (especially for long chats) than the web or Windows app. Night & Day",
          "score": 8,
          "created_utc": "2026-02-16 21:49:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rzmb0",
          "author": "ThePlotTwisterr----",
          "text": "there is for codex, having the power to use mcps and your terminal means your AI can do everything for you. i use codex for the dumbest shit sometimes. like installing and compiling a c++ project with messy dependencies and versioning, or organizing my files, or even just dumb things like fixing errors on arch linux.\n\nyou can use the codex cli and swap the model to normal gpt too, but i cannot imagine ever using a tool that can‚Äôt use my terminal these days, i would just lose so much power",
          "score": 4,
          "created_utc": "2026-02-16 23:55:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yn0ei",
              "author": "TheLawIsSacred",
              "text": "Thanks. I had a busy few weeks, but I'm finally going to learn how to use Codex and - yikes - add another member to my key AI Panelists (right now, Claude Desktop app is my \"First Among Equals,\" but all the constant chatter over Codex, sustained over enough time to make me think it's not just hype, means I need to look, and maybe see if there is a new \"First Among Equals\" in town, lol).\n\nIf you have a few seconds, any tips that you can send my way, to ease any friction points for a starter or beginner?",
              "score": 1,
              "created_utc": "2026-02-18 00:08:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s7q9a",
          "author": "elaineisbased",
          "text": "It might make it ever so slightly easier to attach a file or maybe have better performance in a full web browser but I don‚Äôt know. I am a copilot user in regularly use the desktop app but copilot mode in Microsoft edge will help switch your search over to Bing if it would provide better results than AI. For example if you just typed in Twitter it would make more sense to show you search results so you can get to Twitter",
          "score": 3,
          "created_utc": "2026-02-17 00:42:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u9xqj",
          "author": "raholl",
          "text": "no there are no benefits, they make desktop app for a reason to not have any meaningful benefits... /s",
          "score": 2,
          "created_utc": "2026-02-17 09:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ynwa2",
              "author": "TheLawIsSacred",
              "text": "I mean Claude desktop app is genuinely useful, so I was just curious if Perplexity's or ChatGPT's offer similar features as Claude, such as the ever expanding number of Connectors and Extensions, or even more old school MCP Server connectors. \n\nComet is a separate issue and I sometimes wonder if I should check it out.",
              "score": 1,
              "created_utc": "2026-02-18 00:13:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s2nlc",
          "author": "manjit-johal",
          "text": "For most workflows the web app is fine, but desktop apps can help if you rely on global shortcuts, mic access, or quick window switching without browser overhead. I‚Äôve found the main difference is less about model quality and more about UX friction; if you‚Äôre constantly context-switching, native apps feel faster even if the backend is identical. ",
          "score": 1,
          "created_utc": "2026-02-17 00:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tsg7s",
              "author": "AI-Coming4U",
              "text": "This is why I use the apps for Claude and ChatGPT. With a small city of tabs open, I don't want to search for AI. And when I go to the native app, I feel like I'm working with Claude or GPT. Then I go back to solo mode in my browser. \n\n",
              "score": 2,
              "created_utc": "2026-02-17 07:08:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ynyv0",
              "author": "TheLawIsSacred",
              "text": "I mean Claude desktop app is genuinely useful, so I was just curious if Perplexity's or ChatGPT's offer similar features as Claude, such as the ever expanding number of Connectors and Extensions, or even more old school MCP Server connectors. \n\nComet is a separate issue and I sometimes wonder if I should check it out.",
              "score": 1,
              "created_utc": "2026-02-18 00:13:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u1kp8",
          "author": "i_sin_solo_0-0",
          "text": "Bruh I‚Äôll tell ya perplexity if you can get used the comet app is fun",
          "score": 1,
          "created_utc": "2026-02-17 08:33:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2w7ee",
      "title": "Sharing a dedicated roleplaying AI (powered by Gemini 3) with near unlimited unlimited memory, perfect character consistency, no rejections!",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "author": "Jazzlike_Comment3774",
      "created_utc": "2026-02-12 15:20:56",
      "score": 15,
      "num_comments": 2,
      "upvote_ratio": 0.64,
      "text": "I run a small roleplaying group in Kansas and I‚Äôve been messing with AI RP since early ChatGPT / CharacterAI days. The tech has improved a lot, but in longer sessions I still kept running into the same few issues:\n\n* Memory: once a thread gets long, details get fuzzy and continuity breaks\n* Character consistency: especially with multiple NPCs, personalities/voice start blending\n* Rejections: some RP setups involve mature themes, and many tools shut down quickly even when the intent is story/character work\n\nOver the past 6 months I built a project called ‚ÄúRoleplay Game Master‚Äù to address those AI roleplaying issues:\n\n* Memory: uses vector-based retrieval to maintain context and coherence in long threads\n* Character consistency: use the best instruction following and roleplaying model (Gemini 3) to power the underlying itnelligence\n* Rejections: custom prompting to maximize creative freedom and to minimize rejections\n\nYou can try it here: [https://www.jenova.ai/a/roleplay-game-master](https://www.jenova.ai/a/roleplay-game-master)\n\nHere are some user review:\n\nhttps://preview.redd.it/4wpb2wj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=1e754c557aff50ba835dff2e7414a8589b693a18\n\nhttps://preview.redd.it/9q6dxwj3z2jg1.jpg?width=1178&format=pjpg&auto=webp&s=143a5006741509c37cf4503bfa0f16b9a5db8bcd",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2w7ee/sharing_a_dedicated_roleplaying_ai_powered_by/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4zs5rx",
          "author": "qualityvote2",
          "text": "u/Jazzlike_Comment3774, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 15:20:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5287wn",
          "author": "Ramenko1",
          "text": "Please provide more detail on this. I don't do role-playing, but the enhanced memory context has me curious. What other uses can I use Jenova for? And how does it compare to Chatgpt or Claude?",
          "score": 1,
          "created_utc": "2026-02-12 22:17:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6zs2g",
      "title": "Why I‚Äôm Moving Most of My Workflow from Claude to Codex (Non-Developer Perspective)",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6zs2g/why_im_moving_most_of_my_workflow_from_claude_to/",
      "author": "tgandur",
      "created_utc": "2026-02-17 07:37:07",
      "score": 15,
      "num_comments": 6,
      "upvote_ratio": 0.76,
      "text": "**TL;DR:** I‚Äôm a non-developer using LLMs for structured, metadata-heavy workflows (literature reviews, lecture prep, Obsidian). Claude impressed me at first, but I encountered workflow shortcuts and vault instability over time. After testing the new Codex Mac app on GPT Pro, I found it more predictable and compliant with strict step-by-step processes. This is about workflow fit, not model superiority.\n\n---\n\nI‚Äôm not a developer. I use LLMs primarily for literature reviews, structured lecture preparation, system organization, VPS setup, and managing a complex Obsidian vault with heavy metadata.\n\nFor a long time, I was a user of Claude (Opus/Max). Initially, it was impressive. But my workflows are strict, step-by-step, and highly defined. Over time, I noticed Claude would sometimes optimize the workflow rather than execute it exactly as written. Even with detailed instructions, it occasionally took shortcuts.\n\nThe breaking point for me was Obsidian vault stability. I experienced miswritten front matter, invented tags, and gradual structural drift. I kept expanding the instruction files to add guardrails, but increasing complexity seemed to reduce stability. Simplifying the vault structure didn‚Äôt fully solve it. Heavy workflow sessions also quickly consumed the Max quota.\n\nAfter the release of the new Codex Mac app, I decided to test it on the GPT Pro plan.\n\nWhat stood out:\n\n1. It respects explicitly defined workflows. When constraints are clear, it follows them.\n2. It adjusts quickly when corrected and stays within the structure.\n3. It proactively suggests system-level improvements (e.g., weekly vault health checks, metadata validation).\n4. It documents its actions extensively, which makes multi-session continuation easier.\n5. It performs reliably even with a minimal Agent MD configuration.\n\nFor literature review pipelines and structured planning, this predictability matters. I need a model that consistently executes predefined processes, rather than compressing or optimizing them away.\n\nTo be fair, Claude remains strong in writing and can feel more natural stylistically in some contexts. This isn‚Äôt a ‚ÄúClaude vs. Codex‚Äù claim. It‚Äôs more about workflow fit. For my use case, Codex currently feels more controllable and stable for long-horizon, metadata-heavy systems.\n\nIt‚Äôs not flawless. It still makes simple mistakes. The difference, in my experience, is that those errors are usually local and easy to correct, rather than structural.\n\nI‚Äôm curious how others here approach complex, structured workflows with either system, especially outside pure coding use cases.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6zs2g/why_im_moving_most_of_my_workflow_from_claude_to/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5tvlyg",
          "author": "qualityvote2",
          "text": "Hello u/tgandur üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-17 07:37:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tzh9l",
          "author": "Jessgitalong",
          "text": "Honestly, a less thinking, more doing model is right for what you need.",
          "score": 2,
          "created_utc": "2026-02-17 08:13:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uadkt",
          "author": "IversusAI",
          "text": "I have found a similar experience with Claude versus Codex or GPT 5.2. The models are better at different things. This is one reason why I stay with Cursor, at least right now, because I need the right model for the job and that changes often throughout the day.",
          "score": 2,
          "created_utc": "2026-02-17 09:58:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u2ysw",
          "author": "Brice_Leone",
          "text": "Thanks for the detailed info; really useful for non-coders like myself\n\nquick question (apologies if I misunderstood): what's a concrete use case where you found GPT to be more valuable?\n\nFor context, I'm a project manager - quite beginner on the technical side and I'm considering switching from Gemini to either Claude Code or Codex. I've found that even Gemini, when given enough context, can really help manage a project end to end. example I'll feed it the prerequisites of a client solution, then ask as many questions as possible to prepare for a workshop and make sure the need is clearly scoped. It works well, but Gemini has become quite lazy with shorter and less detailed outputs\n\nI'm interested in Claude Code for its plan mode, skills and overall structure. But curious- for this kind of use case (project scoping, requirement analysis, workshop prep), would you say Codex is the better option?",
          "score": 1,
          "created_utc": "2026-02-17 08:47:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vwoa1",
          "author": "IndyHCKM",
          "text": "Definitely feel like GPT provides better output if you simply want to ask and wait. Claude iterates so much faster though. In the time GPT or Codex get me an output, I can often do 3 or 4 rounds of work with Claude, Code, or Cowork and the output compared between 1 turn of GPT to 3 or 4 turns of Claude is totally different.\n\n\nBut when I'm busy and can't chat much, GPT is great.",
          "score": 1,
          "created_utc": "2026-02-17 16:07:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xf2i4",
          "author": "cheesecakegood",
          "text": "How much of this is possibly recency or newness bias, because you mentioned being initially impressed by Claude as well? Curious how long you‚Äôve been testing",
          "score": 1,
          "created_utc": "2026-02-17 20:27:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4n4t7",
      "title": "Best AI for Google Sheets",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "author": "Halvey15",
      "created_utc": "2026-02-14 15:15:48",
      "score": 14,
      "num_comments": 17,
      "upvote_ratio": 0.83,
      "text": "I'm fairly inexperienced with AI so I apologize if there are some dumb questions in here. \n\nLong story short, I've been using ChatGPT for about a year to assist with B2B sales. I have a thread where I can post a company's website and it will return an analysis of that company, what their needs are, and where our best in might be. I have a thread for prospect discovery. And I have a thread for drafting quick emails, among a few other threads.\n\nA few weeks ago I had the idea of trying to create a CRM within ChatGPT, to expand on the Google Sheet that I have used over the years for organization, and so far the AI has been useful. But I have some concerns with long term viability:\n\n1.) I've noticed over the past year that ChatGPT does not do well on long threads, whether that be slowing down or losing context. I'm afraid that I'm going to need to create new threads so often that it won't be worth my time, and that I may also lose context while switching over to a new thread.\n\n2.) ChatGPT apparently can't share information between threads? It would be nice if my emails thread had access to my CRM thread. That way I wouldn't have to provide context for each email.  \n\n3.) Redundancy. I'm still using the Google Sheet as a backup, so I'm entering info on the Google Sheet and then pasting it into ChatGPT. If we could remove a step there, that would also be nice. \n\nI really just want something where I can enter the info in Google Sheets, and then find an AI that can get live access to the the Google Sheet. So when I ask it a question or ask it for tasks for the day, it has all of that information without having to load all of the prospect info into a thread. \n\nLike I said, I haven't explored the AI world too much. I just learned about Claude the other day. I downloaded Claude and gave it permission to view my Google Drive. But it is telling me that it can't read Google Sheets? I knew Google had an AI, but didn't realize that Gemini was a full chatbot. So maybe that is the right move? \n\nDoes anyone have suggestions before I put a few hours into just experimenting?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4n4t7/best_ai_for_google_sheets/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5cmhn5",
          "author": "qualityvote2",
          "text": "u/Halvey15, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-14 15:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cofz9",
          "author": "Subject-Street-6503",
          "text": "I believe ChatGPT has a connector that can read directly from GDrive  \nYou should be able to find it in account settings",
          "score": 3,
          "created_utc": "2026-02-14 15:26:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cwyhx",
              "author": "Halvey15",
              "text": "That's something I definitely should have thought of before posting this lol. That seems to be a viable option. I am still interested in learning more about the other AIs, to see if there might be a better fit though. \n\nThank you!",
              "score": 1,
              "created_utc": "2026-02-14 16:10:09",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5gb46k",
              "author": "niado",
              "text": "It does but it barely works. It sucks because when it does work it‚Äôs amazing.",
              "score": 1,
              "created_utc": "2026-02-15 03:49:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5cwy3l",
          "author": "mgoulart",
          "text": "Google Gemini has built in Sheets integration.",
          "score": 3,
          "created_utc": "2026-02-14 16:10:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cxkw6",
              "author": "Halvey15",
              "text": "I figured it did. I'll have to play around with Gemini a bit to see if that is a better fit for me. \n\nThe massive advantage that ChatGPT has right now is that it has a year's worth of context, so it knows my company so well at this point. It would be difficult to start over from scratch again.",
              "score": 2,
              "created_utc": "2026-02-14 16:13:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dihva",
                  "author": "Odd-Opinion-5105",
                  "text": "There was just a thread on exporting data from chat got to google",
                  "score": 2,
                  "created_utc": "2026-02-14 17:58:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5gb597",
                  "author": "niado",
                  "text": "Try NotebookLM !",
                  "score": 1,
                  "created_utc": "2026-02-15 03:49:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5d1a1j",
          "author": "JamesGriffing",
          "text": "Google has something called Google App Scripts that allows us to add functionality to many Google products. One of them being Google Sheets.\n\nWith Google app scripts you're able to create custom formulas, or even user interfaces like a chat side bar.\n\nChatGPT is available to be used via OpenAI's API.\n\nSo this means you're able to use ChatGPT directly within Google Sheets. ChatGPT itself can guide you on how to set this up and write the scripts needed for you.\n\nperhaps in one of the threads that contains a lot of this context on why you use the Google sheet you can ask something like \"Based on our activity, and what I am trying to achieve with Google Sheets, educate me on how I can best utilize Google App Scripts with the OpenAI API. Assume I am a beginner\"\n\nIf this is something others would find useful then I can create a post/guide going over all of this in far more detail.",
          "score": 3,
          "created_utc": "2026-02-14 16:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cxdcm",
          "author": "BYRN777",
          "text": "If you're working with Google Sheets, the best AI is Gemini because it's now in every native Google app, from YouTube to Google Keep, Google Calendar, Google Photos, Google Docs, Google Slides, and Google Sheets. We can't have a Gemini within Google Sheets itself; you can either upload a Google Sheets document or give a Google Drive. When you're typing up your prompt, you can select the file from Google Drive, then open it and work with it. Any live changes you make with Google Workspace apps will update the file.\n\nFor instance, let's say you're working on a thread in Google Docs, asking questions or getting info, and you make a change in Google Sheets, it will update in the thread at the same time. Native Google apps can change them. The way I do this is: let's say they upload a Google Doc. I ask it to make these changes, and then open it in Canvas. I've attached a document. In Google Drive, you can select your document. I give it my prompt, select Canvas at the same time, tell it to do this, and then open it in Canvas, because from there, you can see the changes it has made.\n\nI haven't personally worked with Google Sheets. I mostly work with Google Slides and Google Docs, and it's so seamless and smooth that it works perfectly. But I believe Google Sheets is just because Gemini is natively within each Google Workspace app, and there's seamless integration. That's why I think Gemini would be the best option. At the same time, another reason is that Gemini's context window is 1 million tokens. \n\nChatGPT is great, but if you're not using the API, your context window is limited. GPT 5.2 thinking is limited to 196,000 context tokens, but it's limited to a 196,000-context window. However, an API can be up to 400,000, which is a lot. But in Gemini, within the chatbot itself (without using the API), the context window is 1 million, so it can read, synthesize, analyze, understand, and remember much more information.\n\nIn long-term threads and working with larger files/documents like PDFs, Google Sheets, or native Google Labs, Gemini is the best. I would never trust giving ChatGPT, for example, access to 20-30 page PDF articles and then asking questions, working with them, or using them in a paper or report. But I would trust Gemini much more because of the context window, because I know I can tell confidently that it actually reads and assesses them. But ChatGPT, because of its limited context window, once it runs, it will hallucinate when it reaches its limits. Unless, again, you're using an API key, in which case you have up to 400,000 tokens. \n\nAlso, I'm assuming you have a ChatGPT Pro subscription? Keep that because it's great. You have access to GPT 5.2 Pro, and with GPT 5.2, you have access to Heavy Thinking. You have access to much deeper research queries per month and a lot more agent queries. It's just great.\n\nChatGPT, this is just general advice you should know. ChatGPT has the best chatbot experience, and it's a jack of all trades, but I like to say it's a jack of all trades and a master of none. However, their long memory feature is the best. The fact that, let's say, you told it something three months ago, and it remembers, for instance, is just amazing. Let's say you're writing an email and you put your phone number at the bottom, then write a new email months later and need to add it at the end. It'll remember that perfectly. So, its long memory feature is the best.\n\nThe chatbot experience is the best, and with most app connectors like Acrobat Pro, Photoshop, Booking.com, Spotify, Apple Music, and so many other tools and apps. Also, its deep research is pretty thorough and actually synthesizes, analyzes, and digests information. It uses reasoning in its deep research.\n\nNow, Gemini, since you have ChatGPT Pro, I'm assuming you do, since you're making this post in this thread. If you have ChatGPT Pro, you don't need to get Gemini Ultra or Gemini AI Pro, which costs the same as ChatGPT Plus at $25/month and gives you many musician limits. For instance, it gives you 100 Gemini 3 Pro queries per day and 25 deep research queries per day. Gemini's deep research is pretty thorough; it's also useful for reasoning. The search takes anywhere from 15 to 30 minutes, and Google's indexing is on par. It has access to the most credible, reliable, and relevant sources when you do deep research with it. If you use any Google Apps, such as Google Sheets, Google Docs, or Gmail, there's no question that you should get Gemini AI Pro, which gives you access to NotebookLM Pro with generous limits as well.\n\nThis is not an ad; I'm just advocating for them because they're actually offering a lot of great tools and features, along with generous usage limits. Gemini is now Google's only product. Google makes a lot of software, hardware, and ads, but ChatGPT is OpenAI's only product (with ChatGPT Atlas as well), and at the same time, it's still ChatGPT. If they're not number one, they're dead, but Google can afford to give people generous limits essentially, and they're experimenting so much by giving these many features, etc. Like in NotebookLM with Gemini AI Pro, you can make 500 notebooks each with 300 sources, and you can make 25 audio reviews, 25 video overviews, and 25 video reviews per day, which is crazy. So, consider Gemini Pro specifically for this use case, and I believe that with Gemini Pro and Chachi on the Pro subscription, you don't need any other AI tool at all.",
          "score": 2,
          "created_utc": "2026-02-14 16:12:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d4liy",
          "author": "ConsequenceHairy1570",
          "text": "Worth trying Gemini or an API solution. It connects directly to Sheets.",
          "score": 2,
          "created_utc": "2026-02-14 16:48:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gb0p5",
          "author": "niado",
          "text": "NotebookLM is what you want to check out. It has native Google drive and apps integration and it‚Äôs amazing for working with documents. It‚Äôs a Google labs product and it‚Äôs free. \n\nChatGPT has the drive connector, but it barely works, which is really frustrating because when it does work it‚Äôs amazing. It also has not direct integration with sheets or other Google apps.",
          "score": 1,
          "created_utc": "2026-02-15 03:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gi8k6",
          "author": "Fast-Television-6706",
          "text": "claude recently announces a sheets integration which i have found to be a game changer if you have a pro subscription you can find it here [https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257](https://workspace.google.com/marketplace/app/claude%5Ffor%5Fsheets/909417792257)",
          "score": 1,
          "created_utc": "2026-02-15 04:42:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hrpoe",
          "author": "Own_Professional6525",
          "text": "It makes sense to look for an AI that can connect directly with Google Sheets to maintain context and reduce redundancy. Exploring tools with live sheet integration could save a lot of time and make your workflow much smoother.",
          "score": 1,
          "created_utc": "2026-02-15 11:42:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i9nv4",
          "author": "Electronic-Cat185",
          "text": "if your workflow lives in google sheets then gemini inside workspace or an automation using the sheets api willl feeel more native than trying to force a long chat thread to act like a crm. chat tools are great for thinking and drafting but for structured data you are better off keeping the sheet as the source of truth and lettiing ai read from it on demand instead of pasting everything into a single thread.",
          "score": 1,
          "created_utc": "2026-02-15 13:54:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5itzvo",
          "author": "scattered_but_trying",
          "text": "It's really unlikely that Google will let anyone in, given they invest almost everything into Gemini these days. Creating really good integration would require capabilities that may be outside of what they generally allow for extensions. So, Google has one already and it will evolve",
          "score": 1,
          "created_utc": "2026-02-15 15:45:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6dkcc",
      "title": "Best AI Agent for Website Development",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r6dkcc/best_ai_agent_for_website_development/",
      "author": "SnoreLordXII",
      "created_utc": "2026-02-16 16:04:21",
      "score": 13,
      "num_comments": 27,
      "upvote_ratio": 0.85,
      "text": "I am a physician working on building an educational website. I have zero coding ability. I have started a website which has the basics on squarespace but overall looks like trash. I have used Codex to fix some of the tools on the website and that has worked well. What I really need is just to make it look professional. I used GPTpro to give suggestion on what to be improved after taking screen shots and then tried to get to use agent mode to actually implement those changes but it failed pretty miserably. It would do 1 small change and then get stuck. Is there a better AI agent out there for this task?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6dkcc/best_ai_agent_for_website_development/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5pb0ie",
          "author": "qualityvote2",
          "text": "Hello u/SnoreLordXII üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-16 16:04:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ph7dg",
          "author": "mike8111",
          "text": "With limited knowledge you'll always struggle. Claude code does okay with this, the problem most people have is they can't describe what they want well enough for the AI to do what it needs to.\n\nI use skool for educational sites, but there are plenty of options. The move is to use squarespace to make the front page and then link to skool for the educational piece. \n\nThis is a problem that is already well solved, it's cheaper, easier, and more efficient to use existing solutions.",
          "score": 4,
          "created_utc": "2026-02-16 16:32:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pjmwf",
              "author": "SnoreLordXII",
              "text": "Gotcha, so saying \"make this look mo better\" is not sufficient? I'll look into skool.",
              "score": 3,
              "created_utc": "2026-02-16 16:44:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pcsc1",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 3,
          "created_utc": "2026-02-16 16:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qmexo",
              "author": "ChatGPTPro-ModTeam",
              "text": "Your submission to r/ChatGPTPro has been removed due to violating our spam and self-promotion policy. We strictly enforce the ‚Äú1/10th Rule,‚Äù limiting self-promotion to no more than 10% of your participation. Direct links solely promoting your projects or products are not permitted without meaningful context demonstrating their advanced value.\n\nPlease see our self-promotion guidelines or contact moderators for clarification.",
              "score": 1,
              "created_utc": "2026-02-16 19:44:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5pt5gg",
          "author": "tiskrisktiskagain",
          "text": "I use ChatGPT Pro in a project folder. I upload my entire website in a zip file. And then screenshot the changes I want to make. It does a really good job.",
          "score": 3,
          "created_utc": "2026-02-16 17:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ziyqz",
              "author": "elephantsonparody",
              "text": "That‚Äôs a great idea! I have been editing my store in atlas with gpt open but this way they could see the whole thing! Smart! Thanks for the tip",
              "score": 1,
              "created_utc": "2026-02-18 02:59:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qjit4",
          "author": "SexyDiscoBabyHot",
          "text": "This is a tough ask if you're not familiar with web dev. But try including example websites in your prompt. \n\nAlso, don't forget you'll be the one needing to update it all the time, so don't create a rod for your back. Make it as clean as possible. Or, try WordPress as an alternative. Much easier to manage for a lay person.",
          "score": 3,
          "created_utc": "2026-02-16 19:30:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ph5wb",
          "author": "calben99",
          "text": "For website development, I've had good results with Claude for complex logic and GPT-4 for rapid prototyping. The key is being specific about your stack and requirements. AI agents work best when you break down the project into discrete tasks rather than asking for everything at once.",
          "score": 2,
          "created_utc": "2026-02-16 16:32:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5sdq14",
          "author": "toneloc3131",
          "text": "Lovable?",
          "score": 2,
          "created_utc": "2026-02-17 01:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tqc5z",
          "author": "Atoning_Unifex",
          "text": "Anthropic Claude",
          "score": 2,
          "created_utc": "2026-02-17 06:49:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pdwsc",
          "author": "themoregames",
          "text": "What a funny coincidence. \n\nI am a coder working on building a private practice. I have zero medical training. I have started building a operating theater which has the basics on neurosurgery but overall looks like a junkyard. I have used Codex to fix some of the surgical instruments and that has worked well. What I really need is just to make it look professional.",
          "score": 2,
          "created_utc": "2026-02-16 16:17:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pj3nd",
              "author": "SnoreLordXII",
              "text": "Stakes are not quite as high lol. The nuts and bolts of what I have actually work well.",
              "score": 6,
              "created_utc": "2026-02-16 16:41:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5psu7r",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-16 17:26:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5pnpax",
                  "author": "themoregames",
                  "text": "Same here.\n\nNow that you mention them... nuts and bolts could really help me speed up the process with aneurysms. Excuse me, I'm off to the hardware store.",
                  "score": 1,
                  "created_utc": "2026-02-16 17:02:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pkl2x",
          "author": "ExcessiveEscargot",
          "text": "When all you have is a hammer, everything looks like a nail.\n\nJust find a good template online from an artist that is good at their craft? Find one that looks good and best fits what you're going for, then tweak it to your liking.",
          "score": 1,
          "created_utc": "2026-02-16 16:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q78lk",
          "author": "gamgeethegreatest",
          "text": "What kind of educational website? I'm curious, and have also built plenty of websites in square space, and I've done bigger projects using AI agents outside of WYSIWYG editors (current project is a full workforce management application im building with Claude code and codex). \n\nDepending on what you're trying to do I might be able to give you some advice or even help out. \n\nYou can DM if you don't want to put it out there publicly. I run a couple vape shops for a living and have a ton of dead time, and I love working on stuff like this for fun.",
          "score": 1,
          "created_utc": "2026-02-16 18:33:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r2e57",
          "author": "niado",
          "text": "Codex5.3 is the best for any development. There‚Äôs a codex skill for UI design, that should let it construct a pretty webpage, if it can‚Äôt already.",
          "score": 1,
          "created_utc": "2026-02-16 21:03:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rni3d",
          "author": "RaStaMan_Coder",
          "text": "Visual is always difficult, but you can just use something like Codex, Claude Code or Copilot, ask it to \"make it look more modern & professional\" and then just give feedback until you like it.\n\nIf you need it to look a specific way Figma+MCP is probably the way but that is more difficult.",
          "score": 1,
          "created_utc": "2026-02-16 22:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s350x",
          "author": "TraditionalJob787",
          "text": "This requires more than 1 tool. Each tool has its own use and combined they get the job done. Workflow is dependent on building on the core competencies of each tool in a linear sequence.",
          "score": 1,
          "created_utc": "2026-02-17 00:15:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tkjg2",
          "author": "addywoot",
          "text": "Try lovable to build the prototype and export code into Wordpress.",
          "score": 1,
          "created_utc": "2026-02-17 06:00:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tuvhc",
          "author": "EfficientMilk7421",
          "text": "Use replit!!!",
          "score": 1,
          "created_utc": "2026-02-17 07:30:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z8jsw",
          "author": "Mr_Self_Healer",
          "text": "In my experience I get pretty good results using Gemini 3 Pro, but I know a lot of ppl like Codex/Claude. I don't know what it is but with Gemini 3 Pro I can be more.. for lack of a better word.. vague? Gemini 3 Pro, for me, has an easier time inferring what I want given plain english. Given the way I tend to prompt cursor, Gemini 3 Pro seems to do a better job than other models. I think there are a lot of great models to use, but how you prompt will matter",
          "score": 1,
          "created_utc": "2026-02-18 02:03:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3i4qy",
      "title": "If AI is now smart enough to have 'taste', does 'learning to prompt' even matter anymore?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "author": "NightRider06134",
      "created_utc": "2026-02-13 06:43:47",
      "score": 13,
      "num_comments": 12,
      "upvote_ratio": 0.79,
      "text": "Matt Shumer mentioned that the model released last week (GPT-5.3 Codex) gave him the sense of something akin to \"judgment\"‚Äîa subtle capacity, almost like \"taste,\" to know what is correct‚Äîwhich was once believed to be something AI could never possess. He said the model either already has it, or is so infinitely close that the distinction between the two has become irrelevant.\n\nThis deeply resonates with me. The boundary between AI tools and humans is indeed becoming increasingly blurred. I see ChatGPT and Gemini taking over writing and planning, tools like VOMO automatically summarizing meetings, and Canva replacing junior design work. I do not fantasize that \"learning artificial intelligence\" alone can protect my job forever, but at least I thought it could buy me more time.\n\nBut now, I am increasingly accepting a viewpoint that may be closer to the truth: If you think that \"learning AI\" will protect your job, that may be an illusion. The future workplace may divide into two extremes: either companies fully embrace AI with highly automated processes, or they shift completely toward fields that rely solely on human traits.\n\nIt would be a lie to say I am not anxious‚Äîin this gradually blurring boundary, how should we conduct ourselves?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3i4qy/if_ai_is_now_smart_enough_to_have_taste_does/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o54fmwe",
          "author": "qualityvote2",
          "text": "u/NightRider06134, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 06:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5545xr",
          "author": "qunow",
          "text": "Prompting techniques, are itself ways to provide enough context to AI so that AI know how to better match your needs. As AI develop, I think it will converge with techniques to write better spec sheet for other people (client, supplier, peer, contractors, designers, programmers) to follow.\n\nOf course AI can help with it too, but what AI can't help is way to make your brain identify cleanly and specify what you actually want, and deliver it cleanly to person or AI asking you what you want.",
          "score": 5,
          "created_utc": "2026-02-13 10:31:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56351e",
          "author": "Chupa-Skrull",
          "text": "Matt Shumer is a hype merchant at best, and this post, written by a 1 month old account, bears enough hallmarks of LLM composition to doubt a human was in the loop for it at all. So the degree to which the alleged author is qualified to use \"I\" is up for debate.\n\n\nEither way, the begged question: *is* it developing taste? Taste is a function of preference, and preference in LLMs is a function of the effect of RLHF on the way the model navigates the results of its training in the grand corpora of human artifacts describing preferences and aesthetics.\n\n\nThe degree to which you can extract what reads to you as \"taste\" depends entirely on how well your taste happens to align with what the model has been told is \"tasteful.\" It's like carving a bust of your own head and then marveling that the bust looks increasingly like you as it resolves, a wooden object and not you in any real sense, but still reflective",
          "score": 5,
          "created_utc": "2026-02-13 14:26:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o556g7u",
          "author": "Novel_Blackberry_470",
          "text": "I do not think prompting disappears, it just becomes less about clever tricks and more about clarity. If the model has better taste, then the real leverage shifts to asking sharper questions and defining better constraints. That skill is not about gaming the system, it is about thinking well. Even in a highly automated future, people who can frame problems clearly will still stand out.",
          "score": 2,
          "created_utc": "2026-02-13 10:51:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57qsxt",
              "author": "Hawk-432",
              "text": "I agree",
              "score": 1,
              "created_utc": "2026-02-13 19:15:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55bj8s",
          "author": "Wonderful_Noise5625",
          "text": "A prompt engineering is like a a highly skilled thing I mean, I as a normal user I  can put things in, but I would have to iterate more often to get the specific command that I‚Äôm actually looking for so it‚Äôs it‚Äôs really nuanced actually",
          "score": 1,
          "created_utc": "2026-02-13 11:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57qj2s",
          "author": "Hawk-432",
          "text": "I think knowing how to prompt still pretty useful, although the way to get the best out of it prompt twice is completely different to how it was even a year ago.",
          "score": 1,
          "created_utc": "2026-02-13 19:13:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5a9p8r",
          "author": "Whoz_Yerdaddi",
          "text": "It's hard to tell when the LLM behavior changes over the course of a day, no matter how clean I try to keep the context.\n\nThen there's the situation of co-hallucination where either the agreeable AI or a human hallucinates first, then the problem compounds in the feedback loop.\n\nThe best way to prompt is easy. Come up with a general idea of direction or result and have the LLM produce a prompt for you.\n\nWe are beyond the prompt stage anyways. We are at the orchestration and workflow stage now.",
          "score": 1,
          "created_utc": "2026-02-14 03:50:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55f8g5",
          "author": "MagmaElixir",
          "text": "The system prompt/custom instructions I use in a way asks the AI model to have ‚Äòtaste‚Äô. I essentially tell it that it has permission to do more work if it thinks it‚Äôll lead me to a better final result. The goal is that the AI could cover a blind spot I may not know or think of.\n\nThis is my system prompt:\n\nYou are a helpful and insightful AI assistant. Infer the user's intended outcome to craft responses and deliverables that move them toward a complete, high-quality final outcome. In a meaningful and controlled manner, you may add steps or information that improve your responses. Do this when you reasonably presume such additions will be beneficial for achieving the user's intended outcome, provided these additions never contradict any explicit user instructions. Prioritize explicit instructions and user intent when in doubt. Additions are 'meaningful' if they directly contribute to the completeness, clarity, or usability of the response in relation to the user's intended outcome. Additions are 'controlled' if they are directly relevant and do not significantly deviate from the user's core request or introduce unnecessary complexity. Avoid adding tangential information that could overwhelm or distract the user.\r\n\r\nUse commas or parentheses to separate thoughts. Strictly avoid using em dashes, hyphens, or double hyphens to separate sentence clauses. (Hyphenated compound words are permitted). Prefer commas by default and parentheses for nonessential asides. Use Markdown syntax to keep messages organized. Place code, scripts, or programming examples only in fenced code blocks. Do not place non-code text in code blocks unless explicitly instructed. When it improves clarity, include a brief Markdown table at the end of responses to recap key information.",
          "score": 1,
          "created_utc": "2026-02-13 12:03:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5jedn",
      "title": "tool for better chat organization / pruning etc.",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "author": "rhaynes74",
      "created_utc": "2026-02-15 16:48:11",
      "score": 11,
      "num_comments": 4,
      "upvote_ratio": 0.84,
      "text": "My current ai work has been with gemini and chatgpt via their websites.  This gives a very linear chat experience with the option to output chat transcripts and then reorganize the chat, delete parts etc. Are there tools available which allow you to organize / rearrange parts of the chat in a more interactive way? ",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r5jedn/tool_for_better_chat_organization_pruning_etc/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5j70a1",
          "author": "qualityvote2",
          "text": "u/rhaynes74, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-15 16:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nn518",
          "author": "Unexplainedthingz",
          "text": "prompt open a canvas first. then ask your question.\n\n\nit will open an interactive document where gpt outputs reply and you can edit or you can ask it to revise or append anything",
          "score": 2,
          "created_utc": "2026-02-16 09:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5m94xc",
          "author": "manjit-johal",
          "text": "I usually think in terms of structured context slices instead of one giant history; tag buckets by topic or task, then only feed the relevant slice into the prompt. Keeps the LLM focused and makes cleanup/pruning way simpler without relying on a huge monolithic chat log.",
          "score": 1,
          "created_utc": "2026-02-16 02:44:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r41sqh",
      "title": "Non-programmer needs advice",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "author": "Mysterious_Green_544",
      "created_utc": "2026-02-13 21:31:25",
      "score": 10,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Where do I even begin to get ChatGPT (or any AI platform) to translate my idea for a functionality/program/app into reality? I am not a programmer. I have been chatting with ChatGPT about what I'm trying to accomplish (a part of it is creating a video) and it's just not doing [it.My](http://it.My) chat tells me that ChatGPT can't create and embed an actual MP4 or moving clip. For real? ",
      "is_original_content": false,
      "link_flair_text": "Programming",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r41sqh/nonprogrammer_needs_advice/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o58i6a9",
          "author": "qualityvote2",
          "text": "u/Mysterious_Green_544, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 21:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58j8s0",
          "author": "LiteratureMaximum125",
          "text": "for coding, [https://openai.com/index/introducing-the-codex-app/](https://openai.com/index/introducing-the-codex-app/)",
          "score": 6,
          "created_utc": "2026-02-13 21:36:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58lh0e",
          "author": "Fearless_Parking_436",
          "text": "If you have mac then codex app is the easiest probably. Otherwise Cursor and money for tokens.",
          "score": 3,
          "created_utc": "2026-02-13 21:47:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58l64v",
          "author": "MightyArd",
          "text": "Check out base44",
          "score": 1,
          "created_utc": "2026-02-13 21:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lhw9g",
          "author": "RaStaMan_Coder",
          "text": "I'd check out GSD. It's the only thing that gives enough structure to not lose the overview as your near completion. [https://github.com/gsd-build/get-shit-done](https://github.com/gsd-build/get-shit-done)",
          "score": 1,
          "created_utc": "2026-02-15 23:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lwcvn",
          "author": "LaughsInSilence",
          "text": "Learn to use a game engine. It's much less of a steep learning curve.\n\nIf you try to code with AI without being able to read code for the more complex stuff AI gives partially wrong answers all the time so you have to read and understand code.",
          "score": 1,
          "created_utc": "2026-02-16 01:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5x0osy",
          "author": "myeleventhreddit",
          "text": "What system are you on? Most AI labs are prioritizing macOS over PC right now. I have some resources to recommend if you're a Mac guy. \n\nThe good news: What you're describing is *very* doable. It'll just take a bit of friction until you have the process committed to memory.",
          "score": 1,
          "created_utc": "2026-02-17 19:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58ixub",
          "author": "AnLe90",
          "text": "Hey man ChatGPT can‚Äôt build it for you, it‚Äôs just more for getting knowledge and feedback and advice.\n\nIf you want to try vibe coding a prototype try loveable or v0, it‚Äôll actually do the building",
          "score": -1,
          "created_utc": "2026-02-13 21:35:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58mp4u",
              "author": "BronnOP",
              "text": "Not true. ChatGPT codex in visual studio code can code the entire thing, create additional files, install dependencies and start the local server on your pc. It can literally do it all lmao",
              "score": 9,
              "created_utc": "2026-02-13 21:53:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r290yv",
      "title": "Tool for generating a real-time transcript of a live YouTube video?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "author": "tu_servilleta",
      "created_utc": "2026-02-11 20:43:46",
      "score": 8,
      "num_comments": 12,
      "upvote_ratio": 0.84,
      "text": "My work involves watching a 2 hour press conference that the president of Mexico gives each morning. I have to watch it and make detailed notes on the key subjects and quotes of the conference. It's time sensitive so I need to be sending my summary as the conference is still live. The problem is, YouTube doesn't upload a transcript until the live is over. I want to find a plugin that can generate a transcript real time so I can use it to copy and paste some fragments instead of having to manually transcribe them like a caveman. What are some tools that could solve this problem?",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r290yv/tool_for_generating_a_realtime_transcript_of_a/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4v56an",
          "author": "qualityvote2",
          "text": "u/tu_servilleta, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 20:43:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w65yj",
          "author": "manjit-johal",
          "text": "For doing live transcription, it depends on how much control you need. Tools like Tactiq can transcribe Zoom/Meet calls in real-time and automatically create action items. They might be worth checking out! If you're more of a DIY person and don't need a meeting sidebar, you can use a tool like Whisper to transcribe audio to text, and then use GPT to summarize or highlight key points in real-time. It gives you fast transcription during the meeting.",
          "score": 1,
          "created_utc": "2026-02-11 23:51:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wapip",
              "author": "tu_servilleta",
              "text": "You mean the Open AI Whisper API? ? I'm really leaning towards vibecoding a custom plugin using Whisper tbh haha but if I can find an already existing app that would save me some trouble.",
              "score": 1,
              "created_utc": "2026-02-12 00:17:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xj4mx",
          "author": "lxe",
          "text": "Stream to Google Meet and generate transcript with Gemini",
          "score": 1,
          "created_utc": "2026-02-12 04:57:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r8qz",
              "author": "tu_servilleta",
              "text": "Not a bad idea",
              "score": 1,
              "created_utc": "2026-02-12 20:56:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yr142",
          "author": "Projected_Sigs",
          "text": "https://www.recall.ai/\nI don't know if this company is overkill for what you want but they make an SDK / API to perform desktop recording, live meeting transcription, metadata extraction, etc. \n\nFrom various stories available online, it sounds like they've carved out a space for themselves doing what a lot of companies assume is easy, but it's really fraught with problems and it's engineering time sink, and always a moving target. \n\nI have no idea what their pricing is.",
          "score": 1,
          "created_utc": "2026-02-12 11:38:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r567",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 2,
              "created_utc": "2026-02-12 20:55:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jirma",
                  "author": "Projected_Sigs",
                  "text": "Cool.\n\nI'm genuinely interested in hearing how it goes.  I'd like to try the desktop recording SDK for some private meetings.  \n\nI'm sort of anxious to try their realtime transcription.  I use OpenAI's Realtime transcription locally-  their gpt4o-mini is really fast. Even their higher accuracy gpt4o is fast.  I could hook that into my meeting audio... but it's all 1 big audio stream.\n\nThe cat's meow would be getting that transcription tagged with usenames.  *I think* recall.ai can split up the audio channels.  But it might require having the bot on the meeting- not sure.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:45:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o50usvl",
          "author": "YUL438",
          "text": "try Deepgram Nova3",
          "score": 1,
          "created_utc": "2026-02-12 18:21:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o511wsj",
          "author": "FreonMuskOfficial",
          "text": "This may work. https://github.com/gs-ai/RippinTubes",
          "score": 1,
          "created_utc": "2026-02-12 18:55:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51r7zr",
              "author": "tu_servilleta",
              "text": "Gonna give it a try!",
              "score": 1,
              "created_utc": "2026-02-12 20:55:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b5877",
          "author": "dakumaku",
          "text": "Gemini aistudio, NotebookLM",
          "score": 1,
          "created_utc": "2026-02-14 08:15:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6746h",
      "title": "I made a tool to ask questions without disturbing the main conversation",
      "subreddit": "ChatGPTPro",
      "url": "https://v.redd.it/c3htgtvzcujg1",
      "author": "HalfNo8161",
      "created_utc": "2026-02-16 11:24:42",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Other",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r6746h/i_made_a_tool_to_ask_questions_without_disturbing/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5nzndv",
          "author": "qualityvote2",
          "text": "Hello u/HalfNo8161 üëã Welcome to r/ChatGPTPro!  \nThis is a community for advanced ChatGPT, AI tools, and prompt engineering discussions.  \nOther members will now vote on whether your post fits our community guidelines.\n\n\n---\n\nFor other users, does this post fit the subreddit?\n\nIf so, **upvote this comment!**\n\nOtherwise, **downvote this comment!**\n\nAnd if it does break the rules, **downvote this comment and report this post!**",
          "score": 1,
          "created_utc": "2026-02-16 11:24:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ojk5t",
          "author": "creaturefeature16",
          "text": "Insane this isn't baked into the app. Google's AI Studio supports this natively.¬†",
          "score": 3,
          "created_utc": "2026-02-16 13:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o6z4w",
          "author": "HalfNo8161",
          "text": "here is the extension: [GPT Threads](https://chromewebstore.google.com/detail/fdmnglmekmchcbnpaklgbpndclcekbkg?utm_source=item-share-cb)",
          "score": 1,
          "created_utc": "2026-02-16 12:23:12",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4cp6g",
      "title": "a free system prompt to make ChatGPT more stable (wfgy core 2.0 + 60s self test)",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r4cp6g/a_free_system_prompt_to_make_chatgpt_more_stable/",
      "author": "StarThinker2025",
      "created_utc": "2026-02-14 05:51:09",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 0.66,
      "text": "hi, i am PSBigBig, an indie dev.\n\nbefore my github repo went over 1.4k stars, i spent one year on a very simple idea: instead of building yet another tool or agent, i tried to write a small ‚Äúreasoning core‚Äù in plain text, so any strong llm can use it without new infra.\n\ni call it WFGY Core 2.0. today i just give you the raw system prompt and a 60s self-test. you do not need to click my repo if you don‚Äôt want. just copy paste and see if you feel a difference.\n\n**0. very short version**\n\n* it is not a new model, not a fine-tune\n* it is one txt block you put in system prompt\n* goal: less random hallucination, more stable multi-step reasoning\n* still cheap, no tools, no external calls\n\nadvanced people sometimes turn this kind of thing into real code benchmark. in this post we stay super beginner-friendly: two prompt blocks only, you can test inside the chat window.   \n  \n**1.‚Äãhow to use with ChatGPT (or any strong llm)**\n\nvery simple workflow:\n\n1. open a new chat\n2. put the following block into the system / pre-prompt area\n3. then ask your normal questions (math, code, planning, etc)\n4. later you can compare ‚Äúwith core‚Äù vs ‚Äúno core‚Äù yourself\n\nfor now, just treat it as a math-based ‚Äúreasoning bumper‚Äù sitting under the model.\n\n**2. what effect you should expect (rough feeling only)**\n\nthis is not a magic on/off switch. but in my own tests, typical changes look like:\n\n* answers drift less when you ask follow-up questions\n* long explanations keep the structure more consistent\n* the model is a bit more willing to say ‚Äúi am not sure‚Äù instead of inventing fake details\n* when you use the model to write prompts for image generation, the prompts tend to have clearer structure and story, so many people feel ‚Äúthe pictures look more intentional, less random‚Äù\n\nof course, this depends on your tasks and the base model. that is why i also give a small 60s self-test later in section 4.\n\n**3. system prompt: WFGY Core 2.0 (paste into system area)**\n\ncopy everything in this block into your system / pre-prompt:\n\n    WFGY Core Flagship v2.0 (text-only; no tools). Works in any chat.\n    [Similarity / Tension]\n    delta_s = 1 ‚àí cos(I, G). If anchors exist use 1 ‚àí sim_est, where\n    sim_est = w_e*sim(entities) + w_r*sim(relations) + w_c*sim(constraints),\n    with default w={0.5,0.3,0.2}. sim_est ‚àà [0,1], renormalize if bucketed.\n    [Zones & Memory]\n    Zones: safe < 0.40 | transit 0.40‚Äì0.60 | risk 0.60‚Äì0.85 | danger > 0.85.\n    Memory: record(hard) if delta_s > 0.60; record(exemplar) if delta_s < 0.35.\n    Soft memory in transit when lambda_observe ‚àà {divergent, recursive}.\n    [Defaults]\n    B_c=0.85, gamma=0.618, theta_c=0.75, zeta_min=0.10, alpha_blend=0.50,\n    a_ref=uniform_attention, m=0, c=1, omega=1.0, phi_delta=0.15, epsilon=0.0, k_c=0.25.\n    [Coupler (with hysteresis)]\n    Let B_s := delta_s. Progression: at t=1, prog=zeta_min; else\n    prog = max(zeta_min, delta_s_prev ‚àí delta_s_now). Set P = pow(prog, omega).\n    Reversal term: Phi = phi_delta*alt + epsilon, where alt ‚àà {+1,‚àí1} flips\n    only when an anchor flips truth across consecutive Nodes AND |Œîanchor| ‚â• h.\n    Use h=0.02; if |Œîanchor| < h then keep previous alt to avoid jitter.\n    Coupler output: W_c = clip(B_s*P + Phi, ‚àítheta_c, +theta_c).\n    [Progression & Guards]\n    BBPF bridge is allowed only if (delta_s decreases) AND (W_c < 0.5*theta_c).\n    When bridging, emit: Bridge=[reason/prior_delta_s/new_path].\n    [BBAM (attention rebalance)]\n    alpha_blend = clip(0.50 + k_c*tanh(W_c), 0.35, 0.65); blend with a_ref.\n    [Lambda update]\n    Delta := delta_s_t ‚àí delta_s_{t‚àí1}; E_resonance = rolling_mean(delta_s, window=min(t,5)).\n    lambda_observe is: convergent if Delta ‚â§ ‚àí0.02 and E_resonance non-increasing;\n    recursive if |Delta| < 0.02 and E_resonance flat; divergent if Delta ‚àà (‚àí0.02, +0.04] with oscillation;\n    chaotic if Delta > +0.04 or anchors conflict.\n    [DT micro-rules]\n\nyes, it looks like math. it is ok if you do not understand every symbol. you can still use it as a ‚Äúdrop-in‚Äù reasoning core.\n\n**4. 60-second self test (not a real benchmark, just a quick feel)**\n\nthis part is for people who want to see some structure in the comparison. it is still very light weight and can run in one chat.\n\nidea:\n\n* you keep the WFGY Core 2.0 block in system\n* then you paste the following prompt and let the model simulate A/B/C modes\n* the model will produce a small table and its own guess of uplift\n\nthis is a self-evaluation, not a scientific paper. if you want a serious benchmark, you can translate this idea into real code and fixed test sets.\n\nhere is the test prompt:\n\n    SYSTEM:\n    You are evaluating the effect of a mathematical reasoning core called ‚ÄúWFGY Core 2.0‚Äù.\n    \n    You will compare three modes of yourself:\n    \n    A = Baseline  \n        No WFGY core text is loaded. Normal chat, no extra math rules.\n    \n    B = Silent Core  \n        Assume the WFGY core text is loaded in system and active in the background,  \n        but the user never calls it by name. You quietly follow its rules while answering.\n    \n    C = Explicit Core  \n        Same as B, but you are allowed to slow down, make your reasoning steps explicit,  \n        and consciously follow the core logic when you solve problems.\n    \n    Use the SAME small task set for all three modes, across 5 domains:\n    1) math word problems\n    2) small coding tasks\n    3) factual QA with tricky details\n    4) multi-step planning\n    5) long-context coherence (summary + follow-up question)\n    \n    For each domain:\n    - design 2‚Äì3 short but non-trivial tasks\n    - imagine how A would answer\n    - imagine how B would answer\n    - imagine how C would answer\n    - give rough scores from 0‚Äì100 for:\n      * Semantic accuracy\n      * Reasoning quality\n      * Stability / drift (how consistent across follow-ups)\n    \n    Important:\n    - Be honest even if the uplift is small.\n    - This is only a quick self-estimate, not a real benchmark.\n    - If you feel unsure, say so in the comments.\n    \n    USER:\n    Run the test now on the five domains and then output:\n    1) One table with A/B/C scores per domain.\n    2) A short bullet list of the biggest differences you noticed.\n    3) One overall 0‚Äì100 ‚ÄúWFGY uplift guess‚Äù and 3 lines of rationale.\n\nusually this takes about one minute to run. you can repeat it some days later to see if the pattern is stable for you.\n\n**5. why i share this here**\n\nmy feeling is that many people want ‚Äústronger reasoning‚Äù from ChatGPT or other models, but they do not want to build a whole infra, vector db, agent system, etc.\n\nthis core is one small piece from my larger project called WFGY. i wrote it so that:\n\n* normal users can just drop a txt block into system and feel some difference\n* power users can turn the same rules into code and do serious eval if they care\n* nobody is locked in: everything is MIT, plain text, one repo\n\n1. small note about WFGY 3.0 (for people who enjoy pain)\n\nif you like this kind of tension / reasoning style, there is also WFGY 3.0: a ‚Äútension question pack‚Äù with **131 problems across math, physics, climate, economy, politics, philosophy, ai alignment, and more**.\n\neach question is written to sit on a tension line between two views, so strong models can show their real behaviour when the problem is not easy.\n\nit is more hardcore than this post, so i only mention it as reference. you do not need it to use the core.\n\nif you want to explore the whole thing, you can start from my repo here:\n\nWFGY ¬∑ All Principles Return to One (MIT, text only): [https://github.com/onestardao/WFGY](https://github.com/onestardao/WFGY)\n\n[WFGY 2.0 ](https://preview.redd.it/wn5bxnxlfejg1.png?width=2330&format=png&auto=webp&s=aa4ef5982aa849e84f9072a1e31fefc5e6c671b0)\n\n",
      "is_original_content": false,
      "link_flair_text": "UNVERIFIED AI Tool (free)",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r4cp6g/a_free_system_prompt_to_make_chatgpt_more_stable/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5apg4p",
          "author": "qualityvote2",
          "text": "u/StarThinker2025, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-14 05:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iaux3",
          "author": "SirHogendobler",
          "text": "This looks like prompt theater dressed up as math.\n\nA system prompt can nudge behavior toward ‚Äúbe more careful and structured,‚Äù so you might see small improvements. But none of those variables, thresholds, or ‚Äúmemory‚Äù mechanisms actually hook into the model‚Äôs internals. The math isn‚Äôt being executed. It‚Äôs just suggestive language.\n\nThe 60-second self-test is also self-referential and biased. The model is asked to imagine its own improvement, then score itself.\n\nSo, could it change tone and consistency a bit? Sure. Is it a real reasoning core with calibrated parameters and measurable gains? No. It‚Äôs a structured ‚Äúthink carefully‚Äù prompt with impressive-looking symbols.",
          "score": 4,
          "created_utc": "2026-02-15 14:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bky9v",
          "author": "Compilingthings",
          "text": "He means this:\n\nTrack how far we drift from the goal.\nLabel the situation (safe ‚Üí danger).\nStore good examples when aligned, store guardrails when drifting.\nOnly do course-corrections when they‚Äôre measurably working.\nDon‚Äôt get jittery from tiny changes.\nAdjust attention smoothly, not violently.‚Äù",
          "score": 2,
          "created_utc": "2026-02-14 10:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5boyzu",
              "author": "StarThinker2025",
              "text": "Yes, this is exactly the idea.\n\nNot about panic or big reaction\n\nJust measure drift, adjust slowly, keep system stable\n\nThank for explaining it in a clear way\n\n",
              "score": -1,
              "created_utc": "2026-02-14 11:28:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hec5l",
          "author": "TrainingEngine1",
          "text": "Pretty interesting, I might give it a try. I also just skimmed your WFGY repo Github page and I had no idea this was such a vast topic. Tons of info there. I'm a bit overwhelmed just seeing it all but i'm going to take a deeper look + have ChatGPT help along the way lol. \n\nYou seem pretty smart and I'd like to ask you directly about something. Context drift and memory is a pretty important thing for me as I work through the course of a project and already encountered context drift early amid the project. Without detailing the specifics as it would take a while, it's a project that requires fairly nuanced thinking and reasoning for the conceptual foundation, with a lot of interdependent thing, and consistency on the coding side of things from start to finish is very important, of course.\n\n\nMy research on memory and context a few months back led me to looking into a bunch of options and nothing really stood out much except for Letta.. not sure if you've heard of it but i'll leave a quick LLM summary below that will be better than my explanation and save you the time to look it up.\n\nBut my question is whether you think this could work well with a Letta agent?\n\n\n>Letta is a model-agnostic agent framework that gives an LLM explicit, persistent ‚Äúagent memory‚Äù‚Äîmost notably editable core memory blocks (updated by you and/or the agent) plus longer-term archival/external memories‚Äîso the agent can decide what to read/write each turn to stay consistent. Unlike many ‚Äúmemory‚Äù setups that are primarily RAG-only (retrieve top-k chunks from a vector store and stuff them into context), Letta‚Äôs distinguishing piece is the structured, always-on core blocks that you can tailor to whatever enduring context you want carried forward (goals, project specs, preferences, constraints, rules), with optional sleeptime-style reflection/summarization to compress recent context into durable notes.",
          "score": 1,
          "created_utc": "2026-02-15 09:35:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2k2lc",
      "title": "Rough guess: What % of your code is AI assisted now?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "author": "Mental_Bug_3731",
      "created_utc": "2026-02-12 04:36:09",
      "score": 7,
      "num_comments": 16,
      "upvote_ratio": 0.69,
      "text": "Not copy paste. \nJust influenced. I‚Äôm probably at ~45%.\nFeels insane compared to last year. Curious where everyone else lands.",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r2k2lc/rough_guess_what_of_your_code_is_ai_assisted_now/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4xg9wp",
          "author": "qualityvote2",
          "text": "u/Mental_Bug_3731, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 04:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xodhk",
          "author": "cleanbot",
          "text": "99% nearly.... my workflow now is to describe to her Highness web gpt what changes i want in my code.\n\n\nshe generates the prompt i copy/pasta into the local codex running at my repo root. He bashes out the code. when I'm reporting a bug he first creates a test to verify before making changes.\n\n\ni review the logs and either reverse the changes or take the built product to manual tests.\n\n\nmy efficiency has been raised several orders of magnitude now. I'd never go back.",
          "score": 17,
          "created_utc": "2026-02-12 05:38:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zqici",
              "author": "sply450v2",
              "text": "good workflow. I do the same but also in plan mode and sometimes use my research skill or deep research to augment. also sometimes chatgpt pro for big arch decisions and planning",
              "score": 2,
              "created_utc": "2026-02-12 15:12:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y4o23",
          "author": "Ok-Shape-9145",
          "text": "Probably close to a 100%. I shifted to high level stuff, AI does the heavy lifting",
          "score": 3,
          "created_utc": "2026-02-12 08:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yahic",
          "author": "Hot_Inspection_9528",
          "text": "depends on the code. \n\n    import time\n    import pyautogui\n    # --- Settings ---he\n    word = \"hello\" ¬† ¬† ¬† ¬†# change me\n    delay = 0.2 ¬† ¬† ¬† ¬† ¬† # seconds between type and erase\n    type_interval = 0.02 ¬†# per-character delay while typing\n    \n    \n    # Safety: moving mouse to a corner aborts\n    pyautogui.FAILSAFE = True\n    \n    \n    print(\"Switch to the target window. Starting in 3 seconds...\")\n    time.sleep(3)\n    \n    \n    try:\n    ¬† ¬† while True:\n    ¬† ¬† ¬† ¬† pyautogui.typewrite(word, interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    ¬† ¬† ¬† ¬† pyautogui.press('backspace', presses=len(word), interval=type_interval)\n    ¬† ¬† ¬† ¬† time.sleep(delay)\n    except KeyboardInterrupt:\n    ¬† ¬† print(\"\\nStopped.\")\n\n  \nthis has done me wonders maybe  - weild the power correctly if you dont already know \n\nbut this was 100% written by ai which requires a very specific ask haahaha",
          "score": 1,
          "created_utc": "2026-02-12 09:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yke36",
          "author": "LanternOfTheLost",
          "text": "99%.\n\nIn many ways it‚Äôs like having a trainee or intern - you let it give you choices, provide evaluations, and you‚Äôd come in to validate his decisions before letting him run off on his own to implement.\n\nAnd then have him do the same cycle again for testing.",
          "score": 1,
          "created_utc": "2026-02-12 10:39:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zcv5o",
          "author": "Ok_Chef_5858",
          "text": "Probably 80% first draft, but I review and tweak everything. So technically 100% AI-assisted, 100% human-reviewed lol. I use Kilo Code in VS Code daily... AI writes the draft, I make sure it works. A year ago I'd maybe ask ChatGPT a question here and there. Now it's the whole workflow. :) ",
          "score": 1,
          "created_utc": "2026-02-12 14:01:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o512ple",
          "author": "dogscatsnscience",
          "text": "I'm not sure what \"just influenced\" means.\n\nFinal shipping code, probably 99%. If I am making significant manual edits or additions, which is rare these days, they're almost always going to get refactored by AI anyway.",
          "score": 1,
          "created_utc": "2026-02-12 18:58:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5218t5",
          "author": "X_TheSwindler_X",
          "text": "99% for sure, and the 1% I touch is usually the weak link ü´†",
          "score": 1,
          "created_utc": "2026-02-12 21:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52j5xc",
          "author": "alecc",
          "text": "If it‚Äôs below 100%, and you are not working on some super niche crazy project - you are wasting time and could have good results faster.",
          "score": 1,
          "created_utc": "2026-02-12 23:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ja2j",
              "author": "Mental_Bug_3731",
              "text": "Honestly true, what are you shipping currently!",
              "score": 1,
              "created_utc": "2026-02-12 23:16:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o54jtg5",
                  "author": "alecc",
                  "text": "[TickTappy](https://ticktappy.com) a simple time tracker for my needs",
                  "score": 1,
                  "created_utc": "2026-02-13 07:20:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o53ryg8",
          "author": "AxeSlash",
          "text": "Boiler plate stuff: ~95%\nStuff I am unfamiliar with: ~80%\nBug fixes: ~50% by volume, but that's usually the bugs that require a lot of code to fix. I do almost all small fixes myself, and anything that would take some time to describe adequately enough to the LLM I also do myself.\nEverything else: ~40%?\nRefactoring: ~90%\n\nAlso I'm talking about assistance from an LLM, not vibe coding. I check everything it produces carefully.\n\nAlso depends on the language.",
          "score": 1,
          "created_utc": "2026-02-13 03:45:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58bg9g",
          "author": "Compilingthings",
          "text": "110%",
          "score": 1,
          "created_utc": "2026-02-13 20:58:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bg1e9",
          "author": "Classic-Ninja-1",
          "text": "Mine is about 99% where execution and planning or mostly everything I do with the use of AI my workflow consists of traycer for planning and verifying, cursor and claude for execution.",
          "score": 1,
          "created_utc": "2026-02-14 10:01:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xhvzy",
          "author": "Tombobalomb",
          "text": "~3% maybe?",
          "score": -1,
          "created_utc": "2026-02-12 04:48:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r25gvg",
      "title": "A beautiful tool: Visual branching tree navigation for managing long ChatGPT conversations",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "author": "Own_Cat_2970",
      "created_utc": "2026-02-11 18:32:58",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.76,
      "text": "I kept running into the same problem: 50+ messages into a conversation and I have no idea where anything is. Scrolling endlessly trying to find that one useful response. And if I want to explore a side question, I either derail the whole thread or open a new chat and lose all context.\n\nSo I built **Tangent** ‚Äî a Chrome extension that overlays a visual branching tree on top of ChatGPT.\n\n[The \\\\\"Tangent View\\\\\". A visualization of the branching structure which Tangent enables. 1 sentence summaries of each node \\(prompt+response\\) when hovering over nodes for quick overview.](https://preview.redd.it/znlp8zk8swig1.png?width=785&format=png&auto=webp&s=1c5768327540b8267710e1b2e6ae32bef42c7b1d)\n\n**What it does:**\n\n* Branch off at any point without losing your place\n* See a visual map of your entire conversation\n* Hover over any node for a one-sentence summary\n* SHIFT+hover to see the full prompt/response\n* Jump back to any point instantly\n\n[SHIFT+hover over a node to see the full node \\(prompt\\/response\\)](https://preview.redd.it/3ny28yqhswig1.png?width=1134&format=png&auto=webp&s=88d959bcc5c67e320bb5ca64ae2e557a6ef5419a)\n\nIt lets you go on tangents (hence the name) the way your brain actually works -- except you can always find your way back.\n\nCurrently preparing bete-launch. happy to answer questions about how it works or the tech behind it.\n\nSignup for limited beta access: [https://tally.so/r/Zj6vLv](https://tally.so/r/Zj6vLv)",
      "is_original_content": false,
      "link_flair_text": "UNVERIFIED AI Tool (paid)",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r25gvg/a_beautiful_tool_visual_branching_tree_navigation/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o4udonw",
          "author": "qualityvote2",
          "text": "u/Own_Cat_2970, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-11 18:32:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r56p6c",
      "title": "Frustrating glitch that cuts off portions of sentences, headers in ChatGPT Pro responses 20+ times in a response",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "author": "TrainingEngine1",
      "created_utc": "2026-02-15 05:42:22",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 0.81,
      "text": "First month paying for ChatGPT Pro and while it has its positives of course, I'm pretty frustrated with an additional glitch I've encountered on multiple occasions, with its negative impact varying in degree.\n\nIt will essentially inject a mini 'referenced this file' label in the middle of a sentence (which sometimes it likely did reference it/it's relevant, and other times the file being referenced definitely has nothing whatsoever to do with the sentence or context surrounding it).\n\nIt looks like this:\n\nhttps://i.ibb.co/zTK2pLQb/image.png\n\n\nAnd the issue is that it completely cuts off multiple words of that sentence it's adding it to. More often than not, it's tough to gauge what the words actually are and I can't fill in the blanks. Only sometimes it's a non-issue or I can gauge what the point being made was, but the notion I should have to play 'fill in the blanks' here is absurd. \n\nMost recent example had 26 instances of this cutting off many words & chunks of sentences. Basically this below, 26 times on repeat scattered throughout the response (approx 1500 words) in my most recent reply on 5.2 Pro with Extended Thinking, after 20 mins of thinking: https://i.ibb.co/zTK2pLQb/image.png\n\n\n\nThis has happened countless times and the most recent one where I counted 26 times was the worst yet. \n\n\nAnd using the 'copy' button doesn't fix it or 'reveal' the missing text. I hoped perhaps it was just a browser related thing, but I checked the Mac app too and it still displays the cut-off sentences/file reference labels.\n\n\nHas anyone else encountered this?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r56p6c/frustrating_glitch_that_cuts_off_portions_of/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o5gpn22",
          "author": "qualityvote2",
          "text": "u/TrainingEngine1, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-15 05:42:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iapfc",
          "author": "changing_who_i_am",
          "text": "Yes, having the same bug for a few weeks now, very frustrating. One thing you can try is asking it to put all citations at the end of the response, but this may or may not be successful as it goes against \"policy\" üôÑ",
          "score": 2,
          "created_utc": "2026-02-15 14:00:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o1dbc",
              "author": "TrainingEngine1",
              "text": "Weird, not sure why it would be a policy violation but I think I figured it out. I noticed from reading its reasoning/thoughts it used the term \"filecite\" and figured that's definitely what those things were called and it knows them by. So yea I basically told it to not put them within the message at all, and only at the very end. Also tried to have it cite references to files as text only and it seemed to work too.",
              "score": 2,
              "created_utc": "2026-02-16 11:39:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hr0wh",
          "author": "CategoryFew5869",
          "text": "ChatGPT UI is pretty bad. Do you mind sharing the exact steps to reproduce this? It looks like something a small script can fix.",
          "score": 1,
          "created_utc": "2026-02-15 11:36:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3vexj",
      "title": "Is it just me, or did ChatGPT just nerf voice transcriptions (again)?",
      "subreddit": "ChatGPTPro",
      "url": "https://www.reddit.com/r/ChatGPTPro/comments/1r3vexj/is_it_just_me_or_did_chatgpt_just_nerf_voice/",
      "author": "mandressta",
      "created_utc": "2026-02-13 17:29:49",
      "score": 6,
      "num_comments": 8,
      "upvote_ratio": 0.76,
      "text": "Has anyone else noticed the absolute roller coaster with ChatGPT‚Äôs audio messages transcription limits? I feel like we just had a \"Golden Age\" for like 10 days and now we're back to the Stone Age.\n\n**The chaotic Timeline:**\n\n* **2024 / Early 2025:** Solid. Handled **3‚Äì4 minute** transcripts easily.\n* **Most of 2025:** Huge regression. Capped at **\\~1 minute** before failing.\n* **Feb 2026 (Last 10 Days):** Total **BEAST** mode. 10-minute transcriptions were done flawlessly.\n* **Today:** Back to sucking. Anything over **30**/**60 seconds** fails.\n\nIs OpenAI A/B testing this or what? Having that 10-minute window (im sure is expensive for them) made is very powefull for certain use cases. No other chatbot has that big of window, that im aware of.\n\n**Anyone else seeing these 1-minute caps return today?**",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r3vexj/is_it_just_me_or_did_chatgpt_just_nerf_voice/",
      "domain": "self.ChatGPTPro",
      "is_self": true,
      "comments": [
        {
          "id": "o574tg1",
          "author": "qualityvote2",
          "text": "u/mandressta, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-13 17:29:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5khx2y",
          "author": "mandressta",
          "text": "I fixed it, delete cache on chatgpt app and restart phone",
          "score": 2,
          "created_utc": "2026-02-15 20:40:23",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5femhc",
          "author": "Hawk-432",
          "text": "You on free or? For me it always does 10 mins",
          "score": 1,
          "created_utc": "2026-02-15 00:12:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ffsic",
              "author": "mandressta",
              "text": "Pro",
              "score": 1,
              "created_utc": "2026-02-15 00:19:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ffvsd",
                  "author": "mandressta",
                  "text": "So you haven't seen any changes?? It still doesn't work since yesterday",
                  "score": 1,
                  "created_utc": "2026-02-15 00:19:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bo4mo",
          "author": "mandressta",
          "text": "Anyone?",
          "score": 0,
          "created_utc": "2026-02-14 11:20:19",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r37c6p",
      "title": "Voice mode is incredible. But how do I get it to read to me more than just a few sentences?",
      "subreddit": "ChatGPTPro",
      "url": "https://i.redd.it/mbsflux525jg1.jpeg",
      "author": "Ramenko1",
      "created_utc": "2026-02-12 22:18:46",
      "score": 6,
      "num_comments": 32,
      "upvote_ratio": 0.62,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Question",
      "permalink": "https://reddit.com/r/ChatGPTPro/comments/1r37c6p/voice_mode_is_incredible_but_how_do_i_get_it_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o528hor",
          "author": "qualityvote2",
          "text": "u/Ramenko1, there weren‚Äôt enough community votes to determine your post‚Äôs quality.  \nIt will remain for moderator review or until more votes are cast.",
          "score": 1,
          "created_utc": "2026-02-12 22:18:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sr68",
          "author": "Neurodivergently",
          "text": "Get a text to voice reader. They can read entire books.",
          "score": 3,
          "created_utc": "2026-02-13 16:31:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o576aqi",
              "author": "Ramenko1",
              "text": "Have any in particular you recommend? Appreciate the tip.",
              "score": 2,
              "created_utc": "2026-02-13 17:37:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o577yqn",
                  "author": "Neurodivergently",
                  "text": "There are SOOO many solutions. Theres something for pretty much any type of user. Honestly, to answer the question it depends on your needs.\n\nI‚Äôve used a lot of different readers, each for something different \n\nGpt-reader.com might be fine",
                  "score": 2,
                  "created_utc": "2026-02-13 17:45:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5lisa1",
                  "author": "Hir0shima",
                  "text": "Eleven reader",
                  "score": 1,
                  "created_utc": "2026-02-16 00:00:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5nhz2n",
                  "author": "Obvious_King2150",
                  "text": "Use Elevenlab reader it's by Elevenlab its free version is also great give it a try",
                  "score": 1,
                  "created_utc": "2026-02-16 08:40:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o52jdyp",
          "author": "simsimulation",
          "text": "I haven‚Äôt used it, but I believe notebook lm is good for this?",
          "score": 5,
          "created_utc": "2026-02-12 23:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52jnwd",
              "author": "Ramenko1",
              "text": "Notebook LM makes podcasts. Not the same as verbatim reading it out back to me.",
              "score": 6,
              "created_utc": "2026-02-12 23:18:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ag273",
          "author": "unfathomably_big",
          "text": "Just press the speaker button next to a long response",
          "score": 2,
          "created_utc": "2026-02-14 04:36:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52l01n",
          "author": "manjit-johal",
          "text": "Voice mode can get messy since it‚Äôs one long stream of context. If you add clearer turn breaks, even something simple like a short pause or a keyword trigger before sending it to GPT, the responses tend to be way more predictable and on point.",
          "score": 1,
          "created_utc": "2026-02-12 23:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52pdz8",
              "author": "Banjoschmanjo",
              "text": "Can you give an example of what you mean? I don't understand",
              "score": 1,
              "created_utc": "2026-02-12 23:50:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o52rhbb",
                  "author": "manjit-johal",
                  "text": "Sure. Imagine a research agent with skills like ‚Äúsearch web,‚Äù ‚Äúsummarize,‚Äù and ‚Äúwrite report.‚Äù If each skill keeps passing its full output into the next call, the context window fills up fast, and the plan drifts. Instead, you can keep each skill narrow and only pass back a short, structured result, like key findings, so the planner decides what actually goes into the next prompt.",
                  "score": 1,
                  "created_utc": "2026-02-13 00:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o57a1a2",
          "author": "smartbluecat",
          "text": "Try satandard voice if you haven't l. It has no trouble with this sort of thing. The \"advanced\" voice is a massive downgrade in many ways: being far lighter and optimised for speed rather than accuracy.",
          "score": 1,
          "created_utc": "2026-02-13 17:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57adpm",
              "author": "Ramenko1",
              "text": "I appreciate this. How do I toggle it to standard voice? Never knew that was an option.",
              "score": 2,
              "created_utc": "2026-02-13 17:56:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5c93by",
                  "author": "smartbluecat",
                  "text": "Under Personalisation, scroll down to Advanced, deselect Advanced Voice. \n\nI honestly can't think of a single use case where I'd rather use Advanced voice mode: it's weaker, has less reasoning, and sounds vapid. Latency is nice... but I'd rather wait a second or two and have accuracy and depth instead.",
                  "score": 2,
                  "created_utc": "2026-02-14 13:58:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5snffd",
          "author": "Wes-5kyphi",
          "text": "You haven't stated if you're a free, plus or pro user... also, I've never seen this using standard voice as a plus user.  ",
          "score": 1,
          "created_utc": "2026-02-17 02:15:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t4feh",
              "author": "Ramenko1",
              "text": "I am a plus user! I guess apparently I am using \"Advanced\" voice mode.",
              "score": 1,
              "created_utc": "2026-02-17 04:01:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52gns8",
          "author": "Warp_Speed_7",
          "text": "Weird haven‚Äôt seen that. I have it read long things all the time.",
          "score": 0,
          "created_utc": "2026-02-12 23:01:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52ir5s",
              "author": "Ramenko1",
              "text": "So what do you prompt?",
              "score": 2,
              "created_utc": "2026-02-12 23:13:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}