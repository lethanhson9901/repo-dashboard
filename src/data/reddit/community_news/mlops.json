{
  "metadata": {
    "last_updated": "2025-12-30 17:18:57",
    "time_filter": "week",
    "subreddit": "mlops",
    "total_items": 2,
    "total_comments": 8,
    "file_size_bytes": 10779
  },
  "items": [
    {
      "id": "1pvygot",
      "title": "Feature Stores: why the MVP always works and that's the trap (6 years of lessons)",
      "subreddit": "mlops",
      "url": "https://mikamu.substack.com/p/feature-store-the-sprawl",
      "author": "Valuable-Cause-6925",
      "created_utc": "2025-12-26 07:24:13",
      "score": 24,
      "num_comments": 9,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mlops/comments/1pvygot/feature_stores_why_the_mvp_always_works_and_thats/",
      "domain": "mikamu.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw0uk45",
          "author": "stratguitar577",
          "text": "Sounds like the requirements were not defined at all before building. If you approach a feature store without planning on what it needs to solve, it’s pretty obvious you’ll run into these problems. Point in time training data is a key requirement so not sure why it’s talked about as an afterthought. ",
          "score": 7,
          "created_utc": "2025-12-26 13:50:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0xm2i",
              "author": "Valuable-Cause-6925",
              "text": "I totally agree that dataset construction is a must-have capability for a Feature Store.  \n  \nIn practice, though, the teams care much more about \"getting to production\" first. Figuring out how to make sure that training is consistent with serving is a secondary concern that some teams solve and others leave to their DS counterparts.",
              "score": 1,
              "created_utc": "2025-12-26 14:10:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw13wxq",
                  "author": "stratguitar577",
                  "text": "That’s where the feature “platform” takes over vs just the storage piece feature stores deal with. It should abstract the compute to allow writing the transformation once and running across both training and serving contexts for eliminating skew. ",
                  "score": 1,
                  "created_utc": "2025-12-26 14:50:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw1qynv",
          "author": "DangKilla",
          "text": "An acquaintance is implementing too many features before launching, instead of focusing on the problem being solved",
          "score": 2,
          "created_utc": "2025-12-26 16:57:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw1t7jw",
              "author": "Valuable-Cause-6925",
              "text": "Feature Store related?",
              "score": 1,
              "created_utc": "2025-12-26 17:09:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwitrbv",
          "author": "seunosewa",
          "text": "This might as well be an advertisement for storing everything in standard relational databases like PostgreSQL and MySQL.",
          "score": 1,
          "created_utc": "2025-12-29 10:13:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwivbr9",
              "author": "Valuable-Cause-6925",
              "text": "By everything you mean what exactly?",
              "score": 1,
              "created_utc": "2025-12-29 10:27:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwjces7",
                  "author": "seunosewa",
                  "text": "Data.",
                  "score": 1,
                  "created_utc": "2025-12-29 12:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pxpzeu",
      "title": "Built a small production-style MLOps platform while learning FastAPI, Docker, and CI/CD – looking for feedback",
      "subreddit": "mlops",
      "url": "https://www.reddit.com/r/mlops/comments/1pxpzeu/built_a_small_productionstyle_mlops_platform/",
      "author": "Melodic_Struggle_95",
      "created_utc": "2025-12-28 12:14:33",
      "score": 9,
      "num_comments": 9,
      "upvote_ratio": 0.8,
      "text": "I’ve been learning MLOps and wanted to move beyond notebooks, so I built a small production-style setup from scratch.\n\n\n\nWhat it includes:\n\n\\- Training pipeline with evaluation gate\n\n\\- FastAPI inference service with Pydantic validation\n\n\\- Dockerized API\n\n\\- GitHub Actions CI pipeline\n\n\\- Swagger UI for testing predictions\n\n\n\nThis was mainly a learning project to understand how models move from training to deployment and what can break along the way.\n\n\n\nI ran into a few real-world issues (model loading inside Docker, environment constraints on Ubuntu, CI failures) and documented fixes in the README.\n\n\n\nI’d really appreciate feedback on:\n\n\\- Project structure\n\n\\- Anything missing for a “real” MLOps setup\n\n\\- What you’d add next if this were production\n\n\n\nRepo: [https://github.com/faizalbagwan786/mlops-production-platform](https://github.com/faizalbagwan786/mlops-production-platform)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/mlops/comments/1pxpzeu/built_a_small_productionstyle_mlops_platform/",
      "domain": "self.mlops",
      "is_self": true,
      "comments": [
        {
          "id": "nwcrjyb",
          "author": "raiffuvar",
          "text": "Not gonna put it in production. Split training and platform into different repos.\nGrab a real training repo, stick it here, and see what happens.",
          "score": 4,
          "created_utc": "2025-12-28 12:32:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcs8hh",
              "author": "Melodic_Struggle_95",
              "text": "Fair point. This repo isn’t meant to represent a final production setup, but a learning-focused MLOps platform where I can iterate end to end.\nIn a real production environment, I agree that training and serving would typically live in separate repos or at least separate deployment units, often owned by different teams.\nFor now, I kept them together to understand the full lifecycle and the interfaces between training, evaluation, and inference. My next step is to split training and serving and treat the trained model as an external artifact to the platform.\nAppreciate the feedback.",
              "score": 2,
              "created_utc": "2025-12-28 12:38:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwh2vk2",
          "author": "BackgroundLow3793",
          "text": "Oh that's nice. Thank you. I'm learning MLOps recently too. I think next thing is MLFlow, understand why people use MLFlow. I mean it doesn't have to be MLFLow, but the core idea is tracking and model versioning I guess. \n\nThere is also a good article here: [https://docs.databricks.com/aws/en/machine-learning/mlops/mlops-workflow](https://docs.databricks.com/aws/en/machine-learning/mlops/mlops-workflow)",
          "score": 2,
          "created_utc": "2025-12-29 02:18:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjldtq",
              "author": "Melodic_Struggle_95",
              "text": "Thanks! Yeah, I’m on the same page. The main value is tracking and versioning, not MLflow itself. I’m planning to add that next, and the Databricks article looks solid. Appreciate you sharing it.",
              "score": 1,
              "created_utc": "2025-12-29 13:48:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdgfa6",
          "author": "wallesis",
          "text": "Where's the \"platform\" part?",
          "score": 1,
          "created_utc": "2025-12-28 15:15:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdl5gc",
              "author": "Melodic_Struggle_95",
              "text": "Right now the “platform” part is still small by design. At this stage I’m focusing on building the core pieces first a clean training pipeline, an evaluation gate, a consistent model loading layer, and a serving API with clear contracts.The idea is to treat this as the foundation, and then gradually add real platform features like CI/CD, model registry, monitoring, and automated retraining. This repo shows the early platform core, not the final version.",
              "score": 1,
              "created_utc": "2025-12-28 15:40:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwozj3m",
          "author": "Significant-Fig-3933",
          "text": "How do you handle data lineage, code tracking, orchestration, and data/model monitoring?\nLike what exact data and what exact code (model design, features, etc) was the model trained with?\n\nAnd how do you coordinate/track retraining etc (ie orchestration)?",
          "score": 1,
          "created_utc": "2025-12-30 07:24:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoztqm",
              "author": "Melodic_Struggle_95",
              "text": "Right now the project tracks data and code through the training pipeline and Git commits, with retraining handled manually, and the next planned step is adding MLflow and orchestration to properly manage lineage, versioning, monitoring, and automated retraining.",
              "score": 2,
              "created_utc": "2025-12-30 07:27:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqwnyh",
          "author": "bad_detectiv3",
          "text": "Can you provide resource where you built up on MLOps material? I want to give this a try beyond using LLM in application use case",
          "score": 1,
          "created_utc": "2025-12-30 15:49:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}