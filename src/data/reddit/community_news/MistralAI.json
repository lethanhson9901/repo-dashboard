{
  "metadata": {
    "last_updated": "2026-02-28 16:44:10",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 87,
    "file_size_bytes": 101945
  },
  "items": [
    {
      "id": "1rf8asl",
      "title": "Mistral AI Lands Accenture as Latest Big Client",
      "subreddit": "MistralAI",
      "url": "https://www.wsj.com/tech/ai/mistral-ai-lands-accenture-as-latest-big-client-7c5a0ca4",
      "author": "BuildwithVignesh",
      "created_utc": "2026-02-26 12:00:13",
      "score": 199,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf8asl/mistral_ai_lands_accenture_as_latest_big_client/",
      "domain": "wsj.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7ikx90",
          "author": "Mystical_Whoosing",
          "text": "Very cool, congratulations!",
          "score": 19,
          "created_utc": "2026-02-26 14:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ir50w",
          "author": "LowIllustrator2501",
          "text": "* [Accenture Struck a Deal With OpenAi. The Stock Is Still Sliding Despite New OpenAI Deal.](https://www.barrons.com/articles/accenture-stock-price-openai-deal-32404cab)\n* [Anthropic and Accenture Strike AI Deal Targeting Business Clients](https://www.wsj.com/articles/anthropic-and-accenture-strike-ai-deal-targeting-business-clients-0a82f28a)\n\nAccenture has deals with everyone. ",
          "score": 17,
          "created_utc": "2026-02-26 14:38:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jqgu1",
              "author": "4baobao",
              "text": "Mistral doesn't, so good for them",
              "score": 11,
              "created_utc": "2026-02-26 17:23:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pdyy7",
          "author": "tom_mathews",
          "text": "The enterprise play makes sense for Mistral because their models actually deploy well on-prem, which is what these consulting firms need when their clients have data residency requirements. I've run Mistral Large and the older Medium behind corporate firewalls and the inference cost per token is genuinely competitive once you factor in not paying the OpenAI tax on every API call at scale.\n\nThe real question is whether Accenture's army of consultants can actually fine-tune and deploy these models competently or if they'll just wrap the API in a chatbot and call it \"AI transformation.\" Based on what I've seen from Big Four/Five consulting engagements, it's usually the latter until the client pushes back.\n\nMistral's advantage here is the EU angle. Half of Accenture's enterprise clients in Europe won't touch US-hosted inference for regulated workloads. That alone justifies the deal regardless of benchmark numbers.",
          "score": 3,
          "created_utc": "2026-02-27 14:22:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lczcn",
          "author": "LoadZealousideal7778",
          "text": "The funny thing is, Mistral is probably one of the most secure pure AI labs. Not because they are likely to achieve profitability any time soon but simply because the cost/benefit of bailing then out is so low. Any one of their bigger clients have the cash on hand to bail them out. Or just ask the EU nicely to bankroll them. IRISÂ² cost 10B to have a strategic alternative to Starlink. Airbus exists because Europe bankrolled a competitior to Boeing into existence. Throw some pocket change at them to keep the head over and everyone is happy.",
          "score": 4,
          "created_utc": "2026-02-26 21:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o3ote",
              "author": "AnaphoricReference",
              "text": "I agree. I try out a lot of different models in workflows, but for confidential workflows and core architecture components like embedding, voice, and routing I exclusively use Mistral models, because they feel like a future-proof and secure choice.",
              "score": 2,
              "created_utc": "2026-02-27 08:32:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7klv85",
          "author": "guyfromwhitechicks",
          "text": "Yipee",
          "score": 1,
          "created_utc": "2026-02-26 19:49:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbtult",
      "title": "If you actively want to make Le Chat better, then start using the Thumbs Up/Down buttons on individual responses!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/",
      "author": "Little_Protection434",
      "created_utc": "2026-02-22 18:44:42",
      "score": 170,
      "num_comments": 11,
      "upvote_ratio": 0.97,
      "text": "A few days ago I asked the question how I as an user can make Le Chat better. I got an amazing answer and wanted to share it with you. Thanks u/[Individual-Worry5316](https://www.reddit.com/user/Individual-Worry5316/)\n\nAn user can give direct feedback that makes Le Chat better. \n\nIt would beÂ helpful to distinguish between immediate context (how it behaves right now) and global training (how it improves for everyone over time).\n\n**The most effective way to help Le Chat improve globally is by using the Thumbs Up/Down buttons on individual responses. When you click these you usually have the option to provide specific details.**\n\nThis data is used for RLHF (Reinforcement Learning from Human Feedback). This is the primary way developers \"tune\" the model to be more helpful, accurate and safe. Giving feedback directly in the text of a conversation is useful for fixing a mistake in that specific moment, but itâ€™s less likely to be used for model-wide training compared to the dedicated feedback buttons.\n\nLearning happens in two distinct ways:\n\nÂ \\* Short-term (In-Conversation): Within a single chat session, Le Chat \"learns\" your preferences and the facts you provide. This is restricted to that specific conversation window.\n\nÂ \\* Long-term (Global): The model does not learn in real-time from your facts to update its base knowledge. If you tell it a new fact today, it won't automatically know that fact when you start a new chat tomorrow, nor will it know it when talking to a different user. Privacy and Knowledge Sharing Knowledge is not transferred directly from one user to another in real-time. If you teach the model a specific niche fact about your hobby, another user in a different part of the world won't suddenly see that reflected in their answers.\n\n**Significant improvements only happen when the developers at Mistral aggregate feedback and data to release a new version or a \"fine-tuned\" update of the model. Your feedback helps them decide what those updates should look like.**\n\nSo, if you want to help make Le Chat better, then start using the **Thumbs Up/Down buttons on individual responses!**",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6tnwuk",
          "author": "Kualdiir",
          "text": "Also, using it instead of competitors and getting other people to use it also helps a bunch! Had a colleague who paid for chatgpt premium and got her to switch to le chat instead. ",
          "score": 25,
          "created_utc": "2026-02-22 19:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x1m2q",
              "author": "SkyPL",
              "text": "I would avoid doing that for the people who are unaware of the AI space in general. The difference between Mistral  and ChatGPT can be night and day, and with Mistral loving to provide misleading answers (which, to a degree, can be addressed by your own pre-made prompts combined with follow-up questions) - it can have very negative consequences in the person's job vs if that person had used ChatGPT, Gemini or any other leading LLM.",
              "score": 5,
              "created_utc": "2026-02-23 07:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o73dsos",
                  "author": "Revision2000",
                  "text": "Iâ€™d honestly be concerned for a personâ€™s job in general, if they rely heavily on an LLM _[to do their job for them]_.Â \n\nSo rather than avoiding Mistral altogether, Iâ€™d much rather _educate_ my colleague on some of the LLM options out there, how to use it effectively as a tool, what traps to avoid, and why I switched to Mistral.Â \n\nIn my case, because it works good enough and I want to support a European product. Plenty of colleagues donâ€™t care much for that and stick with what they already know (ChatGPT), but at least now they know there are alternatives.Â \n",
                  "score": 6,
                  "created_utc": "2026-02-24 06:29:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o773l08",
                  "author": "Kualdiir",
                  "text": "We are kinda required to use copilot for work so not like it can get worse. She uses mistral for private use and isn't tech illiterate.",
                  "score": 0,
                  "created_utc": "2026-02-24 19:59:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tv7lm",
          "author": "[deleted]",
          "text": "Hi Mistral, can we have learn mode? :)",
          "score": 8,
          "created_utc": "2026-02-22 19:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tvyv3",
          "author": "micocoule",
          "text": "I wasnâ€™t doing it because I didnâ€™t understand the purpose of the ðŸ‘ ðŸ‘Ž. Iâ€™ll do it starting now",
          "score": 14,
          "created_utc": "2026-02-22 19:58:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7bak8r",
              "author": "pkk888",
              "text": "You and me both!",
              "score": 1,
              "created_utc": "2026-02-25 12:13:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wkxsr",
          "author": "Minute-Situation-724",
          "text": "Yes, we should start to use it for as many different use-cases as possible to see where it's strenghts and limitations are in practice. And then give feedback about it. I also ended my subscribtion of ChatGPT and came to Mistral instead. It's much more stable with so much less drama. ",
          "score": 4,
          "created_utc": "2026-02-23 05:24:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u926e",
          "author": "CodeBlurred",
          "text": "Best way to improve. Feedback helps a lot!",
          "score": 7,
          "created_utc": "2026-02-22 21:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7116yh",
          "author": "Extra_Programmer788",
          "text": "I use it all the time, i use le chat quite often, itâ€™s a good model to have conversations compared to the gpt 5 or opus models.",
          "score": 3,
          "created_utc": "2026-02-23 21:54:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tpqe6",
          "author": "suiramarius",
          "text": "How do I make Vibe better, besides paying for it?",
          "score": 6,
          "created_utc": "2026-02-22 19:27:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfq60l",
      "title": "Mistral Vibe charged me $280, check your account.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "author": "ButtholeCleaningRug",
      "created_utc": "2026-02-26 23:29:10",
      "score": 128,
      "num_comments": 42,
      "upvote_ratio": 0.95,
      "text": "II figured Iâ€™d give Mistral Vibe a go this month instead of Claude Code. I checked their site to see if there were any indicators of how many tokens I could burn through before being shut off (like with Claude). At the time of signing up for Vibe, the site only mentioned â€œgenerous usage,â€ so I had no idea when Iâ€™d hit any kind of limit. I saw nothing else and went on my way. I used it for a couple of weeks on some projects I was working on and didnâ€™t love it or hate it. I was at dinner when I suddenly got an invoice for $280. I logged into the site and there is now a monthly usage tracker with â€œPay as you goâ€ set by default and, as far as I can tell, no way to turn it off. Safe to say I will not be using Mistral Vibe again. I guess this is more a PSA than anything, so check your Vibe usage.\n\nEdit: Because I should have mentioned it. Current Le Chat Pro subscriber.  \nEdit2: Even more wild I had thought something like this could happen, so I even capped my API usage at $20. I submitted a ticket with Mistral, will update.\n\n  \nUpdate 1: Someone from the Mistral team reached out and I emailed with them. I was told, â€œwe have updated clearer usage monitoring in your Vibe page, and we will refund everyone impacted this month while this tracking was not in place.â€ I genuinely appreciate how quickly they resolved this, and I will update again when I see the chargeback hit my card.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7oeibe",
          "author": "pandora_s_reddit",
          "text": "Hi everyone, thank you for the quick report! As mentioned, the team is working on fixing the issue and refunding affected individuals.\n\n\nWe will post further details in a follow-up later. Thanks again, and weâ€™re sorry for the inconvenience.\n\n\nIf you are not refunded the incomming days and you believe to have been affected, please reach out via support.\n\n\nEDIT: Follow up: https://www.reddit.com/r/MistralAI/comments/1rg8789/vibe_payg_refund/",
          "score": 37,
          "created_utc": "2026-02-27 10:15:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ooqw9",
              "author": "ButtholeCleaningRug",
              "text": "Thank you for responding so quickly. Iâ€™ve read enough stories on different subreddits of â€œCompany C charged me Y,â€ where the only recourse is talking to the companyâ€™s AI, which just gaslights and denies the claim. Filing a ticket on your site was really easy, and you were quick to follow up with a real human. Every company makes mistakes, and itâ€™s nice to see one handling it the right way. Sadly, these days it seems to be the exception rather than the rule.\n",
              "score": 14,
              "created_utc": "2026-02-27 11:43:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7qthhq",
              "author": "teilifis_sean",
              "text": "Can you explain why I was charged for 12 months of premium when I was only given access to one month of premium? The support lady said once an early payment was missed there was an outstanding balance. So even though all the next 11 transactions went through Mistral didn't provide premium that entire time. That's not how these things work, you either cut the service if there is an outstanding balance and stop taking money or continue to provide it while taking money. You don't get to take money and not provide the premium service I was paying for citing a missed transaction a year before.\n\nI was simply naive trying to support a nascent EU tech scene but you guys simply ripped me off. I will never be giving you money again and now I give Claude 100 Euro a month now.\n\nI'm so infuriated with you guys. I can explain that behavior. Greed.",
              "score": 1,
              "created_utc": "2026-02-27 18:30:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mji9q",
          "author": "LongjumpingTear5779",
          "text": "They tried to charge me 119 EUR. Thanks God I just have small amount of money in account with card (just move money to it when I am buing somethink).\nI put limit 10 EUR in Scale. In my language (Polish) when I read info about Le Chat Pro tere is only \"Access to Mistral Vibe\" - 0 info about extra payment for this.Â \nIn my account also today they show limit of usage - I used 94% but in Polish it's says \"The Scale plan resist after exceeding the limit.\"\nSo if I don't exceed why they charge me...\nAlso they should put somethink like this with information, this usage just show up today so when I bought Le Chat Pro and use there was no info about limits - and also for save i put 10 EUR limit.\n\n\nI send them ticket.Â ",
          "score": 20,
          "created_utc": "2026-02-27 01:50:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mkzw9",
              "author": "ButtholeCleaningRug",
              "text": "Hopefully this is just some weird bug and they are quick with refunds. I know Europe (EU) has more consumer protections so if itâ€™s not an error it seems like a pretty dumb play from a PR and legal standpoint.Â ",
              "score": 6,
              "created_utc": "2026-02-27 01:59:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mplu2",
                  "author": "LongjumpingTear5779",
                  "text": "Idk how it work in France. In Poland they can put aÂ fine up to 10% of the company's annual turnover and compensation for affected parties.\nProbably it is implementation of EU laws so if they don't say sorry and refund this can hurt.\n\n\nSome telecomunication operators got fine because in marketing they say \"no limit Internet\" and there was little * - after x GB internet slow down to n Mbps.",
                  "score": 4,
                  "created_utc": "2026-02-27 02:25:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7o7l2h",
              "author": "ComeOnIWantUsername",
              "text": "Are you using Organization API key, or Vibe API key?",
              "score": 3,
              "created_utc": "2026-02-27 09:09:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7luu5t",
          "author": "feral_user_",
          "text": "Did you already have a Le Chat subscription? I believe it's included with it?",
          "score": 7,
          "created_utc": "2026-02-26 23:31:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7luwcf",
              "author": "ButtholeCleaningRug",
              "text": "I did! ",
              "score": 3,
              "created_utc": "2026-02-26 23:31:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7lyrlo",
                  "author": "feral_user_",
                  "text": "Wow, that is worrisome then. Let us know when you find out what happened.",
                  "score": 7,
                  "created_utc": "2026-02-26 23:53:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m4nz4",
          "author": "TapedOrigami",
          "text": "Thanks, I now also see the limit, and the pay as you go warning. Really untransparant to not notify us about this change. They keep saying, enough for all day long usage.",
          "score": 6,
          "created_utc": "2026-02-27 00:26:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mk1s7",
              "author": "LongjumpingTear5779",
              "text": "In your language it's also say The Scale Plan after exceed the limit? (It's somethink like that in their Polish ui)",
              "score": 1,
              "created_utc": "2026-02-27 01:53:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ni9s1",
                  "author": "ComeOnIWantUsername",
                  "text": "Where do you see this warning? I checked it myself and can't find anything like it",
                  "score": 1,
                  "created_utc": "2026-02-27 05:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mz1ti",
          "author": "sampdoria_supporter",
          "text": "I've been using Codestral on  console.mistral.ai and it says at the top \"use codestral via your favorite code completion tool for free\" - I better screenshot it",
          "score": 4,
          "created_utc": "2026-02-27 03:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nf9wl",
              "author": "mobileJay77",
              "text": "This could mean \"bring your own LLM\"? You can set up vibe to use any.",
              "score": 0,
              "created_utc": "2026-02-27 05:07:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7m3zxw",
          "author": "_st4rlight_",
          "text": "Keep us posted, thanks! In Admin->usage does it state which APIs charged you this much? If you're only using Vibe you should be using Devstral, which is not even listed among the APIs that could charge you.\n\nMaybe an error on their part?",
          "score": 2,
          "created_utc": "2026-02-27 00:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m7squ",
              "author": "ButtholeCleaningRug",
              "text": "The only record with the charge breakdown is in the invoice they sent. I hunted all over their dashboard and the only API tracker they have is the one I set to max at $20/mo, and it currently reads $0 used.\n\n  \nEdit: It certainly could be an error, hopefully it is, but depending on your payment method and your financial health ,waiting for Mistral to refund you could be a really bad time.",
              "score": 2,
              "created_utc": "2026-02-27 00:43:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7o38bf",
          "author": "Developer_Bot",
          "text": "Could it be that you entered the wrong API key into your vibe set-up? I never even generated an API Plan key. Iam on pro too and dont have that issue. My API usage still shows 0. Daily User here.",
          "score": 2,
          "created_utc": "2026-02-27 08:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o46f5",
              "author": "Developer_Bot",
              "text": "https://www.reddit.com/r/MistralAI/s/x0eTeuaie6\nI got it from there.so i was prepared to use the correct key.",
              "score": 2,
              "created_utc": "2026-02-27 08:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7obo2a",
              "author": "ButtholeCleaningRug",
              "text": "No, I used the correct key. Vibe has its own key, and through their newly implemented (and never announced) tracker, it shows that I went over the limit and was switched to pay-as-you-go at some point. I have no idea when, as I never received any notification that pay-as-you-go had become the policy, nor that it couldnâ€™t be turned off. The only API tracker visible on the page was one Iâ€™d set to a $20 per month maximum, and it still shows $0 in usage. I understand that the tracker probably applies to other API keys, but when I first set up Vibe, it was the only area on the entire page that had any form of API tracker or a way to set a usage limit, and it still is. \n\nHere is the newly implemented Vibe tracker. It does not even show how many tokens I have used on pay-as-you-go. It feels like they decided to start charging people before they actually rolled out the most important features: a way to set limits, turn it off, and a way to see what you have spent.\n\nhttps://preview.redd.it/k8tswfvec0mg1.png?width=1142&format=png&auto=webp&s=06d0cd9b902c32219a102315ae3314ff5ad9179c\n\n",
              "score": 2,
              "created_utc": "2026-02-27 09:48:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7o7c26",
              "author": "ComeOnIWantUsername",
              "text": "Just out of curiosity, do you see any Vibe token usage on [https://console.mistral.ai/codestral/cli](https://console.mistral.ai/codestral/cli) ? Mine shows that it can't retrieve it. I use API key generated on this page, and not regular key (so as it should be)",
              "score": 1,
              "created_utc": "2026-02-27 09:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o9bpw",
                  "author": "Developer_Bot",
                  "text": "Yes (on firefox).it des not say 'vibe' though. Just token usage.",
                  "score": 1,
                  "created_utc": "2026-02-27 09:26:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nqvzz",
          "author": "andriatz",
          "text": "Like all API services, before using them, you need to go to the settings and set the maximum monthly spending limits. I set mine to 5 euros, and indeed, thatâ€™s the amount I was billed. After some fine-tuning and a lot of vibe",
          "score": 2,
          "created_utc": "2026-02-27 06:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m4eyk",
          "author": "wirtshausZumHirschen",
          "text": "what you get charged more than your API cap of 20$?! Do they count Mistral Vibe usage differently or what?",
          "score": 1,
          "created_utc": "2026-02-27 00:24:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m86be",
              "author": "ButtholeCleaningRug",
              "text": "Apparently they do, but there is no actual tracker anywhere on their site that i could find. Maybe they plan on rolling it out, but bad form to charge people before they can actually track what they spend. The only API tracker they do have, reads $0 for me. ",
              "score": 1,
              "created_utc": "2026-02-27 00:45:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nu6wv",
          "author": "Legitimate-Help8016",
          "text": "Where do I find that? In admin panel I can go under limits and disable spending..?",
          "score": 1,
          "created_utc": "2026-02-27 07:06:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o27u8",
              "author": "TapedOrigami",
              "text": "You can find the usage info and the warning here: https://console.mistral.ai/codestral/cli",
              "score": 2,
              "created_utc": "2026-02-27 08:18:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o2nc3",
                  "author": "Legitimate-Help8016",
                  "text": "I see, thanks, I turned of the limit, will PAG still apply?",
                  "score": 1,
                  "created_utc": "2026-02-27 08:22:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7o6yzy",
          "author": "ComeOnIWantUsername",
          "text": "I can't even check my Vibe usage info lol\n\nI'll definitely stop using it until we'll know what is happening\n\n\n\nhttps://preview.redd.it/z29zi0ys50mg1.png?width=1244&format=png&auto=webp&s=7dd7b82b4c8ffb47b7316486ba4166b824f6f94d\n\n",
          "score": 1,
          "created_utc": "2026-02-27 09:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7s742c",
          "author": "umipaloomi",
          "text": "I just created an api key on la platforme and my usage is always at 0$ even though Iâ€™m using devstral 2 via opencode regularly",
          "score": 1,
          "created_utc": "2026-02-27 22:38:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s7zcw",
              "author": "ButtholeCleaningRug",
              "text": "Different API key for Vibe. My non-Vibe API also says $0. If youâ€™re using the Vibe API you need to scroll to the bottom. They added a tracker that says how much usage you have left before you enter PAYG. Last I looked there is no way to set a limit or turn off PAYG so youâ€™re stuck watching that until they add some sort of feature to limit usage.Â ",
              "score": 1,
              "created_utc": "2026-02-27 22:43:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7s8fxe",
                  "author": "umipaloomi",
                  "text": "I see. Iâ€™m on the experiment planâ€¦ but i never had issues with limits etcâ€¦ not sure if what the limits here are. Also mistral Large 3 works like s charm.",
                  "score": 1,
                  "created_utc": "2026-02-27 22:45:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nfdst",
          "author": "cutebluedragongirl",
          "text": "French engineering at its finest, I guess.",
          "score": -7,
          "created_utc": "2026-02-27 05:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nqbnz",
              "author": "porzione",
              "text": "oh no - openai, anthropic, google, Chinese companies - they all have these overcharge \"bugs\"",
              "score": 2,
              "created_utc": "2026-02-27 06:33:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nlds2",
          "author": "Emotional-Cupcake432",
          "text": "You know you can use it with ollam for free localy",
          "score": -2,
          "created_utc": "2026-02-27 05:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nnecd",
              "author": "Kypsys",
              "text": "*for free if you have a 2000$ mac, or a 5000$ GPU",
              "score": 4,
              "created_utc": "2026-02-27 06:09:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o8ed9",
                  "author": "ComeOnIWantUsername",
                  "text": "and spend more on electricity for this machine than for API usage and/or subscription",
                  "score": 1,
                  "created_utc": "2026-02-27 09:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rgwm8e",
      "title": "New models versions coming soon - Devstral 2.1",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rgwm8e/new_models_versions_coming_soon_devstral_21/",
      "author": "gohm_dv",
      "created_utc": "2026-02-28 07:44:34",
      "score": 95,
      "num_comments": 24,
      "upvote_ratio": 0.98,
      "text": "https://preview.redd.it/zr29y4u3w6mg1.png?width=916&format=png&auto=webp&s=9e8891b24508a82ba0830bc13f9203a5a8c673e9\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rgwm8e/new_models_versions_coming_soon_devstral_21/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7uia9y",
          "author": "spaceman_",
          "text": "So no mention of new small models? And the small models are retiring? Is this the end of local Mistral for mere mortals?",
          "score": 6,
          "created_utc": "2026-02-28 08:05:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uzecd",
              "author": "Chemistrycat214",
              "text": "I think they will remain as open weigh for local use, but they won''t work on them any further nor provide api access.",
              "score": 3,
              "created_utc": "2026-02-28 10:48:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ujmqx",
              "author": "LowIllustrator2501",
              "text": "That's the advantage  of local models - once it's release you can have it. If Mistral no longer hosts them - it doesn't affect users in any way. ",
              "score": 2,
              "created_utc": "2026-02-28 08:17:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ukj06",
              "author": "gohm_dv",
              "text": "What small new models you refere to? I mostly use ministal models via their API. My app is using ministral-14b-2512. As you can see no mentioned it in this mail. So i guess they are no retiring.",
              "score": 1,
              "created_utc": "2026-02-28 08:25:35",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7vq787",
              "author": "kiwibonga",
              "text": "They're telling people to switch from 2512 (Devstral Small 2 from December 2025) to the new devstral_small_latest, presumably Devstral Small 2.1",
              "score": 1,
              "created_utc": "2026-02-28 14:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7vr4dh",
                  "author": "spaceman_",
                  "text": "No, it's telling them to switch to the big devstral. Devstral-small-latest is mentioned but also EOL in May.",
                  "score": 1,
                  "created_utc": "2026-02-28 14:13:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7un4hb",
          "author": "Legitimate-Help8016",
          "text": "I hope it's better than 2.0 because it's really bad when comparing to sonnet 4.5.. I didn't even try to vibe code for now.",
          "score": 5,
          "created_utc": "2026-02-28 08:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wb7qq",
              "author": "Positive-Plan4877",
              "text": "Looking at the price it will have some reasoning so hopefully it will be much better",
              "score": 1,
              "created_utc": "2026-02-28 16:00:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ujlx0",
          "author": "Careful-Lake-13",
          "text": "They recommend migrating to Devstral 2.1 for 'best performance,' but don't mention if the context window or logic is actually that much better to justify the $2 output price. For that cost, it better be coding my entire repo while I sleep.",
          "score": 2,
          "created_utc": "2026-02-28 08:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ukc1k",
              "author": "EzioO14",
              "text": "Claude doesnâ€™t do that more for much more money what are you expecting :â€™)",
              "score": 2,
              "created_utc": "2026-02-28 08:23:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7uk9zj",
          "author": "EzioO14",
          "text": "Canâ€™t wait to give it a try",
          "score": 2,
          "created_utc": "2026-02-28 08:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7uj56k",
          "author": "iBukkake",
          "text": "Question for Devstral users: when and where are you using these small models? From Mistral coding models, or anyone else?\n\nCaveat: I'm not a SWE, but I do use Claude Code with a Max plan. I am building tools that make extensive use of Mistral Large, OCR and Voxtral. So I love the business; I just don't understand the use cases for using Devstral when Claude Code, Codex etc exist.",
          "score": 2,
          "created_utc": "2026-02-28 08:12:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7umfpp",
              "author": "ComeOnIWantUsername",
              "text": "> I just don't understand the use cases for using Devstral when Claude Code, Codex etc exist.Â \n\n\nI don't understand using Tesla, when Ford exist.\n\n\nI don't understand using iPhone, when Samsung exist.\n\n\nI don't understand using Chrome when Firefox exist.\n\nIt's just alternative. Devstal 2 is a bit worse than CC or Codex, but still very good. It's not that big difference",
              "score": 8,
              "created_utc": "2026-02-28 08:43:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7unppz",
                  "author": "Timo425",
                  "text": "How is the difference for planning? Because thats the main strenght of claude for me.",
                  "score": 2,
                  "created_utc": "2026-02-28 08:54:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7v5jds",
                  "author": "Ndugutime",
                  "text": "It is also a matter of style and also personality.  There are now dozens, if not 100s of good models that have their own quirks.  I think the more competition, the better.   I believe like Yann LeCun that there isnâ€™t or should not be one AI product.  That all intelligence is collective.",
                  "score": 2,
                  "created_utc": "2026-02-28 11:43:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7uu27f",
                  "author": "iBukkake",
                  "text": "If that is a fair comparison, then sure, ok I obviously get that.\n\nBut my understanding is that the current SOTA models, especially since December '25, are leaps and bounds ahead. More akin to comparing a car to a bicycle. And in that scenario, I don't think bikes (Devstral) shouldn't exist, I just wonder what the bicycle use case is for daily users.",
                  "score": 1,
                  "created_utc": "2026-02-28 09:56:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7umxsl",
              "author": "BitterProfessional7p",
              "text": "Devstral 2 123B is actually very good, look at SWE rebench scores, one of the top non-thinking models. Not at the frontier but still very usable, the instruction following is better than some other frontier models.\n\nI use it in Cline.",
              "score": 3,
              "created_utc": "2026-02-28 08:47:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7umiik",
              "author": "Particular-Way7271",
              "text": "For the same. I do have a preference for EU products (lately...;)) or open source and it works pretty well. There is mistral vibe cli which you can try out, it's the equivalent of claude code and it has generous free tier. You could also use the devstral models offline if you find them working well. They also have vision.",
              "score": 3,
              "created_utc": "2026-02-28 08:43:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7wa34g",
              "author": "AnaphoricReference",
              "text": "When I want coding assistance for a small fraction of the cost? Which is most of the time. \n\nI will sometimes switch to Claude Opus if I get stuck, in the hope its larger knowledge base will help me with new hypotheses. But two out of three times it disappoints me. But for an order of magnitude more money (for instance 5/25 vs 0,40/2 on Openrouter, which has them both).\n\nSame thing with models in my own tools. They automatically fall back on a bigger model if they can't get things done. Different model sizes have different use cases. A good basic model is one that knows when it doesn't know, instead of hallucinating it way out. Which basically comes down to following instructions.",
              "score": 1,
              "created_utc": "2026-02-28 15:55:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7v2aen",
          "author": "OnesKsenO",
          "text": "What happens to Le Chat Pro Vibe api?",
          "score": 1,
          "created_utc": "2026-02-28 11:14:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7v426n",
          "author": "One_Development8489",
          "text": "Cant mistral do what others, i mean learning from claude directly using api or to not waste so many tokens, just publish agent env where eu devs would dump input/output from claude/codex sessions?\n\nOr they do it already? (Or is it ILLEGAL in eu because this is noT oK)",
          "score": 1,
          "created_utc": "2026-02-28 11:30:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcf5tn",
      "title": "OpenClaw 2026.2.22 ðŸ¦ž add support for the Mistral AI provider",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/f4p88qi6d8lg1.jpeg",
      "author": "Nunki08",
      "created_utc": "2026-02-23 11:38:12",
      "score": 92,
      "num_comments": 10,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcf5tn/openclaw_2026222_add_support_for_the_mistral_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6yxdti",
          "author": "Kualdiir",
          "text": "Sadly openclaw is going to the US",
          "score": 10,
          "created_utc": "2026-02-23 15:58:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o714b6r",
              "author": "Desperate-Shallot-33",
              "text": "Openclaw is open source isnâ€™t it? And therefore I wouldt consider it US property",
              "score": 8,
              "created_utc": "2026-02-23 22:09:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75bgyr",
                  "author": "EzioO14",
                  "text": "Now itâ€™s controlled by OpenAI soâ€¦",
                  "score": 9,
                  "created_utc": "2026-02-24 15:09:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o717hg8",
                  "author": "SkyPL",
                  "text": "It's controlled by a US company, including what is and isn't merged, which direction the project is headed, etc.. Stop thinking of 'open source' as some magical thing that automatically makes everything out of big tech's hands. That's just not the reality.",
                  "score": 3,
                  "created_utc": "2026-02-23 22:25:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7a3k6p",
              "author": "mabiturm",
              "text": "The founder now works for openAI, I dont think openclaw was bought by openAI",
              "score": 2,
              "created_utc": "2026-02-25 05:56:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o72n1h5",
              "author": "victorc25",
              "text": "Boy you will be mad if you knew where GitHub and Reddit are fromÂ ",
              "score": 5,
              "created_utc": "2026-02-24 03:16:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o72kftg",
              "author": "DerpSenpai",
              "text": "It's opensource. It literally doesn't matter.Â ",
              "score": 2,
              "created_utc": "2026-02-24 03:01:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rg8789",
      "title": "[Vibe] PAYG Refund",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-27 14:30:26",
      "score": 89,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rg8789/vibe_payg_refund/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7pje5h",
          "author": "_st4rlight_",
          "text": "I knew you would address this professionally\n\nProblems and mistakes happen to everybody, the difference is how you handle them\n\nKeep up the good work!",
          "score": 28,
          "created_utc": "2026-02-27 14:50:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7px3qj",
          "author": "No-Equivalent-2440",
          "text": "Thank you! This shows that you value you customers and it is highly appreciated!",
          "score": 3,
          "created_utc": "2026-02-27 15:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pyhq4",
          "author": "DespondentMoose",
          "text": "Is this part of the same issue? My dashboard says I used 100% of my usage limit, but it shows $1.74 used out of $15.\n\nhttps://preview.redd.it/3fkgz1o092mg1.png?width=1075&format=png&auto=webp&s=b05d095cd43c5fe7787c403791ac700f1dd4a52d\n\n",
          "score": 1,
          "created_utc": "2026-02-27 16:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qr9ur",
          "author": "pkk888",
          "text": "Good stuff! Well done!",
          "score": 1,
          "created_utc": "2026-02-27 18:20:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r5i8w",
          "author": "ComeOnIWantUsername",
          "text": "I use Vibe from my Pro plan. Any ideas why the second link tells me just: \"Unable to retrieve your quota.\" for \"Vibe token usage\"?",
          "score": 1,
          "created_utc": "2026-02-27 19:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r5qy3",
          "author": "EzioO14",
          "text": "Kudos to you mistral team",
          "score": 1,
          "created_utc": "2026-02-27 19:29:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf1kf2",
      "title": "Mistral has competition",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/r5zpwu6hxrlg1.jpeg",
      "author": "Emotional-Carob-750",
      "created_utc": "2026-02-26 05:21:44",
      "score": 46,
      "num_comments": 7,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf1kf2/mistral_has_competition/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7gtt7j",
          "author": "Nefhis",
          "text": "Well, I think the word \"Magistral\" is quite common in languages â€‹â€‹derived from Latin. Funny to see it referring to windows, anyway ðŸ˜Š",
          "score": 7,
          "created_utc": "2026-02-26 05:38:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7h0yfc",
              "author": "PitchPleasant338",
              "text": "So no windows? That's what I thought, Mistral is building the next Linux!",
              "score": 3,
              "created_utc": "2026-02-26 06:35:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7h1yhe",
                  "author": "Nefhis",
                  "text": "Oh my God! Isn't that the worst joke of the day? ðŸ¤£ðŸ¤£ðŸ¤£ And yet... I wish they would do it.",
                  "score": 2,
                  "created_utc": "2026-02-26 06:44:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7hfpfw",
          "author": "drorago",
          "text": "the next model from mistral will be about magic and will be powered by windows?",
          "score": 1,
          "created_utc": "2026-02-26 08:50:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ht8rb",
          "author": "bastonpauls",
          "text": "Dishwashing detergent sold in Argentina\n\nhttps://preview.redd.it/enu0s9clltlg1.jpeg?width=573&format=pjpg&auto=webp&s=c55a0aa29635adc4dc79336f646038fa0d5593d3",
          "score": 1,
          "created_utc": "2026-02-26 10:58:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfilo6",
      "title": "US orders diplomats to fight data sovereignty initiatives",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfilo6/us_orders_diplomats_to_fight_data_sovereignty/",
      "author": "Nefhis",
      "created_utc": "2026-02-26 18:45:20",
      "score": 39,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "Reuters news report, February 25, 2026. Link below:  \n  \n[https://www.reuters.com/sustainability/boards-policy-regulation/us-orders-diplomats-fight-data-sovereignty-initiatives-2026-02-25/](https://www.reuters.com/sustainability/boards-policy-regulation/us-orders-diplomats-fight-data-sovereignty-initiatives-2026-02-25/)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rfilo6/us_orders_diplomats_to_fight_data_sovereignty/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7kkffe",
          "author": "mobileJay77",
          "text": "We should demand export tariffs on all data packets going to the US.\n\nAt this point, I am hard pressed if this is /s  or sane advice among the insane.",
          "score": 4,
          "created_utc": "2026-02-26 19:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lew6k",
              "author": "wirtshausZumHirschen",
              "text": "haha def an interesting idea to charge per data packets.  \nDoubt whether even feasible technically, but great marketing title",
              "score": 2,
              "created_utc": "2026-02-26 22:08:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7om823",
                  "author": "mobileJay77",
                  "text": "As if this would stop our politicians. Remember, when von der Leyen attempted put stop signs online to protect children?",
                  "score": 1,
                  "created_utc": "2026-02-27 11:23:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7psit3",
              "author": "EzioO14",
              "text": "How about 1000â‚¬/packet?",
              "score": 1,
              "created_utc": "2026-02-27 15:35:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7vouvh",
              "author": "deniercounter",
              "text": "And as European this would be funny because the importing country pays it. \n\nBut I am not sure if the concept is generally understood.",
              "score": 1,
              "created_utc": "2026-02-28 14:00:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rc8rwf",
      "title": "Mistral API quota and rate limits pools analysis for Free Tier plan (20.02.2026)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "author": "VohaulsWetDream",
      "created_utc": "2026-02-23 05:20:53",
      "score": 33,
      "num_comments": 11,
      "upvote_ratio": 0.94,
      "text": "The goal of research is to map which models share quota pools and rate limits on the Mistral Free Tier, and document the actual limits returned via response headers.\n\nFindings reflect the state as of 2026-02-23\n\nModels not probed (quota and rate limits status unknown): \n- `codestral-embed`\n- `mistral-moderation-2411`\n- `mistral-ocr-*`\n- `labs-devstral-small-2512`\n- `labs-mistral-small-creative`\n- `voxtral-*`\n\n**Important note:** On the Mistral Free Tier, there is a global rate limit of **1 request per second** per API key, applicable to all models regardless of per-minute quotas.\n\n---\n\n## Methodology\n\nA single curl request to `https://api.mistral.ai/v1/chat/completions` with a minimal payload (`max_tokens=3`) returns rate-limit headers. Example:  \n\n```\ncurl -si https://api.mistral.ai/v1/chat/completions \\\n  -H \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\":\"codestral-latest\",\"messages\":[{\"role\":\"user\",\"content\":\"hi\"}],\"max_tokens\":3}' \\\n  | grep -i \"x-ratelimit\\|HTTP/\"\n```\n\nHeaders show:\n- `x-ratelimit-limit-tokens-minute`\n- `x-ratelimit-remaining-tokens-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n\nThe model `mistral-large-2411` is the only one that has a bit different set of headers:\n- `x-ratelimit-limit-tokens-5-minute`\n- `x-ratelimit-remaining-tokens-5-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n- `x-ratelimit-tokens-query-cost`\n- `x-ratelimit-limit-req-minute`\n- `x-ratelimit-remaining-req-minute`\n\n\n---\n\n## Quota Pools\n\nQuota limits are not per-model â€” they are shared across groups of models. All aliases consume from the same pool as their canonical model.\n\n**mistral-large-2411** is the only model on the Free Tier with a 5-minute token window instead of a per-minute window. All other models use a 1-minute sliding window.\n\n---\n\n**Pool 1: Standard**\n\nLimits: 50,000 tokens/min | 4,000,000 tokens/month\n\n    mistral-small-2506, mistral-small-2501\n    mistral-large-2512\n    codestral-2508\n    open-mistral-nemo\n    ministral-3b-2512, ministral-8b-2512, ministral-14b-2512\n    devstral-small-2507, devstral-medium-2507\n    pixtral-large-2411\n\nNote: `devstral-small-2507` and `devstral-medium-2507` are in this pool. `devstral-2512` is a separate pool (see Pool 7).\n\n---\n\n**Pool 2: mistral-large-2411** (special)\n\nLimits: 600,000 tokens/5-min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-large-2411   (no aliases; completely isolated from mistral-large-2512)\n\n> Note: This is the only model with a **5â€‘minute** token window. Do not confuse with `mistral-large-2512` (in Standard pool).    \n    \n---\n\n**Pool 3: mistral-medium-2508**\n\nLimits: 375,000 tokens/min | 25 req/min | no monthly limit\n\n    mistral-medium-2508  (+ mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools)\n\n---\n\n**Pool 4: mistral-medium-2505**\n\nLimits: 60,000 tokens/min | 60 req/min | no monthly limit\n\n    mistral-medium-2505  (no aliases; separate pool from mistral-medium-2508 despite similar name)\n\n---\n\n**Pool 5: magistral-small-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-small-2509  (+ magistral-small-latest)\n\n---\n\n**Pool 6: magistral-medium-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-medium-2509  (+ magistral-medium-latest)\n\nPools 5 and 6 have identical limits but are confirmed separate by differing `remaining_month` values.\n\n---\n\n**Pool 7: devstral-2512**\n\nLimits: 1,000,000 tokens/min | 50 req/min | 10,000,000 tokens/month\n\n    devstral-2512  (+ devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest)\n\n---\n\n**Pool 8: mistral-embed**\n\nLimits: 20,000,000 tokens/min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-embed-2312  (+ mistral-embed)\n\n---\n\n## Summary Table\n\n| Pool | Models | Tokens/min | Tokens/5-min | Req/min | Tokens/month |\n|------|--------|-----------|--------------|---------|-------------|--------|\n| Standard | mistral-small, mistral-large-2512, codestral, open-mistral-nemo, ministral-*, devstral-small/medium-2507, pixtral-large | 50,000 | â€” | â€” | 4,000,000|\n| mistral-large-2411 | mistral-large-2411 only | â€” | 600,000 | 60 | 200,000,000,000|\n| mistral-medium-2508 | mistral-medium-2508 | 375,000 | â€” | 25 | no limit | \n| mistral-medium-2505 | mistral-medium-2505 | 60,000 | â€” | 60 | no limit |\n| magistral-small | magistral-small-2509 | 20,000 | â€” | 10 | 1,000,000,000 | | magistral-medium | magistral-medium-2509 | 20,000 | â€” | 10 | 1,000,000,000 | | devstral-2512 | devstral-2512 | 1,000,000 | â€” | 50 | 10,000,000 | \n| embed | mistral-embed-2312 | 20,000,000 | â€” | 60 | 200,000,000,000 | \n\n## Model Aliases (base model -> aliases)\n\n| Base Model | Aliases |\n| :--- | :--- |\n| mistral-small-2506 | mistral-small-latest |\n| mistral-small-2501 | (deprecated 2026-02-28, replacement: mistral-small-latest) |\n| mistral-large-2512 | mistral-large-latest |\n| mistral-large-2411 | **no aliases, isolated model** |\n| mistral-medium-2508 | mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools |\n| mistral-medium-2505 | **no aliases, isolated model** |\n| codestral-2508 | codestral-latest |\n| open-mistral-nemo | open-mistral-nemo-2407, mistral-tiny-2407, mistral-tiny-latest |\n| ministral-3b-2512 | ministral-3b-latest |\n| ministral-8b-2512 | ministral-8b-latest |\n| ministral-14b-2512 | ministral-14b-latest |\n| devstral-small-2507 | **no aliases** |\n| devstral-medium-2507 | **no aliases** |\n| devstral-2512 | devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest |\n| labs-devstral-small-2512 | devstral-small-latest |\n| pixtral-large-2411 | pixtral-large-latest, mistral-large-pixtral-2411 |\n| magistral-small-2509 | magistral-small-latest |\n| magistral-medium-2509 | magistral-medium-latest |\n| mistral-embed-2312 | mistral-embed |\n| codestral-embed | codestral-embed-2505 |\n| mistral-moderation-2411 | mistral-moderation-latest |\n| mistral-ocr-2512 | mistral-ocr-latest |\n| mistral-ocr-2505 | **no aliases** |\n| mistral-ocr-2503 | (deprecated 2026-03-31, replacement: mistral-ocr-latest) |\n| voxtral-mini-2507 | voxtral-mini-latest (audio understanding) |\n| voxtral-mini-2602 | voxtral-mini-latest (transcription; note: alias conflict with above) |\n| voxtral-mini-transcribe-2507 | voxtral-mini-2507 |\n| voxtral-small-2507 | voxtral-small-latest |\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6z3s0z",
          "author": "cosimoiaia",
          "text": "That is a great report but I have one suggestion: if you can, you should test this over a time period since it has been known that they extend/shrink the limits according to global system capacity. Still, thanks for sharing!",
          "score": 3,
          "created_utc": "2026-02-23 16:27:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zgq5r",
              "author": "VohaulsWetDream",
              "text": "Good idea, I will definitely do it.",
              "score": 2,
              "created_utc": "2026-02-23 17:28:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wmyac",
          "author": "No-Falcon-8135",
          "text": "This is great information. Thank you so much. So is Mistral Medium  2508 2505 also 123B Dense like Mistral Large 2? Just wondering which is the \"smartest model that isn't MOE. ",
          "score": 2,
          "created_utc": "2026-02-23 05:40:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72lgth",
              "author": "DerpSenpai",
              "text": "Yes the smartest non MoE is Mistrals Medium",
              "score": 2,
              "created_utc": "2026-02-24 03:07:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6wvr3r",
              "author": "VohaulsWetDream",
              "text": "i didn't do any research comparing model capabilities, so these are just my guesses: the smartest non-MoE model in mistral's lineup is mistral-large-2411 (123b). \n\nimportant that it's the one with a unique quota on free tier (600k tokens/5 min, 200b/month) and it's not part of the standard pool. it's the best dense model and the only heavy model available right now. \n\nIIRC ministral 14b is also dense, but it's 14b vs 123b, so...",
              "score": 1,
              "created_utc": "2026-02-23 06:56:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6z31at",
              "author": "cosimoiaia",
              "text": "None of the latest models are MoE afaik.",
              "score": 1,
              "created_utc": "2026-02-23 16:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72le2v",
                  "author": "DerpSenpai",
                  "text": "Mistral Large 3 is MoE",
                  "score": 2,
                  "created_utc": "2026-02-24 03:06:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76j6t6",
          "author": "Salt-Ear-1393",
          "text": "Isn't there a limitation to 8k context token input with all models via free tiers?",
          "score": 1,
          "created_utc": "2026-02-24 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77iygg",
              "author": "VohaulsWetDream",
              "text": "tbh idk yet. but i'll check soon and write in detail if i find something worthy.",
              "score": 1,
              "created_utc": "2026-02-24 21:11:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77o1cp",
                  "author": "Little_Protection434",
                  "text": "What I found / experienced with the Free Tier, is that Le Chat limits the amount of messages to around 20 in an 2 hour time period. The time period starts when you first write a message. Then from that moment 2 hours later the period will restart and you can again get 20 messages. The beauty of this, is that you can ask multiple questions in one message and it still counts as 1. So, the limit isnÂ´t how many letters or words, the limit is the amount of messages. ",
                  "score": 3,
                  "created_utc": "2026-02-24 21:34:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1raw23l",
      "title": "Is it trolling me?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/zqfmisx4ovkg1.png",
      "author": "zenabiz",
      "created_utc": "2026-02-21 16:53:04",
      "score": 31,
      "num_comments": 12,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1raw23l/is_it_trolling_me/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6mmwcu",
          "author": "Visible_Tank5935",
          "text": "If often use le chat agents with files and they work very well for most of the time. And sometimes it just does not. Opening a new chat and trying again and than it works. Weird but anyway, works for me.",
          "score": 11,
          "created_utc": "2026-02-21 17:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6mnatl",
              "author": "zenabiz",
              "text": "Thats the 5th chat window it has done that, despite updating memories, and using prompts it provided for me to get the \"correct\" result",
              "score": 1,
              "created_utc": "2026-02-21 17:09:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6mozek",
                  "author": "Visible_Tank5935",
                  "text": "And can you elaborate a bit more on the type of file? I sometimes had that it strugled with very long complex type of pdf's with lots of tables. I than used tabula locally to extract the data from the pdf and import as json in le chat. However, lately, this was not necessary anymore and it seems the ocr and extracting capabilities had improved.",
                  "score": 1,
                  "created_utc": "2026-02-21 17:18:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mwox4",
          "author": "N0Legendary",
          "text": "LeChat loves to ragebait",
          "score": 7,
          "created_utc": "2026-02-21 17:57:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mllu7",
          "author": "sudoku_coach",
          "text": "No, because for that it would need intent.",
          "score": 3,
          "created_utc": "2026-02-21 17:01:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6mnng8",
              "author": "zenabiz",
              "text": "I didn't mean it literally. It was just a way to show a frustrating interaction. ",
              "score": 2,
              "created_utc": "2026-02-21 17:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6n5olr",
                  "author": "DaleCooperHS",
                  "text": "I guess we found the problem",
                  "score": -1,
                  "created_utc": "2026-02-21 18:41:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nb27g",
          "author": "Haegar_the_Terrible",
          "text": "Never have seen this.",
          "score": 1,
          "created_utc": "2026-02-21 19:07:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nf0wx",
          "author": "MimosaTen",
          "text": "I find the mistralâ€™s chat interface a bit messy. Using their raw models should be much better",
          "score": 1,
          "created_utc": "2026-02-21 19:27:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n6vzb",
          "author": "VohaulsWetDream",
          "text": "for data processing, agent.minimax.io is better tbh",
          "score": 0,
          "created_utc": "2026-02-21 18:47:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rds6ex",
      "title": "My first experiences with Mistral Vibe; tips for use?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rds6ex/my_first_experiences_with_mistral_vibe_tips_for/",
      "author": "Mistral_user_TMP",
      "created_utc": "2026-02-24 20:46:46",
      "score": 27,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "I'm running Vibe in an isolated environment. Using no after-install configuration, so with the default devstral-2 model. My experience:\n\n\\+ I like the user interface; it works smoothly.\n\nâˆ’ When I want to compare own code with a trusted (Jupyter-like) notebook, it either replaces the entire notebook or keeps the notebook in its original state. This happens repeatedly.\n\nâˆ’ While the Quickstart can be found [here](https://docs.mistral.ai/mistral-vibe/introduction/quickstart), detailed set-up info can be found in the [README](https://github.com/mistralai/mistral-vibe/blob/main/README.md). I find that a bit unclear; wouldn't the documentation website be a better fit?\n\nâˆ’ I was negatively surprised when Vibe/devstral-2 tried the following: \\`git reset HEAD\\`, thereafter commenting that the command was not very helpful. Surely, a development model should know better than that?!\n\n\n\nThe way things look right now, I think I would be better off using Codestral suggestions, and skipping the agentic factor. I already expected that working with agents would require some getting used to however, and I'm willing to try some more. Does anybody have recommendations for working with Vibe?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rds6ex/my_first_experiences_with_mistral_vibe_tips_for/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7arcj6",
          "author": "d9viant",
          "text": "It's a workhorse, use it DETERMINISTICALLY, be Explicit, it vibes slop really badly otherwise. A really good workhorse tho",
          "score": 3,
          "created_utc": "2026-02-25 09:28:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77nmf7",
          "author": "cosimoiaia",
          "text": "While I agree that the documentation could definitely find a better place, I have very positive experiences with vibe.\n\nI don't think I can recall one instance where it used git commands without me mentioning first and only for consistency (like if I say twice that it should commit some changes then it starts to propose to do that by itself).\n\nI never tried Jupiter notebooks with it so I'm not sure how it handles that.\n\nUsually I try to give it very clear and short-ish prompts, I don't ask a lot of things at the same time and I make it write MD files to carry over work over different sessions. I also try to avoid to saturate or compress the context if I can, even if it usually handles that fairly well.\n\nMy main complaint about vibe itself is that it tends to be sluggish after a while and usually takes forever to restore a session.\n\nI personally like how devstral works the tasks, it keeps it short and to the point, sometimes to a fault and I wish it would go a bit further or be more proactive but on the other hand that does leave me more control so it's a trade-off that I can accept.",
          "score": 2,
          "created_utc": "2026-02-24 21:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7atd3z",
          "author": "whoisyurii",
          "text": "Be very precise with your tasks, and try to feed some additional info to it (I mean, for Claude Code sometimes plain english text is enough with no context attached).\n\nIt is called vibe but it is not yet a really 'vibe' tool, you gotta have some knowledge to co-operate with it. But FOR ME, that is even better - I like to interact with agent more and more.",
          "score": 2,
          "created_utc": "2026-02-25 09:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wfgxg",
          "author": "Jbpin",
          "text": "Always ask him to run test and build to validate its changes as it will not do it by itself. Then plan and specs.",
          "score": 1,
          "created_utc": "2026-02-28 16:21:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbjblw",
      "title": "Codestral free limits",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/nmb3k6yy41lg1.png",
      "author": "OM3X4",
      "created_utc": "2026-02-22 11:16:19",
      "score": 25,
      "num_comments": 5,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbjblw/codestral_free_limits/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6rrz0e",
          "author": "Hector_Rvkp",
          "text": "I don't think subscriptions really ever tell you how many tokens you get. To start with, you don't know which model you're served, so a token on a 1b model is worth less than one on a sota model. And it's probably an MoE anyway. So maybe a better metric would how much energy or compute you're allowed to use, but that's too complex for users and too dangerous to show investors, and the wrong metric to contractually commit to. \nAnd so, you don't know. \nIf you buy api tokens, then I assume that it's assumed that you get sota model all the time, which is probably a lie, but hey. \nHow the sausage gets made is complicated",
          "score": 1,
          "created_utc": "2026-02-22 13:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rvy8l",
              "author": "OM3X4",
              "text": "In other words , will this give me unlimited completions , even with worse models after some limit",
              "score": 1,
              "created_utc": "2026-02-22 14:17:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rxp1j",
                  "author": "Hector_Rvkp",
                  "text": "It's an API afaik, and works with tokens you buy, beyond what seems to be a free allowance?",
                  "score": 1,
                  "created_utc": "2026-02-22 14:27:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o76jqap",
              "author": "Repulsive-Machine706",
              "text": "I believe you can go to usage, scroll down until you see the models, then toggle â€œshow consumtion in eurâ€ and you can see how many tokens you used per model. Also in limits you can see the weekly and monthly limits for all models. Bassically all the same, 500,000 tokens per minute and 1,000,000,000 tokens per month. Im on the free expermental plan.",
              "score": 1,
              "created_utc": "2026-02-24 18:29:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rg1rfe",
      "title": "Cowork alternative for Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rg1rfe/cowork_alternative_for_mistral/",
      "author": "Bregir",
      "created_utc": "2026-02-27 09:05:46",
      "score": 25,
      "num_comments": 4,
      "upvote_ratio": 0.89,
      "text": "for work, I have started using Claude Cowork, and I am really happy with that setup. It's not the underlying model that makes it great, it is the context management with local files, skills, instructions, etc.\n\nFor private use, I prefer going European and am using Mistral. I am hoping Mistral introduces something similar, and I am wondering if anyone has heard anything to that effect or can suggest alternatives to get similar setups using Mistral?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rg1rfe/cowork_alternative_for_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7ocg8b",
          "author": "AdIllustrious436",
          "text": "Some leaks in Vibe's source code revealed that Mistral is currently building a cloud platform for agentic use cases. Their recent acquisition of Koyeb pushes in that direction. [Details here.](https://www.reddit.com/r/MistralAI/s/pRzG7uvryc)",
          "score": 16,
          "created_utc": "2026-02-27 09:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o91vs",
          "author": "striketheviol",
          "text": "You can connect Mistral to [https://openwork.software/](https://openwork.software/)",
          "score": 10,
          "created_utc": "2026-02-27 09:23:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o9o30",
          "author": "Lkrambar",
          "text": "At the moment you have to build it yourself. What Anthropic is very good at is delivering their product: they ship a product that is covering 90-95% of what power users want, while having enough of a wow factor to get consumers who donâ€™t know what they want onboard.\n\nMistral is more of a hobbyist approach (although itâ€™s actually quite well connected and the fact you can use MCP connectors in the free tier is big value)",
          "score": 6,
          "created_utc": "2026-02-27 09:29:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ozms2",
          "author": "poolboy9",
          "text": "There is opensource alternatives to cowork. \nCheck this one out: https://github.com/iOfficeAI/AionUi\nI however donâ€™t use this myself, I just saw enthousiasm about it in the communities and had it bookmarked. \n\nYou can link mistral vibe to that and many others.",
          "score": 3,
          "created_utc": "2026-02-27 13:00:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbtjdh",
      "title": "Mistral Le Chat allows custom connector in free tier, woohoo!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rbtjdh/mistral_le_chat_allows_custom_connector_in_free/",
      "author": "ElectronicControl182",
      "created_utc": "2026-02-22 18:33:02",
      "score": 17,
      "num_comments": 3,
      "upvote_ratio": 0.95,
      "text": "I recently launched an MCP connector-based app on Play Store (link in my profile) but ChatGPT, Claude, Gemini CLI all need paid plans for custom MCP connectors. It's been a BIG issue with adoption. So very excited to see Mistral bucking the trend.\n\nhttps://preview.redd.it/jqumdhzxa3lg1.png?width=252&format=png&auto=webp&s=fc9f291aa6a70896e1ccb49e4424ea49d0b7697c\n\n$8 per month (ChatGPT, lowest I think) is a lot for many enthusiasts/students, and we need them to improve the MCP community. If you are from Anthropic, Open AI or Google please consider (maybe) up to 5 free custom connectors in your free tier?\n\nThanks Mistral team!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbtjdh/mistral_le_chat_allows_custom_connector_in_free/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6txnrp",
          "author": "Lkrambar",
          "text": "Itâ€™s been months.",
          "score": 2,
          "created_utc": "2026-02-22 20:06:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ztgd0",
              "author": "ElectronicControl182",
              "text": "I see, well I'm glad to have found it finally for my app users!",
              "score": 1,
              "created_utc": "2026-02-23 18:27:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zu0hs",
          "author": "ElectronicControl182",
          "text": "About the app, the link is in my profile but fwiw [here](https://phone-mcp.com) it is also",
          "score": 1,
          "created_utc": "2026-02-23 18:29:36",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1rds0rr",
      "title": "Tip: You can create your own agents for Le Chat in Mistral's AI Studio",
      "subreddit": "MistralAI",
      "url": "https://console.mistral.ai/build/agents",
      "author": "Mistral_user_TMP",
      "created_utc": "2026-02-24 20:40:59",
      "score": 14,
      "num_comments": 0,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rds0rr/tip_you_can_create_your_own_agents_for_le_chat_in/",
      "domain": "console.mistral.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1redfjf",
      "title": "iOS Features",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1redfjf/ios_features/",
      "author": "Perplexe974",
      "created_utc": "2026-02-25 13:37:42",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 0.85,
      "text": "Hello, \n\nI am in the process of de-googling my life and I started to use Le Chat - so far so good, Iâ€™m happy with the results. \n\nWhat i didnâ€™t expect to miss is the iOS widget, turns out I use those a lot and I am hoping itâ€™s an upcoming feature. \n\nDoes anyone know where i can find or request these kind of features ? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1redfjf/ios_features/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7bp9ji",
          "author": "KeyReindeer1046",
          "text": "make a home screen shortcut, works similar",
          "score": 3,
          "created_utc": "2026-02-25 13:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c8hjj",
          "author": "LeRouxGongle",
          "text": "You can use the shortcut app. \nThis native app from Apple (always nice) can directly take action on your device. \nSadly, Mistral just lets us open the app and not more. Is that enough for you?",
          "score": 2,
          "created_utc": "2026-02-25 15:23:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7c9o7t",
              "author": "Perplexe974",
              "text": "I suppose I donâ€™t have much options lmao",
              "score": 2,
              "created_utc": "2026-02-25 15:29:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cbhnw",
          "author": "LoveInTheFarm",
          "text": "the iOs widget ??",
          "score": 1,
          "created_utc": "2026-02-25 15:37:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ccxqc",
              "author": "Perplexe974",
              "text": "Yes, I would like an iOS widget to launch the app directly \n\nI was used to the one from Gemini, you could even take a picture from the widget and it attached itself directly to a prompt. Worked great and I miss it now that I use Mistral",
              "score": 2,
              "created_utc": "2026-02-25 15:44:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rcczpe",
      "title": "Mistral Vibe / Devstral became kinda dumb",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "author": "MiMillieuh",
      "created_utc": "2026-02-23 09:30:44",
      "score": 13,
      "num_comments": 14,
      "upvote_ratio": 0.93,
      "text": "Hello everyone.\n\nI've noticed recently (since Vibe 2.0) that Devstral has became way more dumb than it was when Vibe 1.x was around.\n\n* It's looping often.\n* It think it can't use certains tools (when it totally can).\n* It refuses to follow a prompt that tells it to test using some tools.\n\nI can go on...\n\nDid anyone noticed that too ?\n\nUsing Devstral in another tool than Vibe doesn't seem to help much (but still slightly better)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6xfh1z",
          "author": "pcx_wave",
          "text": "I've noticed it's a recurring bug that mistral can't seem to use it's tools. I always need to start a fresh convo saying 'use this now' to ensure it uses it.\nI've noticed such bugs in chatgpt as well...",
          "score": 9,
          "created_utc": "2026-02-23 10:07:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xkpwx",
              "author": "wish_I_knew_before-1",
              "text": "Oh well Claude needs to be reminded every single to read and adhere to rules in CLAUDE.md.",
              "score": 3,
              "created_utc": "2026-02-23 10:56:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xdlsn",
          "author": "skinney",
          "text": "I actually have the reverse experience. Devstral became much smarter than in Vibe 1.0.\n\nI don't have any of the problems you mention ðŸ¤·â€â™‚ï¸",
          "score": 7,
          "created_utc": "2026-02-23 09:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ypff6",
          "author": "ComeOnIWantUsername",
          "text": "I don't see these issues.\n\nThe only problem I had once or twice was that Vibe was trying to edit some file, applying edit failed, so it had to read the file again and only then was able to apply it ",
          "score": 3,
          "created_utc": "2026-02-23 15:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yucr0",
          "author": "Non_Professional_Web",
          "text": "For me Vibe always says that it can't search the web, I need to directly tell him to go and read his exact allowed tooling with indication of an actual path to the file.",
          "score": 3,
          "created_utc": "2026-02-23 15:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xdoqz",
          "author": "Charming_Support726",
          "text": "Not using Devstral in Vibe, but as model on API in one of my projects (for running my tests - because they are fast). \n\nI dont think so, but I noticed that both Devstral Models are extremely sensitive to their system and input promts. \n\nAnd I mean EXTREME \n\nI when there's an issue with the prompts or the tasks both tend to loop instead of stopping and saying \"Sorry Dave - Can't do this\"\n\nMaybe someone changed the system prompt in 2.0?",
          "score": 2,
          "created_utc": "2026-02-23 09:50:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zeq8v",
          "author": "Snickers_B",
          "text": "I have an Astro site and I had been using Mistral for blog uploads and publishing but it always gets it wrong.",
          "score": 2,
          "created_utc": "2026-02-23 17:18:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xbx0a",
          "author": "Kedf47",
          "text": "Hi, yes, I was asking myself the same thing this morning.Â ",
          "score": 1,
          "created_utc": "2026-02-23 09:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xkkh0",
          "author": "wish_I_knew_before-1",
          "text": "Yep. Not reading what I ask to read as background to analyse a file. To then provide best practice suggestions opposed to tailored solution.",
          "score": 1,
          "created_utc": "2026-02-23 10:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zgeyy",
          "author": "Gen5nake",
          "text": "I've noticedÂ  that as well. It was a better experience on V1.x for me.\nHe tends also to forget a lot of his context and task, even if it's less than half full.",
          "score": 1,
          "created_utc": "2026-02-23 17:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73hk19",
          "author": "Kriss-de-Valnor",
          "text": "I noticed that itâ€™s getting dumber when the context buffer is getting big (like over 60%) or after a long use. A restart with â€”continue often help",
          "score": 1,
          "created_utc": "2026-02-24 07:02:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75o5st",
          "author": "OkReference5581",
          "text": "Yep! Itâ€˜s crude. The code (py) isnâ€˜t well. Lot of bugs. Even simple code broken. Claude fixed it in 2 Minutes.",
          "score": 1,
          "created_utc": "2026-02-24 16:08:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z9gpj",
          "author": "NerasKip",
          "text": "Alwayse being dumb lol",
          "score": 0,
          "created_utc": "2026-02-23 16:54:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf3vkl",
      "title": "Mistral Vibe vs Codex App + GPT-5.2 High or Gemini CLI + gemini-3.1-pro-preview ?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rf3vkl/mistral_vibe_vs_codex_app_gpt52_high_or_gemini/",
      "author": "Old-Glove9438",
      "created_utc": "2026-02-26 07:32:26",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 0.74,
      "text": "How does Mistral Vibe compare with Codex App using GPT-5.2 High, or Gemini CLI using gemini-3.1-pro-preview ?\n\nI am quite satisfied with OpenAI and Google agentic coding platforms; how does Mistral do ? Anybody paid a subscription and tested it out? Potentially also interested in comparison against Claude Code, since it can be considered a leading solution together with Codex and Gemini as well (though I don't use it myself). ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf3vkl/mistral_vibe_vs_codex_app_gpt52_high_or_gemini/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7h9s8a",
          "author": "victorc25",
          "text": "How does a rock compare to a sledgehammer?Â ",
          "score": 10,
          "created_utc": "2026-02-26 07:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hcq20",
          "author": "ComeOnIWantUsername",
          "text": "I can't say about Codex nor Gemini CLI, but I use both Vibe and Copilot CLI (with Claude Sonnet 4.6) and Vibe is noticeably worse. It's OK for the most of my needs, but sometimes it encounters a problem with something and is taking many steps in order to fix it (usually trying the same few things in a loop) and then I run Copilot CLI which fixes it on first try.",
          "score": 5,
          "created_utc": "2026-02-26 08:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hkt6x",
          "author": "Nervous_Sun4915",
          "text": "I have a hybrid approach on that, Claude or Codex for finding nasty bugs and boilerplate code, Vibe for unit tests and similar tasks that only involve one or two files. Unfortunately, Vibe isn't on the same level as the others, it constantly does things that I definitely didn't ask it to do or gets it wrong, even though other models seem to be perfectly fine with my instructions.",
          "score": 5,
          "created_utc": "2026-02-26 09:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h8hcg",
          "author": "EzioO14",
          "text": "Nowhere near those on autonomous coding",
          "score": 5,
          "created_utc": "2026-02-26 07:41:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hcgmk",
          "author": "LowIllustrator2501",
          "text": "Can someone with experience explain what's the advantage of  using Claude code, Geminii CLI/ Codex/Vibe that are locked to a single model provider over [https://opencode.ai/](https://opencode.ai/) that allows me to use any existing model including local ones?  ",
          "score": 4,
          "created_utc": "2026-02-26 08:18:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hdubj",
              "author": "schacks",
              "text": "OpenCode is nice, but I prefer KiloCode. [https://kilo.ai/install](https://kilo.ai/install)\n\n",
              "score": 4,
              "created_utc": "2026-02-26 08:32:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7hi9mr",
                  "author": "LowIllustrator2501",
                  "text": "I didn't use kilo code at all. it seems it has less flexibility with models than opencode.\n\nAnyway - both tools allow selection of  model providers. That's the most important part.\n\nThe question remains - why most people use tool that force you into vendor locking?",
                  "score": 3,
                  "created_utc": "2026-02-26 09:15:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ho6pp",
          "author": "d9viant",
          "text": "I use em all ayyyy",
          "score": 1,
          "created_utc": "2026-02-26 10:12:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hxprs",
          "author": "ashersullivan",
          "text": "vibe is noticeably faster than both codex and gemini cli with very good context awareness... great daily driver for most coding tasks but still a step behind claude code on the hardest problems.",
          "score": 1,
          "created_utc": "2026-02-26 11:36:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcbxp5",
      "title": "Model Aliases (23.02.2026)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rcbxp5/model_aliases_23022026/",
      "author": "VohaulsWetDream",
      "created_utc": "2026-02-23 08:25:05",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.86,
      "text": "Findings reflect the state as of 2026-02-23\n\n\n## Model Aliases (base model -> aliases)\n\n| Base Model | Aliases |\n| :--- | :--- |\n| mistral-small-2506 | mistral-small-latest |\n| mistral-small-2501 | (deprecated 2026-02-28, replacement: mistral-small-latest) |\n| mistral-large-2512 | mistral-large-latest |\n| mistral-large-2411 | **no aliases, isolated model** |\n| mistral-medium-2508 | mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools |\n| mistral-medium-2505 | **no aliases, isolated model** |\n| codestral-2508 | codestral-latest |\n| open-mistral-nemo | open-mistral-nemo-2407, mistral-tiny-2407, mistral-tiny-latest |\n| ministral-3b-2512 | ministral-3b-latest |\n| ministral-8b-2512 | ministral-8b-latest |\n| ministral-14b-2512 | ministral-14b-latest |\n| devstral-small-2507 | **no aliases** |\n| devstral-medium-2507 | **no aliases** |\n| devstral-2512 | devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest |\n| labs-devstral-small-2512 | devstral-small-latest |\n| pixtral-large-2411 | pixtral-large-latest, mistral-large-pixtral-2411 |\n| magistral-small-2509 | magistral-small-latest |\n| magistral-medium-2509 | magistral-medium-latest |\n| mistral-embed-2312 | mistral-embed |\n| codestral-embed | codestral-embed-2505 |\n| mistral-moderation-2411 | mistral-moderation-latest |\n| mistral-ocr-2512 | mistral-ocr-latest |\n| mistral-ocr-2505 | **no aliases** |\n| mistral-ocr-2503 | (deprecated 2026-03-31, replacement: mistral-ocr-latest) |\n| voxtral-mini-2507 | voxtral-mini-latest (audio understanding) |\n| voxtral-mini-2602 | voxtral-mini-latest (transcription; note: alias conflict with above) |\n| voxtral-mini-transcribe-2507 | voxtral-mini-2507 |\n| voxtral-small-2507 | voxtral-small-latest |",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcbxp5/model_aliases_23022026/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1rh01b3",
      "title": "Input tokens Cache",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rh01b3/input_tokens_cache/",
      "author": "agentgoose007",
      "created_utc": "2026-02-28 11:13:06",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "Hi! \n\nI guess it's a feature request for Mistral API.\nQuite often the prompts have a large static prefix + smaller dynamic part. Caching the input tokens would reduce the latency and the costs. \n\nFor the reference:\n https://developers.openai.com/api/docs/guides/prompt-caching/\n\nhttps://platform.claude.com/docs/en/build-with-claude/prompt-caching\n\n\nIs something like that planned for Mistral API? Can it be considered? \n\nThanks!\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rh01b3/input_tokens_cache/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7w3vmt",
          "author": "martinderm",
          "text": "They will have to implement it for agentic Systems",
          "score": 1,
          "created_utc": "2026-02-28 15:23:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}