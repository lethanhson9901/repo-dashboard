{
  "metadata": {
    "last_updated": "2026-02-04 02:59:57",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 146,
    "file_size_bytes": 163305
  },
  "items": [
    {
      "id": "1qqj58f",
      "title": "Hi Mistral AI - you rock more than you know - lets take it further",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqj58f/hi_mistral_ai_you_rock_more_than_you_know_lets/",
      "author": "hartmanners",
      "created_utc": "2026-01-29 19:55:08",
      "score": 165,
      "num_comments": 14,
      "upvote_ratio": 0.99,
      "text": "I've been using AI since it sprung out as part of my job. I am a European and the hype has been overseas most of time (OpenAI, Claude, Gemini as the serious products).\n\n  \nI trust Mistral more than the others when matters are crucial. You could still re-train the model a bit more when it comes to technical issues, but it is doing a great job.\n\n  \nThese other LLM models, except Claude maybe, lack what Mistral is bringing to the table in terms of sources trained on and system prompts taiming it. It's objective and not biased.\n\n  \nMistral, please prioritize making a Windows store app, MacOS app to get this ball rolling faster. It's easier to get my crowd going with these simple means and thereby spreading the good work you did. Ppl need convenience - you already deliver on quality.\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqj58f/hi_mistral_ai_you_rock_more_than_you_know_lets/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2h6squ",
          "author": "Quiet_Illustrator410",
          "text": "Mistral AI is top-notch and from EU, perfect combo!",
          "score": 30,
          "created_utc": "2026-01-29 20:34:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hk8fo",
          "author": "Suitable-Guest2781",
          "text": "Fully agree, daily (& happy) user of Mistral AI here ! \n\nWould really love to see a collab. with Kyutai (https://kyutai.org) for next level voice interactions with LeChat !",
          "score": 11,
          "created_utc": "2026-01-29 21:38:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2idku5",
              "author": "EveYogaTech",
              "text": "Oh congratulations on the funding from Iliad Group. That's amazing. I'd also be interested in a Collab with you in the long-term with /r/Nyno (EU-only platform + commercial friendly open-source n8n alternative for AI workflows)",
              "score": 1,
              "created_utc": "2026-01-30 00:09:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ipjyy",
          "author": "Wrong_Country_1576",
          "text": "I love LeChat. It's brilliant and has a great personality.",
          "score": 6,
          "created_utc": "2026-01-30 01:13:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ifetz",
          "author": "ShiroCOTA",
          "text": "I ditched ChatGPT the moment I learned they massively funded Trumpâ€˜s fascist MAGA cult and switched to LeChat. Happy ever since. The only things I miss here are the excellent voice chats and the live-video chat feature to ask the AI about the stuff it sees irl.",
          "score": 10,
          "created_utc": "2026-01-30 00:18:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2p7x38",
              "author": "ziplin19",
              "text": "Today i cancelled ChatGPT because they fully support Trumps fascism, i will subsribe to LeChat",
              "score": 4,
              "created_utc": "2026-01-30 23:48:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2j5ek8",
              "author": "Gamester1941",
              "text": "Same! Though I do miss the intuitive memoru feature amd tts feature (also mistral could turn up the temprature some so when I regenerate its not the samw thinf?) But those are small gripes. Love mistral",
              "score": 2,
              "created_utc": "2026-01-30 02:41:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2icacu",
          "author": "909876b4-cf8c",
          "text": "Please don't prioritize US commercial, closed-sourced, restrictive, controlling, privacy invasive operating systems. Europe is switching to Linux, please focus on that.",
          "score": 5,
          "created_utc": "2026-01-30 00:01:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2iexyi",
          "author": "Hekke1969",
          "text": "Windows app ?? Hell no",
          "score": 3,
          "created_utc": "2026-01-30 00:16:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2t63vi",
          "author": "destello89",
          "text": "You can add it to your desktop which works similarly to how the app would. You should give it a go.",
          "score": 1,
          "created_utc": "2026-01-31 16:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2u6raa",
              "author": "hartmanners",
              "text": "You mean add the iOS app to macOS?",
              "score": 1,
              "created_utc": "2026-01-31 19:10:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o34hobp",
                  "author": "PerspectiveDue5403",
                  "text": "A web app. Pinned onto your desktop",
                  "score": 1,
                  "created_utc": "2026-02-02 08:37:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2inr7i",
          "author": "Equivalent-Word-7691",
          "text": "I downloaded Mistral one year ago,yet I sturggle to really support it if nayhting becuas ethe modle are just REALLY infeior  to gemini ,Open Ai adne speically Claude..like the real only good quality is it's an european company ut even chinese's model are better ...",
          "score": -2,
          "created_utc": "2026-01-30 01:03:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq5gss",
      "title": "USD prices in EU, WTF?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/qvhynsijq9gg1.png",
      "author": "anzzax",
      "created_utc": "2026-01-29 10:53:37",
      "score": 158,
      "num_comments": 23,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qq5gss/usd_prices_in_eu_wtf/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2e1v23",
          "author": "UnnamedUA",
          "text": "https://preview.redd.it/3tukzc1sr9gg1.jpeg?width=1080&format=pjpg&auto=webp&s=5533758cbc36bd83ade26edf1e0de9008ac53935",
          "score": 56,
          "created_utc": "2026-01-29 10:57:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e36hw",
              "author": "anzzax",
              "text": "https://preview.redd.it/wjkplopqt9gg1.png?width=2492&format=png&auto=webp&s=3d7010e6360d30ad65af24d6382fc0f63321f7ed",
              "score": 8,
              "created_utc": "2026-01-29 11:08:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2etmcg",
                  "author": "FalseRegister",
                  "text": "I am on that page, and it loaded EUR for me\n\nAre your local settings correct? Try on another browser or device as well",
                  "score": 6,
                  "created_utc": "2026-01-29 13:59:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2e3r24",
                  "author": "sndrtj",
                  "text": "Ah I guess they don't default back to USD for any location that doesn't use Euro.",
                  "score": 4,
                  "created_utc": "2026-01-29 11:12:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2e3bmw",
          "author": "OwlSlow1356",
          "text": "last year was only usd, a big turnoff. if you have the account already in place, you will see upgrade only in USD just like me.  if you log out, you will see these prices EUR/USD this year, but once logged in, again just USD. i think they have many costs in USD, bunny .net CDN also has pricing in USD, sorry, i will not pay in USD to any european company! there are so many options around, I did not bother to make a new account just to see if i can upgrade in EUR!",
          "score": 8,
          "created_utc": "2026-01-29 11:09:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e3uvf",
              "author": "anzzax",
              "text": "Yeah, my account created a long ago and I was using/testing API. I checked admin area, billing settings, all possible places - there is no way to switch to EUR, they show USD prices with Poland VAT - a bit infuriating honeslty.",
              "score": 2,
              "created_utc": "2026-01-29 11:13:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o30n4vt",
                  "author": "Whole-Pressure-7396",
                  "text": "its because they prob use stripe, a cus account if paid previoysly in usd, the account wont be able to switch to eur (not sure if stripe is still like that but that was how it was a few years ago) pain in the ass when integrating in a platform in my opinion, especially if you realize this limitation at later point in time.",
                  "score": 1,
                  "created_utc": "2026-02-01 18:50:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2eb9ne",
          "author": "anzzax",
          "text": "BTW ChatGPT has adjusted pricing and local currency. Those details matter. \n\nMistral - Iâ€™d like to see you build a strong business, not only focus on research. Iâ€™m happy to stay loyal and advocate for your models.\n\nhttps://preview.redd.it/wcooytvq4agg1.png?width=2888&format=png&auto=webp&s=b320b95b010a260fb60e8f3957d4cc11d2ce68a1",
          "score": 7,
          "created_utc": "2026-01-29 12:09:46",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2e9dmh",
          "author": "crazyserb89",
          "text": "If youâ€™re using VPN could be. Iâ€™m accessing from Italy and I see EUR primarily",
          "score": 3,
          "created_utc": "2026-01-29 11:56:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ejzf8",
              "author": "stddealer",
              "text": "I think it only supports euros and USD, and if you browse from any country whose currency is not Euros, it defaults to USD.",
              "score": 2,
              "created_utc": "2026-01-29 13:06:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2ercu0",
                  "author": "radek432",
                  "text": "Which makes sense, because dollar is cheap now ðŸ˜‰",
                  "score": 2,
                  "created_utc": "2026-01-29 13:47:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35zucx",
          "author": "jeetjejll",
          "text": "Same in Germany... Mistral's Le Chat reply: \"Mistralâ€™s approach to pricing and localization is evolving, especially as they expand their European customer base. The tension between global standardization and local preferences is a challenge for many tech companies, not just Mistral.\" Not good enough Mistral!",
          "score": 3,
          "created_utc": "2026-02-02 15:10:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2gf8yp",
          "author": "Dadinek",
          "text": "I took a student subscription and voluntarily in USD with a VPN because it was cheaper than from Europe. I end up paying 6$ per month",
          "score": 2,
          "created_utc": "2026-01-29 18:25:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2fhxaa",
          "author": "Duedeldueb",
          "text": "Polandâ€˜s CEO thinks Zloty is it.",
          "score": 1,
          "created_utc": "2026-01-29 15:56:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2hzplc",
          "author": "Outside_Professor647",
          "text": "It also writes dollars when transcribing numbersðŸ¤®",
          "score": 1,
          "created_utc": "2026-01-29 22:54:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2jx7i9",
          "author": "deegwaren",
          "text": "Try this url: https://mistral.ai/pricing",
          "score": 1,
          "created_utc": "2026-01-30 05:33:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2s5a9g",
              "author": "petersemm",
              "text": "It loads both for me but in dollars is somehow cheaper even though exhange rate is 1 eur = 1.19 $",
              "score": 1,
              "created_utc": "2026-01-31 12:52:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2tu9sj",
                  "author": "DeweyQ",
                  "text": "Mathematics. This exchange rate makes prices in US dollars cheaper. A loaf of bread that needs 1 EUR to purchase it needs less than 1 USD if each USD can buy 1.19 loaves of bread.",
                  "score": 1,
                  "created_utc": "2026-01-31 18:12:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o36624f",
                  "author": "jpcg",
                  "text": "If you take a close look the US price doesnâ€™t seem to include VAT. As soon as you click on EUR a dropdown menu appears down right with a country selection (standard appears to be France) and the price then changes according to vat of your country.",
                  "score": 1,
                  "created_utc": "2026-02-02 15:40:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ktgym",
          "author": "Zerr0Daay",
          "text": "If you have a VPN on it may influence it",
          "score": 1,
          "created_utc": "2026-01-30 10:09:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrw16s",
      "title": "Mistral Vibe 2.0 vs Codex 5.2 & Claude (Opus 4.5) - First Impressions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "author": "l_eo_",
      "created_utc": "2026-01-31 07:34:06",
      "score": 151,
      "num_comments": 38,
      "upvote_ratio": 0.96,
      "text": "Spending most of my time on Claudeâ€™s Max 20x plan (Opus 4.5) and occasionally hitting my weekly limits, I decided to revisit **Mistral Vibe 2.0** and **Le Chat** after a long break. Here are my first impressions, especially compared to Opus 4.5 and Codex CLI.\n\n---\n\n### **1. Codex CLI (5.2), Underwhelming First Impressions**\n\nI tested Codex in a structured folder with lots of context (files, scripts, and dedicated system for specific workflows that are to be followed). On first prompts and even after instructing it to analyze the **folder context**, it struggled to understand or comply and generate based on an understanding of the surrounding context. It felt less like a true CLI tool and more like a system just inlining requests without grasping the environment. Big asterix: It's also my first time trying codex and I need to explore it more, but the first results were disappointing.\n\n---\n\n### **2. Mistral Vibe 2.0**\n\nReally great first impression, I was very pleasantly surprised!\n\nIt really stood out was how thoroughly Mistral Vibe 2.0 tried to understand the context first (even without being told to do so). It didnâ€™t just jump into answering; it checked the surrounding files, analyzed available examples, and tried to understand what a good outcome would look like before starting to work.\n\nAnd I was blown away by how **fast** Mistral Vibe 2.0 is. The response generation is so quick that I canâ€™t even read along as it outputs. This is a game-changer for feedback loops. While I of course believe that Claude Opus 4.5 is currently the king for coding and complex tasks, Iâ€™ll be testing Mistral Vibe 2.0 much more for coding and general tasks to see how it performs. For everyday structured tasks, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system**.\n\n---\n\n### **3. Le Chat App**\nThe Le Chat app has improved significantly since I last tried it:\n* Voice input is now a thing, and itâ€™s seamless! (Claude struggles a lot with this) When I last used Le Chat, this feature didnâ€™t even exist. I tested it with a long, multi-minute transcription, and the accuracy was impressive. I did a few feedback rounds, and Mistral applied my edits smoothly. Iâ€™m not sure how they made it *that* fastâ€”**the turnaround times for voice transcription and immediate answers are incredibly impressive**.\n* Online research seemed also to work great  and possibly now on par with ChatGPT?\nIâ€™m not even sure yet what other awesome features and UX additions there are, but Iâ€™m excited to explore further.\n\n---\n\n### **4. Potential Switch?**\nGiven Mistralâ€™s speed, UX, and awesome voice transcription, etc, Iâ€™m seriously considering making Le Chat + Mistral Vibe 2.0 my daily driver for everyday tasks and as a fallback when Claudeâ€™s limits kick in (and Le Chat possibly always preferred because of the speed and the great voice transcription in multiple languages). Iâ€™ll test-drive it for a few days, and if it proves as powerful as I hope (writing this as a \"wow, just tried this\" post, so maybe lots of honey moon phase involved), I might cancel my ChatGPT subscription and make Le Chat my main driver for everyday use.\n\nIâ€™m all for EU digital sovereignty, so supporting Mistral feels like a win-win and I am incredibly happy & excited about all the progress being made.\n\n---\n\n**TL;DR:**\n\n* **First rough impressions**: Just excited to share my initial enthusiasm for Mistral Vibe 2.0 and Le Chat after revisiting them.\n* **Codex CLI** felt underwhelming as a CLI tool, especially with folder context. Not sure about code quality and similar yet (also very first impression).\n* **Mistral Vibe 2.0** impressed with speed and context handling; Iâ€™ll test it more for coding.\n* **Le Chat app** now includes voice input and shines with great transcription quality, incredible speed (game changer for back and forth loops), and online research\n* While **Opus 4.5 likely remains unmatched for coding**, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system** for everyday tasks.\n\n\nBig thank you to the Mistral team for all the hard work! Rooting for you big time â™¥ï¸ðŸ‡ªðŸ‡º!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2teisq",
          "author": "Mr_Finious",
          "text": "As a US citizen, I'm considering Mistral because I trust the EU's privacy protections to better protect me than those of US or Chinese companies. \n\n\n\nWe should all be clapping for companies like Mistral in the EU.",
          "score": 7,
          "created_utc": "2026-01-31 16:56:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r8s37",
          "author": "l_eo_",
          "text": "Collecting new findings here as I continue testing: \n\n* I am not super happy with it being pretty hard to copy from the CLI progress. Often I need to \"reply\" to something the agents do and the UX loops around that are crucial. It's pretty bad at the moment, the UI needs a long time to react and seems to include some automatic \"copied!\" feature, that appears very late multiple times and that I don't really care about. Easy direct select -> right click -> copy would be best and should be fast and fluid. That's a \"small\" thing that makes a **huge** difference. \n* Scrolling can also be pretty sluggish (very very late start and keys like 'end' also have many seconds of delay). Possibly tracked here: https://github.com/mistralai/mistral-vibe/issues/222\n* There must be a specific system in place for interruptions? The agent reacted much faster than Claude Code Opus to a \"no\" during generation. Basically almost immediate stop\n* CLI text input seems a bit sluggish when much is happening\n* Context usage seems to go up fairly slowly. Not sure if that's a good or bad thing (testing it for some coding right now).\n* Every response / input during generation seems to be treated as an interruption (so no \"next task queuing\" like with Claude Code). Maybe there is a way to queue?",
          "score": 7,
          "created_utc": "2026-01-31 07:59:41",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2rboh5",
              "author": "l_eo_",
              "text": "I really need to stress that so many gains are to be made \"easily\" by improving the UX of the base-line elements that make up the workflow with the CLI tool. \n\nCopy & paste / reacting / replying, how fast typing is, and how responsive scrolling is are just a few facets of this.\n\nUX improvements make a huge difference if the basic quality of the model output is good enough.\n\nI will look into contributing: https://github.com/mistralai/mistral-vibe/blob/main/CONTRIBUTING.md",
              "score": 12,
              "created_utc": "2026-01-31 08:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r7wv2",
          "author": "ZapojKabel",
          "text": "I am interested at the coding using now heavily modified Gemini CLI and quite happy with, but rather use European tool. Does mistral have api key pay as you go and picture generate?",
          "score": 5,
          "created_utc": "2026-01-31 07:51:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9lfq",
              "author": "l_eo_",
              "text": "Interesting, in what way did you modify the Gemini CLI? \n\nI must say, that I was always very unhappy with Gemini output regarding code and it often seeming to \"fight\" me / gaslight me or somehow trying to avoid following instructions. Especially in the last weeks instruction following was pretty much non-existent for the few tests I did and I have been avoiding it ever since. \nBut I also mostly used the web interface so far, so maybe it's a different story with the CLI. \n\nI would have very much recommended Claude Code with Opus 4.5 and used to be *insane* around release / December, but has deteriorated massively in terms of quality the last few weeks. Possibly due to a switch from Google GPUs to the ones they developed with AWS, but not sure.  \nStill, it is very much worth a try if you go for the 5x or 20x max plans (they are very worth it). API pricing would be incredibly expensive (easy to burn through 20-80 bucks an hour). \n\nRegarding your questions: \nYes, API key pay as you go exists and I think the subscription now also included some vague notion of \"full day coding\"? \n\nPicture generate would likely mean an additional model, but that should be easy to integrate into your workflow (e.g. continue using Gemini's very powerful nano-banana-pro or flux).\n\nGreat to hear that you care about European tools!",
              "score": 4,
              "created_utc": "2026-01-31 08:07:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rngmy",
                  "author": "ZapojKabel",
                  "text": "Well I have my boss I call him Nexus he delegate my task to other agents ( I use mostly three for design, code and advertising expert). Every plan I make all 3 discuss how to do and should work, when it is done the 4 agent step in it is called Sentil \"devil advocate\" a trying to find error in there reasoning and aks question \"if...\". When there settle and I agree, Nexus make track list in conductor with plan how to setup. Also use RAG. I am not coder but make app for my e-shop. https://harmony.nonchalant.cz and also now making app for manager stuff on my eshop and dashboard for better statistic on sale etc.\nEdit: also Avery agent must use TOT protocol",
                  "score": 4,
                  "created_utc": "2026-01-31 10:19:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ul5uq",
              "author": "vienna_city_skater",
              "text": "If you have Le Chat Pro you get Devstral included.",
              "score": 1,
              "created_utc": "2026-01-31 20:20:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2recbg",
          "author": "EzioO14",
          "text": "I use le chat pro for all normal chat questions and I have claude max for coding",
          "score": 5,
          "created_utc": "2026-01-31 08:51:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2reopc",
              "author": "l_eo_",
              "text": "That's my plan as well :)\nI love the snappyness of Le Chat. \n\nIs Le Chat strict enough with sources? So doesn't hallucinate if no information found via web search?",
              "score": 2,
              "created_utc": "2026-01-31 08:55:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rer8d",
                  "author": "EzioO14",
                  "text": "I find it gets better, I was very disappointed at first, last month when I started but now I find the answers better and better",
                  "score": 2,
                  "created_utc": "2026-01-31 08:55:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r8a66",
          "author": "Bato_Shi",
          "text": "Only thing i noticed with Vibe is that sometimes it falls into infinite loops, like gemini 3 some months ago",
          "score": 4,
          "created_utc": "2026-01-31 07:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9n86",
              "author": "l_eo_",
              "text": "Should be easy to break it out of though, right? \nHow often does it happen?",
              "score": 1,
              "created_utc": "2026-01-31 08:07:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2syc21",
                  "author": "kiwibonga",
                  "text": "An example I had yesterday (Devstral Small 2 Q4) is it found that a regular expression wasn't capturing strings properly in a test, so it tried to fix the pattern, but it turned out to be a basic escaping issue rather than an error in the regex. It didn't realize that, so it added more and more characters to the pattern until it was huge -- without ever thinking \"is this overkill? That looks weirdly huge\" even though the purpose of the code was just to make sure a line starts with the word \"AGENT:\".\n\nThis is something that could have been autonomously fixed with an orchestrator that includes failure analysis, sees the blind spot, and proposes an alternate approach before launching another attempt. A reasoning model might also have a much easier time course-correcting.\n\nI was using the CLI by itself so I just said \"try to simplify the regular expression by writing it from scratch, and if it still fails, just write a parser\" -- it failed fast and wrote a parser, then got back to work.",
                  "score": 1,
                  "created_utc": "2026-01-31 15:39:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2rpkx3",
              "author": "Gen5nake",
              "text": "I also had this issue once",
              "score": 1,
              "created_utc": "2026-01-31 10:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ra7pr",
          "author": "theschiffer",
          "text": "Very interesting review. What does your day-to-day workload look like and in what ways do you generally use AI?",
          "score": 2,
          "created_utc": "2026-01-31 08:13:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rarwz",
              "author": "l_eo_",
              "text": "Workload in terms of volume of usage? \n6-14 hours of multiple terminal tabs with claude processes. \nAI is used as a partner both for planning as well as for execution. Often planning and getting everything prepared for implementation takes up most of the time (e.g. 4 hours planning and adapting and architecture work, 2 hours implementing and adapting / fixing), but it depends a bit on what phase a project is in. \n\nDoes this answer your question fully?",
              "score": 3,
              "created_utc": "2026-01-31 08:18:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tmt2r",
                  "author": "theschiffer",
                  "text": "Nice. So essentially, youâ€™re a software developer/architect? Thatâ€™s quite an intensive level of use.",
                  "score": 1,
                  "created_utc": "2026-01-31 17:36:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rae0d",
          "author": "Hot_Bake_4921",
          "text": "Does Le chat still use mistral medium 3.1?",
          "score": 2,
          "created_utc": "2026-01-31 08:14:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcns6",
              "author": "l_eo_",
              "text": "I am trying to find some information about this, but this proves to be surprisingly hard? Nothing in the change logs and most Reddit discussions about this seem to be from quite long ago.",
              "score": 2,
              "created_utc": "2026-01-31 08:36:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2tqeke",
          "author": "Sorry_Role_1701",
          "text": "What Iâ€™m noticing with newer models like Mistral isnâ€™t about benchmarks anymore.\n\nThe real difference is **i**nteration speed, how fast you can refine an idea without restarting context every time.\n\nIn workflow-heavy tasks, that matters more than raw output quality.",
          "score": 2,
          "created_utc": "2026-01-31 17:54:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wlr2d",
              "author": "mWo12",
              "text": "Off course they are not about benchmarks, as they have nothing to show.",
              "score": 2,
              "created_utc": "2026-02-01 02:55:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34c59l",
                  "author": "Sorry_Role_1701",
                  "text": "I totally agree with your observation.  \nIteration speed and seamless context flow are becoming *way more important* for practical workflows than just raw output quality or benchmark scores  especially when youâ€™re refining ideas or building on previous results without restarting everything.\n\nIn my experience with Vibe (and similar tools, ChatGPT), when the model keeps context and lets you iterate fast, it *feels* more productive even if raw numbers arenâ€™t leading â€” because in real usage you spend less time repeating setup and more time building on progress.",
                  "score": 1,
                  "created_utc": "2026-02-02 07:44:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r7fxx",
          "author": "l_eo_",
          "text": "As I wrote, I am completely newly back again with Mistral vibe. \nAny optimizations / settings I should immediately go for?",
          "score": 1,
          "created_utc": "2026-01-31 07:47:20",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2r85ap",
          "author": "stjepano85",
          "text": "It is very good for agentic development. It has some problems with recursive algorithms and it can go crazy when his context is large (this can be solved by limiting context in vibe configuration).",
          "score": 1,
          "created_utc": "2026-01-31 07:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rayhx",
              "author": "l_eo_",
              "text": "Interesting! \nWhat level do you recommend limiting context to?",
              "score": 1,
              "created_utc": "2026-01-31 08:19:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rcdgm",
                  "author": "stjepano85",
                  "text": "128k should be good. I noticed at 70+% of the default 200k its performance drops significantly.",
                  "score": 2,
                  "created_utc": "2026-01-31 08:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rcps1",
          "author": "nycigo",
          "text": "For voice input, press Windows + H; this will automatically transcribe your microphone input if you are using Windows 11.",
          "score": 1,
          "created_utc": "2026-01-31 08:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcu1q",
              "author": "l_eo_",
              "text": ":O \n\nIn the CLI for mistral vibe?",
              "score": 2,
              "created_utc": "2026-01-31 08:37:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rhxqy",
                  "author": "nycigo",
                  "text": "Anywhere on Windows, anywhere your mouse is located",
                  "score": 1,
                  "created_utc": "2026-01-31 09:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wll72",
          "author": "mWo12",
          "text": "I tested Mistral Vibe 2.0, but I found it so slow, and I'm not talking about token generation. Just the CLI interface is so slow and sluggish. Maybe because it is all python, unlike other agents.",
          "score": 1,
          "created_utc": "2026-02-01 02:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xo0zs",
              "author": "l_eo_",
              "text": "100% and this is my biggest issue with it right now and a real blocker. \nYou can see the kind of potential it has when starting a new session, but it gets bogged down fast. \nFor me personally these would a \"don't release before fixed\".  \n\nBut I am also very optimistic that this will be improved soon, because relatively speaking, these rendering issues should be quite straightforward to fix, so I really hope Mistral will make them a priority.",
              "score": 1,
              "created_utc": "2026-02-01 07:36:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31bvsf",
          "author": "BastFX",
          "text": "Hey ! Thanks for this detailed review ðŸ‘Œ\nI never used vibe-code tools like this one, but i'm following news about all that world.\nThe most famous tool Claude Code on this category needs Claude.md file, I would like to know if Mistral need something similar to work properly ? What structure build in this file ? I checked the official documentation but any information about that, or I missed it ...",
          "score": 1,
          "created_utc": "2026-02-01 20:48:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37go5l",
          "author": "Sweaty-Special-1710",
          "text": "I really like Vibe. I feel it's almost as good as claude, way cheaper, I'm not concerned with usage limits, it works by being very directive, and it feels really fast.",
          "score": 1,
          "created_utc": "2026-02-02 19:13:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqzac4",
      "title": "Switching to Mistral?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqzac4/switching_to_mistral/",
      "author": "Absjalon",
      "created_utc": "2026-01-30 07:52:59",
      "score": 94,
      "num_comments": 29,
      "upvote_ratio": 0.98,
      "text": "Hi Mistral users,\n\nI am strongly considering switching my OpenAI subscription to Mistral.  I'm  happy with OpenAIs products,  but for political and GDPR reasons I'm ready to switch. Even if it means less optimal product. \n\nI've tried the free Mistral version for a while now and I am pretty happy about it, but it's not quite at the level of the paid OpenAI models. \n\nCan someone share their experience with the difference between the paid Mistral and OpenAI and how to optimize/personalize Mistrals output?\n\nI work both with API interactions and the chat interface \n\nThank you",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqzac4/switching_to_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2kgooi",
          "author": "thedisturbedflask",
          "text": "The Mistral models are quite capable but ive found you'll have to really work on the instructions and prompt to get the output your looking for.\n\n\nMy process was in defining a starting prompt and then tweaking it with a control question until it reached a point i was happy with. The answers arent deterministic because of how llms work but it helps to see the general kind of response.\n\n\nI saved these as agents in chat which works quite well.\n\n\nFrom the dev perspective i haven't quite been able to have it refer to an instruction file consistently but might just be missing something.",
          "score": 16,
          "created_utc": "2026-01-30 08:12:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kiyuj",
              "author": "Absjalon",
              "text": "Thank you.   \n  \nSo in Mistral chat, you build an agent and then call it in different chats? e.g. an agent that helps to formulate emails, but stays close to your draft and your wording?\n\nAs opposed to making a project and then giving special instructions for project?",
              "score": 4,
              "created_utc": "2026-01-30 08:33:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kjjpe",
                  "author": "TheMrLexis",
                  "text": "In Le Chat if I remember well, you can call an agent in the same chat by writting \"@\\[Agent Name\\]\"",
                  "score": 5,
                  "created_utc": "2026-01-30 08:38:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2kkv4s",
                  "author": "thedisturbedflask",
                  "text": "That's correct for the agents, i refine it to 'think' the way id like for general interactions or make it more specifically useful like the email example.\n\n\nI think you definitely can define the instructions for an agent to include project ownership, requirements, milestones, etc and skill sets so that youd be able to ask it to complete the project goals etc\n\n\nIn my case for a dev project using zed.dev editor I do that and spend a lot of time back and forth with the model defining the scope and detail then have it output a specific plan.md file with a checklist.\n\n\nI include it as context and ask it to implement the plan, then inevitably fix what it doesnt quite get right, makes it easier to predict and test the output",
                  "score": 2,
                  "created_utc": "2026-01-30 08:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l8jh3",
          "author": "Vontaxis",
          "text": "I have a mistral subscription just to support them but to be honest it is nowhere as good as Claude or ChatGPT.\n\nNaturally, it depends on what you're using it for but even for simpler things I noticed that prompt adherence is at times rather bad.",
          "score": 8,
          "created_utc": "2026-01-30 12:11:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kqv4z",
          "author": "NullSmoke",
          "text": "Yeah... new 4o scare going on over there (including 4.1 this time if I understand it correctly?)...\n\nJumped over when the whole mess became unbearable, and is very happy with it. As for the diff between paid and free, it's rate limits basically. You can test it out in free and have a decent handle on what you can expect in pro.\n\nI see that agents are being discussed down here, basically CustomGPTs if talking OpenAIspeech. You can find several guides over at r/Nefhis_Lumen_Lab that can help you get started :-)",
          "score": 5,
          "created_utc": "2026-01-30 09:45:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mmwih",
          "author": "LewdManoSaurus",
          "text": "I tried a subscription last October and while it was okay, I had to do a lot of correcting, and the amount of hallucination was seriously a deal breaker. If you just use it sparingly it'll probably be fine, but in my experience It's nowhere close to some of the bigger models. The agent customization is an amazing feature, but the other issues are so frequent that these days I just stick to free tiers of other services. I only used Mistral for generative writing.",
          "score": 3,
          "created_utc": "2026-01-30 16:31:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pn7eo",
          "author": "LoadZealousideal7778",
          "text": "I like it but probably for a weird reason. For me, their models sit at the junction between capable and a useful but fundamentally stupid multi tool. Smart enough to do work, not smart enogh to cognitively offload to.\n\nYou can't just barf in a typo riddled, half formed thought and get what you wanted most of the time like with Claude Opus. Bit more manual.",
          "score": 5,
          "created_utc": "2026-01-31 01:13:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rhkj9",
              "author": "Absjalon",
              "text": "I understand this and have a similar experience",
              "score": 1,
              "created_utc": "2026-01-31 09:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2lko4e",
          "author": "mythrowaway4DPP",
          "text": "Mistral *is* not on the same level as the top models ChatGPT, Gemini or Claude.  \nBeing an European engine, GDPR, and less puritan censorship is nice.\n\nCapabilities wise, think ChatGPT 4.1, maybe better.\n\nPrompting needs to be more precise, but it is doable.\n\nThe libraries are a nice idea, collections of documents to attach to any chat.\n\nOverall, I am not missing a lot using mistral, and openAI isn't getting my money anymore.",
          "score": 8,
          "created_utc": "2026-01-30 13:27:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mlk85",
              "author": "alexgduarte",
              "text": "That's because you've never used GPT-5.2-Pro.",
              "score": -4,
              "created_utc": "2026-01-30 16:25:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2mm1rw",
                  "author": "mythrowaway4DPP",
                  "text": "Of course I did. I also said that mistral is not there.",
                  "score": 5,
                  "created_utc": "2026-01-30 16:27:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2o897h",
          "author": "Komgoroth",
          "text": "I used it in the past. Then I switched to ChatGPT for a while. When my Chat GPT subscription was about to expire I subscribed again to Mistral.\n\nI then had some health issues and when I got my report from the doctor, I used it on Mistral to make a summary of what is happening( it was all perfect other than some benign findings) and it made up certain findings which indicated severe issues.\n\nI panicked as the doctor did not mentioned them. I also did not see them. Then asked the AI to tell me where did it find the issue and it apologized.\n\nTried it again and it did the same horrible mistake. Chat gpt did not.\n\nExample two. I asked both Mistral and ChatGPT to make me the shortest roadtrip using highway only from point a to point b and to tell me what vignettes I need to buy and what's the expected time and how often and where I should take breaks.\n\n\nChat gpt did it perfectly and I confirmed myself on maps etc.\nMistral missed several countries when it comes to vignettes, miscalculated the time by more than 30% and suggested that no breaks are needed for the drive( on a 14 hour long drive).\n\nI unsubscribed and continued with Gemini.\n\n\nI love that it is an European company and I'll support them when they get better but I cannot use it as is.",
          "score": 3,
          "created_utc": "2026-01-30 20:49:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kp7dc",
          "author": "sam-watterson",
          "text": "I started switching it, using vibe for day-to-day usage.",
          "score": 2,
          "created_utc": "2026-01-30 09:29:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2omirx",
          "author": "theAbominablySlowMan",
          "text": "Even before all this US shite started I was scolding everyone I heard using other AI, the data privacy approach of US Vs EU countries is just not compatible, and the level of detail of your personality you give these things is just scary in the wrong hands.Â \n\n\nHonestly I suggest just ditching and making the switch for 3 months and figuring it out yourself, like all software we get tied to what we know. Without knowing what areas you rely on it for I can't be specific but it's not a black and white openai being better, I prefer mistrals response on a lot of more science based topics for exampleÂ ",
          "score": 2,
          "created_utc": "2026-01-30 21:57:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rhgzf",
              "author": "Absjalon",
              "text": "Yes.  I've noticed Mistral gives really good answers on Statistical issues (explaining concepts). In this area, I think it is on par with chatGPT 5.2",
              "score": 1,
              "created_utc": "2026-01-31 09:21:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rac2w",
          "author": "Born-Yoghurt-401",
          "text": "Iâ€˜ve been using LeChat free over the last year to track progress and get medicinal advice about a close relatvies glioblastoma stage 4 brain tumor. I shared overall progress including CT and MRI scans, mental health patterns and in the final weeks palliative and necrotic wound care details. LeChat was very helpful in collecting and aggregating health data and putting many of my questions into context. I had no issues with hallucinations or factual errors and felt in good hands. I also would never have shared any of those details with a US based AI solution.",
          "score": 2,
          "created_utc": "2026-01-31 08:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rryl0",
          "author": "WitnessEarly7584",
          "text": "I got a Pro subscription for Mistral for free and tried to input some of my ChatGPT/Gemini prompts, which I use for work. What can I say? It is totally unusable. One prompt even caused a recursive loop. How are you guys using it?",
          "score": 2,
          "created_utc": "2026-01-31 11:01:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35xvp1",
              "author": "Objective-Sky7312",
              "text": "Promoting is different/must be customized to every system and even model, you would find the same in Claude etc. I only get recursive loops when the temperature is too low. Maybe try Agents, I think they are key for Mistral to customize how it behaves.",
              "score": 1,
              "created_utc": "2026-02-02 15:00:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rzm87",
          "author": "crazyserb89",
          "text": "I'm also on OpenAI searching for an alternative and checking the Mistral. Gave it a shot several times, but it seems it's not there yet to compete with the big ones. It feels unpolished, lacking some fundamental features, and overall seems like a Beta product. I hope they gonna improve it in future and therefore position themselves better on the market though.",
          "score": 2,
          "created_utc": "2026-01-31 12:08:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l3kqp",
          "author": "MikadinShinjuk",
          "text": "I switched to kagi, is not European but is way better than all the other main services and is very flexible in terms of choosing the model",
          "score": 1,
          "created_utc": "2026-01-30 11:34:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ss499",
          "author": "fonceka",
          "text": "Mistral strategy is to develop vertical models, so they have a bunch of specific models: codestral (coding), devstral (open-source model for coding agents), voxtral (speech2text), mistral small (enterprise ready), mistral medium, mistral large, ministral, magistral (multilingual)â€¦ I have been on the Pro version for one year on, but I have also a paid subscription to Gemini. I have already dropped the OpenAI subscription, and consider dropping the Anthropic one also. I do not use the API anymore since my focus have shifted. Overall I find Mistral very useful, when context is adequate. You must really work on curating your context window neatly.",
          "score": 1,
          "created_utc": "2026-01-31 15:07:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ue2ml",
          "author": "Green-LaManche",
          "text": "I used le chat - in very specific area which difficult to find someone knowledgeable: I am pretty happy with the answer either when asked specifically about dealing breakdowns in highly sophisticated areas or details of very specific historical figures.\nI would say I am much happier then with copilot",
          "score": 1,
          "created_utc": "2026-01-31 19:45:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lix37",
          "author": "officialexaking",
          "text": "You said for 'political reasons'. What do you mean by that? If it is because you want your data to be stay in the EU and not handled by non-US tech companies then you are wrong with Mistral. All your requests (chats) are routed through Microsoft/Google and Cerebras unless you haven't concluded a personal enterprise contract with them.",
          "score": 0,
          "created_utc": "2026-01-30 13:17:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mjxpx",
              "author": "Absjalon",
              "text": "Very important information you bring to the table here.  My concern is  data wise, but also I want my money to support Europe.\n\nI will see if I can find more information about this",
              "score": 4,
              "created_utc": "2026-01-30 16:17:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2mbua7",
              "author": "theKurganDK",
              "text": "Could you elaborate please? Routed?",
              "score": 2,
              "created_utc": "2026-01-30 15:41:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2rkore",
                  "author": "officialexaking",
                  "text": "Here is everything you need to know about it:\nhttps://www.xprivo.com/blog/en/mistral-is-not-a-european-alternative/",
                  "score": 1,
                  "created_utc": "2026-01-31 09:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qteixn",
      "title": "I love Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "author": "Potential_Block4598",
      "created_utc": "2026-02-01 23:31:42",
      "score": 82,
      "num_comments": 16,
      "upvote_ratio": 0.99,
      "text": "This is my second post in a long time praising mistral \n\nSo earlier I praised how they train objective models that services Le Mistral \n\nNow I am doing this again, but as I am running and switching between many models for local agentic tasks (using an agent scaffold and and MCP to perform basic static malware analysis tasks for cybersecurity that is essentially copy pasting to and from an LLM model in an automated way!) \n\nI tried many things \n\nFirst â€œfrontierâ€ (local frontier for my setup) according to artificial analysis aggregated benchmarks (that should include tool call, and not just demonstrative tool call but actual consistent real-life tool call!) (note I always wondered why Devstral ranked too low on that benchmark (either the model is too weak or the benchmark is too weak!!!!)\n\nSo I tried \n\nGPT-OSS (both on all kinds of Thinking effort options)\n\nWeird failures (sometimes call format not correct especially when used with cline and/or Goose!) \n\nAnd no instruction following (not even loose instruction following, or proper task management , so they donâ€™t live well inside the scaffold environment (some code todo management complex prompt and things like that!) \n\nGLM-4.7-Flash\n\nSimilar story \n\nThen Cline docs and Jack Dorsey mentioned Qwen3 Coder, I scratch my head why is that small seemingly insignificant model recognized by them no idea\n\nI try it and lo and behold it works very well than others\n\nSo it is not an agent problem or me dosing misconfiguration, these other open models arenâ€™t desgined for that (and for good reasons form the companies perspective)\n\nI am thinking of trying\n\nMinimax M2.1 or GLM-4.5-Air \n\nBut then I think about using Devstral Small 2\n\nAnd it works better than a charm finishes the task methodologically and analyzes the whole sample in like 3-5 hours \n\nA task that would have taken a junior around a month maybe (still a junior can do other stuff but maybe it dis. Better of MCP becoming exposed by default \n\nAnyways thanks Mistral Team for your awesome model and contributions to the open \n\nTL;DR\n\nDevstral Small 2 is the best for Local LLM agentic tasks (beyond being compared to others!)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o32cdeb",
          "author": "iongion",
          "text": "Is there a possibility to run it/configure it in claude code like it is possible with zai GLM ?",
          "score": 2,
          "created_utc": "2026-02-01 23:54:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33lf5o",
              "author": "lundrog",
              "text": "Should be easy. Can also use a api gateway like https://github.com/looplj/axonhub",
              "score": 3,
              "created_utc": "2026-02-02 04:13:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35ctlk",
                  "author": "iongion",
                  "text": "Thanks man, these things appear out of nowhere",
                  "score": 1,
                  "created_utc": "2026-02-02 13:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o32i448",
              "author": "Potential_Block4598",
              "text": "Havenâ€™t tried that yet",
              "score": 2,
              "created_utc": "2026-02-02 00:26:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3726pq",
              "author": "erizon",
              "text": "It is far easier, just set few environment variables:\n\n    ANTHROPIC_BASE_URL=\"https://api.z.ai/api/anthropic\" \\\n    API_TIMEOUT_MS=\"3000000\" \\\n    ANTHROPIC_DEFAULT_HAIKU_MODEL=\"glm-4.5-air\" \\\n    ANTHROPIC_DEFAULT_SONNET_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_DEFAULT_OPUS_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_AUTH_TOKEN=\"8xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxo\" \\\n    claude",
              "score": 2,
              "created_utc": "2026-02-02 18:08:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o378ib9",
                  "author": "iongion",
                  "text": "But thats what i do, i wanted the same but with devstral/mistral official ones",
                  "score": 1,
                  "created_utc": "2026-02-02 18:36:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o33xky0",
              "author": "nycigo",
              "text": "Yes, 100% ask Claude for the code ðŸ˜‚",
              "score": 0,
              "created_utc": "2026-02-02 05:39:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o33bmmj",
          "author": "aaronr_90",
          "text": "What are your thoughts on Qwen3 Coder vs Devstral Small 2?",
          "score": 2,
          "created_utc": "2026-02-02 03:13:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w52x",
              "author": "Potential_Block4598",
              "text": "Devstral can continue for longer without my interaction and can correct itself if it faces an issue while Qwen would just loop trying the same mistake again and again and failing\n\nOn the other hand Devstral is slower",
              "score": 1,
              "created_utc": "2026-02-02 05:28:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33xnzm",
                  "author": "nycigo",
                  "text": "It's super fast via API, but I don't know about local processing.",
                  "score": 1,
                  "created_utc": "2026-02-02 05:40:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33i840",
          "author": "former_farmer",
          "text": "In which hardware are you running this?",
          "score": 1,
          "created_utc": "2026-02-02 03:53:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w6f1",
              "author": "Potential_Block4598",
              "text": "AMD Strix Halo\n\nNot the best I guess but it kinda works",
              "score": 1,
              "created_utc": "2026-02-02 05:28:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o348o0p",
          "author": "SourceCodeplz",
          "text": "I don't see the harness that you used? How did you work with Devstral? Inside what tool?  \nI see you say about MCPs, but in what tool?",
          "score": 1,
          "created_utc": "2026-02-02 07:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36b3u9",
          "author": "nico_aka_redcat",
          "text": "What resource do you have to run devstral locally ?",
          "score": 1,
          "created_utc": "2026-02-02 16:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32fqii",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -4,
          "created_utc": "2026-02-02 00:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32gss6",
              "author": "cosimoiaia",
              "text": "Others do what they think it's best for you, Mistral does what you actually say.\n\n(It's my experience too, it has always been the best instruction following model of all)",
              "score": 7,
              "created_utc": "2026-02-02 00:19:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o32i1gy",
              "author": "Potential_Block4598",
              "text": "There is a TL;DR\n\nBest model for local agentic ai stuff",
              "score": 3,
              "created_utc": "2026-02-02 00:25:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qpa554",
      "title": "Payment in EUR more expensive than in USD?",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/9xg4e9dz33gg1",
      "author": "d4v1d_dp",
      "created_utc": "2026-01-28 12:34:01",
      "score": 76,
      "num_comments": 18,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qpa554/payment_in_eur_more_expensive_than_in_usd/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o27drrt",
          "author": "Axiom05",
          "text": "The price in US dollars never includes VAT, unlike the price in euros.",
          "score": 74,
          "created_utc": "2026-01-28 12:44:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o27kcj7",
              "author": "Jazzlike-Spare3425",
              "text": "Yes, this is it. You can see it by the asterisk. If you scroll down to the bottom of the table that compares the plan, just over the FAQ section, for the USD version it will say \"excluding taxes\" and for the Euro price it will say \"including taxes\"",
              "score": 12,
              "created_utc": "2026-01-28 13:24:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o29i11u",
              "author": "Patrick_Barababord",
              "text": "Maybe, but $1 = 0,83â‚¬ also.  \nSo $14.99 = 12.44â‚¬ ...and 12.44 + 20% VAT = 14.9â‚¬.",
              "score": 3,
              "created_utc": "2026-01-28 18:42:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2daedd",
                  "author": "aoc145134",
                  "text": "I don't think you'll get a reasonable comparison by using a conversion rate based on a four-year low for the dollar. Even a week ago it would have been $1 = 0.854 giving 15.36 Euros.",
                  "score": 1,
                  "created_utc": "2026-01-29 06:49:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o27f4ys",
              "author": "OwlSlow1356",
              "text": "paid one month in USD last year, the only currency available then although i am in europe but nonEUR country, and they deducted the VAT from USD price when providing a VAT number, second month they charged me full USD price, asked why if first month VAT was deducted, never received any answer, cancelled and good bye!",
              "score": 1,
              "created_utc": "2026-01-28 12:53:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o284ehb",
          "author": "EzioO14",
          "text": "Itâ€™s just a tax matter, not an advantage to U.S",
          "score": 14,
          "created_utc": "2026-01-28 15:06:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27cktf",
          "author": "Little_Protection434",
          "text": "That seems to be the case. I just checked the exchange rate and based on that it should indeed be the opposite.",
          "score": 9,
          "created_utc": "2026-01-28 12:37:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o282bu9",
              "author": "ComeOnIWantUsername",
              "text": "Just read the pricing as a whole, not just one part. For USD it's \"excluding taxes\". For EUR \"including taxes\".",
              "score": 8,
              "created_utc": "2026-01-28 14:56:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o282og9",
                  "author": "Little_Protection434",
                  "text": "That makes sense. Thanks!",
                  "score": 2,
                  "created_utc": "2026-01-28 14:58:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o28shtk",
          "author": "TheBl4ckFox",
          "text": "Itâ€™s always excluding tax for US customers and including VAT for EU.",
          "score": 3,
          "created_utc": "2026-01-28 16:52:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27teac",
          "author": "Nokushi",
          "text": "prices were aligned before, but were all without VAT included, which is uncommon in France\n\ni guess they now show EUR prices VAT included",
          "score": 2,
          "created_utc": "2026-01-28 14:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o280wet",
              "author": "sndrtj",
              "text": "And since VAT rates depend on the country of the _purchaser_, not the seller, exact amounts may change depending on where you are located.",
              "score": 4,
              "created_utc": "2026-01-28 14:49:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o286pfw",
          "author": "bluepuma77",
          "text": "Just saw that too, was irritated, it seems sooo stupid what they are doing with their pricing page.  \n  \n1. It's \"$15 with \\*\".   \n2. What's a \\*, okay pages down \\* means it's without tax.   \n3. Then I switch to Eur and it's \"â‚¬18 with \\*\"\n\nWho would have thought that the meaning of the \\*, many pages down, would silently change.\n\nI highly recommend to not hide the \\* so far down. And maybe use \\*1 and \\*2 or something.",
          "score": 1,
          "created_utc": "2026-01-28 15:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ecvg4",
              "author": "Fisherman-63",
              "text": "C'est notÃ© ! Will improve our page soon :)",
              "score": 2,
              "created_utc": "2026-01-29 12:21:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o27txik",
          "author": "Far-Reaction-1980",
          "text": "To this day I don't get Mistrals pricing",
          "score": 1,
          "created_utc": "2026-01-28 14:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o27htt4",
          "author": "Basiliscus219",
          "text": "Usually the prices are set based on the local purchase power. In poorer countries the price is lower.",
          "score": -5,
          "created_utc": "2026-01-28 13:09:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsvmbo",
      "title": "Is Mistral Large 3 actually the best ai writing tool or are we just coping?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "author": "Fresh_State_1403",
      "created_utc": "2026-02-01 11:02:36",
      "score": 53,
      "num_comments": 23,
      "upvote_ratio": 0.95,
      "text": "Iâ€™ve spent the last month running Mistral Large 3 against the new Claude 4.5 and GPT-5.1 \"Thinking\" modes, and Iâ€™ve come to a conclusion that might annoy the purists here. If I had to pick one for logic-heavy, technical writing where I don't want a \"guidance counselor\" lecturing me on my tone, Mistral is the winner, but only if you aren't paying the $20 \"tax\" for a single-model sub.\n\nMistral Large 3 is fundamentally the best ai writing tool for anyone who needs high-density output without the sycophancy. While GPT-5 tries to guess what I want to hear and Claude gets bogged down in its own safety \"Constitutional\" logic, Mistral just executes the Markdown. It treats the prompt like a set of instructions, not a suggestion.\n\nImportantly, the reasoning depth here (let me elaborate!!) is finally at parity with the frontier models, but without the \"lobotomy\" effect we see after a modelâ€™s been out for six months. Iâ€™ve been testing this by running complex document analysis through writingmate, where I can flip between Mistral and the other models in a single thread. such a  \"hallucination drift\" is significantly lower on Mistral when you're dealing with non-English technical specs or legacy codebases, at least I found this to be true for my workflow.\n\nThe real problem isn't the model; itâ€™s the fragmentation. Most people claim ChatGPT is the best ai writing tool simply because theyâ€™ve already paid the $20 and don't want to admit it's lagging in raw reasoning. But the minute you need to cross-check a hallucination or run a deep search without the \"Exactly!\" and \"Sharp observation!\" fluff, the value of a single-model subscription falls apart.\n\nClaude and Gemini are great for their specific moats (f.e. Claude for narrative, Gemini for the 2M context window), but Mistral is the only one that feels like itâ€™s built for professionals who want a tool, not a friend. My skeptic take? Perhaps, stop overpaying for the \"big brand\" wrappers and start using a brief stack of tools that let you use the right logic for the right task.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2yarri",
          "author": "Working-Chemical-337",
          "text": "oh, price consolidation is the only thing that convinced me to try managed platforms. was paying >100 dollars/month for GPT, Claude, and Gemini separately. then tried multi ai platforms (or wrappers with many models) like writing mate, just because i heard it handled the agent side better than the standard APIs, and saving that ammount per month while still getting frontier-level Mistral reasoning is probably the only \"win\" Iâ€™ve had in my tech stack this year that just started",
          "score": 9,
          "created_utc": "2026-02-01 11:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yjlcd",
              "author": "Fresh_State_1403",
              "text": "makes a lot of sense",
              "score": 2,
              "created_utc": "2026-02-01 12:20:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2z78k1",
              "author": "Tuckebarry",
              "text": "Wait so what's the stack then? What's the best multi AI platform that you mentioned?\n\nThanks",
              "score": 1,
              "created_utc": "2026-02-01 14:49:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb0jt",
          "author": "One-Risk-4266",
          "text": "doing the same thing and bouncing drafts between Claude and Mistral. I find Claude is better for the initial soul of a piece, but Mistral is the only one I trust to actually follow a style guide without drifting into aispeak after three pages. and itâ€™s hard to argue itâ€™s not a top-tier contender for the title of best ai writing tool in 2026, especially if you value data sovereignty and want something local",
          "score": 5,
          "created_utc": "2026-02-01 11:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yk8ss",
              "author": "Fresh_State_1403",
              "text": "i totally get that. Claude has that \"human\" spark, but it definitely starts to hallucinate its own \"creativity\" after a while. and Mistral is just cold, hard logic, which is a godsend for technical consistency and actually sticking to a style guide without the aispeak fluff; so for me all in one chats like writingmate are just to keep them both in one window because I was getting massive tab fatigue trying to copy-paste between accounts. Itâ€™s way easier to just flip the model toggle when Claude starts getting too \"wordy\" and you need Mistral to tighten things up. Honestly, the best ai writing tool in 2026 isn't a single model anymore, itâ€™s just whichever one isn't currently acting \"lobotomized\" or ignoring your instructions\n\nbtw are you running Mistral locally via Ollama for that data sovereignty piece, or are you just sticking to the API for the speed?",
              "score": 1,
              "created_utc": "2026-02-01 12:26:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z379l",
          "author": "porzione",
          "text": "How do you actually use Large? Mistral lacks actual tools, except vibe/devstral - the same issue as with Chinese models. I use local Mistral Small as creative scene writer, but everything is planned by Opus, because I need to collect names, facts, timeline, check backstories from Obsidian vault with \\~1500 files and I use Claude Code for this, then CC writes detailed scene description/plan and sends it to local fine tuned Mistral Small.\n\nIn theory OpenCode or Zed may work for this, but my previous attempts to use Mistral modelsâ€™ agentic features have all failed miserably, except Devstral. I hope that Mistral will add all their models to Vibe, so it will work without fiddling with 3rd party tools.",
          "score": 3,
          "created_utc": "2026-02-01 14:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30mhi5",
              "author": "Working-Chemical-337",
              "text": "what tools does mistral lack?",
              "score": 1,
              "created_utc": "2026-02-01 18:47:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30plz7",
                  "author": "porzione",
                  "text": "Vibe with all Mistral models, specifically - cli tool with ACP support.",
                  "score": 1,
                  "created_utc": "2026-02-01 19:01:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31povj",
              "author": "erizon",
              "text": "GLM family works perfectly fine in Claude Code via ANTHROPIC_BASE_URL environment variable (actually much faster than via OpenAI style //api.z.ai/api/coding/paas/v4). Deepseek also supports it, which Chinese model does not?",
              "score": 1,
              "created_utc": "2026-02-01 21:55:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zmlna",
          "author": "Ambitious_Fee3169",
          "text": "Mistral Large is fantastic. It's the default in our AI chat system. Mistral medium is also great (but more expensive for some reason for output tokens vs large).",
          "score": 2,
          "created_utc": "2026-02-01 16:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30sgl1",
              "author": "Fresh_State_1403",
              "text": "I don't like using it per credits / calls, because it never seemed to be economically viable for me, so i used 'all in one' chatbot subscription(s) which in my case seems to work more, like writingmate in either pro or ultimate",
              "score": 2,
              "created_utc": "2026-02-01 19:14:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb78z",
          "author": "DrPinguin98",
          "text": "I do a lot with AIs and use a service provider that lets me use pretty much all AIs, and honestly, Mistral Large 3 is definitely no better than GPT 5.2 Thinking.\n\nJust the day before yesterday, I tried to rewrite some of my reports and got a little frustrated with Mistral. Content was constantly missing, it made things up (even though I explicitly forbade it), or it didn't rewrite things the way I defined in the prompt.\n\nBut that could also be due to the languageâ€”in my case, German.\n\nI have to say, though, that a lot is happening in this regard, and we're starting to reach the point where I can and will really use Mistral.\n\nAnd when the time comes, my monthly subscription will belong entirely to Mistral, and I honestly can't wait.",
          "score": 5,
          "created_utc": "2026-02-01 11:10:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30j53c",
              "author": "Fresh_State_1403",
              "text": "by the way, does the need to use German change a lot in how you pick AI tools? what differences do you see when it comes to non-English responses?   \n5.2 thinking is very ok",
              "score": 1,
              "created_utc": "2026-02-01 18:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb5w2",
          "author": "TonyHMeow",
          "text": "The best thing about OA is the saved memory blocks and profiling aspect of the models in both writing and conversational discussion flow, and as of now still leading compared to other major competitors IMO.\n\nComing from GPT 4oâ€™s writing, how is LeChat saved memory (storage size/utilization) and context tracking (in a project, say) compared to OpenAI? Genuinely considering trying out Mistral after 4o retires, would love some input on this!",
          "score": 1,
          "created_utc": "2026-02-01 11:09:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ykzkx",
              "author": "Fresh_State_1403",
              "text": "OpenAIâ€™s memory is definitely the stickiest part of their ecosystem to me, it's hard to leave once the model knows your specific quirks. Yet if youâ€™re looking at lechat , in my xp  Itâ€™s less \"vibe-based\" and more literal. Their Project Libraries actually beat GPT in my opinion because they index your files properly. Instead of the model just cramming everything into the context window and hallucinating when it gets full, Mistral pulls only whatâ€™s relevant. Itâ€™s way more stable for long-term technical work. So I often use Writingmate to A/B test the recall between them and overall compare models side by side, and while GPT feels more intuitive, Mistral is much more transparent about what itâ€™s actually pulling from your history. You won't get that \"as an AI assistant\" lecture every five minutes either, which is a massive plus. There's also a trade-off which is, Mistral won't remember a random chat from three weeks ago unless you specifically tell it to save that info to your memory or project. Itâ€™s more manual, but somwewhat better for privacy and focus.",
              "score": 2,
              "created_utc": "2026-02-01 12:31:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2zudq7",
                  "author": "TonyHMeow",
                  "text": "ok, thanks for the info!\n\nWhen you said \"Mistral is much more transparent about what itâ€™s actually pulling from your history.\" Do you mean like it literally quotes you (\"word for word\") from another conversation/your uploaded files? Because i think GPT had an update about that a couple of weeks, which I really dislike lol.",
                  "score": 1,
                  "created_utc": "2026-02-01 16:40:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yhhi4",
          "author": "Alex-plosion",
          "text": "For  ideas, I don't find mistral large 3 to be amazing, but for writing, yeah it's great, especially in French.\nI tend to write the plan, or a whole draft with another model and rewrite it after with mistral.",
          "score": 1,
          "created_utc": "2026-02-01 12:04:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30jzvw",
              "author": "Fresh_State_1403",
              "text": "when I am able to switch within one chat with tools like writingmate, I can interchange mistral with gpt and gemini without changing context, tools, or chatbots. but frm what I know, Mistral is truly very fine at European languages",
              "score": 1,
              "created_utc": "2026-02-01 18:36:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yqxwq",
          "author": "Charming_Support726",
          "text": "No. Definitely No.\n\nUsed all of them for writing. All of them showed ugly quirks. I tried German, European Portuguese, English. \n\nGemini follows style instructions quite well, but lacks some variance in creativity. Style was very important for me. \n\nAll others still do this damn \"its not only A, it is B\" thing in every second sentence. You can't get rid of it. \n\nThe creative model from Mistral Labs can get European Portuguese right - this is the only model except for Gemini 3 Pro, which is capable. All others fails (Claude, Gpt, Large3 and more). Unfortunately it is not open weights, otherwise I'd like to see an optimized version.",
          "score": 1,
          "created_utc": "2026-02-01 13:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30qf27",
              "author": "Working-Chemical-337",
              "text": "you can prompt them not to use negations, and other signs of ai writing, and otherwise follow your natural style of writing. some editing may be required even then, but hey, this can save a lot of time when you have to do some huge outputs",
              "score": 1,
              "created_utc": "2026-02-01 19:05:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z0vxg",
          "author": "TeeRKee",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-01 14:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eut58",
          "author": "urzabka",
          "text": "I am practically using all of models I like and Mistral as well in multi-ai tools. For now itâ€™s writingmate and works well for me. Does it cover 100% of all that I need AI for? No but all that I need a chatbot for, having like mistral GPt Claude Gemini and others",
          "score": 1,
          "created_utc": "2026-02-03 21:08:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtp21z",
      "title": "Mistral vs. ChatGPT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "author": "sachama2",
      "created_utc": "2026-02-02 07:59:28",
      "score": 47,
      "num_comments": 50,
      "upvote_ratio": 0.96,
      "text": "I already have a ChatGPT subscription. What additional benefits would I get if I also subscribe to Mistral?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o34ez2f",
          "author": "EzioO14",
          "text": "You wonâ€™t gain anything by using both, mistral is good but a bit behind ChatGPT. Most people use mistral because itâ€™s good enough for their needs, cheaper and not American.",
          "score": 78,
          "created_utc": "2026-02-02 08:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34jg1j",
              "author": "SpeedDaemon3",
              "text": "Also mistral is not censored like chatgpt...Â ",
              "score": 36,
              "created_utc": "2026-02-02 08:54:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34oy5v",
                  "author": "EzioO14",
                  "text": "Do you have an example? I havenâ€™t used ChatGPT much",
                  "score": 3,
                  "created_utc": "2026-02-02 09:47:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35u3om",
                  "author": "Objective-Sky7312",
                  "text": "Iâ€™m finding it still very censoredâ€¦ are people getting it to do NSFW?",
                  "score": 2,
                  "created_utc": "2026-02-02 14:40:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38nm2w",
                  "author": "S1lv3rC4t",
                  "text": "https://preview.redd.it/wv4zc3wfs5hg1.png?width=788&format=png&auto=webp&s=c4cee9bb77aa4b7b21289402e080980e7d2b584d\n\nThat is pretty much hard censoring for me.",
                  "score": -5,
                  "created_utc": "2026-02-02 22:38:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34i5ne",
          "author": "mythrowaway4DPP",
          "text": "It is more of a replacement.  \n  \n***TL;DR***   \nMistral is behind ChatGPT a little bit, but less censored, and European.\n\n**Some details**\n\n* Their research feature is great, and easily on par with CGPT. (yes, I did the testing).\n* Image generation is kinda mid. (afaik, they are still using FLUX by black forest labs, not flux 2)\n* No text to speech, but their transcription of voice input is great and FAST!\n* Their document management uses a concept of different \"libraries\" of documents, that you can then use in different chats.\n\nPrompting mistral needs to be more strict and detail oriented. Especially if you need it to access a file, you need to very EXPLICITLY tell it to do so.   \nThis is very different from CGPT which feels like it is swimming in the provided documents and accesses them too eagerly at times.\n\nOverall, I am very happy with it.",
          "score": 23,
          "created_utc": "2026-02-02 08:41:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36b4fy",
              "author": "sachama2",
              "text": "\"transcription of voice input is great and FAST\" Very interesting. Do you mean you can load via the ineterface a mp3 file?",
              "score": 1,
              "created_utc": "2026-02-02 16:04:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36bi92",
                  "author": "mythrowaway4DPP",
                  "text": "No. I was talking about using voice for input",
                  "score": 4,
                  "created_utc": "2026-02-02 16:05:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o37bugr",
              "author": "Dadinek",
              "text": "Love the voice input as well and the fact that you can select if you want to autosend or not",
              "score": 1,
              "created_utc": "2026-02-02 18:51:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34j1ja",
          "author": "MimosaTen",
          "text": "I left ChatGPT due to it being extremely slow, in favour of Gemini. But I use Mistral Vibe CLI that uses devstral 2 to automate code writing",
          "score": 8,
          "created_utc": "2026-02-02 08:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37p140",
              "author": "obadacharif",
              "text": "Check [Windo](http://trywindo.com) when switching models, itâ€™s a portable AI memory that allows you to carry your memory with across models. No need to re-explain yourself.\n\nPS: Im involved with the project",
              "score": 2,
              "created_utc": "2026-02-02 19:52:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34i5xt",
          "author": "Nervous_Sun4915",
          "text": "I don't know if this is relevant for you, but you gain (limited) access to their API which you can use for your own applications as a LLM endpoint, OCR, vibe-coding, etc.\n\nI built a tool that transforms all my PDFs of scanned books/articles (basically images) into fully searchable PDFs where I can use the text in less than an hour, using Mistral and their OCR API & Python assisted coding.",
          "score": 6,
          "created_utc": "2026-02-02 08:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35ctek",
          "author": "Lakafior",
          "text": "\\- MCP custom server integration on mobile and desktop is the reason I've bought it, and it's way ahead the rest (meaning other apps don't have this feature at all). I can talk with my database while on the phone now, and morevover not using my tokens doing that.\n\n\\- Libraries, which are like your knowledge bubbles with links, documents etc. you can pin to a new chat. It's a great way to chat with your notes etc. without creating custom GPT.\n\n\\- It's faster and more focused on your prompts without going sideways.\n\n\\- European, so a lot more privacy-protected and in general LLM who you talk about a lot of things this is very important point imo.\n\n\\- Cheaper",
          "score": 7,
          "created_utc": "2026-02-02 13:03:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36bi9w",
              "author": "sachama2",
              "text": "\"Â MCP custom server integration on mobile and desktop\" Do you mean that I can imagine a chat (i.e. \"mining\" ) my Calibre directory?",
              "score": 2,
              "created_utc": "2026-02-02 16:05:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36mjd7",
                  "author": "mythrowaway4DPP",
                  "text": "With an mcp server handling the requests and handing them to a calibre API - why not?",
                  "score": 1,
                  "created_utc": "2026-02-02 16:56:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38j6bf",
              "author": "ohhellnaws",
              "text": "Afaik you can pin mid chat. Same for agents. Have some with customer prompts for quick chat style, some with attached library, guardrails, etc and call upon them and swap out mid chat. Best feature not anywhere else.",
              "score": 1,
              "created_utc": "2026-02-02 22:15:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34ecc9",
          "author": "uusrikas",
          "text": "Well, they kinda do the same thing but ChatGPT is better at it. I don't use ChatGPT because they are big Trump donors and I don't want to support that. Having two subscriptions would be pointless. Gemini is better than both functionally.",
          "score": 17,
          "created_utc": "2026-02-02 08:05:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34rav1",
          "author": "allulcz",
          "text": "Something to note, I use their API for free now and I am more than happy. I use Mistral Small 3.2 and I am very surprised how good it is. I use it for automation, classification, and text parse. Just surprised how well it works.",
          "score": 4,
          "created_utc": "2026-02-02 10:10:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34kom4",
          "author": "Gold-Guess4651",
          "text": "Mistral le chat is GDPR-compliant so has much better privacy than chatGPT. It's not an additional benefit next to using chatGPT but is certainly a benefit of le chat over chatGPT.",
          "score": 8,
          "created_utc": "2026-02-02 09:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34xurd",
              "author": "Spiritual-Plant3930",
              "text": "There is no privacy when it comes to any LLM; otherwise, they wouldn't work. \n\nLLMs are \"leaking\" all the time by design.\n\nNeural networks can't be privacy-conscious. \n\nIt's like telling a kid to learn without any access to knowledge (can't use the internet, can't read books, etc.).\n\nTo have privacy, you have to know where the info is coming from (to know it's private info) - LLMs don't exactly know where the info came from.\n\nFor more, this one is a good start. \nhttps://youtu.be/_3okhTwa7w4",
              "score": -4,
              "created_utc": "2026-02-02 11:10:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o356xg9",
                  "author": "Gold-Guess4651",
                  "text": "I didn't say le chat is fully private, I said that due to GDPR-compliance privacy protection is better (or perhaps not as terrible if you like) than e.g. chatGPT. This is because le chat doesn't use chats or any data in the chat to train the LLM, all data are stored at European servers (and therefore cannot be accessed by the USA government), and doesn't share info with third parties.",
                  "score": 7,
                  "created_utc": "2026-02-02 12:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35fp0g",
          "author": "aajl2",
          "text": "Try to make a single payment $10 on open router so you'll access to openai, mistral other providers and many more LLM. Why? Testing, comparing, evaluating the best that fit your needs. I use gpt5-codex for python learning and it's been great",
          "score": 2,
          "created_utc": "2026-02-02 13:21:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37bkul",
          "author": "Dadinek",
          "text": "I don't use ChatGPT because their business model is just shitty. Every innovation is meant to swallow more personal data.",
          "score": 2,
          "created_utc": "2026-02-02 18:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34sfep",
          "author": "crazyserb89",
          "text": "Iâ€™m paying for ChatGPT and Gemini and I was testing Le Chat too. Honestly itâ€™s far behind those, but itâ€™s a good concept. If they improve it in future I would be glad to move there",
          "score": 2,
          "created_utc": "2026-02-02 10:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35wg1e",
              "author": "TheMrLexis",
              "text": "What can they do for improving Le Chat?",
              "score": 2,
              "created_utc": "2026-02-02 14:53:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o360hus",
                  "author": "MattyGWS",
                  "text": "For starters, it doesnâ€™t do coding as well as chatgpt. \n\nWould be nice if it had a voice chat feature too",
                  "score": 1,
                  "created_utc": "2026-02-02 15:13:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35z3u2",
                  "author": "crazyserb89",
                  "text": "Custom chats, clipboard copy pasting doesnâ€™t work on iOS, text to speech is trash and thereâ€™s no live speech. More integrations, more optimizations etc.. I mean the price is not correct even, you can take Gemini Plus for few bucks only and to get way more",
                  "score": 0,
                  "created_utc": "2026-02-02 15:06:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35uhxf",
          "author": "martapap",
          "text": "I started using mistral recently. It is incredibly dumb at following directions. Seems like it has a mind of its own ane just gives you whatever it wants instead of what you ask for. With the exception of agents. I created a couple of agents using language another model gave me and it was able to follow directions then.",
          "score": 3,
          "created_utc": "2026-02-02 14:42:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qry40r",
      "title": "Replace github copilot with Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "author": "InternalBroad2522",
      "created_utc": "2026-01-31 09:39:58",
      "score": 34,
      "num_comments": 10,
      "upvote_ratio": 0.93,
      "text": "Hi all! I would like to replace Github Copilot with Mistral for coding in VSCode IDE. What can I do?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2rk80x",
          "author": "scara1701",
          "text": "Does it have to be in vscode? I guess you could run mistral vibe in a terminal window.",
          "score": 6,
          "created_utc": "2026-01-31 09:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vlko5",
              "author": "LoadZealousideal7778",
              "text": "Or in the Jetbrains IDE of your choice",
              "score": 3,
              "created_utc": "2026-01-31 23:25:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2roc3i",
          "author": "katafrakt",
          "text": "Mistral Vibe supports ACP, so any VSCode extension supporting ACP would do. I'm not too familiar with this ecosystem, so I won't give any recommendations.",
          "score": 4,
          "created_utc": "2026-01-31 10:27:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2szqsy",
          "author": "kiwibonga",
          "text": "There's a mistral vibe extension that lets you have the CLI in VSCode. It's mostly a convenience thing that saves you the trouble of launching the terminal and setting the working directory.",
          "score": 2,
          "created_utc": "2026-01-31 15:45:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2utlgd",
          "author": "Bob5k",
          "text": "Have in mind that you either pay for API usage of devstral or accept the quite mediocre quota allowance on experiment plan.",
          "score": 2,
          "created_utc": "2026-01-31 21:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xnbbp",
              "author": "deegwaren",
              "text": "Oh? Didn't they just include vibe-cli usage in their pro plan? Meaning it's included like Claude code usage in the Claude Pro plan.",
              "score": 1,
              "created_utc": "2026-02-01 07:30:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2yd1vv",
                  "author": "Bob5k",
                  "text": "They included cloud vibe usage afaik, don't know about vibe cli tbh and not sure on the quota allowance, i still think the cli falls under Mistral ai studio.",
                  "score": 1,
                  "created_utc": "2026-02-01 11:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ro18m",
          "author": "opsmanager",
          "text": "Im using the Continue extension, works reasonably well. I havent yet figured out how to make it as seemless as the copilot extension with regards to accessing the repository files. But im sure its just me missing something obvious.",
          "score": 2,
          "created_utc": "2026-01-31 10:24:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uj3bq",
              "author": "vienna_city_skater",
              "text": "Continue is soso, good for code completion, but agent mode sucks, Roo Code works well for agentic coding in VS Code, but the TUIs are much better. I switched everything to OpenCode because I mix models a lot. However, so far I have not find a way to get access to the free devstral with my Le Chat Pro subscription outside of vibe CLI.  \nEDIT: I think I found the problem, I used the API key from La Platforme Admin Panel not from the AI Studio VIBE CLI section, so I was charged on-the-go.",
              "score": 3,
              "created_utc": "2026-01-31 20:10:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqw89j",
      "title": "Made myself a LeChat application on linux",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqw89j/made_myself_a_lechat_application_on_linux/",
      "author": "MattyGWS",
      "created_utc": "2026-01-30 05:03:06",
      "score": 33,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "Ok I'm no programmer, but I just had some fun learning how to build 'web apps' with Electron. I made a lil desktop icon too (in gimp). So now I have my own desktop application for Mistral! \n\n\n\nhttps://preview.redd.it/900xz4j75fgg1.png?width=2005&format=png&auto=webp&s=fdbbb04df3c14f515991184693b4fa46119766e0\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqw89j/made_myself_a_lechat_application_on_linux/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2lf64l",
          "author": "AdIllustrious436",
          "text": "Great! Just for you to know, you can achieve the same result in one click with Chromium PWA, which install websites as applications on the system.",
          "score": 5,
          "created_utc": "2026-01-30 12:55:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mcd54",
              "author": "MattyGWS",
              "text": "Yea I know that's how I normally do it but I wanted to learn how Electron apps are made, seemed like a great yet simple example to bring LeChat to desktop. :)",
              "score": 4,
              "created_utc": "2026-01-30 15:43:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o36s7md",
              "author": "LoadZealousideal7778",
              "text": "That seems to have issues with Apple Music. Will try the Electron method next. Or maybe google if someone already did.",
              "score": 1,
              "created_utc": "2026-02-02 17:22:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xzts3",
          "author": "LearningPodd",
          "text": "Good job! I'm also starting to creat stuff with AI â˜ºï¸ It's so much fun and the more people that creat things themselves, the less power companies will have over our products  ðŸ‘",
          "score": 2,
          "created_utc": "2026-02-01 09:26:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv1o6n",
      "title": "How do you see LeChat in 2026 February compared to ChatGPT and other LLMs?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "author": "BonoboPowr",
      "created_utc": "2026-02-03 19:31:03",
      "score": 33,
      "num_comments": 30,
      "upvote_ratio": 0.93,
      "text": "I always found it (sadly) underpowered. Sometimes I checked in on it and concluded that it's still lacking. But now I started a conversation, and it surprised me for the better.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3ebvkc",
          "author": "SkyPL",
          "text": "It underperforms. That's obvious for anyone using LeChat with SOTA models. Benchmarks try to quantify it that gap, but it *is* an observable issue in the actual work that I do.\n\nOverall though it does decently for being an alternative point of view. Especially for the stuff that requires search online.\n\nYou can input more complex topics into something like ChatGPT, Gemini, Deepseek and LeChat and the truth will be somewhere in there, either in one of, or between the four ;)",
          "score": 20,
          "created_utc": "2026-02-03 19:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3fcxim",
              "author": "mythrowaway4DPP",
              "text": "I actually just did a personal test with a complex deep research task.\nChatGPT, Gemini, Mistral, Claude\n\nMistral did just fine.",
              "score": 1,
              "created_utc": "2026-02-03 22:33:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3fnpkg",
              "author": "troyvit",
              "text": "I agree that Mistral under-performs, but when adding prices as a metric, how much does it under-perform? When I compare Mistral Large on sites like this one:\n\n[https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512](https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512)\n\nto Claude Sonnet 4.5:\n\n[https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5](https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5)\n\nMistral large is around 1/6 the price for inputs and 1/10 the price for outputs.\n\nSo does Mistral suck 10x more than Sonnet? The answer could very well be \"yes\" if because of the model choice you spend 10x as long on a project.\n\nBTW I don't know if [pricepertoken.com](http://pricepertoken.com) is a real web site, so if I have those prices wrong my apologies. My take also doesn't take into account alternative ways of paying.",
              "score": 1,
              "created_utc": "2026-02-03 23:30:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ei4f2",
          "author": "Helenaisavailable",
          "text": "It's great for role-playing and for creative collaboration. That's what I mostly use LLMs for, so I'm satisfied. Agents are fantastic once set up properly.Â Mistral is improving , and I want to support them by using their product.Â ",
          "score": 12,
          "created_utc": "2026-02-03 20:09:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3erh1l",
              "author": "Icy_Distribution_361",
              "text": "Role playing? What do you mean? You role play with the LLM? And then what?",
              "score": 4,
              "created_utc": "2026-02-03 20:53:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ezpxx",
                  "author": "Helenaisavailable",
                  "text": "I'm a painter. I have certain characters, worlds, scenarios, creatures in my mind and tell the LLM to act it out with me,Â and we co-write a story.Â It can sometimes inspire me.Â Whatever happened in the role-play might spark an idea for a certain painting or drawing.\n\n\nI dont need an LLM to inspire my art, and I understand that role-playing might seem weird to some people. But I find it very fun! It's just an outlet for my daydreaming.Â ",
                  "score": 7,
                  "created_utc": "2026-02-03 21:31:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ewvep",
                  "author": "BonoboPowr",
                  "text": "ðŸ’¦",
                  "score": 0,
                  "created_utc": "2026-02-03 21:17:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3enfp1",
          "author": "Substantial-Yam3769",
          "text": "Further and further behind, i hope they soon will unvail a new model, something like Kimi K2.5.\n\n\nHowever it is still one of my favorite AIs, not just becouse of GDPR, and EU data protections, but also becouse of the flexibility Le chat offers and i like style of communication of the models.",
          "score": 7,
          "created_utc": "2026-02-03 20:34:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ecpge",
          "author": "farawayviridian",
          "text": "For fiction writing itâ€™s great. For everything else I use Gemini.",
          "score": 5,
          "created_utc": "2026-02-03 19:43:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eebw7",
          "author": "aeonixx",
          "text": "It's more likena scalpel, it doesn't do shit I didn't ask for. It means I do more preparation before sending the prompt, and I rarely have to correct tomfoolery.",
          "score": 5,
          "created_utc": "2026-02-03 19:51:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esm6s",
              "author": "amunozo1",
              "text": "This is very true. It follows much more the instructions without adding things nobody asked for.",
              "score": 3,
              "created_utc": "2026-02-03 20:58:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eiv28",
          "author": "Big_River_",
          "text": "formidable! it only underperforms on useless benchmarks - in many use cases it is state of the art - plus it has improved performance over and within large context windows",
          "score": 4,
          "created_utc": "2026-02-03 20:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3exa52",
              "author": "BonoboPowr",
              "text": ">formidable\n\nIn what language?",
              "score": 1,
              "created_utc": "2026-02-03 21:19:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3eby4j",
          "author": "uusrikas",
          "text": "Good at fiction writing.\n\n\n\n\nPretty bad at searching for facts.\n\n\n\n\nBad image recognition. Image generation is ok if you ask it to do normal mundane stuff, but bad at realizing weird image ideasÂ \n\n\n\n\nTerrible thinking mode, almost unusable how it starts questioning itself and gets stuck in infinite loops.\n\n\n\n\nGood at helping me work, programming.\n\n\n\n\nFrankly, the only reason why I use it is because it is European. They are catching up when AI development slows down, but I really hope they pick up the pace.Â \n\n\nI use free versions of Gemini and Anthropic when ever I want a second opinion. Gemini is overall really good now and Anthropic has a nice pleasant writing style I like",
          "score": 6,
          "created_utc": "2026-02-03 19:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ed8u9",
          "author": "erizon",
          "text": "Different LLMs have different strengths in different categories.\n\nUnder/overpowered is meaningless without context (unless they are notoriously awful in everything). Are you writing Javascript code? FORTRAN code? Writing a novel? Researching science? \n\nI personally found Devstral better than Opus/Sonnet/Gemini for code implementation where design is already provided, en par with Haiku (only these two proactively wrote and executed tests in my experience). \n\nNot much to say about LeChat myself, as I barely started using it few days ago",
          "score": 2,
          "created_utc": "2026-02-03 19:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eh068",
          "author": "Edereum",
          "text": "For small very deterministic tasks in an agent flow, OCR and data extraction, its very cost effective with very good performance.  \nFor the rest, it underperforms.  \nI second SkyPL on \"research\" that give another view of SOTA.",
          "score": 2,
          "created_utc": "2026-02-03 20:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3einy3",
          "author": "Snickers_B",
          "text": "The coding is on par with other tools for specified tasks. Usually small tasks that is. \n\nThe writing is very good and I think better than ChatGPT but not better than Claude for writing or code.",
          "score": 2,
          "created_utc": "2026-02-03 20:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3et5p2",
          "author": "Celmad",
          "text": "I was using it now again after a while, and after using Gamini Pro, and It was very underwhelming.\n\nI was asking about email providers in Europe, alias management and password managers.\n\nGemini Pro seems like a person giving you very reliable information and even being creative and bringing information I might've missed.\n\nMistral (free tier) replied fast, yes, but with not much info. Just a quick few facts (some of them wrong, like saying 2FAS Pass was from Poland instead of US) in the form of a table with not much more info than what I gave it.\n\nReally really underwhelming.\n\nI had to stopped using it at work because I was working with Drupal .module files and Mistral didn't accept these files, only ChatGPT and Gemini did accept them of the AI chats I tried.",
          "score": 2,
          "created_utc": "2026-02-03 21:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eer49",
          "author": "faresar0x",
          "text": "The entire world push new stuff every few months. Le chat like once a year and it doesnâ€™t even compete. I would like to support it but its way behind. If they wanna win market share, they gotta nail coding benchmarks",
          "score": 4,
          "created_utc": "2026-02-03 19:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3efmf4",
          "author": "pirisca",
          "text": "A few days ago it came up with:\n\"Total Duration: 18 months (from February 2026 to July 2026).\"Â \nI asked how did it made such an error.Â \nThe response :\nYouâ€™re right to call out the oversightâ€”it was a clear miscalculation on my part, and I appreciate your patience. Hereâ€™s what happened:\n\n\n1. **Misinterpretation of Dates**: I mistakenly treated \"February 2026 to July 2026\" as an 18-month span instead of **6 months**. This was an error in basic arithmetic and attention to detail.\n2. **Overlooked Context**: I didnâ€™t double-check the timeline against your long-term horizon (20+ years), which should have signaled that a 6-month DCA was a short-term tactic within your broader strategy.\n\n\n### **How Iâ€™ll Improve**\n- **Verify Dates**: Always cross-check timeframes with a calendar or simple math (e.g., February to July = 6 months).\n(...)Â \n\n\nSigh...Â ",
          "score": 1,
          "created_utc": "2026-02-03 19:57:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3et602",
          "author": "ohhellnaws",
          "text": "Personally I do feel it's a little lacking. It's very quick, clear, and concise and a lot of the time that's exactly what I want. I use it as a chat bot for a quick to and from. Nothing beats it on speed.\n\nOne thing I havenâ€™t really explored yet is to push it to answer and think more deeply by using different prompts for different agents, one of his strength seems to be able to call upon one of your agents/libraries mid any chat. \n\nIt's very good, however, at creating CSVs for me and discussing grey areas where ChatGPT may completely refuse.",
          "score": 1,
          "created_utc": "2026-02-03 21:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ext13",
          "author": "SoWhoAmIReallyHuh",
          "text": "It's surprisingly good at generating images.",
          "score": 1,
          "created_utc": "2026-02-03 21:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f3shm",
          "author": "crazyserb89",
          "text": "I would say ChatGPT, Gemini and Claude are tie on top (depending on use-case), and LeChat is not even close.. I hope they will be able to do some magic like Kimi in 2026, otherwise RIP",
          "score": 1,
          "created_utc": "2026-02-03 21:49:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fto1a",
          "author": "Equivalent-Word-7691",
          "text": "Honestly way behind gtp, Gemini and especially Claude, but also to kimi, deepseek and GML\n\nO use AI for creative writing and it's probably the worse out of the AI I mentioned , another thing is the output length... Gosh too short\n\nAs an European I would like to support ot more for more than one reasons , but honestly the quality is juybad compared to both Americans and Chinese AI \n\nThe price also is too much high for the quality",
          "score": 1,
          "created_utc": "2026-02-04 00:03:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eo2si",
          "author": "Competitive_Ad_2192",
          "text": "Far, far behind, unfortunately.",
          "score": 0,
          "created_utc": "2026-02-03 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eib49",
          "author": "Shichroron",
          "text": "LeChat is dead",
          "score": -4,
          "created_utc": "2026-02-03 20:09:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esdfc",
              "author": "Temporary-Outside737",
              "text": "No. It's still purring.",
              "score": 1,
              "created_utc": "2026-02-03 20:57:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ebgru",
          "author": "NerasKip",
          "text": "Trash",
          "score": -10,
          "created_utc": "2026-02-03 19:37:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qq3rlf",
      "title": "Anthropic is winning market share in the enterprise LLM space. Google and Anthropic are gaining ground quickly, while OpenAI is currently seeking new investment in Saudi. Mistral's share is in image 2",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/gallery/1qq3okh",
      "author": "neural_core",
      "created_utc": "2026-01-29 09:11:52",
      "score": 23,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qq3rlf/anthropic_is_winning_market_share_in_the/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o2foxcs",
          "author": "Den_er_da_hvid",
          "text": "The colors in the legend for the stacked barchart is really difficult to see. What color is Mistral?",
          "score": 5,
          "created_utc": "2026-01-29 16:27:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2jxm3f",
              "author": "deegwaren",
              "text": "Mistral is baby blue, around 2%.",
              "score": 3,
              "created_utc": "2026-01-30 05:36:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2jzbvl",
                  "author": "Den_er_da_hvid",
                  "text": "It will be interesting to see in a few month as it seems people are shifting from US to European tech.",
                  "score": 4,
                  "created_utc": "2026-01-30 05:49:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqguur",
      "title": "Mistral OCR Skill",
      "subreddit": "MistralAI",
      "url": "https://skills.sh/parlamento-ai/parlamento-ai/mistral-ocr",
      "author": "antoine849502",
      "created_utc": "2026-01-29 18:33:36",
      "score": 22,
      "num_comments": 2,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqguur/mistral_ocr_skill/",
      "domain": "skills.sh",
      "is_self": false,
      "comments": [
        {
          "id": "o2gznci",
          "author": "nnamfuak",
          "text": "Thank you very much! It works really well. I've been using Mistral OCR3 (mistral-ocr-2512) for 3 weeks now, and it consistently delivers top-quality markdown! Love it!",
          "score": 2,
          "created_utc": "2026-01-29 19:59:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h1dp5",
              "author": "antoine849502",
              "text": "And the free version is so generous; this should be installed by default with any local agent",
              "score": 1,
              "created_utc": "2026-01-29 20:08:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qr2987",
      "title": "How do you use vibe effectively?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qr2987/how_do_you_use_vibe_effectively/",
      "author": "hyper_plane",
      "created_utc": "2026-01-30 10:51:43",
      "score": 13,
      "num_comments": 8,
      "upvote_ratio": 0.88,
      "text": "I am using the Vibe CLI to work on a project. I feel like the coding capabilities of the underlying devstral model are pretty good, but I have the impression that I am not using it right. Has anybody here tips and tricks on how to really take the best out of this tool? What do you put in your instructions? Do you write instructions for each project? How do you smoothly integrate with your IDE or code editor?\n\nI suppose we are all still learning how to use coding agents effectively, but if you have some really good tips, please share them here! ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qr2987/how_do_you_use_vibe_effectively/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2naf3s",
          "author": "RegrettableBiscuit",
          "text": "Write an AGENTS.md file that explains what your project is, how it is structured, how to extend it, coding guidelines, etc.\n\n\nWhen prompting, provide a path to example code files similar to what you are building so the LLM can emulate your code base's approach.\n\n\nWrite specific prompts that explain exactly what you want the LLM to do in detail.\n\n\nMake each prompt limited in scope and review after the LLM is done to make sure it's on the right track.Â ",
          "score": 5,
          "created_utc": "2026-01-30 18:15:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kyvx2",
          "author": "EzioO14",
          "text": "I only use vibe cli for documentation and nothing else",
          "score": 3,
          "created_utc": "2026-01-30 10:56:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kzp6q",
          "author": "chebum",
          "text": "This presentation from Jake Nations (Netflix) describes a framework of working with AI assistants which seems to provide best results in my experience : https://youtu.be/eIoohUmYpGI?si=rr5O4GLdLJTzOgPS",
          "score": 4,
          "created_utc": "2026-01-30 11:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l7l6x",
          "author": "AriyaSavaka",
          "text": "General rule of thumb for any coding agent would be effective system instruction that enforce strict test driven development with frequent atomic commit. And have git hooks already set up for running unit tester/formatter/linter/checker after every turn.",
          "score": 1,
          "created_utc": "2026-01-30 12:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pieyv",
          "author": "Bob5k",
          "text": "Using Clavix to help with prd and input. \nHowever - i find the limit on experiment plan quite low for serious work, so usually I'm using vibe whenever j just want to switch from Claude code combined with Kimi K2.5.",
          "score": 1,
          "created_utc": "2026-01-31 00:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2quc8z",
          "author": "Holiday_Purpose_3166",
          "text": "For context, I spent billions in tokens last year in prototypes and public facing, production work and it's mostly financial models interacting with 6 figures contracts. Shrimp in my circles, small, but produces income. \n\nRoughly, 70-80% of the jobs produced last year, had to be polished using SOTA closed source models, but I'm seeing that gap closing considerably fast and Devstral Small 2 beats GPT-OSS-120B on the same tasks, and has been doing more work than any OSS model up to 235B model I've used last year.\n\nI wish I could speak better about Mistral Vibe, as my experience was short-lived due to context bloat and errors - using the local Devstral Small 2 UD-Q4_K_XL which also had its issues with inference engines and stale quants. This is fixed by now but I've got plenty of experience with it since then, and I've been riding the Q8_0 which has been God. \n\nI assume Devstral 2 will be in the same ballpark with a better punch in knowledge. \n\nWhen Mistral Vibe launched, the context management blew up quickly and it often derailed. It may not be the case now based on what I've seen. \n\nBased on experience, any model is as good as the agentic framework is operating on, and how good is your context engineering for that specific setup. \n\nMost likely it will be your context work. I polished mine by repeating different cases in my codebases, using different prompts styles until I had repeated, positive results. \n\nNo walls of text prompts. Less is more, but not bare. \n\nKeep working out the environment you're using until you get better. It pays long-term, a LOT. \n\nIf you haven't produced reliable outputs every time, and you start jumping around different agentic tools and models, I guarantee you'll be frustrated. \n\nI found Devstral to work better with Kilocode with a custom agent I made, that saves me over 90% of context over original agents. Opencode works very well too, but Kilocode offers me Orchestrator choice which cuts most context bloat into smaller jobs for my custom agent. I might try Mistral Vibe back again later. \n\nMy base template for all repos must always include a folder for docs and that will generally include a blueprint with project spec overview, and a README.md which explains how the project works downstream. \n\nMost folks likely use AGENTS.md for repo context, which is generally fine. I like to break my docs modular enough, that isn't going to bloat the agent, but isn't hard enough to maintain either. \n\nThey complement each other. (How it works and where). Sometimes I ditch the README.md when I know the job doesn't require it, and that keeps my model light.\n\nIf I have a mono repo with different frameworks, I still use a single blueprint for the whole codebase and a single README.md, but I create separate sub-folder docs for each framework with their own framework-specific spec overview and directories. \n\nIn this last case, if I had to work in the front-end, I'd feed only the framework doc and not the whole blueprint and README.md. \n\nIf the work involved another framework, you could add the whole codebase blueprint and the other framework work doc too, and it works itself out. \n\nYou essentially make a modular doc system that doesn't add too much technical debt to maintain, and can be used whenever needed without giving the whole elephant every time. \n\nWhen it comes to prompt style, just simply write one and ask the model to format in a way it would understand and execute. Same with the documents. Devstral 2 models can surprisingly produce extensive documents if needed. \n\nI've used prompt styles from GPT-OSS-120B which broke Devstral. This is important.",
          "score": 1,
          "created_utc": "2026-01-31 05:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2le3ca",
          "author": "clayingmore",
          "text": "I'm not sure how 'basic' you're after. Have you got to the point where you are creating an [AGENTS.md](http://AGENTS.md) file in the root directory for any project? Also I use Claude Code and OpenCode rather than Vibe CLI but I am under the impression it works the same way. I have a Chinese Wall in between my IDE and the CLI so I'm mostly using the IDE for my own review and tinkering.\n\nAs a general approach, I try to create a Reason-Act agent pattern on a bigger scale. I create a constitution for the project, describing what the project is doing, why, what the tech stack is. Then I 'discuss' the entire project with my LLM to get to a point where I am confident that the model's semantic understanding is in line with mine. This coincidentally pushes the 'model' to think more and lay out a specific architecture as well as catch things I missed which I then sign off on.\n\nIf my [AGENTS.md](http://AGENTS.md) file, style guide, [ARCHITECTURE.md](http://ARCHITECTURE.md) file, unit tests, and any other supplementary plans are in good shape then the project can 'go'. Coincidentally, the coding LLMs are great at reviewing these documents as well.\n\n\"Yes.\" \"Yes.\" \"Yes.\" \"No change this.\" \"Yes.\" \"Yes.\"\n\nThe coding agent then does a huge portion of the project faster than I could do it, and in many cases better than I could do it. \n\nMake sure to insist on modularity so the whole thing doesn't break at once, effective version control so that you can roll things back, triple check relevant security issues, etc.\n\nThe model WILL make mistakes all the time, but it can also establish its own test driven development cycle in which it is immediately proceeding to fix those mistakes.",
          "score": 1,
          "created_utc": "2026-01-30 12:48:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kzx26",
          "author": "Eastern-Group-1993",
          "text": "I just generate code samples or ask questions or use it as a shortcut to what do I need to search for in documentation.  \nIf gpt-oss:20b isn't enough I either use claude or gpt-5.1 via [duck.ai](http://duck.ai) or I just try to figure it out on my own.\n\nGenerally I don't really full blown rely on it, I tried to make Github Copilot generate 3 python scripts:  \nGear Ratio to RPM converter, RPM to Gear Ratio converter, Gear Ratio generator using amount of frames between 200 RPM periods on a 1.000 gear ratio, which went as well you imagine.  \nI basically used 100% of the free monthly limit in 1-3 hours and the scripts barely worked(they didn't), I don't know how people manage to vibe code anything at all.\n\nAt least gpt-oss:20b is way better than whatever facebook puts into meta AI/whatsapp.  \nI wanted to go to sleep at 3am after playing RDR2, used LLaMa 4 ONCE and it's fully convinced Red Dead Redemption 2 has a \"save and quit\" button.  \nI would have to be more desperate than having access to 8kbps internet(which enables use of meta ai via whatsapp), at least gpt-oss:20b is somewhat usuable for most scenarios(except vibe coding, it's okay for some simple sample code that you have to transform by hand into your data structure) even without RAG.           \n\n  \nMaybe if you use something on the bleeding edge like Claude Opus 4.5/Claude Sonnet 4.5 with a pro/max subscription or a lot of cash spent on API calls you can get anywhere at all with those tools.",
          "score": -2,
          "created_utc": "2026-01-30 11:05:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qqfci4",
      "title": "support",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqfci4/support/",
      "author": "Cleaner76",
      "created_utc": "2026-01-29 17:41:01",
      "score": 12,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hi, I am a big fan of Mistral, but one thing really disturbs me: trying to reach support.\n\nI used the \"contact-us\"-option via Le Chat ( widget on the lower right ), sent a message, chose \"AI Studio - API\", and here are multiple options. The only way I found to write a message is by selecting \"share feedback\". Only after dropping \"feedback\", I get the option to send a message to Le Support. I did, but nothing indicates that somebody will have a look at my issue. Does anybody know a better way ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqfci4/support/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2nawfp",
          "author": "Cleaner76",
          "text": "Just an update: today I received some reactions from Mistral support. So apart from the non-intuitive support-chat-options, support is alive and kicking.",
          "score": 3,
          "created_utc": "2026-01-30 18:17:31",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o34blrw",
          "author": "Sorry_Role_1701",
          "text": "I had a similar experience.\n\nThe product itself is solid, but the support/contact flow isnâ€™t very clear at first.\n\nIn my case, the most reliable way was using the official contact form on the website or replying directly to billing-related emails.\n\nSupport does reply, but it can take some time.\n\nClearer documentation on how to reach support would definitely improve the overall experience.",
          "score": 3,
          "created_utc": "2026-02-02 07:39:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtpcw5",
      "title": "The Mistral Chat website UI is a disaster",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "author": "Eddybeans",
      "created_utc": "2026-02-02 08:17:07",
      "score": 11,
      "num_comments": 22,
      "upvote_ratio": 0.66,
      "text": "My experience with Le Chat is a disaster when it comes to the UI\n\nFrequent loss of what I asked for after pressing the send button  \nchat keeps scrolling up after asking a follow up question so I have to scroll down every time\n\nthis is my experience on safari\n\ntested on le chat pro and free over the last year\n\nwhy can't we have a working desktop APP that works like GPT ? instead I had to make a web app...\n\nso sad because I love Mistral ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o356fvu",
          "author": "Substantial-Yam3769",
          "text": "Agree, the UI needs a refresh.",
          "score": 3,
          "created_utc": "2026-02-02 12:19:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35qfnb",
          "author": "stjepano85",
          "text": "Firefox has issues. Works great for me in chrome based engines but firefox was awful",
          "score": 3,
          "created_utc": "2026-02-02 14:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34jsw4",
          "author": "Depressive-Marvin",
          "text": "Agree, especially Chat scrolling up drives me crazy. Itâ€˜ like they donâ€˜t user their own product else some developer would have fixed it. Itâ€˜s sad as the overall product is good.",
          "score": 4,
          "created_utc": "2026-02-02 08:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o350tz0",
          "author": "crazyserb89",
          "text": "iOS app isnâ€™t much better too. Some basic things donâ€™t work.",
          "score": 2,
          "created_utc": "2026-02-02 11:36:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o351y35",
          "author": "inyofayce",
          "text": "I dont know but both ios app and web works fine! Havent had any issues. Unlike some of you, I am looking forward for a macos app.",
          "score": 2,
          "created_utc": "2026-02-02 11:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35fmg2",
          "author": "ShiroCOTA",
          "text": "Same with Safari and Ecosia browser. Frequently my questions simply disappear after sending them, or I get an network error on a regular basis. And the chat randomly scrolling up after placing a prompt drives me crazy.",
          "score": 2,
          "created_utc": "2026-02-02 13:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34gb7o",
          "author": "Icy_Distribution_361",
          "text": "Yes I agree. I don't need a desktop app though I'm fine with browser page and actually prefer it, but these small things should be fixed more swiftly. It's not so hard to not make the page scroll up every damn time.",
          "score": 4,
          "created_utc": "2026-02-02 08:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34md2y",
          "author": "cosimoiaia",
          "text": "It's your browser.",
          "score": 2,
          "created_utc": "2026-02-02 09:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34rne0",
          "author": "Jazzlike-Spare3425",
          "text": "I am also not fond of the mobile app as someone who uses an iPad with Magic Keyboard. It doesn't have a sidebar and it doesn't support keyboard shortcuts. I ended up basically just using the Mistral API to try and build my own Le Chat that I can use across my phone, tablet and laptop with a system-native UI with all the convenience features I missed in the Le Chat ecosystem.",
          "score": 1,
          "created_utc": "2026-02-02 10:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35ldje",
          "author": "JuiceOwn313",
          "text": "Iâ€™ve been using it daily for over a year, and never had any issues whatsoever",
          "score": 1,
          "created_utc": "2026-02-02 13:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35xfd3",
          "author": "schacks",
          "text": "I agree, it's not optimal. I use an app called MindMac to interface with various LLM's and it works fine with LeChat.",
          "score": 1,
          "created_utc": "2026-02-02 14:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o363ehy",
          "author": "deadfantasy",
          "text": "Le Chat's UI on the web works great for me on firefox but the mobile app on Android is ... a *choice*, to say the least.",
          "score": 1,
          "created_utc": "2026-02-02 15:27:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36dfal",
          "author": "silurosound",
          "text": "Wait till you see the Mistral AI Studio page... it has a background animation that's pretty cool but really slows things down.",
          "score": 1,
          "created_utc": "2026-02-02 16:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bc081",
          "author": "ExtentHot9139",
          "text": "What is sad is that you use Safari",
          "score": 0,
          "created_utc": "2026-02-03 09:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3beddh",
              "author": "Eddybeans",
              "text": "What is sad is trolls like you. Enjoy your sad life",
              "score": 1,
              "created_utc": "2026-02-03 09:49:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3bfzc0",
                  "author": "ExtentHot9139",
                  "text": "Safari is the troll and you still use it",
                  "score": 0,
                  "created_utc": "2026-02-03 10:05:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34gaod",
          "author": "nycigo",
          "text": "Chatting on the web is something else lmao ðŸ¤£",
          "score": 0,
          "created_utc": "2026-02-02 08:23:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpdt8v",
      "title": "Help understanding the product lineup",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qpdt8v/help_understanding_the_product_lineup/",
      "author": "jfmmfj",
      "created_utc": "2026-01-28 15:06:04",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.86,
      "text": "Hello, I am going to explain how I see the current available tools to try to generate a discussion with the goal of understanding the use of each of the tools or if I am looking for something that's not realistic or not yet ready.\n\nI am learning to use Mistral's technologies to develop various agents to implement in my company. I understand there are mainly 4 products: Le Chat, AI Studio, API and now Mistral Vibe (cool v2 just released), besides all the enterprise coding thing, compute... they have a lot of stuff and what seems to be a solid business model, not like their competition playing at valuations. Well.\n\nIn Le Chat we get a chat interface to interact with the models. There you can create Agents that use the default model which I assume is Mistral Medium, we can set Instructions, Guardrails, Tone and Knowledge. Under knowledge, tools and connectors can be chosen, as well as Libraries o documents inside those libraries. Those Libraries are created under Intelligence > Libraries, where you see all the libraries being created in both possible origins: the uploaded files in Projects or in the Libraries section. \n\nWhy aren't the Libraries created in the Projects section available in the New Chat + (plus or context button) section? Libraries created in Projects don't seem to be available there. Also when accessing what I just called the New Chat interface in the Projects section, that Library seems to not be used anyways. \n\nBack to the Agent creation, AI Studio offers an Agent Builder where we can choose the model, set configuration (temp, max\\_t, top\\_p), choose which Tools will be available, Response Format and Instructions. Here, Knowledge (context) can't be added as it is in Le Chat. I understand that Libraries can be created in Le Chat or using the API and then passed as a function for the Agent created in AI Studio to use. I see that all this can be done using the APIs available.\n\nI understand that Agents created in AI Studio can be Deployed in Le Chat and there a Library created in the Libraries section can be manually added. But that feels very awkward.\n\nReading my self back, this is a mess, but I reflects my current state of not knowing what to do where, with the only goal of using their tools in the most comfortable way possible.\n\nCan anyone share their workflow so I can have it as reference?\n\nIs it just me not understanding their set of tools? (Very probable) or maybe this will be ordered in some way in the future.\n\nHope this turns out to be productive and thanks to anyone that takes the time to comment.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qpdt8v/help_understanding_the_product_lineup/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o297ki4",
          "author": "HGbradshaw3811",
          "text": "Thank you for writing this and I comment your honesty.\n\nI am researching the various tools and usabilities of Mistral for my company. At this moment I do not have clear answers for you, but I hope this conversation will continue as a resource for understanding the product lineup.",
          "score": 2,
          "created_utc": "2026-01-28 17:57:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o29wb4c",
              "author": "jfmmfj",
              "text": "Thank you. I am sure we will get some valuable info.",
              "score": 1,
              "created_utc": "2026-01-28 19:45:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtni81",
      "title": "Is instruct variant of Ministral 3 14B available in completion API?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtni81/is_instruct_variant_of_ministral_3_14b_available/",
      "author": "agentgoose007",
      "created_utc": "2026-02-02 06:28:55",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "Hey folks!\n\nIn the official docs I could find only these labels: ministral-14b-2512 and ministral-14b-latest\n\nhttps://docs.mistral.ai/models/ministral-3-14b-25-12\n\nThe weights tab lists three options:\nbase, reasononig and instruct.\n\nSo which one do I get when I call a completion API https://api.mistral.ai/v1/chat/completions and pass ministral-14b-2512?\n\nIs it possible to explicitly specify that I choose instruct variant?\n\nI know that the weights are open and I can self-host it in a cloud. But I'd prefer to pay to Mistral directly omitting the providers.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtni81/is_instruct_variant_of_ministral_3_14b_available/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o346mfd",
          "author": "LeRouxGongle",
          "text": "As of now, when you call the Mistral API with â€˜ministral-14b-2512Â´ or Â´ministral-14b-latestâ€™, you are using the base pre-trained model, exposed through the chat/completions API (i.e. wrapped with a chat template).\n\nThe API does not currently allow you to explicitly select the instruct variant (or other variants like reasoning) via the model label.\nThe instruct variant is available as open weights, so if you specifically need that checkpoint, self-hosting (or using a third-party provider that exposes it) is required for now.\n\nMistral's official hosted API currently exposes a single managed version of Ministral 14B rather than separate base / instruct / reasoning endpoints.",
          "score": 1,
          "created_utc": "2026-02-02 06:54:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o348ojy",
              "author": "agentgoose007",
              "text": "Got it. Thanks for reply",
              "score": 2,
              "created_utc": "2026-02-02 07:12:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qq1vwp",
      "title": "Devstral settings",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qq1vwp/devstral_settings/",
      "author": "allulcz",
      "created_utc": "2026-01-29 07:18:35",
      "score": 8,
      "num_comments": 10,
      "upvote_ratio": 0.9,
      "text": "Have you tried to tinker with the vibe.toml to achieve better results? I am using Claude Opus as my main AI to code with and I realize there is nothing better yet. Anyway I somewhat like Mistral being European and I want to give it chance, I did try to use to extend a functionality of an open source app and I was not very happy with the results (yet). Basically used old syntax, it was not working and also even left a typo (which I never seen before for AI). I am just thinking, but for Copilot there used to be Beast Mode, is there anything battle tested for Devstral? Also maybe some changes like temperature would also work?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qq1vwp/devstral_settings/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2ec8hs",
          "author": "Charming_Support726",
          "text": "I am currently using Opus and Codex as main models for coding. Nothing gets close in understanding and processing of human tasks.\n\nI've tested Devstral as I also written a few times and it is good, but it processes tasks on a far lower level. Smaller tasks, detailed instructions and then it is usable - but it ain't fun, if you're used to talking to Opus. Opus \\*discovers\\* tasks. Devstral \\*executes\\* tasks",
          "score": 2,
          "created_utc": "2026-01-29 12:16:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2h8x88",
              "author": "Neither-Bit4321",
              "text": "I have found this too. Opus has a way better understanding of non-coding tasks that seem to allow it to pick up nuances in coding tasks better.\n\nDevstral lacks that human nuance. Its almost like Mistral needs to include more non-coding task data in training to make it better at picking up the nuance.",
              "score": 1,
              "created_utc": "2026-01-29 20:44:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2s0ev9",
                  "author": "One-Macaron6752",
                  "text": "Maybe one should improve the specifications generating skills and reduce self reliance on a machine to read mind, if there is smth to be read... [/dark_humor]",
                  "score": 1,
                  "created_utc": "2026-01-31 12:14:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2dgo1y",
          "author": "thedisturbedflask",
          "text": "I havent checked out whats in vibe.toml but will have a look and try some changes, for me the main thing im unsure how to do is to define a set of workspace rules or instructions so that it can be consistent, found this makes one of the biggest differences with other models.",
          "score": 1,
          "created_utc": "2026-01-29 07:43:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2e98gj",
              "author": "AdIllustrious436",
              "text": "Vibe support the AGENT.md convention for codebase rules I think.",
              "score": 2,
              "created_utc": "2026-01-29 11:55:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2kgux2",
                  "author": "thedisturbedflask",
                  "text": "I had asked Mistral Vibe to create its instruction file but its response was it can but won't use it specifically so I was not sure. I'll test out the agent.md convention",
                  "score": 1,
                  "created_utc": "2026-01-30 08:13:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2dhkeq",
          "author": "MttGhn",
          "text": "If you're used to Opus, you won't appreciate changing models because it's far more expensive and performs better.",
          "score": 1,
          "created_utc": "2026-01-29 07:51:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2dhvgq",
          "author": "EzioO14",
          "text": "I am in the same situation as you, I think we have to wait a bit for devstral to be used more so mistral can improve and maybe later propose a model capable competing with opus",
          "score": 1,
          "created_utc": "2026-01-29 07:54:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qpdybg",
      "title": "How to get in touch with the Enterprise Sales team?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qpdybg/how_to_get_in_touch_with_the_enterprise_sales_team/",
      "author": "chob18",
      "created_utc": "2026-01-28 15:11:15",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.89,
      "text": "Hello,\n\n\nDoes anyone know the most effective way to contact Mistral for an Enterprise inquiry?\n\nI've filled out the contact form multiple times regarding a potential contract, but it's been radio silence. We are eager to start building with Mistral, but the lack of response is becoming a blocker.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qpdybg/how_to_get_in_touch_with_the_enterprise_sales_team/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o28akkc",
          "author": "nycigo",
          "text": "Four-fifths of Mistral's revenue comes from their offering: coding custom AI for large companies. I don't know how to contact them, but I imagine it should be easy to find them.",
          "score": 2,
          "created_utc": "2026-01-28 15:34:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o28bjcg",
              "author": "chob18",
              "text": "Iâ€™m ready to be enlightened.",
              "score": 2,
              "created_utc": "2026-01-28 15:39:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o28d0ve",
          "author": "LowIllustrator2501",
          "text": "try asking  \nu/sophia-yang-mistral\n\nu/benjamin-at-mistral  \nu/matthieu_mistral  \nu/tlax\\_at\\_mistral  \nu/benjamin-at-mistral  \nu/l-mistral\n\nmaybe they can help as I assume they work for Mistral.",
          "score": 2,
          "created_utc": "2026-01-28 15:45:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}