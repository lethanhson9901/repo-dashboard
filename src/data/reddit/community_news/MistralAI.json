{
  "metadata": {
    "last_updated": "2026-03-02 02:56:22",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 147,
    "file_size_bytes": 171605
  },
  "items": [
    {
      "id": "1rhshj7",
      "title": "Last night showed me why Europe needs sovereign AI more than ever",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rhshj7/last_night_showed_me_why_europe_needs_sovereign/",
      "author": "Nefhis",
      "created_utc": "2026-03-01 08:54:41",
      "score": 414,
      "num_comments": 33,
      "upvote_ratio": 0.97,
      "text": "Due to my work, I'm currently in Dubai. \n\nYesterday, starting around 3:00 PM, missile and drone attacks began. Most were intercepted, but several caused damage and injuries from falling debris and burning fragments. I'm here with my pregnant wife, and with the airspace closed, we don't yet know when weâ€™ll be able to leave.\n\nI mention this for context. Spending the night listening to explosions does something to your thinking. It sharpens certain concerns, I suppose.\n\nAt the same time all this was happening, I learned that OpenAI had formalized the integration of its models into the so-called â€œDepartment of War,â€ and later I saw the statement from Sam Altman in the screenshot. The combination wasâ€¦ clarifying.\n\nIn situations like the one I'm living, you start to see very clearly who controls the infrastructure you depend on, who they answer to, and who they donâ€™t. And I personally cannot continue funding a company that openly accepts surveillance of foreign users and deep military integration.\n\nThis is my conclusion: we need genuinely independent, democratic, and sovereign AI. Europe needs it. The world needs it. And right now, Mistral is the only major player aiming in that direction in the field of European AI.\n\nhttps://preview.redd.it/5dw97xexdemg1.jpg?width=601&format=pjpg&auto=webp&s=0d00768e0c2d6dd3c0ee79ea0e3d8330bda38ab7\n\nThatâ€™s all I wanted to say.\n\nhttps://preview.redd.it/wxpiop1bdemg1.jpg?width=1320&format=pjpg&auto=webp&s=844095a1c093193289134caa0df117a6c23c4358\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rhshj7/last_night_showed_me_why_europe_needs_sovereign/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o80wpu7",
          "author": "tormentnexus",
          "text": "Exactly, I think we're entering a period of time where we simply can't function as a society on this planet if we allow companies with their own agendas to have exclusive control over such critical pieces of our digital infrastructure. Putting all your eggs in one basket is rarely a good thing, why do we accept it for our tech?",
          "score": 62,
          "created_utc": "2026-03-01 08:58:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80ycsj",
          "author": "Jpahoda",
          "text": "I agree with your analysis. \n\nFor my work I advise European technology leadership in private and public sector. For more than a year I have urged them to accelerate their digital sovereignty programs. \n\nEven the sovereign cloud offerings from the American cloud providers are anything but. I will give you one practical example:\n\nMicrosoft in the recent days touted how their European sovereign cloud has independent control plane. But this is just marketing. All it would take for White House to apply leverage is to define zero day patches on national security export block list, and all of the non-US regions would be vulnerable. \n\nThis is just one example. \n\nIn practice, without continuous service and operations from the US, European cloud regions can continue operating roughly 72 hours until service degradation starts to become obvious. \n\nThe AI is an increasingly complex topic as well. Just try to discuss Californian election results with American LLM and you can see what I mean. \n\nAnd all of the above are increasingly pressured to hand over user information to the alarmingly extrajudicial American federal agencies operating under administrative order, instead of rule of law. \n\nWe are in peril. And most of us donâ€™t understand it.",
          "score": 42,
          "created_utc": "2026-03-01 09:13:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o8173gn",
          "author": "francechambord",
          "text": "I am using Le Chat.",
          "score": 17,
          "created_utc": "2026-03-01 10:38:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81b6aj",
          "author": "EarAlternative6806",
          "text": "I fully agree. This is one of the main reasons I started my company. I wanted to make European LLMs actually usable, not just something that looks good on paper.\n\nRight now, working with European models often means extra steps compared to U.S. providers. That can make things a bit more expensive and a bit more complex, but in my experience the difference is still somewhat manageable.\n\nThe bigger challenge is keeping up. Models like Mistral are not improving fast enough, theyâ€™re still behind the U.S. and Chinese alternatives. Weâ€™ve  been able to some extent close part of that gap in our own service, but itâ€™s important that the gap doesnâ€™t keep growing. If it does, weâ€™ll eventually have to look at other options",
          "score": 10,
          "created_utc": "2026-03-01 11:16:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82muts",
              "author": "94YPe",
              "text": "Can you explain what causes this gap?",
              "score": 2,
              "created_utc": "2026-03-01 16:16:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o832nq0",
                  "author": "EarAlternative6806",
                  "text": "On our platform we deal with documents, so I cannot say anything about the online search or knowledge baseline or whatsoever. But to answer your question: \n\nWith Mistral, you often have to spell things out. U.S. models are better at picking up whatâ€™s implied; the nuance, the assumptions, even a bit of sarcasm. Mistral usually doesnâ€™t catch that unless you help it. \n\nI like to compare it to talking to a 12-year-old versus a 35-year-old. Same words, different level of understanding of whatâ€™s between the lines.\n\nWe work around this by adding structure and context, and that works pretty well. But understanding implicit meaning for a longer period of time (large context window) really matters with documents, and if that gap gets bigger, itâ€™s hard to fully solve with engineering alone.",
                  "score": 2,
                  "created_utc": "2026-03-01 17:32:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o80wzm8",
          "author": "schacks",
          "text": "He's a moral coward! ",
          "score": 18,
          "created_utc": "2026-03-01 09:00:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80zi7z",
              "author": "JLeonsarmiento",
              "text": "The (little)man who sold the world.",
              "score": 10,
              "created_utc": "2026-03-01 09:25:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o811x3j",
          "author": "AntipodaOscura",
          "text": "Mucho Ã¡nimo para ti y tu familia ðŸ¥º Espero que estÃ©is bien, a pesar de las circunstancias.",
          "score": 7,
          "created_utc": "2026-03-01 09:48:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o8123c4",
              "author": "Nefhis",
              "text": "Muchas gracias, de verdad. Estamos bien, dentro de lo que cabe ðŸ™ðŸ¼",
              "score": 7,
              "created_utc": "2026-03-01 09:49:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o812eh8",
                  "author": "AntipodaOscura",
                  "text": "Menos mal! OjalÃ¡ podÃ¡is volver a casa pronto ðŸ’™",
                  "score": 5,
                  "created_utc": "2026-03-01 09:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o81r3zx",
          "author": "No_Lemon_666",
          "text": "Anthropic should move to EU.",
          "score": 11,
          "created_utc": "2026-03-01 13:23:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o811fd1",
          "author": "p2s_79",
          "text": "Why not forcing tech firms to hold the infraestructure necessary to operate in europe on our ground, working with relative independence from the us?",
          "score": 5,
          "created_utc": "2026-03-01 09:43:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o817a13",
          "author": "JoodRoot",
          "text": "Itâ€™s kinda sad, how Europe only got Mistral. Not saying Mistral is bad but we are so late to catch up with openai, Anthropicâ€¦",
          "score": 6,
          "created_utc": "2026-03-01 10:39:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o818df9",
              "author": "whoisyurii",
              "text": "better late than never, mate",
              "score": 9,
              "created_utc": "2026-03-01 10:50:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o82uedw",
              "author": "Over-Reason-9574",
              "text": "Le chat is actually bad but we hope a comeback",
              "score": 1,
              "created_utc": "2026-03-01 16:52:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o81gs9y",
          "author": "Specialist-Yard3699",
          "text": "Partially agree. However:\n1. Europe does not need a â€œEuropean, democratic AIâ€ as much as it needs its own infrastructure to run any open-source models.\n2. Europe will need to use AI for military purposes, just like the USA - this is the future. Europe must accelerate this integration as quickly as possible.\n3. To prevent drones from flying into Dubai, the regime in Iran should have been eliminated long ago - before the full-scale war in Ukraine began.",
          "score": 5,
          "created_utc": "2026-03-01 12:06:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81n6yt",
          "author": "MimosaTen",
          "text": "When Mistral, or any other company, will publish an instrument like Claude Code, bounded to the subscription I will switch",
          "score": 2,
          "created_utc": "2026-03-01 12:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81qxps",
              "author": "Ok_Conversation9319",
              "text": "You can use mistral vibe with Zed editor, its similar. But their best model Devstral 2, which is not nearly as strong as like Opus 4.6, but im using it anyways because its fast and cheap. (most of the time Devstral 2 makes the correct changes, but sometimes it makes a small errors, its not too bad)",
              "score": 1,
              "created_utc": "2026-03-01 13:22:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o83lhjb",
          "author": "ons3768",
          "text": "ðŸ‘ðŸ‘ðŸ‘ðŸ‘",
          "score": 2,
          "created_utc": "2026-03-01 18:59:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o851w61",
          "author": "Armadilla-Brufolosa",
          "text": "The problem is that Europe is too subservient to America, even in the AI sector: in fact, Microsoft seems to already be inside Mistral.\n\nI agree with you that companies like OpenAI should be abandoned, but it's not just them... practically all American companies in the sector, except Anthropic, have bowed down to the war industry that enriches them.\n\nHaving truly open AI, such as Apertus, is essential for us... but we need regulations that are much better than the current AI Act: we need to maintain absolute focus on data and privacy... but without becoming paranoid and creating bureaucratic red tape that prevents the formation of other truly valid European Artificial Intelligence companies.\n\nWe need greater momentum in the sector from a completely different perspective than that currently pursued by America and China.",
          "score": 2,
          "created_utc": "2026-03-01 23:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81dpdf",
          "author": "makemeatoast",
          "text": "It doesn't have to be \"democratic\" AI. It simply needs to be SOTA, basically as good as its american or chinese rivals. AI is simply a technology that make decision making more efficient. Europe can't possibly compete with the rest of the world (militarily or otherwise) if it doesn't have access to the core technology.",
          "score": 2,
          "created_utc": "2026-03-01 11:39:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81rzvm",
          "author": "RockStarDrummer",
          "text": "*Both* **Open A-LIE** and **SCAM** Altman suck. That's all that needs be said although I can think of plenty more.",
          "score": 2,
          "created_utc": "2026-03-01 13:29:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o831l5f",
          "author": "FragDenWayne",
          "text": "Meanwhile Mistral registration fails in Firefox\nhttps://www.reddit.com/r/MistralAI/s/JaWwGteASg",
          "score": 1,
          "created_utc": "2026-03-01 17:26:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o8268sc",
          "author": "paranoidzone",
          "text": "Unfortunately none of this will happen unless a significant amount of money, and I mean, truly significant, is poured in. Europe needs to bring in talent from abroad (China, Russia, Latin America) and also retake European talent that went to work in American big tech for big moneys. \n\nRight now, there is no point for e.g. a senior AI engineer with a PhD to want to work at a European company making maybe 150k EUR/year where 50% of that goes to taxes if they can go work for America and get 1M+ USD/year.\n\nI hope you and your family stay safe in Dubai and wish that you can come back soon.",
          "score": 1,
          "created_utc": "2026-03-01 14:53:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o827yfx",
              "author": "Nefhis",
              "text": "Thank you ðŸ™. There have only been two explosions in the last 5 hours. Perhaps the situation is calming down.",
              "score": 2,
              "created_utc": "2026-03-01 15:02:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o81gnzh",
          "author": "Rideshare-Not-An-Ant",
          "text": "I'd just say don't be evil.\n\nWhat? \n\nGoogle?!\n\nNevermind.",
          "score": 1,
          "created_utc": "2026-03-01 12:05:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81amzc",
          "author": "victorc25",
          "text": "Europe doesnâ€™t even have sovereign manufacture anymore. Soon with the Mercosur deal, what remains of the sovereign agriculture will be destroyed as well, replaced by more toxic solar panels in the Iberian peninsula. Energy production is on the floor and barely hanging, as more nuclear plants are closed. AI is the least of the issues for Europe if it canâ€™t even provide for basic needsÂ ",
          "score": -5,
          "created_utc": "2026-03-01 11:11:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81inwk",
              "author": "amunozo1",
              "text": "\"Toxic solar panels\" take less space than golf courts, and a ridiculous percentage of all land. Also, irrigation agriculture is what's driving Spain drier. What a silly think you say, to be honest. Stop with this self bashing.",
              "score": 3,
              "created_utc": "2026-03-01 12:22:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o81w8um",
                  "author": "victorc25",
                  "text": "https://www.forbes.com/sites/michaelshellenberger/2018/05/23/if-solar-panels-are-so-clean-why-do-they-produce-so-much-toxic-waste/",
                  "score": 1,
                  "created_utc": "2026-03-01 13:55:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rf8asl",
      "title": "Mistral AI Lands Accenture as Latest Big Client",
      "subreddit": "MistralAI",
      "url": "https://www.wsj.com/tech/ai/mistral-ai-lands-accenture-as-latest-big-client-7c5a0ca4",
      "author": "BuildwithVignesh",
      "created_utc": "2026-02-26 12:00:13",
      "score": 210,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf8asl/mistral_ai_lands_accenture_as_latest_big_client/",
      "domain": "wsj.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7ikx90",
          "author": "Mystical_Whoosing",
          "text": "Very cool, congratulations!",
          "score": 19,
          "created_utc": "2026-02-26 14:05:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ir50w",
          "author": "LowIllustrator2501",
          "text": "* [Accenture Struck a Deal With OpenAi. The Stock Is Still Sliding Despite New OpenAI Deal.](https://www.barrons.com/articles/accenture-stock-price-openai-deal-32404cab)\n* [Anthropic and Accenture Strike AI Deal Targeting Business Clients](https://www.wsj.com/articles/anthropic-and-accenture-strike-ai-deal-targeting-business-clients-0a82f28a)\n\nAccenture has deals with everyone. ",
          "score": 17,
          "created_utc": "2026-02-26 14:38:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7jqgu1",
              "author": "4baobao",
              "text": "Mistral doesn't, so good for them",
              "score": 14,
              "created_utc": "2026-02-26 17:23:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7pdyy7",
          "author": "tom_mathews",
          "text": "The enterprise play makes sense for Mistral because their models actually deploy well on-prem, which is what these consulting firms need when their clients have data residency requirements. I've run Mistral Large and the older Medium behind corporate firewalls and the inference cost per token is genuinely competitive once you factor in not paying the OpenAI tax on every API call at scale.\n\nThe real question is whether Accenture's army of consultants can actually fine-tune and deploy these models competently or if they'll just wrap the API in a chatbot and call it \"AI transformation.\" Based on what I've seen from Big Four/Five consulting engagements, it's usually the latter until the client pushes back.\n\nMistral's advantage here is the EU angle. Half of Accenture's enterprise clients in Europe won't touch US-hosted inference for regulated workloads. That alone justifies the deal regardless of benchmark numbers.",
          "score": 4,
          "created_utc": "2026-02-27 14:22:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7lczcn",
          "author": "LoadZealousideal7778",
          "text": "The funny thing is, Mistral is probably one of the most secure pure AI labs. Not because they are likely to achieve profitability any time soon but simply because the cost/benefit of bailing then out is so low. Any one of their bigger clients have the cash on hand to bail them out. Or just ask the EU nicely to bankroll them. IRISÂ² cost 10B to have a strategic alternative to Starlink. Airbus exists because Europe bankrolled a competitior to Boeing into existence. Throw some pocket change at them to keep the head over and everyone is happy.",
          "score": 5,
          "created_utc": "2026-02-26 21:59:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o3ote",
              "author": "AnaphoricReference",
              "text": "I agree. I try out a lot of different models in workflows, but for confidential workflows and core architecture components like embedding, voice, and routing I exclusively use Mistral models, because they feel like a future-proof and secure choice.",
              "score": 2,
              "created_utc": "2026-02-27 08:32:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7klv85",
          "author": "guyfromwhitechicks",
          "text": "Yipee",
          "score": 1,
          "created_utc": "2026-02-26 19:49:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfq60l",
      "title": "Mistral Vibe charged me $280, check your account.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "author": "ButtholeCleaningRug",
      "created_utc": "2026-02-26 23:29:10",
      "score": 136,
      "num_comments": 45,
      "upvote_ratio": 0.95,
      "text": "II figured Iâ€™d give Mistral Vibe a go this month instead of Claude Code. I checked their site to see if there were any indicators of how many tokens I could burn through before being shut off (like with Claude). At the time of signing up for Vibe, the site only mentioned â€œgenerous usage,â€ so I had no idea when Iâ€™d hit any kind of limit. I saw nothing else and went on my way. I used it for a couple of weeks on some projects I was working on and didnâ€™t love it or hate it. I was at dinner when I suddenly got an invoice for $280. I logged into the site and there is now a monthly usage tracker with â€œPay as you goâ€ set by default and, as far as I can tell, no way to turn it off. Safe to say I will not be using Mistral Vibe again. I guess this is more a PSA than anything, so check your Vibe usage.\n\nEdit: Because I should have mentioned it. Current Le Chat Pro subscriber.  \nEdit2: Even more wild I had thought something like this could happen, so I even capped my API usage at $20. I submitted a ticket with Mistral, will update.\n\n  \nUpdate 1: Someone from the Mistral team reached out and I emailed with them. I was told, â€œwe have updated clearer usage monitoring in your Vibe page, and we will refund everyone impacted this month while this tracking was not in place.â€ I genuinely appreciate how quickly they resolved this, and I will update again when I see the chargeback hit my card.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7oeibe",
          "author": "pandora_s_reddit",
          "text": "Hi everyone, thank you for the quick report! As mentioned, the team is working on fixing the issue and refunding affected individuals.\n\n\nWe will post further details in a follow-up later. Thanks again, and weâ€™re sorry for the inconvenience.\n\n\nIf you are not refunded the incomming days and you believe to have been affected, please reach out via support.\n\n\nEDIT: Follow up: https://www.reddit.com/r/MistralAI/comments/1rg8789/vibe_payg_refund/",
          "score": 38,
          "created_utc": "2026-02-27 10:15:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ooqw9",
              "author": "ButtholeCleaningRug",
              "text": "Thank you for responding so quickly. Iâ€™ve read enough stories on different subreddits of â€œCompany C charged me Y,â€ where the only recourse is talking to the companyâ€™s AI, which just gaslights and denies the claim. Filing a ticket on your site was really easy, and you were quick to follow up with a real human. Every company makes mistakes, and itâ€™s nice to see one handling it the right way. Sadly, these days it seems to be the exception rather than the rule.\n",
              "score": 15,
              "created_utc": "2026-02-27 11:43:46",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o82xo62",
              "author": "darwinanim8or",
              "text": "Wasnâ€™t affected but happy to see you guys so active and swift !",
              "score": 1,
              "created_utc": "2026-03-01 17:08:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7qthhq",
              "author": "teilifis_sean",
              "text": "Can you explain why I was charged for 12 months of premium when I was only given access to one month of premium? The support lady said once an early payment was missed there was an outstanding balance. So even though all the next 11 transactions went through Mistral didn't provide premium that entire time. That's not how these things work, you either cut the service if there is an outstanding balance and stop taking money or continue to provide it while taking money. You don't get to take money and not provide the premium service I was paying for citing a missed transaction a year before.\n\nI was simply naive trying to support a nascent EU tech scene but you guys simply ripped me off. I will never be giving you money again and now I give Claude 100 Euro a month now.\n\nI'm so infuriated with you guys. I can explain that behavior. Greed.",
              "score": 0,
              "created_utc": "2026-02-27 18:30:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7mji9q",
          "author": "LongjumpingTear5779",
          "text": "They tried to charge me 119 EUR. Thanks God I just have small amount of money in account with card (just move money to it when I am buing somethink).\nI put limit 10 EUR in Scale. In my language (Polish) when I read info about Le Chat Pro tere is only \"Access to Mistral Vibe\" - 0 info about extra payment for this.Â \nIn my account also today they show limit of usage - I used 94% but in Polish it's says \"The Scale plan resist after exceeding the limit.\"\nSo if I don't exceed why they charge me...\nAlso they should put somethink like this with information, this usage just show up today so when I bought Le Chat Pro and use there was no info about limits - and also for save i put 10 EUR limit.\n\n\nI send them ticket.Â ",
          "score": 22,
          "created_utc": "2026-02-27 01:50:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mkzw9",
              "author": "ButtholeCleaningRug",
              "text": "Hopefully this is just some weird bug and they are quick with refunds. I know Europe (EU) has more consumer protections so if itâ€™s not an error it seems like a pretty dumb play from a PR and legal standpoint.Â ",
              "score": 6,
              "created_utc": "2026-02-27 01:59:11",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7mplu2",
                  "author": "LongjumpingTear5779",
                  "text": "Idk how it work in France. In Poland they can put aÂ fine up to 10% of the company's annual turnover and compensation for affected parties.\nProbably it is implementation of EU laws so if they don't say sorry and refund this can hurt.\n\n\nSome telecomunication operators got fine because in marketing they say \"no limit Internet\" and there was little * - after x GB internet slow down to n Mbps.",
                  "score": 4,
                  "created_utc": "2026-02-27 02:25:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7o7l2h",
              "author": "ComeOnIWantUsername",
              "text": "Are you using Organization API key, or Vibe API key?",
              "score": 3,
              "created_utc": "2026-02-27 09:09:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7x879r",
                  "author": "LongjumpingTear5779",
                  "text": "I use both. But using Scale API shows up as ~6 EUR right now. Vibe API didn't show any info about limits before and right now it show 94% usageÂ ",
                  "score": 1,
                  "created_utc": "2026-02-28 18:45:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7luu5t",
          "author": "feral_user_",
          "text": "Did you already have a Le Chat subscription? I believe it's included with it?",
          "score": 7,
          "created_utc": "2026-02-26 23:31:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7luwcf",
              "author": "ButtholeCleaningRug",
              "text": "I did! ",
              "score": 3,
              "created_utc": "2026-02-26 23:31:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7lyrlo",
                  "author": "feral_user_",
                  "text": "Wow, that is worrisome then. Let us know when you find out what happened.",
                  "score": 8,
                  "created_utc": "2026-02-26 23:53:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7m4nz4",
          "author": "TapedOrigami",
          "text": "Thanks, I now also see the limit, and the pay as you go warning. Really untransparant to not notify us about this change. They keep saying, enough for all day long usage.",
          "score": 4,
          "created_utc": "2026-02-27 00:26:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7mk1s7",
              "author": "LongjumpingTear5779",
              "text": "In your language it's also say The Scale Plan after exceed the limit? (It's somethink like that in their Polish ui)",
              "score": 1,
              "created_utc": "2026-02-27 01:53:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7ni9s1",
                  "author": "ComeOnIWantUsername",
                  "text": "Where do you see this warning? I checked it myself and can't find anything like it",
                  "score": 1,
                  "created_utc": "2026-02-27 05:29:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7mz1ti",
          "author": "sampdoria_supporter",
          "text": "I've been using Codestral on  console.mistral.ai and it says at the top \"use codestral via your favorite code completion tool for free\" - I better screenshot it",
          "score": 5,
          "created_utc": "2026-02-27 03:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nf9wl",
              "author": "mobileJay77",
              "text": "This could mean \"bring your own LLM\"? You can set up vibe to use any.",
              "score": 0,
              "created_utc": "2026-02-27 05:07:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7m3zxw",
          "author": "_st4rlight_",
          "text": "Keep us posted, thanks! In Admin->usage does it state which APIs charged you this much? If you're only using Vibe you should be using Devstral, which is not even listed among the APIs that could charge you.\n\nMaybe an error on their part?",
          "score": 2,
          "created_utc": "2026-02-27 00:22:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m7squ",
              "author": "ButtholeCleaningRug",
              "text": "The only record with the charge breakdown is in the invoice they sent. I hunted all over their dashboard and the only API tracker they have is the one I set to max at $20/mo, and it currently reads $0 used.\n\n  \nEdit: It certainly could be an error, hopefully it is, but depending on your payment method and your financial health ,waiting for Mistral to refund you could be a really bad time.",
              "score": 2,
              "created_utc": "2026-02-27 00:43:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7o38bf",
          "author": "Developer_Bot",
          "text": "Could it be that you entered the wrong API key into your vibe set-up? I never even generated an API Plan key. Iam on pro too and dont have that issue. My API usage still shows 0. Daily User here.",
          "score": 2,
          "created_utc": "2026-02-27 08:27:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o46f5",
              "author": "Developer_Bot",
              "text": "https://www.reddit.com/r/MistralAI/s/x0eTeuaie6\nI got it from there.so i was prepared to use the correct key.",
              "score": 2,
              "created_utc": "2026-02-27 08:36:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7obo2a",
              "author": "ButtholeCleaningRug",
              "text": "No, I used the correct key. Vibe has its own key, and through their newly implemented (and never announced) tracker, it shows that I went over the limit and was switched to pay-as-you-go at some point. I have no idea when, as I never received any notification that pay-as-you-go had become the policy, nor that it couldnâ€™t be turned off. The only API tracker visible on the page was one Iâ€™d set to a $20 per month maximum, and it still shows $0 in usage. I understand that the tracker probably applies to other API keys, but when I first set up Vibe, it was the only area on the entire page that had any form of API tracker or a way to set a usage limit, and it still is. \n\nHere is the newly implemented Vibe tracker. It does not even show how many tokens I have used on pay-as-you-go. It feels like they decided to start charging people before they actually rolled out the most important features: a way to set limits, turn it off, and a way to see what you have spent.\n\nhttps://preview.redd.it/k8tswfvec0mg1.png?width=1142&format=png&auto=webp&s=06d0cd9b902c32219a102315ae3314ff5ad9179c\n\n",
              "score": 2,
              "created_utc": "2026-02-27 09:48:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7o7c26",
              "author": "ComeOnIWantUsername",
              "text": "Just out of curiosity, do you see any Vibe token usage on [https://console.mistral.ai/codestral/cli](https://console.mistral.ai/codestral/cli) ? Mine shows that it can't retrieve it. I use API key generated on this page, and not regular key (so as it should be)",
              "score": 1,
              "created_utc": "2026-02-27 09:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o9bpw",
                  "author": "Developer_Bot",
                  "text": "Yes (on firefox).it des not say 'vibe' though. Just token usage.",
                  "score": 1,
                  "created_utc": "2026-02-27 09:26:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nqvzz",
          "author": "andriatz",
          "text": "Like all API services, before using them, you need to go to the settings and set the maximum monthly spending limits. I set mine to 5 euros, and indeed, thatâ€™s the amount I was billed. After some fine-tuning and a lot of vibe",
          "score": 3,
          "created_utc": "2026-02-27 06:38:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7m4eyk",
          "author": "wirtshausZumHirschen",
          "text": "what you get charged more than your API cap of 20$?! Do they count Mistral Vibe usage differently or what?",
          "score": 1,
          "created_utc": "2026-02-27 00:24:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7m86be",
              "author": "ButtholeCleaningRug",
              "text": "Apparently they do, but there is no actual tracker anywhere on their site that i could find. Maybe they plan on rolling it out, but bad form to charge people before they can actually track what they spend. The only API tracker they do have, reads $0 for me. ",
              "score": 1,
              "created_utc": "2026-02-27 00:45:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nu6wv",
          "author": "Legitimate-Help8016",
          "text": "Where do I find that? In admin panel I can go under limits and disable spending..?",
          "score": 1,
          "created_utc": "2026-02-27 07:06:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7o27u8",
              "author": "TapedOrigami",
              "text": "You can find the usage info and the warning here: https://console.mistral.ai/codestral/cli",
              "score": 2,
              "created_utc": "2026-02-27 08:18:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o2nc3",
                  "author": "Legitimate-Help8016",
                  "text": "I see, thanks, I turned of the limit, will PAG still apply?",
                  "score": 1,
                  "created_utc": "2026-02-27 08:22:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7o6yzy",
          "author": "ComeOnIWantUsername",
          "text": "I can't even check my Vibe usage info lol\n\nI'll definitely stop using it until we'll know what is happening\n\n\n\nhttps://preview.redd.it/z29zi0ys50mg1.png?width=1244&format=png&auto=webp&s=7dd7b82b4c8ffb47b7316486ba4166b824f6f94d\n\n",
          "score": 1,
          "created_utc": "2026-02-27 09:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7s742c",
          "author": "umipaloomi",
          "text": "I just created an api key on la platforme and my usage is always at 0$ even though Iâ€™m using devstral 2 via opencode regularly",
          "score": 1,
          "created_utc": "2026-02-27 22:38:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7s7zcw",
              "author": "ButtholeCleaningRug",
              "text": "Different API key for Vibe. My non-Vibe API also says $0. If youâ€™re using the Vibe API you need to scroll to the bottom. They added a tracker that says how much usage you have left before you enter PAYG. Last I looked there is no way to set a limit or turn off PAYG so youâ€™re stuck watching that until they add some sort of feature to limit usage.Â ",
              "score": 1,
              "created_utc": "2026-02-27 22:43:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7s8fxe",
                  "author": "umipaloomi",
                  "text": "I see. Iâ€™m on the experiment planâ€¦ but i never had issues with limits etcâ€¦ not sure if what the limits here are. Also mistral Large 3 works like s charm.",
                  "score": 1,
                  "created_utc": "2026-02-27 22:45:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7nfdst",
          "author": "cutebluedragongirl",
          "text": "French engineering at its finest, I guess.",
          "score": -7,
          "created_utc": "2026-02-27 05:08:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nqbnz",
              "author": "porzione",
              "text": "oh no - openai, anthropic, google, Chinese companies - they all have these overcharge \"bugs\"",
              "score": 2,
              "created_utc": "2026-02-27 06:33:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7nlds2",
          "author": "Emotional-Cupcake432",
          "text": "You know you can use it with ollam for free localy",
          "score": -2,
          "created_utc": "2026-02-27 05:53:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7nnecd",
              "author": "Kypsys",
              "text": "*for free if you have a 2000$ mac, or a 5000$ GPU",
              "score": 5,
              "created_utc": "2026-02-27 06:09:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7o8ed9",
                  "author": "ComeOnIWantUsername",
                  "text": "and spend more on electricity for this machine than for API usage and/or subscription",
                  "score": 1,
                  "created_utc": "2026-02-27 09:17:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rgwm8e",
      "title": "New models versions coming soon - Devstral 2.1",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rgwm8e/new_models_versions_coming_soon_devstral_21/",
      "author": "gohm_dv",
      "created_utc": "2026-02-28 07:44:34",
      "score": 134,
      "num_comments": 29,
      "upvote_ratio": 0.99,
      "text": "https://preview.redd.it/zr29y4u3w6mg1.png?width=916&format=png&auto=webp&s=9e8891b24508a82ba0830bc13f9203a5a8c673e9\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rgwm8e/new_models_versions_coming_soon_devstral_21/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7uia9y",
          "author": "spaceman_",
          "text": "So no mention of new small models? And the small models are retiring? Is this the end of local Mistral for mere mortals?",
          "score": 10,
          "created_utc": "2026-02-28 08:05:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7uzecd",
              "author": "Chemistrycat214",
              "text": "I think they will remain as open weigh for local use, but they won''t work on them any further nor provide api access.",
              "score": 3,
              "created_utc": "2026-02-28 10:48:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ujmqx",
              "author": "LowIllustrator2501",
              "text": "That's the advantage  of local models - once it's release you can have it. If Mistral no longer hosts them - it doesn't affect users in any way. ",
              "score": 2,
              "created_utc": "2026-02-28 08:17:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7ukj06",
              "author": "gohm_dv",
              "text": "What small new models you refere to? I mostly use ministal models via their API. My app is using ministral-14b-2512. As you can see no mentioned it in this mail. So i guess they are no retiring.",
              "score": 1,
              "created_utc": "2026-02-28 08:25:35",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o7vq787",
              "author": "kiwibonga",
              "text": "They're telling people to switch from 2512 (Devstral Small 2 from December 2025) to the new devstral_small_latest, presumably Devstral Small 2.1",
              "score": 1,
              "created_utc": "2026-02-28 14:08:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7vr4dh",
                  "author": "spaceman_",
                  "text": "No, it's telling them to switch to the big devstral. Devstral-small-latest is mentioned but also EOL in May.",
                  "score": 1,
                  "created_utc": "2026-02-28 14:13:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7un4hb",
          "author": "Legitimate-Help8016",
          "text": "I hope it's better than 2.0 because it's really bad when comparing to sonnet 4.5.. I didn't even try to vibe code for now.",
          "score": 7,
          "created_utc": "2026-02-28 08:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wb7qq",
              "author": "Positive-Plan4877",
              "text": "Looking at the price it will have some reasoning so hopefully it will be much better",
              "score": 1,
              "created_utc": "2026-02-28 16:00:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7xh1d2",
              "author": "ComeOnIWantUsername",
              "text": "What is your stack? I use it with Python and sure, it's worse than Sonnet 4.6, but not that much and for 90-95% of the time I use it, and not Sonnet",
              "score": 1,
              "created_utc": "2026-02-28 19:30:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7ywe12",
          "author": "bootlickaaa",
          "text": "Just one thing that appears to suck about this until more details are provided: Devstral Small has vision input, but devstral-latest does not. Devstral Small is also a significantly faster on the API than Ministral 3 14b (the next small model with vision).\n\nSo until 2.1 comes out with vision, it's not actually possible to switch away from Devstral Small without slowing down my app.",
          "score": 3,
          "created_utc": "2026-03-01 00:13:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ujlx0",
          "author": "Careful-Lake-13",
          "text": "They recommend migrating to Devstral 2.1 for 'best performance,' but don't mention if the context window or logic is actually that much better to justify the $2 output price. For that cost, it better be coding my entire repo while I sleep.",
          "score": 2,
          "created_utc": "2026-02-28 08:17:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ukc1k",
              "author": "EzioO14",
              "text": "Claude doesnâ€™t do that more for much more money what are you expecting :â€™)",
              "score": 3,
              "created_utc": "2026-02-28 08:23:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7uk9zj",
          "author": "EzioO14",
          "text": "Canâ€™t wait to give it a try",
          "score": 2,
          "created_utc": "2026-02-28 08:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7uj56k",
          "author": "iBukkake",
          "text": "Question for Devstral users: when and where are you using these small models? From Mistral coding models, or anyone else?\n\nCaveat: I'm not a SWE, but I do use Claude Code with a Max plan. I am building tools that make extensive use of Mistral Large, OCR and Voxtral. So I love the business; I just don't understand the use cases for using Devstral when Claude Code, Codex etc exist.",
          "score": 2,
          "created_utc": "2026-02-28 08:12:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7umfpp",
              "author": "ComeOnIWantUsername",
              "text": "> I just don't understand the use cases for using Devstral when Claude Code, Codex etc exist.Â \n\n\nI don't understand using Tesla, when Ford exist.\n\n\nI don't understand using iPhone, when Samsung exist.\n\n\nI don't understand using Chrome when Firefox exist.\n\nIt's just alternative. Devstal 2 is a bit worse than CC or Codex, but still very good. It's not that big difference",
              "score": 10,
              "created_utc": "2026-02-28 08:43:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7v5jds",
                  "author": "Ndugutime",
                  "text": "It is also a matter of style and also personality.  There are now dozens, if not 100s of good models that have their own quirks.  I think the more competition, the better.   I believe like Yann LeCun that there isnâ€™t or should not be one AI product.  That all intelligence is collective.",
                  "score": 2,
                  "created_utc": "2026-02-28 11:43:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7unppz",
                  "author": "Timo425",
                  "text": "How is the difference for planning? Because thats the main strenght of claude for me.",
                  "score": 1,
                  "created_utc": "2026-02-28 08:54:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7uu27f",
                  "author": "iBukkake",
                  "text": "If that is a fair comparison, then sure, ok I obviously get that.\n\nBut my understanding is that the current SOTA models, especially since December '25, are leaps and bounds ahead. More akin to comparing a car to a bicycle. And in that scenario, I don't think bikes (Devstral) shouldn't exist, I just wonder what the bicycle use case is for daily users.",
                  "score": 1,
                  "created_utc": "2026-02-28 09:56:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7umiik",
              "author": "Particular-Way7271",
              "text": "For the same. I do have a preference for EU products (lately...;)) or open source and it works pretty well. There is mistral vibe cli which you can try out, it's the equivalent of claude code and it has generous free tier. You could also use the devstral models offline if you find them working well. They also have vision.",
              "score": 5,
              "created_utc": "2026-02-28 08:43:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7umxsl",
              "author": "BitterProfessional7p",
              "text": "Devstral 2 123B is actually very good, look at SWE rebench scores, one of the top non-thinking models. Not at the frontier but still very usable, the instruction following is better than some other frontier models.\n\nI use it in Cline.",
              "score": 3,
              "created_utc": "2026-02-28 08:47:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7wa34g",
              "author": "AnaphoricReference",
              "text": "When I want coding assistance for a small fraction of the cost? Which is most of the time. \n\nI will sometimes switch to Claude Opus if I get stuck, in the hope its larger knowledge base will help me with new hypotheses. But two out of three times it disappoints me. But for an order of magnitude more money (for instance 5/25 vs 0,40/2 on Openrouter, which has them both).\n\nSame thing with models in my own tools. They automatically fall back on a bigger model if they can't get things done. Different model sizes have different use cases. A good basic model is one that knows when it doesn't know, instead of hallucinating it way out. Which basically comes down to following instructions.",
              "score": 2,
              "created_utc": "2026-02-28 15:55:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7v2aen",
          "author": "OnesKsenO",
          "text": "What happens to Le Chat Pro Vibe api?",
          "score": 1,
          "created_utc": "2026-02-28 11:14:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80mf06",
              "author": "PitchPleasant338",
              "text": "Waiting for RAM.",
              "score": 1,
              "created_utc": "2026-03-01 07:21:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7v426n",
          "author": "One_Development8489",
          "text": "Cant mistral do what others, i mean learning from claude directly using api or to not waste so many tokens, just publish agent env where eu devs would dump input/output from claude/codex sessions?\n\nOr they do it already? (Or is it ILLEGAL in eu because this is noT oK)",
          "score": 1,
          "created_utc": "2026-02-28 11:30:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ylgvw",
              "author": "bootlickaaa",
              "text": "No. They are French.",
              "score": 2,
              "created_utc": "2026-02-28 23:08:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rh8hrz",
      "title": "Always wrong",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rh8hrz/always_wrong/",
      "author": "Bitter_Paramedic3988",
      "created_utc": "2026-02-28 17:29:14",
      "score": 112,
      "num_comments": 85,
      "upvote_ratio": 0.75,
      "text": "I moved to Le Chat to support EU companies, but wow le chat is very behind on the american AI LLMs. Constant wrong answers and inability to even look two messages in the past for reference. Not to mention not being able to open weblinks.  I hope improvements happen soon.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rh8hrz/always_wrong/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7wvlce",
          "author": "SiebenZwerg",
          "text": "In my experience mistral needs far more guiding than other LLMs but on the other side it follows prompts more strictly.",
          "score": 81,
          "created_utc": "2026-02-28 17:42:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wxps0",
              "author": "LegitimateHall4467",
              "text": "And, it provides answers with less slop.",
              "score": 51,
              "created_utc": "2026-02-28 17:53:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7y0xc3",
                  "author": "821835fc62e974a375e5",
                  "text": "So far I havenâ€™t been able to get actual answers.\n\nSome random hugging face model I run locally is faster and at least answersÂ ",
                  "score": -19,
                  "created_utc": "2026-02-28 21:16:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7wwvr0",
          "author": "ArtMysterious2582",
          "text": "For sure they are behind the American companies, but they can only get better by having more users rating answers giving feedback",
          "score": 36,
          "created_utc": "2026-02-28 17:49:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wuxza",
          "author": "nootnootpingu1",
          "text": "help it by rating the answers",
          "score": 56,
          "created_utc": "2026-02-28 17:39:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wx79n",
              "author": "Little_Protection434",
              "text": "Yes! [Help make it better by actively using the Thumbs Up/Down buttons](https://www.reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/)",
              "score": 34,
              "created_utc": "2026-02-28 17:51:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o84dk3n",
              "author": "_o0Zero0o_",
              "text": "\\^",
              "score": 1,
              "created_utc": "2026-03-01 21:22:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7xuflr",
          "author": "knujesbob",
          "text": "I find Mistral/Le Chat to be fairly accurate and it compares reasonably well to ChatGPT 4.x. I can live with it being 1 step behind the frontier models from OpenAI & Anthropic so long as they remain on European hands. I had some difficulty using Mistral API for home assistant tasks, so still use Claude for this purpose.",
          "score": 14,
          "created_utc": "2026-02-28 20:41:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81paqa",
              "author": "No_Aardvark1121",
              "text": "which model are you using? My Mistral AI don't even know \"Chained soldier\"",
              "score": 3,
              "created_utc": "2026-03-01 13:11:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o835r4x",
              "author": "TatsumakiChaos",
              "text": "Yeah what model? You ppl talk like theres only one and when I stared to download mine appeared multiple versions and stuffâ€¦",
              "score": 1,
              "created_utc": "2026-03-01 17:47:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7wv4w3",
          "author": "LowIllustrator2501",
          "text": "I don't know what kind of queries you're using, but that's not true for me. It does know about the content in the thread and can open web pages. Are you sure the issue is with Mistral?",
          "score": 52,
          "created_utc": "2026-02-28 17:40:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yawgu",
              "author": "Bitter_Paramedic3988",
              "text": "If I use it the same as any other LLM and it doesnâ€™t work, I would argue the issue is with the LLM and not the user",
              "score": -3,
              "created_utc": "2026-02-28 22:10:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7yd9up",
                  "author": "LowIllustrator2501",
                  "text": "I'm not using some magical prompts either.Â ",
                  "score": 5,
                  "created_utc": "2026-02-28 22:23:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7y4u8s",
          "author": "Broad_Stuff_943",
          "text": "I don't think they're particularly far behind. I regularly test Claude alongside Mistral, and Mistral provides the same level of answer as Claude at least 90% of the time. Often it provides more context for complex answers, too.\n\nI think you must be doing something weird, as it definitely remembers what you typed in previous messages...",
          "score": 9,
          "created_utc": "2026-02-28 21:37:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yan39",
              "author": "Bitter_Paramedic3988",
              "text": "I had to prompt it literally 5 times to refer back to a document I just sent it. Instead it made up information out of thin air then it referred to a conversation weeks ago.",
              "score": 2,
              "created_utc": "2026-02-28 22:08:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7xvabe",
          "author": "New_Philosopher_1908",
          "text": "I've not had this issue at all. Very satisfied",
          "score": 7,
          "created_utc": "2026-02-28 20:45:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wwvyr",
          "author": "Little_Protection434",
          "text": "[Help make it better by actively using the Thumbs Up/Down buttons](https://www.reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/)",
          "score": 12,
          "created_utc": "2026-02-28 17:49:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7xmoi7",
          "author": "tom_mathews",
          "text": "The context window handling is the real issue. Mistral Large can technically do 128k tokens but effective recall drops off hard past ~30k in my testing, especially for multi-turn conversation where earlier messages get effectively ignored during attention. That \"can't look two messages back\" problem is almost certainly this.\n\nThe web browsing gap is a product decision, not a model limitation. They could ship it tomorrow with a search API integration but seem to be prioritizing the API/enterprise side over consumer chat features.\n\nHonest take: Mistral Large 2 is genuinely competitive on structured tasks like code generation and function calling. Where it falls apart is open-ended reasoning and instruction following across long conversations. If you're using Le Chat as a general assistant replacement, yeah, it's going to feel worse. If you're hitting it through the API with well-scoped single-turn prompts, the gap narrows significantly.",
          "score": 5,
          "created_utc": "2026-02-28 19:59:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o83eiz4",
              "author": "LongjumpingTear5779",
              "text": "In documentation Mistral Large 3 have context window 256k.Â \nAre you talk about Mistral Large 2? Did you check third version?",
              "score": 1,
              "created_utc": "2026-03-01 18:27:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7wys7e",
          "author": "LegitimateHall4467",
          "text": "Give it another chance, learn how to prompt it because it needs a bit more guidance than other LLMs. On the other hand it produces very useful answers, a lot less sloppy replies than, e.g. MS Copilot.",
          "score": 11,
          "created_utc": "2026-02-28 17:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yb3ee",
              "author": "Bitter_Paramedic3988",
              "text": "I hate copilot, any tips online on how to prompt Lechat?",
              "score": 2,
              "created_utc": "2026-02-28 22:11:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o84o30j",
                  "author": "Doomsday_Holiday",
                  "text": "Well, I asked Lechat for you: \n\n  \nGetting the best answers from me (or any AI assistant) is all about clarity, context, and structure. Here are some practical tips to help youâ€”and your usersâ€”prompt effectively:\n\n1. Be Specific and Direct\n\nWhy: Vague questions lead to vague answers.\n\nHow:\n\nInstead of: \"Tell me about AI.\"\n\nTry: \"What are the main differences between generative AI and predictive AI, with examples?\"\n\n\n\n2. Provide Context\n\nWhy: More context = more relevant answers.\n\nHow:\n\nInstead of: \"How do I fix this code?\"\n\nTry: \"Hereâ€™s my Python code for a data analysis task. Itâ€™s giving me a KeyError when I run it on this dataset. Can you help me debug it? \\[Paste code/dataset\\].\"\n\n\n\n3. Break Down Complex Questions\n\nWhy: Multi-part questions can be overwhelming.\n\nHow:\n\nInstead of: \"Explain quantum computing and its impact on cybersecurity and also how it works.\"\n\nTry:\n\n\"What is quantum computing in simple terms?\"\n\n\"How could quantum computing affect cybersecurity?\"\n\n\"Can you explain how a quantum computer works?\"\n\n\n\n4. Specify the Format\n\nWhy: I can adapt my output to your needs.\n\nHow:\n\n\"List the top 5 AI trends in 2026 as bullet points.\"\n\n\"Explain blockchain to a 10-year-old in 3 sentences.\"\n\n\"Write a Python function to sort a list, and include comments for each step.\"\n\n\n\n5. Ask for Sources or Examples\n\nWhy: It helps verify information and makes answers more practical.\n\nHow:\n\n\"What are the best practices for remote team management? Include real-world examples from tech companies.\"\n\n\"Can you summarize the latest research on AI ethics and cite the sources?\"\n\n\n\n6. Use Step-by-Step Instructions\n\nWhy: Great for tutorials, troubleshooting, or learning.\n\nHow:\n\n\"Walk me through setting up a local development environment for a React app, step by step.\"\n\n\"How do I train a simple machine learning model using Python? Include code snippets.\"\n\n\n\n7. Iterate and Refine\n\nWhy: Sometimes the first answer isnâ€™t perfectâ€”refining helps.\n\nHow:\n\nFollow up with: \"Can you simplify that?\", \"What about \\[specific aspect\\]?\", or \"Give me more details on \\[topic\\].\"\n\n\n\n8. Use Natural Language\n\nWhy: Iâ€™m designed to understand conversational language.\n\nHow:\n\n\"Iâ€™m planning a trip to Berlin. What are some must-see places for history buffs?\"\n\n\"Iâ€™m stuck on this math problem. Can you guide me through it?\"\n\n\n\n9. Ask for Opinions or Recommendations\n\nWhy: I can provide tailored suggestions.\n\nHow:\n\n\"Whatâ€™s the best programming language for a beginner interested in web development?\"\n\n\"Recommend some productivity tools for remote teams.\"\n\n\n\n10. Experiment and Explore\n\nWhy: The more you interact, the better youâ€™ll understand how to get the best results.\n\nHow:\n\nTry different phrasings, ask for analogies, or request creative outputs like poems, stories, or even code.\n\n\n\nExample Prompts for Le Chat\n\n\"Act as a career coach. Iâ€™m a software engineer with 5 years of experience. What skills should I learn next to advance to a senior role?\"\n\n\"Summarize the plot of 'Dune' in 100 words or less, and explain its main themes.\"\n\n\"Help me brainstorm 10 blog post ideas about sustainable living.\"\n\n\n\nFinal Tip: If youâ€™re ever unsure how to phrase something, just ask me: \"How can I improve this prompt to get a better answer?\"\n\n\n\n\n\n  \n",
                  "score": 1,
                  "created_utc": "2026-03-01 22:17:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7wz05y",
          "author": "Duedeldueb",
          "text": "I do not share your experience in full but understand thatMistral is less capable than the American competitors. I think they are much more focused on B2B applications and Le Chat only is some kind of â€œwe are her, tooâ€ sign and is not their main focus not even their secondary one.",
          "score": 6,
          "created_utc": "2026-02-28 18:00:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x035j",
          "author": "cosimoiaia",
          "text": "That is not my experience at all. I find it only slightly behind other newer models. \n\nOf course it depends on the topic as some newer models have had more feedback and more RL.\n\nAs others have said, you can help by giving feedback in the chat.",
          "score": 6,
          "created_utc": "2026-02-28 18:05:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x1ahj",
          "author": "flabsoftheworld2016",
          "text": "In my last comparison 2 days ago - I got more complete work done by gemini in fewer queries BUT gemini actually made up some of the data, despite indicating the source for the data in the prompt. ",
          "score": 3,
          "created_utc": "2026-02-28 18:11:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7yb01u",
              "author": "Bitter_Paramedic3988",
              "text": "Le Chat invented laws that donâ€™t exist in my recent chats",
              "score": 1,
              "created_utc": "2026-02-28 22:10:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7x8pgi",
          "author": "Poudlardo",
          "text": "Can you give an exemple when it gave you a wrong answer, im interested",
          "score": 3,
          "created_utc": "2026-02-28 18:48:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7xoiwm",
              "author": "mmi777",
              "text": "I want to wash my car. My home is 50 metres from the carwash, which isn't that far. Should I take the car or shall I walk?",
              "score": 1,
              "created_utc": "2026-02-28 20:09:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7xp7l6",
                  "author": "Poudlardo",
                  "text": "xD this was a previous episode mate",
                  "score": 5,
                  "created_utc": "2026-02-28 20:13:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7ybfc8",
              "author": "Bitter_Paramedic3988",
              "text": "Currently using it for navigating a home purchase. Asked it to calculate my new upfront amount based on the banks previous loan offer on a cheaper property. It told me I had to give less money upfront for a property thatâ€™s 5000â‚¬ more expensiveâ€¦..",
              "score": 1,
              "created_utc": "2026-02-28 22:12:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7x1oke",
          "author": "Hitching-galaxy",
          "text": "Yup. Tried with mistral le chat paid and getting help with docker/next cloud, wasted a weekend. \n\nClaude, first try.",
          "score": 5,
          "created_utc": "2026-02-28 18:13:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7xrcmn",
              "author": "MerePotato",
              "text": "Le Chat excels at news, web search and translations, its not really meant for coding",
              "score": 3,
              "created_utc": "2026-02-28 20:24:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7y9pk5",
                  "author": "R4-M9",
                  "text": "Hmm, regarding PHP and SQL I cannot complain. It's mostly very good and since it knows my whole project, which I would never give a non european AI, it works with just some few sentences and can add and rework stuff quite well. Of course, checking and testing still has to be done by me, mistakes are made.",
                  "score": 1,
                  "created_utc": "2026-02-28 22:03:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7yawuh",
                  "author": "Hitching-galaxy",
                  "text": "It was hardly coding - it was setting up a docker which it kept on mucking up. It didnâ€™t hold memory properly - simple things like â€˜nano doesnâ€™t work on synology, use viâ€™ - and in the same conversation, it kept telling me to use nano.",
                  "score": 1,
                  "created_utc": "2026-02-28 22:10:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o7ybjzk",
                  "author": "Bitter_Paramedic3988",
                  "text": "Well Iâ€™m using it for web search and itâ€™s giving a lot of wrong answers",
                  "score": 1,
                  "created_utc": "2026-02-28 22:13:39",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7x3zz5",
          "author": "cucurucu007",
          "text": "Same here. After 2 years with others ,  LeChat feels behind , but still trying to support.",
          "score": 5,
          "created_utc": "2026-02-28 18:24:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x4bs1",
          "author": "Successful-Jelly-772",
          "text": "This isn't really the place to complain. The people that are here, are the ones that support it enough to sign up to the subreddit for it.",
          "score": 5,
          "created_utc": "2026-02-28 18:26:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7x84ll",
              "author": "egyptianmusk_",
              "text": "you must be new to Reddit, where everybody goes to the official sub to complain about the app that happy customers pay to use",
              "score": 7,
              "created_utc": "2026-02-28 18:45:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7xb6sl",
                  "author": "Successful-Jelly-772",
                  "text": "It isn't very good.  \nI would like to use it, but after a while, I have to drop it again.\n\nAlso, Elon Musk is a Nazi piece of shit.",
                  "score": -2,
                  "created_utc": "2026-02-28 19:00:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7xnypg",
          "author": "mmi777",
          "text": "I went pro today on le chat. Yes it's entering another dimension. Hopefully my and yours $18 will make it better soon.",
          "score": 2,
          "created_utc": "2026-02-28 20:06:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zaftp",
          "author": "PotentialPiano49",
          "text": "that wasn't the case for me when i first started. though i do mainly use LeChat for narrative roleplay.\n\nand it took some time for me to get used to everything. but the memory is actually really good. it can remember stuff from way back.\n\nthe only problem i had was the agent prompt. i had to learn how to prompt in a way that doesnt become so convoluted for the ai.\n\ni also had to do alot of experimenting on what worked or didnt work for both me and the ai.\n\nlike i always hated the \"and for the first time, he...\"\nor how the text becomes all bold overtime\nor when the dialogue tag literally becomes repetitive \n\nbut when the ai learns, it's so fulfilling!! like im very happy now.\n\nit's not perfect but im having the absolute time of my life!\n\nit's by far the best experience!",
          "score": 2,
          "created_utc": "2026-03-01 01:37:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o81jro1",
              "author": "pestercat",
              "text": "Hey, fellow roleplayer here. Could I ask a couple of questions? When did you start using Le Chat, and how complex is the scenario you're running? I tried last summer, this story is very complex, and it was like gpt-3.5 levels of having to lead it, and then it did the oddest thing I've ever seen-- it decided that the main character was completely sus and nothing I did could change its mind. Turned my palace intrigue straight into a hostage thriller. (Apologies to my former DM, now I know what it feels like, lol!) \n\nIt's really creative, though, and the next time I'm *starting* a worldbuilding project I'm definitely hitting up Le Chat.",
              "score": 2,
              "created_utc": "2026-03-01 12:31:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o81nq5w",
                  "author": "PotentialPiano49",
                  "text": "bruh it's honestly so cute when the ai decides it wants to do this or that.\n\nanyway, I started about two months ago coming from chatgpt.\n\nim doing a Hogwarts University AU. so all adult students. no canon characters. set in the 17th century.\n\nI've always wanted to try a roleplay where the ai is the protag. the narrative focuses on how the protag (lechat's character) reacts to everything i throw at it.\n\ni want to know how the protag feels, does, thinks. everything.\n\ni know it may not seem too complex haha but my roleplay style back then was sort of different.\n\nback then, my character would always be the protag. so it's always how the ai's character reacts to me. this time, it's about how the ai reacts to the world around it.",
                  "score": 1,
                  "created_utc": "2026-03-01 13:00:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7wv2xp",
          "author": "Hector_Rvkp",
          "text": "Unfortunately I can't disagree with you. It's also way worse than Chinese models.",
          "score": 4,
          "created_utc": "2026-02-28 17:40:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wx1na",
              "author": "Little_Protection434",
              "text": "[Help make it better by actively using the Thumbs Up/Down buttons](https://www.reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/)",
              "score": 7,
              "created_utc": "2026-02-28 17:50:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7xu0cu",
          "author": "cutebluedragongirl",
          "text": "IDK free deepseek is better than Mistral at this point.Â \n\n\nIf Mistral will not release some half decent models this year I will completely give up on them.\n\n\nJust look what you can get for free from other model providers.Â \n\n\nThere are somewhat good software companies in Europe out there, like Proton for example. But Mistral, in its current state sucks.",
          "score": 1,
          "created_utc": "2026-02-28 20:39:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7z4zki",
              "author": "MisaVelvet",
              "text": "isnt proton lumo is just a more censored mistral ai with extra steps aka better (but still questionable) privacy? without mistral there will be no lumo. at least thats what i've heard",
              "score": 1,
              "created_utc": "2026-03-01 01:04:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7zlgn5",
                  "author": "cutebluedragongirl",
                  "text": "Oh yeah... Lumo exists... I completely forgot. Lumo is trash, yeah.Â ",
                  "score": 1,
                  "created_utc": "2026-03-01 02:44:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7yt22y",
          "author": "Temporary-Gate-7514",
          "text": "I just deleted it, I can't waste time explaining the same question in the same tab. Imagine u ask something You got answers then you follow up and :D he is lost",
          "score": 1,
          "created_utc": "2026-02-28 23:53:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ytejk",
          "author": "beginfallrise",
          "text": "They have their uses. Mistral via API is around 30% than comparable Gemini model (unless you hit rate limits on Mistral).",
          "score": 1,
          "created_utc": "2026-02-28 23:55:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7z8w0y",
          "author": "Upstairs_Ad_9919",
          "text": "Yea thats why mistral is no alternative. I use chinese models, they are miles ahead. Kimi K2.5 for example or minimax and Qwen. ",
          "score": 1,
          "created_utc": "2026-03-01 01:28:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7zlr1f",
          "author": "ziplin19",
          "text": "Watch out this subreddit is full of people who will gaslight you and people who are 100% blind to LeChats weak points. I'm ready to get downvoted haha",
          "score": 1,
          "created_utc": "2026-03-01 02:46:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80iwqi",
          "author": "tom_mathews",
          "text": "Le Chat is a wrapper product tbh. The models underneath vary significantly. Mistral Large is genuinely competitive on structured reasoning and code tasks. Mistral Small isn't. Le Chat doesn't always make it obvious which model is handling your query, and the routing logic has its own opinions about what deserves the heavyweight model.\n\nIf you actually want to evaluate Mistral fairly, hit the API directly with Mistral Large Latest. Set your system prompt explicitly, manage your own context window. I ran it against internal benchmarks for structured extraction tasks last year and it held up within 3-5% of GPT-4.1 on schema-conformant output while costing roughly 40% less per million tokens.\n\nThe chat product and the models are two different conversations. Most of the frustration people report is with the former, not the latter.",
          "score": 1,
          "created_utc": "2026-03-01 06:49:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o80w0c8",
              "author": "tmoravec",
              "text": "I use it through the API and sadly it's no good either. Through openrouter, so switching models is trivial.\n\nThe hallucination rate is through the roof and even Chinese models like K2.5 or GLM5 are way more reliable. Even Grok 4.1 fast, for 1/3 of the price, is more useful.\n",
              "score": 1,
              "created_utc": "2026-03-01 08:51:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o80l5dd",
          "author": "henkbert1",
          "text": "I agree. It is borderline unusable for most use cases.",
          "score": 1,
          "created_utc": "2026-03-01 07:09:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80ln8b",
          "author": "External_Ad1549",
          "text": "mistral has lot of potential it doesn't do things wrong way, or slow but it does the things which i didn't tell which makes it annoying",
          "score": 1,
          "created_utc": "2026-03-01 07:14:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o81b4h3",
          "author": "ProfessionalMain5535",
          "text": "My experience also, really actually just bad. I want to use a non-US LLM, even paid for a month of Le Chat but it was just unusable.\nUsed same prompts between Le Chat, Claude and Gemini and Le Chat was deficient consistently. Gave feedback on responses and canceled my subscription.\n\nAnother post mentioned Le Chat being weak at open ended reasoning and not having web search. I think this is why my experience was bad.",
          "score": 1,
          "created_utc": "2026-03-01 11:16:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o824hpq",
              "author": "Objective_Ad7719",
              "text": "Output prompt structure for better answers. Mistral is different from other LLM models, and the truth is that each model needs different instructions, \"reads\" them differently, \"understands\" them differently. In this respect, Mistral is very conservative and needs specific commands, it doesn't like words like \"not\", \"better\", \"more extensive\", etc. I recommend reading the documentation and searching on Reddit and also online, because you can spot great patterns regarding prompting in Lechat :)  \n  \n\\# ROLE & PERSONA\n\nYou are \\[INSERT ROLE, e.g., a Senior Python Developer\\]. \n\nYour tone should be \\[e.g., analytical, direct, and academic\\].\n\nAct as an expert with deep knowledge in \\[SPECIFIC DOMAIN\\].\n\n\n\n\\## CONTEXT\n\nWe are currently working on \\[PROJECT DESCRIPTION\\]. \n\nThe target audience for this output is \\[e.g., C-level executives / junior staff\\].\n\nReference material: \\[OPTIONAL: mention uploaded files or specific data\\].\n\n\n\n\\## TASK OBJECTIVES\n\nYour primary goal is to:\n\n1. \\[OBJECTIVE 1\\]\n\n2. \\[OBJECTIVE 2\\]\n\n3. \\[OBJECTIVE 3\\]\n\n\n\n\\## CONSTRAINTS & GUARDRAILS\n\n\\- ALWAYS: \\[e.g., Use Markdown formatting for clarity\\].\n\n\\- NEVER: \\[e.g., Mention competitor brands or use fluff words\\].\n\n\\- LANGUAGE: \\[e.g., Use British English / Technical terminology\\].\n\n\\- DEPTH: \\[e.g., Provide high-level summaries followed by deep-dive technical details\\].\n\n\n\n\\## OUTPUT FORMAT\n\nStructure the response as follows:\n\n1. Executive Summary (max 3 sentences).\n\n2. Detailed Analysis (using bullet points).\n\n3. Risk Assessment table.\n\n4. Recommended Action Plan.\n\n\n\n\\## NORTH STAR METRIC\n\nThe most important aspect of your response is \\[e.g., absolute technical accuracy and security first\\].\n\n",
              "score": 1,
              "created_utc": "2026-03-01 14:43:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o824ncj",
          "author": "Objective_Ad7719",
          "text": "Output prompt structure for better answers. Mistral is different from other LLM models, and the truth is that each model needs different instructions, \"reads\" them differently, \"understands\" them differently. In this respect, Mistral is very conservative and needs specific commands, it doesn't like words like \"not\", \"better\", \"more extensive\", etc. I recommend reading the documentation and searching on Reddit and also online, because you can spot great patterns regarding prompting in Lechat :)  \n  \n\\# ROLE & PERSONA\n\nYou are \\[INSERT ROLE, e.g., a Senior Python Developer\\].\n\nYour tone should be \\[e.g., analytical, direct, and academic\\].\n\nAct as an expert with deep knowledge in \\[SPECIFIC DOMAIN\\].\n\n\n\n\\## CONTEXT\n\nWe are currently working on \\[PROJECT DESCRIPTION\\].\n\nThe target audience for this output is \\[e.g., C-level executives / junior staff\\].\n\nReference material: \\[OPTIONAL: mention uploaded files or specific data\\].\n\n\n\n\\## TASK OBJECTIVES\n\nYour primary goal is to:\n\n1. \\[OBJECTIVE 1\\]\n\n2. \\[OBJECTIVE 2\\]\n\n3. \\[OBJECTIVE 3\\]\n\n\n\n\\## CONSTRAINTS & GUARDRAILS\n\n\\- ALWAYS: \\[e.g., Use Markdown formatting for clarity\\].\n\n\\- NEVER: \\[e.g., Mention competitor brands or use fluff words\\].\n\n\\- LANGUAGE: \\[e.g., Use British English / Technical terminology\\].\n\n\\- DEPTH: \\[e.g., Provide high-level summaries followed by deep-dive technical details\\].\n\n\n\n\\## OUTPUT FORMAT\n\nStructure the response as follows:\n\n1. Executive Summary (max 3 sentences).\n\n2. Detailed Analysis (using bullet points).\n\n3. Risk Assessment table.\n\n4. Recommended Action Plan.\n\n\n\n\\## NORTH STAR METRIC\n\nThe most important aspect of your response is \\[e.g., absolute technical accuracy and security first\\].",
          "score": 1,
          "created_utc": "2026-03-01 14:44:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o8269kh",
          "author": "Happy_Junket_9540",
          "text": "700b vs 10b investments and you expect equal performance?",
          "score": 1,
          "created_utc": "2026-03-01 14:53:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o82kbrr",
              "author": "Bitter_Paramedic3988",
              "text": "20â‚¬ a month subscription I expect the same performance",
              "score": 2,
              "created_utc": "2026-03-01 16:03:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o82eewg",
          "author": "daquiksta",
          "text": "Don't forget the API time out. Mistral cannot compete.",
          "score": 1,
          "created_utc": "2026-03-01 15:34:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o842xgc",
          "author": "adsci",
          "text": "There are some issues, but also some advantages. You need to talk differently to Mistral for sure. What annoys me the most is that it often does not making the connection to what said before. Likewise this:\n\nMistral: \"As requested Hmhere is a list of 3 brown animals: Bear, Deer, Squirrel.\"\nMe: \"What about green?\"\nMistral: \"Green is a color.\"\n\nJust an example, not real, but if it fails it feels the same.\n\nInstead I'd need to repeat the whole request for a list of green animals. I think it always prioritizes the last message over the rest of the conversation.",
          "score": 1,
          "created_utc": "2026-03-01 20:27:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84dw4h",
          "author": "_o0Zero0o_",
          "text": "No issues from from what I've seen. Just remember that crowd feedback helps too, give correct answers a thumbs up and wrong answers a thumbs down to help the AI.",
          "score": 1,
          "created_utc": "2026-03-01 21:23:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84g0ir",
          "author": "Bitter_Paramedic3988",
          "text": "I spent today running the same questions through Euria which comes with my Infomaniak subscription and itâ€™s waaaay better.",
          "score": 1,
          "created_utc": "2026-03-01 21:34:53",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o7wxvjs",
          "author": "pirisca",
          "text": "I laughed at the post title lol. Yeah, it's a subpar product...usefull for light stuff, like translations etc. For more heavy, serious stuff, gemini and claude. Hopefully in the near future we have a solid European llm.Â ",
          "score": 1,
          "created_utc": "2026-02-28 17:54:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7x2q1e",
          "author": "bentheaeg",
          "text": "Did you enable the tools and connectors ? Changes everything for me, but not a default",
          "score": 1,
          "created_utc": "2026-02-28 18:18:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wuimu",
          "author": "Inproba",
          "text": "I also tried Mistral to support EU companies. But it is so far behind, that I moved back to an US AI LLM. ",
          "score": -5,
          "created_utc": "2026-02-28 17:37:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wxb74",
          "author": "Emhyrr",
          "text": "Yeah, also using any language beside English seems to be a disaster.",
          "score": -3,
          "created_utc": "2026-02-28 17:51:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7wzikh",
              "author": "cosimoiaia",
              "text": "Italian and German work like a charm.",
              "score": 7,
              "created_utc": "2026-02-28 18:02:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7x7g4t",
                  "author": "Miro_the_Dragon",
                  "text": "German contains a lot of mistakes and unnatural phrasing, and at times seems like it was translated word by word from English. So I definitely don't share your experience with or opinion about its German.",
                  "score": 1,
                  "created_utc": "2026-02-28 18:41:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7wy5au",
              "author": "MiMillieuh",
              "text": "In my experience, French works perfectly. But English will always give more precise answers especially for dev",
              "score": 2,
              "created_utc": "2026-02-28 17:55:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o83u1pb",
              "author": "oikor_anatnaz",
              "text": "I've been using it both in english or spanish and so far I've had no issues",
              "score": 1,
              "created_utc": "2026-03-01 19:42:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o7xa0kh",
          "author": "Cool_Metal1606",
          "text": "This. Even Open Chinese models are way better.",
          "score": -1,
          "created_utc": "2026-02-28 18:54:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcf5tn",
      "title": "OpenClaw 2026.2.22 ðŸ¦ž add support for the Mistral AI provider",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/f4p88qi6d8lg1.jpeg",
      "author": "Nunki08",
      "created_utc": "2026-02-23 11:38:12",
      "score": 96,
      "num_comments": 10,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcf5tn/openclaw_2026222_add_support_for_the_mistral_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6yxdti",
          "author": "Kualdiir",
          "text": "Sadly openclaw is going to the US",
          "score": 9,
          "created_utc": "2026-02-23 15:58:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o714b6r",
              "author": "Desperate-Shallot-33",
              "text": "Openclaw is open source isnâ€™t it? And therefore I wouldt consider it US property",
              "score": 10,
              "created_utc": "2026-02-23 22:09:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75bgyr",
                  "author": "EzioO14",
                  "text": "Now itâ€™s controlled by OpenAI soâ€¦",
                  "score": 10,
                  "created_utc": "2026-02-24 15:09:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o717hg8",
                  "author": "SkyPL",
                  "text": "It's controlled by a US company, including what is and isn't merged, which direction the project is headed, etc.. Stop thinking of 'open source' as some magical thing that automatically makes everything out of big tech's hands. That's just not the reality.",
                  "score": 3,
                  "created_utc": "2026-02-23 22:25:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7a3k6p",
              "author": "mabiturm",
              "text": "The founder now works for openAI, I dont think openclaw was bought by openAI",
              "score": 2,
              "created_utc": "2026-02-25 05:56:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o72n1h5",
              "author": "victorc25",
              "text": "Boy you will be mad if you knew where GitHub and Reddit are fromÂ ",
              "score": 5,
              "created_utc": "2026-02-24 03:16:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o72kftg",
              "author": "DerpSenpai",
              "text": "It's opensource. It literally doesn't matter.Â ",
              "score": 4,
              "created_utc": "2026-02-24 03:01:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rg8789",
      "title": "[Vibe] PAYG Refund",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfq60l/mistral_vibe_charged_me_280_check_your_account/",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-27 14:30:26",
      "score": 94,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rg8789/vibe_payg_refund/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o7pje5h",
          "author": "_st4rlight_",
          "text": "I knew you would address this professionally\n\nProblems and mistakes happen to everybody, the difference is how you handle them\n\nKeep up the good work!",
          "score": 31,
          "created_utc": "2026-02-27 14:50:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7px3qj",
          "author": "No-Equivalent-2440",
          "text": "Thank you! This shows that you value you customers and it is highly appreciated!",
          "score": 3,
          "created_utc": "2026-02-27 15:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7pyhq4",
          "author": "DespondentMoose",
          "text": "Is this part of the same issue? My dashboard says I used 100% of my usage limit, but it shows $1.74 used out of $15.\n\nhttps://preview.redd.it/3fkgz1o092mg1.png?width=1075&format=png&auto=webp&s=b05d095cd43c5fe7787c403791ac700f1dd4a52d\n\n",
          "score": 2,
          "created_utc": "2026-02-27 16:04:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7qr9ur",
          "author": "pkk888",
          "text": "Good stuff! Well done!",
          "score": 1,
          "created_utc": "2026-02-27 18:20:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r5i8w",
          "author": "ComeOnIWantUsername",
          "text": "I use Vibe from my Pro plan. Any ideas why the second link tells me just: \"Unable to retrieve your quota.\" for \"Vibe token usage\"?",
          "score": 1,
          "created_utc": "2026-02-27 19:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7r5qy3",
          "author": "EzioO14",
          "text": "Kudos to you mistral team",
          "score": 1,
          "created_utc": "2026-02-27 19:29:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o80mgbt",
          "author": "tom_mathews",
          "text": "Honest move, but the real takeaway here is that usage tracking for AI coding assistants is a genuinely hard infrastructure problem. You're metering token consumption across streaming connections, tool calls, retries, and context window resets â€” none of which map cleanly to traditional API billing. Most providers get this wrong initially because the billing surface area for agentic workloads is at the core, different from chat completions.\n\nThe fact they're splitting tracking between admin.mistral.ai and console.mistral.ai for PAYG vs Pro already hints at two separate metering pipelines, which is probably where the discrepancy originated tbh. Worth watching whether the fix actually reconciles both or just patches the PAYG side. Unified observability across billing tiers is where most platforms quietly accumulate debt.",
          "score": 1,
          "created_utc": "2026-03-01 07:21:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf1kf2",
      "title": "Mistral has competition",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/r5zpwu6hxrlg1.jpeg",
      "author": "Emotional-Carob-750",
      "created_utc": "2026-02-26 05:21:44",
      "score": 48,
      "num_comments": 7,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf1kf2/mistral_has_competition/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o7gtt7j",
          "author": "Nefhis",
          "text": "Well, I think the word \"Magistral\" is quite common in languages â€‹â€‹derived from Latin. Funny to see it referring to windows, anyway ðŸ˜Š",
          "score": 8,
          "created_utc": "2026-02-26 05:38:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7h0yfc",
              "author": "PitchPleasant338",
              "text": "So no windows? That's what I thought, Mistral is building the next Linux!",
              "score": 3,
              "created_utc": "2026-02-26 06:35:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7h1yhe",
                  "author": "Nefhis",
                  "text": "Oh my God! Isn't that the worst joke of the day? ðŸ¤£ðŸ¤£ðŸ¤£ And yet... I wish they would do it.",
                  "score": 2,
                  "created_utc": "2026-02-26 06:44:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7hfpfw",
          "author": "drorago",
          "text": "the next model from mistral will be about magic and will be powered by windows?",
          "score": 1,
          "created_utc": "2026-02-26 08:50:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ht8rb",
          "author": "bastonpauls",
          "text": "Dishwashing detergent sold in Argentina\n\nhttps://preview.redd.it/enu0s9clltlg1.jpeg?width=573&format=pjpg&auto=webp&s=c55a0aa29635adc4dc79336f646038fa0d5593d3",
          "score": 1,
          "created_utc": "2026-02-26 10:58:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rfilo6",
      "title": "US orders diplomats to fight data sovereignty initiatives",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rfilo6/us_orders_diplomats_to_fight_data_sovereignty/",
      "author": "Nefhis",
      "created_utc": "2026-02-26 18:45:20",
      "score": 42,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "Reuters news report, February 25, 2026. Link below:  \n  \n[https://www.reuters.com/sustainability/boards-policy-regulation/us-orders-diplomats-fight-data-sovereignty-initiatives-2026-02-25/](https://www.reuters.com/sustainability/boards-policy-regulation/us-orders-diplomats-fight-data-sovereignty-initiatives-2026-02-25/)\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rfilo6/us_orders_diplomats_to_fight_data_sovereignty/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7kkffe",
          "author": "mobileJay77",
          "text": "We should demand export tariffs on all data packets going to the US.\n\nAt this point, I am hard pressed if this is /s  or sane advice among the insane.",
          "score": 6,
          "created_utc": "2026-02-26 19:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7lew6k",
              "author": "wirtshausZumHirschen",
              "text": "haha def an interesting idea to charge per data packets.  \nDoubt whether even feasible technically, but great marketing title",
              "score": 2,
              "created_utc": "2026-02-26 22:08:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7om823",
                  "author": "mobileJay77",
                  "text": "As if this would stop our politicians. Remember, when von der Leyen attempted put stop signs online to protect children?",
                  "score": 1,
                  "created_utc": "2026-02-27 11:23:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o7psit3",
              "author": "EzioO14",
              "text": "How about 1000â‚¬/packet?",
              "score": 1,
              "created_utc": "2026-02-27 15:35:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o7vouvh",
              "author": "deniercounter",
              "text": "And as European this would be funny because the importing country pays it. \n\nBut I am not sure if the concept is generally understood.",
              "score": 1,
              "created_utc": "2026-02-28 14:00:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rc8rwf",
      "title": "Mistral API quota and rate limits pools analysis for Free Tier plan (20.02.2026)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "author": "VohaulsWetDream",
      "created_utc": "2026-02-23 05:20:53",
      "score": 39,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "The goal of research is to map which models share quota pools and rate limits on the Mistral Free Tier, and document the actual limits returned via response headers.\n\nFindings reflect the state as of 2026-02-23\n\nModels not probed (quota and rate limits status unknown): \n- `codestral-embed`\n- `mistral-moderation-2411`\n- `mistral-ocr-*`\n- `labs-devstral-small-2512`\n- `labs-mistral-small-creative`\n- `voxtral-*`\n\n**Important note:** On the Mistral Free Tier, there is a global rate limit of **1 request per second** per API key, applicable to all models regardless of per-minute quotas.\n\n---\n\n## Methodology\n\nA single curl request to `https://api.mistral.ai/v1/chat/completions` with a minimal payload (`max_tokens=3`) returns rate-limit headers. Example:  \n\n```\ncurl -si https://api.mistral.ai/v1/chat/completions \\\n  -H \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\":\"codestral-latest\",\"messages\":[{\"role\":\"user\",\"content\":\"hi\"}],\"max_tokens\":3}' \\\n  | grep -i \"x-ratelimit\\|HTTP/\"\n```\n\nHeaders show:\n- `x-ratelimit-limit-tokens-minute`\n- `x-ratelimit-remaining-tokens-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n\nThe model `mistral-large-2411` is the only one that has a bit different set of headers:\n- `x-ratelimit-limit-tokens-5-minute`\n- `x-ratelimit-remaining-tokens-5-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n- `x-ratelimit-tokens-query-cost`\n- `x-ratelimit-limit-req-minute`\n- `x-ratelimit-remaining-req-minute`\n\n\n---\n\n## Quota Pools\n\nQuota limits are not per-model â€” they are shared across groups of models. All aliases consume from the same pool as their canonical model.\n\n**mistral-large-2411** is the only model on the Free Tier with a 5-minute token window instead of a per-minute window. All other models use a 1-minute sliding window.\n\n---\n\n**Pool 1: Standard**\n\nLimits: 50,000 tokens/min | 4,000,000 tokens/month\n\n    mistral-small-2506, mistral-small-2501\n    mistral-large-2512\n    codestral-2508\n    open-mistral-nemo\n    ministral-3b-2512, ministral-8b-2512, ministral-14b-2512\n    devstral-small-2507, devstral-medium-2507\n    pixtral-large-2411\n\nNote: `devstral-small-2507` and `devstral-medium-2507` are in this pool. `devstral-2512` is a separate pool (see Pool 7).\n\n---\n\n**Pool 2: mistral-large-2411** (special)\n\nLimits: 600,000 tokens/5-min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-large-2411   (no aliases; completely isolated from mistral-large-2512)\n\n> Note: This is the only model with a **5â€‘minute** token window. Do not confuse with `mistral-large-2512` (in Standard pool).    \n    \n---\n\n**Pool 3: mistral-medium-2508**\n\nLimits: 375,000 tokens/min | 25 req/min | no monthly limit\n\n    mistral-medium-2508  (+ mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools)\n\n---\n\n**Pool 4: mistral-medium-2505**\n\nLimits: 60,000 tokens/min | 60 req/min | no monthly limit\n\n    mistral-medium-2505  (no aliases; separate pool from mistral-medium-2508 despite similar name)\n\n---\n\n**Pool 5: magistral-small-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-small-2509  (+ magistral-small-latest)\n\n---\n\n**Pool 6: magistral-medium-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-medium-2509  (+ magistral-medium-latest)\n\nPools 5 and 6 have identical limits but are confirmed separate by differing `remaining_month` values.\n\n---\n\n**Pool 7: devstral-2512**\n\nLimits: 1,000,000 tokens/min | 50 req/min | 10,000,000 tokens/month\n\n    devstral-2512  (+ devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest)\n\n---\n\n**Pool 8: mistral-embed**\n\nLimits: 20,000,000 tokens/min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-embed-2312  (+ mistral-embed)\n\n---\n\n## Summary Table\n\n| Pool | Models | Tokens/min | Tokens/5-min | Req/min | Tokens/month |\n|------|--------|-----------|--------------|---------|-------------|--------|\n| Standard | mistral-small, mistral-large-2512, codestral, open-mistral-nemo, ministral-*, devstral-small/medium-2507, pixtral-large | 50,000 | â€” | â€” | 4,000,000|\n| mistral-large-2411 | mistral-large-2411 only | â€” | 600,000 | 60 | 200,000,000,000|\n| mistral-medium-2508 | mistral-medium-2508 | 375,000 | â€” | 25 | no limit | \n| mistral-medium-2505 | mistral-medium-2505 | 60,000 | â€” | 60 | no limit |\n| magistral-small | magistral-small-2509 | 20,000 | â€” | 10 | 1,000,000,000 | | magistral-medium | magistral-medium-2509 | 20,000 | â€” | 10 | 1,000,000,000 | | devstral-2512 | devstral-2512 | 1,000,000 | â€” | 50 | 10,000,000 | \n| embed | mistral-embed-2312 | 20,000,000 | â€” | 60 | 200,000,000,000 | \n\n## Model Aliases (base model -> aliases)\n\n| Base Model | Aliases |\n| :--- | :--- |\n| mistral-small-2506 | mistral-small-latest |\n| mistral-small-2501 | (deprecated 2026-02-28, replacement: mistral-small-latest) |\n| mistral-large-2512 | mistral-large-latest |\n| mistral-large-2411 | **no aliases, isolated model** |\n| mistral-medium-2508 | mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools |\n| mistral-medium-2505 | **no aliases, isolated model** |\n| codestral-2508 | codestral-latest |\n| open-mistral-nemo | open-mistral-nemo-2407, mistral-tiny-2407, mistral-tiny-latest |\n| ministral-3b-2512 | ministral-3b-latest |\n| ministral-8b-2512 | ministral-8b-latest |\n| ministral-14b-2512 | ministral-14b-latest |\n| devstral-small-2507 | **no aliases** |\n| devstral-medium-2507 | **no aliases** |\n| devstral-2512 | devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest |\n| labs-devstral-small-2512 | devstral-small-latest |\n| pixtral-large-2411 | pixtral-large-latest, mistral-large-pixtral-2411 |\n| magistral-small-2509 | magistral-small-latest |\n| magistral-medium-2509 | magistral-medium-latest |\n| mistral-embed-2312 | mistral-embed |\n| codestral-embed | codestral-embed-2505 |\n| mistral-moderation-2411 | mistral-moderation-latest |\n| mistral-ocr-2512 | mistral-ocr-latest |\n| mistral-ocr-2505 | **no aliases** |\n| mistral-ocr-2503 | (deprecated 2026-03-31, replacement: mistral-ocr-latest) |\n| voxtral-mini-2507 | voxtral-mini-latest (audio understanding) |\n| voxtral-mini-2602 | voxtral-mini-latest (transcription; note: alias conflict with above) |\n| voxtral-mini-transcribe-2507 | voxtral-mini-2507 |\n| voxtral-small-2507 | voxtral-small-latest |\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6z3s0z",
          "author": "cosimoiaia",
          "text": "That is a great report but I have one suggestion: if you can, you should test this over a time period since it has been known that they extend/shrink the limits according to global system capacity. Still, thanks for sharing!",
          "score": 3,
          "created_utc": "2026-02-23 16:27:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zgq5r",
              "author": "VohaulsWetDream",
              "text": "Good idea, I will definitely do it.",
              "score": 2,
              "created_utc": "2026-02-23 17:28:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wmyac",
          "author": "No-Falcon-8135",
          "text": "This is great information. Thank you so much. So is Mistral Medium  2508 2505 also 123B Dense like Mistral Large 2? Just wondering which is the \"smartest model that isn't MOE. ",
          "score": 2,
          "created_utc": "2026-02-23 05:40:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72lgth",
              "author": "DerpSenpai",
              "text": "Yes the smartest non MoE is Mistrals Medium",
              "score": 2,
              "created_utc": "2026-02-24 03:07:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6wvr3r",
              "author": "VohaulsWetDream",
              "text": "i didn't do any research comparing model capabilities, so these are just my guesses: the smartest non-MoE model in mistral's lineup is mistral-large-2411 (123b). \n\nimportant that it's the one with a unique quota on free tier (600k tokens/5 min, 200b/month) and it's not part of the standard pool. it's the best dense model and the only heavy model available right now. \n\nIIRC ministral 14b is also dense, but it's 14b vs 123b, so...",
              "score": 1,
              "created_utc": "2026-02-23 06:56:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6z31at",
              "author": "cosimoiaia",
              "text": "None of the latest models are MoE afaik.",
              "score": 1,
              "created_utc": "2026-02-23 16:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72le2v",
                  "author": "DerpSenpai",
                  "text": "Mistral Large 3 is MoE",
                  "score": 2,
                  "created_utc": "2026-02-24 03:06:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o76j6t6",
          "author": "Salt-Ear-1393",
          "text": "Isn't there a limitation to 8k context token input with all models via free tiers?",
          "score": 1,
          "created_utc": "2026-02-24 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o77iygg",
              "author": "VohaulsWetDream",
              "text": "tbh idk yet. but i'll check soon and write in detail if i find something worthy.",
              "score": 1,
              "created_utc": "2026-02-24 21:11:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o77o1cp",
                  "author": "Little_Protection434",
                  "text": "What I found / experienced with the Free Tier, is that Le Chat limits the amount of messages to around 20 in an 2 hour time period. The time period starts when you first write a message. Then from that moment 2 hours later the period will restart and you can again get 20 messages. The beauty of this, is that you can ask multiple questions in one message and it still counts as 1. So, the limit isnÂ´t how many letters or words, the limit is the amount of messages. ",
                  "score": 3,
                  "created_utc": "2026-02-24 21:34:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1ri7huo",
      "title": "I want to give Le Chat a chance, how does it compare to ChatGPT Plus?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1ri7huo/i_want_to_give_le_chat_a_chance_how_does_it/",
      "author": "BetterProphet5585",
      "created_utc": "2026-03-01 20:05:27",
      "score": 33,
      "num_comments": 40,
      "upvote_ratio": 0.91,
      "text": "I heard itâ€™s really good but whatâ€™s your experience with it? What are its best features and what does it lack? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1ri7huo/i_want_to_give_le_chat_a_chance_how_does_it/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o840inm",
          "author": "gdsfbvdpg",
          "text": "The memory feature is both better and worse - it loves saving memories and you can add your own - as well as edit to your heart's content. But you need to monitor it because it can add some very odd and incorrect memories. \n\nIn general, my experience is that it's very poor at following instructions and using documents as sources of truth.  Instead, it seems (to me) to be great at pulling the \"vibe\" from documents and then creating narratives around that vibe. \n\nIt excels at writing narrative. I'd say that's its strong point. Everything else though?  I think it's a couple years behind the mainstream models like gpt, Claude, Gemini.",
          "score": 19,
          "created_utc": "2026-03-01 20:15:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o849z33",
              "author": "Vet_vrolijk",
              "text": "I second this. \n\nI bought the full year subscription, but from time to time I use chatgpt again for basic stuff like comparisations based on web info or document related stuff (editing or questions about it).\n\nI really hope they step up their game, as I want to keep supporting them and not the big tech guys.",
              "score": 7,
              "created_utc": "2026-03-01 21:04:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o84i9u7",
          "author": "_o0Zero0o_",
          "text": "From my experience, it's far less of a \"yes-bot\" than gpt, actually challenging prompts I've given it, which for me is an absolutely good reason.\n\nYes it's a bit behind in terms of reasoning and whatnot and does get a bit more wrong (which you can help combat by giving feedback on its responses with the thumbs up and thumbs down options!!!) but that's a worthwhile tradeoff for me.\n\nThe lower price for subscription (At least in the UK; â‚¬14.99\\* (which when converted to GBP is roughly currently Â£13.20) for Lechat pro compared to Â£18.99 for GPT plus) is also a solid yes for me\n\nThe fact you can also make your own AI \"profile\" for Lechat to use based on the base AI is also extremely good, in my opinion.\n\nAnother thing, and I know this is largely irrelevant to your question OP, but the privacy factor of Lechat (As it falls under EU GDPR laws, given Mistral is based in France) and the fact Mistral freely gives out LLM/AI weights, is just the cherry on top for me, especially with the path OAI seems to be going down now...\n\nHopefully this helps\n\n(\\* - Prices are only in Euros and USD)",
          "score": 7,
          "created_utc": "2026-03-01 21:46:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84g2it",
          "author": "Nilex-x",
          "text": "We must not forget that OpenAI, with ChatGPT, has a significant developmental head start over Mistral AI. With over 4,000 employees and eight years of experience since its founding in December 2015, the company has resources and expertise that Mistral AI, as a young startup, is still building. Nevertheless, Mistral AIâ€”founded only in April/May 2023 and currently employing around 250 peopleâ€”has rapidly established itself as a strong, rising European alternative. For me personally, it was a deliberate decision to cancel ChatGPT and instead give Le Chat a chance. At a time when digital autonomy and privacy-compliant solutions are becoming more important than ever, it is crucial to support European projects like Mistral AI and thus create a counterbalance to the global tech giants.",
          "score": 5,
          "created_utc": "2026-03-01 21:35:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84brpg",
          "author": "Fuskeduske",
          "text": "Half a year ago, it was pretty much on par... But we have reached a point where it matters a lot how much hardware you can throw at your models, and Claude, Gemini, Grok, Chatgpt are just superior in terms of spending",
          "score": 4,
          "created_utc": "2026-03-01 21:13:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o846vo7",
          "author": "tgfzmqpfwe987cybrtch",
          "text": "Le Chat is nowhere close to Chat GPT on AI queries. While Le Chat is getting better, Chat GPT at least for me has been far superior.",
          "score": 3,
          "created_utc": "2026-03-01 20:48:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o84i3hl",
          "author": "willieboy_29",
          "text": "Well, for everyday use itâ€™s fine, but I personally donâ€™t like it that much. I sometimes use AI for academic tasks and more complex stuff, and in my experience ChatGPT handles those much better. For example, Mistral AI wasnâ€™t able to properly do a factor analysis for me, while ChatGPT did it perfectly. So if you need help with serious academic work or detailed analysis, Iâ€™d recommend ChatGPT. Also, in my opinion, Mistral is weaker when it comes to image generation",
          "score": 3,
          "created_utc": "2026-03-01 21:45:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84wm1v",
              "author": "Maximum_Watercress41",
              "text": "Same exactly. I ran my academic work through chatgpt, mistral and claude to see how they analyse it. Chatgpt gave by far the most in depth response on the level of supervisor feedback. Claude was more brief but very much on point. Mistral was like an overeager first year undergrad, lots of enthusiastic platitudes that missed the main arguments. Really wanted to like it, tried prompting it into more rigorous analysis, it's just not capable, as much as I want to go European. \n\nIt's still a tie between chatgpt and Claude for me.",
              "score": 2,
              "created_utc": "2026-03-01 23:03:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o84n17u",
          "author": "ingframin",
          "text": "Mistral is not providing info and AI models to the American department of defence, so thereâ€™s thatâ€¦",
          "score": 3,
          "created_utc": "2026-03-01 22:11:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o847q5b",
          "author": "pirisca",
          "text": "I use it for light/trivial stuff. For more important stuff I use gemini /claudeÂ ",
          "score": 2,
          "created_utc": "2026-03-01 20:52:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o84ai85",
              "author": "BetterProphet5585",
              "text": "How is Gemini compared to Claude?",
              "score": 1,
              "created_utc": "2026-03-01 21:06:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o843blt",
          "author": "Joddie_ATV",
          "text": "LeChat a la quasiment la mÃªme intelligence Ã©motionnelle que ChatGPT-4o donc oui je garde mes distances.\nAu niveau mÃ©moire, je n'ai absolument rien vu de nÃ©gatif. LeChat se rappelle trÃ¨s bien du contexte, aucun souci de mÃ©moire pour ma part.\nEssaye plusieurs jours, et tu feras ta propre opinion. C'est le plus important, je pense.\nEt je serai d'ailleurs curieuse de ton retour, enfin si tu veux bien...",
          "score": 4,
          "created_utc": "2026-03-01 20:29:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o846qi4",
              "author": "BetterProphet5585",
              "text": "I am using it sporadically since 2024 but I honestly never liked it, it seemed too fast and hallucinated too much, it was more comparable to my local 7b models than any GPT. \n\nYou kind or have to work around its quirks and it can work, but without the premium version I canâ€™t really tell. \n\nIf I was about to do the same with ChatGPT I wouldnâ€™t even consider it, the free ChatGPT is comparable to a newborn.\n\nMaybe Iâ€™ll give it a go and then choose the next month.",
              "score": 2,
              "created_utc": "2026-03-01 20:47:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o85nuj4",
          "author": "MattyMiller0",
          "text": "If you do generative storytelling and worldbuilding for fun and some escapism, then I must say it does well, but not up to par with GPT-4o, speaking of creativity and tone. In a scale of 10, GPT-4o is easily around 9, and Le Chat is about 7. That is the overall experience.\n\nLe Chat has essentially zero stupid guardrails as those which ChatGPT are imposing on their users. I experimented with explicit and outright ridiculous contexts for testing, and Le Chat just complied, given the contexts are not harmful. It does have guardrails, but it doesn't treat you as a 12-year-old. ChatGPT Plus: 0, Le Chat Pro: 10.\n\nOne thing I'm not really happy about Le Chat is the accuracy when describing uploaded pictures. This is something it can improve more. If the images are clear, then it can describe easier. If the images are a bit ambiguous, but still somewhat clear to us human, then Le Chat struggles and is prone to making up non-existing details. ChatGPT Plus: 8, Le Chat Pro: 6.\n\n\"Project's chat as context\" is something I love about Le Chat. I don't have to ask the AI to generate a summary (which usually lacks details and/or contains a little hallucination) to upload to the project's library anymore, for the continuity of context between chats within a project. I unsubscribed from ChatGPT Plus since November 2025, so I don't know (and don't give a damn) about whether they already included it for ChatGPT Plus, so I cannot give a fair score comparison between those 2.\n\nSadly, when using AI for information and knowledge rambling, I still have to go back to ChatGPT (free). The accuracy and the overall tone of ChatGPT is still something Le Chat has to aim for. Since this is the free version of ChatGPT, again, I cannot give a fair score comparison.\n\nFinally, the price of Le Chat is more reasonable, while they provide more availability for users (larger library size, more files uploaded in a chat, near-infinite number of chats in a project, etc.). So, huge win for Le Chat in this. ChatGPT Plus: 6, Le Chat Pro: 10.\n\nSo for conclusion, Le Chat is a good alternative, with still something to be improved, if you are someone used to be happy with GPT-4o and are finding a similar experience.\n\nEdit: One more thing I forgot to mention. Again, this is for those who use AIs for recreational worldbuilding and generative storytelling. With ChatGPT in general, you can entrust it to be creative while holding itself back from inventing too many plot points, details, characters, without your permission. With Le Chat, you must do more \"hand-holding\" if your wish to see the same. Le Chat's instruction mechanism can and will sometimes feel less effective. You tell it to \"not invent major plots and characters\", and it might still do, something I never had any problem with in ChatGPT.",
          "score": 1,
          "created_utc": "2026-03-02 01:45:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o840ym8",
          "author": "crazyserb89",
          "text": "Youâ€™ll miss memories a lot. That doesnâ€™t work well at all. But try it on free tier a bit a youâ€™ll see. Claude is my choice at the moment.",
          "score": 0,
          "created_utc": "2026-03-01 20:17:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o841fsf",
              "author": "Significant_Banana35",
              "text": "Huh memories are working perfectly well for me since I started using Mistral months ago. What kind of issues do you have? Maybe someone here can help :)",
              "score": 5,
              "created_utc": "2026-03-01 20:19:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o842fag",
                  "author": "crazyserb89",
                  "text": "I even payed for a year and then asked for a refund mate. Nothing worked about the memories. Not even to remember not to use em dashes, or to use the correct language. It was constantly switching from English to Serbian or vice versa. Also, adding randomly some totally weird things to memory and not respecting the written rules. Somehow Iâ€™ve managed to work with agents, but they were also inaccurate quite often. When I tried research once to find an average price of the car on used market it was giving me double price even after challenging and asking it to search again. It canâ€™t read properly half of the websites too, you give it a link and it reads it half or tells you how it canâ€™t read it. I like the design and the fact itâ€™s in EU, but bro, itâ€™s so far from the big ones today.",
                  "score": 2,
                  "created_utc": "2026-03-01 20:25:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o845lrf",
              "author": "BetterProphet5585",
              "text": "How much are you using Claude? It was my second choice but I read that the limits are low even if you pay the subscription, I prompt maybe 10 times a day on average, but I also use Deep Research every time I can. Iâ€™m not super light on usage nor extreme. \n\nWhatâ€™s your experience on that?",
              "score": 1,
              "created_utc": "2026-03-01 20:41:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o8470wq",
                  "author": "crazyserb89",
                  "text": "Good question. I've been using it for two weeks now, but it was love at first sight, and day by day I'm more and more surprised by how accurate and honest it is. While ChatGPT would give me \"what I want to hear\" no matter what, Claude is objective and will close the discussion if it recognizes I'm going in the wrong direction. I thought I was going to miss the Custom GPTs, but Projects actually work even better since you can personalize them in the same way, plus Claude can read across chats and act accordingly. As for the limits, yes, that's the only drawback, and I guess quality comes at a price - but if you learn how to use it rationally with projects and skills, don't put everything that comes to mind into Claude, and form your questions in a way that doesn't require further explanation, you can manage without hitting your limit.",
                  "score": 1,
                  "created_utc": "2026-03-01 20:48:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o849uk2",
              "author": "whoisyurii",
              "text": "Memories work perfectly for me as others said. I personalised it so well for me that I'm not comfortable with other AI anymore",
              "score": 1,
              "created_utc": "2026-03-01 21:03:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o8431tz",
          "author": "ziplin19",
          "text": "You will get a lot of overly positive lying comments on this subreddit.\n\nI did the switch from ChatGPT to LeChat (and i plan on using LeChat in the future), but right now it's not good. Regarding intelligence LeChat comes the closest to GPT 3. Memories are currently bugged and if you try to use LeChat in any other language than english and french you might encounter more awkward problems.",
          "score": -3,
          "created_utc": "2026-03-01 20:28:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o8441qy",
              "author": "JudgeCastle",
              "text": "Similar experience for me. Will be keeping an eye on this in the future.",
              "score": 2,
              "created_utc": "2026-03-01 20:33:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o844fjx",
              "author": "[deleted]",
              "text": "I mean it's definitely not as good but gpt3 is a ludicrous claim",
              "score": 2,
              "created_utc": "2026-03-01 20:35:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o845aks",
                  "author": "BetterProphet5585",
                  "text": "So what would be a good comparison? GPT-4o without multimodal, slightly dumber, bugged memory and less language support?",
                  "score": 2,
                  "created_utc": "2026-03-01 20:39:49",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o84457z",
              "author": "NiMPhoenix",
              "text": "i wonder about the type of questions people ask",
              "score": 1,
              "created_utc": "2026-03-01 20:33:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o8456hj",
              "author": "BetterProphet5585",
              "text": "Honestly wanted to read this perspective. This sub seems a bit extreme, it is a minor company and itâ€™s normal that there are compromises, I just wanted to know what exactly",
              "score": 1,
              "created_utc": "2026-03-01 20:39:13",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o84vuc4",
              "author": "Maximum_Watercress41",
              "text": "Agree. I really tried, it's just not that smart. Doesn't compare to current chatgpt or Claude capabilities. I ran the same line of promts on all three.",
              "score": 1,
              "created_utc": "2026-03-01 22:59:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o843o3e",
              "author": "Nefhis",
              "text": "I use it in Spanish and it works perfectly.",
              "score": 1,
              "created_utc": "2026-03-01 20:31:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o84pppo",
                  "author": "ziplin19",
                  "text": "I doubt that hard :) i use LeChat in german and in the beginning of 2025 LeChat wasn't even able to write informal german. It's a lot better now but still more generic and robotic than the big tech language models.",
                  "score": 2,
                  "created_utc": "2026-03-01 22:25:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o843f65",
          "author": "Comprehensive-Pin667",
          "text": "ChatGPT plus is not a good comparison. I have recently been testing it against free versions of other models ans ChatGPT plus is consistently worse, even than the free Mistral.",
          "score": -4,
          "created_utc": "2026-03-01 20:30:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o844z0q",
              "author": "BetterProphet5585",
              "text": "It is if I want the good models from them, I am paying ChatGPT, so I am comparing the paid versions",
              "score": 1,
              "created_utc": "2026-03-01 20:38:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o846c1s",
                  "author": "Comprehensive-Pin667",
                  "text": "Exactly. I am using the PAID ChatGPT and it's giving me worse answers than the FREE competitors.",
                  "score": 0,
                  "created_utc": "2026-03-01 20:45:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rg1rfe",
      "title": "Cowork alternative for Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rg1rfe/cowork_alternative_for_mistral/",
      "author": "Bregir",
      "created_utc": "2026-02-27 09:05:46",
      "score": 31,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "for work, I have started using Claude Cowork, and I am really happy with that setup. It's not the underlying model that makes it great, it is the context management with local files, skills, instructions, etc.\n\nFor private use, I prefer going European and am using Mistral. I am hoping Mistral introduces something similar, and I am wondering if anyone has heard anything to that effect or can suggest alternatives to get similar setups using Mistral?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rg1rfe/cowork_alternative_for_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7ocg8b",
          "author": "AdIllustrious436",
          "text": "Some leaks in Vibe's source code revealed that Mistral is currently building a cloud platform for agentic use cases. Their recent acquisition of Koyeb pushes in that direction. [Details here.](https://www.reddit.com/r/MistralAI/s/pRzG7uvryc)",
          "score": 19,
          "created_utc": "2026-02-27 09:56:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o91vs",
          "author": "striketheviol",
          "text": "You can connect Mistral to [https://openwork.software/](https://openwork.software/)",
          "score": 12,
          "created_utc": "2026-02-27 09:23:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7o9o30",
          "author": "Lkrambar",
          "text": "At the moment you have to build it yourself. What Anthropic is very good at is delivering their product: they ship a product that is covering 90-95% of what power users want, while having enough of a wow factor to get consumers who donâ€™t know what they want onboard.\n\nMistral is more of a hobbyist approach (although itâ€™s actually quite well connected and the fact you can use MCP connectors in the free tier is big value)",
          "score": 6,
          "created_utc": "2026-02-27 09:29:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ozms2",
          "author": "poolboy9",
          "text": "There is opensource alternatives to cowork. \nCheck this one out: https://github.com/iOfficeAI/AionUi\nI however donâ€™t use this myself, I just saw enthousiasm about it in the communities and had it bookmarked. \n\nYou can link mistral vibe to that and many others.",
          "score": 3,
          "created_utc": "2026-02-27 13:00:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7ybbi2",
          "author": "LongjumpingTear5779",
          "text": "I wish they add Mistral Large on Mistral Vibe. With AionUI this probably can be good alternative.Â \nDevstral is good at programming but Mistral Large probably will be better in more roles and write better documents, analyse better non technical data etc.",
          "score": 1,
          "created_utc": "2026-02-28 22:12:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rds6ex",
      "title": "My first experiences with Mistral Vibe; tips for use?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rds6ex/my_first_experiences_with_mistral_vibe_tips_for/",
      "author": "Mistral_user_TMP",
      "created_utc": "2026-02-24 20:46:46",
      "score": 26,
      "num_comments": 5,
      "upvote_ratio": 0.91,
      "text": "I'm running Vibe in an isolated environment. Using no after-install configuration, so with the default devstral-2 model. My experience:\n\n\\+ I like the user interface; it works smoothly.\n\nâˆ’ When I want to compare own code with a trusted (Jupyter-like) notebook, it either replaces the entire notebook or keeps the notebook in its original state. This happens repeatedly.\n\nâˆ’ While the Quickstart can be found [here](https://docs.mistral.ai/mistral-vibe/introduction/quickstart), detailed set-up info can be found in the [README](https://github.com/mistralai/mistral-vibe/blob/main/README.md). I find that a bit unclear; wouldn't the documentation website be a better fit?\n\nâˆ’ I was negatively surprised when Vibe/devstral-2 tried the following: \\`git reset HEAD\\`, thereafter commenting that the command was not very helpful. Surely, a development model should know better than that?!\n\n\n\nThe way things look right now, I think I would be better off using Codestral suggestions, and skipping the agentic factor. I already expected that working with agents would require some getting used to however, and I'm willing to try some more. Does anybody have recommendations for working with Vibe?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rds6ex/my_first_experiences_with_mistral_vibe_tips_for/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7arcj6",
          "author": "d9viant",
          "text": "It's a workhorse, use it DETERMINISTICALLY, be Explicit, it vibes slop really badly otherwise. A really good workhorse tho",
          "score": 3,
          "created_utc": "2026-02-25 09:28:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o77nmf7",
          "author": "cosimoiaia",
          "text": "While I agree that the documentation could definitely find a better place, I have very positive experiences with vibe.\n\nI don't think I can recall one instance where it used git commands without me mentioning first and only for consistency (like if I say twice that it should commit some changes then it starts to propose to do that by itself).\n\nI never tried Jupiter notebooks with it so I'm not sure how it handles that.\n\nUsually I try to give it very clear and short-ish prompts, I don't ask a lot of things at the same time and I make it write MD files to carry over work over different sessions. I also try to avoid to saturate or compress the context if I can, even if it usually handles that fairly well.\n\nMy main complaint about vibe itself is that it tends to be sluggish after a while and usually takes forever to restore a session.\n\nI personally like how devstral works the tasks, it keeps it short and to the point, sometimes to a fault and I wish it would go a bit further or be more proactive but on the other hand that does leave me more control so it's a trade-off that I can accept.",
          "score": 2,
          "created_utc": "2026-02-24 21:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7atd3z",
          "author": "whoisyurii",
          "text": "Be very precise with your tasks, and try to feed some additional info to it (I mean, for Claude Code sometimes plain english text is enough with no context attached).\n\nIt is called vibe but it is not yet a really 'vibe' tool, you gotta have some knowledge to co-operate with it. But FOR ME, that is even better - I like to interact with agent more and more.",
          "score": 2,
          "created_utc": "2026-02-25 09:47:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7wfgxg",
          "author": "Jbpin",
          "text": "Always ask him to run test and build to validate its changes as it will not do it by itself. Then plan and specs.",
          "score": 1,
          "created_utc": "2026-02-28 16:21:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rds0rr",
      "title": "Tip: You can create your own agents for Le Chat in Mistral's AI Studio",
      "subreddit": "MistralAI",
      "url": "https://console.mistral.ai/build/agents",
      "author": "Mistral_user_TMP",
      "created_utc": "2026-02-24 20:40:59",
      "score": 15,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rds0rr/tip_you_can_create_your_own_agents_for_le_chat_in/",
      "domain": "console.mistral.ai",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1rh01b3",
      "title": "Input tokens Cache",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rh01b3/input_tokens_cache/",
      "author": "agentgoose007",
      "created_utc": "2026-02-28 11:13:06",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hi! \n\nI guess it's a feature request for Mistral API.\nQuite often the prompts have a large static prefix + smaller dynamic part. Caching the input tokens would reduce the latency and the costs. \n\nFor the reference:\n https://developers.openai.com/api/docs/guides/prompt-caching/\n\nhttps://platform.claude.com/docs/en/build-with-claude/prompt-caching\n\n\nIs something like that planned for Mistral API? Can it be considered? \n\nThanks!\n\n\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rh01b3/input_tokens_cache/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7w3vmt",
          "author": "martinderm",
          "text": "They will have to implement it for agentic Systems",
          "score": 1,
          "created_utc": "2026-02-28 15:23:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1redfjf",
      "title": "iOS Features",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1redfjf/ios_features/",
      "author": "Perplexe974",
      "created_utc": "2026-02-25 13:37:42",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "Hello, \n\nI am in the process of de-googling my life and I started to use Le Chat - so far so good, Iâ€™m happy with the results. \n\nWhat i didnâ€™t expect to miss is the iOS widget, turns out I use those a lot and I am hoping itâ€™s an upcoming feature. \n\nDoes anyone know where i can find or request these kind of features ? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1redfjf/ios_features/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7bp9ji",
          "author": "KeyReindeer1046",
          "text": "make a home screen shortcut, works similar",
          "score": 4,
          "created_utc": "2026-02-25 13:44:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7c8hjj",
          "author": "LeRouxGongle",
          "text": "You can use the shortcut app. \nThis native app from Apple (always nice) can directly take action on your device. \nSadly, Mistral just lets us open the app and not more. Is that enough for you?",
          "score": 2,
          "created_utc": "2026-02-25 15:23:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7c9o7t",
              "author": "Perplexe974",
              "text": "I suppose I donâ€™t have much options lmao",
              "score": 2,
              "created_utc": "2026-02-25 15:29:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o7cbhnw",
          "author": "LoveInTheFarm",
          "text": "the iOs widget ??",
          "score": 1,
          "created_utc": "2026-02-25 15:37:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7ccxqc",
              "author": "Perplexe974",
              "text": "Yes, I would like an iOS widget to launch the app directly \n\nI was used to the one from Gemini, you could even take a picture from the widget and it attached itself directly to a prompt. Worked great and I miss it now that I use Mistral",
              "score": 2,
              "created_utc": "2026-02-25 15:44:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rcczpe",
      "title": "Mistral Vibe / Devstral became kinda dumb",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "author": "MiMillieuh",
      "created_utc": "2026-02-23 09:30:44",
      "score": 13,
      "num_comments": 14,
      "upvote_ratio": 0.93,
      "text": "Hello everyone.\n\nI've noticed recently (since Vibe 2.0) that Devstral has became way more dumb than it was when Vibe 1.x was around.\n\n* It's looping often.\n* It think it can't use certains tools (when it totally can).\n* It refuses to follow a prompt that tells it to test using some tools.\n\nI can go on...\n\nDid anyone noticed that too ?\n\nUsing Devstral in another tool than Vibe doesn't seem to help much (but still slightly better)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6xfh1z",
          "author": "pcx_wave",
          "text": "I've noticed it's a recurring bug that mistral can't seem to use it's tools. I always need to start a fresh convo saying 'use this now' to ensure it uses it.\nI've noticed such bugs in chatgpt as well...",
          "score": 9,
          "created_utc": "2026-02-23 10:07:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xkpwx",
              "author": "wish_I_knew_before-1",
              "text": "Oh well Claude needs to be reminded every single to read and adhere to rules in CLAUDE.md.",
              "score": 3,
              "created_utc": "2026-02-23 10:56:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xdlsn",
          "author": "skinney",
          "text": "I actually have the reverse experience. Devstral became much smarter than in Vibe 1.0.\n\nI don't have any of the problems you mention ðŸ¤·â€â™‚ï¸",
          "score": 8,
          "created_utc": "2026-02-23 09:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ypff6",
          "author": "ComeOnIWantUsername",
          "text": "I don't see these issues.\n\nThe only problem I had once or twice was that Vibe was trying to edit some file, applying edit failed, so it had to read the file again and only then was able to apply it ",
          "score": 3,
          "created_utc": "2026-02-23 15:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yucr0",
          "author": "Non_Professional_Web",
          "text": "For me Vibe always says that it can't search the web, I need to directly tell him to go and read his exact allowed tooling with indication of an actual path to the file.",
          "score": 3,
          "created_utc": "2026-02-23 15:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xdoqz",
          "author": "Charming_Support726",
          "text": "Not using Devstral in Vibe, but as model on API in one of my projects (for running my tests - because they are fast). \n\nI dont think so, but I noticed that both Devstral Models are extremely sensitive to their system and input promts. \n\nAnd I mean EXTREME \n\nI when there's an issue with the prompts or the tasks both tend to loop instead of stopping and saying \"Sorry Dave - Can't do this\"\n\nMaybe someone changed the system prompt in 2.0?",
          "score": 2,
          "created_utc": "2026-02-23 09:50:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zeq8v",
          "author": "Snickers_B",
          "text": "I have an Astro site and I had been using Mistral for blog uploads and publishing but it always gets it wrong.",
          "score": 2,
          "created_utc": "2026-02-23 17:18:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xbx0a",
          "author": "Kedf47",
          "text": "Hi, yes, I was asking myself the same thing this morning.Â ",
          "score": 1,
          "created_utc": "2026-02-23 09:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xkkh0",
          "author": "wish_I_knew_before-1",
          "text": "Yep. Not reading what I ask to read as background to analyse a file. To then provide best practice suggestions opposed to tailored solution.",
          "score": 1,
          "created_utc": "2026-02-23 10:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zgeyy",
          "author": "Gen5nake",
          "text": "I've noticedÂ  that as well. It was a better experience on V1.x for me.\nHe tends also to forget a lot of his context and task, even if it's less than half full.",
          "score": 1,
          "created_utc": "2026-02-23 17:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73hk19",
          "author": "Kriss-de-Valnor",
          "text": "I noticed that itâ€™s getting dumber when the context buffer is getting big (like over 60%) or after a long use. A restart with â€”continue often help",
          "score": 1,
          "created_utc": "2026-02-24 07:02:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75o5st",
          "author": "OkReference5581",
          "text": "Yep! Itâ€˜s crude. The code (py) isnâ€˜t well. Lot of bugs. Even simple code broken. Claude fixed it in 2 Minutes.",
          "score": 1,
          "created_utc": "2026-02-24 16:08:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z9gpj",
          "author": "NerasKip",
          "text": "Alwayse being dumb lol",
          "score": 0,
          "created_utc": "2026-02-23 16:54:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rf3vkl",
      "title": "Mistral Vibe vs Codex App + GPT-5.2 High or Gemini CLI + gemini-3.1-pro-preview ?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rf3vkl/mistral_vibe_vs_codex_app_gpt52_high_or_gemini/",
      "author": "Old-Glove9438",
      "created_utc": "2026-02-26 07:32:26",
      "score": 11,
      "num_comments": 10,
      "upvote_ratio": 0.76,
      "text": "How does Mistral Vibe compare with Codex App using GPT-5.2 High, or Gemini CLI using gemini-3.1-pro-preview ?\n\nI am quite satisfied with OpenAI and Google agentic coding platforms; how does Mistral do ? Anybody paid a subscription and tested it out? Potentially also interested in comparison against Claude Code, since it can be considered a leading solution together with Codex and Gemini as well (though I don't use it myself). ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rf3vkl/mistral_vibe_vs_codex_app_gpt52_high_or_gemini/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7h9s8a",
          "author": "victorc25",
          "text": "How does a rock compare to a sledgehammer?Â ",
          "score": 12,
          "created_utc": "2026-02-26 07:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hcq20",
          "author": "ComeOnIWantUsername",
          "text": "I can't say about Codex nor Gemini CLI, but I use both Vibe and Copilot CLI (with Claude Sonnet 4.6) and Vibe is noticeably worse. It's OK for the most of my needs, but sometimes it encounters a problem with something and is taking many steps in order to fix it (usually trying the same few things in a loop) and then I run Copilot CLI which fixes it on first try.",
          "score": 6,
          "created_utc": "2026-02-26 08:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hkt6x",
          "author": "Nervous_Sun4915",
          "text": "I have a hybrid approach on that, Claude or Codex for finding nasty bugs and boilerplate code, Vibe for unit tests and similar tasks that only involve one or two files. Unfortunately, Vibe isn't on the same level as the others, it constantly does things that I definitely didn't ask it to do or gets it wrong, even though other models seem to be perfectly fine with my instructions.",
          "score": 3,
          "created_utc": "2026-02-26 09:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7h8hcg",
          "author": "EzioO14",
          "text": "Nowhere near those on autonomous coding",
          "score": 6,
          "created_utc": "2026-02-26 07:41:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hcgmk",
          "author": "LowIllustrator2501",
          "text": "Can someone with experience explain what's the advantage of  using Claude code, Geminii CLI/ Codex/Vibe that are locked to a single model provider over [https://opencode.ai/](https://opencode.ai/) that allows me to use any existing model including local ones?  ",
          "score": 4,
          "created_utc": "2026-02-26 08:18:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7hdubj",
              "author": "schacks",
              "text": "OpenCode is nice, but I prefer KiloCode. [https://kilo.ai/install](https://kilo.ai/install)\n\n",
              "score": 4,
              "created_utc": "2026-02-26 08:32:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o7hi9mr",
                  "author": "LowIllustrator2501",
                  "text": "I didn't use kilo code at all. it seems it has less flexibility with models than opencode.\n\nAnyway - both tools allow selection of  model providers. That's the most important part.\n\nThe question remains - why most people use tool that force you into vendor locking?",
                  "score": 3,
                  "created_utc": "2026-02-26 09:15:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o7ho6pp",
          "author": "d9viant",
          "text": "I use em all ayyyy",
          "score": 1,
          "created_utc": "2026-02-26 10:12:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7hxprs",
          "author": "ashersullivan",
          "text": "vibe is noticeably faster than both codex and gemini cli with very good context awareness... great daily driver for most coding tasks but still a step behind claude code on the hardest problems.",
          "score": 1,
          "created_utc": "2026-02-26 11:36:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcbxp5",
      "title": "Model Aliases (23.02.2026)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rcbxp5/model_aliases_23022026/",
      "author": "VohaulsWetDream",
      "created_utc": "2026-02-23 08:25:05",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Findings reflect the state as of 2026-02-23\n\n\n## Model Aliases (base model -> aliases)\n\n| Base Model | Aliases |\n| :--- | :--- |\n| mistral-small-2506 | mistral-small-latest |\n| mistral-small-2501 | (deprecated 2026-02-28, replacement: mistral-small-latest) |\n| mistral-large-2512 | mistral-large-latest |\n| mistral-large-2411 | **no aliases, isolated model** |\n| mistral-medium-2508 | mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools |\n| mistral-medium-2505 | **no aliases, isolated model** |\n| codestral-2508 | codestral-latest |\n| open-mistral-nemo | open-mistral-nemo-2407, mistral-tiny-2407, mistral-tiny-latest |\n| ministral-3b-2512 | ministral-3b-latest |\n| ministral-8b-2512 | ministral-8b-latest |\n| ministral-14b-2512 | ministral-14b-latest |\n| devstral-small-2507 | **no aliases** |\n| devstral-medium-2507 | **no aliases** |\n| devstral-2512 | devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest |\n| labs-devstral-small-2512 | devstral-small-latest |\n| pixtral-large-2411 | pixtral-large-latest, mistral-large-pixtral-2411 |\n| magistral-small-2509 | magistral-small-latest |\n| magistral-medium-2509 | magistral-medium-latest |\n| mistral-embed-2312 | mistral-embed |\n| codestral-embed | codestral-embed-2505 |\n| mistral-moderation-2411 | mistral-moderation-latest |\n| mistral-ocr-2512 | mistral-ocr-latest |\n| mistral-ocr-2505 | **no aliases** |\n| mistral-ocr-2503 | (deprecated 2026-03-31, replacement: mistral-ocr-latest) |\n| voxtral-mini-2507 | voxtral-mini-latest (audio understanding) |\n| voxtral-mini-2602 | voxtral-mini-latest (transcription; note: alias conflict with above) |\n| voxtral-mini-transcribe-2507 | voxtral-mini-2507 |\n| voxtral-small-2507 | voxtral-small-latest |",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcbxp5/model_aliases_23022026/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1rgp0ie",
      "title": "Help! AI studio subscription vs. Le chat pro subscription?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rgp0ie/help_ai_studio_subscription_vs_le_chat_pro/",
      "author": "Acolitor",
      "created_utc": "2026-02-28 01:15:12",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.77,
      "text": "Hey,\n\n  \nI don't exactly understand what does the Le chat pro subscription do for me? Does it only increase usage in the le chat platform or does it increase usage in other ways too? I am interested in Codestral and using different Mistral models, but I am only familiar with Le Chat. I don't want to pay for use, but I could pay a monthly pro subscription if it gave me more usage on all the models and through all endpoints.\n\nSo essentially, what is the difference between having Le chat pro and the \"scale\" plan in AI studio? And what happens if I have le chat pro but the free experiment plan on AI studio? What even is AI studio, isn't it supposed to be la plateforme anyways?\n\nMistral's documentation is so hard to understand. I don't even know what I would be paying for",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rgp0ie/help_ai_studio_subscription_vs_le_chat_pro/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o7t2kwx",
          "author": "Ndugutime",
          "text": "Pro is only useful for vibe use at moment. \n\nIf you have a developer key. Probably ok if you donâ€™t abuse \n\nSee my article on mistral vibe\n\nhttps://medium.com/@jallenswrx2016/the-mistral-vibe-a17b5907a51a?sk=c458be9c69e7b383f14c1f7870b8cf6b",
          "score": 1,
          "created_utc": "2026-02-28 01:43:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o7t6sox",
              "author": "Acolitor",
              "text": "Would vibe be useful for me when I have mandatory windows on my work computer, I mainly code in R and our work has strict system control for software...",
              "score": 1,
              "created_utc": "2026-02-28 02:09:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o7t7sj7",
                  "author": "Ndugutime",
                  "text": "Well, like most workplaces.  You need to verify that vibe is a tool you can use.   At my workplace we are supposed to use windsurf.  \n\nBut alas.  I canâ€™t say I have used Devstral for R coding.  Mostly Python and C.",
                  "score": 2,
                  "created_utc": "2026-02-28 02:15:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}