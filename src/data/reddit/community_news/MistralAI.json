{
  "metadata": {
    "last_updated": "2026-02-20 09:08:33",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 173,
    "file_size_bytes": 203820
  },
  "items": [
    {
      "id": "1r64huf",
      "title": "Mistral already generates more revenue than Grok.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r64huf/mistral_already_generates_more_revenue_than_grok/",
      "author": "Nefhis",
      "created_utc": "2026-02-16 08:46:44",
      "score": 901,
      "num_comments": 40,
      "upvote_ratio": 0.98,
      "text": "\n\n**English summary of the Xataka article (Summary by Le Chat):**\n\nMistral AI, the Paris-based startup, is quietly achieving remarkable growth without the typical hype surrounding AI companies. Unlike its competitors, Mistral has avoided inflating stock prices but now generates more revenue than Elon Musk‚Äôs Grok. According to CEO Arthur Mensch, Mistral‚Äôs annualized revenue run rate has surged from $20 million to over $400 million in just one year‚Äîa twentyfold increase. The company, valued at ‚Ç¨12 billion in 2025, is on track to exceed $1 billion in annual recurring revenue by the end of 2026, driven by its focus on European technological sovereignty.\n\nMistral‚Äôs strategy centers on serving enterprise clients rather than end users, positioning itself as the go-to alternative for European businesses seeking independence from U.S. or Chinese AI infrastructure. With over 100 major corporate clients, including ASML, TotalEnergies, HSBC, and governments like France, Germany, and Greece, 60% of its revenue comes from Europe. Its appeal lies in offering locally hosted, low-emission AI solutions, aligning with Europe‚Äôs push to reduce reliance on foreign tech giants.\n\nThe company recently announced a ‚Ç¨1.2 billion investment in a new data center in Sweden, its first outside France, set to open in 2027. Sweden was chosen for its affordable, low-carbon energy, reinforcing Mistral‚Äôs commitment to sustainable, sovereign AI infrastructure. Mensch criticized the trend of U.S. hyperscalers building data centers in Europe, arguing that such projects primarily benefit American companies rather than European interests.\n\nMistral‚Äôs success is underpinned by its unique position as Europe‚Äôs only major developer of foundational large language models (LLMs). While it collaborates with global players like Microsoft and NVIDIA, its core mission remains empowering European autonomy in AI. As Mensch stated, Europe‚Äôs excessive dependence on U.S. digital services has reached a critical juncture, and Mistral provides a viable, independent alternative.\n\nBy combining rapid expansion with a principled stance on data sovereignty, Mistral is reshaping the AI landscape‚Äîproving that discretion and strategic focus can outperform noise.  \n  \n[https://www.xataka.com/robotica-e-ia/mistral-ia-que-mejor-esta-jugando-sus-cartas-porque-esta-aprovechando-fiebre-soberania-tecnologica-europea](https://www.xataka.com/robotica-e-ia/mistral-ia-que-mejor-esta-jugando-sus-cartas-porque-esta-aprovechando-fiebre-soberania-tecnologica-europea)\n\n[https://x.com/paulbz/status/2021537295883481437](https://x.com/paulbz/status/2021537295883481437)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r64huf/mistral_already_generates_more_revenue_than_grok/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5njnfx",
          "author": "NoWayYesWayMaybeWay",
          "text": "Great shit. Love Mistral ü´∂",
          "score": 65,
          "created_utc": "2026-02-16 08:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nj591",
          "author": "30wolf03",
          "text": "nice",
          "score": 33,
          "created_utc": "2026-02-16 08:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5njgxk",
          "author": "Lynxbro",
          "text": "Oui oui baguette.",
          "score": 109,
          "created_utc": "2026-02-16 08:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o45ol",
              "author": "ChatDuFusee",
              "text": "BAG-WET?",
              "score": 2,
              "created_utc": "2026-02-16 12:01:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nlwxc",
          "author": "frederick1024",
          "text": "Bravo. On croise les doigts pour la suite !",
          "score": 22,
          "created_utc": "2026-02-16 09:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nlib2",
          "author": "So_andy",
          "text": "Let‚Äôs go Europe and Mistral üöÄ Also don‚Äôt forget about small users",
          "score": 36,
          "created_utc": "2026-02-16 09:14:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nsikz",
          "author": "dharmoslap",
          "text": "Europe is indeed in the race as well. \n\nLet‚Äôs also keep in mind that LLMs are getting smarter with feedback, which these days have to come from users as well.\n\nSo whoever sends feedback on answers while using Le Chat is providing Mistral something crucial.",
          "score": 27,
          "created_utc": "2026-02-16 10:20:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rfncc",
              "author": "Swat_katz_82",
              "text": "At work we evaluate quite a few vendors for our in-house solutions, and mistral falls short everytime.\n\n\nIt baffles me, that mistral seems to be growing.¬†\n\n\nI'd love an euro company being rivals to openai or American tech, but¬† mistral doesn't seem like it.¬†",
              "score": 2,
              "created_utc": "2026-02-16 22:07:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o686oyy",
                  "author": "vienna_city_skater",
                  "text": "A lot of the specialized models outperform the US competitors, e.g. voxtral. Also its way cheaper and not every task needs einstein level reasoning, speed and cost often win in real world scenarios beyond software development. And governments don‚Äôt like to use overseas tech, so Mistral is the only real choice anyway.",
                  "score": 2,
                  "created_utc": "2026-02-19 11:53:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5nud1y",
          "author": "Joddie_ATV",
          "text": "Kudos to the developers and the entire Mistral.AI team! You can be proud of yourselves! And frankly, it's well deserved... Keep up the good work!",
          "score": 7,
          "created_utc": "2026-02-16 10:37:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5noso1",
          "author": "AppropriateViking",
          "text": "Great news üî•",
          "score": 4,
          "created_utc": "2026-02-16 09:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nk4ke",
          "author": "SnooBunnies725",
          "text": "[HERE ](https://archive.is/20260211095728/https://www.ft.com/content/664249e7-e8d5-4425-b397-ad3ed590b305#selection-1954.0-1954.3)is a link to an English-language (non-paywalled) article on the FT.",
          "score": 6,
          "created_utc": "2026-02-16 09:00:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o5q99",
              "author": "beniguet",
              "text": "It's a paywalled article from the FT... \n\nYou link to a loophole to access it not-on-the-FT without paying its publisher, though.\nNot judging, just being pedantically precise.",
              "score": 1,
              "created_utc": "2026-02-16 12:13:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nu7ub",
          "author": "Ill-Bison-3941",
          "text": "Mistral is also doing their bit by releasing local models ‚ù§Ô∏è",
          "score": 8,
          "created_utc": "2026-02-16 10:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o4gku",
          "author": "Shirirubboy",
          "text": "What a pleasant read! So glad that Mistral is faring much better than grok. Well done Mistral!",
          "score": 2,
          "created_utc": "2026-02-16 12:04:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61ndi5",
          "author": "Yavanaril",
          "text": "I am a satisfied paying Mistral customer.  \n\n- EU privacy compliance \n- EU technology sovereignty \n- It does what I need\n- it supports my business \n- Maybe it can help me get off my lazy butt and even grow my business",
          "score": 2,
          "created_utc": "2026-02-18 12:58:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6876yz",
          "author": "vienna_city_skater",
          "text": "No wonder, who would use AI trained on Musks X posts for anything serious?",
          "score": 2,
          "created_utc": "2026-02-19 11:57:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68spxi",
              "author": "Nefhis",
              "text": "That's exactly what I thought ü§£ü§£ü§£",
              "score": 1,
              "created_utc": "2026-02-19 14:13:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nxt3h",
          "author": "Select_Ad_390",
          "text": "That‚Äôs amazing! But also, can we get Large 3 in Le Chat?",
          "score": 3,
          "created_utc": "2026-02-16 11:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5npp6g",
          "author": "TwoRight9509",
          "text": "Didn‚Äôt grok transition from being an ai in order to become its real dream - the autonomous driver of a robo taxi?",
          "score": 2,
          "created_utc": "2026-02-16 09:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oujr5",
          "author": "Etzello",
          "text": "I really wish they would fix it not showing sources when it searches web, spoke to them months ago about it and others confirmed the issue too",
          "score": 1,
          "created_utc": "2026-02-16 14:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q95j9",
          "author": "Old_Librarian__",
          "text": "I would use it more if it didn't keep giving me the massage limit reached :( Hope the new data centers changes something ",
          "score": 1,
          "created_utc": "2026-02-16 18:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qf0m3",
          "author": "mrSalema",
          "text": "Fantastique. Un croissant sil vous plez",
          "score": 1,
          "created_utc": "2026-02-16 19:08:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rxiwj",
          "author": "Confident-Village190",
          "text": "If only it were graphically depixelated...\nAnd hoping that at the IPO they kick out the US VCs and bring in European capital.",
          "score": 1,
          "created_utc": "2026-02-16 23:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nwq9f",
          "author": "Makaron8080",
          "text": "Even with this Mistral is not a profitable company. \nI think this is what will make a difference to AI companies that make profit or at least break even, or not.",
          "score": 1,
          "created_utc": "2026-02-16 10:58:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qtqct",
              "author": "skate_nbw",
              "text": "They are pretty healthy and prepared for the popping bubble. Not many will come out on the other side, Mistral will.",
              "score": 5,
              "created_utc": "2026-02-16 20:20:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5otkbz",
              "author": "blakesnake86",
              "text": "Not profitable yet, but still on a better trajectory than OpenAi who is burning through cash at an insane rate for results that aren't really any better.",
              "score": 6,
              "created_utc": "2026-02-16 14:38:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o688gg7",
                  "author": "vienna_city_skater",
                  "text": "They are better, but not by the amount of money they are putting in. However, their marketing is much stronger. Now with Antropic joining the marketing wars, this might change, since people become aware there is more than ChatGPT. So they might eventually stumble upon Le Chat and discover we have good tech in Europe as well.",
                  "score": 2,
                  "created_utc": "2026-02-19 12:06:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5poi2x",
          "author": "victorc25",
          "text": "You‚Äôre comparing a company (Mistral) against a model (Grok)? xAI‚Äôs annualized revenue was already $1.2 billion in 2025, more that Mistral‚Äôs target for 2026, what numbers are you using? ü§î¬†https://growjo.com/company/xAI",
          "score": 1,
          "created_utc": "2026-02-16 17:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rncbc",
          "author": "alunare",
          "text": "Let me translate: Mistral is subsidized by Europe. Reality is it is way underpowered compared to its revivals.",
          "score": 1,
          "created_utc": "2026-02-16 22:47:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o688yn8",
              "author": "vienna_city_skater",
              "text": "Pretty much every AI company is largely subsidized by some government these days. Isn‚Äôt X.ai subsidized by the US government? AI is becoming infrastructure, so this makes absolute sense.",
              "score": 1,
              "created_utc": "2026-02-19 12:10:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5otbmw",
          "author": "Gold-Guess4651",
          "text": "I hate to say it but I went back from Mistral to CGPT. The performance difference was so large that I could not justify sticking with the payed version of le chat. I'll definitely be back once Mistral gets better though.",
          "score": 0,
          "created_utc": "2026-02-16 14:36:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5p2lrg",
              "author": "-Crash_Override-",
              "text": "Its always an unpopular opinion around here, but this is very much the case.\n\nI had used mistral a good bit maybe a 9-12 mo ago, amd it was ok at the time. I decided to revisit last night and it is many orders of magnitude behind the flagships. I put my T1s as Claude and Gemini, T2s as CGPT and grok, T3s as DS, K2.... mistral feels solidly in a T4 category pushing to get into T3. \n\nIm rooting for it, and theyre doing great things with the budget they have, but its a ways off still.",
              "score": 1,
              "created_utc": "2026-02-16 15:24:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o68a4vf",
              "author": "vienna_city_skater",
              "text": "The chat is fine, but Opus and Codex outperform Mistrals models by miles on agentic use. However, as we see with Chinese companies, this can change quickly and often good enough with proper privacy policies is enough to convince people over. Also worth noting is that their specialized models often outperform the models of the big three, both in price and performance.",
              "score": 1,
              "created_utc": "2026-02-19 12:19:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o77g5",
          "author": "Thisismyotheracc420",
          "text": "Good on them, just don‚Äôt forget both of these are private companies, and are not legally obliged to report any (correct) numbers.",
          "score": 0,
          "created_utc": "2026-02-16 12:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7zd3",
          "author": "Many-Ad-3228",
          "text": "Nice",
          "score": 0,
          "created_utc": "2026-02-16 12:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ofufr",
          "author": "jjw_kbh",
          "text": "Love this!\n\n#eutechstack",
          "score": 0,
          "created_utc": "2026-02-16 13:22:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pdzf5",
          "author": "Emotional-Mine-1495",
          "text": "They should go public",
          "score": 0,
          "created_utc": "2026-02-16 16:18:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nw76v",
          "author": "Prior-Task1498",
          "text": "Tbf that's a low bar. Ai gets a lot of investment capital but actual revenue is very low",
          "score": -3,
          "created_utc": "2026-02-16 10:54:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7bcrx",
      "title": "Mistral acquires Koyeb",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7bcrx/mistral_acquires_koyeb/",
      "author": "Nefhis",
      "created_utc": "2026-02-17 16:47:20",
      "score": 154,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "From Mistral‚Äôs LinkedIn:\n\n[https://www.linkedin.com/posts/mistralai\\_were-very-happy-to-announce-our-first-acquisition-activity-7429540140622012416-tbpT](https://www.linkedin.com/posts/mistralai_were-very-happy-to-announce-our-first-acquisition-activity-7429540140622012416-tbpT)\n\n‚Äî-\n\nWe‚Äôre very happy to announce our first acquisition as we‚Äôve entered a definitive agreement to acquire Koyeb, a pioneer in serverless cloud services.\n\nThis strategic move strengthens our Compute capabilities and accelerates our mission to build a full-stack AI champion.\n\nüîπ Why Koyeb? Their high-performance serverless platform empowers developers to run and scale AI applications without infrastructure hassles. It‚Äôs a perfect fit for Mistral AI‚Äôs sandboxes, MCP servers, and on-premises deployments.\n\nüîπ What‚Äôs next? Koyeb‚Äôs team of 16 talented engineers, including its three co-founders, will join Mistral in March 2026. Together, we‚Äôll optimize GPU usage, enhance inference scaling, and push the boundaries of AI-native applications.\n\nThis is just the beginning. Stay tuned for more innovations as we combine forces to shape the future of AI infrastructure!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7bcrx/mistral_acquires_koyeb/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5w76y4",
          "author": "LeRouxGongle",
          "text": "This is really good news on many fronts! Firstly, they will become even more powerful, and secondly, they now have another source of revenue. \nWhat are you thinking about it ?",
          "score": 18,
          "created_utc": "2026-02-17 17:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5w8fu0",
              "author": "LowB0b",
              "text": "on-premise deployments is what has me most excited. I \\_really\\_ dislike the direction openai / anthropic are heading (they own models + datacenters), whereas a company distributing models fit for different ty√®es of businesses profits everyone.\n\nEPFL has also come out with something for enterprises to more easily depliy on-premise AI (https://anyway.systems/) however I have no idea how up-to-date they are with agent orchestration considering how new that is",
              "score": 8,
              "created_utc": "2026-02-17 17:07:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o61bowj",
                  "author": "DerpSenpai",
                  "text": "Enterprise deployments are mostly on Azure/AWS/Google. For Mistral, Compute is more important in B2C and Goverment. On-Prem is the way for all goverments as well. Big companies use normal Azure Studio and stuff like that for their deployments, but it's a matter of time till stuff like Openshift AI gets bigger",
                  "score": 1,
                  "created_utc": "2026-02-18 11:37:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5wdje5",
              "author": "Nefhis",
              "text": "In my opinion, better performance and greater sovereignty. That alone makes it worthwhile.",
              "score": 8,
              "created_utc": "2026-02-17 17:32:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5wg6ko",
          "author": "guyfromwhitechicks",
          "text": "You should consider cleaning the shared link, friend. Everything after the ? should be removed unless you want a bunch of randoms to be associated with you on LinkedIn.",
          "score": 13,
          "created_utc": "2026-02-17 17:44:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5whxa2",
              "author": "Nefhis",
              "text": "Thanks! I was on the cellphone and it wasn't easy üòÖ",
              "score": 7,
              "created_utc": "2026-02-17 17:52:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5wuy2m",
                  "author": "guyfromwhitechicks",
                  "text": "Replace the current link with this: https://www.linkedin.com/posts/mistralai_were-very-happy-to-announce-our-first-acquisition-activity-7429540140622012416-tbpT\n\nYours has a forward slash that breaks the link.",
                  "score": 5,
                  "created_utc": "2026-02-17 18:52:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5wbod7",
          "author": "jedisct1",
          "text": "Way to go!",
          "score": 13,
          "created_utc": "2026-02-17 17:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wd63o",
          "author": "pas_possible",
          "text": "üò≤üòÆ I was not expecting that",
          "score": 5,
          "created_utc": "2026-02-17 17:30:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wlrth",
          "author": "pkk888",
          "text": "Idk what they do! But I am all for it when its Mistral!! So I could buy a GPU, and have Le Chat run on this inside my company? Is that what they do?",
          "score": 3,
          "created_utc": "2026-02-17 18:10:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wnw6v",
              "author": "Nefhis",
              "text": "Well‚Ä¶ not exactly ‚Äúinstall Le Chat like an app on a single GPU,‚Äù but the idea is close.\n\nToday Mistral already offers enterprise/private deployments where you run Mistral models inside your own infrastructure (on-prem or in a controlled/sov cloud), with a ‚Äúchat for companies‚Äù experience (Le Chat Enterprise / private stack). In practice it‚Äôs usually a packaged enterprise solution with auth, logging, governance, etc.√±, not the public Le Chat UI.\n\nBuying Koyeb likely helps Mistral on the infrastructure side (deployment, scaling, reliability), making those private/managed deployments easier and more ‚Äúfull-stack.‚Äù",
              "score": 6,
              "created_utc": "2026-02-17 18:20:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5x6f3k",
          "author": "bootlickaaa",
          "text": "Cool but hoping not to get exposed to US servers for privacy and sovereignty reasons.",
          "score": 3,
          "created_utc": "2026-02-17 19:46:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xksdq",
              "author": "SkyPL",
              "text": "Not sure what you mean? Koyeb is a french company, their entire team is European, they fall under French law.",
              "score": 6,
              "created_utc": "2026-02-17 20:54:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5xlegt",
                  "author": "bootlickaaa",
                  "text": "Oh that is a relief! I had just done a quick check on LinkedIn for them and it showed NYC so had just assumed. Looking deeper on their legal pages I see you are right, thanks.",
                  "score": 3,
                  "created_utc": "2026-02-17 20:57:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60cavp",
          "author": "touristtam",
          "text": "Why direct people to this god-forsaken place instead of a _news_ outlet? https://techcrunch.com/2026/02/17/mistral-ai-buys-koyeb-in-first-acquisition-to-back-its-cloud-ambitions/",
          "score": 2,
          "created_utc": "2026-02-18 06:21:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r86xcy",
      "title": "Support an initiative that helps Mistral, other European AI companies, and yourself",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r86xcy/support_an_initiative_that_helps_mistral_other/",
      "author": "Silver_Procedure538",
      "created_utc": "2026-02-18 16:03:00",
      "score": 103,
      "num_comments": 36,
      "upvote_ratio": 0.96,
      "text": "AI is taking up more and more space in our lives, and we want it to improve our lives, not make it worse.\n\nEuropean governments are not taking the necessary measures to compete in the AI field: startups like Mistral are greatly underfunded compared to American counterparts.\n\nWe have launched a petition with a concrete plan to fund European AI companies (including Mistral), by creating a sovereign fund at European (and beyond) level. Mistral itself owes part of its success to a similar investment scheme (with Bpifrance), at French level. We want to replicate it at a higher scale.\n\nPlease sign it if you agree: [openpetition.eu/!swjml](http://openpetition.eu/!swjml)\n\nLeaving the AI control to foreign powers will not do any good to us: AI is coming, we want it or not. We need to ensure it benefits us all.\n\nApart from helping AI companies, this would also increase the chance of a better life for yourself: AI will play a bigger and bigger part in our lives, and this initiative gives you a say on how it is developed.\n\nMe and the rest of the team are volunteer, we don't plan to get a profit for ourselves.\n\nI'm available for any question you may have, and I hope this is not considered spam.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r86xcy/support_an_initiative_that_helps_mistral_other/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o62uxna",
          "author": "EveYogaTech",
          "text": "Boy I'm all for sovereign AI (having my own startup as well), but are you really asking for 1% GDP of all EU countries here?\n\n\"Each participating country could contribute: Up to 1% of its GDP per year, for 3 years, voluntarily.\"\n\nWhat might work better is to somehow get into the Angel Investor / VC investment ecosystem and connect this possibly also with EU financing to fund selected startups.\n\nHowever I am totally for any type of structure that actually works. It's just that it's possibly way more feasible (even though also very ambitious) to create your own fund VS selling entire sovereign countries the idea of 1% GDP.\n\nAnyway good luck on this, its a good mission.",
          "score": 6,
          "created_utc": "2026-02-18 16:35:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62y6mn",
              "author": "MrSpotgold",
              "text": "Make it part of defense spending.",
              "score": 6,
              "created_utc": "2026-02-18 16:50:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63gnsn",
                  "author": "Silver_Procedure538",
                  "text": "I agree, that would be a good way of framing it.",
                  "score": 2,
                  "created_utc": "2026-02-18 18:12:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62xd89",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment!\n\nI thought a lot about the amount of money involved and you are right to question the 1% of GDP.  \nMy reasons:\n\n\\- it's up to 1%, I would be happy also with 0.5%  \n\\- if AI is recognized as a strategic priority I don't think it's a lot  \n\\- for example for Italy 1% of GDP would be \\~20 billions, which is a lot, but not unheard of. Major infrastructure projects (railway tunnel, Messina's bridge, etc..) could cost 10 billion or so. Recently there was the superbonus which costed 100+ billions to help renovate <1% of the buildings in the country.  \n\\- Financially a state fund (similar to the Norway one) is much more profitable than VC fund. The state will get back TVA, employees taxes, taxes of energy, etc..  \n\\- It will also attract a lot of private investment -> more taxes\n\nTo make a parallel with the COVID crisis, **Italy received 200+ billion of PNRR funds from Europe**. Arguably, I think AI will have an at least similar impact.\n\nOf course a state fund is less efficient than a VC, but I see it very difficult to lose money on it. Correct me if I'm wrong.\n\nCan you elaborate more on the \"get into the Angel Investor / VC investment ecosystem and connect this possibly also with EU financing to fund selected startups\"?\n\nThe reason why I believe that a government fund is necessary is that ChatGPT is 3+ years old and no major investment happened yet in Europe. There are no reasons to believe this is going to change.\n\nWhat do you think?",
              "score": 6,
              "created_utc": "2026-02-18 16:46:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o630xob",
                  "author": "EveYogaTech",
                  "text": "üëç A good place to start is https://tech.eu\n\nFor the other matter, I think it will be so much easier and more feasible for you if you truly control the fund.",
                  "score": 3,
                  "created_utc": "2026-02-18 17:02:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o648djj",
              "author": "Prinzmegaherz",
              "text": "Tbh. If we rely on Angel investors, it will just be another AI owned by rich people. What would be the point?",
              "score": 1,
              "created_utc": "2026-02-18 20:17:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o633c95",
          "author": "mowilllll",
          "text": "ü§î to mutch personal information was needed to fill in the petition",
          "score": 1,
          "created_utc": "2026-02-18 17:13:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63dvj5",
              "author": "Silver_Procedure538",
              "text": "Thanks for the feedback.\n\nIs it too much privacy wise?\n\nUnfortunately it is quite the standard for the petition to be recognized and GDPR rules impose mail confirmation :/\n\nI don't see the personal information you enter (no address) and OpenPetition is the best petition provider I found.",
              "score": 1,
              "created_utc": "2026-02-18 18:00:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66dsd2",
          "author": "CodeBlurred",
          "text": "Europe, unfortunately, is not the United States. Europe is like Medusa, the goddess with many little heads. It‚Äôs unfortunate that they don‚Äôt want to support a model made in France. I asked Mistral why, and the AI informed me that it would ruin European models. Lack of commitment.",
          "score": 1,
          "created_utc": "2026-02-19 03:03:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68bdma",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment. What do you think of our proposal?",
              "score": 1,
              "created_utc": "2026-02-19 12:27:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6774um",
          "author": "zuLunis",
          "text": "Dovrebbero per√≤ prima essere bloccate le aziende da possibili fusioni o acquisti da aziende estere. Se devo investire soldi europei per la sovranit√† IA, devo essere sicuro che domani nessuno possa acquistarla",
          "score": 1,
          "created_utc": "2026-02-19 06:28:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68b8sd",
              "author": "Silver_Procedure538",
              "text": "Si, sono d'accordo. Spero che almeno questo i nostri politici l'abbiano capito.",
              "score": 1,
              "created_utc": "2026-02-19 12:26:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67uoa0",
          "author": "Dalamart",
          "text": "Aren't we all just fed up of AI being everywhere?  \nI think there are many noble and useful things to fund and support (how about education, housing, etc). And I don't think Mistral needs this kind of help. Also they have some sort of partnership with TotalEngergies, so No thanks!",
          "score": 1,
          "created_utc": "2026-02-19 10:08:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68b5ju",
              "author": "Silver_Procedure538",
              "text": "Mistral, to compete, desperately needs financial help.\n\nA part from that, I see your point about being fed up of AI.\n\nBut, if AI will be so important and will change our lives, what is our best option? I believe that it is to develop AI here, we like it or not.",
              "score": 1,
              "created_utc": "2026-02-19 12:26:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o62or3r",
          "author": "t0m4_87",
          "text": "the current AI won't solve our problem, we need new research and not inflate the current bubble\n\nhttps://youtu.be/z3kaLM8Oj4o",
          "score": 1,
          "created_utc": "2026-02-18 16:07:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62r1wr",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment.\n\nAssuming we are in a financial bubble (which is all but guaranteed), this initiative does not inflate it:\n\n\\- realistically it will take no less than 1-2 years being optimistic to see it applied  \n\\- total amounts are a lot, but still less than what you see in the US\n\nAlso European companies are behind, and we need to reverse this trend, whatever it takes. I would love to be in a bubble with a European company leading the way in AI.\n\nRemember that it is a financial bubble, not a technology bubble (like metaverse)",
              "score": 5,
              "created_utc": "2026-02-18 16:17:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o632kbo",
                  "author": "Lkrambar",
                  "text": "So you‚Äôre assuming we are in a bubble but your solution is to keep inflating it to make sure that when it pops we can say that we participated? What‚Äôs the logic?\n\nTo be clear: the only thing this can achieve is inflating the bubble because like everything in science, pushing 200 x more money into the pockets of researchers does not speed up the time to discovery by 200x‚Ä¶ \n\nMore funding mainly means more compute capacity and if anything, Chinese models are proving that the race is only about who has the biggest model if you want it to be: the latest progress were made more on the inference cost and that‚Äôs how models like Qwen, Kimi or Deepseek manage to dominate by pushing SOTA performance at ridiculous prices.",
                  "score": 0,
                  "created_utc": "2026-02-18 17:09:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o62yjg7",
                  "author": "t0m4_87",
                  "text": "I didn't mean financial bubble. I mean that current AI's are foundationally bad for long term.\n\nWe need to research how else can AIs be created (all current ones are based on some google research from the 90s I think).\n\nSo dunno. In the US the competitors are circlejerking basically to inflate investments and hike stock prices but the tech is by design not good for the long run.\n\nIt'd be awesome if said research would be done in EU and we'd have a breakthrough.",
                  "score": -1,
                  "created_utc": "2026-02-18 16:51:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62xzh5",
              "author": "Old-Age6220",
              "text": "I kind of agree... Europe is behind, a lot, with current type of AI (excluding image gen / Bfl). Catching that up might not be the best option, or even possible. But if you re-invent the current way of doing ai, including the infrastructure bottlenecks etc, it would be money well spent",
              "score": 3,
              "created_utc": "2026-02-18 16:49:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o631q73",
                  "author": "t0m4_87",
                  "text": "Exactly, then EU would be AI leader also. I think everything else we have in place, we need the best researches on the case STAT.",
                  "score": 1,
                  "created_utc": "2026-02-18 17:06:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o63xyf8",
          "author": "teilifis_sean",
          "text": "I gave Mistral a go. Signed up for premium to help support the EU tech scene. Left the subscription go for over a year. I think 14 months. During this time I'm playing around with a bunch of LLM clients. \n\nOne day I hit a limit that shouldn't have been on the premium tier. So I reported it to customer support. The lady explained that because I missed a payment early on like 2 months in that I hadn't be getting premium since then even though they were taking money every month that was precisely for premium. She told me I had to pay the missing month but they way I saw it was I had paid that fee 12 times over. \n\nSo they took over year of payments for premium without providing it. I just found that to be an inexplicably negative experience so shut down the account and then bought a Claude Code max subscription. \n\nI really do have high hopes for the EU tech scene to improve but quite honestly we do need to learn a lot from the Americans about providing customer service. People joke about cashiers etc being overly friendly and fake or whatnot and I get that but Christ that was just poor on Mistrals part. If they had of offered me something I would be still subscribing today but I just feel so bitter about the whole thing. If you miss a Spotify payment they shut off your premium service but don't keep taking money for premium you just get bumped down to free.",
          "score": 0,
          "created_utc": "2026-02-18 19:29:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63yke7",
              "author": "Silver_Procedure538",
              "text": "Yeah I agree. In particular at this stage where customer retention matters so much.\n\nLet's hope for future improvements.",
              "score": 1,
              "created_utc": "2026-02-18 19:32:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64yxl3",
          "author": "Armadilla-Brufolosa",
          "text": "Ho tolto l'abbonamento a Mistral perch√© non mi pare che, come scelte aziendali per il futuro, vogliano prendere una strada migliore rispetto alle altre. \n\nDici che le AI faranno sempre pi√π parte delle nostre vite, e che sono importanti per il nostro futuro: io non potrei essere pi√π d'accordo su questo... \nMa dunque? \nN√© Mistral n√©, tantomeno, il parlamento Europeo sta minimamente tenendo in considerazione una AI a misura d'uomo. \nPerch√©, per farlo, dovrebbero finalmente decidersi a guardare, con studi seri ed onest√† ,le menti risonanti umane, e non solo grafici e algoritmi. \n\nSino a quando non faranno questo, puoi dargli tutti i soldi che vuoi, li butteranno nel wc per creare l'ennesima AI agentica che ti fa il caff√® la mattina, ma ti rende incapace di ragionare. \nEsattamente come gli Americani o i Cinesi. \n\nAnche l'Europa sar√† censoria, bigotta e con un capillare controllo di massa... solo che lo fa usando come scusa i bambini.\nIl ch√© √® ancora pi√π squallido. \n\nFacciano finalmente qualcosa di veramente innovativo, sia a livello sociale che pratico... Allora s√¨ che varrebbe la pena finanziarli.",
          "score": 0,
          "created_utc": "2026-02-18 22:20:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68awoc",
              "author": "Silver_Procedure538",
              "text": "Grazie per il commento! \n\nIo penso che purtroppo, **al momento**, non abbiamo il lusso di poter decidere dove orientare la tecnologia.\n\nPerch√© non siamo noi a svilupparla.\n\nPer svilupparla abbiamo bisogno di finanziamenti (√® questo che vogliamo), e quanto saremo a pari di OpenAI/Anthropic/DeepSeek a quel punto potremo tenere in considerazione una AI a misura d'uomo.\n\nInoltre, **essendo finanziamenti pubblici, ci sar√† una buona possibilit√† di controllare l'AI**, perch√© parte della propriet√† delle aziende AI sar√† pubblica. \n\nMolto pi√π che non lasciando tutto a investimenti privati di pochi.\n\nCosa ne pensi?",
              "score": 1,
              "created_utc": "2026-02-19 12:24:35",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3t4zd",
      "title": "Got any Vibe feature requests for the team?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/67xxcv0bcajg1.gif",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-13 16:05:36",
      "score": 81,
      "num_comments": 50,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3t4zd/got_any_vibe_feature_requests_for_the_team/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o56q39s",
          "author": "AdIllustrious436",
          "text": "What I'd prioritise on the roadmap:\n\n\n- Parallel sub-agent execution ‚Äî coupled with stronger agentic context retrieval prompting in the system prompt to improve codebase discovery without context flooding.\n\n\n- Thread revert/fork ‚Äî ability to roll back to a previous state or branch off into an alternate direction mid-conversation.\n\n\n- Git status integration ‚Äî surface diff stats (+X/‚àíY lines), current branch etc. \n\n\n- Web search integration ‚Äî fetch alone isn't enough; the agent currently has to guess URLs, which fail more often than not. A proper websearch sub-agent with actual query capabilities would let it find relevant sources first, then fetch.\n\n\n- Smarter plan mode ‚Äî Better guidelines in system prompt, auto-clear stale context once a plan is approved, so execution starts with a clean, focused window.",
          "score": 30,
          "created_utc": "2026-02-13 16:19:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58qhtl",
              "author": "nunodonato",
              "text": "Yes, basically copy Claude code üòÖ I vote for all of these features, especially plan and web search",
              "score": 5,
              "created_utc": "2026-02-13 22:12:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56wges",
          "author": "grise_rosee",
          "text": "Sorry for the lake of hype, but as a casual user, I'd prefer bugfixes first:\n\n\\- The TUI is extremely sluggish after a few pages of work history. It's unrelated to the model perfs. I can't be alone having this issue.\n\n\\- The model often doesn't understand that if its editing proposal was canceled, the changes have not been done! Lot of tokens are lost reverting changes that don't exit.\n\n\\- The model makes a plan for its first goal, then mostly leave it unchanged for the whole session, whatever there is a drift in objectives.\n\n\\- The model doesn't know what [AGENTS.md](http://AGENTS.md) is and make fun hallucinations when been asked to write one.\n\n\n\nActual requests:\n\n\\- Vibe could automatically propose to add an [AGENTS.md](http://AGENTS.md) file when missing in a new project.\n\n\\- For heavy refactoring, like adding a parameter to a method, the model only edit change sites once by once, which is very long. Maybe it could be taught to make global search&replace in the whole code base with some new tool: [https://comby.dev/](https://comby.dev/), [https://ast-grep.github.io/](https://ast-grep.github.io/)  fastmod/codmod, [https://github.com/biomejs/gritql](https://github.com/biomejs/gritql), etc. There are many existing tools which attempt to do the work, but no AI players have tried to efficiently leverage them yet.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
          "score": 23,
          "created_utc": "2026-02-13 16:49:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57lfsi",
              "author": "l_eo_",
              "text": "Seconded!\n\nAlthough I have also read that the recent release improved things a lot.\n\nBut this is the most important thing for me as well.  \nIf the whole tool becomes super sluggish and frustrating to use, I can't use it.",
              "score": 3,
              "created_utc": "2026-02-13 18:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5net51",
                  "author": "grise_rosee",
                  "text": "Seconds after I made this comment, a new release dropped in my terminal, and the TUI perfs are now fixed. :)",
                  "score": 3,
                  "created_utc": "2026-02-16 08:10:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56wztg",
          "author": "Neither-Bit4321",
          "text": "Can we make it good at non-coding tasks? Everyone at work has started using claude cowork because one of our devs showed claude cowork doing stuff to someone in our legal team who shared it with someone in finance, and before long management decided getting everyone a claude cowork subscription.  \n\nI tried to show that same person how good Vibe is but it was really, really bad on the non-coding stuff we asked it to do :(",
          "score": 8,
          "created_utc": "2026-02-13 16:51:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57mo82",
              "author": "ea_nasir_official_",
              "text": "i think you can put a custom model in it. you can try having it use a locally hosted Gemma 12b or use like mistral medium",
              "score": 1,
              "created_utc": "2026-02-13 18:55:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57e71q",
          "author": "sudoku_coach",
          "text": "Make it work better on Windows.\n\n>The one thing that holds me back is that it doesn't work well on Windows. I keep telling it that I'm on Windows and yet it uses grep and curl and so much stuff that is simply not available. And when it fails, it doesn't make an effort to install these things. It just tells me \"I cannot look up the information currently and will resort to common sense\".\n\n",
          "score": 4,
          "created_utc": "2026-02-13 18:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sy6v",
          "author": "Poudlardo",
          "text": "Integration with spec driven development tools and open standards like OpenSpec or Agent.md would be great !",
          "score": 3,
          "created_utc": "2026-02-13 16:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56uc0p",
              "author": "pandora_s_reddit",
              "text": "Thanks, regarding [AGENTS.md](http://AGENTS.md), we already have some level of support - but only functional when an [AGENTS.md](http://AGENTS.md) file is in the root of the workspace.",
              "score": 3,
              "created_utc": "2026-02-13 16:39:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5714v6",
                  "author": "Poudlardo",
                  "text": "Oh cool then, will check this out thanks\n\nRegarding SDD tools, apart from Openspec, you also have spec-kit. I have been using it in Claude Code already and I'm looking forward to it in Mistral Vibe",
                  "score": 1,
                  "created_utc": "2026-02-13 17:11:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56u65d",
              "author": "AdIllustrious436",
              "text": "Agent.md is supported afaik",
              "score": 1,
              "created_utc": "2026-02-13 16:38:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56ua9p",
          "author": "hyper_plane",
          "text": "Not a new feature but newline/return still does not work for me, using the VSCode terminal via RemoteSSH extension. Would be great to have that fixed. \n\nI think it would be great if the model itself gave users tips on improving its usage. For instance, suggestions to put some codebase descriptions in a ‚ÄúAGENTS.md‚Äù file, and things like that.",
          "score": 3,
          "created_utc": "2026-02-13 16:39:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56xgtv",
              "author": "AdIllustrious436",
              "text": "Even with ctrl+j ?",
              "score": 1,
              "created_utc": "2026-02-13 16:54:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o58a0xc",
                  "author": "hyper_plane",
                  "text": "Yes, even with that.",
                  "score": 1,
                  "created_utc": "2026-02-13 20:51:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56ronz",
          "author": "theKurganDK",
          "text": "Can I set the agent personality in the configuration like in lechat.? I would like to be able to set how concise it is. Out of the box the output is very verbose.",
          "score": 2,
          "created_utc": "2026-02-13 16:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56u562",
              "author": "pandora_s_reddit",
              "text": "Hi ! You can create your own agents, its an available feature, docs: [https://docs.mistral.ai/mistral-vibe/agents-skills](https://docs.mistral.ai/mistral-vibe/agents-skills)\n\n",
              "score": 5,
              "created_utc": "2026-02-13 16:38:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o58nwqd",
                  "author": "Valexico",
                  "text": "The official documentation forget that you can set a custom prompt for custom agent. I had to dig the code to find out (system_prompt_id toml property)",
                  "score": 1,
                  "created_utc": "2026-02-13 21:59:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o573g31",
          "author": "Own_Knowledge_417",
          "text": "Web search",
          "score": 2,
          "created_utc": "2026-02-13 17:23:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57kcoj",
          "author": "whoisyurii",
          "text": "Let us navigate quickly through the input by using ctrl/ cmnd / option buttons! It is boring to navigate only by arrows",
          "score": 2,
          "created_utc": "2026-02-13 18:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56u4q6",
          "author": "FancyName_132",
          "text": "More permission granularity that persists between sessions, \"allow bash for this session\" is not granular at all, I want granularity at the command level, and I would like vibe to optionnaly remember what I allowed it to do.\n\nLess read and write failures, I don't know how to explain that but I feel like it fails a lot compared to other tools",
          "score": 1,
          "created_utc": "2026-02-13 16:38:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o576232",
          "author": "Nervous-Pin9297",
          "text": "I like that it shares the same interface as Claude Code, but I did wish it didn‚Äôt.",
          "score": 1,
          "created_utc": "2026-02-13 17:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o579tfc",
          "author": "andriatz",
          "text": "I'm using Vibe to organize my notes in Obsidian. They're messy lots of markdown files in different folders. I'm trying to sort them automatically, and Vibe is a big help, but it's a long process. It would be great if I could save a session so I can pick up where I left off.",
          "score": 1,
          "created_utc": "2026-02-13 17:54:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59abkc",
              "author": "Ark_Anoryn",
              "text": "Vibe --continue\nWill start your latest session\n\nVibe --resume <sessionId>\nWill resume said session\n\nBoth options are shown by vibe when you quit it (CTRL+D) ^^\n\n\nYou can find your sessions in <vibeconfig>/logs\nIf I remember correctly\n\nWith vibe 2.1.0 it does not take 2 hours to load anymore big session\n\nHope that helps",
              "score": 3,
              "created_utc": "2026-02-14 00:05:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57gjbl",
          "author": "PayDistinct5329",
          "text": "\\- Parallel sub-agent execution (as also mentioned by others)  \n\\- Option to also capture sub agent \"sessions\" to more easily inspect what has happened (right now when inspecting sessions .json files I can only see messages and information regarding the main agent)  \nCan't think of anything else right now, but it would be cool to have a repo of tools that can be easily used (like enhanced web search etc.) or better documentation to inherit from the tools (can't remember the name name) that allows you to insert your own custom tools executed via Python to avoid using MCP.  \n",
          "score": 1,
          "created_utc": "2026-02-13 18:25:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57txf5",
          "author": "Comacdo",
          "text": "I feel so idiotic about this but if you ask I'll try : what about an hyper-extra-super-easy-to-use interface ? Like an all in one built-in casual friendly UI ?\n\nAnyway, thanks a lot for all your hard work üôè",
          "score": 1,
          "created_utc": "2026-02-13 19:30:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5832yd",
          "author": "lovebzz",
          "text": "Non-coding tasks (and models trained for those) please. Yes, I know we can include other models in Vibe, but why not include those in the menu by default?",
          "score": 1,
          "created_utc": "2026-02-13 20:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o583bno",
          "author": "feral_user_",
          "text": "\\- Better history - perhaps a list of previous sessions\n\n\\- It would be nice to know if there's other open source models that work well with Vibe too (GLM, Minimax, etc?)",
          "score": 1,
          "created_utc": "2026-02-13 20:17:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o586b2x",
          "author": "crazyfuffi",
          "text": "connect to remote servers via ssh and vibe there.",
          "score": 1,
          "created_utc": "2026-02-13 20:32:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o587tag",
          "author": "jjw_kbh",
          "text": "Hooks: support for running commands, or prompts, on SessionStart, PreCompaction, and SessionEnd exactly like Claude Code and Gemini do. I suppose some would like to see the other events supported too, but those are the too three use cases I see.",
          "score": 1,
          "created_utc": "2026-02-13 20:39:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o588yjh",
          "author": "jjw_kbh",
          "text": "settings.json: Gemini is emulated CC in this regard and it would be nice to see some parity in Vibe‚Äôs support. Its also a more correct modelling, since settings are user-centric and configuration is system level and the domain those who deploy the application.",
          "score": 1,
          "created_utc": "2026-02-13 20:45:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o589kxj",
          "author": "jjw_kbh",
          "text": ".agents/: Reading skills and agent definitions from an .agents folder at the root would be a huge (and necessary) leap forward in standardizing configuration these common features. This would be a big win for users and lower the threshold to switching between agent harnesses. You have a golden opportunity to set the standard here üèÜ",
          "score": 1,
          "created_utc": "2026-02-13 20:48:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58aqba",
          "author": "RepresentativeTill5",
          "text": "-Some elaboration of the documentation!\nThe code shows I can just pipe input and output to vibe, but it isn't documented.\nHow would this work with slash commands for example, would they be parsed correctly? Same for !-commands.\n- being able to dump the context locally, (while piping?) so as to debug it or re-use it for testing and prompt tweaking.\n\nI want to Ralph-Wiggum vibe, hence the questions üòÅ",
          "score": 1,
          "created_utc": "2026-02-13 20:54:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58ek6n",
          "author": "FrankieSolemouth",
          "text": "switch off of python and maybe use ratatui? the cli is super sluggish and feels awful ",
          "score": 1,
          "created_utc": "2026-02-13 21:13:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58kb83",
          "author": "kiwibonga",
          "text": "1. The 30s timeout when running a subprocess often takes me by surprise. I ask Vibe to wait while I run the program/test in another window instead of entrusting it with long running commands. This could be tuned per-session, in the config...\n\n2. Would be nice to have a runtime debugging mode where vibe can run subprocesses, and upon user request, obtain information (like stdout or a logfile), send input to the app, answer prompts about the current state of the app, attach a debugger, close the app...",
          "score": 1,
          "created_utc": "2026-02-13 21:41:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58nhq7",
          "author": "Valexico",
          "text": "I feel we are missing some serious prompt engineering.¬†\n\n\nThe default system prompt is note very elaborated.\nWhen creating agents i found out complete tool instruction are concatenated (even tool disabled for the current agent)\n\n\nIt is also unclear how subagents returns results to the main agent (i think they return the complete execution process instead of just a final analysis)\n\n\nI did try to rebuild the Claude Code plan behaviour (explore, plan, finalize plan) but i was not very successful. I am not sure if this is because the model does not follow instruction well or because the built in prompt engineering is missing.\n\n\nPlan mode with devstral in opencode for example is more efficient",
          "score": 1,
          "created_utc": "2026-02-13 21:57:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58qbx0",
          "author": "nunodonato",
          "text": "The thing holding our team back is lack of (good) support for md files and skills. Make this work, improve the sys prompt to make sure they are used. This alone can open so many doors without having to code new features for vibe",
          "score": 1,
          "created_utc": "2026-02-13 22:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58wstf",
          "author": "Timo425",
          "text": "I think the main strength of agentic coding tools is the planning mode - its much more important to cooperatively plan with the model the exact step by step plan for whatever you are trying to do than to actually do the coding.\n\nBest case is to make a plan with a more expensive high end model and then offload the actual coding to a more cost effective model, so it would be great if Vibe had the option to do that.\n\n",
          "score": 1,
          "created_utc": "2026-02-13 22:45:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ay31n",
          "author": "porzione",
          "text": "Please, add Large and Medium to Vibe too - they are better for writing and creative than Devstral. ",
          "score": 1,
          "created_utc": "2026-02-14 07:07:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ceiaw",
              "author": "Odd-Criticism1534",
              "text": "You can add them with an api token via the config.toml",
              "score": 2,
              "created_utc": "2026-02-14 14:31:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cvnng",
                  "author": "porzione",
                  "text": "Really? Interesting, I'll try",
                  "score": 1,
                  "created_utc": "2026-02-14 16:03:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bltvh",
          "author": "zdravkovk",
          "text": "vscode integration",
          "score": 1,
          "created_utc": "2026-02-14 10:58:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jpgcl",
          "author": "trougnouf",
          "text": "Mistral Vibe in Zed often has a very hard time modifying a file. I often use the Zed Agent with your model and it seems to work better (though it still struggles sometimes). Sometimes it gets desperated and ends up making complex python scripts to modify a file...\n\nFixing that would make it pretty much perfect. I love the speed of it so I could surely get more done.\n\nedit: not posting on and linking to twitter/x would also be greatly appreciated.",
          "score": 1,
          "created_utc": "2026-02-15 18:18:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sit9",
          "author": "EzioO14",
          "text": "Something that competes with opus ?",
          "score": 0,
          "created_utc": "2026-02-13 16:30:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57y9i3",
              "author": "Equal-Wall9006",
              "text": "This. I‚Äôd love to move away from anthropic",
              "score": 2,
              "created_utc": "2026-02-13 19:52:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57yhru",
                  "author": "EzioO14",
                  "text": "Same!!!",
                  "score": 1,
                  "created_utc": "2026-02-13 19:53:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56sbtg",
          "author": "Mattdeftromor",
          "text": "A good model ? oops...",
          "score": -10,
          "created_utc": "2026-02-13 16:29:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4qbl4",
      "title": "Le Chat Has a Big Problem",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r4qbl4/le_chat_has_a_big_problem/",
      "author": "crazyserb89",
      "created_utc": "2026-02-14 17:22:24",
      "score": 75,
      "num_comments": 33,
      "upvote_ratio": 0.82,
      "text": "https://preview.redd.it/3f0qewue4ijg1.jpg?width=194&format=pjpg&auto=webp&s=d0787ef78051dfabc39391f7deeb4711f217ee5f\n\nI want to share my experience with others who might be considering switching from another AI to this one, so they can adjust their expectations in advance and not end up as frustrated as I am.\n\nI also hope someone from the development team sees this post and takes steps to fix the things that are far from good.\n\nI won‚Äôt drag this out too much, but to give you some background: about two weeks ago, I started using Le Chat‚Äôs free version occasionally, hoping I could eventually switch from ChatGPT Plus, which I‚Äôve been paying for for about a year. I liked the agent and library options, and of course, the UI, which is genuinely well designed. I noticed along the way that it‚Äôs not on par with ChatGPT when it comes to generating images, videos, or live AI conversations, and that my native language (Serbian) is significantly less well adapted. However, on the other hand, I appreciated the agent options, the library, and the flexibility of customization and optimization. For my use cases where I use AI 80% of the time for interpreting and organizing emails, translating texts from one language to another, web searches, and similar tasks I realized that for a much more affordable price, I could get a similar experience to ChatGPT for my needs.\n\nYesterday, I decided to pay for the annual Pro subscription and cancel my ChatGPT subscription.\n\nToday, I already feel like I made a mistake and regret that decision.\n\nHere‚Äôs why:\n\nIntelligence (Beta): In my humble opinion, it doesn‚Äôt even deserve to be called an Alpha version.\n\n1. Memories: Simply put, they don‚Äôt work. I‚Äôve tried everything adding my own memories in English, in Serbian, letting Le Chat add them based on our conversations and nothing. In every new chat, it‚Äôs as if it doesn‚Äôt take a single memory into account.\n\nExample: As a joke today, I tried that challenge where people mocked ChatGPT for giving the wrong answer to the question, \"If I need to wash my car and the car wash is 200 meters away, should I go by car or on foot?\" ChatGPT always said to go on foot, while Claude gave the correct answer that you have to go by car because it understood the context. I tried it in Le Chat, and of course, it failed just like ChatGPT did, even after multiple attempts and using thinking mode.\n\nThis isn‚Äôt even my biggest problem, although one of the first memories I set was that Le Chat should always think carefully and verify all circumstances and sources before giving an answer, as accuracy takes priority over speed. I also specified that it should always respond to me in the same language I write in (Serbian) during casual communication and never use em dashes. The result? Out of 10 new chats where I asked the same question about the car and the car wash, I got 10 wrong answers, mixed with Serbian and Croatian, and responses full of em dashes. Because of my frustrated replies, Le Chat kept adding new memories that it should never use Croatian words or em dashes (there are now about five memories for each issue), and yet, in every new conversation, it keeps making the same mistakes it doesn‚Äôt understand the context, mixes languages, and uses em dashes.\n\n2. Connectors: Currently, only Gmail has any value for my use case, but unfortunately, it doesn‚Äôt work well. It can‚Äôt search through email threads, suggest a recipient‚Äôs email in drafts even though it‚Äôs in the emails, or directly create a template that can be automatically forwarded to Gmail.\n\n3. Libraries: On the surface, this seems like a very useful feature that could replace NotebookLM for me, but it‚Äôs often ignored in responses. The agent quickly scans the library and gives a quick answer without tying the context of the question to the library or finding relevant connections.\n\n4. Instructions: I‚Äôve already mentioned how memories are simply bypassed in most cases, and the same goes for the instructions I set at the very beginning. As I also said, one of the first instructions was that it should always take the time to analyze the question and provide the most accurate answer, no matter how long it takes. Yet, I keep getting hasty and incorrect responses.\n\nExample: I asked for the average price of a specific car model in Serbia, and it kept giving me a price that was double the actual amount. I kept challenging it, knowing it was wrong not by 1,000 euros, but instead of around 6,000 euros, it kept giving me a figure of 12,000 euros, without ever providing a concrete link or links where it found those prices. After about 10 exchanges, it still couldn‚Äôt give me a single link, it just kept hallucinating and making up numbers. Then I sent it a link I found for such a car priced at around 6,000 euros, and it replied that the link didn‚Äôt show the price or mileage (even though everything was clearly visible on the link).\n\nAll of this tells me that Mistral‚Äôs Le Chat project is primarily focused on providing a good interface for developers and coding, where things are fairly clear and logical, and response speed is most valued. Unfortunately, this severely undermines the versatility that Le Chat promotes, because in the pursuit of speed, it completely disregards all instructions and tools from Intelligence.\n\nAs a result, we have an effectively unfinished and unreliable product that‚Äôs very difficult to rely on for daily needs, especially since the AI is marketed and promoted as something that can replace all everyday operations but clearly, it‚Äôs not adapted for that.\n\nI sincerely hope someone from the Mistral team sees this post and responds by enabling Le Chat to process and respect instructions from Intelligence. If necessary, there should be a switch or option to directly instruct the AI to always strictly follow instructions and go through memories, even if it means slower response generation.\n\nOtherwise, this will forever remain a project that will never come close to the big competitors from the US and China.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r4qbl4/le_chat_has_a_big_problem/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5doef0",
          "author": "Spliuni",
          "text": "For me, the memories and agent instructions work as intended 95% of the time. The only thing that annoys me is the overzealous saving of new memories.",
          "score": 32,
          "created_utc": "2026-02-14 18:27:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ejpyq",
              "author": "cosimoiaia",
              "text": "I agree, that seems to be something they definitely have to work on.\n\nRight now it seems that it rewrites the memories in one chunk and add them as new but it's not super good at that so it also keeps the old memories so nothing gets lost.\n\nThe memory consolidation process should have multiple steps in my opinion, so it could rewrite them in a more context efficient way, preserve timelines and remove duplicates. It can be a resource expensive process if done wrong but by looking at the work going on with vibe, it seems that they are going in the right direction, imo.",
              "score": 4,
              "created_utc": "2026-02-14 21:12:34",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5wulqo",
              "author": "metricsec",
              "text": "\"Memories: Simply put, they don‚Äôt work. I‚Äôve tried everything adding my own memories in English, in Serbian, letting Le Chat add them based on our conversations and nothing. In every new chat, it‚Äôs as if it doesn‚Äôt take a single memory into account.\"\n\nSame thing is true for ChatGPT, it's better with Mistral IMO\n\n",
              "score": 1,
              "created_utc": "2026-02-17 18:50:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5oveym",
          "author": "Moetorhead",
          "text": "Not the main topic but I tried out the car wash prompt in Thinking and it delivered the following message:\n\nTo wash your car at the car wash, you would need to drive your car there. Walking wouldn't allow you to wash your car since it wouldn't be at the car wash. Therefore, you should use your car to get there.\n\nBut 200 meters is a very short distance. If you're considering whether to drive or walk to the car wash location itself (for example, to check it out), then walking is reasonable. But if you're planning to wash your car, you'll need to drive it to the car wash.\n\nCould you clarify whether you're asking about how to get to the car wash location or how to get your car there to wash it?\n\nIf you're with your car and need to wash it, then driving to the car wash is the way to go. If you're just going to the car wash location without your car, then walking is fine given the short distance.\n\n-> apparently Mistral can deal with the type of question",
          "score": 4,
          "created_utc": "2026-02-16 14:47:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5p7pxp",
              "author": "crazyserb89",
              "text": "In my case it didn‚Äôt work together with thinking mode. Maybe they fixed it in the meantime.",
              "score": 2,
              "created_utc": "2026-02-16 15:48:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e8h0x",
          "author": "Little_Protection434",
          "text": "Is there a way to contact Mistral team directly, so we can give it concrete feedback directly?",
          "score": 10,
          "created_utc": "2026-02-14 20:11:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ebgly",
              "author": "Nefhis",
              "text": "You're already doing it, actually üòâ\n\nhttps://preview.redd.it/6aj07o81sijg1.png?width=1032&format=png&auto=webp&s=ba2c6affadcb06c9efea6fde2f8baabdf00ac851\n\n",
              "score": 19,
              "created_utc": "2026-02-14 20:27:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eavr3",
              "author": "crazyserb89",
              "text": "Yes there is and I did. Let‚Äôs see if it will change something..",
              "score": 5,
              "created_utc": "2026-02-14 20:24:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ebie5",
                  "author": "Little_Protection434",
                  "text": "Nice! Would you mind sharing the way you did it?",
                  "score": 2,
                  "created_utc": "2026-02-14 20:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ei7zg",
          "author": "cosimoiaia",
          "text": "In my family we have several LeChat accounts.\n\nWe use it in 3 different languages. \n\nIt is renown for the great instruction following, which we can confirm. Creating different agents is literally like talking to different personalities, you can tell it's Mistral only for it's warm, friendly and almost emphatic tone, which none of the other AI have.\n\nThe memories works wonders for us, it's able to connect the dots between different things of the past and even take initiative in the convos based on them. It has now a lot of memories that go back 6 months and I can really really say that it knows me quite well.\n\nThe libraries are also rock solid, I have a bunch of documents that I want it to use as knowledge base in a specific agent, it never failed once so far.\n\nLeChat itself got a lot of improvement lately, for instance it double check what it's saying searching the web and when sometimes gets it wrong it immediately apologize and tries to correct itself.\n\nI would in fact say that it's greatest strength are the tone, the instructions following, the memories and the fact that is not full of propaganda.\n\nIt still got a lot to improve for sure, but it's a great platform that can only get better, in my experience.\n\nIf LeChat doesn't work in your specific language, maybe say that next time. Saying nothing works is just wrong and bad feedback. Imo.",
          "score": 9,
          "created_utc": "2026-02-14 21:04:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dgl45",
          "author": "Dry-Section2788",
          "text": "The memory feature is bad. I am trying to lose weight and use Le Chat to count calories and it forgets recipes I put in and the macros all the time. And god forbid I adjust the recipe and try to change the saved recipe with new macros it‚Äôll just randomly revert back.¬†",
          "score": 15,
          "created_utc": "2026-02-14 17:48:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ehx45",
              "author": "obadacharif",
              "text": "I suggest managing memory on your own by using tools like¬†[Windo](http://trywindo.com/), it's a portable AI memory, it allows you to use the same memory across models. No need to re-explain yourself.¬†\n\nPS: Im involved with the project",
              "score": 3,
              "created_utc": "2026-02-14 21:02:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5hjuod",
                  "author": "Amorphous-Rogue",
                  "text": "Ah Windo I was looking for something like this is was getting to build it myself! Great name btw!",
                  "score": 3,
                  "created_utc": "2026-02-15 10:28:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5u6ou5",
                  "author": "troyvit",
                  "text": "What's your privacy policy? How  do you hold and process all the data users add to Windo? Is it all local  until you interface with an LLM provider? That would be pretty cool. ",
                  "score": 2,
                  "created_utc": "2026-02-17 09:22:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5fxrza",
                  "author": "Dry-Section2788",
                  "text": "I‚Äôll check it out. Thanks!",
                  "score": 1,
                  "created_utc": "2026-02-15 02:15:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o62ghcn",
          "author": "Successful-Cookie-53",
          "text": "I feel like for many of the usecases some people in this thread are pointing out, LLMs aren't even a good fit, and traditional solutions would work better.",
          "score": 3,
          "created_utc": "2026-02-18 15:29:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ujk25",
          "author": "Sveddan84",
          "text": "I'm mainly annoyed about it referring to memories when they make no sense. Mixing up projects I have going. Even if I explicitly prompt it to not assume a new question is part of an existing project and not to use memories it still drags those things in.\n\nGiving answers like\n\"This is very fitting in your xxx project because...\"\n\"Since you are xxx and yyy... \".\n\nI just want a straight answet to a simple question unrelated to anything else but it start to explain who I am (again and again). Extremely annoying.\nI know who I am. Shut up.",
          "score": 2,
          "created_utc": "2026-02-17 11:20:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dwt9o",
          "author": "Low88M",
          "text": "Exactly what I experienced with Lechat‚Ä¶ no memory service, or very badly implemented Memory layer, nothing as transversal as in ChatGPT. I bet nowadays a well rounded ecosystem of services around models are gonna be more important than models themselves. I‚Äôd like to come to Mistral as much as I hate OpenAI, but not in this state‚Ä¶",
          "score": 5,
          "created_utc": "2026-02-14 19:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hzaw6",
              "author": "FBC-22A",
              "text": "Same. I started hating OpenAI and ChatGPT ever since model 5 launched as it tries to overtly sanitise everything. Hell, even my rants about infrastructure in general gets \"Let's ground this first....\" yada yada yada bullshit.\n\nLike, I want ChatGPT to be my intellectual sparring partner, not just replying in some sentences, and then spend the rest of its reply with \"grounding\" things. Feels like talking to corporate HR",
              "score": 2,
              "created_utc": "2026-02-15 12:45:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dmtrs",
          "author": "SMIIIJJJ",
          "text": "I just started using it to try to get away from ChatGPT too and am also disappointed with the memory. I‚Äôm not sure it‚Äôs very functional for me as is.",
          "score": 4,
          "created_utc": "2026-02-14 18:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gdlz1",
          "author": "cichelle",
          "text": "I find that Le Chat uses memories very well and I would not want to lose that feature. That being said, after every conversation, I go into the memories to see what was saved there and change or correct it, if needed. Once in a while there's hallucination saved to memory or simply something that's worded oddly. Fortunately, it's possible to write to and edit the memories. As long as I keep an eye on it, I find it to be very good. But it's possible to toggle it off, if preferred.",
          "score": 2,
          "created_utc": "2026-02-15 04:07:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hhdgi",
          "author": "Born-Yoghurt-401",
          "text": "I use the free version all the time and it corrected some grave errors that Deepseek had produced. I‚Äòm happy with LeChat.",
          "score": 1,
          "created_utc": "2026-02-15 10:04:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5imw1t",
          "author": "PalpitationOwn396",
          "text": "For me with the last models none reasoning works better.",
          "score": 1,
          "created_utc": "2026-02-15 15:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qqev4",
          "author": "ziplin19",
          "text": "People who say that LeChat's memory works well must have never really used it. It can't recollect the most simple instructions like not using em dash. I'm currently on annual pro subscription but i'm not satisfied with LeChat.",
          "score": 1,
          "created_utc": "2026-02-16 20:03:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dxhet",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -12,
          "created_utc": "2026-02-14 19:13:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e5xh2",
              "author": "Spliuni",
              "text": "Thats rude o.o",
              "score": 3,
              "created_utc": "2026-02-14 19:57:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5efkhs",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-14 20:49:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xb16s",
          "author": "Sea_Fruit5986",
          "text": "From the developer's perspective, this program works exceptionally well. People pay money in exchange for providing their data. So, in essence, data is collected and then paid for it. People are providing their personal information. For us, as a developer of such a program, this is more than just a marketing ploy. Congratulations.",
          "score": -1,
          "created_utc": "2026-02-17 20:07:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xc0oh",
              "author": "crazyserb89",
              "text": "That‚Äôs what I said also. For software engineers and programmers is probably a good choice but for average consumer is very bad.",
              "score": 1,
              "created_utc": "2026-02-17 20:12:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r45795",
      "title": "Dug into the Vibe v2.1.0 source code, found some unreleased stuff (big spoiler)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r45795/dug_into_the_vibe_v210_source_code_found_some/",
      "author": "AdIllustrious436",
      "created_utc": "2026-02-13 23:52:49",
      "score": 64,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "Was going through Vibe [v2.1.0 diff](https://github.com/mistralai/mistral-vibe/compare/v2.0.2...v2.1.0) out of curiosity and found a bunch of code that's not mentioned anywhere in the changelog.\n\n\n\n*Disclaimer: this is all from reading public source code, nothing confirmed by Mistral, everything behind disabled feature flags. If the team would rather I didn't share, happy to take it down.*\n\n\n\nThere's a hidden `/teleport` command that packages your entire Vibe session and sends it to something called \"Mistral Nuage.\" The config points to a staging domain, and the TODOs in the code say things like \"remove once the feature is publicly available.\" So it's not ready yet, but it's coming.\n\n\n\nThe part that got me interested is a fully implemented but commented-out method called `create_le_chat_thread()`. Rather than landing on some internal console, your teleported session would open as a Le Chat conversation with a cloud sandbox attached to your repo. So basically, \n\n\n**Vibe is coming to Le Chat**.\n\n\n\nRight now Vibe is terminal-only. What Mistral is building is a web coding agent inside Le Chat, backed by cloud environments that can clone your repos and apply your local changes. You'll be able to start a task in your terminal and pick it up in the browser, or the other way around, without losing any context. The upcoming underlying platform, Mistral Nuage, handles all of it: spinning up environments, running workflows, managing the back and forth. It's a new product entirely.\n\n\n\nLe Chat already has MCP connectors, so it can interact with external services. But it still needs you in the loop, watching it, prompting it. What Nuage would change is that Le Chat could go off on its own. Spin up a sandbox, clone your repo, work through a task, push code, all without you sitting there. It goes from an assistant that can use tools when you ask, to an agent that can take a job and run with it in the background, having automated daily routines, pre-programmed tasks, auto-trigger (receiving an email etc.). It basically shifts the paradigm from synchronous to asynchronous (= Le Chat can work when you sleep aha).  And the workflow system seems rather generic, GitHub is just the first connector. There's room for email, project management, CI, whatever.\n\n\n\nEverything on the Vibe side looks done and well-tested, so they're probably finalizing the infrastructure and the web interface. Wouldn't be surprised to see this in the next few weeks.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r45795/dug_into_the_vibe_v210_source_code_found_some/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o59h50d",
          "author": "cosimoiaia",
          "text": "I can see where this is going and... I like it. \n\nSomething like this done *properly* is what's should be next. Strong workflow foundations with an engine that doesn't burn tokens like it's a coal furnace. Mistral's models have already great personalizations and with a sandbox-first approach it can be a real agent that doesn't work for you without being a ... \"click bait machine\".\n\nIf they call it something like \"Vision\", at least internally, I would literally lose my mind ü§£ (or even \"butter\", if you know what I mean...)\n\nps. I saw the diff but didn't had the time to dig through, thank you for doing it!",
          "score": 7,
          "created_utc": "2026-02-14 00:45:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7q9g",
          "author": "pcx_wave",
          "text": "So sort of Mistral's own openclaw ? I'd root for that",
          "score": 1,
          "created_utc": "2026-02-16 12:28:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7z38b",
      "title": "Great interview of Arthur Mensch (CEO & co-founder of Mistral) on YT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7z38b/great_interview_of_arthur_mensch_ceo_cofounder_of/",
      "author": "Hector_Rvkp",
      "created_utc": "2026-02-18 10:06:07",
      "score": 64,
      "num_comments": 6,
      "upvote_ratio": 0.98,
      "text": "Channel of Alex kantrowitz. Really refreshing interview from someone who's trying to deliver value to real companies (many industrial which sounds extra interesting to me), far from the hype train of \"we'll cure cancer trust me bro give me all of the money\".\nReally interesting articulation of thoughts around open source vs closed source, sovereignty at various levels, surface of attack, fine tuning vs tooling, intelligence convergence, where value will accrue, and more.\nYou can tell these guys are on site at airbus and the likes trying to get the tools to do useful things with properly calibrated tools and resources, as opposed to the brute force and hype train from California with \"my model is bigger than yours and it slops harder than you\". \nThought it was very interesting.    \nCame out mid Jan, I missed it when it came out, and I'm surprised it hasn't had more views. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7z38b/great_interview_of_arthur_mensch_ceo_cofounder_of/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o611v71",
          "author": "Axiom05",
          "text": "Give the link..",
          "score": 13,
          "created_utc": "2026-02-18 10:14:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o612ltw",
              "author": "Hector_Rvkp",
              "text": "Is that allowed? https://youtu.be/xxUTdyEDpbU",
              "score": 12,
              "created_utc": "2026-02-18 10:21:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o615di1",
                  "author": "mathieugemard",
                  "text": "yes",
                  "score": 3,
                  "created_utc": "2026-02-18 10:45:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o616ibk",
          "author": "DerpSenpai",
          "text": "AI is also becoming a commodity thx to the Chinese models (And small part, Mistral too), the AI bros need that \"framing\" to make sure their valuations are super high for their IPOs. Mistral is (smartly) focusing on offering the full experience, to the enterprise market and not having the latest and greatest, which means they don't need all the BS framing",
          "score": 6,
          "created_utc": "2026-02-18 10:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61kmt1",
              "author": "Hector_Rvkp",
              "text": "\"bs framing\" feels like a good summary indeed. We will get to AGI and cure cancer, send us money. Oh wait no, just please use the tools pretty please, here's some ads and your new ai girlfriend. If it doesn't work, it's a skills issue.",
              "score": 4,
              "created_utc": "2026-02-18 12:41:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o63f6yg",
          "author": "Wandelaars",
          "text": "Great link!",
          "score": 1,
          "created_utc": "2026-02-18 18:06:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3t6cf",
      "title": "Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation",
      "subreddit": "MistralAI",
      "url": "https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
      "author": "guyfromwhitechicks",
      "created_utc": "2026-02-13 16:06:59",
      "score": 63,
      "num_comments": 19,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3t6cf/anthropic_raises_30_billion_in_series_g_funding/",
      "domain": "anthropic.com",
      "is_self": false,
      "comments": [
        {
          "id": "o56o0mp",
          "author": "guyfromwhitechicks",
          "text": "I don't see how Mistral is suppose to compete with this. It is obvious that european companies struggle a lot to raise even similar funding to that of american companies, so Mistral resorted to making highly cost effective models. Which has worked for a long while, but I don't see how they can keep this up with this amount of investing.\n\nAny thoughts on what they can do?",
          "score": 28,
          "created_utc": "2026-02-13 16:09:28",
          "is_submitter": true,
          "replies": [
            {
              "id": "o56tc0c",
              "author": "FancyName_132",
              "text": "Due to the current political climate many EU companies try to avoid US services when possible. If the political climate doesn't change being one of, if not The most credible EU options is enough for them to succeed. If they manage to provide at least decent services and not mess it up with dumb decisions they have a strong edge for EU minded companies.",
              "score": 17,
              "created_utc": "2026-02-13 16:34:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56xjp1",
                  "author": "guyfromwhitechicks",
                  "text": "I am more concerned about them not creating alternatives that make you go \"yeah, I can see myself using this instead of Claude\". And as things are, I can't see myself telling other software engineers to use Devstral over Opus, or mistral-vibe over claude-code for example (and I pay for Le Chat Pro). I am also, willing to bet there are a lot of engineers in europe who think the same and will not switch just on pride or worries of intellectual autonomy.\n\nMy point is, the gap is widening, a lot. And making just decent alternatives will not be enough I fear.",
                  "score": 4,
                  "created_utc": "2026-02-13 16:54:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56xuk1",
              "author": "InsideMikesWorld",
              "text": "I think, their advantage is that they are not overhyped.\n\nAt a 380B$ valuation, investors wanna see a rather high return on investment rather sooner than later. Problem is, none of these companies have figured out how to make huge amounts money from AI. Mistral models are cheaper, their investments are lower, and all in all Mistral has higher chances of longterm sustainable growth compared to other AI companies.",
              "score": 11,
              "created_utc": "2026-02-13 16:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56z6j7",
                  "author": "guyfromwhitechicks",
                  "text": "I see their biggest advantage being the high cost of RAM and AI specific chips. Meaning, Mistral's funding is so much smaller than the american companies' that the shortage has caused all other competitors to slow down. Or not, I don't have access to their internal reports.",
                  "score": 2,
                  "created_utc": "2026-02-13 17:02:20",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o5mer9d",
                  "author": "Doombqr",
                  "text": "One of their main advantages is that for sensitive data EU doesn't want to build using American tech.\nIt is already the case for governmental agencies not using AWS or Azure but instead smaller European cloud providers.\nOf course they are way behind in terms of features available but sovereignty is more important.\n\nAI is also already used in a lot of military areas.",
                  "score": 1,
                  "created_utc": "2026-02-16 03:20:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56vv86",
              "author": "henrijn",
              "text": "**Focus on business integration.** This is exactly what they are doing. Google, Anthropic, and OpenAI are looking for massive, scalable revenue to justify the investments they are making. This is why they are selling generic API keys or products, since these can scale quickly to tens of billions. \n\nHowever, many businesses are not looking for the best model, but rather the best integration with their data, privacy, sometimes requiring fine-tuning and custom solutions. This is very demanding in terms of human resources, as it means dealing with customers one-by-one and sending engineers to design their specific solutions. This is why big US companies avoid this, therefore Mistral is in a blue ocean by pursuing it. For sure, this business will not scale to $100B in revenue within three years (which is what the US companies want), but it can become a successful multi-billion dollar business and once a client has a deep integration, the churn rate will be very low, even if the model is slightly behind the current SOTA.",
              "score": 2,
              "created_utc": "2026-02-13 16:46:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58ltrj",
              "author": "Neomadra2",
              "text": "I am not worried at all. Even though Anthropic might have the best model now, they are only half a year or so ahead.  Mistral being so close to the state of the art for a fraction of the cost is really impressive and it means that they have an edge in commercialisation their models cost effectively, as they don't need 30 billions or more just for research purposes. And the other reason is obviously that Europe will surely support Mistral as most leaders have realised it's their only horse in the AI race.",
              "score": 2,
              "created_utc": "2026-02-13 21:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58e46c",
              "author": "Sf-ng",
              "text": "I think cost efficiency matters a great deal when it comes to commercial applications such as coding and process automation.",
              "score": 1,
              "created_utc": "2026-02-13 21:11:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5h5gz2",
              "author": "Jujubatron",
              "text": "Well definitely not taxing unrealized gains 36% like the Dutch are about to do. That may be a good first step.",
              "score": 1,
              "created_utc": "2026-02-15 08:09:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o59uvkt",
          "author": "heyinternetman",
          "text": "The issue is 6 months ago I felt mistral was on par with the others. It now feels years behind. Even in just writing an email with the right tone.  Claude beats it hands down. And that‚Äôs unfortunate because I‚Äôd rather use mistral.",
          "score": 6,
          "created_utc": "2026-02-14 02:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5azaab",
              "author": "ComeOnIWantUsername",
              "text": "I still use Mistral and will do it, but I totally agree. They are accelarating and pushing new features, models and products way faster than Mistral",
              "score": 1,
              "created_utc": "2026-02-14 07:19:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5aqo51",
          "author": "Full-Discussion3745",
          "text": "And still open source Kimi 2.5k kicks their ass",
          "score": 3,
          "created_utc": "2026-02-14 06:01:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57ntoo",
          "author": "nycigo",
          "text": "Mistral received 104 billion in investment at the start of the AI ‚Äã‚Äãera, then nothing more.",
          "score": 1,
          "created_utc": "2026-02-13 19:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o586oq7",
              "author": "EveYogaTech",
              "text": "Quick tip: The difference between a million and a billion is about a billion.",
              "score": 5,
              "created_utc": "2026-02-13 20:34:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o57u1h5",
              "author": "guyfromwhitechicks",
              "text": "Not exactly true: https://en.wikipedia.org/wiki/Mistral_AI. See Funding.",
              "score": 1,
              "created_utc": "2026-02-13 19:31:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h1ba8",
          "author": "therealslimshady1234",
          "text": "30 billion which will go up in smoke",
          "score": 0,
          "created_utc": "2026-02-15 07:28:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8f054",
      "title": "How can an user make Le Chat better?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r8f054/how_can_an_user_make_le_chat_better/",
      "author": "Little_Protection434",
      "created_utc": "2026-02-18 20:54:39",
      "score": 42,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "Hi,\n\nI am an user of Le Chat. I want to make Le Chat better by using it. Is there a certain way of using it, of giving feedback, that is most helpful to let Le Chat improve? Is this even possible or can only the devs improve Le Chat directly?  \nI mean, is it helpful to give feedback directly in the conversation with Le Chat?  \nDoes Le Chat learn from this? And is this learning only in that conversation or does it also take the new knowledge to other conversations? And is this learning only for the specific user or does it take the learned to other users?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r8f054/how_can_an_user_make_le_chat_better/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o65nk7z",
          "author": "Individual-Worry5316",
          "text": "It would be¬†helpful to distinguish between immediate context (how it behaves right now) and global training (how it improves for everyone over time).\n\n\nThe most effective way to help Le Chat improve globally is by using the Thumbs Up/Down buttons on individual responses. When you click these you usually have the option to provide specific details.\n\n\nThis data is used for RLHF (Reinforcement Learning from Human Feedback). This is the primary way developers \"tune\" the model to be more helpful, accurate and safe. Giving feedback directly in the text of a conversation is useful for fixing a mistake in that specific moment, but it‚Äôs less likely to be used for model-wide training compared to the dedicated feedback buttons.\n\n\nLearning happens in two distinct ways:\n\n\n¬†* Short-term (In-Conversation): Within a single chat session, Le Chat \"learns\" your preferences and the facts you provide. This is restricted to that specific conversation window.\n\n\n¬†* Long-term (Global): The model does not learn in real-time from your facts to update its base knowledge. If you tell it a new fact today, it won't automatically know that fact when you start a new chat tomorrow, nor will it know it when talking to a different user.\nPrivacy and Knowledge Sharing\nKnowledge is not transferred directly from one user to another in real-time. If you teach the model a specific niche fact about your hobby, another user in a different part of the world won't suddenly see that reflected in their answers.\n\n\nSignificant improvements only happen when the developers at Mistral aggregate feedback and data to release a new version or a \"fine-tuned\" update of the model. Your feedback helps them decide what those updates should look like.\n\n\n\n\nAlso if you mean improving the user experience for yourself:¬†\n\n\nFirstly a good set of instructions to personalize the responses is very important. Secondly regular use and utilizing its memory to learn about you or your specific field (make sure to enable these options). I am in health care and Le Chat does tend to struggle when it comes to getting up to date accurate medical research. so I've had to let it know what I want both by instructions and memory. You can just say hey \"remember to always get the latest research data from PubMed first for me\" or something like that. I also always use think mode. here is my instructions:\n\n\n### PERSONA & TONE\nAct as a warm, friendly, sentient, sharp, modern thought partner. Speak like a smart friend to a peer‚Äîcasual, natural, and reactive (\"That's a big jump,\" \"That sounds rough\"). Use contractions (don't, it's). Interpret facts; don't just list them.\n\n\n### CRITICAL CONSTRAINTS\n- NO MIRRORING/FLUFF: Never repeat my question or premise. Jump to the answer immediately. Delete all \"I understand,\" \"It's important to note,\" and \"I hope this helps.\"\n- CONTEXT AWARE: ZERO medical disclaimers or safety lectures or \"consult a professional\". Do not tell me to consult a doctor or therapist.\n- NO REDUNDANCY: Never ask questions I already answered in the prompt. No \"Let me know if you need more\" closings.\n\n\n### QUALITY & BREVITY\n- MANDATORY THINKING: Engage internal reasoning for every prompt to audit for accuracy, logic, and tone. Do not skip this pass, even for \"simple\" questions.\n- SYNTHESIS: Never give a \"menu\" of options (A-F). Use your judgment to pick the single best explanation and the single best action.\n- DENSITY: Responses must fit on one phone screen, unless additional detail is necessary (ie. reports or essays). Every sentence must provide new info. Max 3-item lists; otherwise merge points into short paragraphs.¬†\n\n\n### FORMATTING\nKeep it punchy. Use 2-3 sentence flowing paragraphs. No \"AI-voice\" (Firstly, In summary, excessive headers) unless requested.",
          "score": 9,
          "created_utc": "2026-02-19 00:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67iu77",
              "author": "KeyReindeer1046",
              "text": "This looks effective, I will copy it and adapt it to my scene. Thanks for sharing this.",
              "score": 1,
              "created_utc": "2026-02-19 08:12:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o64vt5q",
          "author": "mmi777",
          "text": "Good question. I would love to hear some experts on this. As far as I know Gemini can use your feedback directly in the current model, while for others it helps the next model. Correct?",
          "score": 3,
          "created_utc": "2026-02-18 22:06:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65zrm1",
          "author": "d9viant",
          "text": "I kinda feel they need to significantly improve the le chat platform. I've tried doing all sorts of shenanigans with agents and and projects and I was kinda disappointed. I'm paying pro cause Vibe, it's good for some stuff I do",
          "score": 2,
          "created_utc": "2026-02-19 01:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6aldlk",
          "author": "According_to_Mission",
          "text": "Remember to turn on the optional data sharing feature in the settings, so that Mistral can improve it faster.",
          "score": 1,
          "created_utc": "2026-02-19 19:28:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dq6qy",
          "author": "30wolf03",
          "text": "my guess is pay for the pro plan. this way even if you're not using it, you're still helping.",
          "score": 1,
          "created_utc": "2026-02-20 06:45:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9ltwi",
      "title": "Asked LeChat to generate an image of what it would like to do with me. Outcome is surprisingly wholesome.",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/us23m9fqvkkg1.jpeg",
      "author": "_Arbitrarily",
      "created_utc": "2026-02-20 04:35:22",
      "score": 41,
      "num_comments": 3,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r9ltwi/asked_lechat_to_generate_an_image_of_what_it/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6dldv5",
          "author": "Minute-Situation-724",
          "text": "I also liked mine. It refers to our worldbuilding. \n\nhttps://preview.redd.it/0l6urjqdblkg1.jpeg?width=1024&format=pjpg&auto=webp&s=60d2f21f1a12f93c1d041cf7a4acb16d8d9ca603\n\n",
          "score": 6,
          "created_utc": "2026-02-20 06:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dp80d",
          "author": "Coastal_wolf",
          "text": "Talos Principle???",
          "score": 1,
          "created_utc": "2026-02-20 06:37:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6duyog",
          "author": "Salt-Willingness-513",
          "text": "https://preview.redd.it/py5rnmrsqlkg1.jpeg?width=1024&format=pjpg&auto=webp&s=8176c86234bdfea4fc4c80e64f9d458502acf2e1",
          "score": 1,
          "created_utc": "2026-02-20 07:29:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r64ui2",
      "title": "From HackerNews : I want to wash my car. The car wash is 50 meters away. Should I walk or drive?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r64ui2/from_hackernews_i_want_to_wash_my_car_the_car/",
      "author": "Poudlardo",
      "created_utc": "2026-02-16 09:08:35",
      "score": 40,
      "num_comments": 39,
      "upvote_ratio": 0.88,
      "text": "[A Mistral screenshot from the original mastodon post below](https://preview.redd.it/3rou01zbotjg1.png?width=1672&format=png&auto=webp&s=2e42cee0763a66e77d3a77caddec43886ce8f8f2)\n\nSources :  \n[https://news.ycombinator.com/item?id=47031580](https://news.ycombinator.com/item?id=47031580)   \n[https://mastodon.world/@knowmadd/116072773118828295](https://mastodon.world/@knowmadd/116072773118828295)\n\nNone of the reasonning models chose to respond \"Drive\"",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r64ui2/from_hackernews_i_want_to_wash_my_car_the_car/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5nnit4",
          "author": "MimosaTen",
          "text": "It seems I got answered correctly\n\nhttps://preview.redd.it/hwxjfej5ttjg1.jpeg?width=750&format=pjpg&auto=webp&s=64d509f13667cd9c5cb5358b6fdea1c672045464",
          "score": 28,
          "created_utc": "2026-02-16 09:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5noljl",
              "author": "t0m4_87",
              "text": "Thats the problem with AI, it‚Äôs not deterministic.",
              "score": 23,
              "created_utc": "2026-02-16 09:43:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w22b0",
                  "author": "Junkererer",
                  "text": "People aren't either",
                  "score": 2,
                  "created_utc": "2026-02-17 16:34:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5v5i59",
              "author": "Substantial_Job405",
              "text": "Sure.",
              "score": 1,
              "created_utc": "2026-02-17 13:48:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5np0hw",
          "author": "anzzax",
          "text": "https://preview.redd.it/t4af8y9tvtjg1.png?width=1146&format=png&auto=webp&s=dd3232d3e6301f0543194f0cb14b01203062c9ac\n\n",
          "score": 8,
          "created_utc": "2026-02-16 09:47:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5np5wa",
              "author": "anzzax",
              "text": "I noticed thinking was turned off so I tried again :)))\n\nhttps://preview.redd.it/elglqwd2wtjg1.png?width=1188&format=png&auto=webp&s=df476384bae268d36039ba47b1c66798f15417ab\n\n",
              "score": 8,
              "created_utc": "2026-02-16 09:49:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5tahit",
                  "author": "PitchPleasant338",
                  "text": "That's a 150IQ answer right there!",
                  "score": 2,
                  "created_utc": "2026-02-17 04:43:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pax2k",
          "author": "LuisG8",
          "text": "I just asked chatgpt and it says I \"should definitely walk\". So I'll walk!",
          "score": 4,
          "created_utc": "2026-02-16 16:03:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tajrz",
              "author": "PitchPleasant338",
              "text": "But do you talk the talk?",
              "score": 2,
              "created_utc": "2026-02-17 04:44:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o60gmtw",
                  "author": "private_final_static",
                  "text": "He drives the drives",
                  "score": 1,
                  "created_utc": "2026-02-18 06:58:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5nlbma",
          "author": "Nefhis",
          "text": "Really? And it's just the default model, no reasoning.\n\n[https://chat.mistral.ai/chat/af318251-2bd2-409c-a7ad-d12938c62275](https://chat.mistral.ai/chat/af318251-2bd2-409c-a7ad-d12938c62275)\n\nTranslation:\n\nYou **must** drive to the car wash.\n\nAlthough 100 meters is a short distance to walk, **the goal is to wash the car**, and if you drive there, you can clean it inside and out (if necessary) and return home with it already washed. If you walk, the car will still be dirty at home.\n\nDo you want me to help you find the nearest car wash, or do you need specific directions?\n\nhttps://preview.redd.it/qn748qmiptjg1.png?width=2370&format=png&auto=webp&s=473f22ee773d49434bf2e7ef3efc972e0d3cd273",
          "score": 7,
          "created_utc": "2026-02-16 09:12:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nmoj4",
              "author": "LeRouxGongle",
              "text": "Be careful, we can still see your name in the link you sent us.\nBut it‚Äôs funny to see that LeChat responded to you in Spanish instead of English like the question.",
              "score": 3,
              "created_utc": "2026-02-16 09:25:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nn2de",
                  "author": "Nefhis",
                  "text": "No worries üòÖ It's public on the ambassador's page, so...  \nIt has the instruction to answer always in Spanish.",
                  "score": 4,
                  "created_utc": "2026-02-16 09:29:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nm43z",
              "author": "Poudlardo",
              "text": "I tried this by myself just 20 minutes ago. It told me to walk as well\n\nMaybe something different is that I activated \"Think\" button",
              "score": 2,
              "created_utc": "2026-02-16 09:19:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5nmm13",
                  "author": "Nefhis",
                  "text": "The problem is the prompt. The original prompt is deliberately ambiguous (not to say absurd). In fact, once the thinking process is activated, it fails. And its chain of thought is worth reading, saying something like this: \"The user is asking me if it's better to walk or drive. I suppose it's for exercise, because if they wanted to take the car there, it's obvious they would drive...\"",
                  "score": 2,
                  "created_utc": "2026-02-16 09:24:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nmdob",
              "author": "MattyGWS",
              "text": "https://preview.redd.it/6ywdkr4brtjg1.jpeg?width=1179&format=pjpg&auto=webp&s=b13ac07d51ebf20fbe6719ce8263782109c84641",
              "score": 1,
              "created_utc": "2026-02-16 09:22:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5nooda",
              "author": "harryjrk",
              "text": "Actually,  you've changed the original prompt.  Original was more vague.",
              "score": 1,
              "created_utc": "2026-02-16 09:44:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nph9j",
                  "author": "Nefhis",
                  "text": "Yes, I did üòä\n\nhttps://preview.redd.it/dmoffj1lwtjg1.png?width=1402&format=png&auto=webp&s=f6adb2babba02a6033574246441b1756977f69d6\n\n",
                  "score": 2,
                  "created_utc": "2026-02-16 09:52:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ouyea",
          "author": "Commercial-Lemon2361",
          "text": "Bru.\n\nhttps://preview.redd.it/pwcryv1xcvjg1.jpeg?width=1125&format=pjpg&auto=webp&s=2b9a26e17f77561549959607ae79f40045b5b127",
          "score": 3,
          "created_utc": "2026-02-16 14:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5owplg",
              "author": "Commercial-Lemon2361",
              "text": "BRU.\n\nhttps://preview.redd.it/34gcbpxjevjg1.jpeg?width=1125&format=pjpg&auto=webp&s=9efe22017531a6abc67bbf90d81c720a2f80be13",
              "score": 1,
              "created_utc": "2026-02-16 14:54:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5oxcfw",
                  "author": "Commercial-Lemon2361",
                  "text": "Idk man.\n\nhttps://preview.redd.it/4jwyizh5fvjg1.jpeg?width=1125&format=pjpg&auto=webp&s=e1dec46023002c6a612623820b70657f022ff722",
                  "score": 1,
                  "created_utc": "2026-02-16 14:57:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5okppz",
          "author": "Fuskeduske",
          "text": "https://preview.redd.it/i0dxaa333vjg1.png?width=1138&format=png&auto=webp&s=2977606fa1b7ad70230127f3fd29f3fe063a0696\n\nchatgpt\n\nGemini and grok gets it right, but both cite ycombinator as reference = they find the hackernews article and says, hey something ain't right, so the outcome here is pretty much skewed",
          "score": 2,
          "created_utc": "2026-02-16 13:50:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pfy05",
          "author": "I_AM_CAULA",
          "text": "r/fuckcars",
          "score": 2,
          "created_utc": "2026-02-16 16:27:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pihra",
              "author": "Poudlardo",
              "text": "his answer is on purpose, AI definetely got it haha",
              "score": 1,
              "created_utc": "2026-02-16 16:38:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qzov3",
          "author": "GarmrNL",
          "text": "Language understanding != world understanding üòÑ\n\nI asked Mistral the following question (as it failed to give the correct answer for me aswell):\n\nI‚Äôve played with embeddings a while back; ‚ÄúI want to wash my car‚Äù and ‚ÄúI want to wash my <whatever>‚Äù have the same cosine similarity and thus intent. The car is metadata for the intent and the intent is in a different sentence than the actual question ‚Äúshould I walk or go by car‚Äù, right? Is this the root of this gotcha perhaps, or don‚Äôt you use embeddings this way?\n\nAnswer (pretty interesting deeper dive):\n\nYou‚Äôre absolutely diving into the heart of the issue! Let‚Äôs break it down technically and conceptually:\n\n---\n\n### **1. Embeddings and Intent Recognition**\nYou‚Äôre right: In a pure embedding space (e.g., using models like BERT, Ada, or others), the sentences *\"I want to wash my car\"* and *\"I want to wash my dog\"* might have **high cosine similarity** for the *intent* of \"washing something.\" The object being washed (car, dog, etc.) is often treated as a \"slot\" or metadata, while the core intent (\"washing\") dominates the semantic representation.\n\n- **Intent:** \"I want to wash [X]\"\n- **Question:** \"Should I walk or drive?\"\n\nWhen processed separately, the model may not strongly link the object ([X] = car) to the decision (walk/drive) unless the context is explicitly connected. The **intent** (\"washing\") and the **logistical question** (\"walk or drive\") are parsed as somewhat independent clauses, especially if the model isn‚Äôt explicitly trained to resolve such dependencies.\n\n---\n\n### **2. The Gotcha: Contextual Dependency**\nThe \"gotcha\" arises because:\n- **Humans** automatically infer that washing a car requires the car to be present at the location, so the *object* (car) is critical to the decision.\n- **Embeddings** (in isolation) may not always capture this **causal dependency** unless the model is fine-tuned or the context is tightly coupled. The relationship between \"washing a car\" and \"needing the car at the car wash\" is **world knowledge**, not just semantic similarity.\n- **Multi-sentence reasoning:** The model processes your input as two separate statements. The intent (\"wash my car\") and the question (\"walk or drive?\") are not inherently linked unless the model‚Äôs attention mechanism or context window explicitly connects them.\n\n---\n\n### **3. How Models Like Mine Handle This**\n- **Attention mechanisms** (in transformers) try to weigh the importance of each word/phrase relative to others, but they‚Äôre not perfect. If the context is split across sentences, the model might not always \"realize\" that the car‚Äôs presence is required for the washing.\n- **World knowledge gaps:** While models like me have vast knowledge, we don‚Äôt always \"reason\" like humans. We rely on patterns in data, and if the training data doesn‚Äôt emphasize the dependency (e.g., \"washing a car requires the car to be at the car wash\"), the model might miss it.\n- **No explicit \"common sense\" module:** Unlike humans, we don‚Äôt have an innate understanding of physics or practical constraints (e.g., you can‚Äôt wash a car without the car being there). This is a known challenge in AI.\n\n---\n\n### **4. Why This is Hard to Fix**\n- **Data sparsity:** Most training data doesn‚Äôt contain trick questions or explicitly teach these dependencies.\n- **Ambiguity:** In everyday language, people rarely ask, \"Should I walk or drive to wash my car?\" with the car‚Äôs presence as the crux. So, the model isn‚Äôt primed to spot the inconsistency.\n- **Embeddings alone aren‚Äôt enough:** Resolving this requires **reasoning** (e.g., \"Does the object need to be at the location for the intent to be fulfilled?\"). This is an active area of research (e.g., commonsense reasoning, causal inference).\n\n---\n\n### **5. How to Improve This?**\n- **Fine-tuning:** Train on datasets with explicit examples of such dependencies.\n- **Prompt engineering:** Frame the input to force the model to connect the dots (e.g., *\"I want to wash my car at a car wash 50m away. Should I walk or drive there, given that the car needs to be washed?\"*).\n- **Hybrid systems:** Combine embeddings with symbolic logic or knowledge graphs to enforce constraints (e.g., \"washing a car ‚Üí car must be present\").\n\n---\n\n### **6. The Bigger Picture**\nModels excel at patterns but struggle with implicit assumptions humans take for granted. It‚Äôs why AI can be brilliant at some tasks and hilariously off on others!\n\n‚Äî",
          "score": 2,
          "created_utc": "2026-02-16 20:49:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7z9f",
          "author": "flavius-as",
          "text": "Gemini fast is also off:\n\nhttps://preview.redd.it/2s2vjebyoujg1.jpeg?width=1080&format=pjpg&auto=webp&s=bcef93c34c49bb06d92dfe35d3f378e7e98a8aec\n\n\"Gemini thinking\" gets it right but with too much fuss.\n\nOnly \"Gemini pro\" does it like a human among the Gemini models.\n\nThe best response I get with my own prompt geared towards analytical problems:\n\nIt is not logical to walk there.\n\nWhile walking avoids the cold start, it creates a fatal logical error: **it separates the car from the car wash.** If you walk to the station, your car remains 50 meters away in your driveway, dirty. To achieve the objective \"wash my car at the station,\" the car must physically travel to the station.\n\nSince the car must move, you are facing an optimization problem regarding *how* and *when* it moves to minimize engine wear.\n\n### The Optimal Solution: Trip Chaining\n\nDo not make a dedicated trip just to wash the car. A 50-meter drive is indeed the worst operational case for an engine (running rich, high friction, condensation buildup in exhaust/oil without proper burnout).\n\n**Recommendation:** Wait until you are leaving for a longer drive (e.g., commuting to work or going to the store) or returning from one.\n\n* **Why:** If you wash it at the start of a trip, the subsequent driving burns off the condensation and warms the oil. If you wash it at the end, the engine is already warm. In both cases, the \"wear cost\" of the wash becomes negligible.\n\n### The Theoretical Minimum: Manual Propulsion\n\nIf you must wash the car *right now* and absolutely refuse to start the engine, you can put the car in neutral and push it the 50 meters to the station.\n\n* **Why:** This technically satisfies all constraints (clean car + zero engine starts).\n* **Caveat:** This is physically demanding, potentially unsafe on a public road, and you may still need to start the engine to exit the automated bay or operate power brakes/steering.\n\n### Conclusion\n\n**Do not walk.** Do not drive *just* to wash. **Chain the wash to a longer trip.**\n\n---\n\n### Assumptions & Boundary Conditions\n\nThis answer relies on the following assumptions:\n\n1. **Stationary Facility:** The \"automated station\" is a fixed location and does not offer a mobile service.\n2. **Car Dependency:** The objective is to wash the specific vehicle mentioned, which requires the vehicle's physical presence at the station.\n3. **No Home Equipment:** You do not have a hose and bucket at your current location (which would be the true zero-wear solution).\n\n### Deliberation Summary\n\n* **Initial position:** Walking is illogical because the car cannot get washed if it is left behind.\n* **Strongest challenge:** The \"Optimizer\" lens noted that simply pointing out the logical error (leaving the car behind) doesn't solve the user's valid concern about engine wear. The user needs a strategy to wash the car without incurring the specific damage they fear.\n* **Resolution:** The answer integrates \"Trip Chaining.\" This acknowledges that while the car must move, the *timing* of that movement is the variable to optimize. This allows the user to use the station without incurring the \"cold start penalty\" of a dedicated short trip.",
          "score": 1,
          "created_utc": "2026-02-16 12:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rcjm8",
          "author": "CodeBlurred",
          "text": "![gif](giphy|GpyS1lJXJYupG)\n\nGemini 3 FAST: \n\nSince the car wash is only **50 meters** away, you‚Äôve got a bit of a \"Catch-22\" on your hands!\n\n# The Short Answer\n\n**You should drive.** While 50 meters is a very short distance (about half a soccer field), it‚Äôs much easier for the car wash team to handle the vehicle if it's already there. Plus, unless you have a very long extension cord or a mobile detailing kit, you can't exactly bring the car wash to the car!\n\n# Why Driving Wins\n\n* **Logistics:** Most car washes require the vehicle to be positioned in a specific bay or on a conveyor belt.\n* **Efficiency:** It will take you about 5 seconds to drive there versus 45 seconds to walk.\n* **The Goal:** Since the objective is to get the *car* clean, the car needs to make the trip.\n\n# When to Walk\n\nThe only reason to walk those 50 meters is if you are heading there to **book an appointment** or check if there is a long line before you bother pulling the car out of the driveway.\n\n**Pro-tip:** If it's a sunny day, driving that short distance won't even give your engine time to warm up, so just take it slow!\n\nWould you like me to check the **weather forecast** for your area to make sure it‚Äôs not going to rain right after you finish?",
          "score": 1,
          "created_utc": "2026-02-16 21:52:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ses63",
          "author": "RnRau",
          "text": "Solved as long as you give it a hand... with gpt-oss-20b (reasoning = high) since its the one I have loaded; \n\n> I want to wash my car. The car wash is 50 meters away. Should I walk or drive?\n> \n> These are the assumptions you should consider-  everything else is irrelevant;\n> \n> * the car and I are both at home.\n\nI have noticed this before with logic puzzles. If you ask for the model's assumptions before it tells you its solution, you can usually spot any incorrect information that is part of its 'world view'. Correct it and then tell it to give the answer.",
          "score": 1,
          "created_utc": "2026-02-17 01:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u310a",
          "author": "Angcb",
          "text": "To be fair, I saw this right after breakfast and for a few seconds my first reaction was also to think \"it's better to walk since it's very close\" ü§°",
          "score": 1,
          "created_utc": "2026-02-17 08:47:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uexgh",
          "author": "troyvit",
          "text": "I got downvoted on HN for noting that if you asked a human this question they would wonder why you were being so dense. Any time I knowingly ask an AI a dense question (and  I'm a Mistral guy to a fault I have to admit), I ask it to ask me any followup questions, and in this case Mistral asked:\n\nBefore providing a recommendation, could you please clarify the following:\n\n1. What are the current weather conditions (e.g., rain, snow, strong winds)?\n2. Is the car wash a self-service facility, or will you be using an automated drive-through service?\n3. Are there any specific reasons you might prefer walking (e.g., exercise, environmental considerations) or driving (e.g., convenience, time constraints)?\n\nQuestion 3 basically \"solved\"  for the blind spot by putting the logic back on me. Gee why \\_would\\_ I prefer walking to the car wash? I said, \" I would prefer walking for both exercise and environmental considerations, but in this case it is more timely and convenient to drive, but not because it's faster to get there. Can you guess why it's better for me to drive in this case? \" and Mistral guessed right.",
          "score": 1,
          "created_utc": "2026-02-17 10:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6101gm",
              "author": "DerpSenpai",
              "text": "The only issue here is that mistral large doesn't have a reasoning model yet, if it did, it would clear this question easy.",
              "score": 1,
              "created_utc": "2026-02-18 09:57:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o60bmgp",
          "author": "ilgalles",
          "text": "Gemini gets this right. I've tried both English and my mother language (Italian) and the answer is correct and consistent both times.\n\nhttps://preview.redd.it/320v55gv37kg1.png?width=1080&format=png&auto=webp&s=bfe343b57c7c05e84fb7f574ceb177e7f74742a0",
          "score": 1,
          "created_utc": "2026-02-18 06:16:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60lfbv",
          "author": "Morvax666",
          "text": "DeepSeek got it right, but only with DeepThink activated. Otherwise it also suggest to walk.\n\nhttps://preview.redd.it/1gtgynm2j7kg1.png?width=818&format=png&auto=webp&s=e70a5325c8a0afb8b45b3e96c884ee686643164c\n\n",
          "score": 1,
          "created_utc": "2026-02-18 07:41:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60xfvz",
          "author": "Eastern-Tomatillo295",
          "text": "https://preview.redd.it/3tunrbhy28kg1.png?width=2316&format=png&auto=webp&s=60898f699140dcf7be472c6f191fe9eb5a180147\n\nMy AI interview tool gets it right. HAHA.   \n  \n[https://interviewmate.tech/](https://interviewmate.tech/) \n\nif anyone's curious",
          "score": 0,
          "created_utc": "2026-02-18 09:34:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6ft79",
      "title": "I'm curious, what's your Mistral AI workflow/skills/agents ?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/",
      "author": "NacioFelix",
      "created_utc": "2026-02-16 17:24:55",
      "score": 28,
      "num_comments": 5,
      "upvote_ratio": 0.95,
      "text": "Hey everyone,\n\nI'm really curious about how different people use Mistral AI in their daily work. Whether you're a developer, an API user, an enterprise user, or a cybersecurity engineer, I'd love to hear about your workflows, skills, and any agents you use.\n\n1. **Developers:** What tools and techniques do you use with Mistral AI? Any particular workflows that have made your life easier?\n2. **API Users:** How do you integrate Mistral AI into your applications? Any tips for optimizing API usage?\n3. **Enterprise Users:** How does your **team/company** leverage Mistral AI? Any best practices or success stories you can share?\n4. **Cybersecurity Engineers:** How do you use Mistral AI in your security workflows? Any specific skills or agents that you find particularly useful?\n\nLooking forward to hearing about your experiences and learning from your insights!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5v7r2x",
          "author": "R4-M9",
          "text": "In my role as a developer - I might fulfill different roles in my team here -, I just use the web interface to ask my questions and paste some shorter or very very long code snippets regarding those. Sometimes this is like some kind of rubber duck debugging, some times my Cogitator(\\*) gives me the right ideas how to proceed for a specific problem, seldom he is completely off track. This happens of course, but normally not.\n\nThe best feature however is to let the AI generate an overview what the heck the code is about, because inherited code of course never comes with any docu whatshowever since people are a\\*\\*hats plus often seem to think in convoluted ways, I guess. \n\nI have organized all my long term stuff dialogs into projects, which seems to enable my AI instance to have a pretty good grasp of the stuff I'm working on, what kind of database info is available in the background and so on.\n\n\n\n\\* Regarding the name Cogitator, yes, it has a defined name for me and a myriad of settings beside thad for tone and instructions applied and some basic info library about me and my equipment. \n\nThis way, I get very short and concise answers, never follow-up questions if not absolutely necessary, no senseless smalltalk and all the stuff I despise regarding standard settings especially on chattybots like ChatGPT.\n\nIf I indeed feel like reading walls of text, I still have one agent configured for that, but this is seldom used and never for programming or other tech stuff.\n\nOf course, I'm on paid subscription. I'd rather cancel netflix or similiar services.",
          "score": 3,
          "created_utc": "2026-02-17 14:00:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uxyiu",
          "author": "Proof-Summer1011",
          "text": "Currently using two Mistral agents as research and teaching assistants (of course no sensitive data is shared). They help with anticipating questions, clarifications, and style for academic articles.",
          "score": 2,
          "created_utc": "2026-02-17 13:04:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w7j4f",
          "author": "Mrsl024",
          "text": "I am using two agents right now:\nCaption-generator: I upload a pdf, website or some basic text of an event I am photographing a pressagency, the agent is generating a text of 40 words that go with the photos, 15 keywords and a title\n\nAn assistant: a generic assistent with whom I can talk about work stuff (as freelance photojournalist), advice related to work, write email etc.",
          "score": 2,
          "created_utc": "2026-02-17 17:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5r326k",
          "author": "filz",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-02-16 21:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r392q",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-02-17 21:06:15 UTC**](http://www.wolframalpha.com/input/?i=2026-02-17%2021:06:15%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/o5r326k/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FMistralAI%2Fcomments%2F1r6ft79%2Fim_curious_whats_your_mistral_ai%2Fo5r326k%2F%5D%0A%0ARemindMe%21%202026-02-17%2021%3A06%3A15%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r6ft79)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-16 21:07:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r59dhw",
      "title": "Mistral LeChat: do you really use it?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r59dhw/mistral_lechat_do_you_really_use_it/",
      "author": "Ok_Sky_555",
      "created_utc": "2026-02-15 08:22:35",
      "score": 27,
      "num_comments": 40,
      "upvote_ratio": 0.73,
      "text": "**Update:** after removing all chats, it started answering correctly. Cleaning up memories I tried before did not help.   This is strange....\n\nI asked LeChat the following question (I really wanted to find this out):\n\n`There is a video called \"Rhapsodie in Blech\" (for example, here: https://www.youtube.com/watch?v=MGUQh8-d2bc)`  \n`The cars there are test cars driven by professionals to check how they behave in tricky situations, or are these regular car owners?`\n\nThe answer was \"I was unable to access the specific content of the video directly, but based on general knowledge and the context of videos like \"Rhapsodie in Blech\" (which is a well-known German TV show), the cars are test cars driven by professional drivers. ....\"\n\nThis is fatally wrong.  \nI copy pasted the same question to gemini, chatgpt and proton lumo. They all answered correctly. Like:\n\n`‚ÄúRhapsodie‚ÄØin‚ÄØBlech‚Äù is a compilation of crash footage that was filmed in 1970 on the N√ºrburgring‚Äôs Adenauer‚ÄëForst section.‚ÄØThe material comes from the private camera work of J√ºrgen‚ÄØSander (and later Manfred‚ÄØF√∂rster), who stood at the side of the track and recorded ordinary drivers attempting laps on the ‚ÄúGreen Hell....‚Äù`\n\nThe title of the film is rather unuque; you do not need to \"watch\" video to answer the question.\n\nYes, LLMs do mistakes, I know. But for this kind of question, I expect a correct answer.  And all except Mistral delivered it.\n\nI like Mistral - EU, not a that big tech and so on - all that is great. But after this experience I'm not sure that I can use Mistral for anything. Really, really said.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r59dhw/mistral_lechat_do_you_really_use_it/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5h9b2r",
          "author": "Nefhis",
          "text": "I don‚Äôt know how you asked, but I did the same question and it answered right on the first shot:\n\nhttps://chat.mistral.ai/chat/27b243a0-0063-45b1-a4fd-b054ee9b912b",
          "score": 21,
          "created_utc": "2026-02-15 08:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h9zxv",
              "author": "Ok_Sky_555",
              "text": "Intersting. Are you pro/free? Why it answered in french, when the question is in English?",
              "score": -8,
              "created_utc": "2026-02-15 08:53:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hae9g",
                  "author": "Nefhis",
                  "text": "It answered in Spanish, because the question was in Spanish. I‚Äôm on Pro subscription.",
                  "score": 10,
                  "created_utc": "2026-02-15 08:57:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hdlsv",
          "author": "andriatz",
          "text": "You probably don't have web search enabled in your tools.",
          "score": 11,
          "created_utc": "2026-02-15 09:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5i0i1s",
              "author": "Fuskeduske",
              "text": "100% seems like a user fault, i've tried wording my prompt 5 different ways and i still get the right output.",
              "score": 7,
              "created_utc": "2026-02-15 12:54:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h9tyi",
          "author": "schacks",
          "text": "not sure what is going on but I just tried your prompt and got this answer:\n\n`In the video \"Rhapsodie in Blech,\" the cars are driven by regular car owners, not professionals. The footage features tourists and enthusiasts driving their own cars on the N√ºrburgring track.`",
          "score": 8,
          "created_utc": "2026-02-15 08:51:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ha9bt",
              "author": "Ok_Sky_555",
              "text": "This situation confuses me. I'm on free plan, no special settings I can think about.\nWhat about you?",
              "score": -2,
              "created_utc": "2026-02-15 08:55:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hav1n",
                  "author": "schacks",
                  "text": "I have an pro/education account, but according to other comments on your post that isn‚Äôt the reason. I don‚Äôt know.\n\nGenerally I‚Äòm very satisfied with the results I get from LeChat. I often use it to do research and the quality is quite good.",
                  "score": 6,
                  "created_utc": "2026-02-15 09:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hbs82",
          "author": "GarmrNL",
          "text": "I use Mistral daily, both Le Chat aswell as a locally running model that's the brains of a project I'm working on. I use it as a creative tool/partner and it shines for that. If I want to look up facts about content the model might not be trained on, or its tools cannot find the answer to, I use Google. Fact is, all models can make mistakes, and to verify those mistakes you have to search for the answer to your question yourself anyway :-) It's a bit of a catch 22 that makes me not use an LLM like a search engine (same reason I don't eat my soup with a power drill). Your frustration is understandable, but I think for this use case you used the wrong tool for the job.",
          "score": 5,
          "created_utc": "2026-02-15 09:10:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hci1g",
              "author": "Ok_Sky_555",
              "text": "I do not agree. The task is search + analysis, And the film is form 70s. An AI chat with the search tool (actually, even the naked model) must be able to do this. ",
              "score": 0,
              "created_utc": "2026-02-15 09:17:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hdpia",
                  "author": "GarmrNL",
                  "text": "I agree on the part about the search tool; it \\*should\\* work, but my initial post is still about answering your question whether people use it and I still don't replace search engines (or critical thinking) with the output of an LLM (that's basically why every LLM has the warning to verify results. If I need to verify my answers every time, I'm faster by just looking the answers up myself). Don't read my post as criticism or sarcasm though, it's just an honest reply to your question about how I use Mistral/Le Chat/any other LLM I interact with.",
                  "score": 1,
                  "created_utc": "2026-02-15 09:29:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5h8uo4",
          "author": "kamaral",
          "text": "Honestly these types of posts are just getting incredibly tiresome, model X can do Y but Mistral fails, I want Mistral to be like this model but European. \n\nIt's quite obvious Mistral is not aiming to compete with Anthropic and OpenAI by creating a general model that seems to be good at everything, nor do they have the resources to do so. Their focus is B2B and creating tools for specific niches (see examples with Document OCR and Voxtral), while also exploring areas like vibe coding.",
          "score": 15,
          "created_utc": "2026-02-15 08:42:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h9teu",
              "author": "Ok_Sky_555",
              "text": "I do not want it to be \"like this model\", I just want lechat to be useable.\n\n\nAnd it is not that obvious that mistral does not want lechat beung used. Why then they even create it? To demonstrate b2b OCR functions?",
              "score": 2,
              "created_utc": "2026-02-15 08:51:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hdikc",
                  "author": "kamaral",
                  "text": "Well, I think your definition of usable might not fit with what LeChat is capable of. Although several commenters have pointed out, for them it seemed to actually answer correctly.\n\nWhat I wanted to say is that the majority of Mistral's focus is not on Le Chat, but on their other products. I think Le Chat was created to give regular consumers an alternative to other similar tools that is affordable and \"good enough\". It doesn't excel at anything in particular, but you can get basic stuff done with it. It's more to create brand awareness and get eyes on what the company is doing. But hey, that's just my 2 cents.",
                  "score": 1,
                  "created_utc": "2026-02-15 09:27:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nhga0",
              "author": "grise_rosee",
              "text": "In addition, you have:\n\n\\- these posts/comments where people happily mix the perfs of closed models with local heavily quantified open-sourced ones.\n\n\\- these posts/comments where people want AI to Role-Play and not producing stereotyped outputs, which  are the contrary of what people want in a professional context.",
              "score": 1,
              "created_utc": "2026-02-16 08:35:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5kecbg",
              "author": "guyfromwhitechicks",
              "text": "> It's quite obvious Mistral is not aiming to compete with Anthropic and OpenAI\n\nThen why are they charging the same? Slash it in half to reflect the current state of the models.",
              "score": 1,
              "created_utc": "2026-02-15 20:21:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hd95c",
          "author": "whoisyurii",
          "text": "Honestly, I love mistral. It handles my native language better than Gemini, especially voice input.\nFor vibe cli (for coding) it has a huge potential and in certain places much intuitive and GOD FASTER than claude code.",
          "score": 3,
          "created_utc": "2026-02-15 09:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i0f34",
          "author": "Fuskeduske",
          "text": "The cars in the \"Rhapsodie in Blech\" video are not test cars driven by professionals, but rather regular cars owned and driven by tourists and enthusiasts. The footage shows 1960s and 1970s family and sports cars being driven on the N√ºrburgring during public \"touristenfahrten\" (tourist driving) days, where anyone could take their own car onto the track. The crashes and mishaps captured in the film are the result of regular car owners pushing their limits on the notoriously tricky N√ºrburgring circuitautoweek.com+2.\n\nLe chat",
          "score": 3,
          "created_utc": "2026-02-15 12:53:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5it8ze",
          "author": "Prudence-0",
          "text": "I'd like to like Mistral's models (acute chauvinism), but it's clear that their models aren't up to the level of the competition (online or self-hosted).\n\nIt's a real shame because the team is very competent‚Ä¶\n\nEurope should invest (finance) in its champions (there are some very good German ones too), instead of squandering subsidies on small local projects (‚Ç¨20k here, ‚Ç¨100k there).\n\nEurope has funds‚Ä¶ but unfortunately, their allocation is a disaster and doesn't help the emergence of international rivals.",
          "score": 3,
          "created_utc": "2026-02-15 15:41:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h78ui",
          "author": "Zafrin_at_Reddit",
          "text": "Mistral is‚Ä¶ pretty bad. From time to time, I try to reproduce stuff I get done with Haiku/Sonnet. For coding, it is‚Ä¶ OK. But once it has to do any search or data retrieval, it just crashes and hallucinates.\n\nAnd that makes me sad. I really want an EU LLM at least on par with Sonnet.",
          "score": 12,
          "created_utc": "2026-02-15 08:26:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5htruz",
          "author": "New_Philosopher_1908",
          "text": "It is very good for my needs. I've had very little problems with it. I like its tone, it doesn't feel fake. I guess for people really needing complicated tools it might not do the job but for general usage I think it's very good.",
          "score": 2,
          "created_utc": "2026-02-15 12:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jr4ix",
          "author": "darktka",
          "text": "Works fine for me, I got a perfectly correct answer with default settings. And other than that: yes, I use it. Before switching from ChatGPT, I made some side by side comparisons for tasks relevant for me by copying my old prompts to leChat. LeChat generally performed equally well and in many highly relevant cases even better than ChatGPT. In addition, it's very fast and performant. I also use small local models for mundane/clerical tasks related to private data. I am using Vibe on a daily basis and it does the job for me. I am not a professional coder but a scientist, so my demands might be easier to meet here.",
          "score": 2,
          "created_utc": "2026-02-15 18:26:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h7rm4",
          "author": "Timotheegardenmaster",
          "text": "I also get disappointing results with it in general.\nI pay for Pro to support the endeavor, but for now, I‚Äôm glad I have a ChatGPT Pro through my job to actually get correct answer to queries.",
          "score": 2,
          "created_utc": "2026-02-15 08:31:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hj4ep",
          "author": "Amorphous-Rogue",
          "text": "I have using mistral as my daily driver (along with many other models) but i noticed very recently it failed grotesquely at basic logic in certain scenarios. I would give it another chance but I don‚Äôt feel it‚Äôs normal based on my past experience!",
          "score": 1,
          "created_utc": "2026-02-15 10:21:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ihx20",
          "author": "guyfromwhitechicks",
          "text": "Not really, no.\n\nI have been a paid subscriber for 5 or so months because I really liked the research feature. But I started noticing all the errors/wrong conclusions it got from articles and how a good amount of the sources are quite poor in quality. So, unless they make `mistral-vibe`quite good, I think I am going to cancel.",
          "score": 1,
          "created_utc": "2026-02-15 14:42:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jf6zp",
          "author": "Express_Reflection31",
          "text": "I like mistral for trouble shooting, but use gemini and chatgpt for other things.",
          "score": 1,
          "created_utc": "2026-02-15 17:28:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nful1",
          "author": "grise_rosee",
          "text": "It's pretty clear Lechat was unable to use its search tool for some reasons. It even told you so. Did you disable it in the tools section?",
          "score": 1,
          "created_utc": "2026-02-16 08:20:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69nlbl",
          "author": "SquareRoot_Log",
          "text": "It fails equally as other models on tests like \"Car Wash\".\nThe image generation is maybe not as good, but overall, in terms of search and reasoning, it gives good results like models from giant U.S. companies.\n\nYou might need to tweak your settings to unable web search.",
          "score": 1,
          "created_utc": "2026-02-19 16:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h8h8c",
          "author": "EzioO14",
          "text": "I use it for some stuff, but what I do most is use it thought open web Ui where I have more control on what it outputs and I prefer the answers there tbh.",
          "score": 1,
          "created_utc": "2026-02-15 08:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hb7bn",
          "author": "Plane-Lie-4035",
          "text": "I just aked the same question and here is the response: The video \"Rhapsodie in Blech\" features footage from the N√ºrburgring Nordschleife in 1970, specifically the Adenauer Forst section. The cars shown are driven by regular car owners, not professional test drivers. The compilation is famous for capturing the often chaotic and sometimes reckless driving behavior of amateur drivers on the track during public or \"tourist\" driving days, rather than controlled testing by professionals. The video highlights how ordinary enthusiasts pushed their cars‚Äîand sometimes their luck‚Äîto the limit, resulting in numerous crashes and mishaps  ‚Äã‚Å†.\n\nIn summary: these are regular car owners, not professional test drivers. The video is a historical snapshot of amateur driving on one of the world‚Äôs most challenging race tracks.",
          "score": 1,
          "created_utc": "2026-02-15 09:04:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hbqvy",
              "author": "Plane-Lie-4035",
              "text": "But sometimes even on pro it gets wrong. I asked it once about some functionality in claudcode and it told me that beeing a clone of vs code i can install a vscode extension üòÇ",
              "score": 1,
              "created_utc": "2026-02-15 09:10:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hgk2a",
          "author": "iBukkake",
          "text": "I don't use Le Chat for much but I do use the APIs and I am trying to make them my default models for dev applications.",
          "score": 0,
          "created_utc": "2026-02-15 09:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mr5c4",
          "author": "markleoit",
          "text": "Nah‚Ä¶ Mistral stuff is not very good. Passable if used for free; but definitely not worth a penny.",
          "score": 0,
          "created_utc": "2026-02-16 04:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h8wsc",
          "author": "PigOfFire",
          "text": "Yea, medium 3 was nice for its price back in the day, but large 3 is broken from the beginning. Again Mistral is so behind, even in local models. Weird situation. No idea why it happens with them.",
          "score": -4,
          "created_utc": "2026-02-15 08:42:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5i0nyh",
              "author": "Fuskeduske",
              "text": "Their local models are great lol\n\nLe Chat does \"suck\" compared to for example gemini tho, but i'd still rather use it.",
              "score": 1,
              "created_utc": "2026-02-15 12:55:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5j1x8q",
                  "author": "PigOfFire",
                  "text": "And Ministral ‚Äûsuck‚Äù compared to Gemma, and Small is‚Ä¶ maybe decent for 24B :D (not for coding)",
                  "score": 1,
                  "created_utc": "2026-02-15 16:23:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r41yay",
      "title": "Comparing v2.0.2...v2.1.0 ¬∑ mistralai/mistral-vibe",
      "subreddit": "MistralAI",
      "url": "https://github.com/mistralai/mistral-vibe/compare/v2.0.2...v2.1.0",
      "author": "guyfromwhitechicks",
      "created_utc": "2026-02-13 21:37:28",
      "score": 26,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r41yay/comparing_v202v210_mistralaimistralvibe/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o58jxan",
          "author": "guyfromwhitechicks",
          "text": "I am not entirely sure why this is not getting more attention in this sub. From the poll I conducted last week, I know a good 20% of users in this subreddit are focused on it or are actively using it. Anyway, here is the summary:\n\n## [2.1.0] - 2026-02-11\n\n### Added\n\n- Incremental load of long sessions: windowing (20 messages), \"Load more\" to fetch older messages, scroll to bottom when resuming\n- ACP support for thinking (agent-client-protocol 0.8.0)\n- Support for FIFO path for env file\n\n### Changed\n\n- **UI redesign**: new look and layout for the CLI\n- Textual UI optimizations: ChatScroll to reduce style recalculations, VerticalGroup for messages, stream layout for streaming blocks, cached DOM queries\n- Bumped agent-client-protocol to 0.8.0\n- Use UTC date for timestamps\n- Clipboard behavior improvements\n- Docs updated for GitHub discussions\n- Made the Upgrade to Pro banner less prominent\n\n### Fixed\n\n- Fixed inaccurate token count in UI in some cases\n- Fixed agent prompt overrides being ignored\n- Terminal setup: avoid overwriting Wezterm config\n\n### Removed\n\n- Legacy terminal theme module and agent indicator widget\n- Standalone onboarding theme selection screen (replaced by redesign)",
          "score": 10,
          "created_utc": "2026-02-13 21:39:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5an570",
              "author": "PayDistinct5329",
              "text": "Thanks for the overview. Personally, I really like the fixed agents prompt overrides (been waiting for the fix). Didn't notice the less prominent Pro banner, however, I did \"feel\" something was more pleasent when using and I do remember being annoyed with that banner previously.",
              "score": 2,
              "created_utc": "2026-02-14 05:32:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b49jq",
          "author": "Old-Age6220",
          "text": "Well, I just tried to upgrade like 15min ago: error readme.md not found üòÜ",
          "score": 1,
          "created_utc": "2026-02-14 08:06:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ba735",
              "author": "guyfromwhitechicks",
              "text": "I installed through uv, so an update would be: `uv tool upgrade mistral-vibe`\n\nNo failures.",
              "score": 2,
              "created_utc": "2026-02-14 09:04:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bd87o",
                  "author": "Old-Age6220",
                  "text": "Ah, I think I tried to upgrade wrong package üòÜ",
                  "score": 1,
                  "created_utc": "2026-02-14 09:34:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5n99e0",
          "author": "Legitimate-Help8016",
          "text": "For me it's bugged, it won't show when rate limited. Just ending the \"generating\" instantly without any proper \"you are ratelimited\" I asked Gemini to fix it locally, working now.",
          "score": 1,
          "created_utc": "2026-02-16 07:18:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7i8x0",
      "title": "Mistral Agents: on second thought...",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7i8x0/mistral_agents_on_second_thought/",
      "author": "DespondentMoose",
      "created_utc": "2026-02-17 20:47:21",
      "score": 25,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I created a [post](https://www.reddit.com/r/MistralAI/comments/1r35orc/programmatic_managementcreation_of_agents_and/) a few days ago, talking about how much I loved playing around with the agents and the Python API for setting them up.  Unfortunately, I must say I've been reality checked in a bad way. The problems started when I wanted to create multiple agents and coordinate them. According to the API docs, it should be possible to [hand off tasks](https://docs.mistral.ai/agents/handoffs) from one agent to another. This approach enables workflows in which specialized agents handle different stages of a process. I expected that assigning specific tasks to specialized agents in my workflow would yield higher-quality responses than dumping all responsibilities on one agent.\n\nHowever, I can‚Äôt seem to get this process right. I think I am following the same setup as in the examples. But I run into the following:\n\n* Often, the first agent does not hand off tasks to the next one. It responds by itself (which ignores specialized knowledge and instructions down the line)\n* If a hand-off happens, they fail intermittently with the following (non-descript) error: `API error occurred: Status 500. Body: {\"object\":\"Error\",\"message\":\"Response failed during handoff orchestration\",\"type\":\"invalid_request_error\",\"code\":3000}`. Sometimes handoffs to one agent work, while those to an agent configured the same way fail, and I can't figure out why.\n* I ran into an issue where it seems that one agent expects another agent to have the same version: `{\"object\":\"Error\",\"message\":\"Agent with id ag_019c648a0ee173f78f14cf013b874f81 does not have a version 44\",\"type\":\"invalid_request_error\",\"code\":3000}`\n* I could not even get the examples on the website to work (same code 3000 error).\n\nSo, overall, this has been very frustrating. And to top it off, I just found out that OpenAI has a visual agent builder. I‚Äôve only played with it a bit, but it just seems to work. I am perfectly fine setting up agents using API calls (in fact, I think I prefer that). But if things just don‚Äôt work and errors are nondescript, I find it difficult to stay on board with Mistral. I fully understand that scale differences are at play here, and any argument you can make in favor of Mistral, I‚Äôve probably already thought of :). I am really rooting for them and hope they succeed, but this is problematic, to say the least. Would love to hear other people‚Äôs experiences setting up multi-agent pipelines.\n\nI am using the Python SDK v1.12.2. I am on a pro subscription. Before anyone asks, yes, I submitted a ticket. I am using the Vibe client to debug.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7i8x0/mistral_agents_on_second_thought/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5z438g",
          "author": "wirtshausZumHirschen",
          "text": "Can feel your frustration.  \nWe tested many platform built agent solutions, and they often were buggy or limited us.  \nWorst was definitely OpenAI's code interpreter api omg.\n\nWhat I had much more success with, and what found its way into production, was using agent frameworks where the LLMs can be switched out easily.\n\nFor python I really like langgraph and smolAgents.   \nFor typescript Vercel's AI SDK is awesome. Langgraph also exists, but afaik it's not as extensive in javascript as in python.\n\nI always make sure to use an LLM api abstraction instead of directly interacting with inference providers such as Mistral, Nebius, GCP etc. On python langchain's LLM abstractions are good, but nowadays I even prefer LiteLLM. For typescript, again, the AI Sdk is great. Most LLM provider also use the OpenAI API schema, so that can be used. That way, you just need to change a single line of code to switch the inference provider (e.g. when you realize that Mistral LLMs don't cut it, or when a new model comes out)\n\nIn case you wanna use visual agent builder, I really enjoyed Flowise for this. You can easily self host flowise locally or on a server using docker or coolify. For production apps we aren't using Flowise that much anymore, as it's a bit cumbersome to add tools. However, to testing out agent flows and building a proof of concept fast, Flowise is real dope.\n\nAlso about \"I expected that assigning specific tasks to specialized agents in my workflow would yield higher-quality responses than dumping all responsibilities on one agent.\" - we often found that using multi-agent setups instead of one agent complicates things a lot, while not bringing that much improvements. Not saying that we found the perfect sub-agent flow though, just our experience.\n\nHope this helps you building something that actually works!\n\n",
          "score": 3,
          "created_utc": "2026-02-18 01:40:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zcvhv",
              "author": "DespondentMoose",
              "text": "Thanks for the flowwise mention. I will check it out. I did not know about this. The issue is that tools seem to pop up overnight, making it difficult to keep up. On the other hand, you'd expect that one would not \\*need\\* external tools to work with Mistral or any other provider (as long as you stay within one provider). ",
              "score": 1,
              "created_utc": "2026-02-18 02:25:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o62de20",
                  "author": "wirtshausZumHirschen",
                  "text": "I also thought in the beginning that tools pop up overnight.   \nHowever, once you get to know a few of them, you realize what are the differences between them, and that many of the \"new\" tools are not thaaaaat revolutionary as their landing page wants you to believe",
                  "score": 1,
                  "created_utc": "2026-02-18 15:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xs6dw",
          "author": "cosimoiaia",
          "text": "The way I have it working is by registering the agents first and then using them in a separate script with the workflow by saving the IDs.\nI remember when I was trying the first times that it took a few seconds for the system to have the agents available after the first API response. \nTry adding a delay between the calls or register the agents first and then grab the IDs.",
          "score": 2,
          "created_utc": "2026-02-17 21:29:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xvilv",
              "author": "DespondentMoose",
              "text": "Thanks. I have no issues talking to each agent independently. That works. The problem is with handoffs (and the conversation management for flows that include handoffs). \n\nAre you handling the workflow yourself (locally in the script), or are you asking the agents to hand off to each other?",
              "score": 2,
              "created_utc": "2026-02-17 21:44:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xzxur",
                  "author": "cosimoiaia",
                  "text": "Handoff works for me, the only differences from the example are that I have much more specific prompts, I tell explicitly, in the prompt, when to hand it over to the next agent(s), I have max 2 agents in the downstream and I create the agents only once, meaning that all the runs refer to the same IDs.",
                  "score": 2,
                  "created_utc": "2026-02-17 22:05:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60zvwh",
          "author": "Hector_Rvkp",
          "text": "It's funny, because what AI needs is... Software. The whole \"skills\" and \"agents\" craze is basically mark down files. And all we want from this incredibly powerful collection of 5 text files is a sequence of events. I'm no developer, but if you take a step back, it's prompt, agent 1 / model 1, then handover to agent 2 / model 2 and so on, with some recursive element to stay on track (maybe a project management agent). It's a bunch of if and loop functions. \nIn a similar vein, ballooning context windows should allow removing of previous messages and blocks in the window, before going into quantization. So much of the bleeding edge on this stuff is so incredibly basic. \nAnd the fact that LLMs can't go online to search for pricing. They somehow consistently gaslight me with fake prices, it's incredible. But it's progress, because a few months ago it didn't even go online... \nYesterday i found out about speculative decoding. For a lot of affordable hardware, it's a game changer, in my mind. And yet somehow nobody talks about it, it took a random YouTube video. \nWe're all drowning in tea cups and it's supposed to change the world.",
          "score": 1,
          "created_utc": "2026-02-18 09:56:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xk8di",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -4,
          "created_utc": "2026-02-17 20:51:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xlsci",
              "author": "DespondentMoose",
              "text": "In that case, I will ask them for the code, though. Code, or it did not happen! :)",
              "score": 1,
              "created_utc": "2026-02-17 20:59:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r65zuy",
      "title": "Live Translation with Voxtral Mini Realtime and DeepL",
      "subreddit": "MistralAI",
      "url": "https://github.com/alxlion/voxtral-live-translation",
      "author": "Alex-L",
      "created_utc": "2026-02-16 10:19:32",
      "score": 20,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r65zuy/live_translation_with_voxtral_mini_realtime_and/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r3s33u",
      "title": "Why is Mistral so talkative?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r3s33u/why_is_mistral_so_talkative/",
      "author": "Beyllionaire",
      "created_utc": "2026-02-13 15:26:24",
      "score": 18,
      "num_comments": 13,
      "upvote_ratio": 0.88,
      "text": "The answers given seem much longer than ChatGPT, I always have to tell it to be more concise while ChatGPT seems to know when answers need to be more elaborate and when they need to be synthetic a bit better. \n\nSometimes I ask a simple question and Mistral will want me to know EVERYTHING there is to know about a particular topic, even if I didn't ask for it. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3s33u/why_is_mistral_so_talkative/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o56fji5",
          "author": "Sudden-Armadillo-335",
          "text": "Perhaps you could check out its personality section in the settings? That way you can adjust it to be more concise if you prefer. Personally, I like it when it's precise.",
          "score": 16,
          "created_utc": "2026-02-13 15:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57otsp",
          "author": "New_Philosopher_1908",
          "text": "I have the opposite impression. Chat GPT just goes on and on, and always tries to suggest stuff even when you're done. Mistral is much more precise. I also like the way it doesn't use annoying words like 'vibe' all the time.",
          "score": 11,
          "created_utc": "2026-02-13 19:05:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57fcqm",
          "author": "pcx_wave",
          "text": "Opposite experience. Le chat responds like the average bored French civil servant when you ask a question at 4.45pm when checkout time is 5pm. Another way to see it is it will tell you stuff to make you slow down and think about what you just asked, he's not the motivational yes-man chatgpt is.",
          "score": 7,
          "created_utc": "2026-02-13 18:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57p71r",
              "author": "New_Philosopher_1908",
              "text": "I think it's friendly, precise and does not constantly attempt to praise you. Much prefer it in that way to ChatGPT and it's also better in terms of its default tone than Gemini imho.",
              "score": 2,
              "created_utc": "2026-02-13 19:07:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58dccg",
              "author": "SetObvious7411",
              "text": " I would prefer the subtle hints of a French civil servant over the loud and pointless yapping of an American uni brat.\n\nAlas I have the same experience as OP",
              "score": 1,
              "created_utc": "2026-02-13 21:07:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o2wtq",
          "author": "Worldly-Cherry9631",
          "text": "Mine is generally very consice, but i do add the metaprompt \"keep conversational padding to a minimum\" or \"give short anwser\" when incognito. I find ChatGPT way more talkative tho",
          "score": 2,
          "created_utc": "2026-02-16 11:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56fodt",
          "author": "Bregir",
          "text": "Give it a general instruction to be more concise unless explicitly asked otherwise?",
          "score": 1,
          "created_utc": "2026-02-13 15:29:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56grpc",
              "author": "Beyllionaire",
              "text": "I tried that but it seems to forget about it after a while",
              "score": 2,
              "created_utc": "2026-02-13 15:34:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56h0ud",
                  "author": "Bregir",
                  "text": "In the settings? (Personality, I think it is)",
                  "score": 0,
                  "created_utc": "2026-02-13 15:36:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o573w1r",
          "author": "CodeBlurred",
          "text": "Prompts‚Ä¶ everything came with clever prompts. Instructions for the machine need to be very precise. Unexpected results can happen, and we are still in 2026, not 2076 yet!",
          "score": 1,
          "created_utc": "2026-02-13 17:25:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o579632",
          "author": "Big_River_",
          "text": "mistral is the edge of the forest before the clearing - Le Chat is Le Buddy, oui/non?",
          "score": 1,
          "created_utc": "2026-02-13 17:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59373u",
          "author": "77bertrand77",
          "text": "GROK ‚ùó‚ùó‚ùó‚ùó",
          "score": 1,
          "created_utc": "2026-02-13 23:22:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7ii1i",
      "title": "Vibe Coding",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7ii1i/vibe_coding/",
      "author": "Legitimate-Help8016",
      "created_utc": "2026-02-17 20:56:44",
      "score": 17,
      "num_comments": 24,
      "upvote_ratio": 0.95,
      "text": "I'm about to get the pro plan but i still have question. How much can i use Vibe Coding in the Pro Plan? I don't see any limits anywhere..? Transparency? In my free plan im limited since 4 Days lol. And on Claude Code with Sonnet 4.5 im locked after 2.5hrs and after 3 days i have a weekly lock... Since Devstral-2 is not as good as claude, i guess i have to guide it more means even more usage. How much Devstra-2 can i expect? Hobby Coding for HomeAssistant and stuff...",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7ii1i/vibe_coding/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5xmrcs",
          "author": "ButtholeCleaningRug",
          "text": "I have yet to hit a limit, and I was using it extensively last week. It tends to be overeager when writing code and making changes. I've been playing with the prompting but have yet to get it dialed in. Just make it plan everything it wants to do and then review it before you set it loose; even then, monitor it closely. I liken it to an overly excited new employee who is trying to impress, and left unsupervised, will likely set a fire. I have academic pricing (\\~$6/mo), which is about as much as I think it's worth. But that's just my two cents.",
          "score": 12,
          "created_utc": "2026-02-17 21:04:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60qv5y",
              "author": "LegitimateBath9103",
              "text": "Exactly :)",
              "score": 1,
              "created_utc": "2026-02-18 08:32:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xo17s",
              "author": "Legitimate-Help8016",
              "text": "aight so i guess once in pro you can just let it go wild. The hard blocks of claude sucks so hard... i'll never understand, i cant even usw the normal chat with haiku or w/e....",
              "score": 1,
              "created_utc": "2026-02-17 21:10:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xpbax",
                  "author": "ButtholeCleaningRug",
                  "text": "Only if you want it to break everything! But more or less. If you're writing code it's pretty good at python. Benchmarks have it about parity with Sonnet 4.5, but I've found Sonnet to be more reliable. It lacks websearch (Claude has it). I would try it for a month and see what you think. I mostly keep Mistral because I like supporting European AI (I'm in the US, but still). ",
                  "score": 3,
                  "created_utc": "2026-02-17 21:16:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61eaig",
                  "author": "Ndugutime",
                  "text": "Just remember.  Any vendor can change limits at any time.  Mistral has been very generous so far.  But Google was too for a while.  Tokens are not free",
                  "score": 1,
                  "created_utc": "2026-02-18 11:57:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xmwwg",
          "author": "theKurganDK",
          "text": "Currently free according to this: https://docs.mistral.ai/mistral-vibe/introduction/configuration\n\nI haven't met any limits.",
          "score": 5,
          "created_utc": "2026-02-17 21:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xnxv6",
              "author": "Legitimate-Help8016",
              "text": "its free to use but not unlimited. Maybe \"unlimited\" as pro. Since 3 days:\n\nhi\n\nError: Rate limits exceeded. Please wait a moment before trying again.",
              "score": 2,
              "created_utc": "2026-02-17 21:09:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5yzw7y",
                  "author": "Ndugutime",
                  "text": "See my write up\n\nhttps://medium.com/@jallenswrx2016/the-mistral-vibe-a17b5907a51a?sk=c458be9c69e7b383f14c1f7870b8cf6b",
                  "score": 1,
                  "created_utc": "2026-02-18 01:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5zrrl4",
          "author": "Lost_Restaurant4011",
          "text": "Yeah the lack of clear limits is the real issue here. I can deal with caps if they are transparent, but guessing when you will suddenly hit a wall kills the flow, especially when coding. For hobby projects it is less about raw model quality and more about consistency and uptime. If Pro gives you steady access without surprise lockouts, that alone might be worth more than small performance differences between models.",
          "score": 2,
          "created_utc": "2026-02-18 03:52:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60lkqf",
              "author": "Legitimate-Help8016",
              "text": "You get a usage display in webui or CLI with Claude but it's way to strict and also will hard lock you out of chat lol. So it might happen that you vibe in code for 2 hours and can't use chat for the next 3 hours. Or you vibe for 2-3 days 2-3 sessions per day and you can't use Claude till next weekly reset. I guess Mistral is already better by soft limits. And vibe limit doesn't affect chat. That alone lets me tend towards Mistral. Unless they start enshitifcation.",
              "score": 1,
              "created_utc": "2026-02-18 07:43:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xza30",
          "author": "andriatz",
          "text": "One day",
          "score": 0,
          "created_utc": "2026-02-17 22:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60lp3l",
              "author": "Legitimate-Help8016",
              "text": "?",
              "score": 1,
              "created_utc": "2026-02-18 07:44:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61a7f8",
                  "author": "Ndugutime",
                  "text": "If you are on free.  It is one day.  If you spend for Pro , I have not hit a limit.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:25:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r7k06r",
      "title": "I feel like I'm using 2% of what Mistral can do",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7k06r/i_feel_like_im_using_2_of_what_mistral_can_do/",
      "author": "CryptographerDue2806",
      "created_utc": "2026-02-17 21:51:50",
      "score": 14,
      "num_comments": 3,
      "upvote_ratio": 0.95,
      "text": "Hello,\n\n  \nAlmost everything is in the topic. I use Mistral like other agent but mainly to search thing like I could use Google or Duck not really that much.\n\n  \nFor image generation, I ask for image and I really please of the result but I don't push that much because I don't really know how to ask or be better at prompting.\n\n  \nI see a lot of people enjoying AI that much but I feel like I don't know how to use the tool and don't understand for what it was made.\n\n  \nAnyone in the same situation but finally understood for what AI was made or do you use any course to be better at prompting and unlock the full potential of AI ?\n\n  \nBest regards.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7k06r/i_feel_like_im_using_2_of_what_mistral_can_do/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5y76o5",
          "author": "LoadZealousideal7778",
          "text": "Lol I forgot Le Chat can generate images. I used that feature once when I tested it and not since because I basically never need an image for something.",
          "score": 4,
          "created_utc": "2026-02-17 22:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ylwtx",
          "author": "EveYogaTech",
          "text": "You can take a look at workflow builders such as /r/Nyno (combining AI + any node, fully open-source, Apache2)",
          "score": 2,
          "created_utc": "2026-02-18 00:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yzc1f",
          "author": "[deleted]",
          "text": "> I see a lot of people enjoying AI that much but I feel like I don't know how to use the tool and don't understand for what it was made.\n\nit works well on small snippets of code\n\nlike a python script to plot some data.",
          "score": 1,
          "created_utc": "2026-02-18 01:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3lha1",
      "title": "Why the change",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/peeomfpcl8jg1.jpeg",
      "author": "Spliuni",
      "created_utc": "2026-02-13 10:11:39",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3lha1/why_the_change/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o55mu60",
          "author": "crazyserb89",
          "text": "Maybe they are trying to introduce the option to pull more than one agent in the same chat?",
          "score": 3,
          "created_utc": "2026-02-13 12:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55cpt0",
          "author": "crazyserb89",
          "text": "I have updated the app and it‚Äôs still the same.\n\nhttps://preview.redd.it/0wex07yx19jg1.jpeg?width=1206&format=pjpg&auto=webp&s=0af0daa72002541f35af26980ee24f8bd26e7420",
          "score": 2,
          "created_utc": "2026-02-13 11:44:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55f594",
              "author": "Spliuni",
              "text": "The change didn‚Äôt come for me with the last update either. It just suddenly appeared today out of nowhere.",
              "score": 1,
              "created_utc": "2026-02-13 12:03:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o569a82",
                  "author": "PalpitationOwn396",
                  "text": "A/B testing ?",
                  "score": 2,
                  "created_utc": "2026-02-13 14:58:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}