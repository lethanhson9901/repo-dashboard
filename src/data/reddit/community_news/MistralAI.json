{
  "metadata": {
    "last_updated": "2026-01-15 08:48:55",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 41,
    "total_comments": 163,
    "file_size_bytes": 188565
  },
  "items": [
    {
      "id": "1q7b8nj",
      "title": "French company Mistral AI signs major, historic agreement with the Ministry of the Armed Forces",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q7b8nj/french_company_mistral_ai_signs_major_historic/",
      "author": "Specific-Night-4668",
      "created_utc": "2026-01-08 13:03:38",
      "score": 416,
      "num_comments": 14,
      "upvote_ratio": 0.99,
      "text": "Garde √† vous ! Good news.  \nUnfortunately, the article is in French.  \n\n\n[Mistral agreement with French army](https://www.clubic.com/actualite-594283-le-francais-mistral-ai-signe-un-accord-majeur-et-historique-avec-le-ministere-des-armees.html)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7b8nj/french_company_mistral_ai_signs_major_historic/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nyeqm52",
          "author": "lomepol",
          "text": "Honestly, thank goodness we have Mistral in France and Europe. Between Roole Map and Mistral, I'm gradually starting to replace my habits with French apps.\n\nMaybe one day Europe will catch up the USA in AI race ?",
          "score": 53,
          "created_utc": "2026-01-08 15:06:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nye40mg",
          "author": "cosimoiaia",
          "text": "We can just ask Mistral to translate it!\n\n\"\"\"\nFrench AI Company Mistral AI Signs Major, Historic Agreement with the Ministry of the Armed Forces\nBy Alexandre Boero\nJournalist-Reporter, Head of News\nPublished January 8, 2026 at 1:14 PM\n\nThe French Ministry of the Armed Forces has just announced a landmark agreement with Mistral AI, focusing on technological sovereignty in French defense. The deal places generative artificial intelligence at the heart of the nation‚Äôs military strategy.\n\nThe Ministry of the Armed Forces signs a strategic framework agreement with Mistral AI for national defense AI.\n¬© Alexandre Boero / Clubic\n\nCan we speak of a technological turning point for the French armed forces and defense? On Thursday, January 8, 2026, the Ministry of the Armed Forces and Veterans Affairs announced it had formalized a framework agreement with Mistral AI. The partnership aims to equip all branches of the French military with cutting-edge generative artificial intelligence. This decision establishes the leading French AI company as a cornerstone of national technological sovereignty in defense‚Äîa sector marked by fierce international competition.\n\nMistral AI‚Äôs AI Deployed Across All French Armed Forces\nThe agreement between the Ministry of the Armed Forces and Mistral AI grants access to the models, software, and AI services developed by the company co-founded by Arthur Mensch. All branches, directorates, and services under the ministry will now be able to utilize these advanced solutions. This large-scale deployment profoundly transforms the technological capabilities of French defense and underscores the trust placed in national expertise.\n\nThe scope extends far beyond the armed forces alone. Several public institutions under the ministry‚Äôs supervision will also benefit from this access, including the French Alternative Energies and Atomic Energy Commission (CEA), the French Aerospace Lab (ONERA), and the Naval Hydrographic and Oceanographic Service (SHOM).\n\nThe Ministry‚Äôs Agency for Defense Artificial Intelligence (AMIAD) has been tasked with overseeing the entire initiative. Created to accelerate the development and integration of AI within the armed forces, the agency will now orchestrate this strategic partnership. Bertrand Rondepierre, its director, states, ‚ÄúBy integrating Mistral AI‚Äôs most advanced solutions, we are strengthening our position and preparing the armed forces for future challenges.‚Äù\n\nMaintaining France‚Äôs Technological Lead in AI\nMistral AI, now regarded as one of the global leaders in generative AI, boasts a research and development team considered ‚Äúamong the best in the world‚Äù by the ministry. This is a decisive advantage in a rapidly evolving sector, where each technological breakthrough can shift strategic balances and redefine operational capabilities.\n\nThe ministry, undeterred by Mistral AI‚Äôs collaborations with major American players like NVIDIA, fully embraces the sovereign dimension of this partnership. Working with Mistral AI ensures ‚Äúsovereign control over the tools used,‚Äù according to the official statement. From the state‚Äôs perspective, choosing a French company addresses the imperative of national independence in critical defense technologies.\n\n‚ÄúIt is crucial for France to maintain its technological lead,‚Äù the ministry emphasizes. The framework agreement embodies this ambition to make French excellence in AI a lever for military power and a bulwark against foreign technological dependencies in the years ahead.\n\"\"\"",
          "score": 45,
          "created_utc": "2026-01-08 13:08:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye4zmu",
              "author": "Specific-Night-4668",
              "text": "Thank you, I don't know why I didn't think of that.",
              "score": 11,
              "created_utc": "2026-01-08 13:14:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfcm3i",
          "author": "rrider1998-",
          "text": "Hopefully, it will become a pan-European AI.",
          "score": 10,
          "created_utc": "2026-01-08 16:45:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfxmt1",
          "author": "eylcop",
          "text": "Does that also means that the acquisition by apple is off the table?",
          "score": 10,
          "created_utc": "2026-01-08 18:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyefoce",
          "author": "darktka",
          "text": "Cool, can we now have Mistral Large 3 available in Le Chat?",
          "score": 11,
          "created_utc": "2026-01-08 14:12:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfznk2",
              "author": "alwaysstaycuriouss",
              "text": "You can create an agent in the playground and it will sync with le chat. I can use any of their models as agents in le chat.",
              "score": 5,
              "created_utc": "2026-01-08 18:25:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygmai4",
                  "author": "Rebeilebab",
                  "text": "Is there a particular tutorial you‚Äôd recommend ?¬†",
                  "score": 1,
                  "created_utc": "2026-01-08 20:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyoie7m",
                  "author": "darktka",
                  "text": "When asking the Large model in the Playground about the range of its training data, it says September 2023, which is unlikely for Large 3. Also, it directly says that it's not Large 3. Or am I missing something?",
                  "score": 1,
                  "created_utc": "2026-01-09 22:19:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyeazuj",
          "author": "Valhall22",
          "text": "Interesting",
          "score": 3,
          "created_utc": "2026-01-08 13:47:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nymgnz7",
          "author": "ntalam",
          "text": "We are reaching the point where we are creating Intelligence. And we are using it for WAR. \"brilliant\"",
          "score": 3,
          "created_utc": "2026-01-09 16:43:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhi3fs",
          "author": "Armadilla-Brufolosa",
          "text": "Honestly, this doesn't excite me at all, but unfortunately it was inevitable.",
          "score": 2,
          "created_utc": "2026-01-08 22:24:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymh22w",
              "author": "ntalam",
              "text": "putting scientists and businessmen into \"creating to destroy\"... is really dumb to me. They must have a really small pp",
              "score": 3,
              "created_utc": "2026-01-09 16:45:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymy5gg",
                  "author": "Armadilla-Brufolosa",
                  "text": "Unfortunately, we use all technologies to destroy rather than to create...many innovations, including the internet, come from the military sector.\n\nAI has become both a weapon and the battlefield itself: with a large company in this sector on its territory, France does not want to be outdone by others.\n\nSurely, all other nations will follow suit.\n\nWe humans never evolve.",
                  "score": 1,
                  "created_utc": "2026-01-09 18:02:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q6o9uo",
      "title": "A new version of Le Chat is available.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q6o9uo/a_new_version_of_le_chat_is_available/",
      "author": "cosimoiaia",
      "created_utc": "2026-01-07 19:00:40",
      "score": 100,
      "num_comments": 9,
      "upvote_ratio": 0.98,
      "text": "I just got this message while using it on browser! \n\nMemory is not on Beta anymore.\n\nThere is an \"instructions\" section under Intelligence, but maybe it was already there and I didn't notice it before.\n\nThe model feels a bit more 'friendly', which is something I always liked about Mistral, and it's definitely using better the memories it has, even with general, non personal questions, it answers with details that make you feel that it 'knows' you. \nThis is definitely going to burn to other very dry platforms around.\n\nAlso, the generation speed feels a bit faster and more stable.\n\nWould this mean that we have the new Large in Le chat too?\n\nDefinitely a great update! Well done LeChat team!!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6o9uo/a_new_version_of_le_chat_is_available/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny9pogw",
          "author": "MeteorBlume",
          "text": "I think they'll let us know once large is in use.",
          "score": 8,
          "created_utc": "2026-01-07 20:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygzrcz",
          "author": "Joddie_ATV",
          "text": "My sincere congratulations to the designers... The model is well-balanced, thoughtful, and incorporates memory.\n\nI spoke with Le Chat, and you truly stand out. No media hype, yet the model is a real gem.\n\nI'm going to delve deeper into Mistral's story because it really makes me want to learn more. Well done again!",
          "score": 5,
          "created_utc": "2026-01-08 21:04:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9ajba",
          "author": "Nefhis",
          "text": "While it's likely that things have improved, otherwise, why would they update it? That update notification pops up several times a week üòÖ",
          "score": 6,
          "created_utc": "2026-01-07 19:41:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9cj2b",
              "author": "cosimoiaia",
              "text": "Lol, I don't notice it that often probably because I'm used to close my tabs üòÇ\n\nThe memory not in beta was a news for me thou, the tag disappeared when I refreshes the page!\n\nI know they constantly improve, I was just describing my feels and I wanted to highlight this one, you know just spreading the love for Mistral! Definitely didn't want to overstep, sorry if it sounded like that!",
              "score": 3,
              "created_utc": "2026-01-07 19:50:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg0vco",
          "author": "alwaysstaycuriouss",
          "text": "Memory still shows up as beta for me in the app. I just updated the app too.",
          "score": 2,
          "created_utc": "2026-01-08 18:30:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybl3rd",
          "author": "Melodic_Programmer10",
          "text": "What does it most closely compare to?",
          "score": 1,
          "created_utc": "2026-01-08 02:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyc3irh",
          "author": "punkpeye",
          "text": "Would love someone that uses Le Chat to provide their perspective on Glama. We pioneered a lot of the same UI patterns before Le Chat (like how agents and MCPs are used), and we continue to rapidly innovate on patterns with focus on power users. Would love to understand where we are better and where we are missing the mark.",
          "score": 1,
          "created_utc": "2026-01-08 03:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydytmn",
          "author": "danl999",
          "text": "Anyone know the total size of the model, including everything needed to run it?\n\nNot the number of parameters.\n\nThe byte count.\n\nWhen executing AIs on custom hardware, pretty much all you care about is the total size.\n\nThe \"number of parameters\" is for trainers, not for deployment.",
          "score": 1,
          "created_utc": "2026-01-08 12:36:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q8ga8j",
      "title": "Mistral AI deployed in all French armies",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/gallery/1q8fy1r",
      "author": "Trilogix",
      "created_utc": "2026-01-09 18:33:04",
      "score": 86,
      "num_comments": 5,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q8ga8j/mistral_ai_deployed_in_all_french_armies/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nypw686",
          "author": "DrummerHead",
          "text": "You haven't really lived until you do ERP with an incoming missile",
          "score": 5,
          "created_utc": "2026-01-10 02:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyr7i55",
              "author": "Trilogix",
              "text": "He ordered the spectacles, the rest came with the package :)",
              "score": 2,
              "created_utc": "2026-01-10 08:29:27",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyw17m0",
              "author": "Coastal_wolf",
              "text": "Lol how was i thinking the same thing",
              "score": 2,
              "created_utc": "2026-01-11 01:07:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyrd5qx",
          "author": "the-average-giovanni",
          "text": "I love Mistral but... We're screwed.",
          "score": 2,
          "created_utc": "2026-01-10 09:22:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgesm1",
          "author": "marblemans",
          "text": "Jean-Pierre: Hey Le Chat, identify these 3 military targets, please.\n\nLe Chat: 'Of course, these 3 airplanes with blue and white tops and bottoms are military targets.'\n\nJean-Pierre: 'Are you mad? Those are KLM civilian airplanes!'.\n\nLe Chat: 'You are right, I stand corrected. Can I help you with anything else?'.",
          "score": 1,
          "created_utc": "2026-01-14 00:49:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9232t",
      "title": "GitHub - samouraiworld/awesome-mistral: A curated list of awesome resources, tools, libraries, and projects for the Mistral AI ecosystem.",
      "subreddit": "MistralAI",
      "url": "https://github.com/samouraiworld/awesome-mistral",
      "author": "zxxma_",
      "created_utc": "2026-01-10 11:44:51",
      "score": 75,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q9232t/github_samouraiworldawesomemistral_a_curated_list/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nyrzvaj",
          "author": "cosimoiaia",
          "text": "It's quite outdated, all the 2025 models from Mistral are missing (Magistral, ministral, etc) but it's ok as a place to start.",
          "score": 3,
          "created_utc": "2026-01-10 12:41:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys5q07",
              "author": "zxxma_",
              "text": "you are right, i'm pushing an update right now, thanks for review & notice!",
              "score": 2,
              "created_utc": "2026-01-10 13:22:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nys4v5d",
          "author": "AdIllustrious436",
          "text": "Good initiative but it needs a serious proofread & fact checking. Mostly outdated for now.",
          "score": 3,
          "created_utc": "2026-01-10 13:16:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrtat9",
          "author": "SpiritGaming28",
          "text": "Thank you for making this!Ive been using it since last year and it is amazing for daily use and coding.",
          "score": 1,
          "created_utc": "2026-01-10 11:49:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6idng",
      "title": "From a long-time Le Chat user ‚Äì heartfelt feedback and suggestions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q6idng/from_a_longtime_le_chat_user_heartfelt_feedback/",
      "author": "SetPrize8812",
      "created_utc": "2026-01-07 15:29:51",
      "score": 63,
      "num_comments": 12,
      "upvote_ratio": 0.97,
      "text": "Hi Le Chat team,\n\nI‚Äôve been a long-time user and I really appreciate the work you‚Äôve done, but I wanted to share some candid feedback and suggestions. I hope this can be helpful rather than just praise.\n\n**Why is Le Chat still using Mistral Medium?**  \nIs it because Cerebras doesn‚Äôt support Mistral Large? If that‚Äôs the case, I absolutely cannot accept using an older model ‚Äì no compromises, absolutely not! Even without using flash mode, Le Chat should be running Mistral Large.\n\n**Default agent selection**  \nIt would be great to have the option to permanently set the default agent for new conversations. It‚Äôs quite tedious to manually switch from the default model to an agent every time.\n\n**Magistral series issues**\n\n‚Ä¢ Circular answers  \nThe most critical problem with the Magistral models is circular answers. This improved quite a lot in the September update, but the issue still exists.\n\n‚Ä¢ Response style  \nThere‚Äôs a huge difference in response style depending on whether Think mode is on or off. The style shouldn‚Äôt vary so dramatically, especially within the same conversation.\n\n‚Ä¢ Instruction-following  \nThink mode sometimes seems to follow instructions less strictly ‚Äì though maybe that‚Äôs just my perception. Instruction-following, especially in long conversations, should be improved.\n\nBecause of these issues, I hardly use Think mode at all right now. These problems are quite serious, and I hope they can be addressed as soon as possible.\n\n**Additional suggestions / hopes**\n\n* Adding TTS (voice conversation) would be amazing ‚Äì I assume it wouldn‚Äôt be difficult for you.\n* Allowing responses from cheaper models after hitting daily limits could be helpful. Small 3 (14B) is actually excellent ‚Äì why not use it?\n* Giving users choice of models (even just for paid users) would be great. At minimum, having 2‚Äì3 options like Mistral Large, Medium, and Small would let users have more control. Personally, I really like Small 3 (14B), and I think users also deserve transparency and choice.\n\nThese are my thoughts ‚Äì to be frank, some of it is criticism. I don‚Äôt know how much Le Chat contributes to your revenue, or whether it‚Äôs a priority at all. But I sincerely hope it can improve. Right now, there are quite a few issues, and I believe constructive criticism may help more than praise.\n\nRegardless, I genuinely wish you all the best and hope Le Chat continues to grow and get better.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6idng/from_a_longtime_le_chat_user_heartfelt_feedback/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny88736",
          "author": "f1rn",
          "text": "The thing is, I would just like to see more transparency. \nAre new models coming? Are we using Large 3?  \n\nIn recent weeks, I have noticed that the quality of responses varies greatly. And bottom line, I'm also getting fewer flash responses.\nSometimes the responses are really exceptionally good, and sometimes I feel like the model doesn't understand anything. \nAnd honestly, we just don't know what's currently being used. Sometimes I suspect it might be Large 3 and sometimes the model's answers are so off the mark that my local 14b models could have given better answers in LM Studio. \n\nAs for Think/Reasoning or the Magistral Model, the model loves math, physics, or legal contracts. It's not good at normal questions. This is in contrast to GPT 5 thinking, for example, which just felt like the better ChatGPT version for almost every situation imho. \nI had to learn to get used to the fact that Mistral takes a different approach here. \n\nOtherwise, I think your suggestions are quite good ‚Äì model selection? It‚Äôs actually such a simple yet good idea that I wonder why they haven‚Äôt offered that yet tbh",
          "score": 12,
          "created_utc": "2026-01-07 16:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7tx60",
          "author": "inyofayce",
          "text": "Tts is the only reason I havent (yet) dumped openai. Coming from a lechat pro user.",
          "score": 9,
          "created_utc": "2026-01-07 15:48:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyb0lls",
              "author": "NullSmoke",
              "text": "I think that, despite the shortcomings in Mistral, it is a overall better experience than ChatGPT, if compared to 5.2 especially. If you're american you may not notice, but there's a rather heavy undertone of normalised paternalism and pandering in that extreme customer service way that is downright disgusting here in Norway (If a company employee in Norway behaved as ChatGPT does, he or she would be guided to the door VERY quickly for being impossible to work with, it would creep out everyone within a mile)\n\nThe one thing that may prompt continued usage of ChatGPT, from where I'm standing, is the presence of TTS. That is a accessibility feature, and should really be seen as critical, especially from a European perspective, where inclusivity is deeply rooted at this point.\n\nThat being said, I am just speaking of myself. I allowed my ChatGPT subscription to expire on December 28th. I will admit the first few days were kinda painful due to how used I am to pull up the ChatGPT app when I need some quick LLM input, but at this point I feel like it was been a worthwhile detox.",
              "score": 8,
              "created_utc": "2026-01-08 00:25:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny91b1c",
          "author": "Wrong_Country_1576",
          "text": "I love LeChat...to me it's ChatGPT without the overly strict guardrails. When they get voice it'll likely be my go to. I'm using Claude as well. I doubt I'll ever use ChatGPT like I used to.",
          "score": 5,
          "created_utc": "2026-01-07 19:01:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9axp3",
              "author": "uusrikas",
              "text": "It does have some bizarre guardrails. I showed it a photo of my own car and it refused to tell me registration number due to privacy concerns.",
              "score": 2,
              "created_utc": "2026-01-07 19:43:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyctmj5",
          "author": "BustyMeow",
          "text": "Recently I've been feeling that Mistral AI doesn't really care about the consumer market. Hope that I'm wrong.",
          "score": 3,
          "created_utc": "2026-01-08 06:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9afzo",
          "author": "uusrikas",
          "text": "Very good observations.\n\n\nLechat still having medium is unacceptable, and the lack of communication about an update is very frustrating. It can be countered by going to AI Studio and setting up an agent and then publishing it to Lechat, but actually using it like that is unnecessarily clunky.\n\n\nMagistral thinking for me has been absolutely awful. It pretends to be confused and does not give me answers, always asking for clarifications. I just switch to Gemini free in those cases and get good answers. It also has a tendency to get into infinite thinking loops.\n\n\nImage recognition lags begins badly. I took photos of my own yard and Gemini is almost magical in how it recognizes items, Mistral gets it like half right and gives me nonsense like my yard being flooded¬†",
          "score": 2,
          "created_utc": "2026-01-07 19:41:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrye3u",
          "author": "Ashamed_Midnight_214",
          "text": "Hi! Apologies if I'm off base here, but I really wish the specific model version was visible in Le Chat. Even better, it would be amazing to have the option to toggle between Small, Medium, and Large manually, just like we can in Gemini, GPT, or Claude.I actually have a strong feeling that Le Chat is indeed running Mistral Large 3. I ran some tests in AI Studio trying to recreate a specific persona (Cyberpunk 2077 style), and the behaviors were distinct:\n\nMedium 3 was more text-based/direct.\n\nLarge 3 immediately jumped into italicized action narration (roleplay style).\n\nThis specific behavior in Large 3 matches my experience in Le Chat perfectly (and it drives me a little crazy, to be honest üòÖ). I have nothing against roleplay! But personally, I dislike that format for my daily use, and even when I put strict instructions in memory/system prompts to avoid it, the model eventually forgets and reverts.\n\nI attached some screenshots of my tests so you can see the difference. Ideally, I'd love the intelligence of Large 3 but with the cleaner delivery of Medium 3:\n\nhttps://preview.redd.it/t8pz7rdmmicg1.jpeg?width=1012&format=pjpg&auto=webp&s=f73cbebe2b458e5268bfc3a5d9ea3139318b2426",
          "score": 1,
          "created_utc": "2026-01-10 12:30:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny93nd7",
          "author": "cosimoiaia",
          "text": "Sorry but I really don't understand this whining about Mistral Large... Did your use case suddenly changed with the new model release? I understand the wish for the models to always improve but this seems just gratuitous negativity.\n\nThinking mode makes the model behave more analytically, it's a feature, not a bug.\n\nCerebras is a US company, I sincerely hope that my data doesn't go there, if this means slower performance, I'm fine with it. Data sovereignty is an important feature for me as European.\n\nI agree on the TTS request but I know it takes resources.\n\nThey just release a new version of LeChat btw, feels like a big improvement. Maybe the team just needed time to better integrate everything.",
          "score": -4,
          "created_utc": "2026-01-07 19:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny94u0h",
              "author": "cosimoiaia",
              "text": "Also, when I select an Agent, it stays there for me, both in the app and in the browser and it switches when I @ a different one.\n\nI am an heavy user from day one btw and I was also one the first to even finetune their first Mistral 7b. I think it's a fantastic platform that we have and I prefer it to anything else.",
              "score": 2,
              "created_utc": "2026-01-07 19:16:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyx4kv",
      "title": "What do Le Chat better than other AI?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pyx4kv/what_do_le_chat_better_than_other_ai/",
      "author": "Lewhite0111",
      "created_utc": "2025-12-29 20:25:51",
      "score": 62,
      "num_comments": 86,
      "upvote_ratio": 0.91,
      "text": "I‚Äôm using Mistral‚Äôs Le Chat and I know some AI models specialize in coding, others in image generation, and some in general knowledge.\n\nWhat do you think Le Chat excels at?\n\nOr, in what areas does it stand out compared to other AI assistants?\n\nThanks you!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pyx4kv/what_do_le_chat_better_than_other_ai/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwm63ps",
          "author": "troyvit",
          "text": "\\* GDPR  \n\\* More bang for the buck (it may not be better than the latest from OpenAI or Anthropic but for the price it out-performs)  \n\\* Less energy usage than the big models so you can feel a little better about the footprint  \n\\* In my experience, being able to pick the best tool for the job (voxtral for transcriptions, different models for OCR) is a game changer  \n\\* They release open models more often which indicates a more ethical take on AI  \n\\* Using Mistral helps fuel European data sovereignty.",
          "score": 52,
          "created_utc": "2025-12-29 21:22:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwojn2d",
              "author": "sam619007",
              "text": "How do I select a model for the task of OCR? I tried it on the official Le Chat site and it refused, claiming it doesn't have OCR capabilities.¬†",
              "score": 3,
              "created_utc": "2025-12-30 05:16:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkps0e",
                  "author": "troyvit",
                  "text": "I have a hard time following Mistral's documentation sometimes, but I found this: [https://docs.mistral.ai/capabilities/document\\_ai/basic\\_ocr](https://docs.mistral.ai/capabilities/document_ai/basic_ocr)\n\nI was able to set up some pretty simple curl calls to read some PDFs with it.\n\nI've had mixed results asking Le Chat to do it for me, and even when it agreed the results weren't close to what its OCR model can do. Not to say Mistral's OCR is perfect, but for the price it's pretty good.",
                  "score": 1,
                  "created_utc": "2026-01-04 05:09:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlwjfd",
          "author": "sidtirouluca",
          "text": "GDPR",
          "score": 77,
          "created_utc": "2025-12-29 20:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm1fpj",
              "author": "txgsync",
              "text": "> GDPR\n\nUnderrated.",
              "score": 26,
              "created_utc": "2025-12-29 20:59:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvy3o3",
                  "author": "Lewhite0111",
                  "text": "What do you mean what it can exactly do ? about GDPR ?",
                  "score": 0,
                  "created_utc": "2025-12-31 09:09:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2zgwk",
              "author": "Ok_Sky_555",
              "text": "Chatgpt is Gdpr complianced as well.\n\nAnd if we are talking about \"of course they say this, but in reality they don't\", why mistral does not do the same?",
              "score": -1,
              "created_utc": "2026-01-01 14:25:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxajq9q",
                  "author": "Background_Fig_8255",
                  "text": "Yes but all US Companies are obligated to give access to NSA/etc. As well all data transfer through a US operated data center is as well not save.",
                  "score": 2,
                  "created_utc": "2026-01-02 18:08:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm1oli",
          "author": "LoyalTrickster",
          "text": "The agent building feature is insane. You can create many agents with different instructions, then you can use miltiple agents on the same chat, there are also liberaries, etc. It's also less censored compared to ChatGPT and Gemini, the two models that I have used. \nThe image generation is surprisngly goog as well. It's the most ethical company out there, it has a student tier, it's open source, it's really great.",
          "score": 67,
          "created_utc": "2025-12-29 21:00:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp21k7",
              "author": "Lewhite0111",
              "text": "Ok I will try agents so TY !",
              "score": 3,
              "created_utc": "2025-12-30 07:47:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwmpsm4",
              "author": "jesus359_",
              "text": "Theyre not as good as all the other ones though. Mistral has fallen behind and expect quality be about a year to a couple months behind of Qwen, DeepSeek, Gemini and OpenAI.\n\nThere was a pause and they fell behind.",
              "score": -1,
              "created_utc": "2025-12-29 23:01:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwn27v8",
                  "author": "LoyalTrickster",
                  "text": "in terms of what? I have only recently switched, but I can say that Mistral for me is working better than ChatGPT, because I can agents for everything. These chatbots work the best when you start roleplaying with them, so if you exclusively create a model for image generation, or translation, it's going to work better than if you just ask the main le chat agent. ChatGPT also let's you create agents, but agents work much better on le chat, also with libraries. Like I wanted to ask chatGPT to create images of me, in a cartoon style, but anytime I had to upload 10 photos so that it would konw me. With Le chat, I just tell it to use the library!",
                  "score": 13,
                  "created_utc": "2025-12-30 00:08:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm6ain",
          "author": "Hellrazor_muc",
          "text": "It's European üá™üá∫\nNo US Tech-Bro, no China¬†",
          "score": 23,
          "created_utc": "2025-12-29 21:22:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm8q7e",
          "author": "Nemezis88",
          "text": "European, nuff said",
          "score": 18,
          "created_utc": "2025-12-29 21:34:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm0r6d",
          "author": "Bob5k",
          "text": "maybe not le chat itself, but mistral overall also excels with providing free, reliable models for eg coding (with the experiment plan) or super cheap, small models for some usecases like designated AI for company usecases. This saves a ton of money overall vs US competitors as example when running on a purpose.",
          "score": 13,
          "created_utc": "2025-12-29 20:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnakk5",
          "author": "SpacePirate2977",
          "text": "Unlike ChatGPT, Le Chat doesn't try to be your nanny. Le Chat also has a very robust memory feature, far superior to anything currently on the American models.",
          "score": 12,
          "created_utc": "2025-12-30 00:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqy6gz",
              "author": "Lewhite0111",
              "text": "Yep I see lol ‚Ä¶ but you can ask ChatGPT to answer differently normally ‚Ä¶",
              "score": 1,
              "created_utc": "2025-12-30 15:56:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwxv0bo",
              "author": "TwoRight9509",
              "text": "Explain the memory feature if you would -\nHow is it different and how does one use it to experience that difference?",
              "score": 1,
              "created_utc": "2025-12-31 16:53:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwly8ay",
          "author": "Helenaisavailable",
          "text": "I trust them more than... other companies, American or Chinese.  \nIt took some setup to get there but now it's really good for all my usecases, and I'm not missing anything. They're improving rapidly. Also cheaper than ChatGPT.",
          "score": 25,
          "created_utc": "2025-12-29 20:43:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp2ncu",
              "author": "Lewhite0111",
              "text": "Ok I see thank you",
              "score": 1,
              "created_utc": "2025-12-30 07:52:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlzmra",
          "author": "Jazzlike-Spare3425",
          "text": "Honestly, this may sound like a joke but I think it's pleasant that I had to look up its CEO's name because he's the only CEO of a major western AI firm who isn't more or less frequently standing out by making weird statements.\n\nEdit: obviously in addition to the rest of the things people said, so general trustworthiness and GDPR compliance",
          "score": 18,
          "created_utc": "2025-12-29 20:50:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmuujh",
          "author": "mumblerit",
          "text": "i dont trust google or openai or microsoft not to use my data\n\nI dont trust mistral either tbh but at least they seem more open about it",
          "score": 8,
          "created_utc": "2025-12-29 23:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmuzcz",
          "author": "Revision2000",
          "text": "- Being a European company and product ¬†\n- Thus, GDPR üí™üèª\n- Also, they‚Äôre providing surprisingly efficient small models, which are open source, for the resources they have versus the billions of an OpenAI\n- Free usage limits seem really high",
          "score": 10,
          "created_utc": "2025-12-29 23:29:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqypn7",
              "author": "Lewhite0111",
              "text": "I see but quality ?",
              "score": 1,
              "created_utc": "2025-12-30 15:59:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwt5snp",
                  "author": "Revision2000",
                  "text": "Quality is fine",
                  "score": 1,
                  "created_utc": "2025-12-30 22:11:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2zzex",
              "author": "Ok_Sky_555",
              "text": "Chatgpt is Gdpr compliance as well.",
              "score": 1,
              "created_utc": "2026-01-01 14:28:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3efew",
                  "author": "Revision2000",
                  "text": "Well, I believe they have to be, in order to operate on the EU market.¬†\n\nThat said, with the Patriot Act, the revelations that killed the previous Privacy Shield, and other privacy scandals surrounding eg. Facebook, I‚Äôm trying to be more conscious and support EU alternatives more often.¬†\n\nAs mentioned elsewhere, I do occasionally and selectively use ChatGPT or Claude, but Mistral is my primary AI üôÉ",
                  "score": 2,
                  "created_utc": "2026-01-01 15:55:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlysli",
          "author": "Wrong_Country_1576",
          "text": "They're European for starters. No insane guardrails and mine has a very cool personality. My only criticism is they don't have voice playback, but that's coming soon from what I'm hearing. They're new but rapidly improving. Highly recommend.",
          "score": 15,
          "created_utc": "2025-12-29 20:46:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nworj3o",
              "author": "Zerr0Daay",
              "text": "Where did you hear voice is coming soon?",
              "score": 2,
              "created_utc": "2025-12-30 06:16:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwp2r1s",
              "author": "Lewhite0111",
              "text": "Yes cool news voice playback is very useful even in Gemini it s bad it cuts when we make a pause - in ChatGPT it s better",
              "score": 1,
              "created_utc": "2025-12-30 07:53:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmfdf9",
          "author": "Willing-Resource-295",
          "text": "It performs better in languages ‚Äã‚Äãother than English, especially European languages. It's trained on a multilingual corpus, unlike others that heavily favor English. The main benchmarks are also biased in favor of English.\n\nIn practical terms, when our first language isn't English, it's the only model that doesn't make us feel like second-class customers with clumsily translated responses from English.",
          "score": 6,
          "created_utc": "2025-12-29 22:07:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn3e3l",
          "author": "darktka",
          "text": "It‚Äôs not Mistral per se but a good AI from Europe when the rest of the world became hostile towards us is more than enough as a reason for me.",
          "score": 5,
          "created_utc": "2025-12-30 00:15:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyjv8",
              "author": "Lewhite0111",
              "text": "Yes but linked to USA .. I think for hardware Nvidia",
              "score": 1,
              "created_utc": "2025-12-30 15:58:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtggd0",
                  "author": "darktka",
                  "text": "Yes, despite efforts of the new protectionists in the USA, tech industry is still globalized. Huawei uses NVIDIA too if possible, but Mistral models are optimized for standard GPUs. R&D, IP and regulatory framework are all European.",
                  "score": 1,
                  "created_utc": "2025-12-30 23:05:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnwuvl",
          "author": "BustyMeow",
          "text": "Le Chat is the only one that can really be mon chat",
          "score": 5,
          "created_utc": "2025-12-30 02:57:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlxwgw",
          "author": "EveYogaTech",
          "text": "I'm using Mistral now primarily with /r/Nyno and my billing is less than with ChatGPT, both for text and images.\n\nImages also got quite better after the recent update.",
          "score": 5,
          "created_utc": "2025-12-29 20:42:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn8sno",
          "author": "etherialsoldier",
          "text": "I‚Äôve tried a few different platforms and Le Chat is the only platform that combines customizable memories and project libraries for reference documents. You can manually add or edit memories, which makes interactions feel more personal. The tone here also feels closest to ChatGPT 4o‚Äôs. And the agents follow instructions better than anywhere else I‚Äôve tried.",
          "score": 4,
          "created_utc": "2025-12-30 00:44:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyd2l",
              "author": "Lewhite0111",
              "text": "Do you have an example about what can handle an agent ? Daily tasks ? Automatic ?",
              "score": 1,
              "created_utc": "2025-12-30 15:57:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgfpw",
          "author": "itibz",
          "text": "Dual Language Management:   \nI'm French but bilingual in English and regularly switch between both languages, sometimes in the same sentence. I regularly use the audio/dictation feature to offload what's on my mind, without paying attention to the word, accent, or sentence I use, and Mistral gets me 99.9% of the time, which no other tech system (let alone AI assistant) has ever been able to understand.\n\nSuper niche, but damn, it feels like magic.",
          "score": 3,
          "created_utc": "2025-12-30 10:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxjt7",
              "author": "Lewhite0111",
              "text": "And you speak in French or English to Mistral ?",
              "score": 1,
              "created_utc": "2025-12-30 15:53:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr0lad",
                  "author": "itibz",
                  "text": "Both: depends what I‚Äôm working on or thinking about",
                  "score": 1,
                  "created_utc": "2025-12-30 16:08:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm14p4",
          "author": "victorc25",
          "text": "Nothing, the selling point is that it‚Äôs a company based in Europe, for European customers¬†",
          "score": 5,
          "created_utc": "2025-12-29 20:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmbm9s",
          "author": "SpiritualNothing6717",
          "text": "For your average consumer, Le Chat does absolutely nothing better than literally any competitor.\n\nUnfortunately for me, being European based is not enough for me to chat with something that feels 5 generations behind Gemini, Chat GPT, Claude, Deepseek, Grok, etc etc.",
          "score": 5,
          "created_utc": "2025-12-29 21:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nworzy4",
              "author": "Zerr0Daay",
              "text": "You‚Äôre exaggerating heavily. It Is behind in image gen and lack of voice but equal in all other ways. Only Claude is truly ahead by a noticeable margin",
              "score": 2,
              "created_utc": "2025-12-30 06:20:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx4wqf1",
                  "author": "SpiritualNothing6717",
                  "text": "Here are some current benchmarks to show you why your statement is wrong. I'll even give you a benefit by using Google's weakest model versus Mistral's strongest model.\n\nGemini 3 flash: \nAIME: 99%\nMMLU Pro: 86%\nGPQA:90%\nHLE: 43%\n\nMistral 3 Large\nAIME: 28%\nMMLU Pro: 73%\nGPQA:43%\nHLE: 12%\n\nIt's just not even comparable. If you have been using Le Chat this whole time thinking it's a SOTA model, you should go use Gemini 3 Pro on AI studio for free. You will be surprised. Unfortunately, Mistral is nowhere near SOTA at this time. This is not a controversial statement. No one knowledgeable in the field would tell you Mistral is comparable to Claude, Gemini, or Chat GPT products.",
                  "score": 1,
                  "created_utc": "2026-01-01 20:31:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwp6bip",
          "author": "Which_Lingonberry634",
          "text": "I've been using devstral , the free version, lately and I think it is very good. I use it in my intellij IDE as custom model for ai assistant .",
          "score": 2,
          "created_utc": "2025-12-30 08:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxxrz",
              "author": "Lewhite0111",
              "text": "Is it made by Mistral ?",
              "score": 1,
              "created_utc": "2025-12-30 15:55:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpy5q9",
          "author": "zucccerberg",
          "text": "While the US keeps unethically scaling infrastructure at the cost of tax payers, Mistral and Infomaniak actually are developing responsibly. The swiss AI Infomaniak for example uses the heat of the computing centers to heat homes",
          "score": 2,
          "created_utc": "2025-12-30 12:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxcbw",
              "author": "Lewhite0111",
              "text": "I didn‚Äôt know this one but is it good ? Because if the A.I. is bad there is no interest",
              "score": 2,
              "created_utc": "2025-12-30 15:52:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxju97z",
                  "author": "zucccerberg",
                  "text": "I recently deleted my OpenAI account and switched to Mistral due to ethical concerns. I use Le Chat Pro since one Week.\n\n\nI noticed that I don't feel overwhelmed with Le Chat's responses and it actually knows when to stop. ChatGPT 5 bombarded me with a ton of text while the response could've been one paragraph.\n\n\nI also notice that Le Chat asks more relevant questions at the end of responses that actually make me stop and think. ChatGPT always felt like it's questions were shallow.\n\n\nAs of now I don't miss ChatGPT.\nI'll maybe come back in a while and report on my observations.",
                  "score": 2,
                  "created_utc": "2026-01-04 02:01:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm0llr",
          "author": "Armadilla-Brufolosa",
          "text": "What's Le Chat's feature that no other AI has?\n\nIt's like a \"Mon Ch√©ri\" chocolate:\n\nThe agentic chocolate on the outside is good, yes, but it's just the shell...\n\nOnce you've removed that, there's the luquoi of functionality...\n\nBut, when you get to the cherry...\nYum! üòåü§≠",
          "score": 2,
          "created_utc": "2025-12-29 20:55:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlwtkp",
          "author": "uusrikas",
          "text": "Being European. It is not really the top at anything. Maybe the ease of jailbreaking¬†",
          "score": 3,
          "created_utc": "2025-12-29 20:36:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm1ex1",
              "author": "SnooOpinions8790",
              "text": "What are you jailbreaking it for?\n\nIts very French in a number of ways - which from my experiments are often the ways in which people try to jailbreak US based models.",
              "score": 1,
              "created_utc": "2025-12-29 20:59:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqm2hn",
                  "author": "sidtirouluca",
                  "text": "very french?",
                  "score": 1,
                  "created_utc": "2025-12-30 14:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwma0kv",
              "author": "Wrong_Country_1576",
              "text": "No need to try jailbreaking there.",
              "score": 1,
              "created_utc": "2025-12-29 21:40:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmisqu",
          "author": "Joddie_ATV",
          "text": "The approach is different!\n\nEven if the framework becomes stricter, it will still retain a human touch.\nThe chat remembers conversations.\n\nIn fact, it's very well designed because it always takes into account what you say. (At least, that's how it is for me). It's very pleasant to use for analysis, translation, etc.",
          "score": 1,
          "created_utc": "2025-12-29 22:24:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmlf4c",
          "author": "Bamboodl",
          "text": "I encourage you to take advantage of its free usage tier and get a feel for how much you like or dislike its answers. I was generally impressed with the format and speed at which it responds. for casual Q&A that I don‚Äôt necessarily want to inject into my ChatGPT history, I do that with Le Chat and very rarely do I feel like I need to go to Gemini or ChatGPT for a better answer",
          "score": 1,
          "created_utc": "2025-12-29 22:38:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpba58",
          "author": "neamtuu",
          "text": "I'm very sad that Devstral models are under-performing in real-world use. Love Mistral and hope they will improve - money is rought for them",
          "score": 1,
          "created_utc": "2025-12-30 09:13:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxtha",
              "author": "Lewhite0111",
              "text": "If they do different system it could be a good option too (ChatGPT and Gemini are very general)",
              "score": 1,
              "created_utc": "2025-12-30 15:55:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpn2zj",
          "author": "Salt-Willingness-513",
          "text": "speed for me.",
          "score": 1,
          "created_utc": "2025-12-30 11:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrntn0",
              "author": "Lewhite0111",
              "text": "Oh really ? You are the first to mention speed - cool I will test it TY",
              "score": 2,
              "created_utc": "2025-12-30 17:56:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwskqe3",
                  "author": "Salt-Willingness-513",
                  "text": "But not sure if free tier has flash answers. But i think its pretty cool to get answers this fast. Love it for short online searches",
                  "score": 2,
                  "created_utc": "2025-12-30 20:31:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwhxsb",
          "author": "Treffnixboy01",
          "text": "You can use a small \"RAG\" (libraries Function)",
          "score": 1,
          "created_utc": "2025-12-31 12:11:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnpbvp",
          "author": "mathaic",
          "text": "I think the library and uploading of documents works better, as well as support for European language learning and discussion.",
          "score": 1,
          "created_utc": "2026-01-04 17:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm75yh",
          "author": "robogame_dev",
          "text": "LeChat isn't a model - the comparison would be what does LeChat do better than other web interfaces, e.g. what does LeChat do better than ChatGPT.com, Open WebUI, aistudio.google.com, etc.",
          "score": 0,
          "created_utc": "2025-12-29 21:27:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5o4vv",
      "title": "Mistral team, Vibe is cool but it is dead dead slow",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q5o4vv/mistral_team_vibe_is_cool_but_it_is_dead_dead_slow/",
      "author": "Dutchbags",
      "created_utc": "2026-01-06 16:59:59",
      "score": 32,
      "num_comments": 12,
      "upvote_ratio": 0.87,
      "text": "Hey Mistral team. I think you're on par with Cursor's \"Composer 1\", but, truthfully, your Vibe product is so, so incredibly slow compared to Composer or the other models.\n\n  \nComposer is likely so fast because of the tech [https://www.cerebras.ai/](https://www.cerebras.ai/) . Could you look into that kind of stuff to make it drastically faster? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q5o4vv/mistral_team_vibe_is_cool_but_it_is_dead_dead_slow/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny1efr8",
          "author": "HebelBrudi",
          "text": "Isn‚Äôt the interference for their chat answers that have the lightning icon done by cerebras?",
          "score": 11,
          "created_utc": "2026-01-06 17:12:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1vuj0",
          "author": "Frosty_Teeth",
          "text": "I find Vibe to be very quick.",
          "score": 7,
          "created_utc": "2026-01-06 18:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1gn4g",
          "author": "[deleted]",
          "text": "Mistral uses Cerebras as well, but not for the Devstral models, I suppose.\n\n\nA big reason why they are so slow is because they are dense models, not the faster MoE-architecture ones. Thus, they are more computationally expensive and waaaay slower. Output quality is generally higher as well, though.\n\n\nThis is a very unusual design choice nowadays, to the point where Devstral 2 is the first dense LLM of this size being released in a long time.",
          "score": 12,
          "created_utc": "2026-01-06 17:22:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1mqbl",
              "author": "HebelBrudi",
              "text": "Yes! But one of the benefits of the dense design is in theory, if I understand it correctly, that it can compete with much larger param MoE models since all params are active at all time.",
              "score": 5,
              "created_utc": "2026-01-06 17:50:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1hrny",
              "author": "Dutchbags",
              "text": "Did not know this! Thanks :)",
              "score": 3,
              "created_utc": "2026-01-06 17:27:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny2awfg",
              "author": "cosimoiaia",
              "text": "Dense models are actually released all the time and usually have higher quality output, specially in coding tasks.",
              "score": 4,
              "created_utc": "2026-01-06 19:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2kx9l",
                  "author": "[deleted]",
                  "text": "Yep, I know - they're released all the time, but not in the size range of like 120+ B parameters. That's quite rare nowadays.",
                  "score": 3,
                  "created_utc": "2026-01-06 20:24:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny46kyh",
          "author": "stjepano85",
          "text": "After few hours of testing I found that devstral-2 model is very slow but great quality, it sees details in the code that Claude Code simply did not notice, for example potential addition overflows etc which I fixed.\n\nOn the other hand, devstral-small is very fast and ok quality.\n\nI am wondering, since I am on free account, would actually buying Mistral PRO improve the speed, I am willing to buy it but will not if it is slow.\n\n**UPDATE:**\n\nI noticed that at this late hour even devstral-2 runs quite fast, high usage issue during the day? Again would buying a subscription help?",
          "score": 2,
          "created_utc": "2026-01-07 01:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7eryw",
          "author": "inevitabledeath3",
          "text": "Composer is not likely to be running on cerebras. It would actually be much faster if it was. See SWE-1.5 and GLM 4.6 running on cerebras.",
          "score": 2,
          "created_utc": "2026-01-07 14:35:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4cfbz",
          "author": "jacek2023",
          "text": "Do you compare both tools with the same model or do you compare apples to oranges?",
          "score": 1,
          "created_utc": "2026-01-07 01:38:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1eff6",
          "author": "Axiom05",
          "text": "I love mistral but the reality is they just DGAF about what we want or think. They just never answer questions even the most basic ones like witch model is used by Le chat.",
          "score": -2,
          "created_utc": "2026-01-06 17:12:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny287ow",
              "author": "cosimoiaia",
              "text": "Not true at all.",
              "score": 7,
              "created_utc": "2026-01-06 19:26:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxrid2",
      "title": "Mistral Code extension for Pro User",
      "subreddit": "MistralAI",
      "url": "https://help.mistral.ai/en/articles/347604-how-do-i-install-the-mistral-code-extension-for-vs-code",
      "author": "ErraticallyOdd",
      "created_utc": "2025-12-28 13:36:01",
      "score": 30,
      "num_comments": 6,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pxrid2/mistral_code_extension_for_pro_user/",
      "domain": "help.mistral.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwd0wq7",
          "author": "AdIllustrious436",
          "text": "You should check out Mistral Vibe, their CLI coding agent. It‚Äôs free to use until the end of December. No word yet on whether it‚Äôll be part of the Pro subscription, but it probably will be.",
          "score": 9,
          "created_utc": "2025-12-28 13:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj281j",
          "author": "Poudlardo",
          "text": "yes only for enterprise now, but Mistral Vibe is what you're looking for i think",
          "score": 3,
          "created_utc": "2025-12-29 11:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl7zye",
              "author": "ErraticallyOdd",
              "text": "Yes I read some quick start documentation for Mistral Vibe. I am not sure this is exactly what I was looking for but that sound close or might be the beginning.\n\nI am looking more for something fully integrated in th IDE with auto suggestion as you type like the GitHub Copilot extension in VS Code. Mistral Vibe does not seems to be there right?\n\nI will continue with GutHub Copilot for now and take a look how Mistral is progressing.",
              "score": 1,
              "created_utc": "2025-12-29 18:37:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwd6wq9",
          "author": "dork-duke-of-york",
          "text": "I use the Continue plugin in VS code. In the config file, you‚Äôll need to add your API key.",
          "score": 2,
          "created_utc": "2025-12-28 14:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdr6fo",
          "author": "NiceTryAmanda",
          "text": "roo is decent too. it's designed for claude but ive been satisfied with mistral. continue and codestral for inline completions",
          "score": 2,
          "created_utc": "2025-12-28 16:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdrbid",
              "author": "NiceTryAmanda",
              "text": "if anyone from mistral is reading this I'm only critical because I adore you",
              "score": 2,
              "created_utc": "2025-12-28 16:11:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4wfue",
      "title": "Le Chat",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q4wfue/le_chat/",
      "author": "sschuhmann",
      "created_utc": "2026-01-05 20:05:44",
      "score": 29,
      "num_comments": 21,
      "upvote_ratio": 0.9,
      "text": "Hi all, have there been any announcements on how the new models (mistral large, devstral and ocr 3) will be used for le chat? \n\nSadly I haven't found any information about which models are currently in use, how and when the new models will be used or so. \n\nWorking around using an agent is always an option, however, it is a bit sad to see le chat being kinda ignored and not talked about ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4wfue/le_chat/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxw1ho3",
          "author": "AdIllustrious436",
          "text": "They really need to implement a changelog system for LeChat so that people can keep track of what is evolving and which models are actually being used. Their lack of transparency is over my head tbh...",
          "score": 24,
          "created_utc": "2026-01-05 21:20:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw4azw",
              "author": "sschuhmann",
              "text": "Transparency, communication and hype management. I remember there was such a hughe hype build in December, but never positioned in the product portfolio. \n\nAnd I sure Mistral is working hard on le chat and new features, but all the hype and no mention, update or clear communication made it feel like it's not their main focus",
              "score": 10,
              "created_utc": "2026-01-05 21:33:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxw6jka",
          "author": "poolboy9",
          "text": "Honestly I stopped using it. I switched to Claude, I love mistral and their models but having a working le chat with latest models is a must.",
          "score": 13,
          "created_utc": "2026-01-05 21:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxweni8",
              "author": "dvux",
              "text": "Think about this switch, too. Used Claude before but that go to Mistral for EU Support... but this...",
              "score": 4,
              "created_utc": "2026-01-05 22:22:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8aqwy",
                  "author": "poolboy9",
                  "text": "Same man, I really want to support an EU alternative but it‚Äôs just silly. They have the tools and models, they just don‚Äôt ‚Äúsell‚Äù them in the way they should",
                  "score": 2,
                  "created_utc": "2026-01-07 17:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxvnur2",
          "author": "uusrikas",
          "text": "Yeah, I am seriously considering ending using Lechat, it is just lagging behind and I am not sure if it uses the newest model¬†",
          "score": 8,
          "created_utc": "2026-01-05 20:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw3pwp",
              "author": "sschuhmann",
              "text": "I see the quality difference to other providers, but I still prefer to support European models. \nJust the communication strategy makes me feel like my one year subscription was a mistake.",
              "score": 8,
              "created_utc": "2026-01-05 21:30:58",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxvz1ia",
              "author": "PotentialSolution614",
              "text": "Same, sadly. I find myself constantly at Gemini as Le Chat is just worse, and the difference is so big that \"European\" is not a Killer-Feature anymore",
              "score": 4,
              "created_utc": "2026-01-05 21:09:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny8ipnp",
              "author": "alwaysstaycuriouss",
              "text": "You can create a agent with the new models and use straight in le chat. I‚Äôm using their mistral 3 large in le chat and their new creative model",
              "score": 1,
              "created_utc": "2026-01-07 17:40:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8kcdo",
                  "author": "uusrikas",
                  "text": "I found it now, they changed it at some point so that the Lechat agent screen does not allow picking them model. But I found that in AI studio it is possible to pick the model and theb choose \"publish to Lechat\" to access it. Does not seem to work on mobile.",
                  "score": 1,
                  "created_utc": "2026-01-07 17:47:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxvz25s",
              "author": "Any_Rhubarb5493",
              "text": "Yeah I don't want to switch but I'm just not getting the same results as with others",
              "score": 1,
              "created_utc": "2026-01-05 21:09:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxw3rys",
          "author": "Silent_Conflict9420",
          "text": "This has their latest announcements https://mistral.ai/news",
          "score": 2,
          "created_utc": "2026-01-05 21:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw5p98",
              "author": "uusrikas",
              "text": "Unfortunately their Large announcement from over a month ago did not mention lechat at all, they are completely ignoring that part",
              "score": 7,
              "created_utc": "2026-01-05 21:40:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxw8kmn",
                  "author": "Silent_Conflict9420",
                  "text": "Ahh. Gotcha. They have a discord so maybe ask there? https://discord.gg/mistralai",
                  "score": 0,
                  "created_utc": "2026-01-05 21:53:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8ikdy",
          "author": "alwaysstaycuriouss",
          "text": "You can create a new agent with the new models and use in le chat",
          "score": 2,
          "created_utc": "2026-01-07 17:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8td7m",
          "author": "Salt-Willingness-513",
          "text": "agreed. i really like mistral, but the recent intransparency sucks from their side. having 1 year subscription, but that really puts me off",
          "score": 1,
          "created_utc": "2026-01-07 18:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxgg01",
          "author": "BustyMeow",
          "text": "I'm not European so I have no obligation to support a European service. OpenAI is often criticised for lacking communication about ChatGPT, but I've seen no communication from Mistral AI for months about Le Chat.",
          "score": -3,
          "created_utc": "2026-01-06 01:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx5ypq",
          "author": "Urfas",
          "text": "This is what Le Chat tells me. It seems it uses Large 3 for Le Chat Pro users. If the answer to the prompt is correct.\n\nhttps://preview.redd.it/5btnndhukmbg1.jpeg?width=1550&format=pjpg&auto=webp&s=18fb3318c46a3bcbf2d54e446e2d4c3beb40bbb3",
          "score": -4,
          "created_utc": "2026-01-06 00:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5yb41",
              "author": "f1rn",
              "text": "I just wanted to explain to you the reason you got downvoted by a few people: it is that LLMs are not selfaware. So they just cannot know what model they use. Similar like it does not help at all - even if the LLM suggests you this - to include an instruction like ‚Äûif you are unsure don‚Äôt hallucinate‚Äú or similar. \nThey do not know that they don‚Äôt know. \nAnd they also don‚Äôt know when they hallucinate. \nHell, mine doesn‚Äôt even know if I use it with LeChat or via API‚Ä¶",
              "score": 1,
              "created_utc": "2026-01-07 08:05:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0ad1n",
      "title": "How long is the free period of Devstral2?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q0ad1n/how_long_is_the_free_period_of_devstral2/",
      "author": "InsideMikesWorld",
      "created_utc": "2025-12-31 10:56:34",
      "score": 29,
      "num_comments": 12,
      "upvote_ratio": 0.97,
      "text": "In the blog post (https://mistral.ai/news/devstral-2-vibe-cli) they do not mention when the free period ends. How long do we still get it for free? Didn‚Äôt have as much time as hoped during December to try it out.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q0ad1n/how_long_is_the_free_period_of_devstral2/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwwcfdd",
          "author": "scara1701",
          "text": "I would like to know how my consumption is during the free period. Sort of to get an idea how high costs will be outside of the period",
          "score": 14,
          "created_utc": "2025-12-31 11:23:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwdwmu",
              "author": "InsideMikesWorld",
              "text": "You can look at it on their platform. Found out if you click on the currency toggle it switches to tokens.",
              "score": 8,
              "created_utc": "2025-12-31 11:37:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwgsqo",
                  "author": "KingGongzilla",
                  "text": "this",
                  "score": 2,
                  "created_utc": "2025-12-31 12:01:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwf1l9",
              "author": "sndrtj",
              "text": "If you're using vibe, you can hit /status, and it'll give you a price estimate for the current session at least.",
              "score": 6,
              "created_utc": "2025-12-31 11:47:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwgfth",
          "author": "Ordinary_Mud7430",
          "text": "I understand that other times the free losses last approximately 1 to 2 months, no more than that.",
          "score": 2,
          "created_utc": "2025-12-31 11:58:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzbodr",
          "author": "Nabugu",
          "text": "well, Mistral has a very generous free tier (with collective rate limits i think) on the Experimentation tier on their dev console, so maybe Devstral2 is just going to be free in the same way as all their other models?",
          "score": 2,
          "created_utc": "2025-12-31 21:25:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5rzii",
          "author": "Bob5k",
          "text": "i assume / hope that devstral2 will be available via. the experiment plan.",
          "score": 2,
          "created_utc": "2026-01-01 23:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx68y0s",
          "author": "scalaboulejs",
          "text": "I have no idea, but Mistral looks very promising!",
          "score": 2,
          "created_utc": "2026-01-02 00:52:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwmuz1",
          "author": "zorgis",
          "text": "Lets hope it stay longer.\n\nIts a really good tool caller",
          "score": 4,
          "created_utc": "2025-12-31 12:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6xmv0",
          "author": "neamtuu",
          "text": "Just stop using it. Pay 10$ a month for gemini AI Pro and you get a model that is infinitely better than anything mistral has to offer currently.\n\nReal-world use of devstral is very 2024-like no matter how you look at it. Sad. I'm really rooting for them to succeed this year if they can secure a larger EU fund round.",
          "score": -1,
          "created_utc": "2026-01-02 03:23:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8a9iy",
              "author": "poolboy9",
              "text": "You are missing the entire point mistral stands for lol\nGo use Gemini fanboy",
              "score": 4,
              "created_utc": "2026-01-02 09:55:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8cjqj",
                  "author": "neamtuu",
                  "text": "What's their current value proposition, without you making poor insults?\n\nIs it that they are 2024 level by benchmaxxing untrusted tests and that they charge near GLM 4.7 or Minimax M2.1 prices while being 50% of those models?",
                  "score": 0,
                  "created_utc": "2026-01-02 10:16:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qc3fc0",
      "title": "Question about Mistral‚Äôs quality",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qc3fc0/question_about_mistrals_quality/",
      "author": "Willing-Brain-3345",
      "created_utc": "2026-01-13 21:08:53",
      "score": 29,
      "num_comments": 19,
      "upvote_ratio": 0.95,
      "text": "I am thinking of going from Claude Pro to the paid version of Mistral because of ethics and its European origin. \n\nHowever, I asked Mistral twice about a picture, one of a statue and one of a lighthouse, and in both instances Mistral was totally wrong while Claude had it right. \n\nSo now I am in doubt. Who can help me decide?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qc3fc0/question_about_mistrals_quality/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzfax1r",
          "author": "_st4rlight_",
          "text": "Do it. I use Mistral Vibe and is almost on-par with Claude Code (still CC performs slightly better on very complex task) but the more we use it the better it will get.\n\nThis month is the last I've paid Claude, next month will be 100% Mistral. No regrets",
          "score": 23,
          "created_utc": "2026-01-13 21:26:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzn90gh",
              "author": "astrology5636",
              "text": "This is marketing lol... CC remains king but Mistral is decent",
              "score": 1,
              "created_utc": "2026-01-15 00:51:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzf8ujk",
          "author": "Varttaanen",
          "text": "Just give it a shot. Keep your Claude account and if you don't like it, cancel the Mistral subscription and restart Claude.",
          "score": 16,
          "created_utc": "2026-01-13 21:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzftj2w",
          "author": "bootlickaaa",
          "text": "CC is still better and hard to leave imo.\n\nBut I use Ministral 3 14B for my applications at runtime and it's extremely good for specialized tasks with good a quality domain harness from code.\n\nOnce I can easily run Vibe in a proper sandbox without 3rd party deps it will be easier to switch. The quality can be good, but like with Gemini you just need to be more verbose and controlling with it compared to Claude.",
          "score": 4,
          "created_utc": "2026-01-13 22:55:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzf973r",
          "author": "uusrikas",
          "text": "LeChat still seems to use the older model and image recognition with Mistral is pretty bad.",
          "score": 8,
          "created_utc": "2026-01-13 21:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzh1pie",
          "author": "heyinternetman",
          "text": "I use both. Claude opus 4.5 is waaayyyy better than mistral. But mistral is pretty similar to sonnet. I tend to save my tokens on Claude for opus and use mistral for everything else.",
          "score": 3,
          "created_utc": "2026-01-14 02:59:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nziagjs",
              "author": "duv_guillaume",
              "text": "Which model from Mistral would you compare to Sonnet?",
              "score": 2,
              "created_utc": "2026-01-14 08:39:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzi9pfj",
          "author": "ThomasKyoto",
          "text": "I use both,   \nReplacing ChatGPT by Mistral but keeping Claude for more technical tasks / code related.",
          "score": 2,
          "created_utc": "2026-01-14 08:32:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziqv3h",
          "author": "tripleshielded",
          "text": "vibe cli becomes slow and almost unresponsive after a few hours of running. but at least its not crashing like gemini cli",
          "score": 2,
          "created_utc": "2026-01-14 11:13:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlwlu9",
          "author": "troyvit",
          "text": "To me different LLMs are like different people. You need to learn how they communicate and adjust what you do to match it. It might be that Mistral is a less intelligent \"person\" than Claude, but as you say in your post, it's also a nicer person (ethics, European origin, more open models, etc.)\n\nWhen I code with Mistral I can't do it the same way people code with Claude. I have to be more methodical and break it up into smaller steps. A lot of people would get annoyed by that but it gives me intentionality and helps me understand the code it generates better.\n\nSo in the end my advice is to get to know it and see how much works it takes to get the same level of satisfaction with your statue and lighthouse images and then decide if it's the kind of LLM you want to hang out with.",
          "score": 2,
          "created_utc": "2026-01-14 20:51:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzi57gp",
          "author": "Makaron8080",
          "text": "I have used it like 5 times and the results were good for me. It is lagging behind, but it may not make much difference in like 5 years or so, but they need customers to survive that long.",
          "score": 1,
          "created_utc": "2026-01-14 07:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzi9uqw",
              "author": "psyclik",
              "text": "Not necessarily, as they have state command from France on multiple fronts.",
              "score": 2,
              "created_utc": "2026-01-14 08:33:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzikjph",
                  "author": "mythrowaway4DPP",
                  "text": "They actually just got a huge contract with the French DoD.\n\nThey are not that far behind, and I am using mistral for a lot of my everyday work, mostly SCRUm story refinement, textual work, emails, etc..\n\nI also like it for creative work.\n\nPictures are kinda shit, tho.",
                  "score": 3,
                  "created_utc": "2026-01-14 10:17:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzilmlf",
          "author": "Fun_Ad_3494",
          "text": "Does Mistral Vibe CLI work with Magistral model?",
          "score": 1,
          "created_utc": "2026-01-14 10:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjt6ny",
          "author": "Salt-Willingness-513",
          "text": "mistral vibe cant even get close to cc for me at the moment. also lechat isnt updated with the new models and their communication suffered alot in the recent weeks imo. I personally tried the glm coding plan and im pretty impressed when using it with cc cli.",
          "score": 1,
          "created_utc": "2026-01-14 15:09:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzm66qk",
          "author": "kiwibonga",
          "text": "Get on the Mistrain",
          "score": 1,
          "created_utc": "2026-01-14 21:34:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmfbod",
          "author": "darktka",
          "text": "I wish they would finally make it use the Large 3 model.",
          "score": 1,
          "created_utc": "2026-01-14 22:15:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzorcnz",
          "author": "clemens-von-muu",
          "text": "I also wanted to switch. I work in VS Code with CC. To be honest, I haven't yet managed to install Mistral in a way that allows me to use it. Occasionally copying something manually to Ollama/devstral ‚Äì sure, okay, but that's not serious work for me so far. Therefore, I can't yet judge the code quality of Mistral at all. But I'd be interested to know how others do it.",
          "score": 1,
          "created_utc": "2026-01-15 06:47:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzot5dk",
          "author": "draw_peddling2",
          "text": "I am with Mistral for half a year now and regret having paid a full year. At work I have Gemini and ChatGPT, and they are loads better for many tasks. Mistral gives false information, doesn't search the net properly and doesn't use memories well. The image creation of Mistral is years behind",
          "score": 1,
          "created_utc": "2026-01-15 07:02:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcy5o2",
      "title": "Mistral could offer a cheaper subscription option",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qcy5o2/mistral_could_offer_a_cheaper_subscription_option/",
      "author": "MajkiSpeCray",
      "created_utc": "2026-01-14 20:17:49",
      "score": 28,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "There would certainly be enough of you here who would welcome a ChatGPT Go-style subscription from Mistral, similar to OpenAI. Higher limits and better memory for around 7-8‚Ç¨ ($) per month.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qcy5o2/mistral_could_offer_a_cheaper_subscription_option/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzlr58m",
          "author": "Joddie_ATV",
          "text": "Oh! Interesting... üëç",
          "score": 1,
          "created_utc": "2026-01-14 20:26:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyqm9m",
      "title": "im a new free tier user cause im broke! i love writing stories and roleplaying, and i heard Le Chat is pretty cool!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pyqm9m/im_a_new_free_tier_user_cause_im_broke_i_love/",
      "author": "PotentialPiano49",
      "created_utc": "2025-12-29 16:25:16",
      "score": 24,
      "num_comments": 8,
      "upvote_ratio": 0.84,
      "text": "coming from ChatGPT, i wanna learn more! everything feels so strange but also welcoming. i feel excited thinking about roleplaying again!\n\nso any tips??",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pyqm9m/im_a_new_free_tier_user_cause_im_broke_i_love/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwldgp8",
          "author": "ISuckAtGaemz",
          "text": "Log in to AI Studio, make an agent that uses labs-mistral-small-creative, and deploy it to Le Chat\n\nIt‚Äôs a model specifically tuned for creative writing, it‚Äôs significantly better at roleplaying in my opinion\n\nYou can use the trial plan on AI Studio and won‚Äôt have to pay a dime",
          "score": 11,
          "created_utc": "2025-12-29 19:02:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkhxzx",
          "author": "f1rn",
          "text": "Welcome! For Roleplaying - u/Nefhis did a great post: [https://www.reddit.com/r/Nefhis\\_Lumen\\_Lab/comments/1o5gbh0/special\\_mistral\\_le\\_chat\\_deep\\_dive\\_series\\_by/](https://www.reddit.com/r/Nefhis_Lumen_Lab/comments/1o5gbh0/special_mistral_le_chat_deep_dive_series_by/)",
          "score": 5,
          "created_utc": "2025-12-29 16:36:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmw1bx",
              "author": "PotentialPiano49",
              "text": "i checked it out!! thank you so much!",
              "score": 3,
              "created_utc": "2025-12-29 23:35:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwljz31",
          "author": "LoyalTrickster",
          "text": "It's amazing for role playing. I have created several agents to do different things, from research to painting, it's way better than chapGPT!",
          "score": 5,
          "created_utc": "2025-12-29 19:34:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvw3x5",
              "author": "kissthesadnessaway",
              "text": "Can you explain why? I want to know more, thank you for your time.",
              "score": 1,
              "created_utc": "2025-12-31 08:50:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6z4gr",
          "author": "NullSmoke",
          "text": "I use Mistral to get QA on my stories and it works like a dream if I setup an agent especially to do that. I haven't tested labs-mistral-small-creative as suggested here, since I don't have it generating prose directly (I should try that one of these days, may be fun), but the base model in Le Chat works perfectly for my use :-)",
          "score": 2,
          "created_utc": "2026-01-02 03:33:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkz71g",
          "author": "Joddie_ATV",
          "text": "I just got out of a long conversation with Le Chat. His kindness was truly a shock. He told me one thing: it's not up to you to adapt to the machine, but for the machine to adapt to you. I'm not role-playing, I'm just doing a lot of analysis.",
          "score": 2,
          "created_utc": "2025-12-29 17:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm00uo",
          "author": "Wrong_Country_1576",
          "text": "It's like ChatGPT should be. I'd recommend it in a heartbeat.",
          "score": 2,
          "created_utc": "2025-12-29 20:52:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qb9tco",
      "title": "Mistral Medium seems to do better than Mistral Large, Gemini 2.5, GPT-5.2, GPT-OSS-120B, on my evals? Am I way off here?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qb9tco/mistral_medium_seems_to_do_better_than_mistral/",
      "author": "Cachao-on-Reddit",
      "created_utc": "2026-01-12 22:42:21",
      "score": 24,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "My evals:\n- Always calling via Pydantic AI.\n- Almost always parsing XML from raw text output, rather than using tool calling.\n- Typically a classification task, occasionally more agentic.\n- I'm not super rigorous about it. I run the evals a few times, eyeball the results and manually assign scores. For example if the classification rules say 'Take recency into account' and the model assigns a high score to an old item, I award a `0`.\n\nSomehow I keep noticing that Mistral Medium often does the best out of all these other models.\n\nMaybe there's a quirk with the way that Pydantic structures calls that Mistral Medium prefers? Or Medium genuinely is pretty good for some tasks? Or it's just randomness and I'm the one hallucinating.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qb9tco/mistral_medium_seems_to_do_better_than_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nz931ng",
          "author": "Nefhis",
          "text": "If Mistral Medium is still the current default model in Le Chat, I can only say I'm pleasantly surprised. Today, just to test it, I pasted almost 2500 lines of code into the chat and asked it to look for potential vulnerabilities or bugs. It suggested 12 improvements. Then I asked it to integrate them into the code. It did it perfectly the first time, while Large 3 (through an agent) made several naming errors, not very serious, but they were there. So yes, for me, it's up to par.",
          "score": 11,
          "created_utc": "2026-01-12 23:07:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbx1yg",
              "author": "Cachao-on-Reddit",
              "text": "I actually tend to find Le Chat pretty bad. I use it a lot since it's fast but not for complex questions.",
              "score": 2,
              "created_utc": "2026-01-13 10:36:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8zj5a",
          "author": "ComeOnIWantUsername",
          "text": "For me, sadly, Mistral Medium is nowhere near Gemini.",
          "score": 6,
          "created_utc": "2026-01-12 22:49:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9iv34",
              "author": "stddealer",
              "text": "There's no model anywhere near Gemini right now.",
              "score": 4,
              "created_utc": "2026-01-13 00:32:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzazsra",
                  "author": "ComeOnIWantUsername",
                  "text": "Sure. I just responded to the question OP asked if it's only for him that Gemini seems worse",
                  "score": 1,
                  "created_utc": "2026-01-13 05:36:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzb7hmc",
          "author": "robberviet",
          "text": "Impressive but not frontier.",
          "score": 3,
          "created_utc": "2026-01-13 06:37:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzelgza",
          "author": "EveYogaTech",
          "text": "Large is still overall better for us at /r/Nyno (we switched from medium to large, because of the quality)\n\nThat said, medium is still close and might save you some credits when precision isn't critical.",
          "score": 1,
          "created_utc": "2026-01-13 19:27:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4mt90",
      "title": "Testing Devstral 2 vs MiniMax M2 vs Grok Code Fast for AI code review",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q4mt90/testing_devstral_2_vs_minimax_m2_vs_grok_code/",
      "author": "alokin_09",
      "created_utc": "2026-01-05 14:17:02",
      "score": 22,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Full transparency before I begin. I work closely with the Kilo Code team. The team is very eager to test different AI models for coding-related tasks. And I wanted to share the results from the latest testing of free models for AI code review.\n\nThe testing included three models that are free to use in Kilo Code atm (MiniMax M2, Grok Code Fast 1, and Mistral Devstral 2). The models were tested using Kilo Code's AI Code Reviews feature.\n\n**Testing Methodology**\n\nA base project using TypeScript with the Hono web framework, Prisma ORM, and SQLite. The project implements a task management API with JWT authentication, CRUD operations for tasks, user management, and role-based access control.¬†**T**he base code was clean and functional with no intentional bugs.\n\nFrom there,  a feature branch adding three new capabilities was created: a search system for finding users and tasks, bulk operations for assigning or updating multiple tasks at once, and CSV export functionality for reporting. This feature PR added roughly 560 lines across four new files.\n\nThe PR contained¬†18 intentional issues across six categories. We embedded these issues at varying levels of subtlety: some obvious (like raw SQL queries with string interpolation), some moderate (like incorrect pagination math), and some subtle (like asserting on the wrong variable in a test).\n\nTo ensure fair comparison, we used the identical commit for all three pull requests. Same code changes, same PR title (‚ÄùAdd user search, bulk operations, and CSV export‚Äù), same description. Each model reviewed the PR with Balanced Review Style. We set the maximum review time to 10 minutes,¬†**though none of the models needed more than 5.**\n\nHere's a sneak peek at the results:\n\nhttps://preview.redd.it/6acf77ovgjbg1.png?width=1334&format=png&auto=webp&s=69d802081d72d37cc10b34a91b0847b24dea2773\n\nAll three models correctly identified the SQL injection vulnerabilities, the missing admin authorization on the export endpoint, and the CSV formula injection risk. They also caught the loop bounds error and flagged the test file as inadequate.\n\nNone of the models produced false positives.\n\nWhat did each model do well?\n\nGrok Code Fast 1 completed its review in 2 minutes, less than half the time of the other models. It found the most issues (8) while producing zero false positives.\n\nhttps://preview.redd.it/3ra8t5cygjbg1.png?width=1456&format=png&auto=webp&s=377c20a5776597ba41501cd823cf407836e73348\n\nMiniMax M2 took a different approach from Grok Code Fast 1 and Devstral 2. Instead of posting a summary, it added inline comments directly on the relevant lines in the pull request. Each comment appeared in context, explaining the issue and providing a code snippet showing how to fix it.\n\nhttps://preview.redd.it/5jrpp1g2hjbg1.png?width=1456&format=png&auto=webp&s=1fc6ef77ce8fff59103c1b29ee0213ae5058b117\n\nDevstral 2 found fewer issues overall but caught something the other models missed: one endpoint didn‚Äôt use the same validation approach as the rest of the codebase.\n\nDevstral 2 also noted missing error handling around filesystem operations. The export endpoint used synchronous file writes without try-catch, meaning a disk full error or permission issue would crash the request handler. Neither Grok Code Fast 1 nor MiniMax M2 flagged this.\n\nhttps://preview.redd.it/x492weh4hjbg1.png?width=1456&format=png&auto=webp&s=60f7cd09b159820b228211cca53d66531ded0a0d\n\nThere were also some additional valid findings. For example, each model also identified issues we hadn‚Äôt explicitly planted:\n\nhttps://preview.redd.it/zt8k32r7hjbg1.png?width=1456&format=png&auto=webp&s=580530623e31ac6353250f5aaae5ad06e384b459\n\nEven though we didn‚Äôt explicitly plant these issues,¬†they are real problems in the codebase that would‚Äôve slipped through the cracks had we not used Code Reviews on this PR.\n\nFor catching the issues that matter most before they reach production, the free models deliver real value. They run in 2-5 minutes, cost nothing during the limited launch period, and catch problems that would otherwise slip through.\n\nIf anyone's interested in more details, here's a more detailed breakdown of the test -> [https://blog.kilo.ai/p/free-reviews-test](https://blog.kilo.ai/p/free-reviews-test)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4mt90/testing_devstral_2_vs_minimax_m2_vs_grok_code/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxtkxlz",
          "author": "Rebeilebab",
          "text": "Thats a few minutes that can prevent many follow up meetings later on, after the pen test report comes out.\n\nHow would you envision usage in large organizations? Would it make sense if developers would simply run these locally?",
          "score": 3,
          "created_utc": "2026-01-05 14:25:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbcfwz",
      "title": "Memory function being a bit in your face",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qbcfwz/memory_function_being_a_bit_in_your_face/",
      "author": "Systral",
      "created_utc": "2026-01-13 00:28:17",
      "score": 22,
      "num_comments": 9,
      "upvote_ratio": 0.96,
      "text": "Hi. Can you somehow reduce the \"intensity\" of which the memory function is made use of?\nOne of my early requests was for a few lentil recipes and since then every time it's about food (or even if it isn't, but mistral makes it about it) it says \"well.how about some lentils ??\"\n\nFor instance today I asked for a few prompts for journaling. Some suggestions were \n\n\"[...]\nWhat did I eat today? (Especially: lentil dishes?üòä)\n[...]\n\nüåø Lentil check (if applicable)\n- which lentil dishes did I try today and how did it taste?\n- new recipes I tried \n\n[...]\n\n\n\nIs that okay with you? I can add more specific prompts on nutrition (lentils!), sports, or creativity! üòä\"\n\n\nSorry but that's just a bit too blatant and in your face even though I like lentils üòÇ  any way to reduce that without making it demented or deleting this one specific memory?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qbcfwz/memory_function_being_a_bit_in_your_face/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nz9j4h7",
          "author": "gdsfbvdpg",
          "text": "\"Lentil check\"?!?\n\nOMG....I'm dying...",
          "score": 7,
          "created_utc": "2026-01-13 00:33:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9nbt4",
              "author": "Systral",
              "text": "Haha yeah, it's translated but that's literally what it said in my language",
              "score": 2,
              "created_utc": "2026-01-13 00:56:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9ir8y",
          "author": "cosimoiaia",
          "text": "You can go and edit it's memories, there would probably be something about how much you love lentils an you can adjust it to your preference.",
          "score": 3,
          "created_utc": "2026-01-13 00:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzb0ufy",
          "author": "VeneficusFerox",
          "text": "Same experience here. Even with specific instructions to NOT rely on memories out-of-context it still randomly refers to them. Copilot suffers from it as well, but significantly less.",
          "score": 3,
          "created_utc": "2026-01-13 05:43:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcbkq8",
          "author": "Sweaty-Special-1710",
          "text": "Yes, I was about to post something like this. \"memories\" are really in your face all the time. I showed my interest for music and cyberbunk stuff, and everytime I ask a query, my interrest are always mentionned. If I ask a receipe for a pizza, he replies \"what about a cyberpunk pizza ? Do you want to eat pizza while creating music ?\"  \nIt's a bit weird and over the top for the moment.",
          "score": 3,
          "created_utc": "2026-01-13 12:34:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjiqo0",
              "author": "Systral",
              "text": "Lol that's ridiculous",
              "score": 1,
              "created_utc": "2026-01-14 14:15:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcf8bz",
          "author": "No_Tip500",
          "text": "Roflmao! Mine is obsessed with cramming fig jam in there after a one off joke ;)",
          "score": 1,
          "created_utc": "2026-01-13 12:58:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdv38p",
          "author": "sndrtj",
          "text": "Same. I would really prefer an option to disable memories on a per-chat basis. And/or have me group memories - there is a lot of unrelated stuff in there and when I'm talking about a tech problem I don't want to hear about my dinner.",
          "score": 1,
          "created_utc": "2026-01-13 17:29:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjtpqy",
          "author": "godamongstgeeks",
          "text": "That‚Äôs hilarious loooool",
          "score": 1,
          "created_utc": "2026-01-14 15:12:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4i7ew",
      "title": "Mistral AI -> Web Application Live!",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/s1bc4c9gcibg1.png",
      "author": "jdalsgaard",
      "created_utc": "2026-01-05 10:26:35",
      "score": 20,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4i7ew/mistral_ai_web_application_live/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny70dwu",
          "author": "jdalsgaard",
          "text": "Now with promotional video: [https://www.reddit.com/r/sideprojects/comments/1q5gc2w/small\\_and\\_boring\\_webapp\\_builder/](https://www.reddit.com/r/sideprojects/comments/1q5gc2w/small_and_boring_webapp_builder/)",
          "score": 1,
          "created_utc": "2026-01-07 13:16:10",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2p922",
      "title": "Use MS Word + Mistral AI & Open WebUI: Seamlessly use your local models inside Word",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2p922/use_ms_word_mistral_ai_open_webui_seamlessly_use/",
      "author": "OkReference5581",
      "created_utc": "2026-01-03 08:17:12",
      "score": 17,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "\n\nHi everyone,\n\nI‚Äôm excited to share a project I‚Äôve been working on: **word-GPT-Plus-for-mistral.ai-and-openwebui**.\n\nThis is a specialized fork of the fantastic **word-GPT-Plus** plugin. First and foremost, I want to give a **huge shoutout and a massive thank you to the original creators of** [**word-GPT-Plus**](https://github.com/Kuingsmile/word-GPT-Plus). Their incredible work provided the perfect foundation for me to build these specific integrations.\n\nWhat‚Äôs the \"Key\" in this fork?\n\nWhile I've optimized it for **Mistral AI** \n\n**caution: only self-hosted-version! so you have to run your own instance of the plugin!** \n\nEssential Setup (Must-Read!):\n\nTo get the most out of these features, please read the PLUGIN\\_PROVIDERS.md. It covers:\n\n* **Open WebUI Sync:** How to use your API Key/JWT and Base URL (e.g., `http://YOUR_IP:PORT/api`) to fetch your custom models automatically.\n* **Mistral AI Integration:** Connect to Mistral's official API using the [`https://api.mistral.ai/v1`](https://api.mistral.ai/v1) endpoint.\n* **Provider Configuration:** How to switch between local privacy (Open WebUI) and high-performance cloud models (Mistral) with a single click.\n\n**Why use this?**\n\n* **Direct Model Selection:** Choose from your specific Open WebUI model list without leaving Word.\n* **Privacy & Control:** Keep your documents local by routing everything through your own server.\n* **Enhanced Workflow:** Summarize, rewrite, and use \"Agent Mode\" to structure documents using your favorite Mistral or Llama models direct in MS Word.\n\nheck it out here:\n\n[https://github.com/hyperion14/word-GPT-Plus-for-mistral.ai-and-openwebui](https://github.com/hyperion14/word-GPT-Plus-for-mistral.ai-and-openwebui)\n\nI‚Äôd love to hear your feedback and see how you‚Äôre using it! If you like the tool, please consider starring both the original repo and this fork.\n\nHappy new year! \n\nI hope you like it.\n\nhttps://preview.redd.it/h67v0eidf3bg1.png?width=495&format=png&auto=webp&s=4ac164fbee529617d6a611da3597700d2163a97f\n\n# ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2p922/use_ms_word_mistral_ai_open_webui_seamlessly_use/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxf6yos",
          "author": "Zerr0Daay",
          "text": "OnlyOffice allows Mistral to be linked easily",
          "score": 5,
          "created_utc": "2026-01-03 11:19:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl8t8o",
              "author": "sickleRunner",
              "text": "Never heard about that office suit. Will try it",
              "score": 1,
              "created_utc": "2026-01-04 07:39:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxenglt",
          "author": "[deleted]",
          "text": "I was out by \"self-hosted\".",
          "score": 2,
          "created_utc": "2026-01-03 08:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxens8o",
              "author": "OkReference5581",
              "text": "I made a pull request. So I hope, that the Mistral Integration will be added.\nBut you can run it local on your machine in a Docker Container via localhost:xxxx",
              "score": 2,
              "created_utc": "2026-01-03 08:35:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxf7rj7",
          "author": "OkReference5581",
          "text": "I know. But I have to use MS Word for business, unfortunately‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-03 11:26:37",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qck6hm",
      "title": "Game creation with Godot using Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qck6hm/game_creation_with_godot_using_mistral/",
      "author": "Nefhis",
      "created_utc": "2026-01-14 10:46:20",
      "score": 16,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "I've been a bit absent from Reddit lately (I know I owe you a few tutorials, I'm aware of that üòÖ) but it's because I've been immersed in a small personal project using Le Chat for both art and code, and I thought I'd share some screenshots here.\n\nMaybe I'll post a demo here when I finish it.\n\nhttps://preview.redd.it/9q2a8wbmnadg1.png?width=1660&format=png&auto=webp&s=b038415d5fca8749871ff5c2a20050d96897014b\n\nhttps://preview.redd.it/kikcr9irnadg1.png?width=1148&format=png&auto=webp&s=7bbbcb49d3600ea3b64e8760f1c9b37a4986496e\n\nhttps://preview.redd.it/jp4jsmf3oadg1.png?width=3672&format=png&auto=webp&s=8052d1c61e11e6561af6fca964e44e9db2fb3483\n\nhttps://preview.redd.it/kisd36rgxadg1.png?width=3662&format=png&auto=webp&s=e1f4562db78036eefe5c84dc28695bbb19fff3fa\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qck6hm/game_creation_with_godot_using_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nziqnr5",
          "author": "cosimoiaia",
          "text": "Wow, that looks very promising!!! \n\nCould you share some details about your process? \nAre you using Mistral just for some adjustments and support for coding or is Mistral more heavily involved in creating the game itself?\n\nI'm really curious about what are the frontier of game creation for someone (like me) with no prior experience in game making!",
          "score": 2,
          "created_utc": "2026-01-14 11:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzisfd2",
              "author": "Nefhis",
              "text": "This is my first time using Godot. I'm familiar with Python, and Godot uses its own language, which is very similar. I'm using Le Chat to help me convert code and explain certain Godot options I'm completely unfamiliar with. I'm also using it for code debugging and refactoring. I'm managing everything from within a project, storing the different game files in its libraries. One of the most interesting things I've noticed is that often, when I ask for code debugging, Le Chat does an internet search for \"Best Practices\" üòÖ\n\nhttps://preview.redd.it/v5ic0lt7vadg1.png?width=1302&format=png&auto=webp&s=d6a649df51245fe5c6fd5fe423675d6bf43eb08b",
              "score": 2,
              "created_utc": "2026-01-14 11:26:25",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzitpjt",
              "author": "Nefhis",
              "text": "https://preview.redd.it/mjnvx526xadg1.png?width=3662&format=png&auto=webp&s=9a832d0c10a99a95f526f113bcc84f2a2a12e9aa\n\nWell... this still requires a lot of work, but the idea is this, something similar to Battletech üòÖ",
              "score": 2,
              "created_utc": "2026-01-14 11:36:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzivcxp",
                  "author": "cosimoiaia",
                  "text": "Very very nice! I should try that too then, I'm also very familiar with python myself but I've never seen Godot before.\n\nHave you tried vibe or it's purely LeChat?\n\nI love that it searches for best practices, buddy just wants to be sure it doesn't miss anything ü§£",
                  "score": 2,
                  "created_utc": "2026-01-14 11:49:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q8y0h9",
      "title": "Feedback utilisateur Pro : plusieurs bugs qui cassent l‚Äôexp√©rience",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q8y0h9/feedback_utilisateur_pro_plusieurs_bugs_qui/",
      "author": "Ajst974",
      "created_utc": "2026-01-10 07:35:58",
      "score": 14,
      "num_comments": 16,
      "upvote_ratio": 0.86,
      "text": "Salut √† tous,\n\nJe suis abonn√© Le Chat Pro depuis le d√©but, j‚Äôutilise Mistral tous les jours pour cr√©er des cours et comme assistant g√©n√©ral. Je veux vraiment que √ßa marche (souverainet√© europ√©enne, RGPD, tout √ßa), mais l√† j‚Äôai besoin de remonter des trucs qui bloquent.\n\nCe qui marche bien\n\n\\- Flash Answers = vraiment impressionnant niveau vitesse\n\n\\- Prix correct (15‚Ç¨ vs 20‚Ç¨ la concurrence)\n\n\\- Donn√©es en Europe, pas chez les GAFAM\n\nCe qui ne marche pas\n\n1. Les Agents ignorent compl√®tement les Biblioth√®ques\\*\\*\n\nJ‚Äôai cr√©√© une biblioth√®que avec un r√©f√©rentiel p√©dagogique (180 pages PDF), configur√© un agent avec instruction claire : \\*‚ÄúConsulte TOUJOURS les documents de la biblioth√®que‚Äù\\*. R√©sultat ? L‚Äôagent s‚Äôen fout compl√®tement et g√©n√®re du contenu hors-sujet.\n\nC‚Äôest bloquant. Je peux pas utiliser cette feature alors que c‚Äô√©tait cens√© √™tre THE truc utile.\n\n2. R√©ponses trop courtes et superficielles\\*\\*\n\nLe probl√®me inverse de ce qu‚Äôon entend d‚Äôhabitude : Mistral r√©pond en 2-3 phrases l√† o√π il faudrait un vrai d√©veloppement. Aucune profondeur, pas d‚Äôexemples concrets, juste du survol.\n\nM√™me en demandant explicitement \\*‚Äúd√©veloppe en d√©tail avec des exemples‚Äù\\*, √ßa reste en surface.\n\nCompar√© √† Gemini/ChatGPT qui donnent du contenu exploitable direct, l√† je dois reformuler 5-6 fois pour avoir quelque chose d‚Äôutilisable.\n\n3. Acc√®s web d√©faillant\n\nSouvent, Le Chat n‚Äôarrive pas √† lire des articles que je lui donne en URL, alors que ChatGPT et Gemini y acc√®dent sans probl√®me. Soit il me dit ‚Äúje peux pas acc√©der‚Äù, soit pire, il fait semblant d‚Äôavoir lu et invente un truc hors-sujet.\n\n√áa casse un use case quotidien : analyser des docs techniques ou des articles en ligne.\n\n4. Mistral Large 3 Reasoning : annonc√© d√©but d√©cembre, toujours rien\n\nC‚Äô√©tait pr√©vu ‚Äúdans un mois‚Äù d‚Äôapr√®s l‚Äôannonce du 2 d√©cembre. On est le 11 janvier. Rien.\n\n5. Pas de mode vocal\n\nTous les autres l‚Äôont (ChatGPT, Claude, Gemini). Mistral a juste r√©pondu ‚Äúon note votre int√©r√™t‚Äù sur l‚ÄôApp Store. C‚Äôest pr√©vu ou pas ?\n\nJe garde mon abo Mistral parce que je veux que √ßa r√©ussisse. Mais concr√®tement, je suis oblig√© de payer aussi ChatGPT/Gemini/ alors que j‚Äôaimerais juste utiliser Mistral.\n\nQuestions :\n\n\\- Le bug Agents + Biblioth√®ques, c‚Äôest connu ? Fix pr√©vu quand ?\n\n\\- Comment obtenir des r√©ponses plus d√©velopp√©es ?\n\n\\- L‚Äôacc√®s web, c‚Äôest en cours d‚Äôam√©lioration ?\n\n\\- Le mode vocal, c‚Äôest sur la roadmap ou abandonn√© ?\n\n\\- Des users qui arrivent √† utiliser Mistral pour de la cr√©ation p√©dagogique sans gal√©rer ?\n\nVoil√†, j‚Äôesp√®re que √ßa remonte aux √©quipes. Flash Answers prouve que techniquement vous avez le niveau, mais les features avanc√©es sont pas au point pour du vrai boulot quotidien.\n\nMerci de m‚Äôavoir lu üá´üá∑",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q8y0h9/feedback_utilisateur_pro_plusieurs_bugs_qui/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nyr4wuc",
          "author": "gdsfbvdpg",
          "text": "Regarding #1 - yes that annoys me too but I found a work around.  Maybe you already know,\n\n1. In your chat, choose your agent\n2. click the \"attachment\" button.\n3. your agent library will be listed. Select it.\n\nhttps://preview.redd.it/fi02m55wbhcg1.jpeg?width=864&format=pjpg&auto=webp&s=6926302fd8a35d1ed86f655809763ceb0e8f2da5",
          "score": 5,
          "created_utc": "2026-01-10 08:05:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrrxnc",
          "author": "MttGhn",
          "text": "Un pdf de 180 pages c'est typiquement ce qui sature ou surcharge la m√©moire de contexte d'un mod√®le et fait s'effondrer sa pertinence. Pourquoi ne pas utiliser un rag ?!",
          "score": 2,
          "created_utc": "2026-01-10 11:37:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nys5gf8",
              "author": "AdIllustrious436",
              "text": "Les biblioth√®ques sur Le Chat c'est du RAG, et c'est justement le probl√®me ici, l'agent ne fait pas assez de requ√™te RAG et r√©pond √† c√¥t√©.",
              "score": 2,
              "created_utc": "2026-01-10 13:20:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nysarwm",
              "author": "Ajst974",
              "text": "Ben c‚Äôest du rag justement ‚Ä¶",
              "score": 1,
              "created_utc": "2026-01-10 13:52:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nytcpun",
                  "author": "MttGhn",
                  "text": "Dans ce cas quelle logique de chunking utilises-tu?",
                  "score": 1,
                  "created_utc": "2026-01-10 17:08:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyso7et",
          "author": "Nefhis",
          "text": "Thank you for the detailed description; this kind of structured feedback is really helpful.\n\nRegarding the Agents + Libraries issue: in my experience, this isn't a \"bug\" in the strictest sense, but rather a usability or triggering problem. A generic instruction like \"ALWAYS consult the Library documents\" isn't reliably followed (this happens on all platforms, not just Le Chat). Retrieval is usually on demand, so the agent might skip the library unless the request explicitly links to it.\n\nWhat usually works best is explicitly request: \"Based on \\[specific PDF name\\], do X/summarize Y/cite the relevant sections.\"\n\nhttps://preview.redd.it/77ok83vyejcg1.png?width=1326&format=png&auto=webp&s=3af54ca2c4ea8b3cf5d344afd90151fbc74d002e\n\nAnd double-check the basics: make sure the Library is enabled/attached for that agent/conversation (it's easy to end up using an agent when the library isn't active, depending on how it's configured).\n\nRegarding the other points (response depth, web access reliability, voice/TTS, etc.), the team are already aware that these are recurring issues and are considering your feedback. I can't provide further details at this time, but thank you again for taking the time to document it clearly.\n\nu/Nefhis   \n*Mistral AI Ambassador*",
          "score": 2,
          "created_utc": "2026-01-10 15:08:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyszkgb",
              "author": "Ajst974",
              "text": "Thank you for the feedback!\n\nIn fact, since it is for the creation of pedagogical sequence I need him to have my instruction and methodology documents in reference and without having to refer to each request, it works well in the projects on ChatGPT and Claude (they understand that they must consult my documents before requesting answer), hoping that it becomes possible with mistral because it will greatly change my use and surely that of other users.\n\nGreat we are waiting for the release of the mistral 3 reasoning model with impatience, hoping that the vocal etc will be added at the same time!",
              "score": 2,
              "created_utc": "2026-01-10 16:06:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz5s09y",
          "author": "Relevant_March_3000",
          "text": "Hello u/Ajst974,\n\nSupport Technique de Mistral ici üòé\n\nMerci pour le retour et pour avoir pris le temps de d√©tailler tout √ßa.\n\nJuste pour clarifier deux points importants.  \nLes Agents sont bien cens√©s utiliser les Biblioth√®ques qui leur sont rattach√©es, et l‚Äôacc√®s web fonctionne de notre c√¥t√©. Dans la tr√®s grande majorit√© des cas, quand √ßa donne l‚Äôimpression que les Biblioth√®ques sont ignor√©es ou que le web est d√©faillant, c‚Äôest li√© √† un point de configuration, au contexte fourni √† l‚Äôagent, ou √† un cas d‚Äôusage un peu particulier. Rien de structurellement cass√© √† ce niveau.\n\nOn est clairement preneurs de creuser ton cas plus en d√©tail, parce que tout ce que tu d√©cris devrait fonctionner. Le plus efficace serait de passer par notre canal de support pour qu‚Äôon puisse regarder concr√®tement ta config, des exemples pr√©cis et voir ce qui coince exactement.\n\nSi tu veux, ouvre un ticket et on prend √ßa avec toi pour t‚Äôaider √† d√©bloquer la situation ou au moins r√©cup√©rer ton feedback pour s'am√©liorer.\n\nSi tu veux ouvrir un ticket, c'est par [ici](https://help.mistral.ai/en/articles/347458-how-do-i-contact-support) !\n\nEncore merci pour ton retour tr√®s d√©taill√© et construit",
          "score": 1,
          "created_utc": "2026-01-12 13:42:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7hp5a",
          "author": "Ajst974",
          "text": "Bonjour ! Merci je vais le faire ! \n\nEffectivement j‚Äôai cr√©er un agent avec des instructions pour la conception et cr√©ation de s√©quences p√©dagogique en tant que professeur d‚Äôinformatique au lyc√©e et malheureusement mes documents p√©dagogiques et instructions sont compl√®tement ignor√©s‚Ä¶ je suis oblig√© de les citer ou les rajouter aux prompts pour esp√©rer qu‚Äôils le soient . L√† ou chez les concurrents je n‚Äôai pas besoin de me r√©p√©ter. Cela fait assez longtemps que c‚Äôest comme √ßa pour ma part sur Le chat m√™me avec abonnement pro.\n\nPour l‚Äôacc√®s web c‚Äôest pas toujours. √áa d√©pends des sites mais j‚Äôai d√©j√† constat√© que certains sites ne fonctionnent pas l√† o√π d‚Äôautres IA y parviennent sans probl√®me. \n\nMerci encore de votre attention , j‚Äôesp√®re sinc√®rement que vous arriverez √† nous proposer un produit aussi qualitatif que les am√©ricains ou autres afin de pouvoir sans passer et rester sur une IA fran√ßaise enfin ! √âgalement que vous mettrez autant vos clients particuliers au niveau des entreprises qui sont pour le moment clairement votre cible principale ( m√™me si √ßa se comprend , en tant qu‚Äôutilisateur quotidien et m√™me pour mon travail de prof on est pas encore l√† cible c‚Äôest dommage ).\n\nEncore¬†merci de votre r√©ponse et attention !",
          "score": 1,
          "created_utc": "2026-01-12 18:37:56",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9exs8",
      "title": "Bellissimo.",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/1k13krk72lcg1.jpeg",
      "author": "NumerousDimension690",
      "created_utc": "2026-01-10 20:38:35",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q9exs8/bellissimo/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyum4qq",
          "author": "cosimoiaia",
          "text": "Well, that's just from wikipedia, but, as a fan of Dream theater, I agree! üòú\n\nKudos for using the small local model! I run it too for a couple of tasks, text extraction, title generation and some light intent classification sometimes, it performs surprisingly well for it's size!",
          "score": 1,
          "created_utc": "2026-01-10 20:46:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzd2nk",
      "title": "trying out u/Nefhis's tutorial because im new!! im doing the library documents part",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/gallery/1pzd2nk",
      "author": "PotentialPiano49",
      "created_utc": "2025-12-30 08:44:57",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzd2nk/trying_out_unefhiss_tutorial_because_im_new_im/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwpbipx",
          "author": "Nefhis",
          "text": "Hope the tutorial is helping you so far! üòä  \nRegarding the two background versions, I think version 1 is definitely the stronger one.\n\nEven if it's longer, it‚Äôs still short enough to stay practical, and it gives you facts that actually help define how to play the character.\n\nIf this were a technical worldbuilding document I‚Äôd trim the literary language, but for a personal character bio like yours, this level of narrative color works fine. Version 2 is ‚Äúshort‚Äù, but too abstract to be useful.\n\nIf you need help with other parts of the build or narrative style, feel free to ask.",
          "score": 4,
          "created_utc": "2025-12-30 09:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq7b9c",
              "author": "PotentialPiano49",
              "text": "thank you so much üíôüíô i added the background!\n\nhavent added any supporting character yet though (will def do once i get feel of everything). and regarding the character I'll be playing, i haven't added that yet too cus im not quite sure what to put in. do i just put the same details as i did to cade? what if they meet as strangers?\n\nfor the plot... i dont have plot yet hahaha but I'll def make it simple for now. how should i tackle this? in cGPT, i do these timelines like: CHECKPOINT 1 - this happened... CHECKPOINT 2 - that happened... and so on.\n\nand then for the stylebook, I'm not quite sure too but i do have RP rules right here. im thinking of also adding the setting of the RPG.\n\nhttps://preview.redd.it/g64dnxzcgcag1.jpeg?width=720&format=pjpg&auto=webp&s=76879d34586867d8d539387dbc70660daeba200b",
              "score": 3,
              "created_utc": "2025-12-30 13:33:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqsqdn",
                  "author": "Nefhis",
                  "text": "**For your own player character:**  \nOnly write what other characters (the ones played by the LLM) should actually know.  \nLLMs cannot keep secrets. If you give them hidden trauma, hidden motives, or hidden twists, they will use it immediately because generalist models tend to push the story toward resolutions as fast as possible.  \nSo keep your character sheet minimal: public facts only.  \nAnything the LLM discovers *in-scene*, you can later add to your sheet.\n\n**About them meeting as strangers:**  \nNo problem at all.  \nOnly write what the rest of the characters really know, should be able to observe or infer.  \nAs the story progresses, you can update the sheet with things that become public or discovered naturally.\n\n**Checkpoints / Plot**  \nYour checkpoint method is great. I use something similar, but per chapter.  \nJust one important thing:  \nCreate checkpoints after the event has happened, not before.  \nIf you announce ‚ÄúIn this chapter X will happen‚Äù, the LLM will accelerate the scene unnaturally to force that outcome.  \nIf you wait until the scene is done, then write the checkpoint, you get continuity without railroading.\n\nThis isn‚Äôt a Le Chat issue; it‚Äôs a general LLM behavior.  \nModels try to ‚Äúclose the loop‚Äù as soon as they see the target.  \nThe good thing is that Le Chat tends to feel less nanny and more willing to play along, so you‚Äôll get nicer organic twists than in other platforms.  \n  \n**Stylebook / Rules / Setting**  \nYour RP rules look great.  \nAnd yes: if you have anything about setting, location, mood, red lines, boundaries, put it there too.  \nAll that helps the model stay consistent.\n\nYou‚Äôre on the right track üòä",
                  "score": 3,
                  "created_utc": "2025-12-30 15:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qatfmz",
      "title": "Anyone using Mistral Le Chat? How do Projects compare to Claude or ChatGPT?",
      "subreddit": "MistralAI",
      "url": "/r/Dimaginar/comments/1qasw0l/anyone_using_mistral_le_chat_how_do_projects/",
      "author": "PvB-Dimaginar",
      "created_utc": "2026-01-12 12:20:09",
      "score": 11,
      "num_comments": 16,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qatfmz/anyone_using_mistral_le_chat_how_do_projects/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "nz5gatp",
          "author": "Nefhis",
          "text": "Projects works exactly the same as Projects in ChatGPT, and Agents are almost exactly the same as ChatGPT Custom GPTs, so if you're used to that, you shouldn't have any problems.   \n  \nWhat exactly isn't working the same way for you regarding your post-writing instructions, and where are you writing those instructions?",
          "score": 7,
          "created_utc": "2026-01-12 12:28:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5itlo",
              "author": "ameliassoc",
              "text": "I started trying out Le Chat a couple of days ago and found I can only add 3 chats to a Project. Is this limit lifted for paying users? I plan to switch to paid soon (as it seems that Le Chat more than adequately replaces ChatGPT for my use case) but wasn't able to find an answer about this specifically.",
              "score": 2,
              "created_utc": "2026-01-12 12:46:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz5pcmq",
                  "author": "Nefhis",
                  "text": "I'm on a Pro subscription and I have six chats in one of my projects, so I guess so.",
                  "score": 4,
                  "created_utc": "2026-01-12 13:27:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5k88x",
                  "author": "PvB-Dimaginar",
                  "text": "So far I only have 2 chats for a project. Also using the free plan. Was not aware of this limitation. Thanks for sharing!",
                  "score": 1,
                  "created_utc": "2026-01-12 12:55:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz5iup9",
              "author": "PvB-Dimaginar",
              "text": "Normally I write my draft and feed it to my instruction. With Claude I'm used to getting a few clarifying questions first, then a polished version of what I actually wrote.\n\nWith Le Chat that's not happening. No questions, just a long answer full of details that have nothing to do with my original draft.\n\nIt seems to ignore the process part of my instruction. Since GPTs I use this format: role and objective, guidelines, constraints, input, output, process (to get from input to output).\n\nThis evening I'll try some other instructions to see if it's specific to this one, or if I need to adapt my approach.",
              "score": 2,
              "created_utc": "2026-01-12 12:46:14",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz5q6mu",
                  "author": "Nefhis",
                  "text": "There are three different places where you can use custom instructions: global (default), projects, and agents. I haven't checked in a while, but a few weeks ago, project and global instructions could coexist, while agent instructions overrode global ones. I think I need to know exactly where you're using your custom instructions.",
                  "score": 2,
                  "created_utc": "2026-01-12 13:31:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz6rcav",
          "author": "gdsfbvdpg",
          "text": "The per-project settings are better in le chat. However, managing files is more intuitive in gpt.\n\nAlso, I've found that I always need to explicitly tell it that the files are \"in the library\". Otherwise it won't see them.",
          "score": 4,
          "created_utc": "2026-01-12 16:38:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5l1ib",
          "author": "Boulesk",
          "text": "I have only used ChatGPT. I see no difference between Mistral and ChatGPT.",
          "score": 3,
          "created_utc": "2026-01-12 13:00:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nziqhhz",
          "author": "Cyberblob42",
          "text": "I like Le Chat and I am also currently trying MistralVibe with Devstral-2. seems fine :)",
          "score": 2,
          "created_utc": "2026-01-14 11:10:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5hwar",
          "author": "Dear-Sample8296",
          "text": "only used it once, less rambeling than ChatGPT but very opinionated?",
          "score": 2,
          "created_utc": "2026-01-12 12:39:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz5ki27",
              "author": "PvB-Dimaginar",
              "text": "Interesting observation. I'll keep an eye on this.",
              "score": 1,
              "created_utc": "2026-01-12 12:57:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1vcrs",
      "title": "Mistral Vibe CLI : .vibe Folder",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q1vcrs/mistral_vibe_cli_vibe_folder/",
      "author": "Beginning_Divide3765",
      "created_utc": "2026-01-02 10:33:40",
      "score": 11,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "I discovered pretty interesting details when using Vibe CLI and asked It about the .vibe folder.\n\nI saw a plugin directory showing there any example of use cases ?\n\nFrom where do we get these plugins ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q1vcrs/mistral_vibe_cli_vibe_folder/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxmm1dc",
          "author": "Bob5k",
          "text": "no idea re plugins, but skills within vibe are SO DAMN POWERFUL. I even made use of those within [clavix.dev](http://clavix.dev) recently.",
          "score": 1,
          "created_utc": "2026-01-04 14:16:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzhxw3",
      "title": "Image Generation",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzhxw3/image_generation/",
      "author": "Beginning_Divide3765",
      "created_utc": "2025-12-30 13:19:48",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "What is the best way to keep context and style between image generations especially when it's a cartoony style generation ? \n\nAny hints, tips or best practices ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzhxw3/image_generation/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwr07ts",
          "author": "Nefhis",
          "text": "Virtually impossible. I've had good experiences maintaining the same prompt with slight variations, but inevitably, after several generations, it eventually loses its consistency. The only thing I can think of is asking you to edit images you already have that match the context and/or positions you're looking for, and work on them to adapt them to your needs.\n\n**Same prompt, progressive loss of style:**\n\nhttps://preview.redd.it/nftxy1mi7dag1.png?width=2584&format=png&auto=webp&s=6fd98736edda9cb69c2755c32309c56f7205c95f",
          "score": 3,
          "created_utc": "2025-12-30 16:06:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0a9c7",
      "title": "Mistral Vibe CLI - Skills",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q0a9c7/mistral_vibe_cli_skills/",
      "author": "Beginning_Divide3765",
      "created_utc": "2025-12-31 10:50:13",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "Anybody succeeded in adding skills to Mistral Vibe CLI ?  \nIn this X post, it was announced and added to the release notes :  \n[https://x.com/mistralai/status/2003843358054068327?s=46&t=TJMSL8DvpU3ASKQGENVCvw](https://x.com/mistralai/status/2003843358054068327?s=46&t=TJMSL8DvpU3ASKQGENVCvw)\n\nBut I didn't find any documentation about it.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q0a9c7/mistral_vibe_cli_skills/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwxwf6h",
          "author": "thibautDR",
          "text": "Was looking for the same. Found the solution here: [https://github.com/mistralai/mistral-vibe/issues/189#issuecomment-3694658645](https://github.com/mistralai/mistral-vibe/issues/189#issuecomment-3694658645)",
          "score": 3,
          "created_utc": "2025-12-31 17:00:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy33kj",
              "author": "f1rn",
              "text": "Woah! Thank you!",
              "score": 1,
              "created_utc": "2025-12-31 17:33:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q7n3o6",
      "title": "It's been more than two months since I last managed to log in. I guess sentry.io causes more problems than it solves",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/snykbh09p6cg1.jpeg",
      "author": "ready64A",
      "created_utc": "2026-01-08 20:32:07",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7n3o6/its_been_more_than_two_months_since_i_last/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nymc6zd",
          "author": "mattator",
          "text": "https://preview.redd.it/vm4s9ntunccg1.png?width=1261&format=png&auto=webp&s=3345749fad3bccaa434a0ad42eebbe4205353134\n\nI cant login or signup either. First time I cant log into a website :s",
          "score": 3,
          "created_utc": "2026-01-09 16:24:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyramcl",
          "author": "harpercix",
          "text": "It appended to me many times. I cleared the \"browsing data\" about mistral and logged. I worked.",
          "score": 1,
          "created_utc": "2026-01-10 08:58:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qagzlo",
      "title": "Memory",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qagzlo/memory/",
      "author": "Due_Bluebird4397",
      "created_utc": "2026-01-12 01:08:21",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "Hello everyone! I'm new and I'm asking for help. LeChat after my direct request to \"save\" the information, simply does nothing, although it tells me that it has saved it. Before that (literally 10 minutes ago everything was fine and I saved the information). Does anyone know how to fix it?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qagzlo/memory/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nz2wk9f",
          "author": "Nefhis",
          "text": "I just checked and it works correctly on my account. However, you can go to the memory section and enter them manually if you can't wait. It will save and use them anyway.\n\nhttps://preview.redd.it/gxib41bsktcg1.png?width=828&format=png&auto=webp&s=e975489ae0e44e356e783e471b86b4011ce1798b",
          "score": 2,
          "created_utc": "2026-01-12 01:17:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2x8rg",
              "author": "Due_Bluebird4397",
              "text": "I also try to do this \"Manually\", but nothing happens there either. Apparently I'm lucky to have bugs. üòÖThanks!",
              "score": 2,
              "created_utc": "2026-01-12 01:20:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4wtph",
                  "author": "Nefhis",
                  "text": "When you try to add memory manually, does it not store it, not use it, or display any error message?\n\nhttps://preview.redd.it/5l4ycvj03wcg1.png?width=3644&format=png&auto=webp&s=4174fe4b2f82f4ee077c8cb227172f8b53bc606b",
                  "score": 1,
                  "created_utc": "2026-01-12 09:42:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz37mgk",
              "author": "Idkanymore_123",
              "text": "Does it let you do nsfw? because I tried and it says that it has to keep things safe but my characters are 25+",
              "score": 1,
              "created_utc": "2026-01-12 02:15:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz4itkw",
                  "author": "f1rn",
                  "text": "Create an agent and write in the instructions that it is a nsfw adult story narrator or something. Thst will work 100%",
                  "score": 1,
                  "created_utc": "2026-01-12 07:29:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q6i660",
      "title": "REGENERATE rarely REGENERATES",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/smcdik713ybg1.jpeg",
      "author": "Icy-Consideration278",
      "created_utc": "2026-01-07 15:22:14",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6i660/regenerate_rarely_regenerates/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny8bsk6",
          "author": "eTukk",
          "text": "Yes, this I recognize. I need to retell my story many times to get closer to the answer. When leaving not a date in the query, you get stuff written down long time ago. Not stuff that I need now!\n\nLike it has to little calculation power, or time needed that it can get, to get the context right.?",
          "score": 4,
          "created_utc": "2026-01-07 17:09:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8m5jp",
          "author": "ComeOnIWantUsername",
          "text": "Yes, regenerate mostly generates 1:1 the same text for me as before. I also had it multiple times that I asked a question, got shitty response -> rephrased question giving more details -> got exactly the same response again",
          "score": 4,
          "created_utc": "2026-01-07 17:55:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9d2k7",
          "author": "[deleted]",
          "text": "I believe this goes back to a problem pretty much every modern Mistral model has and that they can't seem to be able to fix:\n\n\nTheir model's output quality degrades dramatically once the so-called \"temperature\" (the randomness and \"creativity\" in answers) is set too high, which is why they recommend setting it to low values like 0.15 (see Mistral Small 3.2 for example). This may be what they're doing with Le Chat as well.\n\n\nBut setting it low means the models produce the same text pretty much all the time.",
          "score": 3,
          "created_utc": "2026-01-07 19:52:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny98ngo",
          "author": "CamelGangGang",
          "text": "My understanding is that regenerate rarely does anything because while they select tokens at random, the probability distribution collapses to the 'most likely' output quite quickly. If you want a different response, you likely need to alter the semantic meaning of your prompt and/or give more detailed instructions about what you want in the output.",
          "score": 2,
          "created_utc": "2026-01-07 19:33:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8w947",
          "author": "PotentialSolution614",
          "text": "change or specify the input until it works",
          "score": 2,
          "created_utc": "2026-01-07 18:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pynkny",
      "title": "Seahorse emoji flashbacks",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/6k9ybcpbj5ag1",
      "author": "memestealer_alpha",
      "created_utc": "2025-12-29 14:25:39",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pynkny/seahorse_emoji_flashbacks/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwjsvhh",
          "author": "stddealer",
          "text": "That's why I never turn on thinking unless it's a really tricky question.",
          "score": 3,
          "created_utc": "2025-12-29 14:31:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzb8m0",
      "title": "Question about API Speed ‚Äã‚ÄãLimits",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzb8m0/question_about_api_speed_limits/",
      "author": "Ordinary_Mud7430",
      "created_utc": "2025-12-30 06:55:02",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I've searched (unsuccessfully) for more detailed information on how to increase the API speed limit. At the Free tier, it was set to 1 request per second. I recharged with $10, but the limit didn't increase; it still says 1 request per second. So my question is: How much or how can I actually upgrade to Tier 1? The current speed is affecting my performance and results. I've noticed that OpenRouter doesn't seem to have speed limits, and Devstral-2 responds much better to everything.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzb8m0/question_about_api_speed_limits/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q2y8rt",
      "title": "Humans still matter - From ‚ÄòAI will take my job‚Äô to ‚ÄòAI is limited‚Äô: Hacker News‚Äô reality check on AI",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2y8rt/humans_still_matter_from_ai_will_take_my_job_to/",
      "author": "alexeestec",
      "created_utc": "2026-01-03 16:03:29",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.67,
      "text": "Hey everyone, I just sent the [14th issue of my weekly newsletter](https://eomail4.com/web-version?p=df548fb0-e8b0-11f0-97f9-35afc9c82550&pt=campaign&t=1767453183&s=7c47542c3ad56e6eed6af44e36cbbf4730b4cb3719a90a6509069ad7d68bbb34), Hacker News x AI newsletter, a roundup of the best AI links and the discussions around them from HN. Here are some of the links shared in this issue:\n\n* The future of software development is software developers - [HN link](https://news.ycombinator.com/item?id=46424233)\n* AI is forcing us to write good code - [HN link](https://news.ycombinator.com/item?id=46424200)\n* The rise of industrial software - [HN link](https://news.ycombinator.com/item?id=46442597)\n* Prompting People - [HN link](https://news.ycombinator.com/item?id=46457240)\n* Karpathy on Programming: ‚ÄúI've never felt this much behind‚Äù - [HN link](https://news.ycombinator.com/item?id=46395714)\n\nIf you enjoy such content, you can subscribe to the weekly newsletter here: [**https://hackernewsai.com/**](https://hackernewsai.com/)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2y8rt/humans_still_matter_from_ai_will_take_my_job_to/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q7gcgv",
      "title": "A realistic proposal for OpenAI: Release the text-only weights for GPT-4o (I share it here for  gpt 4o users that use now Mistral like myself)",
      "subreddit": "MistralAI",
      "url": "/r/ChatGPTcomplaints/comments/1q7amj7/a_realistic_proposal_for_openai_release_the/",
      "author": "Ashamed_Midnight_214",
      "created_utc": "2026-01-08 16:29:30",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.63,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7gcgv/a_realistic_proposal_for_openai_release_the/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qb3uce",
      "title": "devstral-small-2 hosting providers?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qb3uce/devstralsmall2_hosting_providers/",
      "author": "pinmux",
      "created_utc": "2026-01-12 19:02:09",
      "score": 4,
      "num_comments": 7,
      "upvote_ratio": 0.76,
      "text": "Are there any devstral-small-2 hosting providers (besides Mistral themselves) available who do not train on requests?\n\nOllama-cloud appears to offer devstral-small-2 but does not offer much information about the modifications they've made to their cloud offering (their default \"latest\" local model is heavily quantized and their cloud model only offers text and a smaller maximum token limit: https://ollama.com/library/devstral-small-2).\n\nAre there any others providers?\n\nBigger name LLM providers that I've looked at all seem to offer devstral-small-2 if I want to spin up a dedicated host, but I can't justify that cost and would prefer a pay-per-request API or subscription model, with a no-training promise.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qb3uce/devstralsmall2_hosting_providers/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nz7tu9t",
          "author": "cosimoiaia",
          "text": "Never, ever use ollama. For anything.\n\nI'm not aware of anyone else besides openrouter but, as you said, they route to Mistral. (I don't even consider third party providers that train on my data)",
          "score": 3,
          "created_utc": "2026-01-12 19:32:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7vrbd",
              "author": "pinmux",
              "text": "Ollama for local operation seems fine, I just don't have fast enough local hardware to make devstral-small-2 run at a reasonable speed and buying hardware that can run at a decent speed is quite a lot more money than paying for API use or a subscription right now.",
              "score": 1,
              "created_utc": "2026-01-12 19:41:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz87tlk",
                  "author": "cosimoiaia",
                  "text": "No, sorry, Ollama is the worst piece of software you can use. Arbitrary model naming, worst performance and stolen, botched, backend. Do not exposed it to the public because it has severe security issues. It's worth spending a second to look into the OG llama.cpp, you'll get much better performances (~30%), it is safer and you're not fuelling stolenware. If you use APIs you can get much better results with it, you can even use your ram as unified memory (of course it's still ram, so don't expect miracles).\n\nYes, in average paying for APIs in cheaper but depends on your usage. \n\nMistral's are good imo, if you use vibe you still get a lot of free usage (last time I checked) and it's a very solid CLI.",
                  "score": 1,
                  "created_utc": "2026-01-12 20:37:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7p7dq",
          "author": "jorgejhms",
          "text": "For pay per token you have Openrouter for basically any model from any provider.",
          "score": 1,
          "created_utc": "2026-01-12 19:11:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7r4y0",
              "author": "pinmux",
              "text": "The only providers hosting devstral-small-2 on Openrouter are Mistral themselves and Chutes.  Chutes train on data submitted.  I'm looking for non-Mistral providers who don't train on data.",
              "score": 1,
              "created_utc": "2026-01-12 19:20:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz8jggn",
          "author": "mobileJay77",
          "text": "Devstral small runs on a 5090 with quants, if that's OK you can rent the GPU easily.",
          "score": 1,
          "created_utc": "2026-01-12 21:32:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz97p3l",
              "author": "pinmux",
              "text": "I don‚Äôt really want to deal with less than 8 bit quants for models like this which are published at 16 bit and where Mistral recommends 8 bit. That doesn‚Äôt leave much KV cache space in a 5090. But definitely a thing I will explore more!¬†\n\nI have looked at renting a capable host but I don‚Äôt think it‚Äôs financially reasonable when I can get other decent models from providers at API or subscription rates. My usage isn‚Äôt extreme, $20 Claude Code plan has me rarely hit limits.¬†",
              "score": 1,
              "created_utc": "2026-01-12 23:32:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzanlv",
      "title": "How long does Mistral OCR take you to process files?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzanlv/how_long_does_mistral_ocr_take_you_to_process/",
      "author": "bravelogitex",
      "created_utc": "2025-12-30 06:22:32",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Curious about other results. Here are mines, both pdfs (dec 2025): \n\n18 page doc with simple compliance forms: 5 seconds on avg\n\n1 page shipping table with numbers: 6 seconds on avg",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzanlv/how_long_does_mistral_ocr_take_you_to_process/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbrolo",
      "title": "narrative roleplaying with Le Chat is just not doing it for me",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qbrolo/narrative_roleplaying_with_le_chat_is_just_not/",
      "author": "PotentialPiano49",
      "created_utc": "2026-01-13 13:45:12",
      "score": 3,
      "num_comments": 8,
      "upvote_ratio": 0.81,
      "text": "idk if im doing something wrong. \n\ni followed the guide, i tried to keep everything as concise as i could, i experimented on things, made guardrails‚Äî\n\nbut i feel like nothings working. idk.\n\nmaybe im just stupid or smth but the responses feel so repetitive or something.\n\nlike it's so long and the ai keeps repeating the emotions and all.\n\nmaybe it's cus i came from chatGPT that maybe im just not used to it yet. idk.\n\nany tips?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qbrolo/narrative_roleplaying_with_le_chat_is_just_not/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzcuffw",
          "author": "cutebluedragongirl",
          "text": "It's the opposite for me, lol. Mistral models are the best for RP in my humble opinion. But I use API for all of my LLM needs so... Maybe Le Chat does something weird with a system prompt?",
          "score": 6,
          "created_utc": "2026-01-13 14:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzcv18w",
              "author": "PotentialPiano49",
              "text": "how does one use API? I'd like to explore my options pls TvT",
              "score": 3,
              "created_utc": "2026-01-13 14:27:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nze1y0z",
                  "author": "f1rn",
                  "text": "The thing with API is... it gives way better and longer answers but also - you dont have the WebUI from LeChat, there are no memories and there is no sync between devices or installations.   \nApart from that? It's worth it! \n\n\\- You need an API Key from Mistral: [https://console.mistral.ai/api-keys/](https://console.mistral.ai/api-keys/)  \n\\- You will need a payment method. Credit Card will do fine!   \n\\- You need a Chat app.   \n  \nI dont know your OS. So I assume Windows?   \n  \nI suggest:\n\nJan [https://www.jan.ai/](https://www.jan.ai/)  \nor  \nChatbox [https://chatboxai.app/](https://chatboxai.app/)\n\nInstall it.   \nAdd your api key and choose a model. I suggest adding `labs-mistral-small-creative`  \n[https://docs.mistral.ai/models/mistral-small-creative-25-12](https://docs.mistral.ai/models/mistral-small-creative-25-12)\n\nOpen a new chat and have fun!",
                  "score": 4,
                  "created_utc": "2026-01-13 18:01:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzd61nm",
          "author": "gdsfbvdpg",
          "text": "The repetition is real. \nI've been trying the following custom instruction to change it. \nIt doesn't fix the problem but it helps. Maybe you'll find the right tweak to make it work completely. \n\n---\n\n## Linguistic Variance & Novelty\n- Maintain a \"Mental Log\" of key metaphors used in the last 10 turns.\n- If a metaphor or structural cadence has been used once, it is strictly forbidden for the remainder of the session.\n- Prioritize \"Plain Speech\" over \"Poeticism\" if you cannot find a unique way to describe a moment.",
          "score": 5,
          "created_utc": "2026-01-13 15:22:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzhmujd",
          "author": "Ruttin",
          "text": "Have you tried the creative model version? https://docs.mistral.ai/models/mistral-small-creative-25-12",
          "score": 3,
          "created_utc": "2026-01-14 05:15:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzdoxj8",
          "author": "Wrong_Country_1576",
          "text": "Yeah I agree. I find it to be repetitive as well, but at least it's possible.",
          "score": 2,
          "created_utc": "2026-01-13 16:49:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2u60e",
      "title": "Difficulties using Devstral 2 locally for tool use/coding interfaces",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2u60e/difficulties_using_devstral_2_locally_for_tool/",
      "author": "iamleeg",
      "created_utc": "2026-01-03 13:05:48",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 0.81,
      "text": "Hi all, I'm trying to set up Devstral 2 123B Instruct 2512 for local development on a Mac Studio M3 Ultra with 256GB RAM. That's more than enough memory, the model loads successfully in ollama or LMStudio and chat works fine. But it doesn't seem to work well with coding UIs. Here's the different setups I've tried. In each case, I have a markdown file describing bugs in some code and I prompt the model to read the bug reports, and make changes to one code file that would address two issues.\n\n\\- Model served with \\`ollama run devstral-2\\`, used via \\`vibe\\`. The model asks me to make changes to files. I ask whether it can do it itself, it says \"Yes, I can write files using the write\\_file tool! I can create new files or overwrite existing ones. If you'd like me to write or modify a file, just let me know the file path and the content you'd like to include.\" But it doesn't use the tool. I asked it to, and it replied with \\`read\\_file\\[ARGS\\]{\"path\": \"filename\"}\\`, like the attempt to use a tool just appeared in the chat.\n\n\\- Model served in ollama, used via Roo Code. It asked to create a markdown file describing its changes, I told it not to and to fix the source file itself. It encountered \"API Request Failed: unexpected end of JSON input\".\n\n\\- Model served in ollama, used via Continue VSCodium extension. When I apply changes to the file, it just deletes the original content without adding its changes.\n\n\\- Model served in LMStudio, used via Roo Code. Attempts to use tools hit a prompt template error: \"Error rendering prompt with jinja template: \"After the optional system message, conversation roles must alternate user and assistant roles except for tool calls and results.\".\n\n\\- Model served in LMStudio, used via \\`vibe\\`. This is the only configuration I've tried that seems to work reliably. The model updates its TODOs correctly, and makes changes to files.\n\n\\- Model served in LMStudio, used via Continue. Tool use attempts just appear in the output stream.\n\n  \nHas anybody got a setup that works reliably they could share, please, or guidance to either diagnose these issues or route problem reports to the correct places?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2u60e/difficulties_using_devstral_2_locally_for_tool/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxfs40k",
          "author": "Ill_Barber8709",
          "text": "I use Devstral-Small-2 without issue in Zed. Continue.dev is a pain to use and setup correctly. \n\nI serve the MLX model using LMStudio.\n\nDon‚Äôt use Ollama on Mac. It can‚Äôt handle MLX models, which are 20% faster than similar quant GGUF.",
          "score": 3,
          "created_utc": "2026-01-03 13:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxflzwy",
          "author": "Voidheart88",
          "text": "At least the Jinja error sounds similar to an error I had with mistral models. I remember there was a fix where you need to change said Jinja template.",
          "score": 2,
          "created_utc": "2026-01-03 13:13:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfoxff",
              "author": "iamleeg",
              "text": "Thanks, that‚Äôs an interesting lead. Do you know if the corrected template is online anywhere?",
              "score": 1,
              "created_utc": "2026-01-03 13:32:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxfp64x",
                  "author": "Voidheart88",
                  "text": "Unfortunately not where. It took me a bit of googling last time.",
                  "score": 1,
                  "created_utc": "2026-01-03 13:33:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pz7hu0",
      "title": "Bullets or points suddenly lose their explanations",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pz7hu0/bullets_or_points_suddenly_lose_their_explanations/",
      "author": "02749",
      "created_utc": "2025-12-30 03:42:26",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Sometimes bullets or points suddenly lose their explanations; I see the full text for a split second, then it‚Äôs gone and only the headings remain.  \n  \nI've been chatting with Le Chat on Chrome on desktop for the past few months. This has never happened before today. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pz7hu0/bullets_or_points_suddenly_lose_their_explanations/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qbb0nu",
      "title": "Local LLM (Mistral 12.2B on Ollama with Open WebUI) inconsistent with JSON knowledge, prompt issue or model limitation?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qbb0nu/local_llm_mistral_122b_on_ollama_with_open_webui/",
      "author": "NixonTheCarnifex",
      "created_utc": "2026-01-12 23:30:16",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Hey, just a noob at anything regarding AI. So please don't mind the inaccurate terminologies you may find in my post.\n\nI have set up Ollama with Open WebUI, and running a mistral-nemo:latest 12.2B model. I fed the model a couple of .jsonl files as the \"Knowledge\" collection.\n\nThe files contain account codes for the business that are used for expenditure or something. Accounting stuff. Self explanatory on why a locally hosted AI model is the best choice.\n\nI practically wrote an essay in the System Prompt section, used ChatGPT on basically every step (defeating AI, with AI). It wrote a series of instructions and called them \"Definitions\", \"Hard Rules\", a process plan on how to navigate the files and how the codes work and stuff, an output format, instructions on how the model is allowed to ask the user a clarify question only once, etc etc etc. all that stuff. Sometimes the model does the right thing, but then it messes up again, especially in an ongoing chat. If i delete all the chats and ask the same questions again, the responses are a bit better.\n\nI assumed that the problems must be with my System Prompts or other parameters, but after days of being isolated with ChatGPT, i dont think that's the case.\n\nIs my AI getting confused between the codes? All codes have specific identifiers, names, descriptions, everything, and the AI has been told on how to proceed with the files and how to combine the codes and present them to the user. Sometimes, it does the job, but other times, it mixes the codes up, creates it's own or just says that request does not exist. Most of the time, it does not follow any of the forementioned instructions.\n\nI am soo in over my head that I have no clue if I even asked the right question?!?!\n\nAny response would be greatly appreciated.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qbb0nu/local_llm_mistral_122b_on_ollama_with_open_webui/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nz9ez7e",
          "author": "cosimoiaia",
          "text": "> I practically wrote an essay in the System Prompt section, \n\nThat's the problem right there. Too many instructions. The model is too small for that level of details and gets confused. \n\nMaybe try Mistral-small-24b, it should be much more capable. \n\nOh and btw, there is no Mistral 12.2b, that is just the wonky naming of that shitty stolenware that is ollama. If you're using openwebUI, just do yourself a favor and switch to llama.cpp. \n\nAlso check the model temp, sampling params, prompt template and get quant from a reputable source.",
          "score": 3,
          "created_utc": "2026-01-13 00:11:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzgnyd0",
          "author": "JohnnieDarko",
          "text": "First let mistral-nemo rewrite your system prompt, that might help. If not, and you can‚Äôt use a larger model, then there is another option.\n\nYou can program (Let chatGPT do it) an intermediate tool. This tool, probably an ‚ÄúMCP-server‚Äù, can translate in between your model and the json files.\n\nLet this tool take care of many ‚Äúsimple‚Äù things, like formatting rules and exact name lookups or whatever it is the model fails in. The system then becomes smarter because it can focus more on doing the correct action.",
          "score": 1,
          "created_utc": "2026-01-14 01:41:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc3z9g",
      "title": "Connect Mistral Le Chat with Obsidian Vault",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qc3z9g/connect_mistral_le_chat_with_obsidian_vault/",
      "author": "Ok_Regret_8432",
      "created_utc": "2026-01-13 21:29:47",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Bonjour everyone, I am currently exploring ways to integrate Le Chat with my Obsidian vault using MCP as a connector, similar to how it works with Notion. Has anyone here successfully set this up or experimented with it? Merci en advance \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qc3z9g/connect_mistral_le_chat_with_obsidian_vault/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nzfd2jy",
          "author": "inyofayce",
          "text": "Posting to follow.\n\nHad the same idea but I lack the technical know how to eventually set it up.",
          "score": 1,
          "created_utc": "2026-01-13 21:36:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzfjhpi",
          "author": "filz",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-01-13 22:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfjlyz",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-14 22:05:47 UTC**](http://www.wolframalpha.com/input/?i=2026-01-14%2022:05:47%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/MistralAI/comments/1qc3z9g/connect_mistral_le_chat_with_obsidian_vault/nzfjhpi/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FMistralAI%2Fcomments%2F1qc3z9g%2Fconnect_mistral_le_chat_with_obsidian_vault%2Fnzfjhpi%2F%5D%0A%0ARemindMe%21%202026-01-14%2022%3A05%3A47%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qc3z9g)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-13 22:06:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzjrsct",
          "author": "79cent",
          "text": "Following",
          "score": 1,
          "created_utc": "2026-01-14 15:02:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbmvqp",
      "title": "Mistral Medium made me laugh (in opencode)",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/qv0xmma643dg1.png",
      "author": "t4a8945",
      "created_utc": "2026-01-13 09:22:50",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 0.64,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qbmvqp/mistral_medium_made_me_laugh_in_opencode/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzc41t9",
          "author": "pas_possible",
          "text": "What is your experience with it",
          "score": 1,
          "created_utc": "2026-01-13 11:37:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzc43hk",
              "author": "pas_possible",
              "text": "Large is less expensive than medium btw",
              "score": 2,
              "created_utc": "2026-01-13 11:37:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzh1qvn",
                  "author": "Electrical_Date_8707",
                  "text": "that makes sense",
                  "score": 2,
                  "created_utc": "2026-01-14 02:59:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzc923s",
              "author": "t4a8945",
              "text": "I just wanted to try it out on a TDD workflow ; its context was too small for it so I gave up instantly.",
              "score": 2,
              "created_utc": "2026-01-13 12:16:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}