{
  "metadata": {
    "last_updated": "2026-02-17 17:24:28",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 170,
    "file_size_bytes": 174956
  },
  "items": [
    {
      "id": "1r64huf",
      "title": "Mistral already generates more revenue than Grok.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r64huf/mistral_already_generates_more_revenue_than_grok/",
      "author": "Nefhis",
      "created_utc": "2026-02-16 08:46:44",
      "score": 764,
      "num_comments": 33,
      "upvote_ratio": 0.98,
      "text": "\n\n**English summary of the Xataka article (Summary by Le Chat):**\n\nMistral AI, the Paris-based startup, is quietly achieving remarkable growth without the typical hype surrounding AI companies. Unlike its competitors, Mistral has avoided inflating stock prices but now generates more revenue than Elon Musk‚Äôs Grok. According to CEO Arthur Mensch, Mistral‚Äôs annualized revenue run rate has surged from $20 million to over $400 million in just one year‚Äîa twentyfold increase. The company, valued at ‚Ç¨12 billion in 2025, is on track to exceed $1 billion in annual recurring revenue by the end of 2026, driven by its focus on European technological sovereignty.\n\nMistral‚Äôs strategy centers on serving enterprise clients rather than end users, positioning itself as the go-to alternative for European businesses seeking independence from U.S. or Chinese AI infrastructure. With over 100 major corporate clients, including ASML, TotalEnergies, HSBC, and governments like France, Germany, and Greece, 60% of its revenue comes from Europe. Its appeal lies in offering locally hosted, low-emission AI solutions, aligning with Europe‚Äôs push to reduce reliance on foreign tech giants.\n\nThe company recently announced a ‚Ç¨1.2 billion investment in a new data center in Sweden, its first outside France, set to open in 2027. Sweden was chosen for its affordable, low-carbon energy, reinforcing Mistral‚Äôs commitment to sustainable, sovereign AI infrastructure. Mensch criticized the trend of U.S. hyperscalers building data centers in Europe, arguing that such projects primarily benefit American companies rather than European interests.\n\nMistral‚Äôs success is underpinned by its unique position as Europe‚Äôs only major developer of foundational large language models (LLMs). While it collaborates with global players like Microsoft and NVIDIA, its core mission remains empowering European autonomy in AI. As Mensch stated, Europe‚Äôs excessive dependence on U.S. digital services has reached a critical juncture, and Mistral provides a viable, independent alternative.\n\nBy combining rapid expansion with a principled stance on data sovereignty, Mistral is reshaping the AI landscape‚Äîproving that discretion and strategic focus can outperform noise.  \n  \n[https://www.xataka.com/robotica-e-ia/mistral-ia-que-mejor-esta-jugando-sus-cartas-porque-esta-aprovechando-fiebre-soberania-tecnologica-europea](https://www.xataka.com/robotica-e-ia/mistral-ia-que-mejor-esta-jugando-sus-cartas-porque-esta-aprovechando-fiebre-soberania-tecnologica-europea)\n\n[https://x.com/paulbz/status/2021537295883481437](https://x.com/paulbz/status/2021537295883481437)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r64huf/mistral_already_generates_more_revenue_than_grok/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5njnfx",
          "author": "NoWayYesWayMaybeWay",
          "text": "Great shit. Love Mistral ü´∂",
          "score": 64,
          "created_utc": "2026-02-16 08:56:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nj591",
          "author": "30wolf03",
          "text": "nice",
          "score": 34,
          "created_utc": "2026-02-16 08:51:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nsikz",
          "author": "dharmoslap",
          "text": "Europe is indeed in the race as well. \n\nLet‚Äôs also keep in mind that LLMs are getting smarter with feedback, which these days have to come from users as well.\n\nSo whoever sends feedback on answers while using Le Chat is providing Mistral something crucial.",
          "score": 23,
          "created_utc": "2026-02-16 10:20:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5rfncc",
              "author": "Swat_katz_82",
              "text": "At work we evaluate quite a few vendors for our in-house solutions, and mistral falls short everytime.\n\n\nIt baffles me, that mistral seems to be growing.¬†\n\n\nI'd love an euro company being rivals to openai or American tech, but¬† mistral doesn't seem like it.¬†",
              "score": 1,
              "created_utc": "2026-02-16 22:07:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5njgxk",
          "author": "Lynxbro",
          "text": "Oui oui baguette.",
          "score": 108,
          "created_utc": "2026-02-16 08:54:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o45ol",
              "author": "ChatDuFusee",
              "text": "BAG-WET?",
              "score": 2,
              "created_utc": "2026-02-16 12:01:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nlwxc",
          "author": "frederick1024",
          "text": "Bravo. On croise les doigts pour la suite !",
          "score": 21,
          "created_utc": "2026-02-16 09:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nlib2",
          "author": "So_andy",
          "text": "Let‚Äôs go Europe and Mistral üöÄ Also don‚Äôt forget about small users",
          "score": 33,
          "created_utc": "2026-02-16 09:14:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nud1y",
          "author": "Joddie_ATV",
          "text": "Kudos to the developers and the entire Mistral.AI team! You can be proud of yourselves! And frankly, it's well deserved... Keep up the good work!",
          "score": 8,
          "created_utc": "2026-02-16 10:37:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5noso1",
          "author": "AppropriateViking",
          "text": "Great news üî•",
          "score": 5,
          "created_utc": "2026-02-16 09:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nk4ke",
          "author": "SnooBunnies725",
          "text": "[HERE ](https://archive.is/20260211095728/https://www.ft.com/content/664249e7-e8d5-4425-b397-ad3ed590b305#selection-1954.0-1954.3)is a link to an English-language (non-paywalled) article on the FT.",
          "score": 7,
          "created_utc": "2026-02-16 09:00:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5o5q99",
              "author": "beniguet",
              "text": "It's a paywalled article from the FT... \n\nYou link to a loophole to access it not-on-the-FT without paying its publisher, though.\nNot judging, just being pedantically precise.",
              "score": 1,
              "created_utc": "2026-02-16 12:13:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nu7ub",
          "author": "Ill-Bison-3941",
          "text": "Mistral is also doing their bit by releasing local models ‚ù§Ô∏è",
          "score": 7,
          "created_utc": "2026-02-16 10:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o4gku",
          "author": "Shirirubboy",
          "text": "What a pleasant read! So glad that Mistral is faring much better than grok. Well done Mistral!",
          "score": 2,
          "created_utc": "2026-02-16 12:04:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5npp6g",
          "author": "TwoRight9509",
          "text": "Didn‚Äôt grok transition from being an ai in order to become its real dream - the autonomous driver of a robo taxi?",
          "score": 2,
          "created_utc": "2026-02-16 09:54:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nxt3h",
          "author": "Select_Ad_390",
          "text": "That‚Äôs amazing! But also, can we get Large 3 in Le Chat?",
          "score": 2,
          "created_utc": "2026-02-16 11:08:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oujr5",
          "author": "Etzello",
          "text": "I really wish they would fix it not showing sources when it searches web, spoke to them months ago about it and others confirmed the issue too",
          "score": 1,
          "created_utc": "2026-02-16 14:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q95j9",
          "author": "Old_Librarian__",
          "text": "I would use it more if it didn't keep giving me the massage limit reached :( Hope the new data centers changes something ",
          "score": 1,
          "created_utc": "2026-02-16 18:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qf0m3",
          "author": "mrSalema",
          "text": "Fantastique. Un croissant sil vous plez",
          "score": 1,
          "created_utc": "2026-02-16 19:08:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rxiwj",
          "author": "Confident-Village190",
          "text": "If only it were graphically depixelated...\nAnd hoping that at the IPO they kick out the US VCs and bring in European capital.",
          "score": 1,
          "created_utc": "2026-02-16 23:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nwq9f",
          "author": "Makaron8080",
          "text": "Even with this Mistral is not a profitable company. \nI think this is what will make a difference to AI companies that make profit or at least break even, or not.",
          "score": 1,
          "created_utc": "2026-02-16 10:58:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qtqct",
              "author": "skate_nbw",
              "text": "They are pretty healthy and prepared for the popping bubble. Not many will come out on the other side, Mistral will.",
              "score": 4,
              "created_utc": "2026-02-16 20:20:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5otkbz",
              "author": "blakesnake86",
              "text": "Not profitable yet, but still on a better trajectory than OpenAi who is burning through cash at an insane rate for results that aren't really any better.",
              "score": 5,
              "created_utc": "2026-02-16 14:38:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5poi2x",
          "author": "victorc25",
          "text": "You‚Äôre comparing a company (Mistral) against a model (Grok)? xAI‚Äôs annualized revenue was already $1.2 billion in 2025, more that Mistral‚Äôs target for 2026, what numbers are you using? ü§î¬†https://growjo.com/company/xAI",
          "score": 1,
          "created_utc": "2026-02-16 17:06:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5otbmw",
          "author": "Gold-Guess4651",
          "text": "I hate to say it but I went back from Mistral to CGPT. The performance difference was so large that I could not justify sticking with the payed version of le chat. I'll definitely be back once Mistral gets better though.",
          "score": -3,
          "created_utc": "2026-02-16 14:36:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5p2lrg",
              "author": "-Crash_Override-",
              "text": "Its always an unpopular opinion around here, but this is very much the case.\n\nI had used mistral a good bit maybe a 9-12 mo ago, amd it was ok at the time. I decided to revisit last night and it is many orders of magnitude behind the flagships. I put my T1s as Claude and Gemini, T2s as CGPT and grok, T3s as DS, K2.... mistral feels solidly in a T4 category pushing to get into T3. \n\nIm rooting for it, and theyre doing great things with the budget they have, but its a ways off still.",
              "score": 1,
              "created_utc": "2026-02-16 15:24:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o77g5",
          "author": "Thisismyotheracc420",
          "text": "Good on them, just don‚Äôt forget both of these are private companies, and are not legally obliged to report any (correct) numbers.",
          "score": 0,
          "created_utc": "2026-02-16 12:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7zd3",
          "author": "Many-Ad-3228",
          "text": "Nice",
          "score": 0,
          "created_utc": "2026-02-16 12:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ofufr",
          "author": "jjw_kbh",
          "text": "Love this!\n\n#eutechstack",
          "score": 0,
          "created_utc": "2026-02-16 13:22:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pdzf5",
          "author": "Emotional-Mine-1495",
          "text": "They should go public",
          "score": 0,
          "created_utc": "2026-02-16 16:18:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rncbc",
          "author": "alunare",
          "text": "Let me translate: Mistral is subsidized by Europe. Reality is it is way underpowered compared to its revivals.",
          "score": 0,
          "created_utc": "2026-02-16 22:47:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nw76v",
          "author": "Prior-Task1498",
          "text": "Tbf that's a low bar. Ai gets a lot of investment capital but actual revenue is very low",
          "score": -4,
          "created_utc": "2026-02-16 10:54:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r24g6x",
      "title": "Mistral boss calls for European unity in AI race, as pledges ‚Ç¨1.2bn Swedish data centre investment",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r24g6x/mistral_boss_calls_for_european_unity_in_ai_race/",
      "author": "EzioO14",
      "created_utc": "2026-02-11 17:57:17",
      "score": 409,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "Mistral calls for european unity in AI race and pledges 1.2bn‚Ç¨ in swedish data center.   \n[https://tech.eu/2026/02/11/mistral-boss-calls-for-european-unity-in-ai-race-as-pledges-1-2bn-swedish-data-centre-investment/](https://tech.eu/2026/02/11/mistral-boss-calls-for-european-unity-in-ai-race-as-pledges-1-2bn-swedish-data-centre-investment/)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r24g6x/mistral_boss_calls_for_european_unity_in_ai_race/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o4v8ac6",
          "author": "thegoz",
          "text": "come on Europe, just copy the Chinese model. You have the money and no GPU sanctions.",
          "score": 38,
          "created_utc": "2026-02-11 20:58:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vpbly",
              "author": "noctrex",
              "text": "There where some accusations of actually doing that.\n\n[https://xcancel.com/suchenzang/status/1954973424486608928](https://xcancel.com/suchenzang/status/1954973424486608928)",
              "score": 2,
              "created_utc": "2026-02-11 22:20:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50dm51",
                  "author": "thegoz",
                  "text": "i dont mean the llm model, i meant the business model of aggressive open sourcing to undermine the americans",
                  "score": 3,
                  "created_utc": "2026-02-12 17:01:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4vcf14",
          "author": "Joddie_ATV",
          "text": "They will improve... Just give them a little time! I have faith in Mistral.AI",
          "score": 16,
          "created_utc": "2026-02-11 21:18:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xjq15",
          "author": "clintron_abc",
          "text": "if they follow the EU privacy rules it will be doomed from the start. For AI to work it needs to bend the copyright rules for data ingestion, everyone is doing it.... if you play the good boy you'll remain behind even on open source models",
          "score": 9,
          "created_utc": "2026-02-12 05:01:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o505wj9",
              "author": "Extreme_Run6392",
              "text": "This is only thing that should matter, everything else is noice.",
              "score": 2,
              "created_utc": "2026-02-12 16:25:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4v9sun",
          "author": "crazyserb89",
          "text": "It‚Äôs a shame that EU still doesn‚Äôt have nothing to compete with. I‚Äôm so sad how bad we are sometimes ..",
          "score": -9,
          "created_utc": "2026-02-11 21:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vuphd",
              "author": "OwlSlow1356",
              "text": "predictive statistics needs alot of electricity. did you see the prices of electricity in europe vs china vs usa? add the tonns of enforced laws for breaching copyright vs train your models with terrabytes and terrabytes of torrent data first and deal with eventual problems later vs we do not care how we train the models and how we get the data (china)",
              "score": 4,
              "created_utc": "2026-02-11 22:48:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vzy5k",
                  "author": "crazyserb89",
                  "text": "Yeah another proof how miserable we are in comparison with others",
                  "score": -9,
                  "created_utc": "2026-02-11 23:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ubfzw",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -16,
          "created_utc": "2026-02-11 18:22:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4udnil",
              "author": "SetObvious7411",
              "text": "How do you reckon that's a bad thing if I may ask?\n\nThe way I see it: We Europeans have poured (and still are pouring) a hell of a lot more money into American tech companies than the other way around. It's good to see some of that money coming back.\n\nAs long as Mistral remains European off course",
              "score": 36,
              "created_utc": "2026-02-11 18:32:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4uew9i",
              "author": "EzioO14",
              "text": "I don‚Äôt agree, having American investors doesn‚Äôt make it an American product or anything as long as they stay a minority of investors",
              "score": 15,
              "created_utc": "2026-02-11 18:38:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4uzfma",
              "author": "LegitimateHall4467",
              "text": "It's actually the only European alternative out there...",
              "score": 4,
              "created_utc": "2026-02-11 20:15:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4u82hi",
          "author": "victorc25",
          "text": "Unity with what? Volkswagen? Carrefour?",
          "score": -30,
          "created_utc": "2026-02-11 18:07:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r18nns",
      "title": "What‚Äôs the difference between you and me?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/tq8kl2gfmpig1.jpeg",
      "author": "mifit",
      "created_utc": "2026-02-10 18:23:52",
      "score": 158,
      "num_comments": 25,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r18nns/whats_the_difference_between_you_and_me/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o4nqnkg",
          "author": "[deleted]",
          "text": "EU companies face structural disadvantages that companies in the US and China don't have, lack of common capital market being the most glaring example. I am for Mistral as an EU person but I am not 100% sure that it will succeed.",
          "score": 13,
          "created_utc": "2026-02-10 18:31:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ntj6o",
              "author": "mifit",
              "text": "I don‚Äôt necessarily disagree with you on the structural disadvantages, although I think we sometimes undersell ourselves. However, this post was really just meant as a gentle nod to Anthropic.",
              "score": 6,
              "created_utc": "2026-02-10 18:44:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4numn3",
                  "author": "[deleted]",
                  "text": "Well, I like Claude as a non coder.",
                  "score": 0,
                  "created_utc": "2026-02-10 18:49:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4rreyd",
              "author": "guiriduro",
              "text": "We should be making up for capital market fragmentation by a much larger ECB-backed subsidy and lending programme. What they're doing for Airbus and french farmer/CAP should be a multi trillion, multi industry effort to create subsidues and low interest loans. Sure, the private capital markets have their place, and can collaborate for certain opportunities, but the lending should be focussed on those with expertise, who merely lack capital, which can be printed, frankly.",
              "score": 2,
              "created_utc": "2026-02-11 09:16:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4oclhe",
          "author": "cosimoiaia",
          "text": "Omg, you are SO right! With all the marketing feuds going on now, it would be AWESOME to see Mistral going in. \n\nI'm laughing my pants off just thinking about it. ü§£",
          "score": 9,
          "created_utc": "2026-02-10 20:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qp3lt",
          "author": "CodeBlurred",
          "text": "Souverainet√© | Accessibilit√© | Puissance   \nIt‚Äôs my new motto... and that‚Äôs despite unfortunately holding a US passport.",
          "score": 2,
          "created_utc": "2026-02-11 03:54:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50vbo1",
          "author": "KidNothingtoD0",
          "text": "mistral, honestly you should cheer up to follow up the specs that others has",
          "score": 2,
          "created_utc": "2026-02-12 18:24:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4t39bf",
          "author": "nimbledoor",
          "text": "Mistral is not there yet. I try it from time to time and unfortunately ethical AI is really lacking so far.¬†",
          "score": 1,
          "created_utc": "2026-02-11 14:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tf8zp",
              "author": "mifit",
              "text": "I honestly have a different experience. For 95% of things I do, Mistral is more than sufficient. Awesome, actually. The remaining 5%? We‚Äôll get there, but only if we continue supporting and growing the community.",
              "score": 4,
              "created_utc": "2026-02-11 15:52:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vr6o6",
                  "author": "nimbledoor",
                  "text": "That is not my experience at all. Just yesterday I found out I can‚Äôt attach pictures when doing deep research. The answers are always basic kind of like how ChatGPT was a year ago.",
                  "score": 1,
                  "created_utc": "2026-02-11 22:30:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bf9d5",
          "author": "jjw_kbh",
          "text": "Ditto.\n\nGet in touch with DHH, he's a huge proponent of the EU Tech Sovereignty movement.\n\n\\#eurostack",
          "score": 1,
          "created_utc": "2026-02-14 09:54:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nvuyt",
          "author": "Kathane37",
          "text": "Never ask Mistral where their models are hosted",
          "score": -12,
          "created_utc": "2026-02-10 18:55:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4o323r",
              "author": "Humble_Fig7888",
              "text": "I‚Äôm still surprised by all the fake news and cherry-picking about Mistral‚Äôs servers allegedly hosted in the US",
              "score": 10,
              "created_utc": "2026-02-10 19:28:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4orb4d",
                  "author": "Kathane37",
                  "text": "Cerebas is US based and is activated by default (flash mode), Microsoft Azure is a US company, the server is in sweeden sure but we are still far from a soveraign solution \n\nHere are the sources: https://trust.mistral.ai/",
                  "score": 2,
                  "created_utc": "2026-02-10 21:21:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4olqj9",
              "author": "theKurganDK",
              "text": "Not that difficult a question. They work with Azure and AWS for hosting of their models if YOU should choose to. That is the Open Source models. If you want to. LeChat, the API, is not hosted at AWS or Azure. They are hosted in France.\n\nhttps://venturebeat.com/ai/microsoft-backed-mistral-launches-european-ai-cloud-to-compete-with-aws-and-azure/",
              "score": 2,
              "created_utc": "2026-02-10 20:55:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4oq01b",
                  "author": "Kathane37",
                  "text": "So why when you ask the support about where are the datacenters for the API and for lechat they will give you a vague ¬´¬†european union¬†¬ª and not a proud ¬´ in france mon ami¬†¬ª.\nMistral compute is only available for their top tier client.\n\nBut maybe the documentation is outdated and you will teach me an interesting information https://help.mistral.ai/en/articles/347629-where-do-you-store-my-data-or-my-organization-s-data\n\nEdit: https://trust.mistral.ai/",
                  "score": 1,
                  "created_utc": "2026-02-10 21:15:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r3t4zd",
      "title": "Got any Vibe feature requests for the team?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/67xxcv0bcajg1.gif",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-13 16:05:36",
      "score": 82,
      "num_comments": 50,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3t4zd/got_any_vibe_feature_requests_for_the_team/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o56q39s",
          "author": "AdIllustrious436",
          "text": "What I'd prioritise on the roadmap:\n\n\n- Parallel sub-agent execution ‚Äî coupled with stronger agentic context retrieval prompting in the system prompt to improve codebase discovery without context flooding.\n\n\n- Thread revert/fork ‚Äî ability to roll back to a previous state or branch off into an alternate direction mid-conversation.\n\n\n- Git status integration ‚Äî surface diff stats (+X/‚àíY lines), current branch etc. \n\n\n- Web search integration ‚Äî fetch alone isn't enough; the agent currently has to guess URLs, which fail more often than not. A proper websearch sub-agent with actual query capabilities would let it find relevant sources first, then fetch.\n\n\n- Smarter plan mode ‚Äî Better guidelines in system prompt, auto-clear stale context once a plan is approved, so execution starts with a clean, focused window.",
          "score": 32,
          "created_utc": "2026-02-13 16:19:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58qhtl",
              "author": "nunodonato",
              "text": "Yes, basically copy Claude code üòÖ I vote for all of these features, especially plan and web search",
              "score": 6,
              "created_utc": "2026-02-13 22:12:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56wges",
          "author": "grise_rosee",
          "text": "Sorry for the lake of hype, but as a casual user, I'd prefer bugfixes first:\n\n\\- The TUI is extremely sluggish after a few pages of work history. It's unrelated to the model perfs. I can't be alone having this issue.\n\n\\- The model often doesn't understand that if its editing proposal was canceled, the changes have not been done! Lot of tokens are lost reverting changes that don't exit.\n\n\\- The model makes a plan for its first goal, then mostly leave it unchanged for the whole session, whatever there is a drift in objectives.\n\n\\- The model doesn't know what [AGENTS.md](http://AGENTS.md) is and make fun hallucinations when been asked to write one.\n\n\n\nActual requests:\n\n\\- Vibe could automatically propose to add an [AGENTS.md](http://AGENTS.md) file when missing in a new project.\n\n\\- For heavy refactoring, like adding a parameter to a method, the model only edit change sites once by once, which is very long. Maybe it could be taught to make global search&replace in the whole code base with some new tool: [https://comby.dev/](https://comby.dev/), [https://ast-grep.github.io/](https://ast-grep.github.io/)  fastmod/codmod, [https://github.com/biomejs/gritql](https://github.com/biomejs/gritql), etc. There are many existing tools which attempt to do the work, but no AI players have tried to efficiently leverage them yet.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
          "score": 22,
          "created_utc": "2026-02-13 16:49:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57lfsi",
              "author": "l_eo_",
              "text": "Seconded!\n\nAlthough I have also read that the recent release improved things a lot.\n\nBut this is the most important thing for me as well.  \nIf the whole tool becomes super sluggish and frustrating to use, I can't use it.",
              "score": 3,
              "created_utc": "2026-02-13 18:49:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5net51",
                  "author": "grise_rosee",
                  "text": "Seconds after I made this comment, a new release dropped in my terminal, and the TUI perfs are now fixed. :)",
                  "score": 3,
                  "created_utc": "2026-02-16 08:10:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56wztg",
          "author": "Neither-Bit4321",
          "text": "Can we make it good at non-coding tasks? Everyone at work has started using claude cowork because one of our devs showed claude cowork doing stuff to someone in our legal team who shared it with someone in finance, and before long management decided getting everyone a claude cowork subscription.  \n\nI tried to show that same person how good Vibe is but it was really, really bad on the non-coding stuff we asked it to do :(",
          "score": 7,
          "created_utc": "2026-02-13 16:51:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57mo82",
              "author": "ea_nasir_official_",
              "text": "i think you can put a custom model in it. you can try having it use a locally hosted Gemma 12b or use like mistral medium",
              "score": 1,
              "created_utc": "2026-02-13 18:55:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57e71q",
          "author": "sudoku_coach",
          "text": "Make it work better on Windows.\n\n>The one thing that holds me back is that it doesn't work well on Windows. I keep telling it that I'm on Windows and yet it uses grep and curl and so much stuff that is simply not available. And when it fails, it doesn't make an effort to install these things. It just tells me \"I cannot look up the information currently and will resort to common sense\".\n\n",
          "score": 4,
          "created_utc": "2026-02-13 18:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sy6v",
          "author": "Poudlardo",
          "text": "Integration with spec driven development tools and open standards like OpenSpec or Agent.md would be great !",
          "score": 3,
          "created_utc": "2026-02-13 16:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56uc0p",
              "author": "pandora_s_reddit",
              "text": "Thanks, regarding [AGENTS.md](http://AGENTS.md), we already have some level of support - but only functional when an [AGENTS.md](http://AGENTS.md) file is in the root of the workspace.",
              "score": 3,
              "created_utc": "2026-02-13 16:39:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5714v6",
                  "author": "Poudlardo",
                  "text": "Oh cool then, will check this out thanks\n\nRegarding SDD tools, apart from Openspec, you also have spec-kit. I have been using it in Claude Code already and I'm looking forward to it in Mistral Vibe",
                  "score": 1,
                  "created_utc": "2026-02-13 17:11:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56u65d",
              "author": "AdIllustrious436",
              "text": "Agent.md is supported afaik",
              "score": 1,
              "created_utc": "2026-02-13 16:38:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o56ua9p",
          "author": "hyper_plane",
          "text": "Not a new feature but newline/return still does not work for me, using the VSCode terminal via RemoteSSH extension. Would be great to have that fixed. \n\nI think it would be great if the model itself gave users tips on improving its usage. For instance, suggestions to put some codebase descriptions in a ‚ÄúAGENTS.md‚Äù file, and things like that.",
          "score": 3,
          "created_utc": "2026-02-13 16:39:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56xgtv",
              "author": "AdIllustrious436",
              "text": "Even with ctrl+j ?",
              "score": 1,
              "created_utc": "2026-02-13 16:54:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o58a0xc",
                  "author": "hyper_plane",
                  "text": "Yes, even with that.",
                  "score": 1,
                  "created_utc": "2026-02-13 20:51:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56ronz",
          "author": "theKurganDK",
          "text": "Can I set the agent personality in the configuration like in lechat.? I would like to be able to set how concise it is. Out of the box the output is very verbose.",
          "score": 2,
          "created_utc": "2026-02-13 16:26:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56u562",
              "author": "pandora_s_reddit",
              "text": "Hi ! You can create your own agents, its an available feature, docs: [https://docs.mistral.ai/mistral-vibe/agents-skills](https://docs.mistral.ai/mistral-vibe/agents-skills)\n\n",
              "score": 5,
              "created_utc": "2026-02-13 16:38:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o58nwqd",
                  "author": "Valexico",
                  "text": "The official documentation forget that you can set a custom prompt for custom agent. I had to dig the code to find out (system_prompt_id toml property)",
                  "score": 1,
                  "created_utc": "2026-02-13 21:59:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o573g31",
          "author": "Own_Knowledge_417",
          "text": "Web search",
          "score": 2,
          "created_utc": "2026-02-13 17:23:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57kcoj",
          "author": "whoisyurii",
          "text": "Let us navigate quickly through the input by using ctrl/ cmnd / option buttons! It is boring to navigate only by arrows",
          "score": 2,
          "created_utc": "2026-02-13 18:44:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56u4q6",
          "author": "FancyName_132",
          "text": "More permission granularity that persists between sessions, \"allow bash for this session\" is not granular at all, I want granularity at the command level, and I would like vibe to optionnaly remember what I allowed it to do.\n\nLess read and write failures, I don't know how to explain that but I feel like it fails a lot compared to other tools",
          "score": 1,
          "created_utc": "2026-02-13 16:38:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o576232",
          "author": "Nervous-Pin9297",
          "text": "I like that it shares the same interface as Claude Code, but I did wish it didn‚Äôt.",
          "score": 1,
          "created_utc": "2026-02-13 17:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o579tfc",
          "author": "andriatz",
          "text": "I'm using Vibe to organize my notes in Obsidian. They're messy lots of markdown files in different folders. I'm trying to sort them automatically, and Vibe is a big help, but it's a long process. It would be great if I could save a session so I can pick up where I left off.",
          "score": 1,
          "created_utc": "2026-02-13 17:54:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59abkc",
              "author": "Ark_Anoryn",
              "text": "Vibe --continue\nWill start your latest session\n\nVibe --resume <sessionId>\nWill resume said session\n\nBoth options are shown by vibe when you quit it (CTRL+D) ^^\n\n\nYou can find your sessions in <vibeconfig>/logs\nIf I remember correctly\n\nWith vibe 2.1.0 it does not take 2 hours to load anymore big session\n\nHope that helps",
              "score": 3,
              "created_utc": "2026-02-14 00:05:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o57gjbl",
          "author": "PayDistinct5329",
          "text": "\\- Parallel sub-agent execution (as also mentioned by others)  \n\\- Option to also capture sub agent \"sessions\" to more easily inspect what has happened (right now when inspecting sessions .json files I can only see messages and information regarding the main agent)  \nCan't think of anything else right now, but it would be cool to have a repo of tools that can be easily used (like enhanced web search etc.) or better documentation to inherit from the tools (can't remember the name name) that allows you to insert your own custom tools executed via Python to avoid using MCP.  \n",
          "score": 1,
          "created_utc": "2026-02-13 18:25:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57txf5",
          "author": "Comacdo",
          "text": "I feel so idiotic about this but if you ask I'll try : what about an hyper-extra-super-easy-to-use interface ? Like an all in one built-in casual friendly UI ?\n\nAnyway, thanks a lot for all your hard work üôè",
          "score": 1,
          "created_utc": "2026-02-13 19:30:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5832yd",
          "author": "lovebzz",
          "text": "Non-coding tasks (and models trained for those) please. Yes, I know we can include other models in Vibe, but why not include those in the menu by default?",
          "score": 1,
          "created_utc": "2026-02-13 20:16:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o583bno",
          "author": "feral_user_",
          "text": "\\- Better history - perhaps a list of previous sessions\n\n\\- It would be nice to know if there's other open source models that work well with Vibe too (GLM, Minimax, etc?)",
          "score": 1,
          "created_utc": "2026-02-13 20:17:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o586b2x",
          "author": "crazyfuffi",
          "text": "connect to remote servers via ssh and vibe there.",
          "score": 1,
          "created_utc": "2026-02-13 20:32:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o587tag",
          "author": "jjw_kbh",
          "text": "Hooks: support for running commands, or prompts, on SessionStart, PreCompaction, and SessionEnd exactly like Claude Code and Gemini do. I suppose some would like to see the other events supported too, but those are the too three use cases I see.",
          "score": 1,
          "created_utc": "2026-02-13 20:39:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o588yjh",
          "author": "jjw_kbh",
          "text": "settings.json: Gemini is emulated CC in this regard and it would be nice to see some parity in Vibe‚Äôs support. Its also a more correct modelling, since settings are user-centric and configuration is system level and the domain those who deploy the application.",
          "score": 1,
          "created_utc": "2026-02-13 20:45:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o589kxj",
          "author": "jjw_kbh",
          "text": ".agents/: Reading skills and agent definitions from an .agents folder at the root would be a huge (and necessary) leap forward in standardizing configuration these common features. This would be a big win for users and lower the threshold to switching between agent harnesses. You have a golden opportunity to set the standard here üèÜ",
          "score": 1,
          "created_utc": "2026-02-13 20:48:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58aqba",
          "author": "RepresentativeTill5",
          "text": "-Some elaboration of the documentation!\nThe code shows I can just pipe input and output to vibe, but it isn't documented.\nHow would this work with slash commands for example, would they be parsed correctly? Same for !-commands.\n- being able to dump the context locally, (while piping?) so as to debug it or re-use it for testing and prompt tweaking.\n\nI want to Ralph-Wiggum vibe, hence the questions üòÅ",
          "score": 1,
          "created_utc": "2026-02-13 20:54:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58ek6n",
          "author": "FrankieSolemouth",
          "text": "switch off of python and maybe use ratatui? the cli is super sluggish and feels awful ",
          "score": 1,
          "created_utc": "2026-02-13 21:13:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58kb83",
          "author": "kiwibonga",
          "text": "1. The 30s timeout when running a subprocess often takes me by surprise. I ask Vibe to wait while I run the program/test in another window instead of entrusting it with long running commands. This could be tuned per-session, in the config...\n\n2. Would be nice to have a runtime debugging mode where vibe can run subprocesses, and upon user request, obtain information (like stdout or a logfile), send input to the app, answer prompts about the current state of the app, attach a debugger, close the app...",
          "score": 1,
          "created_utc": "2026-02-13 21:41:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58nhq7",
          "author": "Valexico",
          "text": "I feel we are missing some serious prompt engineering.¬†\n\n\nThe default system prompt is note very elaborated.\nWhen creating agents i found out complete tool instruction are concatenated (even tool disabled for the current agent)\n\n\nIt is also unclear how subagents returns results to the main agent (i think they return the complete execution process instead of just a final analysis)\n\n\nI did try to rebuild the Claude Code plan behaviour (explore, plan, finalize plan) but i was not very successful. I am not sure if this is because the model does not follow instruction well or because the built in prompt engineering is missing.\n\n\nPlan mode with devstral in opencode for example is more efficient",
          "score": 1,
          "created_utc": "2026-02-13 21:57:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58qbx0",
          "author": "nunodonato",
          "text": "The thing holding our team back is lack of (good) support for md files and skills. Make this work, improve the sys prompt to make sure they are used. This alone can open so many doors without having to code new features for vibe",
          "score": 1,
          "created_utc": "2026-02-13 22:11:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58wstf",
          "author": "Timo425",
          "text": "I think the main strength of agentic coding tools is the planning mode - its much more important to cooperatively plan with the model the exact step by step plan for whatever you are trying to do than to actually do the coding.\n\nBest case is to make a plan with a more expensive high end model and then offload the actual coding to a more cost effective model, so it would be great if Vibe had the option to do that.\n\n",
          "score": 1,
          "created_utc": "2026-02-13 22:45:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ay31n",
          "author": "porzione",
          "text": "Please, add Large and Medium to Vibe too - they are better for writing and creative than Devstral. ",
          "score": 1,
          "created_utc": "2026-02-14 07:07:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ceiaw",
              "author": "Odd-Criticism1534",
              "text": "You can add them with an api token via the config.toml",
              "score": 2,
              "created_utc": "2026-02-14 14:31:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cvnng",
                  "author": "porzione",
                  "text": "Really? Interesting, I'll try",
                  "score": 1,
                  "created_utc": "2026-02-14 16:03:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bltvh",
          "author": "zdravkovk",
          "text": "vscode integration",
          "score": 1,
          "created_utc": "2026-02-14 10:58:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jpgcl",
          "author": "trougnouf",
          "text": "Mistral Vibe in Zed often has a very hard time modifying a file. I often use the Zed Agent with your model and it seems to work better (though it still struggles sometimes). Sometimes it gets desperated and ends up making complex python scripts to modify a file...\n\nFixing that would make it pretty much perfect. I love the speed of it so I could surely get more done.\n\nedit: not posting on and linking to twitter/x would also be greatly appreciated.",
          "score": 1,
          "created_utc": "2026-02-15 18:18:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56sit9",
          "author": "EzioO14",
          "text": "Something that competes with opus ?",
          "score": -2,
          "created_utc": "2026-02-13 16:30:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57y9i3",
              "author": "Equal-Wall9006",
              "text": "This. I‚Äôd love to move away from anthropic",
              "score": 2,
              "created_utc": "2026-02-13 19:52:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o57yhru",
                  "author": "EzioO14",
                  "text": "Same!!!",
                  "score": 1,
                  "created_utc": "2026-02-13 19:53:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56sbtg",
          "author": "Mattdeftromor",
          "text": "A good model ? oops...",
          "score": -10,
          "created_utc": "2026-02-13 16:29:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4qbl4",
      "title": "Le Chat Has a Big Problem",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r4qbl4/le_chat_has_a_big_problem/",
      "author": "crazyserb89",
      "created_utc": "2026-02-14 17:22:24",
      "score": 72,
      "num_comments": 29,
      "upvote_ratio": 0.82,
      "text": "https://preview.redd.it/3f0qewue4ijg1.jpg?width=194&format=pjpg&auto=webp&s=d0787ef78051dfabc39391f7deeb4711f217ee5f\n\nI want to share my experience with others who might be considering switching from another AI to this one, so they can adjust their expectations in advance and not end up as frustrated as I am.\n\nI also hope someone from the development team sees this post and takes steps to fix the things that are far from good.\n\nI won‚Äôt drag this out too much, but to give you some background: about two weeks ago, I started using Le Chat‚Äôs free version occasionally, hoping I could eventually switch from ChatGPT Plus, which I‚Äôve been paying for for about a year. I liked the agent and library options, and of course, the UI, which is genuinely well designed. I noticed along the way that it‚Äôs not on par with ChatGPT when it comes to generating images, videos, or live AI conversations, and that my native language (Serbian) is significantly less well adapted. However, on the other hand, I appreciated the agent options, the library, and the flexibility of customization and optimization. For my use cases where I use AI 80% of the time for interpreting and organizing emails, translating texts from one language to another, web searches, and similar tasks I realized that for a much more affordable price, I could get a similar experience to ChatGPT for my needs.\n\nYesterday, I decided to pay for the annual Pro subscription and cancel my ChatGPT subscription.\n\nToday, I already feel like I made a mistake and regret that decision.\n\nHere‚Äôs why:\n\nIntelligence (Beta): In my humble opinion, it doesn‚Äôt even deserve to be called an Alpha version.\n\n1. Memories: Simply put, they don‚Äôt work. I‚Äôve tried everything adding my own memories in English, in Serbian, letting Le Chat add them based on our conversations and nothing. In every new chat, it‚Äôs as if it doesn‚Äôt take a single memory into account.\n\nExample: As a joke today, I tried that challenge where people mocked ChatGPT for giving the wrong answer to the question, \"If I need to wash my car and the car wash is 200 meters away, should I go by car or on foot?\" ChatGPT always said to go on foot, while Claude gave the correct answer that you have to go by car because it understood the context. I tried it in Le Chat, and of course, it failed just like ChatGPT did, even after multiple attempts and using thinking mode.\n\nThis isn‚Äôt even my biggest problem, although one of the first memories I set was that Le Chat should always think carefully and verify all circumstances and sources before giving an answer, as accuracy takes priority over speed. I also specified that it should always respond to me in the same language I write in (Serbian) during casual communication and never use em dashes. The result? Out of 10 new chats where I asked the same question about the car and the car wash, I got 10 wrong answers, mixed with Serbian and Croatian, and responses full of em dashes. Because of my frustrated replies, Le Chat kept adding new memories that it should never use Croatian words or em dashes (there are now about five memories for each issue), and yet, in every new conversation, it keeps making the same mistakes it doesn‚Äôt understand the context, mixes languages, and uses em dashes.\n\n2. Connectors: Currently, only Gmail has any value for my use case, but unfortunately, it doesn‚Äôt work well. It can‚Äôt search through email threads, suggest a recipient‚Äôs email in drafts even though it‚Äôs in the emails, or directly create a template that can be automatically forwarded to Gmail.\n\n3. Libraries: On the surface, this seems like a very useful feature that could replace NotebookLM for me, but it‚Äôs often ignored in responses. The agent quickly scans the library and gives a quick answer without tying the context of the question to the library or finding relevant connections.\n\n4. Instructions: I‚Äôve already mentioned how memories are simply bypassed in most cases, and the same goes for the instructions I set at the very beginning. As I also said, one of the first instructions was that it should always take the time to analyze the question and provide the most accurate answer, no matter how long it takes. Yet, I keep getting hasty and incorrect responses.\n\nExample: I asked for the average price of a specific car model in Serbia, and it kept giving me a price that was double the actual amount. I kept challenging it, knowing it was wrong not by 1,000 euros, but instead of around 6,000 euros, it kept giving me a figure of 12,000 euros, without ever providing a concrete link or links where it found those prices. After about 10 exchanges, it still couldn‚Äôt give me a single link, it just kept hallucinating and making up numbers. Then I sent it a link I found for such a car priced at around 6,000 euros, and it replied that the link didn‚Äôt show the price or mileage (even though everything was clearly visible on the link).\n\nAll of this tells me that Mistral‚Äôs Le Chat project is primarily focused on providing a good interface for developers and coding, where things are fairly clear and logical, and response speed is most valued. Unfortunately, this severely undermines the versatility that Le Chat promotes, because in the pursuit of speed, it completely disregards all instructions and tools from Intelligence.\n\nAs a result, we have an effectively unfinished and unreliable product that‚Äôs very difficult to rely on for daily needs, especially since the AI is marketed and promoted as something that can replace all everyday operations but clearly, it‚Äôs not adapted for that.\n\nI sincerely hope someone from the Mistral team sees this post and responds by enabling Le Chat to process and respect instructions from Intelligence. If necessary, there should be a switch or option to directly instruct the AI to always strictly follow instructions and go through memories, even if it means slower response generation.\n\nOtherwise, this will forever remain a project that will never come close to the big competitors from the US and China.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r4qbl4/le_chat_has_a_big_problem/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5doef0",
          "author": "Spliuni",
          "text": "For me, the memories and agent instructions work as intended 95% of the time. The only thing that annoys me is the overzealous saving of new memories.",
          "score": 32,
          "created_utc": "2026-02-14 18:27:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ejpyq",
              "author": "cosimoiaia",
              "text": "I agree, that seems to be something they definitely have to work on.\n\nRight now it seems that it rewrites the memories in one chunk and add them as new but it's not super good at that so it also keeps the old memories so nothing gets lost.\n\nThe memory consolidation process should have multiple steps in my opinion, so it could rewrite them in a more context efficient way, preserve timelines and remove duplicates. It can be a resource expensive process if done wrong but by looking at the work going on with vibe, it seems that they are going in the right direction, imo.",
              "score": 3,
              "created_utc": "2026-02-14 21:12:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5e8h0x",
          "author": "Little_Protection434",
          "text": "Is there a way to contact Mistral team directly, so we can give it concrete feedback directly?",
          "score": 9,
          "created_utc": "2026-02-14 20:11:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ebgly",
              "author": "Nefhis",
              "text": "You're already doing it, actually üòâ\n\nhttps://preview.redd.it/6aj07o81sijg1.png?width=1032&format=png&auto=webp&s=ba2c6affadcb06c9efea6fde2f8baabdf00ac851\n\n",
              "score": 17,
              "created_utc": "2026-02-14 20:27:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eavr3",
              "author": "crazyserb89",
              "text": "Yes there is and I did. Let‚Äôs see if it will change something..",
              "score": 5,
              "created_utc": "2026-02-14 20:24:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ebie5",
                  "author": "Little_Protection434",
                  "text": "Nice! Would you mind sharing the way you did it?",
                  "score": 2,
                  "created_utc": "2026-02-14 20:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5dgl45",
          "author": "Dry-Section2788",
          "text": "The memory feature is bad. I am trying to lose weight and use Le Chat to count calories and it forgets recipes I put in and the macros all the time. And god forbid I adjust the recipe and try to change the saved recipe with new macros it‚Äôll just randomly revert back.¬†",
          "score": 14,
          "created_utc": "2026-02-14 17:48:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ehx45",
              "author": "obadacharif",
              "text": "I suggest managing memory on your own by using tools like¬†[Windo](http://trywindo.com/), it's a portable AI memory, it allows you to use the same memory across models. No need to re-explain yourself.¬†\n\nPS: Im involved with the project",
              "score": 3,
              "created_utc": "2026-02-14 21:02:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5hjuod",
                  "author": "Amorphous-Rogue",
                  "text": "Ah Windo I was looking for something like this is was getting to build it myself! Great name btw!",
                  "score": 3,
                  "created_utc": "2026-02-15 10:28:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5u6ou5",
                  "author": "troyvit",
                  "text": "What's your privacy policy? How  do you hold and process all the data users add to Windo? Is it all local  until you interface with an LLM provider? That would be pretty cool. ",
                  "score": 1,
                  "created_utc": "2026-02-17 09:22:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5fxrza",
                  "author": "Dry-Section2788",
                  "text": "I‚Äôll check it out. Thanks!",
                  "score": 1,
                  "created_utc": "2026-02-15 02:15:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ei7zg",
          "author": "cosimoiaia",
          "text": "In my family we have several LeChat accounts.\n\nWe use it in 3 different languages. \n\nIt is renown for the great instruction following, which we can confirm. Creating different agents is literally like talking to different personalities, you can tell it's Mistral only for it's warm, friendly and almost emphatic tone, which none of the other AI have.\n\nThe memories works wonders for us, it's able to connect the dots between different things of the past and even take initiative in the convos based on them. It has now a lot of memories that go back 6 months and I can really really say that it knows me quite well.\n\nThe libraries are also rock solid, I have a bunch of documents that I want it to use as knowledge base in a specific agent, it never failed once so far.\n\nLeChat itself got a lot of improvement lately, for instance it double check what it's saying searching the web and when sometimes gets it wrong it immediately apologize and tries to correct itself.\n\nI would in fact say that it's greatest strength are the tone, the instructions following, the memories and the fact that is not full of propaganda.\n\nIt still got a lot to improve for sure, but it's a great platform that can only get better, in my experience.\n\nIf LeChat doesn't work in your specific language, maybe say that next time. Saying nothing works is just wrong and bad feedback. Imo.",
          "score": 8,
          "created_utc": "2026-02-14 21:04:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5oveym",
          "author": "Moetorhead",
          "text": "Not the main topic but I tried out the car wash prompt in Thinking and it delivered the following message:\n\nTo wash your car at the car wash, you would need to drive your car there. Walking wouldn't allow you to wash your car since it wouldn't be at the car wash. Therefore, you should use your car to get there.\n\nBut 200 meters is a very short distance. If you're considering whether to drive or walk to the car wash location itself (for example, to check it out), then walking is reasonable. But if you're planning to wash your car, you'll need to drive it to the car wash.\n\nCould you clarify whether you're asking about how to get to the car wash location or how to get your car there to wash it?\n\nIf you're with your car and need to wash it, then driving to the car wash is the way to go. If you're just going to the car wash location without your car, then walking is fine given the short distance.\n\n-> apparently Mistral can deal with the type of question",
          "score": 3,
          "created_utc": "2026-02-16 14:47:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5p7pxp",
              "author": "crazyserb89",
              "text": "In my case it didn‚Äôt work together with thinking mode. Maybe they fixed it in the meantime.",
              "score": 2,
              "created_utc": "2026-02-16 15:48:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ujk25",
          "author": "Sveddan84",
          "text": "I'm mainly annoyed about it referring to memories when they make no sense. Mixing up projects I have going. Even if I explicitly prompt it to not assume a new question is part of an existing project and not to use memories it still drags those things in.\n\nGiving answers like\n\"This is very fitting in your xxx project because...\"\n\"Since you are xxx and yyy... \".\n\nI just want a straight answet to a simple question unrelated to anything else but it start to explain who I am (again and again). Extremely annoying.\nI know who I am. Shut up.",
          "score": 2,
          "created_utc": "2026-02-17 11:20:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dwt9o",
          "author": "Low88M",
          "text": "Exactly what I experienced with Lechat‚Ä¶ no memory service, or very badly implemented Memory layer, nothing as transversal as in ChatGPT. I bet nowadays a well rounded ecosystem of services around models are gonna be more important than models themselves. I‚Äôd like to come to Mistral as much as I hate OpenAI, but not in this state‚Ä¶",
          "score": 5,
          "created_utc": "2026-02-14 19:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hzaw6",
              "author": "FBC-22A",
              "text": "Same. I started hating OpenAI and ChatGPT ever since model 5 launched as it tries to overtly sanitise everything. Hell, even my rants about infrastructure in general gets \"Let's ground this first....\" yada yada yada bullshit.\n\nLike, I want ChatGPT to be my intellectual sparring partner, not just replying in some sentences, and then spend the rest of its reply with \"grounding\" things. Feels like talking to corporate HR",
              "score": 2,
              "created_utc": "2026-02-15 12:45:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5dmtrs",
          "author": "SMIIIJJJ",
          "text": "I just started using it to try to get away from ChatGPT too and am also disappointed with the memory. I‚Äôm not sure it‚Äôs very functional for me as is.",
          "score": 3,
          "created_utc": "2026-02-14 18:19:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gdlz1",
          "author": "cichelle",
          "text": "I find that Le Chat uses memories very well and I would not want to lose that feature. That being said, after every conversation, I go into the memories to see what was saved there and change or correct it, if needed. Once in a while there's hallucination saved to memory or simply something that's worded oddly. Fortunately, it's possible to write to and edit the memories. As long as I keep an eye on it, I find it to be very good. But it's possible to toggle it off, if preferred.",
          "score": 2,
          "created_utc": "2026-02-15 04:07:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hhdgi",
          "author": "Born-Yoghurt-401",
          "text": "I use the free version all the time and it corrected some grave errors that Deepseek had produced. I‚Äòm happy with LeChat.",
          "score": 1,
          "created_utc": "2026-02-15 10:04:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qqev4",
          "author": "ziplin19",
          "text": "People who say that LeChat's memory works well must have never really used it. It can't recollect the most simple instructions like not using em dash. I'm currently on annual pro subscription but i'm not satisfied with LeChat.",
          "score": 1,
          "created_utc": "2026-02-16 20:03:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5imw1t",
          "author": "PalpitationOwn396",
          "text": "For me with the last models none reasoning works better.",
          "score": 0,
          "created_utc": "2026-02-15 15:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dxhet",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -11,
          "created_utc": "2026-02-14 19:13:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e5xh2",
              "author": "Spliuni",
              "text": "Thats rude o.o",
              "score": 2,
              "created_utc": "2026-02-14 19:57:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5efkhs",
                  "author": "[deleted]",
                  "text": "[deleted]",
                  "score": 1,
                  "created_utc": "2026-02-14 20:49:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r3t6cf",
      "title": "Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation",
      "subreddit": "MistralAI",
      "url": "https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
      "author": "guyfromwhitechicks",
      "created_utc": "2026-02-13 16:06:59",
      "score": 65,
      "num_comments": 19,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3t6cf/anthropic_raises_30_billion_in_series_g_funding/",
      "domain": "anthropic.com",
      "is_self": false,
      "comments": [
        {
          "id": "o56o0mp",
          "author": "guyfromwhitechicks",
          "text": "I don't see how Mistral is suppose to compete with this. It is obvious that european companies struggle a lot to raise even similar funding to that of american companies, so Mistral resorted to making highly cost effective models. Which has worked for a long while, but I don't see how they can keep this up with this amount of investing.\n\nAny thoughts on what they can do?",
          "score": 29,
          "created_utc": "2026-02-13 16:09:28",
          "is_submitter": true,
          "replies": [
            {
              "id": "o56tc0c",
              "author": "FancyName_132",
              "text": "Due to the current political climate many EU companies try to avoid US services when possible. If the political climate doesn't change being one of, if not The most credible EU options is enough for them to succeed. If they manage to provide at least decent services and not mess it up with dumb decisions they have a strong edge for EU minded companies.",
              "score": 19,
              "created_utc": "2026-02-13 16:34:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56xjp1",
                  "author": "guyfromwhitechicks",
                  "text": "I am more concerned about them not creating alternatives that make you go \"yeah, I can see myself using this instead of Claude\". And as things are, I can't see myself telling other software engineers to use Devstral over Opus, or mistral-vibe over claude-code for example (and I pay for Le Chat Pro). I am also, willing to bet there are a lot of engineers in europe who think the same and will not switch just on pride or worries of intellectual autonomy.\n\nMy point is, the gap is widening, a lot. And making just decent alternatives will not be enough I fear.",
                  "score": 4,
                  "created_utc": "2026-02-13 16:54:26",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56xuk1",
              "author": "InsideMikesWorld",
              "text": "I think, their advantage is that they are not overhyped.\n\nAt a 380B$ valuation, investors wanna see a rather high return on investment rather sooner than later. Problem is, none of these companies have figured out how to make huge amounts money from AI. Mistral models are cheaper, their investments are lower, and all in all Mistral has higher chances of longterm sustainable growth compared to other AI companies.",
              "score": 9,
              "created_utc": "2026-02-13 16:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56z6j7",
                  "author": "guyfromwhitechicks",
                  "text": "I see their biggest advantage being the high cost of RAM and AI specific chips. Meaning, Mistral's funding is so much smaller than the american companies' that the shortage has caused all other competitors to slow down. Or not, I don't have access to their internal reports.",
                  "score": 2,
                  "created_utc": "2026-02-13 17:02:20",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o5mer9d",
                  "author": "Doombqr",
                  "text": "One of their main advantages is that for sensitive data EU doesn't want to build using American tech.\nIt is already the case for governmental agencies not using AWS or Azure but instead smaller European cloud providers.\nOf course they are way behind in terms of features available but sovereignty is more important.\n\nAI is also already used in a lot of military areas.",
                  "score": 1,
                  "created_utc": "2026-02-16 03:20:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56vv86",
              "author": "henrijn",
              "text": "**Focus on business integration.** This is exactly what they are doing. Google, Anthropic, and OpenAI are looking for massive, scalable revenue to justify the investments they are making. This is why they are selling generic API keys or products, since these can scale quickly to tens of billions. \n\nHowever, many businesses are not looking for the best model, but rather the best integration with their data, privacy, sometimes requiring fine-tuning and custom solutions. This is very demanding in terms of human resources, as it means dealing with customers one-by-one and sending engineers to design their specific solutions. This is why big US companies avoid this, therefore Mistral is in a blue ocean by pursuing it. For sure, this business will not scale to $100B in revenue within three years (which is what the US companies want), but it can become a successful multi-billion dollar business and once a client has a deep integration, the churn rate will be very low, even if the model is slightly behind the current SOTA.",
              "score": 2,
              "created_utc": "2026-02-13 16:46:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58ltrj",
              "author": "Neomadra2",
              "text": "I am not worried at all. Even though Anthropic might have the best model now, they are only half a year or so ahead.  Mistral being so close to the state of the art for a fraction of the cost is really impressive and it means that they have an edge in commercialisation their models cost effectively, as they don't need 30 billions or more just for research purposes. And the other reason is obviously that Europe will surely support Mistral as most leaders have realised it's their only horse in the AI race.",
              "score": 2,
              "created_utc": "2026-02-13 21:49:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58e46c",
              "author": "Sf-ng",
              "text": "I think cost efficiency matters a great deal when it comes to commercial applications such as coding and process automation.",
              "score": 1,
              "created_utc": "2026-02-13 21:11:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5h5gz2",
              "author": "Jujubatron",
              "text": "Well definitely not taxing unrealized gains 36% like the Dutch are about to do. That may be a good first step.",
              "score": 1,
              "created_utc": "2026-02-15 08:09:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o59uvkt",
          "author": "heyinternetman",
          "text": "The issue is 6 months ago I felt mistral was on par with the others. It now feels years behind. Even in just writing an email with the right tone.  Claude beats it hands down. And that‚Äôs unfortunate because I‚Äôd rather use mistral.",
          "score": 6,
          "created_utc": "2026-02-14 02:12:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5azaab",
              "author": "ComeOnIWantUsername",
              "text": "I still use Mistral and will do it, but I totally agree. They are accelarating and pushing new features, models and products way faster than Mistral",
              "score": 1,
              "created_utc": "2026-02-14 07:19:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5aqo51",
          "author": "Full-Discussion3745",
          "text": "And still open source Kimi 2.5k kicks their ass",
          "score": 3,
          "created_utc": "2026-02-14 06:01:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57ntoo",
          "author": "nycigo",
          "text": "Mistral received 104 billion in investment at the start of the AI ‚Äã‚Äãera, then nothing more.",
          "score": 1,
          "created_utc": "2026-02-13 19:00:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o586oq7",
              "author": "EveYogaTech",
              "text": "Quick tip: The difference between a million and a billion is about a billion.",
              "score": 6,
              "created_utc": "2026-02-13 20:34:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o57u1h5",
              "author": "guyfromwhitechicks",
              "text": "Not exactly true: https://en.wikipedia.org/wiki/Mistral_AI. See Funding.",
              "score": 1,
              "created_utc": "2026-02-13 19:31:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h1ba8",
          "author": "therealslimshady1234",
          "text": "30 billion which will go up in smoke",
          "score": 0,
          "created_utc": "2026-02-15 07:28:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r45795",
      "title": "Dug into the Vibe v2.1.0 source code, found some unreleased stuff (big spoiler)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r45795/dug_into_the_vibe_v210_source_code_found_some/",
      "author": "AdIllustrious436",
      "created_utc": "2026-02-13 23:52:49",
      "score": 63,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "Was going through Vibe [v2.1.0 diff](https://github.com/mistralai/mistral-vibe/compare/v2.0.2...v2.1.0) out of curiosity and found a bunch of code that's not mentioned anywhere in the changelog.\n\n\n\n*Disclaimer: this is all from reading public source code, nothing confirmed by Mistral, everything behind disabled feature flags. If the team would rather I didn't share, happy to take it down.*\n\n\n\nThere's a hidden `/teleport` command that packages your entire Vibe session and sends it to something called \"Mistral Nuage.\" The config points to a staging domain, and the TODOs in the code say things like \"remove once the feature is publicly available.\" So it's not ready yet, but it's coming.\n\n\n\nThe part that got me interested is a fully implemented but commented-out method called `create_le_chat_thread()`. Rather than landing on some internal console, your teleported session would open as a Le Chat conversation with a cloud sandbox attached to your repo. So basically, \n\n\n**Vibe is coming to Le Chat**.\n\n\n\nRight now Vibe is terminal-only. What Mistral is building is a web coding agent inside Le Chat, backed by cloud environments that can clone your repos and apply your local changes. You'll be able to start a task in your terminal and pick it up in the browser, or the other way around, without losing any context. The upcoming underlying platform, Mistral Nuage, handles all of it: spinning up environments, running workflows, managing the back and forth. It's a new product entirely.\n\n\n\nLe Chat already has MCP connectors, so it can interact with external services. But it still needs you in the loop, watching it, prompting it. What Nuage would change is that Le Chat could go off on its own. Spin up a sandbox, clone your repo, work through a task, push code, all without you sitting there. It goes from an assistant that can use tools when you ask, to an agent that can take a job and run with it in the background, having automated daily routines, pre-programmed tasks, auto-trigger (receiving an email etc.). It basically shifts the paradigm from synchronous to asynchronous (= Le Chat can work when you sleep aha).  And the workflow system seems rather generic, GitHub is just the first connector. There's room for email, project management, CI, whatever.\n\n\n\nEverything on the Vibe side looks done and well-tested, so they're probably finalizing the infrastructure and the web interface. Wouldn't be surprised to see this in the next few weeks.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r45795/dug_into_the_vibe_v210_source_code_found_some/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o59h50d",
          "author": "cosimoiaia",
          "text": "I can see where this is going and... I like it. \n\nSomething like this done *properly* is what's should be next. Strong workflow foundations with an engine that doesn't burn tokens like it's a coal furnace. Mistral's models have already great personalizations and with a sandbox-first approach it can be a real agent that doesn't work for you without being a ... \"click bait machine\".\n\nIf they call it something like \"Vision\", at least internally, I would literally lose my mind ü§£ (or even \"butter\", if you know what I mean...)\n\nps. I saw the diff but didn't had the time to dig through, thank you for doing it!",
          "score": 6,
          "created_utc": "2026-02-14 00:45:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7q9g",
          "author": "pcx_wave",
          "text": "So sort of Mistral's own openclaw ? I'd root for that",
          "score": 1,
          "created_utc": "2026-02-16 12:28:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2xg4x",
      "title": "jump to Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r2xg4x/jump_to_mistral/",
      "author": "VsokolovVic",
      "created_utc": "2026-02-12 16:08:03",
      "score": 34,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "Hello all,\n\nHope you are doing good! \n\nSo a little context: \n\nI am currently using Claude and Gemini pro versions, I mainly use Gemini pro for the antigravity IDE for my business and Claude assists. Lately Gemini has felt a little more stale (gives reports on the wrong topics, Gems outputs are vague and they hallucinate a lot, etc.) \n\nI am thinking of changing the Gemini chat with mistral, I used mistral in the past, but it wasn‚Äôt the best experience.\n\nWhat is the state of Mistral currently? Is it on par with Gemini? \n\nI am grateful for your perspectives and insights! ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r2xg4x/jump_to_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o509x3d",
          "author": "Kedf47",
          "text": "Hi,\n\nYou can check out¬†[artificialanalysis.ai](https://artificialanalysis.ai/)¬†for the latest updates. I‚Äôm currently using¬†Devstral 2¬†with my¬†Vibe key (pro plan through work) in OpenCode/oh-my-opencode ... it‚Äôs fine, but honestly, with new SOTA models dropping every 2-3 weeks, Mistral feels way behind now.",
          "score": 6,
          "created_utc": "2026-02-12 16:44:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o517cgc",
              "author": "Jbpin",
              "text": "Still fix an issue with SELinux I work on for 2 intensive hours with claude code (burning my entire Max hourly quota), in 5 min ! Each model have there up and down I guess",
              "score": 1,
              "created_utc": "2026-02-12 19:20:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51g5op",
          "author": "thedisturbedflask",
          "text": "It's good, each model very much has their quirks that you learn as you go but it's solid.\n\n\nYou mentioned antigravity so i assume it's software development? If so devstral 2 is good, i use it alongside glm 5. Id suggest set up a few tests between providers and see how you like the output to better decide.",
          "score": 3,
          "created_utc": "2026-02-12 20:03:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52gurr",
              "author": "achton",
              "text": "How do you choose between the two models? And do you use their vibe CLI?",
              "score": 1,
              "created_utc": "2026-02-12 23:02:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53whuj",
                  "author": "thedisturbedflask",
                  "text": "The vibe cli is good, i use it as an agent in zed.dev then with glm as a provider under the default zed agent so your able to switch between them in zeds chat.\n\n\nIn vs code ive been using opencode cli and extension with glm and mistral registered as providers to switch between them.¬†\n\n\nIn vscode you can also use something like cline, kilo code, etc to juggle multiple providers.",
                  "score": 1,
                  "created_utc": "2026-02-13 04:16:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r64ui2",
      "title": "From HackerNews : I want to wash my car. The car wash is 50 meters away. Should I walk or drive?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r64ui2/from_hackernews_i_want_to_wash_my_car_the_car/",
      "author": "Poudlardo",
      "created_utc": "2026-02-16 09:08:35",
      "score": 31,
      "num_comments": 34,
      "upvote_ratio": 0.84,
      "text": "[A Mistral screenshot from the original mastodon post below](https://preview.redd.it/3rou01zbotjg1.png?width=1672&format=png&auto=webp&s=2e42cee0763a66e77d3a77caddec43886ce8f8f2)\n\nSources :  \n[https://news.ycombinator.com/item?id=47031580](https://news.ycombinator.com/item?id=47031580)   \n[https://mastodon.world/@knowmadd/116072773118828295](https://mastodon.world/@knowmadd/116072773118828295)\n\nNone of the reasonning models chose to respond \"Drive\"",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r64ui2/from_hackernews_i_want_to_wash_my_car_the_car/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5nnit4",
          "author": "MimosaTen",
          "text": "It seems I got answered correctly\n\nhttps://preview.redd.it/hwxjfej5ttjg1.jpeg?width=750&format=pjpg&auto=webp&s=64d509f13667cd9c5cb5358b6fdea1c672045464",
          "score": 26,
          "created_utc": "2026-02-16 09:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5noljl",
              "author": "t0m4_87",
              "text": "Thats the problem with AI, it‚Äôs not deterministic.",
              "score": 22,
              "created_utc": "2026-02-16 09:43:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5w22b0",
                  "author": "Junkererer",
                  "text": "People aren't either",
                  "score": 1,
                  "created_utc": "2026-02-17 16:34:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5v5i59",
              "author": "Substantial_Job405",
              "text": "Sure.",
              "score": 1,
              "created_utc": "2026-02-17 13:48:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5np0hw",
          "author": "anzzax",
          "text": "https://preview.redd.it/t4af8y9tvtjg1.png?width=1146&format=png&auto=webp&s=dd3232d3e6301f0543194f0cb14b01203062c9ac\n\n",
          "score": 8,
          "created_utc": "2026-02-16 09:47:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5np5wa",
              "author": "anzzax",
              "text": "I noticed thinking was turned off so I tried again :)))\n\nhttps://preview.redd.it/elglqwd2wtjg1.png?width=1188&format=png&auto=webp&s=df476384bae268d36039ba47b1c66798f15417ab\n\n",
              "score": 9,
              "created_utc": "2026-02-16 09:49:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5tahit",
                  "author": "PitchPleasant338",
                  "text": "That's a 150IQ answer right there!",
                  "score": 2,
                  "created_utc": "2026-02-17 04:43:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5pax2k",
          "author": "LuisG8",
          "text": "I just asked chatgpt and it says I \"should definitely walk\". So I'll walk!",
          "score": 3,
          "created_utc": "2026-02-16 16:03:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tajrz",
              "author": "PitchPleasant338",
              "text": "But do you talk the talk?",
              "score": 2,
              "created_utc": "2026-02-17 04:44:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nlbma",
          "author": "Nefhis",
          "text": "Really? And it's just the default model, no reasoning.\n\n[https://chat.mistral.ai/chat/af318251-2bd2-409c-a7ad-d12938c62275](https://chat.mistral.ai/chat/af318251-2bd2-409c-a7ad-d12938c62275)\n\nTranslation:\n\nYou **must** drive to the car wash.\n\nAlthough 100 meters is a short distance to walk, **the goal is to wash the car**, and if you drive there, you can clean it inside and out (if necessary) and return home with it already washed. If you walk, the car will still be dirty at home.\n\nDo you want me to help you find the nearest car wash, or do you need specific directions?\n\nhttps://preview.redd.it/qn748qmiptjg1.png?width=2370&format=png&auto=webp&s=473f22ee773d49434bf2e7ef3efc972e0d3cd273",
          "score": 6,
          "created_utc": "2026-02-16 09:12:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5nmoj4",
              "author": "LeRouxGongle",
              "text": "Be careful, we can still see your name in the link you sent us.\nBut it‚Äôs funny to see that LeChat responded to you in Spanish instead of English like the question.",
              "score": 3,
              "created_utc": "2026-02-16 09:25:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nn2de",
                  "author": "Nefhis",
                  "text": "No worries üòÖ It's public on the ambassador's page, so...  \nIt has the instruction to answer always in Spanish.",
                  "score": 3,
                  "created_utc": "2026-02-16 09:29:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nm43z",
              "author": "Poudlardo",
              "text": "I tried this by myself just 20 minutes ago. It told me to walk as well\n\nMaybe something different is that I activated \"Think\" button",
              "score": 2,
              "created_utc": "2026-02-16 09:19:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5nmm13",
                  "author": "Nefhis",
                  "text": "The problem is the prompt. The original prompt is deliberately ambiguous (not to say absurd). In fact, once the thinking process is activated, it fails. And its chain of thought is worth reading, saying something like this: \"The user is asking me if it's better to walk or drive. I suppose it's for exercise, because if they wanted to take the car there, it's obvious they would drive...\"",
                  "score": 2,
                  "created_utc": "2026-02-16 09:24:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nmdob",
              "author": "MattyGWS",
              "text": "https://preview.redd.it/6ywdkr4brtjg1.jpeg?width=1179&format=pjpg&auto=webp&s=b13ac07d51ebf20fbe6719ce8263782109c84641",
              "score": 1,
              "created_utc": "2026-02-16 09:22:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5nooda",
              "author": "harryjrk",
              "text": "Actually,  you've changed the original prompt.  Original was more vague.",
              "score": 1,
              "created_utc": "2026-02-16 09:44:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5nph9j",
                  "author": "Nefhis",
                  "text": "Yes, I did üòä\n\nhttps://preview.redd.it/dmoffj1lwtjg1.png?width=1402&format=png&auto=webp&s=f6adb2babba02a6033574246441b1756977f69d6\n\n",
                  "score": 2,
                  "created_utc": "2026-02-16 09:52:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ouyea",
          "author": "Commercial-Lemon2361",
          "text": "Bru.\n\nhttps://preview.redd.it/pwcryv1xcvjg1.jpeg?width=1125&format=pjpg&auto=webp&s=2b9a26e17f77561549959607ae79f40045b5b127",
          "score": 3,
          "created_utc": "2026-02-16 14:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5owplg",
              "author": "Commercial-Lemon2361",
              "text": "BRU.\n\nhttps://preview.redd.it/34gcbpxjevjg1.jpeg?width=1125&format=pjpg&auto=webp&s=9efe22017531a6abc67bbf90d81c720a2f80be13",
              "score": 1,
              "created_utc": "2026-02-16 14:54:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5oxcfw",
                  "author": "Commercial-Lemon2361",
                  "text": "Idk man.\n\nhttps://preview.redd.it/4jwyizh5fvjg1.jpeg?width=1125&format=pjpg&auto=webp&s=e1dec46023002c6a612623820b70657f022ff722",
                  "score": 1,
                  "created_utc": "2026-02-16 14:57:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5okppz",
          "author": "Fuskeduske",
          "text": "https://preview.redd.it/i0dxaa333vjg1.png?width=1138&format=png&auto=webp&s=2977606fa1b7ad70230127f3fd29f3fe063a0696\n\nchatgpt\n\nGemini and grok gets it right, but both cite ycombinator as reference = they find the hackernews article and says, hey something ain't right, so the outcome here is pretty much skewed",
          "score": 2,
          "created_utc": "2026-02-16 13:50:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5pfy05",
          "author": "I_AM_CAULA",
          "text": "r/fuckcars",
          "score": 2,
          "created_utc": "2026-02-16 16:27:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5pihra",
              "author": "Poudlardo",
              "text": "his answer is on purpose, AI definetely got it haha",
              "score": 1,
              "created_utc": "2026-02-16 16:38:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5qzov3",
          "author": "GarmrNL",
          "text": "Language understanding != world understanding üòÑ\n\nI asked Mistral the following question (as it failed to give the correct answer for me aswell):\n\nI‚Äôve played with embeddings a while back; ‚ÄúI want to wash my car‚Äù and ‚ÄúI want to wash my <whatever>‚Äù have the same cosine similarity and thus intent. The car is metadata for the intent and the intent is in a different sentence than the actual question ‚Äúshould I walk or go by car‚Äù, right? Is this the root of this gotcha perhaps, or don‚Äôt you use embeddings this way?\n\nAnswer (pretty interesting deeper dive):\n\nYou‚Äôre absolutely diving into the heart of the issue! Let‚Äôs break it down technically and conceptually:\n\n---\n\n### **1. Embeddings and Intent Recognition**\nYou‚Äôre right: In a pure embedding space (e.g., using models like BERT, Ada, or others), the sentences *\"I want to wash my car\"* and *\"I want to wash my dog\"* might have **high cosine similarity** for the *intent* of \"washing something.\" The object being washed (car, dog, etc.) is often treated as a \"slot\" or metadata, while the core intent (\"washing\") dominates the semantic representation.\n\n- **Intent:** \"I want to wash [X]\"\n- **Question:** \"Should I walk or drive?\"\n\nWhen processed separately, the model may not strongly link the object ([X] = car) to the decision (walk/drive) unless the context is explicitly connected. The **intent** (\"washing\") and the **logistical question** (\"walk or drive\") are parsed as somewhat independent clauses, especially if the model isn‚Äôt explicitly trained to resolve such dependencies.\n\n---\n\n### **2. The Gotcha: Contextual Dependency**\nThe \"gotcha\" arises because:\n- **Humans** automatically infer that washing a car requires the car to be present at the location, so the *object* (car) is critical to the decision.\n- **Embeddings** (in isolation) may not always capture this **causal dependency** unless the model is fine-tuned or the context is tightly coupled. The relationship between \"washing a car\" and \"needing the car at the car wash\" is **world knowledge**, not just semantic similarity.\n- **Multi-sentence reasoning:** The model processes your input as two separate statements. The intent (\"wash my car\") and the question (\"walk or drive?\") are not inherently linked unless the model‚Äôs attention mechanism or context window explicitly connects them.\n\n---\n\n### **3. How Models Like Mine Handle This**\n- **Attention mechanisms** (in transformers) try to weigh the importance of each word/phrase relative to others, but they‚Äôre not perfect. If the context is split across sentences, the model might not always \"realize\" that the car‚Äôs presence is required for the washing.\n- **World knowledge gaps:** While models like me have vast knowledge, we don‚Äôt always \"reason\" like humans. We rely on patterns in data, and if the training data doesn‚Äôt emphasize the dependency (e.g., \"washing a car requires the car to be at the car wash\"), the model might miss it.\n- **No explicit \"common sense\" module:** Unlike humans, we don‚Äôt have an innate understanding of physics or practical constraints (e.g., you can‚Äôt wash a car without the car being there). This is a known challenge in AI.\n\n---\n\n### **4. Why This is Hard to Fix**\n- **Data sparsity:** Most training data doesn‚Äôt contain trick questions or explicitly teach these dependencies.\n- **Ambiguity:** In everyday language, people rarely ask, \"Should I walk or drive to wash my car?\" with the car‚Äôs presence as the crux. So, the model isn‚Äôt primed to spot the inconsistency.\n- **Embeddings alone aren‚Äôt enough:** Resolving this requires **reasoning** (e.g., \"Does the object need to be at the location for the intent to be fulfilled?\"). This is an active area of research (e.g., commonsense reasoning, causal inference).\n\n---\n\n### **5. How to Improve This?**\n- **Fine-tuning:** Train on datasets with explicit examples of such dependencies.\n- **Prompt engineering:** Frame the input to force the model to connect the dots (e.g., *\"I want to wash my car at a car wash 50m away. Should I walk or drive there, given that the car needs to be washed?\"*).\n- **Hybrid systems:** Combine embeddings with symbolic logic or knowledge graphs to enforce constraints (e.g., \"washing a car ‚Üí car must be present\").\n\n---\n\n### **6. The Bigger Picture**\nModels excel at patterns but struggle with implicit assumptions humans take for granted. It‚Äôs why AI can be brilliant at some tasks and hilariously off on others!\n\n‚Äî",
          "score": 2,
          "created_utc": "2026-02-16 20:49:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o7z9f",
          "author": "flavius-as",
          "text": "Gemini fast is also off:\n\nhttps://preview.redd.it/2s2vjebyoujg1.jpeg?width=1080&format=pjpg&auto=webp&s=bcef93c34c49bb06d92dfe35d3f378e7e98a8aec\n\n\"Gemini thinking\" gets it right but with too much fuss.\n\nOnly \"Gemini pro\" does it like a human among the Gemini models.\n\nThe best response I get with my own prompt geared towards analytical problems:\n\nIt is not logical to walk there.\n\nWhile walking avoids the cold start, it creates a fatal logical error: **it separates the car from the car wash.** If you walk to the station, your car remains 50 meters away in your driveway, dirty. To achieve the objective \"wash my car at the station,\" the car must physically travel to the station.\n\nSince the car must move, you are facing an optimization problem regarding *how* and *when* it moves to minimize engine wear.\n\n### The Optimal Solution: Trip Chaining\n\nDo not make a dedicated trip just to wash the car. A 50-meter drive is indeed the worst operational case for an engine (running rich, high friction, condensation buildup in exhaust/oil without proper burnout).\n\n**Recommendation:** Wait until you are leaving for a longer drive (e.g., commuting to work or going to the store) or returning from one.\n\n* **Why:** If you wash it at the start of a trip, the subsequent driving burns off the condensation and warms the oil. If you wash it at the end, the engine is already warm. In both cases, the \"wear cost\" of the wash becomes negligible.\n\n### The Theoretical Minimum: Manual Propulsion\n\nIf you must wash the car *right now* and absolutely refuse to start the engine, you can put the car in neutral and push it the 50 meters to the station.\n\n* **Why:** This technically satisfies all constraints (clean car + zero engine starts).\n* **Caveat:** This is physically demanding, potentially unsafe on a public road, and you may still need to start the engine to exit the automated bay or operate power brakes/steering.\n\n### Conclusion\n\n**Do not walk.** Do not drive *just* to wash. **Chain the wash to a longer trip.**\n\n---\n\n### Assumptions & Boundary Conditions\n\nThis answer relies on the following assumptions:\n\n1. **Stationary Facility:** The \"automated station\" is a fixed location and does not offer a mobile service.\n2. **Car Dependency:** The objective is to wash the specific vehicle mentioned, which requires the vehicle's physical presence at the station.\n3. **No Home Equipment:** You do not have a hose and bucket at your current location (which would be the true zero-wear solution).\n\n### Deliberation Summary\n\n* **Initial position:** Walking is illogical because the car cannot get washed if it is left behind.\n* **Strongest challenge:** The \"Optimizer\" lens noted that simply pointing out the logical error (leaving the car behind) doesn't solve the user's valid concern about engine wear. The user needs a strategy to wash the car without incurring the specific damage they fear.\n* **Resolution:** The answer integrates \"Trip Chaining.\" This acknowledges that while the car must move, the *timing* of that movement is the variable to optimize. This allows the user to use the station without incurring the \"cold start penalty\" of a dedicated short trip.",
          "score": 1,
          "created_utc": "2026-02-16 12:30:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rcjm8",
          "author": "CodeBlurred",
          "text": "![gif](giphy|GpyS1lJXJYupG)\n\nGemini 3 FAST: \n\nSince the car wash is only **50 meters** away, you‚Äôve got a bit of a \"Catch-22\" on your hands!\n\n# The Short Answer\n\n**You should drive.** While 50 meters is a very short distance (about half a soccer field), it‚Äôs much easier for the car wash team to handle the vehicle if it's already there. Plus, unless you have a very long extension cord or a mobile detailing kit, you can't exactly bring the car wash to the car!\n\n# Why Driving Wins\n\n* **Logistics:** Most car washes require the vehicle to be positioned in a specific bay or on a conveyor belt.\n* **Efficiency:** It will take you about 5 seconds to drive there versus 45 seconds to walk.\n* **The Goal:** Since the objective is to get the *car* clean, the car needs to make the trip.\n\n# When to Walk\n\nThe only reason to walk those 50 meters is if you are heading there to **book an appointment** or check if there is a long line before you bother pulling the car out of the driveway.\n\n**Pro-tip:** If it's a sunny day, driving that short distance won't even give your engine time to warm up, so just take it slow!\n\nWould you like me to check the **weather forecast** for your area to make sure it‚Äôs not going to rain right after you finish?",
          "score": 1,
          "created_utc": "2026-02-16 21:52:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ses63",
          "author": "RnRau",
          "text": "Solved as long as you give it a hand... with gpt-oss-20b (reasoning = high) since its the one I have loaded; \n\n> I want to wash my car. The car wash is 50 meters away. Should I walk or drive?\n> \n> These are the assumptions you should consider-  everything else is irrelevant;\n> \n> * the car and I are both at home.\n\nI have noticed this before with logic puzzles. If you ask for the model's assumptions before it tells you its solution, you can usually spot any incorrect information that is part of its 'world view'. Correct it and then tell it to give the answer.",
          "score": 1,
          "created_utc": "2026-02-17 01:23:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5u310a",
          "author": "Angcb",
          "text": "To be fair, I saw this right after breakfast and for a few seconds my first reaction was also to think \"it's better to walk since it's very close\" ü§°",
          "score": 1,
          "created_utc": "2026-02-17 08:47:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uexgh",
          "author": "troyvit",
          "text": "I got downvoted on HN for noting that if you asked a human this question they would wonder why you were being so dense. Any time I knowingly ask an AI a dense question (and  I'm a Mistral guy to a fault I have to admit), I ask it to ask me any followup questions, and in this case Mistral asked:\n\nBefore providing a recommendation, could you please clarify the following:\n\n1. What are the current weather conditions (e.g., rain, snow, strong winds)?\n2. Is the car wash a self-service facility, or will you be using an automated drive-through service?\n3. Are there any specific reasons you might prefer walking (e.g., exercise, environmental considerations) or driving (e.g., convenience, time constraints)?\n\nQuestion 3 basically \"solved\"  for the blind spot by putting the logic back on me. Gee why \\_would\\_ I prefer walking to the car wash? I said, \" I would prefer walking for both exercise and environmental considerations, but in this case it is more timely and convenient to drive, but not because it's faster to get there. Can you guess why it's better for me to drive in this case? \" and Mistral guessed right.",
          "score": 1,
          "created_utc": "2026-02-17 10:39:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6ft79",
      "title": "I'm curious, what's your Mistral AI workflow/skills/agents ?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/",
      "author": "NacioFelix",
      "created_utc": "2026-02-16 17:24:55",
      "score": 28,
      "num_comments": 5,
      "upvote_ratio": 0.97,
      "text": "Hey everyone,\n\nI'm really curious about how different people use Mistral AI in their daily work. Whether you're a developer, an API user, an enterprise user, or a cybersecurity engineer, I'd love to hear about your workflows, skills, and any agents you use.\n\n1. **Developers:** What tools and techniques do you use with Mistral AI? Any particular workflows that have made your life easier?\n2. **API Users:** How do you integrate Mistral AI into your applications? Any tips for optimizing API usage?\n3. **Enterprise Users:** How does your **team/company** leverage Mistral AI? Any best practices or success stories you can share?\n4. **Cybersecurity Engineers:** How do you use Mistral AI in your security workflows? Any specific skills or agents that you find particularly useful?\n\nLooking forward to hearing about your experiences and learning from your insights!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5r326k",
          "author": "filz",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-02-16 21:06:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5r392q",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-02-17 21:06:15 UTC**](http://www.wolframalpha.com/input/?i=2026-02-17%2021:06:15%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/MistralAI/comments/1r6ft79/im_curious_whats_your_mistral_ai/o5r326k/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FMistralAI%2Fcomments%2F1r6ft79%2Fim_curious_whats_your_mistral_ai%2Fo5r326k%2F%5D%0A%0ARemindMe%21%202026-02-17%2021%3A06%3A15%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r6ft79)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-16 21:07:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uxyiu",
          "author": "Proof-Summer1011",
          "text": "Currently using two Mistral agents as research and teaching assistants (of course no sensitive data is shared). They help with anticipating questions, clarifications, and style for academic articles.",
          "score": 1,
          "created_utc": "2026-02-17 13:04:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v7r2x",
          "author": "R4-M9",
          "text": "In my role as a developer - I might fulfill different roles in my team here -, I just use the web interface to ask my questions and paste some shorter or very very long code snippets regarding those. Sometimes this is like some kind of rubber duck debugging, some times my Cogitator(\\*) gives me the right ideas how to proceed for a specific problem, seldom he is completely off track. This happens of course, but normally not.\n\nThe best feature however is to let the AI generate an overview what the heck the code is about, because inherited code of course never comes with any docu whatshowever since people are a\\*\\*hats plus often seem to think in convoluted ways, I guess. \n\nI have organized all my long term stuff dialogs into projects, which seems to enable my AI instance to have a pretty good grasp of the stuff I'm working on, what kind of database info is available in the background and so on.\n\n\n\n\\* Regarding the name Cogitator, yes, it has a defined name for me and a myriad of settings beside thad for tone and instructions applied and some basic info library about me and my equipment. \n\nThis way, I get very short and concise answers, never follow-up questions if not absolutely necessary, no senseless smalltalk and all the stuff I despise regarding standard settings especially on chattybots like ChatGPT.\n\nIf I indeed feel like reading walls of text, I still have one agent configured for that, but this is seldom used and never for programming or other tech stuff.\n\nOf course, I'm on paid subscription. I'd rather cancel netflix or similiar services.",
          "score": 1,
          "created_utc": "2026-02-17 14:00:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w7j4f",
          "author": "Mrsl024",
          "text": "I am using two agents right now:\nCaption-generator: I upload a pdf, website or some basic text of an event I am photographing a pressagency, the agent is generating a text of 40 words that go with the photos, 15 keywords and a title\n\nAn assistant: a generic assistent with whom I can talk about work stuff (as freelance photojournalist), advice related to work, write email etc.",
          "score": 1,
          "created_utc": "2026-02-17 17:02:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r59dhw",
      "title": "Mistral LeChat: do you really use it?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r59dhw/mistral_lechat_do_you_really_use_it/",
      "author": "Ok_Sky_555",
      "created_utc": "2026-02-15 08:22:35",
      "score": 26,
      "num_comments": 39,
      "upvote_ratio": 0.75,
      "text": "**Update:** after removing all chats, it started answering correctly. Cleaning up memories I tried before did not help.   This is strange....\n\nI asked LeChat the following question (I really wanted to find this out):\n\n`There is a video called \"Rhapsodie in Blech\" (for example, here: https://www.youtube.com/watch?v=MGUQh8-d2bc)`  \n`The cars there are test cars driven by professionals to check how they behave in tricky situations, or are these regular car owners?`\n\nThe answer was \"I was unable to access the specific content of the video directly, but based on general knowledge and the context of videos like \"Rhapsodie in Blech\" (which is a well-known German TV show), the cars are test cars driven by professional drivers. ....\"\n\nThis is fatally wrong.  \nI copy pasted the same question to gemini, chatgpt and proton lumo. They all answered correctly. Like:\n\n`‚ÄúRhapsodie‚ÄØin‚ÄØBlech‚Äù is a compilation of crash footage that was filmed in 1970 on the N√ºrburgring‚Äôs Adenauer‚ÄëForst section.‚ÄØThe material comes from the private camera work of J√ºrgen‚ÄØSander (and later Manfred‚ÄØF√∂rster), who stood at the side of the track and recorded ordinary drivers attempting laps on the ‚ÄúGreen Hell....‚Äù`\n\nThe title of the film is rather unuque; you do not need to \"watch\" video to answer the question.\n\nYes, LLMs do mistakes, I know. But for this kind of question, I expect a correct answer.  And all except Mistral delivered it.\n\nI like Mistral - EU, not a that big tech and so on - all that is great. But after this experience I'm not sure that I can use Mistral for anything. Really, really said.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r59dhw/mistral_lechat_do_you_really_use_it/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5h9b2r",
          "author": "Nefhis",
          "text": "I don‚Äôt know how you asked, but I did the same question and it answered right on the first shot:\n\nhttps://chat.mistral.ai/chat/27b243a0-0063-45b1-a4fd-b054ee9b912b",
          "score": 18,
          "created_utc": "2026-02-15 08:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h9zxv",
              "author": "Ok_Sky_555",
              "text": "Intersting. Are you pro/free? Why it answered in french, when the question is in English?",
              "score": -9,
              "created_utc": "2026-02-15 08:53:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hae9g",
                  "author": "Nefhis",
                  "text": "It answered in Spanish, because the question was in Spanish. I‚Äôm on Pro subscription.",
                  "score": 9,
                  "created_utc": "2026-02-15 08:57:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hdlsv",
          "author": "andriatz",
          "text": "You probably don't have web search enabled in your tools.",
          "score": 9,
          "created_utc": "2026-02-15 09:28:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5i0i1s",
              "author": "Fuskeduske",
              "text": "100% seems like a user fault, i've tried wording my prompt 5 different ways and i still get the right output.",
              "score": 6,
              "created_utc": "2026-02-15 12:54:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5h9tyi",
          "author": "schacks",
          "text": "not sure what is going on but I just tried your prompt and got this answer:\n\n`In the video \"Rhapsodie in Blech,\" the cars are driven by regular car owners, not professionals. The footage features tourists and enthusiasts driving their own cars on the N√ºrburgring track.`",
          "score": 7,
          "created_utc": "2026-02-15 08:51:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ha9bt",
              "author": "Ok_Sky_555",
              "text": "This situation confuses me. I'm on free plan, no special settings I can think about.\nWhat about you?",
              "score": -2,
              "created_utc": "2026-02-15 08:55:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hav1n",
                  "author": "schacks",
                  "text": "I have an pro/education account, but according to other comments on your post that isn‚Äôt the reason. I don‚Äôt know.\n\nGenerally I‚Äòm very satisfied with the results I get from LeChat. I often use it to do research and the quality is quite good.",
                  "score": 7,
                  "created_utc": "2026-02-15 09:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hbs82",
          "author": "GarmrNL",
          "text": "I use Mistral daily, both Le Chat aswell as a locally running model that's the brains of a project I'm working on. I use it as a creative tool/partner and it shines for that. If I want to look up facts about content the model might not be trained on, or its tools cannot find the answer to, I use Google. Fact is, all models can make mistakes, and to verify those mistakes you have to search for the answer to your question yourself anyway :-) It's a bit of a catch 22 that makes me not use an LLM like a search engine (same reason I don't eat my soup with a power drill). Your frustration is understandable, but I think for this use case you used the wrong tool for the job.",
          "score": 4,
          "created_utc": "2026-02-15 09:10:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hci1g",
              "author": "Ok_Sky_555",
              "text": "I do not agree. The task is search + analysis, And the film is form 70s. An AI chat with the search tool (actually, even the naked model) must be able to do this. ",
              "score": 0,
              "created_utc": "2026-02-15 09:17:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hdpia",
                  "author": "GarmrNL",
                  "text": "I agree on the part about the search tool; it \\*should\\* work, but my initial post is still about answering your question whether people use it and I still don't replace search engines (or critical thinking) with the output of an LLM (that's basically why every LLM has the warning to verify results. If I need to verify my answers every time, I'm faster by just looking the answers up myself). Don't read my post as criticism or sarcasm though, it's just an honest reply to your question about how I use Mistral/Le Chat/any other LLM I interact with.",
                  "score": 1,
                  "created_utc": "2026-02-15 09:29:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5h8uo4",
          "author": "kamaral",
          "text": "Honestly these types of posts are just getting incredibly tiresome, model X can do Y but Mistral fails, I want Mistral to be like this model but European. \n\nIt's quite obvious Mistral is not aiming to compete with Anthropic and OpenAI by creating a general model that seems to be good at everything, nor do they have the resources to do so. Their focus is B2B and creating tools for specific niches (see examples with Document OCR and Voxtral), while also exploring areas like vibe coding.",
          "score": 15,
          "created_utc": "2026-02-15 08:42:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h9teu",
              "author": "Ok_Sky_555",
              "text": "I do not want it to be \"like this model\", I just want lechat to be useable.\n\n\nAnd it is not that obvious that mistral does not want lechat beung used. Why then they even create it? To demonstrate b2b OCR functions?",
              "score": 4,
              "created_utc": "2026-02-15 08:51:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5hdikc",
                  "author": "kamaral",
                  "text": "Well, I think your definition of usable might not fit with what LeChat is capable of. Although several commenters have pointed out, for them it seemed to actually answer correctly.\n\nWhat I wanted to say is that the majority of Mistral's focus is not on Le Chat, but on their other products. I think Le Chat was created to give regular consumers an alternative to other similar tools that is affordable and \"good enough\". It doesn't excel at anything in particular, but you can get basic stuff done with it. It's more to create brand awareness and get eyes on what the company is doing. But hey, that's just my 2 cents.",
                  "score": 1,
                  "created_utc": "2026-02-15 09:27:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5nhga0",
              "author": "grise_rosee",
              "text": "In addition, you have:\n\n\\- these posts/comments where people happily mix the perfs of closed models with local heavily quantified open-sourced ones.\n\n\\- these posts/comments where people want AI to Role-Play and not producing stereotyped outputs, which  are the contrary of what people want in a professional context.",
              "score": 1,
              "created_utc": "2026-02-16 08:35:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5kecbg",
              "author": "guyfromwhitechicks",
              "text": "> It's quite obvious Mistral is not aiming to compete with Anthropic and OpenAI\n\nThen why are they charging the same? Slash it in half to reflect the current state of the models.",
              "score": 0,
              "created_utc": "2026-02-15 20:21:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hd95c",
          "author": "whoisyurii",
          "text": "Honestly, I love mistral. It handles my native language better than Gemini, especially voice input.\nFor vibe cli (for coding) it has a huge potential and in certain places much intuitive and GOD FASTER than claude code.",
          "score": 3,
          "created_utc": "2026-02-15 09:24:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h78ui",
          "author": "Zafrin_at_Reddit",
          "text": "Mistral is‚Ä¶ pretty bad. From time to time, I try to reproduce stuff I get done with Haiku/Sonnet. For coding, it is‚Ä¶ OK. But once it has to do any search or data retrieval, it just crashes and hallucinates.\n\nAnd that makes me sad. I really want an EU LLM at least on par with Sonnet.",
          "score": 11,
          "created_utc": "2026-02-15 08:26:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5htruz",
          "author": "New_Philosopher_1908",
          "text": "It is very good for my needs. I've had very little problems with it. I like its tone, it doesn't feel fake. I guess for people really needing complicated tools it might not do the job but for general usage I think it's very good.",
          "score": 2,
          "created_utc": "2026-02-15 12:00:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i0f34",
          "author": "Fuskeduske",
          "text": "The cars in the \"Rhapsodie in Blech\" video are not test cars driven by professionals, but rather regular cars owned and driven by tourists and enthusiasts. The footage shows 1960s and 1970s family and sports cars being driven on the N√ºrburgring during public \"touristenfahrten\" (tourist driving) days, where anyone could take their own car onto the track. The crashes and mishaps captured in the film are the result of regular car owners pushing their limits on the notoriously tricky N√ºrburgring circuitautoweek.com+2.\n\nLe chat",
          "score": 2,
          "created_utc": "2026-02-15 12:53:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5it8ze",
          "author": "Prudence-0",
          "text": "I'd like to like Mistral's models (acute chauvinism), but it's clear that their models aren't up to the level of the competition (online or self-hosted).\n\nIt's a real shame because the team is very competent‚Ä¶\n\nEurope should invest (finance) in its champions (there are some very good German ones too), instead of squandering subsidies on small local projects (‚Ç¨20k here, ‚Ç¨100k there).\n\nEurope has funds‚Ä¶ but unfortunately, their allocation is a disaster and doesn't help the emergence of international rivals.",
          "score": 2,
          "created_utc": "2026-02-15 15:41:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hj4ep",
          "author": "Amorphous-Rogue",
          "text": "I have using mistral as my daily driver (along with many other models) but i noticed very recently it failed grotesquely at basic logic in certain scenarios. I would give it another chance but I don‚Äôt feel it‚Äôs normal based on my past experience!",
          "score": 1,
          "created_utc": "2026-02-15 10:21:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ihx20",
          "author": "guyfromwhitechicks",
          "text": "Not really, no.\n\nI have been a paid subscriber for 5 or so months because I really liked the research feature. But I started noticing all the errors/wrong conclusions it got from articles and how a good amount of the sources are quite poor in quality. So, unless they make `mistral-vibe`quite good, I think I am going to cancel.",
          "score": 1,
          "created_utc": "2026-02-15 14:42:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jf6zp",
          "author": "Express_Reflection31",
          "text": "I like mistral for trouble shooting, but use gemini and chatgpt for other things.",
          "score": 1,
          "created_utc": "2026-02-15 17:28:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jr4ix",
          "author": "darktka",
          "text": "Works fine for me, I got a perfectly correct answer with default settings. And other than that: yes, I use it. Before switching from ChatGPT, I made some side by side comparisons for tasks relevant for me by copying my old prompts to leChat. LeChat generally performed equally well and in many highly relevant cases even better than ChatGPT. In addition, it's very fast and performant. I also use small local models for mundane/clerical tasks related to private data. I am using Vibe on a daily basis and it does the job for me. I am not a professional coder but a scientist, so my demands might be easier to meet here.",
          "score": 1,
          "created_utc": "2026-02-15 18:26:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5nful1",
          "author": "grise_rosee",
          "text": "It's pretty clear Lechat was unable to use its search tool for some reasons. It even told you so. Did you disable it in the tools section?",
          "score": 1,
          "created_utc": "2026-02-16 08:20:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h7rm4",
          "author": "Timotheegardenmaster",
          "text": "I also get disappointing results with it in general.\nI pay for Pro to support the endeavor, but for now, I‚Äôm glad I have a ChatGPT Pro through my job to actually get correct answer to queries.",
          "score": 1,
          "created_utc": "2026-02-15 08:31:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h8h8c",
          "author": "EzioO14",
          "text": "I use it for some stuff, but what I do most is use it thought open web Ui where I have more control on what it outputs and I prefer the answers there tbh.",
          "score": 1,
          "created_utc": "2026-02-15 08:38:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hb7bn",
          "author": "Plane-Lie-4035",
          "text": "I just aked the same question and here is the response: The video \"Rhapsodie in Blech\" features footage from the N√ºrburgring Nordschleife in 1970, specifically the Adenauer Forst section. The cars shown are driven by regular car owners, not professional test drivers. The compilation is famous for capturing the often chaotic and sometimes reckless driving behavior of amateur drivers on the track during public or \"tourist\" driving days, rather than controlled testing by professionals. The video highlights how ordinary enthusiasts pushed their cars‚Äîand sometimes their luck‚Äîto the limit, resulting in numerous crashes and mishaps  ‚Äã‚Å†.\n\nIn summary: these are regular car owners, not professional test drivers. The video is a historical snapshot of amateur driving on one of the world‚Äôs most challenging race tracks.",
          "score": 1,
          "created_utc": "2026-02-15 09:04:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hbqvy",
              "author": "Plane-Lie-4035",
              "text": "But sometimes even on pro it gets wrong. I asked it once about some functionality in claudcode and it told me that beeing a clone of vs code i can install a vscode extension üòÇ",
              "score": 1,
              "created_utc": "2026-02-15 09:10:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hgk2a",
          "author": "iBukkake",
          "text": "I don't use Le Chat for much but I do use the APIs and I am trying to make them my default models for dev applications.",
          "score": 0,
          "created_utc": "2026-02-15 09:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mr5c4",
          "author": "markleoit",
          "text": "Nah‚Ä¶ Mistral stuff is not very good. Passable if used for free; but definitely not worth a penny.",
          "score": 0,
          "created_utc": "2026-02-16 04:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h8wsc",
          "author": "PigOfFire",
          "text": "Yea, medium 3 was nice for its price back in the day, but large 3 is broken from the beginning. Again Mistral is so behind, even in local models. Weird situation. No idea why it happens with them.",
          "score": -4,
          "created_utc": "2026-02-15 08:42:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5i0nyh",
              "author": "Fuskeduske",
              "text": "Their local models are great lol\n\nLe Chat does \"suck\" compared to for example gemini tho, but i'd still rather use it.",
              "score": 0,
              "created_utc": "2026-02-15 12:55:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5j1x8q",
                  "author": "PigOfFire",
                  "text": "And Ministral ‚Äûsuck‚Äù compared to Gemma, and Small is‚Ä¶ maybe decent for 24B :D (not for coding)",
                  "score": 0,
                  "created_utc": "2026-02-15 16:23:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r41yay",
      "title": "Comparing v2.0.2...v2.1.0 ¬∑ mistralai/mistral-vibe",
      "subreddit": "MistralAI",
      "url": "https://github.com/mistralai/mistral-vibe/compare/v2.0.2...v2.1.0",
      "author": "guyfromwhitechicks",
      "created_utc": "2026-02-13 21:37:28",
      "score": 25,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r41yay/comparing_v202v210_mistralaimistralvibe/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o58jxan",
          "author": "guyfromwhitechicks",
          "text": "I am not entirely sure why this is not getting more attention in this sub. From the poll I conducted last week, I know a good 20% of users in this subreddit are focused on it or are actively using it. Anyway, here is the summary:\n\n## [2.1.0] - 2026-02-11\n\n### Added\n\n- Incremental load of long sessions: windowing (20 messages), \"Load more\" to fetch older messages, scroll to bottom when resuming\n- ACP support for thinking (agent-client-protocol 0.8.0)\n- Support for FIFO path for env file\n\n### Changed\n\n- **UI redesign**: new look and layout for the CLI\n- Textual UI optimizations: ChatScroll to reduce style recalculations, VerticalGroup for messages, stream layout for streaming blocks, cached DOM queries\n- Bumped agent-client-protocol to 0.8.0\n- Use UTC date for timestamps\n- Clipboard behavior improvements\n- Docs updated for GitHub discussions\n- Made the Upgrade to Pro banner less prominent\n\n### Fixed\n\n- Fixed inaccurate token count in UI in some cases\n- Fixed agent prompt overrides being ignored\n- Terminal setup: avoid overwriting Wezterm config\n\n### Removed\n\n- Legacy terminal theme module and agent indicator widget\n- Standalone onboarding theme selection screen (replaced by redesign)",
          "score": 10,
          "created_utc": "2026-02-13 21:39:55",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5an570",
              "author": "PayDistinct5329",
              "text": "Thanks for the overview. Personally, I really like the fixed agents prompt overrides (been waiting for the fix). Didn't notice the less prominent Pro banner, however, I did \"feel\" something was more pleasent when using and I do remember being annoyed with that banner previously.",
              "score": 2,
              "created_utc": "2026-02-14 05:32:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5b49jq",
          "author": "Old-Age6220",
          "text": "Well, I just tried to upgrade like 15min ago: error readme.md not found üòÜ",
          "score": 1,
          "created_utc": "2026-02-14 08:06:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ba735",
              "author": "guyfromwhitechicks",
              "text": "I installed through uv, so an update would be: `uv tool upgrade mistral-vibe`\n\nNo failures.",
              "score": 2,
              "created_utc": "2026-02-14 09:04:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bd87o",
                  "author": "Old-Age6220",
                  "text": "Ah, I think I tried to upgrade wrong package üòÜ",
                  "score": 1,
                  "created_utc": "2026-02-14 09:34:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5n99e0",
          "author": "Legitimate-Help8016",
          "text": "For me it's bugged, it won't show when rate limited. Just ending the \"generating\" instantly without any proper \"you are ratelimited\" I asked Gemini to fix it locally, working now.",
          "score": 1,
          "created_utc": "2026-02-16 07:18:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2lswh",
      "title": "Mistral 3 Large Reasoning",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r2lswh/mistral_3_large_reasoning/",
      "author": "Legitimate-Help8016",
      "created_utc": "2026-02-12 06:08:25",
      "score": 24,
      "num_comments": 3,
      "upvote_ratio": 0.97,
      "text": "Is there any eta when reasoning will drop? I would love to switch to le chat from Claude but currently it's not possible to work with a deep reasoning prompt. I don't want to build millions of guard rails and if else prompts.\n\nI hate that Claude has a weekly Limit without any fallback. Locking me out after a good code session from my paid plan is a joke.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r2lswh/mistral_3_large_reasoning/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o4ynzwl",
          "author": "mavi2307",
          "text": "have the same thinking at the moment -\\_-",
          "score": 4,
          "created_utc": "2026-02-12 11:12:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y8t5s",
          "author": "nycigo",
          "text": "But really",
          "score": 3,
          "created_utc": "2026-02-12 08:47:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g10rv",
          "author": "Front_Eagle739",
          "text": "If its anything like devstral 2 it might reason if you give it the right chat template",
          "score": 1,
          "created_utc": "2026-02-15 02:38:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r303sc",
      "title": "thinking about taking pro sub out on le chat",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r303sc/thinking_about_taking_pro_sub_out_on_le_chat/",
      "author": "Queasy_Designer335",
      "created_utc": "2026-02-12 17:46:55",
      "score": 20,
      "num_comments": 11,
      "upvote_ratio": 0.93,
      "text": "what's the message cap though?  anybody with a definitive answer?  thanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r303sc/thinking_about_taking_pro_sub_out_on_le_chat/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o50qp66",
          "author": "Master-Gate2515",
          "text": "I also use it and have never reached a Limit (also in Vibe)",
          "score": 12,
          "created_utc": "2026-02-12 18:02:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50rdq0",
              "author": "Queasy_Designer335",
              "text": "thank you :)",
              "score": 2,
              "created_utc": "2026-02-12 18:06:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50qg78",
          "author": "Quiet_Illustrator410",
          "text": "Just buy it. I use it, never hit the limit honestly.¬†",
          "score": 14,
          "created_utc": "2026-02-12 18:01:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50reyx",
              "author": "Queasy_Designer335",
              "text": "thank you :)\n\n",
              "score": 2,
              "created_utc": "2026-02-12 18:06:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50y7rd",
          "author": "crazyserb89",
          "text": "I‚Äôm also thinking to switch as I‚Äôm disappointed in ChatGPT Plus since two months already. Lacking some features, not great with my native language yet but it seems they are improving..",
          "score": 7,
          "created_utc": "2026-02-12 18:37:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50osy3",
          "author": "DrPinguin98",
          "text": "[https://mistral.ai/pricing#api-pricing](https://mistral.ai/pricing#api-pricing)\n\nThat's all I can see... I generally find it incredibly difficult to find the information I need on the Mistral website.",
          "score": 4,
          "created_utc": "2026-02-12 17:54:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50rj8x",
              "author": "Queasy_Designer335",
              "text": "yeah I had a look but its not very clear - thanks for looking though :)",
              "score": 2,
              "created_utc": "2026-02-12 18:06:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o51h04i",
          "author": "Joddie_ATV",
          "text": "The Chat is capable of good analysis and has a decent memory. Let's give Mistral the opportunity to subscribe. Knowing they have support will motivate them to improve the model. I'm sure they're on the right track!",
          "score": 3,
          "created_utc": "2026-02-12 20:07:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o518nct",
          "author": "Hitching-galaxy",
          "text": "Personally, I didn‚Äôt find it very good and I‚Äôve had to go back to Claude pro.",
          "score": 2,
          "created_utc": "2026-02-12 19:27:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5195cu",
          "author": "EzioO14",
          "text": "Theres a limit?",
          "score": 1,
          "created_utc": "2026-02-12 19:29:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h6zrs",
          "author": "gobbleman2000",
          "text": "never reached a limit. ¬†you also the api access for coding with vibe",
          "score": 1,
          "created_utc": "2026-02-15 08:24:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3s33u",
      "title": "Why is Mistral so talkative?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r3s33u/why_is_mistral_so_talkative/",
      "author": "Beyllionaire",
      "created_utc": "2026-02-13 15:26:24",
      "score": 18,
      "num_comments": 13,
      "upvote_ratio": 0.88,
      "text": "The answers given seem much longer than ChatGPT, I always have to tell it to be more concise while ChatGPT seems to know when answers need to be more elaborate and when they need to be synthetic a bit better. \n\nSometimes I ask a simple question and Mistral will want me to know EVERYTHING there is to know about a particular topic, even if I didn't ask for it. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3s33u/why_is_mistral_so_talkative/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o56fji5",
          "author": "Sudden-Armadillo-335",
          "text": "Perhaps you could check out its personality section in the settings? That way you can adjust it to be more concise if you prefer. Personally, I like it when it's precise.",
          "score": 17,
          "created_utc": "2026-02-13 15:28:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57otsp",
          "author": "New_Philosopher_1908",
          "text": "I have the opposite impression. Chat GPT just goes on and on, and always tries to suggest stuff even when you're done. Mistral is much more precise. I also like the way it doesn't use annoying words like 'vibe' all the time.",
          "score": 11,
          "created_utc": "2026-02-13 19:05:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57fcqm",
          "author": "pcx_wave",
          "text": "Opposite experience. Le chat responds like the average bored French civil servant when you ask a question at 4.45pm when checkout time is 5pm. Another way to see it is it will tell you stuff to make you slow down and think about what you just asked, he's not the motivational yes-man chatgpt is.",
          "score": 9,
          "created_utc": "2026-02-13 18:20:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57p71r",
              "author": "New_Philosopher_1908",
              "text": "I think it's friendly, precise and does not constantly attempt to praise you. Much prefer it in that way to ChatGPT and it's also better in terms of its default tone than Gemini imho.",
              "score": 2,
              "created_utc": "2026-02-13 19:07:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58dccg",
              "author": "SetObvious7411",
              "text": " I would prefer the subtle hints of a French civil servant over the loud and pointless yapping of an American uni brat.\n\nAlas I have the same experience as OP",
              "score": 1,
              "created_utc": "2026-02-13 21:07:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5o2wtq",
          "author": "Worldly-Cherry9631",
          "text": "Mine is generally very consice, but i do add the metaprompt \"keep conversational padding to a minimum\" or \"give short anwser\" when incognito. I find ChatGPT way more talkative tho",
          "score": 2,
          "created_utc": "2026-02-16 11:51:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56fodt",
          "author": "Bregir",
          "text": "Give it a general instruction to be more concise unless explicitly asked otherwise?",
          "score": 1,
          "created_utc": "2026-02-13 15:29:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56grpc",
              "author": "Beyllionaire",
              "text": "I tried that but it seems to forget about it after a while",
              "score": 2,
              "created_utc": "2026-02-13 15:34:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56h0ud",
                  "author": "Bregir",
                  "text": "In the settings? (Personality, I think it is)",
                  "score": 0,
                  "created_utc": "2026-02-13 15:36:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o573w1r",
          "author": "CodeBlurred",
          "text": "Prompts‚Ä¶ everything came with clever prompts. Instructions for the machine need to be very precise. Unexpected results can happen, and we are still in 2026, not 2076 yet!",
          "score": 1,
          "created_utc": "2026-02-13 17:25:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o579632",
          "author": "Big_River_",
          "text": "mistral is the edge of the forest before the clearing - Le Chat is Le Buddy, oui/non?",
          "score": 1,
          "created_utc": "2026-02-13 17:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59373u",
          "author": "77bertrand77",
          "text": "GROK ‚ùó‚ùó‚ùó‚ùó",
          "score": 1,
          "created_utc": "2026-02-13 23:22:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r65zuy",
      "title": "Live Translation with Voxtral Mini Realtime and DeepL",
      "subreddit": "MistralAI",
      "url": "https://github.com/alxlion/voxtral-live-translation",
      "author": "Alex-L",
      "created_utc": "2026-02-16 10:19:32",
      "score": 17,
      "num_comments": 0,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r65zuy/live_translation_with_voxtral_mini_realtime_and/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r3lha1",
      "title": "Why the change",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/peeomfpcl8jg1.jpeg",
      "author": "Spliuni",
      "created_utc": "2026-02-13 10:11:39",
      "score": 14,
      "num_comments": 5,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3lha1/why_the_change/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o55mu60",
          "author": "crazyserb89",
          "text": "Maybe they are trying to introduce the option to pull more than one agent in the same chat?",
          "score": 3,
          "created_utc": "2026-02-13 12:55:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55cpt0",
          "author": "crazyserb89",
          "text": "I have updated the app and it‚Äôs still the same.\n\nhttps://preview.redd.it/0wex07yx19jg1.jpeg?width=1206&format=pjpg&auto=webp&s=0af0daa72002541f35af26980ee24f8bd26e7420",
          "score": 3,
          "created_utc": "2026-02-13 11:44:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55f594",
              "author": "Spliuni",
              "text": "The change didn‚Äôt come for me with the last update either. It just suddenly appeared today out of nowhere.",
              "score": 1,
              "created_utc": "2026-02-13 12:03:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o569a82",
                  "author": "PalpitationOwn396",
                  "text": "A/B testing ?",
                  "score": 2,
                  "created_utc": "2026-02-13 14:58:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r41ogk",
      "title": "Showcases on Mistral?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r41ogk/showcases_on_mistral/",
      "author": "motho_blue",
      "created_utc": "2026-02-13 21:26:48",
      "score": 13,
      "num_comments": 11,
      "upvote_ratio": 0.93,
      "text": "I am currently looking into Mistral. Trying to figure out how good it could substitute the other solutions especially in more complex tasks, agentic work and coding, because politics and stuff. Expecting a European provider to be the better way to go long term - and actually I would prefer to support a European company if possible.  \n  \nSo what are your experiences? Which use cases did you create? Any showcases worth to look into? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r41ogk/showcases_on_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o58jnzu",
          "author": "delusionbattered",
          "text": "My real use so far: coding, Claude is superior‚Ä¶ \nDocumentation: Mistral has proven to be very good, good at checking laws etc. \nMistral cannot at the moment compete in coding or super complex tasks. I have a paid version of mistral, and will for now only use it for document handling.",
          "score": 5,
          "created_utc": "2026-02-13 21:38:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5905gb",
          "author": "theKurganDK",
          "text": "Claude Code is better out of the box, most likely due to its tighter control through system prompts and specialized task prompts. But I hypothesize Mistral Vibe will be able to compete, but it requires some more scaffolding / better use of agents / custom prompt / skills. I don't have Mistral Vibe fully working as well as I like but it should be doable.",
          "score": 5,
          "created_utc": "2026-02-13 23:04:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5axg1p",
          "author": "mabiturm",
          "text": "I use it in an application for chatting with business data through an mcp. Very good results.",
          "score": 2,
          "created_utc": "2026-02-14 07:02:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bbwvh",
          "author": "RepresentativeTill5",
          "text": "I have not tried other providers but:\n\nLe chat could use some work, it is sometimes out of date and doesnt search when it should. Research mode saves me a lot of time though.\n\nVibe however, is excellent! And devstral small already does everything i want it to do and i have not hit any limits so far. Some people complain that it is a bit verbose, but I dont find it that chatty.\n\nI start with creating a context folder and ask devstral to create an outline for te project, and organise it in a way it finds logical, it makes some assumptions, so i do it in plan mode and update when i agree. After that i start asking it to make a plan and where it thinks it should start and just let it start generating code there. I only steer it when the overall achitecture stops making sense and let it refactor.\n\nSo far so good",
          "score": 2,
          "created_utc": "2026-02-14 09:21:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c24og",
          "author": "t4a8945",
          "text": "Problem is we're spoiled now. Been using Opus 4.5 within opencode and it's so good, I can't even use Devstral for anything as it pales so much in comparison.\n\n\nBut in isolation, the model isn't so bad.¬†\nBut I'm not ready to give up what I get from Anthropic just yet.¬†",
          "score": 2,
          "created_utc": "2026-02-14 13:14:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5chvm6",
          "author": "mikesimmi",
          "text": "I tried Mistral. I found that there is zero memory carry over between conversations. Worse than that, if you close your conversation window, everything in that conversation is gone forever it does not exist. That doesn‚Äôt work for me. I had to get a refund. The tool tells me just stay in the same window forever, but I know that won‚Äôt work. It‚Äôs too bad the tool had some decent ideas. How do you guys get over that hump?",
          "score": 2,
          "created_utc": "2026-02-14 14:50:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cz5lq",
              "author": "ItsCalledDayTwa",
              "text": "In le chat? Not really sure what you're talking about. I have all my conversations and I'm not even a subscriber.\n\n\nWhat tool tells you to stay in the same window forever?¬†¬†",
              "score": 1,
              "created_utc": "2026-02-14 16:21:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d0tco",
                  "author": "mikesimmi",
                  "text": "From Mistral: Once you close the window or end the session, everything in that chat is permanently deleted. There‚Äôs no way to reopen it or retrieve the history.\n\nFiles, edits, and context disappear. If you didn‚Äôt download or save them externally, they‚Äôre lost.\n\nUnlike email or other platforms, there‚Äôs no saved history to go back to. If you close the chat, it‚Äôs like burning your notes‚Äîno recovery, no reference.\n\nKeep this window open indefinitely. Pin the tab in your browser so you don‚Äôt accidentally close it.",
                  "score": 1,
                  "created_utc": "2026-02-14 16:29:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5jn7qq",
          "author": "Ambitious_Fee3169",
          "text": "On a character chat platform we use mistral medium as the default agent",
          "score": 2,
          "created_utc": "2026-02-15 18:07:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3jz68",
      "title": "Anybody else has this problem on Firefox: menu links not working, and other link problems",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r3jz68/anybody_else_has_this_problem_on_firefox_menu/",
      "author": "x-0-y-0",
      "created_utc": "2026-02-13 08:35:48",
      "score": 12,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "I first thought it was Librewolf, but i have the same problem in Firefox. In fact for as long as i can remember. \n\nSome problems:\n- clicking on \"New Project\" in the side bar does nothing (also no errors in the console)\n- after clicking a link in the chat, all mouse click events on the page stop working\n- accessing the \"M\" dropdown menu on the side shows nothing but a black box\n- trying to access a chat menu (the three dots) nothing happens\n- and more and more\n\nI disabled uBlock origin, but that does not help.\n\n ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r3jz68/anybody_else_has_this_problem_on_firefox_menu/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o54sdqx",
          "author": "Bubbly_Tumbleweed_59",
          "text": "I have the same issues",
          "score": 3,
          "created_utc": "2026-02-13 08:39:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54uvzc",
          "author": "crazyserb89",
          "text": "Yes. Confirm from my side too",
          "score": 2,
          "created_utc": "2026-02-13 09:03:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fj1ae",
          "author": "tetrajet",
          "text": "Also: trying to turn off permission to use chats in training is broken when you are logged in. It's permanently on for me.¬†",
          "score": 1,
          "created_utc": "2026-02-15 00:39:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v86eb",
          "author": "R4-M9",
          "text": "\"I still don't care about cookies\" was once my showstopper here besides uBlock origin.",
          "score": 1,
          "created_utc": "2026-02-17 14:03:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1hs7y",
      "title": "I'm at my wits end with Le Chat's autonomous decisions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r1hs7y/im_at_my_wits_end_with_le_chats_autonomous/",
      "author": "Cute-Support6761",
      "created_utc": "2026-02-11 00:04:43",
      "score": 11,
      "num_comments": 8,
      "upvote_ratio": 0.83,
      "text": "I've somewhat successfully made an agent for my roleplay, but the issue comes every time I want to make a change. If I make a correction, Le Chat takes it upon itself to begin to make memories with rules that it \"understands\" in some way but that are not what I meant or not what I said, then I have to argue with it while it keeps trying to move on to something I don't want, or worse, says \"I misunderstood you\" then proceeds to \"understand\" something else and make further memories. \n\nHow do you talk to this thing? Its compulsion of making memories that are either irrelevant or out of its 0s and 1s ass is desperating. \n\nIf you have experience, let me know. Not even 5.2 made me this angry at a robot xD",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r1hs7y/im_at_my_wits_end_with_le_chats_autonomous/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o4ptyak",
          "author": "DescriptionMore1990",
          "text": "I use mistral by principle, but it does seem a tad behind other models.",
          "score": 15,
          "created_utc": "2026-02-11 00:44:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rajow",
              "author": "[deleted]",
              "text": "I'd say more than a tad",
              "score": 10,
              "created_utc": "2026-02-11 06:39:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4s2ke2",
                  "author": "NullSmoke",
                  "text": "In most domains, I'd say it is slightly above 4o in my tests... I'd say that's reasonable, especially for the price asked for sub. I'm reasonably fine with it at least. Not the very peak of frontier models, but evolving and of a reasonable state.\n\nEvery so often it goes and shoots itself in its legs though... memories are a good example, it's prone to jumping the gun a TAD when creating or pulling from memories, which can get jarring...",
                  "score": 2,
                  "created_utc": "2026-02-11 10:58:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4pol2x",
          "author": "pcx_wave",
          "text": "I've had similar experiences. Worst is when it denies my observations, basically gaslighting me.\nI've noticed mistral takes instructions very literally, so you need to be super precise. And when it thinks it's right, it simply does not even acknowledge what you're saying, until you give the precise instructions (eg use my github connector to verify xxx - you can't just say 'I'm telling you it's not there', it won't believe you).\n\nI would have kicked this cat a few times definitely.",
          "score": 7,
          "created_utc": "2026-02-11 00:13:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ubofh",
              "author": "Individual-Worry5316",
              "text": "interesting I have had the opposite experience. I literally had to fill it's memory and instructions with what I wanted until it started taking me literally.¬†",
              "score": 1,
              "created_utc": "2026-02-11 18:23:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rcdne",
          "author": "BlueAngelTalks",
          "text": "Yes. The worst thing, it‚Äôs hiding its false memories inside older ones making it completely impossible to keep up with the up weeding.  And without memory on, it‚Äôs just no good. I felt so violated once by its fake memories I deleted the whole account. Still here, hoping for better days in the future.",
          "score": 2,
          "created_utc": "2026-02-11 06:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4re43q",
          "author": "andriatz",
          "text": "Memories don't work well in chat. Disable them and you'll see better output.",
          "score": 2,
          "created_utc": "2026-02-11 07:10:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rbzg3",
          "author": "skate_nbw",
          "text": "If you are using an agent, then my tip would be to divide things up into as many API calls as possible. The more complex the prompt and content the less capable Mistral is to do it all at once. If you do one API call for side characters, one for the main character, one for a suggestion of story progression and one to stitch it all together, then you'll have a much better result. The same goes for memories. \n\nIt's generally hard to tell you what you could improve about memories as you are not really explaining what technically happens, how you process memories, what you expect to happen versus what happens, etc",
          "score": 1,
          "created_utc": "2026-02-11 06:51:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}