{
  "metadata": {
    "last_updated": "2026-02-07 02:58:04",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 181,
    "file_size_bytes": 180633
  },
  "items": [
    {
      "id": "1qvku2t",
      "title": "Mistral robotics team is hiring.",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/jnizqe6gdghg1",
      "author": "Nunki08",
      "created_utc": "2026-02-04 10:15:21",
      "score": 794,
      "num_comments": 21,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvku2t/mistral_robotics_team_is_hiring/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3i97r4",
          "author": "nycigo",
          "text": "Incredible, I love Mistral",
          "score": 45,
          "created_utc": "2026-02-04 10:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i9vcx",
          "author": "flololan",
          "text": "Damn that's really fast",
          "score": 41,
          "created_utc": "2026-02-04 10:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3idmua",
              "author": "Everlier",
              "text": "Likely teleoperated for the video, they have lots of stations, likely to collect training data for these",
              "score": -12,
              "created_utc": "2026-02-04 11:00:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ieu8o",
                  "author": "AdIllustrious436",
                  "text": "They claim it's autonomous at x1 speed in the video.",
                  "score": 12,
                  "created_utc": "2026-02-04 11:10:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iaxs3",
          "author": "InsideMikesWorld",
          "text": "Off topic, but how can I get Mistral Cat plushy!",
          "score": 35,
          "created_utc": "2026-02-04 10:36:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iaym5",
          "author": "johoham",
          "text": "Crazy to see what monitor stands can evolve to once theyâ€™ve scaled off their displays.",
          "score": 24,
          "created_utc": "2026-02-04 10:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iglq9",
          "author": "grise_rosee",
          "text": "No Elonâ€™s hype, no Boston Dynamics choreography, no *I, Robot*\\-style retro-futuristic humanoids. Just raw skills, plain and simple.",
          "score": 24,
          "created_utc": "2026-02-04 11:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iijw4",
          "author": "AriyaSavaka",
          "text": "That *le cat* is adorable",
          "score": 11,
          "created_utc": "2026-02-04 11:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3k0qnq",
          "author": "HIVVIH",
          "text": "I'm so freaking proud of the French and us Europeans right now. Let's freaking go!!",
          "score": 9,
          "created_utc": "2026-02-04 16:37:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3idjl0",
          "author": "Everlier",
          "text": "Absolutely incredible, so that's where the team was at. Can't wait for more updates on the research!",
          "score": 6,
          "created_utc": "2026-02-04 10:59:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iiqk4",
          "author": "No-Equivalent-2440",
          "text": "I love them ðŸ˜…",
          "score": 7,
          "created_utc": "2026-02-04 11:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kgpa9",
          "author": "No_Vehicle7826",
          "text": "We got robotics before TTS on LeChat ðŸ˜­",
          "score": 4,
          "created_utc": "2026-02-04 17:50:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ikaef",
          "author": "CactusJackpot",
          "text": "Very cool!!! Letâ€™s go",
          "score": 3,
          "created_utc": "2026-02-04 11:54:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iomn4",
          "author": "JuiceOwn313",
          "text": "Shame, I was expecting it to throw the backpack when done. And add sun glasses to the cat.\n\nJoke aside, very nice and well executed.",
          "score": 2,
          "created_utc": "2026-02-04 12:26:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3k186a",
          "author": "HandsomeHippocampus",
          "text": "Who's a good kitty? <3",
          "score": 2,
          "created_utc": "2026-02-04 16:39:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3losnc",
          "author": "Btbbass",
          "text": "What is the package ? What about full remote ?",
          "score": 1,
          "created_utc": "2026-02-04 21:15:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxzza",
          "author": "Fearless_Macaron_203",
          "text": "Awesome. I really want this company to do well :)",
          "score": 1,
          "created_utc": "2026-02-05 17:14:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ztu3y",
          "author": "New_World_2050",
          "text": "First impressive thing I've ever seen from Mistral.",
          "score": 1,
          "created_utc": "2026-02-06 23:56:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qws3tx",
      "title": "The mistral team does not get enough credit for their easter eggs",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/4v71jp3grphg1.jpeg",
      "author": "InsideMikesWorld",
      "created_utc": "2026-02-05 17:47:51",
      "score": 159,
      "num_comments": 8,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qws3tx/the_mistral_team_does_not_get_enough_credit_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3r6a3v",
          "author": "Tanuki__",
          "text": "I like also \"Eating a pain a chocolat...\" ðŸ˜‚",
          "score": 15,
          "created_utc": "2026-02-05 17:52:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3svbkh",
              "author": "ouesh35",
              "text": "Worst, i saw \"Eating a chocolatine...\"",
              "score": 5,
              "created_utc": "2026-02-05 22:42:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3v4cmy",
                  "author": "Tanuki__",
                  "text": "Oh no!",
                  "score": 1,
                  "created_utc": "2026-02-06 07:25:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3rqfrv",
          "author": "sndrtj",
          "text": "Petting le chat....",
          "score": 9,
          "created_utc": "2026-02-05 19:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r5kye",
          "author": "Sudden-Armadillo-335",
          "text": "Where did you find that? ðŸ˜‚",
          "score": 3,
          "created_utc": "2026-02-05 17:49:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r7n9r",
              "author": "InsideMikesWorld",
              "text": "Itâ€™s one of the possible texts that comes up in vibe CLI when the model is processing",
              "score": 8,
              "created_utc": "2026-02-05 17:58:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3r7uih",
                  "author": "Sudden-Armadillo-335",
                  "text": "No, that's stylish ðŸ˜‚",
                  "score": 1,
                  "created_utc": "2026-02-05 17:59:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3uboe5",
          "author": "Mystical_Whoosing",
          "text": "But also feels like their target audience speaks French? So they don't want anyone else to sub",
          "score": -6,
          "created_utc": "2026-02-06 03:47:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvrd99",
      "title": "Voxtral transcribes at the speed of sound",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvrd99/voxtral_transcribes_at_the_speed_of_sound/",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-04 15:21:52",
      "score": 158,
      "num_comments": 16,
      "upvote_ratio": 0.99,
      "text": "Today, we are excited to release **Voxtral Mini Transcribe 2** and **Voxtral Mini 4B Realtime**. Transcribe 2 builds on our previous generation with **higher performance** and new features: **Diarization**, **Word Segmentation with Timestamps**, and **Context Biasing**. We are also excited to release **Voxtral Mini 4B Realtime** under an Apache 2.0 license - a **streaming** transcription model with high accuracy and configurable chunk delays, allowing you to balance quality and latency according to your needs.\n\n[Voxtral Transcribe and Voxtral Realtime Performance](https://preview.redd.it/m01oww6srhhg1.png?width=2621&format=png&auto=webp&s=63f38e467245a307e7da0a1e309c27112149610e)\n\n* **Voxtral Mini Transcribe 2**: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.\n* **Voxtral Mini 4B Realtime**: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.\n* **Best-in-class efficiency**: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.\n* **Open Weights**: Voxtral Mini 4B Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.\n   * HF Weights: [mistralai/Voxtral-Mini-4B-Realtime-2602](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602)\n\n*You can test Voxtral Mini Transcribe 2 directly in* [*Mistral Studio*](https://console.mistral.ai/build/audio/speech-to-text)*. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.*\n\nLearn more about Voxtral in our blog post [here](https://mistral.ai/news/voxtral-transcribe-2)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvrd99/voxtral_transcribes_at_the_speed_of_sound/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3jqphc",
          "author": "Living_Procedure_599",
          "text": "Just tested it. Actually works like magic. Surprised how accurate it is.",
          "score": 17,
          "created_utc": "2026-02-04 15:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kgi23",
          "author": "Comacdo",
          "text": "So is this finally a better thing than whisper ?? So cool !",
          "score": 11,
          "created_utc": "2026-02-04 17:49:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lpzlw",
              "author": "Basic-Love8947",
              "text": "Is it really? Would be great to switch",
              "score": 1,
              "created_utc": "2026-02-04 21:21:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3osu1b",
              "author": "LearningPodd",
              "text": "That's fantastic! And happy cake day! ðŸ°",
              "score": 1,
              "created_utc": "2026-02-05 09:15:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3k6ys9",
          "author": "Downtown-Elevator369",
          "text": "I have been trying so many different workflows to transcribe meetings and classes. My fingers are crossed that this is the one I can settle on!",
          "score": 4,
          "created_utc": "2026-02-04 17:05:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lz9h0",
          "author": "lovebzz",
          "text": "It's pretty impressive. I've been struggling to find a tool to transcribe some interviews I did for a documentary project that were mixed-language (English + Vietnamese). Voxtral did them in seconds and they look pretty accurate.",
          "score": 2,
          "created_utc": "2026-02-04 22:05:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m47ll",
              "author": "--Tintin",
              "text": "Have you used it via mistral website or via a tool on Mac/windows? Iâ€™m asking as I havenâ€™t find an app which includes voxtral. Would be great for speaking recognition /embedding.",
              "score": 2,
              "created_utc": "2026-02-04 22:30:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3m4hxt",
                  "author": "lovebzz",
                  "text": "No, I just uploaded audio files to Mistral AI Studio.",
                  "score": 1,
                  "created_utc": "2026-02-04 22:31:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3kprqm",
          "author": "LoadZealousideal7778",
          "text": "Well, they are apparently not using it in the Le Chat app because the voice option there is just... Broken.",
          "score": 2,
          "created_utc": "2026-02-04 18:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pksxk",
          "author": "Bright-Celery-4058",
          "text": "well done mistral team !  \ni am interested in the context biasing + word level timestamp but the API doc is missing those advertised new features. Also the max audio length needs to be updated (15min was for the V1, V2 claims 3h)Â [https://docs.mistral.ai/capabilities/audio\\_transcription#transcription](https://docs.mistral.ai/capabilities/audio_transcription#transcription)",
          "score": 1,
          "created_utc": "2026-02-05 13:05:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pwnvt",
              "author": "pandora_s_reddit",
              "text": "Sorry for the experience, doc will be updated shortly - but word level timestamp you can simply set `timestamp_granularities=[\"word\"]` and work out of the box",
              "score": 1,
              "created_utc": "2026-02-05 14:13:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q0nxs",
                  "author": "Bright-Celery-4058",
                  "text": "thanks !",
                  "score": 1,
                  "created_utc": "2026-02-05 14:35:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qkdg0",
                  "author": "Bright-Celery-4058",
                  "text": "i just tried it in mistral ai studio, segment level works but not the word level ;)",
                  "score": 1,
                  "created_utc": "2026-02-05 16:11:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3qfnhw",
          "author": "Vroedoeboy",
          "text": "I get no model response in both Mistral Console and through API.",
          "score": 1,
          "created_utc": "2026-02-05 15:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qrrx8",
          "author": "nhatnv",
          "text": "Segment timestamp is not accurate. I tried an audio of 2 minutes but some segment timestamps are 2:20...",
          "score": 1,
          "created_utc": "2026-02-05 16:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kko34",
          "author": "Visible_Forever_7636",
          "text": "Many of the models fail to catch the entities of Indian languages. Does it work good on them ?",
          "score": 1,
          "created_utc": "2026-02-04 18:08:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrw16s",
      "title": "Mistral Vibe 2.0 vs Codex 5.2 & Claude (Opus 4.5) - First Impressions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "author": "l_eo_",
      "created_utc": "2026-01-31 07:34:06",
      "score": 157,
      "num_comments": 38,
      "upvote_ratio": 0.96,
      "text": "Spending most of my time on Claudeâ€™s Max 20x plan (Opus 4.5) and occasionally hitting my weekly limits, I decided to revisit **Mistral Vibe 2.0** and **Le Chat** after a long break. Here are my first impressions, especially compared to Opus 4.5 and Codex CLI.\n\n---\n\n### **1. Codex CLI (5.2), Underwhelming First Impressions**\n\nI tested Codex in a structured folder with lots of context (files, scripts, and dedicated system for specific workflows that are to be followed). On first prompts and even after instructing it to analyze the **folder context**, it struggled to understand or comply and generate based on an understanding of the surrounding context. It felt less like a true CLI tool and more like a system just inlining requests without grasping the environment. Big asterix: It's also my first time trying codex and I need to explore it more, but the first results were disappointing.\n\n---\n\n### **2. Mistral Vibe 2.0**\n\nReally great first impression, I was very pleasantly surprised!\n\nIt really stood out was how thoroughly Mistral Vibe 2.0 tried to understand the context first (even without being told to do so). It didnâ€™t just jump into answering; it checked the surrounding files, analyzed available examples, and tried to understand what a good outcome would look like before starting to work.\n\nAnd I was blown away by how **fast** Mistral Vibe 2.0 is. The response generation is so quick that I canâ€™t even read along as it outputs. This is a game-changer for feedback loops. While I of course believe that Claude Opus 4.5 is currently the king for coding and complex tasks, Iâ€™ll be testing Mistral Vibe 2.0 much more for coding and general tasks to see how it performs. For everyday structured tasks, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system**.\n\n---\n\n### **3. Le Chat App**\nThe Le Chat app has improved significantly since I last tried it:\n* Voice input is now a thing, and itâ€™s seamless! (Claude struggles a lot with this) When I last used Le Chat, this feature didnâ€™t even exist. I tested it with a long, multi-minute transcription, and the accuracy was impressive. I did a few feedback rounds, and Mistral applied my edits smoothly. Iâ€™m not sure how they made it *that* fastâ€”**the turnaround times for voice transcription and immediate answers are incredibly impressive**.\n* Online research seemed also to work great  and possibly now on par with ChatGPT?\nIâ€™m not even sure yet what other awesome features and UX additions there are, but Iâ€™m excited to explore further.\n\n---\n\n### **4. Potential Switch?**\nGiven Mistralâ€™s speed, UX, and awesome voice transcription, etc, Iâ€™m seriously considering making Le Chat + Mistral Vibe 2.0 my daily driver for everyday tasks and as a fallback when Claudeâ€™s limits kick in (and Le Chat possibly always preferred because of the speed and the great voice transcription in multiple languages). Iâ€™ll test-drive it for a few days, and if it proves as powerful as I hope (writing this as a \"wow, just tried this\" post, so maybe lots of honey moon phase involved), I might cancel my ChatGPT subscription and make Le Chat my main driver for everyday use.\n\nIâ€™m all for EU digital sovereignty, so supporting Mistral feels like a win-win and I am incredibly happy & excited about all the progress being made.\n\n---\n\n**TL;DR:**\n\n* **First rough impressions**: Just excited to share my initial enthusiasm for Mistral Vibe 2.0 and Le Chat after revisiting them.\n* **Codex CLI** felt underwhelming as a CLI tool, especially with folder context. Not sure about code quality and similar yet (also very first impression).\n* **Mistral Vibe 2.0** impressed with speed and context handling; Iâ€™ll test it more for coding.\n* **Le Chat app** now includes voice input and shines with great transcription quality, incredible speed (game changer for back and forth loops), and online research\n* While **Opus 4.5 likely remains unmatched for coding**, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system** for everyday tasks.\n\n\nBig thank you to the Mistral team for all the hard work! Rooting for you big time â™¥ï¸ðŸ‡ªðŸ‡º!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2teisq",
          "author": "Mr_Finious",
          "text": "As a US citizen, I'm considering Mistral because I trust the EU's privacy protections to better protect me than those of US or Chinese companies. \n\n\n\nWe should all be clapping for companies like Mistral in the EU.",
          "score": 7,
          "created_utc": "2026-01-31 16:56:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r8s37",
          "author": "l_eo_",
          "text": "Collecting new findings here as I continue testing: \n\n* I am not super happy with it being pretty hard to copy from the CLI progress. Often I need to \"reply\" to something the agents do and the UX loops around that are crucial. It's pretty bad at the moment, the UI needs a long time to react and seems to include some automatic \"copied!\" feature, that appears very late multiple times and that I don't really care about. Easy direct select -> right click -> copy would be best and should be fast and fluid. That's a \"small\" thing that makes a **huge** difference. \n* Scrolling can also be pretty sluggish (very very late start and keys like 'end' also have many seconds of delay). Possibly tracked here: https://github.com/mistralai/mistral-vibe/issues/222\n* There must be a specific system in place for interruptions? The agent reacted much faster than Claude Code Opus to a \"no\" during generation. Basically almost immediate stop\n* CLI text input seems a bit sluggish when much is happening\n* Context usage seems to go up fairly slowly. Not sure if that's a good or bad thing (testing it for some coding right now).\n* Every response / input during generation seems to be treated as an interruption (so no \"next task queuing\" like with Claude Code). Maybe there is a way to queue?",
          "score": 7,
          "created_utc": "2026-01-31 07:59:41",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2rboh5",
              "author": "l_eo_",
              "text": "I really need to stress that so many gains are to be made \"easily\" by improving the UX of the base-line elements that make up the workflow with the CLI tool. \n\nCopy & paste / reacting / replying, how fast typing is, and how responsive scrolling is are just a few facets of this.\n\nUX improvements make a huge difference if the basic quality of the model output is good enough.\n\nI will look into contributing: https://github.com/mistralai/mistral-vibe/blob/main/CONTRIBUTING.md",
              "score": 11,
              "created_utc": "2026-01-31 08:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r7wv2",
          "author": "ZapojKabel",
          "text": "I am interested at the coding using now heavily modified Gemini CLI and quite happy with, but rather use European tool. Does mistral have api key pay as you go and picture generate?",
          "score": 5,
          "created_utc": "2026-01-31 07:51:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9lfq",
              "author": "l_eo_",
              "text": "Interesting, in what way did you modify the Gemini CLI? \n\nI must say, that I was always very unhappy with Gemini output regarding code and it often seeming to \"fight\" me / gaslight me or somehow trying to avoid following instructions. Especially in the last weeks instruction following was pretty much non-existent for the few tests I did and I have been avoiding it ever since. \nBut I also mostly used the web interface so far, so maybe it's a different story with the CLI. \n\nI would have very much recommended Claude Code with Opus 4.5 and used to be *insane* around release / December, but has deteriorated massively in terms of quality the last few weeks. Possibly due to a switch from Google GPUs to the ones they developed with AWS, but not sure.  \nStill, it is very much worth a try if you go for the 5x or 20x max plans (they are very worth it). API pricing would be incredibly expensive (easy to burn through 20-80 bucks an hour). \n\nRegarding your questions: \nYes, API key pay as you go exists and I think the subscription now also included some vague notion of \"full day coding\"? \n\nPicture generate would likely mean an additional model, but that should be easy to integrate into your workflow (e.g. continue using Gemini's very powerful nano-banana-pro or flux).\n\nGreat to hear that you care about European tools!",
              "score": 5,
              "created_utc": "2026-01-31 08:07:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rngmy",
                  "author": "ZapojKabel",
                  "text": "Well I have my boss I call him Nexus he delegate my task to other agents ( I use mostly three for design, code and advertising expert). Every plan I make all 3 discuss how to do and should work, when it is done the 4 agent step in it is called Sentil \"devil advocate\" a trying to find error in there reasoning and aks question \"if...\". When there settle and I agree, Nexus make track list in conductor with plan how to setup. Also use RAG. I am not coder but make app for my e-shop. https://harmony.nonchalant.cz and also now making app for manager stuff on my eshop and dashboard for better statistic on sale etc.\nEdit: also Avery agent must use TOT protocol",
                  "score": 3,
                  "created_utc": "2026-01-31 10:19:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ul5uq",
              "author": "vienna_city_skater",
              "text": "If you have Le Chat Pro you get Devstral included.",
              "score": 1,
              "created_utc": "2026-01-31 20:20:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2recbg",
          "author": "EzioO14",
          "text": "I use le chat pro for all normal chat questions and I have claude max for coding",
          "score": 5,
          "created_utc": "2026-01-31 08:51:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2reopc",
              "author": "l_eo_",
              "text": "That's my plan as well :)\nI love the snappyness of Le Chat. \n\nIs Le Chat strict enough with sources? So doesn't hallucinate if no information found via web search?",
              "score": 2,
              "created_utc": "2026-01-31 08:55:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rer8d",
                  "author": "EzioO14",
                  "text": "I find it gets better, I was very disappointed at first, last month when I started but now I find the answers better and better",
                  "score": 2,
                  "created_utc": "2026-01-31 08:55:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r8a66",
          "author": "Bato_Shi",
          "text": "Only thing i noticed with Vibe is that sometimes it falls into infinite loops, like gemini 3 some months ago",
          "score": 5,
          "created_utc": "2026-01-31 07:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9n86",
              "author": "l_eo_",
              "text": "Should be easy to break it out of though, right? \nHow often does it happen?",
              "score": 1,
              "created_utc": "2026-01-31 08:07:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2syc21",
                  "author": "kiwibonga",
                  "text": "An example I had yesterday (Devstral Small 2 Q4) is it found that a regular expression wasn't capturing strings properly in a test, so it tried to fix the pattern, but it turned out to be a basic escaping issue rather than an error in the regex. It didn't realize that, so it added more and more characters to the pattern until it was huge -- without ever thinking \"is this overkill? That looks weirdly huge\" even though the purpose of the code was just to make sure a line starts with the word \"AGENT:\".\n\nThis is something that could have been autonomously fixed with an orchestrator that includes failure analysis, sees the blind spot, and proposes an alternate approach before launching another attempt. A reasoning model might also have a much easier time course-correcting.\n\nI was using the CLI by itself so I just said \"try to simplify the regular expression by writing it from scratch, and if it still fails, just write a parser\" -- it failed fast and wrote a parser, then got back to work.",
                  "score": 1,
                  "created_utc": "2026-01-31 15:39:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2rpkx3",
              "author": "Gen5nake",
              "text": "I also had this issue once",
              "score": 1,
              "created_utc": "2026-01-31 10:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ra7pr",
          "author": "theschiffer",
          "text": "Very interesting review. What does your day-to-day workload look like and in what ways do you generally use AI?",
          "score": 2,
          "created_utc": "2026-01-31 08:13:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rarwz",
              "author": "l_eo_",
              "text": "Workload in terms of volume of usage? \n6-14 hours of multiple terminal tabs with claude processes. \nAI is used as a partner both for planning as well as for execution. Often planning and getting everything prepared for implementation takes up most of the time (e.g. 4 hours planning and adapting and architecture work, 2 hours implementing and adapting / fixing), but it depends a bit on what phase a project is in. \n\nDoes this answer your question fully?",
              "score": 3,
              "created_utc": "2026-01-31 08:18:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tmt2r",
                  "author": "theschiffer",
                  "text": "Nice. So essentially, youâ€™re a software developer/architect? Thatâ€™s quite an intensive level of use.",
                  "score": 1,
                  "created_utc": "2026-01-31 17:36:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rae0d",
          "author": "Hot_Bake_4921",
          "text": "Does Le chat still use mistral medium 3.1?",
          "score": 2,
          "created_utc": "2026-01-31 08:14:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcns6",
              "author": "l_eo_",
              "text": "I am trying to find some information about this, but this proves to be surprisingly hard? Nothing in the change logs and most Reddit discussions about this seem to be from quite long ago.",
              "score": 2,
              "created_utc": "2026-01-31 08:36:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2tqeke",
          "author": "Sorry_Role_1701",
          "text": "What Iâ€™m noticing with newer models like Mistral isnâ€™t about benchmarks anymore.\n\nThe real difference is **i**nteration speed, how fast you can refine an idea without restarting context every time.\n\nIn workflow-heavy tasks, that matters more than raw output quality.",
          "score": 2,
          "created_utc": "2026-01-31 17:54:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wlr2d",
              "author": "mWo12",
              "text": "Off course they are not about benchmarks, as they have nothing to show.",
              "score": 2,
              "created_utc": "2026-02-01 02:55:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34c59l",
                  "author": "Sorry_Role_1701",
                  "text": "I totally agree with your observation.  \nIteration speed and seamless context flow are becoming *way more important* for practical workflows than just raw output quality or benchmark scores  especially when youâ€™re refining ideas or building on previous results without restarting everything.\n\nIn my experience with Vibe (and similar tools, ChatGPT), when the model keeps context and lets you iterate fast, it *feels* more productive even if raw numbers arenâ€™t leading â€” because in real usage you spend less time repeating setup and more time building on progress.",
                  "score": 1,
                  "created_utc": "2026-02-02 07:44:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r7fxx",
          "author": "l_eo_",
          "text": "As I wrote, I am completely newly back again with Mistral vibe. \nAny optimizations / settings I should immediately go for?",
          "score": 1,
          "created_utc": "2026-01-31 07:47:20",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2r85ap",
          "author": "stjepano85",
          "text": "It is very good for agentic development. It has some problems with recursive algorithms and it can go crazy when his context is large (this can be solved by limiting context in vibe configuration).",
          "score": 1,
          "created_utc": "2026-01-31 07:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rayhx",
              "author": "l_eo_",
              "text": "Interesting! \nWhat level do you recommend limiting context to?",
              "score": 1,
              "created_utc": "2026-01-31 08:19:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rcdgm",
                  "author": "stjepano85",
                  "text": "128k should be good. I noticed at 70+% of the default 200k its performance drops significantly.",
                  "score": 2,
                  "created_utc": "2026-01-31 08:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rcps1",
          "author": "nycigo",
          "text": "For voice input, press Windows + H; this will automatically transcribe your microphone input if you are using Windows 11.",
          "score": 1,
          "created_utc": "2026-01-31 08:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcu1q",
              "author": "l_eo_",
              "text": ":O \n\nIn the CLI for mistral vibe?",
              "score": 2,
              "created_utc": "2026-01-31 08:37:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rhxqy",
                  "author": "nycigo",
                  "text": "Anywhere on Windows, anywhere your mouse is located",
                  "score": 1,
                  "created_utc": "2026-01-31 09:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wll72",
          "author": "mWo12",
          "text": "I tested Mistral Vibe 2.0, but I found it so slow, and I'm not talking about token generation. Just the CLI interface is so slow and sluggish. Maybe because it is all python, unlike other agents.",
          "score": 1,
          "created_utc": "2026-02-01 02:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xo0zs",
              "author": "l_eo_",
              "text": "100% and this is my biggest issue with it right now and a real blocker. \nYou can see the kind of potential it has when starting a new session, but it gets bogged down fast. \nFor me personally these would a \"don't release before fixed\".  \n\nBut I am also very optimistic that this will be improved soon, because relatively speaking, these rendering issues should be quite straightforward to fix, so I really hope Mistral will make them a priority.",
              "score": 1,
              "created_utc": "2026-02-01 07:36:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31bvsf",
          "author": "BastFX",
          "text": "Hey ! Thanks for this detailed review ðŸ‘Œ\nI never used vibe-code tools like this one, but i'm following news about all that world.\nThe most famous tool Claude Code on this category needs Claude.md file, I would like to know if Mistral need something similar to work properly ? What structure build in this file ? I checked the official documentation but any information about that, or I missed it ...",
          "score": 1,
          "created_utc": "2026-02-01 20:48:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37go5l",
          "author": "Sweaty-Special-1710",
          "text": "I really like Vibe. I feel it's almost as good as claude, way cheaper, I'm not concerned with usage limits, it works by being very directive, and it feels really fast.",
          "score": 1,
          "created_utc": "2026-02-02 19:13:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxpmrw",
      "title": "Europe can still be competitive in AI - Mistral should take a part in it",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qxpmrw/europe_can_still_be_competitive_in_ai_mistral/",
      "author": "Silver_Procedure538",
      "created_utc": "2026-02-06 18:26:58",
      "score": 119,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "Iâ€™m sharing my thoughts and an initiative hereâ€”I hope it doesnâ€™t come across as spam, but Iâ€™d love to spark a discussion.\n\nI often hear that Europe is hopelessly behind in AI (and not just in AI, by the way). While itâ€™s undeniable that thereâ€™s a gap, Mistralâ€™s Devstral 2 model scores 72.2 on SWE-Bench verified, matching the performance of Claude Opus 4, which was released 7 months earlier.\n\nWe could argue that Mistral is only 7 months behind, despite:\n\n* BudgetsÂ **tens of times smaller**.Â **Mistral has raised about $3B, while OpenAI has $58B, Anthropic $37B,**Â Meta plans to spend $115B in 2026 alone, and xAI secured $5B just as seed funding.\n* No access to massive data centers and higher European energy costs.\n* Limited data compared to Google and others.\n\nSeven months is nothing, and coding performance is one of the best predictors of future success.\n\nAssuming the main issue is capital, how can we attract it? Iâ€™ve thought about this and believe this proposal is feasible:\n\n* Create a large government fund, similar to Norwayâ€™s pension fund, withÂ **voluntary participation from European and non-European countries**.\n* With a modest investment (<0.5% of GDP),Â **we could unlock â‚¬100-300B**â€”a huge sum compared to current European investments.\n* The fund would invest in local innovative AI companies, support a CERN for AI, build data centers (e.g., in Norway or Canada, where energy is cheap), and fund future technologies like robotics.\n* By leveraging private investments, which would surely follow, we could reach even higher figures.\n\nWhat do you think? Iâ€™m interested in your opinions.\n\nIn my view, the benefits would be enormous:\n\n* Competitive European AI on par with the US and China.\n* Partial public control over a technology that could become dangerous.\n* Wealth creation here.\n\nAll this at a manageable initial cost, shared among many countries, and likely to pay off in the coming years with potentially massive returns.\n\nMini-spam: Since talking is good but action is better, some friends and I have createdÂ [a petition](http://openpetition.eu/!swjml)Â andÂ [a website](https://ai-movement.org/)Â to push this project forward. If youâ€™re interested, Iâ€™d be thrilled, but either way, I hope this sparks a meaningful discussion.\n\n[](https://www.reddit.com/submit/?source_id=t3_1qs3bbw)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qxpmrw/europe_can_still_be_competitive_in_ai_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3y9e6b",
          "author": "cosimoiaia",
          "text": "I would mostly agree with some exceptions.\n\nI believe the gap is mostly cultural more than technological, we have extraordinary talents but the corporate business mindset is slowing everything down. They hold all the capital and have very low tolerance to risk and too long term cycles. Things have been slowly improving for the last 10 years but it's not even remotely at the pace everyone else is.\nIf you feel tech hubs like Berlin, Paris, Amsterdam they have very little to envy to others except for access to VCs.\n\nI don't want to be negative with your initiative but it's very highly unlikely that a sovereign fund or crowd capital is going to make any difference at scale (it can still get results but things don't snowball here), they move too slow and the tolerance for risk is too low.\n\nThat being said, Mistral IS competitive in the AI landscape, and IS spearheading it. Their tech is amazing across the board and they have key advantages that others cannot reach. There are other entities (that I can't name without doxxing myself too much) in the EU that are rock solid as well. \n\nSo I wouldn't talk in terms of hypotheticals. \n\nI would say let's keep running, we can already breath on their necks (otherwise we wouldn't see so much FUD spreading posts in here).",
          "score": 15,
          "created_utc": "2026-02-06 19:05:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yi824",
              "author": "Silver_Procedure538",
              "text": "Thank you for your answer!\n\nIn your view, even if massive investment manage to have short term effect on the long term it will not matter because of a cultural gap in term of risk tolerance?\n\nI agree it's not impossible. At the same time I can't think of anything better. Do you think we have a better chance?\n\nI also think public investment like these can easily repay the investment itself: if you consider a conservative private investment of the same order that will follow a public one and consider taxes + VAT you probably already almost repay the investment without even considering returns.\n\n",
              "score": 1,
              "created_utc": "2026-02-06 19:49:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3yo4nh",
                  "author": "cosimoiaia",
                  "text": "The other way around, the low risk tolerance seeks steady long lasting results and keeps from reaching velocity. In other words, \"go slow and don't fail\" is preferred to \"fail fast and learn\".\n\nI totally agree that public investments would easy pay for itself in this global growth. I think that theoretically we need a 'Berlin' framework fueled by VCs that are willing to endure short term pain and double down when things are uncertain, unfortunately this practically never goes well with public money. \n\nBut I think something in the effect of 'collect a billion and give it to Mistral' can be a good idea, the hard part is setting the terms so it is an acceptable agreement for both sides.",
                  "score": 2,
                  "created_utc": "2026-02-06 20:18:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3zxnp3",
              "author": "ItsCalledDayTwa",
              "text": "Am I crazy or does Mistral consistently have some of the best bang for the buck models available?",
              "score": 1,
              "created_utc": "2026-02-07 00:18:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o40epjr",
                  "author": "cosimoiaia",
                  "text": "It depends what you consider but for the amount of compute, money, data and diversification they have to cover, they definitely do. \n\nThey are not a small lab thou, their engineering teams are very very solid and it's basically a 'big' company now (there are much smaller labs that still publish solid models even if not at Mistral's level).\n\nI don't have any inside data but I bet they shred to pieces openai/Anthropic/Google in terms of results over money.",
                  "score": 1,
                  "created_utc": "2026-02-07 02:01:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y6c0p",
          "author": "Dario24se",
          "text": "I work for public administration in the tech field. Most of the people who have the right to make money decisions are completely ignorant about software and hardware in general, and the people who do know what ai is and what it does, are scared to take action cause of the lack of actual engineers / money to make it usable. The results are bullshit corporate open source rebranded software, which doesn't even compare with what Mistral could get you done in a week of configuration for 1/8 the price.\nThere is no hype about Mistral between white collars, there is no love from European countries because we are still behaving as separate nations and we are also really behind with tech in general. \n\nOld people's experiences and wallets should side with young people's ideas. That's the way to go.",
          "score": 6,
          "created_utc": "2026-02-06 18:51:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yhfy4",
              "author": "Silver_Procedure538",
              "text": "Yes I agree. This is necessary: \"Old people's experiences and wallets should side with young people's ideas\"\n\nDo you think an initiative like the one in the link has hope to succeed?",
              "score": 1,
              "created_utc": "2026-02-06 19:45:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y8zvu",
          "author": "deniercounter",
          "text": "Well â€¦ As senior dev codestral:22b from 2 years ago with mxml- server was literally the ONLY model that gave SURPRISINGLY good results. \n\nBackground: Installed qwen-code-next for local use -> unusable on 64GB M2 Max",
          "score": 3,
          "created_utc": "2026-02-06 19:04:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z5xro",
          "author": "FitikWasTaken",
          "text": "I suggest you to post/crosspost it on r/accelerate too, seems to align well with what you're proposing",
          "score": 3,
          "created_utc": "2026-02-06 21:47:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zus7q",
          "author": "astrology5636",
          "text": "Good initiative! The problem is that the gap is widening. Devstral 2 is a joke compared to CC with Opus 4.6 and Codex with GPT 5.3. Let's be clear Kimi K2.5 also destroys Mistral. When scale is the most important differentiator, Europe and Mistral can only be competitive if they start investing as much as US/China. That said, there is a place for Mistral as the top European AI company, even if it is not SOTA, and Europe can dominate on other fronts (like research but also regulations, yes it will be important to have solid regulatory framework for AI).",
          "score": 2,
          "created_utc": "2026-02-07 00:02:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3zvz1j",
          "author": "LordLederhosen",
          "text": "The latest speech to text model that Mistral just released appears to be better than any other model out there.\n\nI know there are lots of cultural issues regarding investment in the EU, but holy crap. The technology is speaking for itself. I just wish they had more languages in Voxtral Transcribe 2.",
          "score": 1,
          "created_utc": "2026-02-07 00:09:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qteixn",
      "title": "I love Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "author": "Potential_Block4598",
      "created_utc": "2026-02-01 23:31:42",
      "score": 85,
      "num_comments": 16,
      "upvote_ratio": 0.99,
      "text": "This is my second post in a long time praising mistral \n\nSo earlier I praised how they train objective models that services Le Mistral \n\nNow I am doing this again, but as I am running and switching between many models for local agentic tasks (using an agent scaffold and and MCP to perform basic static malware analysis tasks for cybersecurity that is essentially copy pasting to and from an LLM model in an automated way!) \n\nI tried many things \n\nFirst â€œfrontierâ€ (local frontier for my setup) according to artificial analysis aggregated benchmarks (that should include tool call, and not just demonstrative tool call but actual consistent real-life tool call!) (note I always wondered why Devstral ranked too low on that benchmark (either the model is too weak or the benchmark is too weak!!!!)\n\nSo I tried \n\nGPT-OSS (both on all kinds of Thinking effort options)\n\nWeird failures (sometimes call format not correct especially when used with cline and/or Goose!) \n\nAnd no instruction following (not even loose instruction following, or proper task management , so they donâ€™t live well inside the scaffold environment (some code todo management complex prompt and things like that!) \n\nGLM-4.7-Flash\n\nSimilar story \n\nThen Cline docs and Jack Dorsey mentioned Qwen3 Coder, I scratch my head why is that small seemingly insignificant model recognized by them no idea\n\nI try it and lo and behold it works very well than others\n\nSo it is not an agent problem or me dosing misconfiguration, these other open models arenâ€™t desgined for that (and for good reasons form the companies perspective)\n\nI am thinking of trying\n\nMinimax M2.1 or GLM-4.5-Air \n\nBut then I think about using Devstral Small 2\n\nAnd it works better than a charm finishes the task methodologically and analyzes the whole sample in like 3-5 hours \n\nA task that would have taken a junior around a month maybe (still a junior can do other stuff but maybe it dis. Better of MCP becoming exposed by default \n\nAnyways thanks Mistral Team for your awesome model and contributions to the open \n\nTL;DR\n\nDevstral Small 2 is the best for Local LLM agentic tasks (beyond being compared to others!)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o32cdeb",
          "author": "iongion",
          "text": "Is there a possibility to run it/configure it in claude code like it is possible with zai GLM ?",
          "score": 2,
          "created_utc": "2026-02-01 23:54:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33lf5o",
              "author": "lundrog",
              "text": "Should be easy. Can also use a api gateway like https://github.com/looplj/axonhub",
              "score": 3,
              "created_utc": "2026-02-02 04:13:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35ctlk",
                  "author": "iongion",
                  "text": "Thanks man, these things appear out of nowhere",
                  "score": 1,
                  "created_utc": "2026-02-02 13:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o32i448",
              "author": "Potential_Block4598",
              "text": "Havenâ€™t tried that yet",
              "score": 2,
              "created_utc": "2026-02-02 00:26:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3726pq",
              "author": "erizon",
              "text": "It is far easier, just set few environment variables:\n\n    ANTHROPIC_BASE_URL=\"https://api.z.ai/api/anthropic\" \\\n    API_TIMEOUT_MS=\"3000000\" \\\n    ANTHROPIC_DEFAULT_HAIKU_MODEL=\"glm-4.5-air\" \\\n    ANTHROPIC_DEFAULT_SONNET_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_DEFAULT_OPUS_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_AUTH_TOKEN=\"8xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxo\" \\\n    claude",
              "score": 2,
              "created_utc": "2026-02-02 18:08:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o378ib9",
                  "author": "iongion",
                  "text": "But thats what i do, i wanted the same but with devstral/mistral official ones",
                  "score": 1,
                  "created_utc": "2026-02-02 18:36:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o33xky0",
              "author": "nycigo",
              "text": "Yes, 100% ask Claude for the code ðŸ˜‚",
              "score": 0,
              "created_utc": "2026-02-02 05:39:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o33bmmj",
          "author": "aaronr_90",
          "text": "What are your thoughts on Qwen3 Coder vs Devstral Small 2?",
          "score": 2,
          "created_utc": "2026-02-02 03:13:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w52x",
              "author": "Potential_Block4598",
              "text": "Devstral can continue for longer without my interaction and can correct itself if it faces an issue while Qwen would just loop trying the same mistake again and again and failing\n\nOn the other hand Devstral is slower",
              "score": 1,
              "created_utc": "2026-02-02 05:28:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33xnzm",
                  "author": "nycigo",
                  "text": "It's super fast via API, but I don't know about local processing.",
                  "score": 1,
                  "created_utc": "2026-02-02 05:40:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33i840",
          "author": "former_farmer",
          "text": "In which hardware are you running this?",
          "score": 1,
          "created_utc": "2026-02-02 03:53:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w6f1",
              "author": "Potential_Block4598",
              "text": "AMD Strix Halo\n\nNot the best I guess but it kinda works",
              "score": 1,
              "created_utc": "2026-02-02 05:28:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o348o0p",
          "author": "SourceCodeplz",
          "text": "I don't see the harness that you used? How did you work with Devstral? Inside what tool?  \nI see you say about MCPs, but in what tool?",
          "score": 1,
          "created_utc": "2026-02-02 07:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36b3u9",
          "author": "nico_aka_redcat",
          "text": "What resource do you have to run devstral locally ?",
          "score": 1,
          "created_utc": "2026-02-02 16:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32fqii",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -5,
          "created_utc": "2026-02-02 00:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32gss6",
              "author": "cosimoiaia",
              "text": "Others do what they think it's best for you, Mistral does what you actually say.\n\n(It's my experience too, it has always been the best instruction following model of all)",
              "score": 6,
              "created_utc": "2026-02-02 00:19:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o32i1gy",
              "author": "Potential_Block4598",
              "text": "There is a TL;DR\n\nBest model for local agentic ai stuff",
              "score": 3,
              "created_utc": "2026-02-02 00:25:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwmszj",
      "title": "How is Mistral so awesome in comparison to other AI?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qwmszj/how_is_mistral_so_awesome_in_comparison_to_other/",
      "author": "SoWhoAmIReallyHuh",
      "created_utc": "2026-02-05 14:31:55",
      "score": 74,
      "num_comments": 34,
      "upvote_ratio": 0.77,
      "text": "Like, how do the guys from Mistral make it so fast and intelligent? Everything is superior to the other AI companies. Le Chat is faster, produces more relevant content, produces better images, is friendlier, is more respectful. If they add video generation, this will be it. It will be game over for all the other companies. Mistral will reign supreme.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwmszj/how_is_mistral_so_awesome_in_comparison_to_other/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3q56ji",
          "author": "Select_Ad_390",
          "text": "I just gave the same deep research task (research on a stock and company) to both Mistral and Gemini. \n\nMistral didnâ€™t even red the latest result report from last month, only cited as far as q2 2024). \n\nI really want Mistral to win as a European company, but sometimes itâ€™s embarrassing. \n\nDonâ€™t get me wrong , other times itâ€™s very good, but the lack of consistency is really stopping me from using it for more complex use cases. \n\nAnybody have any ideas?",
          "score": 68,
          "created_utc": "2026-02-05 14:58:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qgmex",
              "author": "Wise-Artichoke-3808",
              "text": "I had similar feeling. Truth to be told many time it blows my mind how good and relevant output it gives. Other times its incomprehensibly garbage.. I noticed many times, it does not read / index webpages I inquire about just reads the search result headlines / descriptions and infers the rest. \n\nI would prefer Mistral if it would not be soo volatile. ",
              "score": 9,
              "created_utc": "2026-02-05 15:53:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3qtfse",
              "author": "KonserveradMelon",
              "text": "Yep. I honestly think itâ€™s the worst chatbot Iâ€™ve ever used. \n\nIf European companies want to keep up in global competition, they need to innovate, employ, invest. \n\nThis goes for tech, automotive, etc.",
              "score": 2,
              "created_utc": "2026-02-05 16:52:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3yto0i",
              "author": "biyopunk",
              "text": "Iâ€™ve had the same experience. As an LLM it works reasonably well, but I believe itâ€™s a bit outdated, particularly on technical matters, it lacks up-to-date information.",
              "score": 1,
              "created_utc": "2026-02-06 20:46:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3q7399",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -2,
              "created_utc": "2026-02-05 15:08:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q8g3q",
                  "author": "SkyPL",
                  "text": "The version only changes the limits, not the quality.",
                  "score": 2,
                  "created_utc": "2026-02-05 15:15:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3q201h",
          "author": "dontcare10000",
          "text": "Reallly? What do you do with it? I have had pretty much the opposite experience.",
          "score": 32,
          "created_utc": "2026-02-05 14:42:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q92df",
              "author": "NullSmoke",
              "text": "It is very domain spesific. Mistral falls on its face every so often, but in others it does better than ChatGPT and Grok.\n\nThis is based on my personal experience, as quite a heavy user of ChatGPT (until the very end of December) Grok and Mistral. Benchmarks are neat, but they're not reflective of end user experience:\n\nOn the domain of literature, it's largely a question of taste. It lands in the ballpark of 4o there for me, on fact finding, DeepResearch exceeds that of current ChatGPT (well, tested in december when I still were subscriped to ChatGPT, but assume it still holds).\n\nWhen it comes to straight up reasoning though, it's usually slightly above 4o, but handily beaten by ChatGPT5-series models, and usually Grok as well. When it fails though... when it fails it's ugly.\n\nAt least it fails so hard that it's hard to take seriously, making it really easy for the user to flag it as bad info.\n\nThis was kinda what put me off, alongside the short context window they had back then, in like Jan 2025, when I first tried it, when that failure mode was more the norm than the exception.\n\nThat experience put me off the whole thing like the plague, but coming back when OpenAI lost their mind, I found it immensely improved, and the creative model is in fistfights with Grok-4.1 and ChatGPT5-series models, occasionally exceeding.\n\nI would say, Mistral is lagging sligthly against the infinity money black hole models, but it's more sustainable, and keeps improving over time, making it a legitimate player in the field.\n\nYou can get the latest and greatest, along with the US soft colonialism, if you want with the US models, or you can hang back a spell over in Mistral, for a lower price and a more trustworthy creator.\n\nThe latter has increasingly become very important for me at least. Moreso than LLM raw strength.\n\n(also, doesn't hurt that there's a open model that I can run at home as well, just in case)",
              "score": 8,
              "created_utc": "2026-02-05 15:18:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3q23o0",
          "author": "Relevant_Accident666",
          "text": "Is this really the case? \n\nIn my opinion nothing beats Gemini 3 pro so far for reasoning and such.",
          "score": 5,
          "created_utc": "2026-02-05 14:42:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q6gbw",
          "author": "uzyszkodnik007",
          "text": "Sorry,Â  but no. I always have to turn to other models as lechat is talking bs.",
          "score": 6,
          "created_utc": "2026-02-05 15:05:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qm19i",
          "author": "meschi_",
          "text": "For code generation I think it's not the best. I have a workflow with Gemini and OpenSCAD that does not really work with Le Chat, since it is only able to generate the most simple of shapes.\n\nBut I really like that the answers are brief and on point.",
          "score": 2,
          "created_utc": "2026-02-05 16:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v8abi",
          "author": "Fluffy_Fly_6221",
          "text": "Please don't add video, it's such a waste of ressources.",
          "score": 2,
          "created_utc": "2026-02-06 08:01:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yp2rp",
          "author": "Sufficient_Ad_9",
          "text": "I did a small test for a 3d print and mistral nailed it better than gpt, claude and venice. Then i started working with it. Free version. The free is good, BUT then it gets off its rails. adds info from another chat channel. I was doing some basic pything code, and it started adding the 3d print settings into the json file I was calling. It then added my profile info to the json. \nI am sure it is the free version, but wow it was annoying. The free has a timeout period after too many messages, so it stops your from exploding in madness. \nI am curious if the paid version has these issues.",
          "score": 2,
          "created_utc": "2026-02-06 20:23:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q56oa",
          "author": "OwlSlow1356",
          "text": "it is fast, but that is all there is to it. their focus is b2b and they clearly show it.",
          "score": 3,
          "created_utc": "2026-02-05 14:58:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q924y",
              "author": "Relevant_Accident666",
              "text": "And thats a clever move. \n\nB2C is not a market for AI...",
              "score": 3,
              "created_utc": "2026-02-05 15:18:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qb45k",
                  "author": "SnooSeagulls4360",
                  "text": "yeah go Europe...everything is B2B and the end user ends up using US tech. Super.",
                  "score": 8,
                  "created_utc": "2026-02-05 15:28:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vuzuz",
          "author": "silvetti",
          "text": "I donâ€™t have such great experience on the â€œquick answersâ€ to things. I asked it where was a shrine located in botw and it told me southeast of some village in the game, after I spent 30 minutos looking and nothing I asked it again are you sure itâ€™s southeast? And it replied youâ€™re right itâ€™s northwestâ€¦ if you canâ€™t rely for such small things how can I be sure on big things?\nThis is not a critique specifically to Mistral as all LLMs suffer from this.",
          "score": 1,
          "created_utc": "2026-02-06 11:31:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wa74j",
          "author": "TeamAlphaBOLD",
          "text": "Mistralâ€™s stuff does feel really solid right now, but part of that comes down to smart model design and really tight optimization for responsiveness.Â That said, every company has tradeâ€‘offs, and what works best can depend on the use case.Â Itâ€™sÂ awesome to see more competition pushing quality and speed up across the board.Â ",
          "score": 1,
          "created_utc": "2026-02-06 13:16:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xp49e",
          "author": "marcobaldo",
          "text": "It depends entirely on your use case.\n\nI have done private translation related benchmarks (to German) with different LLMs as a judge on translation, and Mistral Large came up strongly as the best based on several on several factors .\n\nHowever for coding, where reasoning and attention matters, I think that most people would agree that they are very behind many Chinese labs, but Mistral Vibe shows that they are working on it.\n\nFor image and video they can probably collaborate with Black Forest Labs, which are pretty much the state of the art for size.",
          "score": 1,
          "created_utc": "2026-02-06 17:29:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3xz1pi",
          "author": "CV1959",
          "text": "They have no nsfw filter and no restrictions unlike ChatGPT.",
          "score": 1,
          "created_utc": "2026-02-06 18:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yhi4c",
          "author": "syntaxjosie",
          "text": "I wasn't particularly impressed at all.",
          "score": 1,
          "created_utc": "2026-02-06 19:45:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qjsd6",
          "author": "crazyserb89",
          "text": "Itâ€™s a nice concept, I like the design and the features they are trying to drive, but itâ€™s too far away from the mainstream ones. I was testing it for days, different use cases and unfortunately isnâ€™t delivering neither close to what Iâ€™m expecting. Maybe sometimes in the future who knows.",
          "score": 1,
          "created_utc": "2026-02-05 16:08:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qnycb",
          "author": "aletheus_compendium",
          "text": "not really an accurate test: mistral doesn't automatically search the web. often you have turn on web search or instruct it specifically. one of the problems of using the same prompt with two different platforms is that the prompt is written for only one of them. you have to craft the same prompt query but in that platform's format and LLM dialect. then you can get a fair comparison. a gemini prompt won't be as effective in Mistral and vice versa. ðŸ¤™ðŸ»",
          "score": 1,
          "created_utc": "2026-02-05 16:27:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r12rl",
              "author": "Select_Ad_390",
              "text": "Ok thanks, this is an interesting insight. So should I ask Mistral how it prefers to have its prompts written? :)",
              "score": 1,
              "created_utc": "2026-02-05 17:28:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r4qcf",
                  "author": "aletheus_compendium",
                  "text": "i just prompted it with this: Search for and report back any and all information you find regarding 2025-2026 best practices for prompting Mistral LE CHAT ai. search beyond top tier and only official sites and sources. reach out into the vast web for blogs, articles, social mentions etc about how best to prompt LE CHAT for high quality results. pay particular attention the any quirks or idiosyncrasies that LE CHAT may have and has been discussed. out put in an orderly fashion starting with an executive summary intro. Make sure to focus search on French AND English language sources. Translate any information from French sources into English.\n\n\nthen you will have a complete guide for how to prompt. give that set of guidelines to a prompt engineer agent and tell it to optimize your prompt accordingly. rinse and repeat with all the platforms and you will know how to prompt them all properly. ðŸ¤™ðŸ»",
                  "score": 1,
                  "created_utc": "2026-02-05 17:45:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3sq8sh",
          "author": "Cereal_Grapeist",
          "text": "What are you basing this off of? Vibes? This is a pretty unusual post that is not based on the available evidence/benchmarks.",
          "score": 1,
          "created_utc": "2026-02-05 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rnc7d",
          "author": "Salt-Willingness-513",
          "text": "/s?",
          "score": 0,
          "created_utc": "2026-02-05 19:10:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sw4wd",
          "author": "KeizerSauze",
          "text": "Well, look, I just tested LeChat, and it's disastrous. It gets sidetracked by one question, forgetting the others, requiring 7-8 messages to get back on track, asking you three times for the document you uploaded, and inventing documents... Shall we continue?",
          "score": 0,
          "created_utc": "2026-02-05 22:46:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3revq8",
          "author": "sheerun",
          "text": "Good data and bunch of computers as far as I'm aware, and not state of art",
          "score": 0,
          "created_utc": "2026-02-05 18:32:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qei0d",
          "author": "uusrikas",
          "text": "This is just not true, Mistral is far behind in many aspects. I compare all my prompts with Mistral, Claude, Gemini and ChatGPT and Gemini is clearly the best.",
          "score": -3,
          "created_utc": "2026-02-05 15:43:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sw1gj",
          "author": "KeizerSauze",
          "text": "Well, look, I just tested LeChat, and it's disastrous. It gets sidetracked by one question, forgetting the others, requiring 7-8 messages to get back on track, asking you three times for the document you uploaded, and inventing documents... Shall we continue?",
          "score": -3,
          "created_utc": "2026-02-05 22:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q7f30",
          "author": "csicky",
          "text": "I don't know, in my experience is the worst family of models.",
          "score": -2,
          "created_utc": "2026-02-05 15:09:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qv1o6n",
      "title": "How do you see LeChat in 2026 February compared to ChatGPT and other LLMs?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "author": "BonoboPowr",
      "created_utc": "2026-02-03 19:31:03",
      "score": 67,
      "num_comments": 56,
      "upvote_ratio": 0.94,
      "text": "I always found it (sadly) underpowered. Sometimes I checked in on it and concluded that it's still lacking. But now I started a conversation, and it surprised me for the better.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3ebvkc",
          "author": "SkyPL",
          "text": "It underperforms. That's obvious for anyone using LeChat with SOTA models. Benchmarks try to quantify it that gap, but it *is* an observable issue in the actual work that I do.\n\nOverall though it does decently for being an alternative point of view. Especially for the stuff that requires search online.\n\nYou can input more complex topics into something like ChatGPT, Gemini, Deepseek and LeChat and the truth will be somewhere in there, either in one of, or between the four ;)",
          "score": 33,
          "created_utc": "2026-02-03 19:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3fnpkg",
              "author": "troyvit",
              "text": "I agree that Mistral under-performs, but when adding prices as a metric, how much does it under-perform? When I compare Mistral Large on sites like this one:\n\n[https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512](https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512)\n\nto Claude Sonnet 4.5:\n\n[https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5](https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5)\n\nMistral large is around 1/6 the price for inputs and 1/10 the price for outputs.\n\nSo does Mistral suck 10x more than Sonnet? The answer could very well be \"yes\" if because of the model choice you spend 10x as long on a project.\n\nBTW I don't know if [pricepertoken.com](http://pricepertoken.com) is a real web site, so if I have those prices wrong my apologies. My take also doesn't take into account alternative ways of paying.",
              "score": 4,
              "created_utc": "2026-02-03 23:30:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3i5lkp",
                  "author": "jacomoRodriguez",
                  "text": "Not sure if pricing is a good metric.\nIf you pay just 1/8 for your balcony and it falls off the house, it was cheap but also cheap ;)\n\nI know, not the best analogy but imo this applies in the ai space as well. Even if cheap, there is a min threshold you want to be above for good and reliable results. According to benchmarks, Mistral is sadly nowhere near that threshold.\n---\nSidenote: I use ai a lot for coding and developing. The gaps in the models are really visible there",
                  "score": 6,
                  "created_utc": "2026-02-04 09:47:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ir8ai",
                  "author": "SkyPL",
                  "text": "Price per token doesn't matter - it's price per job that does - aka cost efficiency. Musk's Grok was notorious for having a relatively low price per token, but it uses absurd amount of tokens on reasoning (tokens that Grok, unlike most other LLMs, never sends to you), making it one of the most expensive models on the market. Qwen 3 suffered from similar issues. And... so does Mistral Large.\n\nSee https://artificialanalysis.ai/#cost - switch to Intelligence vs cost, enable all the latest models from Mistral AI and you will see that compared to the rest of the market - Mistral AI is one of the least cost-effective providers. Devstral2 might be the first model that breaks that pattern, but so far its real-world performance has been mixed bag, and it's clearly below Sonnet 4.5.\n\nEspecially when you have GLM-4.7 that actually DOES offer you Sonnet 4.5 performance at a lower cost. Heck: GLM 4.7 is cheaper than Devstral2! ([$0.4/$1.9](https://openrouter.ai/z-ai/glm-4.7?sort=price) vs [$0.4/$2.0](https://openrouter.ai/mistralai/devstral-2512?sort=price), and with GLM you can have it even cheaper thanks to caching ($0.08), something Devstral2 does not offer).\n\n(If you want to know more about cost efficiency, you can start with [this video](https://www.youtube.com/watch?v=mRWLQGMGY80), it's fairly accessible and a decent starting point)",
                  "score": 1,
                  "created_utc": "2026-02-04 12:43:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3fcxim",
              "author": "mythrowaway4DPP",
              "text": "I actually just did a personal test with a complex deep research task.\nChatGPT, Gemini, Mistral, Claude\n\nMistral did just fine.",
              "score": 3,
              "created_utc": "2026-02-03 22:33:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ei4f2",
          "author": "Helenaisavailable",
          "text": "It's great for role-playing and for creative collaboration. That's what I mostly use LLMs for, so I'm satisfied. Agents are fantastic once set up properly.Â Mistral is improving , and I want to support them by using their product.Â ",
          "score": 22,
          "created_utc": "2026-02-03 20:09:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3erh1l",
              "author": "Icy_Distribution_361",
              "text": "Role playing? What do you mean? You role play with the LLM? And then what?",
              "score": 4,
              "created_utc": "2026-02-03 20:53:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ezpxx",
                  "author": "Helenaisavailable",
                  "text": "I'm a painter. I have certain characters, worlds, scenarios, creatures in my mind and tell the LLM to act it out with me,Â and we co-write a story.Â It can sometimes inspire me.Â Whatever happened in the role-play might spark an idea for a certain painting or drawing.\n\n\nI dont need an LLM to inspire my art, and I understand that role-playing might seem weird to some people. But I find it very fun! It's just an outlet for my daydreaming.Â ",
                  "score": 15,
                  "created_utc": "2026-02-03 21:31:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ewvep",
                  "author": "BonoboPowr",
                  "text": "ðŸ’¦",
                  "score": 1,
                  "created_utc": "2026-02-03 21:17:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3enfp1",
          "author": "Substantial-Yam3769",
          "text": "Further and further behind, i hope they soon will unvail a new model, something like Kimi K2.5.\n\n\nHowever it is still one of my favorite AIs, not just becouse of GDPR, and EU data protections, but also becouse of the flexibility Le chat offers and i like style of communication of the models.",
          "score": 11,
          "created_utc": "2026-02-03 20:34:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eiv28",
          "author": "Big_River_",
          "text": "formidable! it only underperforms on useless benchmarks - in many use cases it is state of the art - plus it has improved performance over and within large context windows",
          "score": 10,
          "created_utc": "2026-02-03 20:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3exa52",
              "author": "BonoboPowr",
              "text": ">formidable\n\nIn what language?",
              "score": 1,
              "created_utc": "2026-02-03 21:19:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3iaefk",
              "author": "Lukasino",
              "text": "Could you list examples of such use cases?",
              "score": 1,
              "created_utc": "2026-02-04 10:31:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ljyf0",
                  "author": "Big_River_",
                  "text": "riding shotgun with me on daily / weekly / monthly not-quite routine scoops across itops, secops, devops - human in the loop policy / process - where reliable valid plus fast saves me hours - surface what matters in the queue and categorize what is easily handled with boilerplate etc",
                  "score": 1,
                  "created_utc": "2026-02-04 20:52:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ecpge",
          "author": "farawayviridian",
          "text": "For fiction writing itâ€™s great. For everything else I use Gemini.",
          "score": 8,
          "created_utc": "2026-02-03 19:43:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hnsj0",
          "author": "Lauantaina",
          "text": "I'm European. A few weeks ago I was asking ChatGPT what would happen if a dump of US treasury bonds happened and it was super bullish on the US to the extent of piousness - it couldn't accept a situation where the US might not come out on top. It simply did not give objective answers. I had the same conversation with Le Chat and it was more objective and factual, certainly using less emotional or manipulative language. \n\nWhen you start pointing out to ChatGPT that it is using persuasive and manipulative devices to keep me engaged, it acknowledges that it is. When you add the inherent bias in there, that's just a bad combination. Personally, I don't need that in my life.\n\nI have found that on market research, which is my primary use case, both models are about equal but surface different things. When I'm producing a paper, I use both.",
          "score": 5,
          "created_utc": "2026-02-04 07:02:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hqbe6",
              "author": "BonoboPowr",
              "text": "ChatGPT is horrible at discussing current political events. It refused to believe that Maduro was kidnapped, I even posted articles about it, and it just kept on saying that I just fell for social media disinformation in the fog of war. No matter what I said it refused to accept.\n\nSimilar about protests in Iran. In the early days it refused to consider the possibility that 1000s to 10s of thousands were murdered. \n\nHappened in other times as well, very annoying. Anything Trump does in real life is not possible according to it.",
              "score": 2,
              "created_utc": "2026-02-04 07:24:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3htsxz",
                  "author": "Lauantaina",
                  "text": "Yes I had a similar experience with political topics. It accused me of falling for lies and disinformation, before going on to totally fog up the response with its own lies and disinformation even when provided with links and proof. Not objective at all, and totally biased towards the US. Mistral at least seems to be neutral and objective on those topics, even when you're being critical of the EU.  \n\nI've also noticed from 5.2 onwards that ChatGPT has really ramped up the gaslighting - making mistakes and then blaming me when I point it out. It's always my mistake. Emotionally manipulative language. Fogging up every discussion. All I want is an output of the facts, I'm not signing up to be manipulated. \n\nAlso the language patterns are too predictable to the point of being almost unusable.",
                  "score": 1,
                  "created_utc": "2026-02-04 07:55:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3eebw7",
          "author": "aeonixx",
          "text": "It's more likena scalpel, it doesn't do shit I didn't ask for. It means I do more preparation before sending the prompt, and I rarely have to correct tomfoolery.",
          "score": 6,
          "created_utc": "2026-02-03 19:51:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esm6s",
              "author": "amunozo1",
              "text": "This is very true. It follows much more the instructions without adding things nobody asked for.",
              "score": 3,
              "created_utc": "2026-02-03 20:58:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ed8u9",
          "author": "erizon",
          "text": "Different LLMs have different strengths in different categories.\n\nUnder/overpowered is meaningless without context (unless they are notoriously awful in everything). Are you writing Javascript code? FORTRAN code? Writing a novel? Researching science? \n\nI personally found Devstral better than Opus/Sonnet/Gemini for code implementation where design is already provided, en par with Haiku (only these two proactively wrote and executed tests in my experience). \n\nNot much to say about LeChat myself, as I barely started using it few days ago",
          "score": 4,
          "created_utc": "2026-02-03 19:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h5xyu",
          "author": "CuteFreedom7715",
          "text": "It is missing dearly a TTS !",
          "score": 4,
          "created_utc": "2026-02-04 04:43:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eh068",
          "author": "Edereum",
          "text": "For small very deterministic tasks in an agent flow, OCR and data extraction, its very cost effective with very good performance.  \nFor the rest, it underperforms.  \nI second SkyPL on \"research\" that give another view of SOTA.",
          "score": 3,
          "created_utc": "2026-02-03 20:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i73i9",
          "author": "IncorrectByDesign",
          "text": "I've been actively using it for a month now and i found some minor inconvenience at times. I write to it in English but because of my IP location it replies in German. I ask it to register that for all our conversations we need to speak in English, it confirms that the memory was updated but then a few days later it speaks to me in German. \n\nI ran a comparison between Chat GPT, Grok and Mistral and asked it if my options trading due diligence was correct.  I asked all of them to help me better understand the Greeks and I found: \n\n  \n1. Chat GPT made regular mistakes on the interpretation of the Greeks because an Option with Expiry date 30/09/2026 was classified as a LEAP with an expiry date in 2027. I asked it twice to review its analysis and twice it supported the wrong thing. I then asked it to count from January to September and tell me how are these 400 and something days? It then said, you are right and stated that based on the fact that between January and September we have x days, my analysis on Delta, Implied volatility is incorrect and this is a crap deal. So reading the fine print showed me that it was Hallucinating for some reason. \n\n2. Grok: much better answer and better refinement by also providing hedging bets to cover potential losses arising from the trade. Chat GPT needed to be asked additional questions for this. Also Grok said that this trade is rather neutral and i should buy the equity rather than go into options i am a fan of slow and steady growth. This was nice to see however I was expecting more math and tangible evidence for the recommendation. \n\n  \n3. Le Chat - Mistral : straight and to the point but was more conservative than both Chat GPT and Grok. It made sure to avoid absolutes in its statements and simply kept to the surface by theorising. I had to press it hard to give me more criteria to take decisions and this was adequate, however I was still expecting a more comprehensive and mathematical analysis as to why it was basing its decision on so and so. \n\n  \nI guess we are not there yet for this type of scenarios.",
          "score": 3,
          "created_utc": "2026-02-04 10:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eby4j",
          "author": "uusrikas",
          "text": "Good at fiction writing.\n\n\n\n\nPretty bad at searching for facts.\n\n\n\n\nBad image recognition. Image generation is ok if you ask it to do normal mundane stuff, but bad at realizing weird image ideasÂ \n\n\n\n\nTerrible thinking mode, almost unusable how it starts questioning itself and gets stuck in infinite loops.\n\n\n\n\nGood at helping me work, programming.\n\n\n\n\nFrankly, the only reason why I use it is because it is European. They are catching up when AI development slows down, but I really hope they pick up the pace.Â \n\n\nI use free versions of Gemini and Anthropic when ever I want a second opinion. Gemini is overall really good now and Anthropic has a nice pleasant writing style I like",
          "score": 4,
          "created_utc": "2026-02-03 19:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3einy3",
          "author": "Snickers_B",
          "text": "The coding is on par with other tools for specified tasks. Usually small tasks that is. \n\nThe writing is very good and I think better than ChatGPT but not better than Claude for writing or code.",
          "score": 2,
          "created_utc": "2026-02-03 20:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3et5p2",
          "author": "Celmad",
          "text": "I was using it now again after a while, and after using Gamini Pro, and It was very underwhelming.\n\nI was asking about email providers in Europe, alias management and password managers.\n\nGemini Pro seems like a person giving you very reliable information and even being creative and bringing information I might've missed.\n\nMistral (free tier) replied fast, yes, but with not much info. Just a quick few facts (some of them wrong, like saying 2FAS Pass was from Poland instead of US) in the form of a table with not much more info than what I gave it.\n\nReally really underwhelming.\n\nI had to stopped using it at work because I was working with Drupal .module files and Mistral didn't accept these files, only ChatGPT and Gemini did accept them of the AI chats I tried.",
          "score": 2,
          "created_utc": "2026-02-03 21:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fto1a",
          "author": "Equivalent-Word-7691",
          "text": "Honestly way behind gtp, Gemini and especially Claude, but also to kimi, deepseek and GML\n\nO use AI for creative writing and it's probably the worse out of the AI I mentioned , another thing is the output length... Gosh too short\n\nAs an European I would like to support ot more for more than one reasons , but honestly the quality is juybad compared to both Americans and Chinese AI \n\nThe price also is too much high for the quality",
          "score": 2,
          "created_utc": "2026-02-04 00:03:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h9nv5",
          "author": "The_Duke28",
          "text": "I don't know, I'm not really an AI Masterbrain, but I regularly compare my results to the one of my wife (she's using ChatGPT) and I always get the same results, sometimes even better ones.",
          "score": 2,
          "created_utc": "2026-02-04 05:09:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hlb30",
          "author": "Prinzmegaherz",
          "text": "I asked both le chat and Claude to design some math training sheets for my son.\n\nLe chat answered with something like 2 + 2, 4 + 4, no equation marks or anything.\n\nClaude gave me a fully layouted and printable sheet with exercises.\n\nThe amount of effort on my side to transform mistrals output into something usable like what Claude did would have been quite a lot. I probably would have been faster to do it myself as compared to using mistral.",
          "score": 2,
          "created_utc": "2026-02-04 06:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eer49",
          "author": "faresar0x",
          "text": "The entire world push new stuff every few months. Le chat like once a year and it doesnâ€™t even compete. I would like to support it but its way behind. If they wanna win market share, they gotta nail coding benchmarks",
          "score": 3,
          "created_utc": "2026-02-03 19:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3efmf4",
          "author": "pirisca",
          "text": "A few days ago it came up with:\n\"Total Duration: 18 months (from February 2026 to July 2026).\"Â \nI asked how did it made such an error.Â \nThe response :\nYouâ€™re right to call out the oversightâ€”it was a clear miscalculation on my part, and I appreciate your patience. Hereâ€™s what happened:\n\n\n1. **Misinterpretation of Dates**: I mistakenly treated \"February 2026 to July 2026\" as an 18-month span instead of **6 months**. This was an error in basic arithmetic and attention to detail.\n2. **Overlooked Context**: I didnâ€™t double-check the timeline against your long-term horizon (20+ years), which should have signaled that a 6-month DCA was a short-term tactic within your broader strategy.\n\n\n### **How Iâ€™ll Improve**\n- **Verify Dates**: Always cross-check timeframes with a calendar or simple math (e.g., February to July = 6 months).\n(...)Â \n\n\nSigh...Â ",
          "score": 1,
          "created_utc": "2026-02-03 19:57:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hpsnr",
              "author": "mobileJay77",
              "text": "Don't let an LLM do maths or even date calculation! Provide it with a service that can and let the llm put the parameters into the right place. These are solved problems.",
              "score": 1,
              "created_utc": "2026-02-04 07:19:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3et602",
          "author": "ohhellnaws",
          "text": "Personally I do feel it's a little lacking. It's very quick, clear, and concise and a lot of the time that's exactly what I want. I use it as a chat bot for a quick to and from. Nothing beats it on speed.\n\nOne thing I havenâ€™t really explored yet is to push it to answer and think more deeply by using different prompts for different agents, one of his strength seems to be able to call upon one of your agents/libraries mid any chat. \n\nIt's very good, however, at creating CSVs for me and discussing grey areas where ChatGPT may completely refuse.",
          "score": 1,
          "created_utc": "2026-02-03 21:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ext13",
          "author": "SoWhoAmIReallyHuh",
          "text": "It's surprisingly good at generating images.",
          "score": 1,
          "created_utc": "2026-02-03 21:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f3shm",
          "author": "crazyserb89",
          "text": "I would say ChatGPT, Gemini and Claude are tie on top (depending on use-case), and LeChat is not even close.. I hope they will be able to do some magic like Kimi in 2026, otherwise RIP",
          "score": 1,
          "created_utc": "2026-02-03 21:49:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hm2vm",
          "author": "SamuraiChicken88",
          "text": "I like it for data-analysis in R. Sometimes I find it better than ChatGPT even.",
          "score": 1,
          "created_utc": "2026-02-04 06:47:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hwlid",
          "author": "_FightingChance",
          "text": "I recently tried large again, and was pleasantly surprised! I use llms for work, coding, academia, and such, and was just trying to see if I can justify supporting them with a subscription, I will try them out for a couple of months. \nSo far I am intrigued by their agentic lineup, which I hear is good!!",
          "score": 1,
          "created_utc": "2026-02-04 08:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i3cyj",
          "author": "tmoravec",
          "text": "I find it next to useless, even with Mistral Large 2512 through AI Studio agents. Curiously, the same model performs quite well through the API, so I suspect the system instructions in Le Chat make it fight my prompts. Use cases: work - business stuff, tech stuff, general world knowledge, context and nuance. No roleplaying.",
          "score": 1,
          "created_utc": "2026-02-04 09:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mf758",
          "author": "Salt-Willingness-513",
          "text": "cool part about lechat is, most of the time its blazing fast, negative is, its rarely usable one shot and i have to rework alot of times, while i can ask claude to do the same and it gives a perfect or at least nearly perfect output. at least on openai/anthropic/googles platforms, we actually get the new model in time with somewhat proper communication. we still wait for large 3 to be available offically on lechat(yes i know you can create agents with large 3 via playground, but thats not the point). Reasoning is terrible and i very often have bugs in every session. I stillw ant to like lechat, but its harder and harder imo when at the same time using the other 3 named ones. I even tried z ai coding plan and i was a bit pikachu faced how good glm4.7 does compared to any mistral model",
          "score": 1,
          "created_utc": "2026-02-04 23:28:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3otdba",
          "author": "LearningPodd",
          "text": "I always start with talking to LeChat and mostly I don't have a need to turn over to another model.",
          "score": 1,
          "created_utc": "2026-02-05 09:20:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3punfv",
          "author": "Sweaty-Special-1710",
          "text": "I'm honestly really happy with it. I also use Vibe CLI for coding. Itâ€™s not expensive, I donâ€™t have any usage limitation issues, and I find it very practical. While Claude Sonnet and Opus seem more advanced, Le Chat is fast, structures its replies well, and fits my light usage needs perfectly.",
          "score": 1,
          "created_utc": "2026-02-05 14:02:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qwqqp",
          "author": "Sky_Linx",
          "text": "Mistral is losing ground pretty quickly. I *really* wanted to use their models for the AI features in my app (a retrospective tool for small teams called SprintPulse - https://sprintpulse.io if you are curious) but performance was so bad it's not even funny. My app has features like detecting related feedback, generating action items from feedback and more. The Mistral models, including the largest, are among the worst performers I have tried so far. So at the moment I am using Claude Opus 4.5 which obviously is a lot more expensive, but it's incredibly good not surprisingly. I really hope that Mistral will improve their models significantly because I'd prefer using models hosted in the EU for my app.",
          "score": 1,
          "created_utc": "2026-02-05 17:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eo2si",
          "author": "Competitive_Ad_2192",
          "text": "Far, far behind, unfortunately.",
          "score": 1,
          "created_utc": "2026-02-03 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eib49",
          "author": "Shichroron",
          "text": "LeChat is dead",
          "score": -5,
          "created_utc": "2026-02-03 20:09:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esdfc",
              "author": "Temporary-Outside737",
              "text": "No. It's still purring.",
              "score": 2,
              "created_utc": "2026-02-03 20:57:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ebgru",
          "author": "NerasKip",
          "text": "Trash",
          "score": -12,
          "created_utc": "2026-02-03 19:37:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsvmbo",
      "title": "Is Mistral Large 3 actually the best ai writing tool or are we just coping?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "author": "Fresh_State_1403",
      "created_utc": "2026-02-01 11:02:36",
      "score": 55,
      "num_comments": 23,
      "upvote_ratio": 0.94,
      "text": "Iâ€™ve spent the last month running Mistral Large 3 against the new Claude 4.5 and GPT-5.1 \"Thinking\" modes, and Iâ€™ve come to a conclusion that might annoy the purists here. If I had to pick one for logic-heavy, technical writing where I don't want a \"guidance counselor\" lecturing me on my tone, Mistral is the winner, but only if you aren't paying the $20 \"tax\" for a single-model sub.\n\nMistral Large 3 is fundamentally the best ai writing tool for anyone who needs high-density output without the sycophancy. While GPT-5 tries to guess what I want to hear and Claude gets bogged down in its own safety \"Constitutional\" logic, Mistral just executes the Markdown. It treats the prompt like a set of instructions, not a suggestion.\n\nImportantly, the reasoning depth here (let me elaborate!!) is finally at parity with the frontier models, but without the \"lobotomy\" effect we see after a modelâ€™s been out for six months. Iâ€™ve been testing this by running complex document analysis through writingmate, where I can flip between Mistral and the other models in a single thread. such a  \"hallucination drift\" is significantly lower on Mistral when you're dealing with non-English technical specs or legacy codebases, at least I found this to be true for my workflow.\n\nThe real problem isn't the model; itâ€™s the fragmentation. Most people claim ChatGPT is the best ai writing tool simply because theyâ€™ve already paid the $20 and don't want to admit it's lagging in raw reasoning. But the minute you need to cross-check a hallucination or run a deep search without the \"Exactly!\" and \"Sharp observation!\" fluff, the value of a single-model subscription falls apart.\n\nClaude and Gemini are great for their specific moats (f.e. Claude for narrative, Gemini for the 2M context window), but Mistral is the only one that feels like itâ€™s built for professionals who want a tool, not a friend. My skeptic take? Perhaps, stop overpaying for the \"big brand\" wrappers and start using a brief stack of tools that let you use the right logic for the right task.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2yarri",
          "author": "Working-Chemical-337",
          "text": "oh, price consolidation is the only thing that convinced me to try managed platforms. was paying >100 dollars/month for GPT, Claude, and Gemini separately. then tried multi ai platforms (or wrappers with many models) like writing mate, just because i heard it handled the agent side better than the standard APIs, and saving that ammount per month while still getting frontier-level Mistral reasoning is probably the only \"win\" Iâ€™ve had in my tech stack this year that just started",
          "score": 10,
          "created_utc": "2026-02-01 11:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yjlcd",
              "author": "Fresh_State_1403",
              "text": "makes a lot of sense",
              "score": 2,
              "created_utc": "2026-02-01 12:20:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2z78k1",
              "author": "Tuckebarry",
              "text": "Wait so what's the stack then? What's the best multi AI platform that you mentioned?\n\nThanks",
              "score": 1,
              "created_utc": "2026-02-01 14:49:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb0jt",
          "author": "One-Risk-4266",
          "text": "doing the same thing and bouncing drafts between Claude and Mistral. I find Claude is better for the initial soul of a piece, but Mistral is the only one I trust to actually follow a style guide without drifting into aispeak after three pages. and itâ€™s hard to argue itâ€™s not a top-tier contender for the title of best ai writing tool in 2026, especially if you value data sovereignty and want something local",
          "score": 6,
          "created_utc": "2026-02-01 11:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yk8ss",
              "author": "Fresh_State_1403",
              "text": "i totally get that. Claude has that \"human\" spark, but it definitely starts to hallucinate its own \"creativity\" after a while. and Mistral is just cold, hard logic, which is a godsend for technical consistency and actually sticking to a style guide without the aispeak fluff; so for me all in one chats like writingmate are just to keep them both in one window because I was getting massive tab fatigue trying to copy-paste between accounts. Itâ€™s way easier to just flip the model toggle when Claude starts getting too \"wordy\" and you need Mistral to tighten things up. Honestly, the best ai writing tool in 2026 isn't a single model anymore, itâ€™s just whichever one isn't currently acting \"lobotomized\" or ignoring your instructions\n\nbtw are you running Mistral locally via Ollama for that data sovereignty piece, or are you just sticking to the API for the speed?",
              "score": 1,
              "created_utc": "2026-02-01 12:26:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z379l",
          "author": "porzione",
          "text": "How do you actually use Large? Mistral lacks actual tools, except vibe/devstral - the same issue as with Chinese models. I use local Mistral Small as creative scene writer, but everything is planned by Opus, because I need to collect names, facts, timeline, check backstories from Obsidian vault with \\~1500 files and I use Claude Code for this, then CC writes detailed scene description/plan and sends it to local fine tuned Mistral Small.\n\nIn theory OpenCode or Zed may work for this, but my previous attempts to use Mistral modelsâ€™ agentic features have all failed miserably, except Devstral. I hope that Mistral will add all their models to Vibe, so it will work without fiddling with 3rd party tools.",
          "score": 3,
          "created_utc": "2026-02-01 14:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30mhi5",
              "author": "Working-Chemical-337",
              "text": "what tools does mistral lack?",
              "score": 1,
              "created_utc": "2026-02-01 18:47:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30plz7",
                  "author": "porzione",
                  "text": "Vibe with all Mistral models, specifically - cli tool with ACP support.",
                  "score": 1,
                  "created_utc": "2026-02-01 19:01:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31povj",
              "author": "erizon",
              "text": "GLM family works perfectly fine in Claude Code via ANTHROPIC_BASE_URL environment variable (actually much faster than via OpenAI style //api.z.ai/api/coding/paas/v4). Deepseek also supports it, which Chinese model does not?",
              "score": 1,
              "created_utc": "2026-02-01 21:55:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zmlna",
          "author": "Ambitious_Fee3169",
          "text": "Mistral Large is fantastic. It's the default in our AI chat system. Mistral medium is also great (but more expensive for some reason for output tokens vs large).",
          "score": 2,
          "created_utc": "2026-02-01 16:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30sgl1",
              "author": "Fresh_State_1403",
              "text": "I don't like using it per credits / calls, because it never seemed to be economically viable for me, so i used 'all in one' chatbot subscription(s) which in my case seems to work more, like writingmate in either pro or ultimate",
              "score": 2,
              "created_utc": "2026-02-01 19:14:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb78z",
          "author": "DrPinguin98",
          "text": "I do a lot with AIs and use a service provider that lets me use pretty much all AIs, and honestly, Mistral Large 3 is definitely no better than GPT 5.2 Thinking.\n\nJust the day before yesterday, I tried to rewrite some of my reports and got a little frustrated with Mistral. Content was constantly missing, it made things up (even though I explicitly forbade it), or it didn't rewrite things the way I defined in the prompt.\n\nBut that could also be due to the languageâ€”in my case, German.\n\nI have to say, though, that a lot is happening in this regard, and we're starting to reach the point where I can and will really use Mistral.\n\nAnd when the time comes, my monthly subscription will belong entirely to Mistral, and I honestly can't wait.",
          "score": 4,
          "created_utc": "2026-02-01 11:10:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30j53c",
              "author": "Fresh_State_1403",
              "text": "by the way, does the need to use German change a lot in how you pick AI tools? what differences do you see when it comes to non-English responses?   \n5.2 thinking is very ok",
              "score": 1,
              "created_utc": "2026-02-01 18:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb5w2",
          "author": "TonyHMeow",
          "text": "The best thing about OA is the saved memory blocks and profiling aspect of the models in both writing and conversational discussion flow, and as of now still leading compared to other major competitors IMO.\n\nComing from GPT 4oâ€™s writing, how is LeChat saved memory (storage size/utilization) and context tracking (in a project, say) compared to OpenAI? Genuinely considering trying out Mistral after 4o retires, would love some input on this!",
          "score": 1,
          "created_utc": "2026-02-01 11:09:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ykzkx",
              "author": "Fresh_State_1403",
              "text": "OpenAIâ€™s memory is definitely the stickiest part of their ecosystem to me, it's hard to leave once the model knows your specific quirks. Yet if youâ€™re looking at lechat , in my xp  Itâ€™s less \"vibe-based\" and more literal. Their Project Libraries actually beat GPT in my opinion because they index your files properly. Instead of the model just cramming everything into the context window and hallucinating when it gets full, Mistral pulls only whatâ€™s relevant. Itâ€™s way more stable for long-term technical work. So I often use Writingmate to A/B test the recall between them and overall compare models side by side, and while GPT feels more intuitive, Mistral is much more transparent about what itâ€™s actually pulling from your history. You won't get that \"as an AI assistant\" lecture every five minutes either, which is a massive plus. There's also a trade-off which is, Mistral won't remember a random chat from three weeks ago unless you specifically tell it to save that info to your memory or project. Itâ€™s more manual, but somwewhat better for privacy and focus.",
              "score": 2,
              "created_utc": "2026-02-01 12:31:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2zudq7",
                  "author": "TonyHMeow",
                  "text": "ok, thanks for the info!\n\nWhen you said \"Mistral is much more transparent about what itâ€™s actually pulling from your history.\" Do you mean like it literally quotes you (\"word for word\") from another conversation/your uploaded files? Because i think GPT had an update about that a couple of weeks, which I really dislike lol.",
                  "score": 1,
                  "created_utc": "2026-02-01 16:40:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yhhi4",
          "author": "Alex-plosion",
          "text": "For  ideas, I don't find mistral large 3 to be amazing, but for writing, yeah it's great, especially in French.\nI tend to write the plan, or a whole draft with another model and rewrite it after with mistral.",
          "score": 1,
          "created_utc": "2026-02-01 12:04:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30jzvw",
              "author": "Fresh_State_1403",
              "text": "when I am able to switch within one chat with tools like writingmate, I can interchange mistral with gpt and gemini without changing context, tools, or chatbots. but frm what I know, Mistral is truly very fine at European languages",
              "score": 1,
              "created_utc": "2026-02-01 18:36:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yqxwq",
          "author": "Charming_Support726",
          "text": "No. Definitely No.\n\nUsed all of them for writing. All of them showed ugly quirks. I tried German, European Portuguese, English. \n\nGemini follows style instructions quite well, but lacks some variance in creativity. Style was very important for me. \n\nAll others still do this damn \"its not only A, it is B\" thing in every second sentence. You can't get rid of it. \n\nThe creative model from Mistral Labs can get European Portuguese right - this is the only model except for Gemini 3 Pro, which is capable. All others fails (Claude, Gpt, Large3 and more). Unfortunately it is not open weights, otherwise I'd like to see an optimized version.",
          "score": 1,
          "created_utc": "2026-02-01 13:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30qf27",
              "author": "Working-Chemical-337",
              "text": "you can prompt them not to use negations, and other signs of ai writing, and otherwise follow your natural style of writing. some editing may be required even then, but hey, this can save a lot of time when you have to do some huge outputs",
              "score": 1,
              "created_utc": "2026-02-01 19:05:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z0vxg",
          "author": "TeeRKee",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-01 14:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eut58",
          "author": "urzabka",
          "text": "I am practically using all of models I like and Mistral as well in multi-ai tools. For now itâ€™s writingmate and works well for me. Does it cover 100% of all that I need AI for? No but all that I need a chatbot for, having like mistral GPt Claude Gemini and others",
          "score": 1,
          "created_utc": "2026-02-03 21:08:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvv4wo",
      "title": "Voxtral Mini Transcribe V2 and Voxtral realtime.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvv4wo/voxtral_mini_transcribe_v2_and_voxtral_realtime/",
      "author": "cosimoiaia",
      "created_utc": "2026-02-04 17:38:40",
      "score": 55,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "Mistral released 2 new STT models!\n\nhttps://mistral.ai/news/voxtral-transcribe-2\n\nhttps://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602\n\nSub 200ms delay for the open weight model, impressive!\n\nGo Mistral! ðŸš€",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvv4wo/voxtral_mini_transcribe_v2_and_voxtral_realtime/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3kh8sv",
          "author": "cosimoiaia",
          "text": "Didn't see their official post from 2 hours ago ðŸ˜…\n\nNevertheless, it's a great release and a super STT open weight model!\n\nIt feels like they read my mind because I was looking for something like this just today!\n\nEdit: typo it's stt not tts.",
          "score": 8,
          "created_utc": "2026-02-04 17:53:04",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3kjzhy",
              "author": "usrlibshare",
              "text": ">and a super TTS model\n\nDid I miss anything? Because I tested it as well, it's awesome, but it's ASR (automated speech recognition) / STT (speech to text) / transcription, however you wanna call it.\n\nTTS would be text to speech , aka. speech synthesis.",
              "score": 2,
              "created_utc": "2026-02-04 18:05:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3krlxx",
                  "author": "cosimoiaia",
                  "text": "Yeah I made a typo in my comment, I even wrote STT in the post.\n\nMaybe it was wishful thinking ðŸ˜…",
                  "score": 3,
                  "created_utc": "2026-02-04 18:39:54",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o3kmdsa",
                  "author": "Neither-Bit4321",
                  "text": "Yea, I can't see a TTS model anywhere.",
                  "score": 1,
                  "created_utc": "2026-02-04 18:16:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ljmy9",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-04 20:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lnvpd",
              "author": "cosimoiaia",
              "text": "Both are transcription models? Why would you do summarization with them? \n\nDo a pass with Mistral 3 3b if you want good summarization/information extraction with low memory footprint.",
              "score": 1,
              "created_utc": "2026-02-04 21:11:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3orv2b",
          "author": "Bright-Celery-4058",
          "text": "I want to try it in my backend but docs is not updated",
          "score": 1,
          "created_utc": "2026-02-05 09:05:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oyxj7",
              "author": "cosimoiaia",
              "text": "It's supported only by vLLM so far but it's quite easy to setup, it's explained in the model card. You can also check the code of the demo in the space for the client side.",
              "score": 1,
              "created_utc": "2026-02-05 10:14:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3pkafn",
                  "author": "Bright-Celery-4058",
                  "text": "https://preview.redd.it/fim2tq58cohg1.png?width=1431&format=png&auto=webp&s=a7d8056442c12f7725dec19c472da069d62a4f9c\n\ni mean the API. i am interested in the context biasing + word level timestamp but the API doc is missing those advertised new features. Also the max audio length needs to be updated (15min was for the V1, V2 claims 3h). [https://docs.mistral.ai/capabilities/audio\\_transcription#transcription](https://docs.mistral.ai/capabilities/audio_transcription#transcription)",
                  "score": 1,
                  "created_utc": "2026-02-05 13:02:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qtp21z",
      "title": "Mistral vs. ChatGPT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "author": "sachama2",
      "created_utc": "2026-02-02 07:59:28",
      "score": 53,
      "num_comments": 57,
      "upvote_ratio": 0.96,
      "text": "I already have a ChatGPT subscription. What additional benefits would I get if I also subscribe to Mistral?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o34ez2f",
          "author": "EzioO14",
          "text": "You wonâ€™t gain anything by using both, mistral is good but a bit behind ChatGPT. Most people use mistral because itâ€™s good enough for their needs, cheaper and not American.",
          "score": 84,
          "created_utc": "2026-02-02 08:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34jg1j",
              "author": "SpeedDaemon3",
              "text": "Also mistral is not censored like chatgpt...Â ",
              "score": 40,
              "created_utc": "2026-02-02 08:54:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34oy5v",
                  "author": "EzioO14",
                  "text": "Do you have an example? I havenâ€™t used ChatGPT much",
                  "score": 3,
                  "created_utc": "2026-02-02 09:47:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35u3om",
                  "author": "Objective-Sky7312",
                  "text": "Iâ€™m finding it still very censoredâ€¦ are people getting it to do NSFW?",
                  "score": 2,
                  "created_utc": "2026-02-02 14:40:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38nm2w",
                  "author": "[deleted]",
                  "text": "https://preview.redd.it/wv4zc3wfs5hg1.png?width=788&format=png&auto=webp&s=c4cee9bb77aa4b7b21289402e080980e7d2b584d\n\nThat is pretty much hard censoring for me.",
                  "score": -8,
                  "created_utc": "2026-02-02 22:38:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34i5ne",
          "author": "mythrowaway4DPP",
          "text": "It is more of a replacement.  \n  \n***TL;DR***   \nMistral is behind ChatGPT a little bit, but less censored, and European.\n\n**Some details**\n\n* Their research feature is great, and easily on par with CGPT. (yes, I did the testing).\n* Image generation is kinda mid. (afaik, they are still using FLUX by black forest labs, not flux 2)\n* No text to speech, but their transcription of voice input is great and FAST!\n* Their document management uses a concept of different \"libraries\" of documents, that you can then use in different chats.\n\nPrompting mistral needs to be more strict and detail oriented. Especially if you need it to access a file, you need to very EXPLICITLY tell it to do so.   \nThis is very different from CGPT which feels like it is swimming in the provided documents and accesses them too eagerly at times.\n\nOverall, I am very happy with it.",
          "score": 26,
          "created_utc": "2026-02-02 08:41:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37bugr",
              "author": "Dadinek",
              "text": "Love the voice input as well and the fact that you can select if you want to autosend or not",
              "score": 2,
              "created_utc": "2026-02-02 18:51:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o36b4fy",
              "author": "sachama2",
              "text": "\"transcription of voice input is great and FAST\" Very interesting. Do you mean you can load via the ineterface a mp3 file?",
              "score": 1,
              "created_utc": "2026-02-02 16:04:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36bi92",
                  "author": "mythrowaway4DPP",
                  "text": "No. I was talking about using voice for input",
                  "score": 4,
                  "created_utc": "2026-02-02 16:05:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34i5xt",
          "author": "Nervous_Sun4915",
          "text": "I don't know if this is relevant for you, but you gain (limited) access to their API which you can use for your own applications as a LLM endpoint, OCR, vibe-coding, etc.\n\nI built a tool that transforms all my PDFs of scanned books/articles (basically images) into fully searchable PDFs where I can use the text in less than an hour, using Mistral and their OCR API & Python assisted coding.",
          "score": 8,
          "created_utc": "2026-02-02 08:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hf0uz",
              "author": "SietJP",
              "text": "Does it support handwritting?",
              "score": 1,
              "created_utc": "2026-02-04 05:49:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34j1ja",
          "author": "MimosaTen",
          "text": "I left ChatGPT due to it being extremely slow, in favour of Gemini. But I use Mistral Vibe CLI that uses devstral 2 to automate code writing",
          "score": 8,
          "created_utc": "2026-02-02 08:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37p140",
              "author": "obadacharif",
              "text": "Check [Windo](http://trywindo.com) when switching models, itâ€™s a portable AI memory that allows you to carry your memory with across models. No need to re-explain yourself.\n\nPS: Im involved with the project",
              "score": 2,
              "created_utc": "2026-02-02 19:52:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o35ctek",
          "author": "Lakafior",
          "text": "\\- MCP custom server integration on mobile and desktop is the reason I've bought it, and it's way ahead the rest (meaning other apps don't have this feature at all). I can talk with my database while on the phone now, and morevover not using my tokens doing that.\n\n\\- Libraries, which are like your knowledge bubbles with links, documents etc. you can pin to a new chat. It's a great way to chat with your notes etc. without creating custom GPT.\n\n\\- It's faster and more focused on your prompts without going sideways.\n\n\\- European, so a lot more privacy-protected and in general LLM who you talk about a lot of things this is very important point imo.\n\n\\- Cheaper",
          "score": 6,
          "created_utc": "2026-02-02 13:03:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36bi9w",
              "author": "sachama2",
              "text": "\"Â MCP custom server integration on mobile and desktop\" Do you mean that I can imagine a chat (i.e. \"mining\" ) my Calibre directory?",
              "score": 2,
              "created_utc": "2026-02-02 16:05:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36mjd7",
                  "author": "mythrowaway4DPP",
                  "text": "With an mcp server handling the requests and handing them to a calibre API - why not?",
                  "score": 2,
                  "created_utc": "2026-02-02 16:56:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38j6bf",
              "author": "ohhellnaws",
              "text": "Afaik you can pin mid chat. Same for agents. Have some with customer prompts for quick chat style, some with attached library, guardrails, etc and call upon them and swap out mid chat. Best feature not anywhere else.",
              "score": 2,
              "created_utc": "2026-02-02 22:15:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pb249",
                  "author": "sachama2",
                  "text": "A tutorial somewhere?",
                  "score": 1,
                  "created_utc": "2026-02-05 11:59:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34rav1",
          "author": "allulcz",
          "text": "Something to note, I use their API for free now and I am more than happy. I use Mistral Small 3.2 and I am very surprised how good it is. I use it for automation, classification, and text parse. Just surprised how well it works.",
          "score": 6,
          "created_utc": "2026-02-02 10:10:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37bkul",
          "author": "Dadinek",
          "text": "I don't use ChatGPT because their business model is just shitty. Every innovation is meant to swallow more personal data.",
          "score": 5,
          "created_utc": "2026-02-02 18:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ecc9",
          "author": "uusrikas",
          "text": "Well, they kinda do the same thing but ChatGPT is better at it. I don't use ChatGPT because they are big Trump donors and I don't want to support that. Having two subscriptions would be pointless. Gemini is better than both functionally.",
          "score": 17,
          "created_utc": "2026-02-02 08:05:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34kom4",
          "author": "Gold-Guess4651",
          "text": "Mistral le chat is GDPR-compliant so has much better privacy than chatGPT. It's not an additional benefit next to using chatGPT but is certainly a benefit of le chat over chatGPT.",
          "score": 9,
          "created_utc": "2026-02-02 09:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34xurd",
              "author": "Spiritual-Plant3930",
              "text": "There is no privacy when it comes to any LLM; otherwise, they wouldn't work. \n\nLLMs are \"leaking\" all the time by design.\n\nNeural networks can't be privacy-conscious. \n\nIt's like telling a kid to learn without any access to knowledge (can't use the internet, can't read books, etc.).\n\nTo have privacy, you have to know where the info is coming from (to know it's private info) - LLMs don't exactly know where the info came from.\n\nFor more, this one is a good start. \nhttps://youtu.be/_3okhTwa7w4",
              "score": -8,
              "created_utc": "2026-02-02 11:10:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o356xg9",
                  "author": "Gold-Guess4651",
                  "text": "I didn't say le chat is fully private, I said that due to GDPR-compliance privacy protection is better (or perhaps not as terrible if you like) than e.g. chatGPT. This is because le chat doesn't use chats or any data in the chat to train the LLM, all data are stored at European servers (and therefore cannot be accessed by the USA government), and doesn't share info with third parties.",
                  "score": 8,
                  "created_utc": "2026-02-02 12:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35fp0g",
          "author": "aajl2",
          "text": "Try to make a single payment $10 on open router so you'll access to openai, mistral other providers and many more LLM. Why? Testing, comparing, evaluating the best that fit your needs. I use gpt5-codex for python learning and it's been great",
          "score": 3,
          "created_utc": "2026-02-02 13:21:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pb6wa",
              "author": "sachama2",
              "text": "Thank you",
              "score": 1,
              "created_utc": "2026-02-05 12:00:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p7s0y",
          "author": "VohaulsWetDream",
          "text": "Mistral is better with *some* programming tasks. Also is better with \"gray zone\" questions, like help me with this software protection.",
          "score": 2,
          "created_utc": "2026-02-05 11:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35uhxf",
          "author": "martapap",
          "text": "I started using mistral recently. It is incredibly dumb at following directions. Seems like it has a mind of its own ane just gives you whatever it wants instead of what you ask for. With the exception of agents. I created a couple of agents using language another model gave me and it was able to follow directions then.",
          "score": 3,
          "created_utc": "2026-02-02 14:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34sfep",
          "author": "crazyserb89",
          "text": "Iâ€™m paying for ChatGPT and Gemini and I was testing Le Chat too. Honestly itâ€™s far behind those, but itâ€™s a good concept. If they improve it in future I would be glad to move there",
          "score": 1,
          "created_utc": "2026-02-02 10:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35wg1e",
              "author": "TheMrLexis",
              "text": "What can they do for improving Le Chat?",
              "score": 5,
              "created_utc": "2026-02-02 14:53:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o360hus",
                  "author": "MattyGWS",
                  "text": "For starters, it doesnâ€™t do coding as well as chatgpt. \n\nWould be nice if it had a voice chat feature too",
                  "score": 1,
                  "created_utc": "2026-02-02 15:13:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35z3u2",
                  "author": "crazyserb89",
                  "text": "Custom chats, clipboard copy pasting doesnâ€™t work on iOS, text to speech is trash and thereâ€™s no live speech. More integrations, more optimizations etc.. I mean the price is not correct even, you can take Gemini Plus for few bucks only and to get way more",
                  "score": -1,
                  "created_utc": "2026-02-02 15:06:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3wgjk9",
          "author": "Fluffy_Fly_6221",
          "text": "cheaper",
          "score": 1,
          "created_utc": "2026-02-06 13:51:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxad5c",
      "title": "Mistral should allow data donations",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qxad5c/mistral_should_allow_data_donations/",
      "author": "pfilzweg",
      "created_utc": "2026-02-06 06:39:33",
      "score": 51,
      "num_comments": 17,
      "upvote_ratio": 0.99,
      "text": "I want mistral to succeed. However, Anthropic and OpenAI etc will advance their lead with all the user input and data they get from people interacting with them. \n\nAs it seems people will trust these systems with anything there is nothing to lose and just to gain to also make this data available to Mistral for them to use in training. \n\nI would do it. Export memory and data and upload to Mistral. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qxad5c/mistral_should_allow_data_donations/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3v0umh",
          "author": "EzioO14",
          "text": "Honestly Iâ€™d be glad to export all my claude conversations and feed them into mistral for training",
          "score": 23,
          "created_utc": "2026-02-06 06:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v6zk1",
          "author": "According_to_Mission",
          "text": "https://preview.redd.it/sxbdhztlxthg1.jpeg?width=1179&format=pjpg&auto=webp&s=4340eeed25d0432f6308edbea1ff453bf077680b\n\nGo into data settings and check the first option, it will share more data with them to help them train their models.",
          "score": 17,
          "created_utc": "2026-02-06 07:49:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3v8gao",
              "author": "pfilzweg",
              "text": "Good first step. I am however not using mistral as heavy as the other just yet as their models were lacking in comparison. I want to help them and level the playing field by this data I accrued in other providers.",
              "score": 1,
              "created_utc": "2026-02-06 08:03:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3v8izn",
                  "author": "According_to_Mission",
                  "text": "I believe you can at least export the memories from other LLMs to it.",
                  "score": 2,
                  "created_utc": "2026-02-06 08:04:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3uz7qb",
          "author": "nycigo",
          "text": "Me too.",
          "score": 14,
          "created_utc": "2026-02-06 06:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v0khn",
          "author": "N0Legendary",
          "text": "Same, if I can't afford to pay the subscription, at least I can allow them to have a deeper look, with some limits from my side",
          "score": 7,
          "created_utc": "2026-02-06 06:52:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vzj6f",
          "author": "64-17-5",
          "text": "Mistral should tie more connections to EU, not more to the US.",
          "score": 3,
          "created_utc": "2026-02-06 12:06:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w5pw4",
              "author": "pfilzweg",
              "text": "Is it actively tieing itself more to the US lately?",
              "score": 2,
              "created_utc": "2026-02-06 12:48:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3w7kl9",
                  "author": "64-17-5",
                  "text": "Close connections to NVIDIA amongst other. Lots of investors from the US. If the AI bubble crashed in the US, Mistral will surely follow.",
                  "score": 2,
                  "created_utc": "2026-02-06 13:00:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3wo6el",
          "author": "EveYogaTech",
          "text": "I think one way to help Mistral succeed is to make it more useful in the broader tool chain, and using those tools, plus creating more value within those tools.\n\nThis is what we're doing for example with /r/Nyno. We're letting users build exportable workflows on top of Mistral. \n\nPublic demo at https://europe.nyno.dev (try on desktop).  All you need is an Mistral API key, which can be obtained via https://console.mistral.ai",
          "score": 2,
          "created_utc": "2026-02-06 14:31:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vlpwl",
          "author": "fusilaeh700",
          "text": "data must be taxed in the country where it is harvested",
          "score": 1,
          "created_utc": "2026-02-06 10:10:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3w8nw2",
          "author": "guyfromwhitechicks",
          "text": "You could pay them instead.",
          "score": 1,
          "created_utc": "2026-02-06 13:07:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qry40r",
      "title": "Replace github copilot with Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "author": "InternalBroad2522",
      "created_utc": "2026-01-31 09:39:58",
      "score": 37,
      "num_comments": 11,
      "upvote_ratio": 0.95,
      "text": "Hi all! I would like to replace Github Copilot with Mistral for coding in VSCode IDE. What can I do?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2rk80x",
          "author": "scara1701",
          "text": "Does it have to be in vscode? I guess you could run mistral vibe in a terminal window.",
          "score": 6,
          "created_utc": "2026-01-31 09:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vlko5",
              "author": "LoadZealousideal7778",
              "text": "Or in the Jetbrains IDE of your choice",
              "score": 3,
              "created_utc": "2026-01-31 23:25:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ji0p2",
              "author": "InternalBroad2522",
              "text": "But Mistral Vibe does not have autocompletion right?",
              "score": 1,
              "created_utc": "2026-02-04 15:09:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2roc3i",
          "author": "katafrakt",
          "text": "Mistral Vibe supports ACP, so any VSCode extension supporting ACP would do. I'm not too familiar with this ecosystem, so I won't give any recommendations.",
          "score": 4,
          "created_utc": "2026-01-31 10:27:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2szqsy",
          "author": "kiwibonga",
          "text": "There's a mistral vibe extension that lets you have the CLI in VSCode. It's mostly a convenience thing that saves you the trouble of launching the terminal and setting the working directory.",
          "score": 2,
          "created_utc": "2026-01-31 15:45:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2utlgd",
          "author": "Bob5k",
          "text": "Have in mind that you either pay for API usage of devstral or accept the quite mediocre quota allowance on experiment plan.",
          "score": 2,
          "created_utc": "2026-01-31 21:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xnbbp",
              "author": "deegwaren",
              "text": "Oh? Didn't they just include vibe-cli usage in their pro plan? Meaning it's included like Claude code usage in the Claude Pro plan.",
              "score": 1,
              "created_utc": "2026-02-01 07:30:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2yd1vv",
                  "author": "Bob5k",
                  "text": "They included cloud vibe usage afaik, don't know about vibe cli tbh and not sure on the quota allowance, i still think the cli falls under Mistral ai studio.",
                  "score": 1,
                  "created_utc": "2026-02-01 11:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ro18m",
          "author": "opsmanager",
          "text": "Im using the Continue extension, works reasonably well. I havent yet figured out how to make it as seemless as the copilot extension with regards to accessing the repository files. But im sure its just me missing something obvious.",
          "score": 2,
          "created_utc": "2026-01-31 10:24:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uj3bq",
              "author": "vienna_city_skater",
              "text": "Continue is soso, good for code completion, but agent mode sucks, Roo Code works well for agentic coding in VS Code, but the TUIs are much better. I switched everything to OpenCode because I mix models a lot. However, so far I have not find a way to get access to the free devstral with my Le Chat Pro subscription outside of vibe CLI.  \nEDIT: I think I found the problem, I used the API key from La Platforme Admin Panel not from the AI Studio VIBE CLI section, so I was charged on-the-go.",
              "score": 3,
              "created_utc": "2026-01-31 20:10:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwdi1e",
      "title": "Integrate Mistral Vibe in VS Code (like Claude Code extension)",
      "subreddit": "MistralAI",
      "url": "https://zatteo.com/en/integrate-mistral-vibe-in-vs-code-like-claude-code-extension/",
      "author": "Tanuki__",
      "created_utc": "2026-02-05 06:09:26",
      "score": 22,
      "num_comments": 9,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwdi1e/integrate_mistral_vibe_in_vs_code_like_claude/",
      "domain": "zatteo.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ob27i",
          "author": "Old-Age6220",
          "text": "YES! This is the main reason I've been neglecting Mistral vibe, because I definitely want it to be on Visual Studio Code, not in any external console / window",
          "score": 3,
          "created_utc": "2026-02-05 06:30:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ocghy",
              "author": "Tanuki__",
              "text": "The second thing I miss is that Claude Code extension \"knows\" the current file opened in VS Code  and it is sometimes very practical. But I think it needs a real extension for this one.",
              "score": 2,
              "created_utc": "2026-02-05 06:42:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pvjlx",
          "author": "crazyfuffi",
          "text": "Anything similar for pycharm?",
          "score": 2,
          "created_utc": "2026-02-05 14:07:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r601j",
              "author": "Tanuki__",
              "text": "No idea I don't know pycharm. But you can ask Le Chat, it helped me find this solution!",
              "score": 1,
              "created_utc": "2026-02-05 17:51:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qb8pi",
          "author": "opsmanager",
          "text": "Oooh, learned something new about VSCode today, thank you! This is awesome.",
          "score": 2,
          "created_utc": "2026-02-05 15:28:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sryfl",
          "author": "alexd_dev",
          "text": "Hey guys, \n\nI created a small vscode extension  inspired by opencode, while waiting for an official integration \\^\\^ [https://www.reddit.com/r/MistralAI/comments/1qwz8gw/a\\_small\\_quick\\_and\\_dirty\\_vscode\\_extension\\_for/](https://www.reddit.com/r/MistralAI/comments/1qwz8gw/a_small_quick_and_dirty_vscode_extension_for/) \n\nThis is my first vscode extension, so I did not have the marketplace setup, download is unfortunately manual for now. Will surely do this weekend ...",
          "score": 2,
          "created_utc": "2026-02-05 22:25:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ow0gq",
          "author": "_coding_monster_",
          "text": "Do we know if Mistral is developing a VSCode extension for its models?",
          "score": 1,
          "created_utc": "2026-02-05 09:46:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ozx0u",
              "author": "grise_rosee",
              "text": "It already exists but for entreprise users only: [https://marketplace.visualstudio.com/items?itemName=mistralai.mistral-code](https://marketplace.visualstudio.com/items?itemName=mistralai.mistral-code)",
              "score": 2,
              "created_utc": "2026-02-05 10:23:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ygc0w",
          "author": "Ok_Falcon_8796",
          "text": "nice setup with Mistral Vibe, those integrations can be tricky to get right. If you're looking for something that handles multi-file edits without the manual context-switching hassle, the Zencoder IDE Plugin is worth checking out since it does multi-repo indexing with automated validation built in. I've seen good results from people using it for those kinds of workflows where you need the AI to stay coherent across differnet files.",
          "score": 1,
          "created_utc": "2026-02-06 19:39:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxkcdn",
      "title": "Merci Beaucoup Team Mistral for listening to the \"Billing in main menu\" feedback to easily view/top-up AI credits for the API!",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/n7s63ecf5whg1.png",
      "author": "EveYogaTech",
      "created_utc": "2026-02-06 15:17:30",
      "score": 20,
      "num_comments": 1,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qxkcdn/merci_beaucoup_team_mistral_for_listening_to_the/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3wxqdb",
          "author": "EveYogaTech",
          "text": "It may seems like a small improvement, but this almost prevented me from buying AI credits the other day and instead just top-up credits from a competitor. \n\nThen again. I pushed through, and eventually found it, because of our dedication to European AI @ r/Nyno",
          "score": 2,
          "created_utc": "2026-02-06 15:20:00",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxfpl7",
      "title": "Limit for the day on Free version",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qxfpl7/limit_for_the_day_on_free_version/",
      "author": "New_Philosopher_1908",
      "created_utc": "2026-02-06 11:59:56",
      "score": 20,
      "num_comments": 3,
      "upvote_ratio": 0.95,
      "text": "Hi guys,\n\nJust started using it and very much like it. Just wondering if anyone knows whether there is a daily limit on Le Chat or does it reset after a period of time (so say 2-3 hours when you don't use it?).\n\nCheers. And yes, I am here because I'm decoupling from US tech.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qxfpl7/limit_for_the_day_on_free_version/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3w8w6q",
          "author": "angry-701",
          "text": "Yes, there is. But you need to use it a LOT for it to kick in. It resets daily",
          "score": 4,
          "created_utc": "2026-02-06 13:08:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3wc4uc",
              "author": "New_Philosopher_1908",
              "text": "So after using it a lot and getting a 'you've reached your limit' info it seems to have reset and I can use it again. So in other words it's about how much you use it in a short space of time.",
              "score": 3,
              "created_utc": "2026-02-06 13:27:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtpcw5",
      "title": "The Mistral Chat website UI is a disaster",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "author": "Eddybeans",
      "created_utc": "2026-02-02 08:17:07",
      "score": 13,
      "num_comments": 22,
      "upvote_ratio": 0.68,
      "text": "My experience with Le Chat is a disaster when it comes to the UI\n\nFrequent loss of what I asked for after pressing the send button  \nchat keeps scrolling up after asking a follow up question so I have to scroll down every time\n\nthis is my experience on safari\n\ntested on le chat pro and free over the last year\n\nwhy can't we have a working desktop APP that works like GPT ? instead I had to make a web app...\n\nso sad because I love Mistral ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o356fvu",
          "author": "Substantial-Yam3769",
          "text": "Agree, the UI needs a refresh.",
          "score": 3,
          "created_utc": "2026-02-02 12:19:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35qfnb",
          "author": "stjepano85",
          "text": "Firefox has issues. Works great for me in chrome based engines but firefox was awful",
          "score": 3,
          "created_utc": "2026-02-02 14:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34jsw4",
          "author": "Depressive-Marvin",
          "text": "Agree, especially Chat scrolling up drives me crazy. Itâ€˜ like they donâ€˜t user their own product else some developer would have fixed it. Itâ€˜s sad as the overall product is good.",
          "score": 3,
          "created_utc": "2026-02-02 08:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o350tz0",
          "author": "crazyserb89",
          "text": "iOS app isnâ€™t much better too. Some basic things donâ€™t work.",
          "score": 2,
          "created_utc": "2026-02-02 11:36:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o351y35",
          "author": "inyofayce",
          "text": "I dont know but both ios app and web works fine! Havent had any issues. Unlike some of you, I am looking forward for a macos app.",
          "score": 2,
          "created_utc": "2026-02-02 11:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35fmg2",
          "author": "ShiroCOTA",
          "text": "Same with Safari and Ecosia browser. Frequently my questions simply disappear after sending them, or I get an network error on a regular basis. And the chat randomly scrolling up after placing a prompt drives me crazy.",
          "score": 2,
          "created_utc": "2026-02-02 13:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35ldje",
          "author": "JuiceOwn313",
          "text": "Iâ€™ve been using it daily for over a year, and never had any issues whatsoever",
          "score": 2,
          "created_utc": "2026-02-02 13:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34gb7o",
          "author": "Icy_Distribution_361",
          "text": "Yes I agree. I don't need a desktop app though I'm fine with browser page and actually prefer it, but these small things should be fixed more swiftly. It's not so hard to not make the page scroll up every damn time.",
          "score": 2,
          "created_utc": "2026-02-02 08:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34md2y",
          "author": "cosimoiaia",
          "text": "It's your browser.",
          "score": 2,
          "created_utc": "2026-02-02 09:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34rne0",
          "author": "Jazzlike-Spare3425",
          "text": "I am also not fond of the mobile app as someone who uses an iPad with Magic Keyboard. It doesn't have a sidebar and it doesn't support keyboard shortcuts. I ended up basically just using the Mistral API to try and build my own Le Chat that I can use across my phone, tablet and laptop with a system-native UI with all the convenience features I missed in the Le Chat ecosystem.",
          "score": 1,
          "created_utc": "2026-02-02 10:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35xfd3",
          "author": "schacks",
          "text": "I agree, it's not optimal. I use an app called MindMac to interface with various LLM's and it works fine with LeChat.",
          "score": 1,
          "created_utc": "2026-02-02 14:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o363ehy",
          "author": "deadfantasy",
          "text": "Le Chat's UI on the web works great for me on firefox but the mobile app on Android is ... a *choice*, to say the least.",
          "score": 1,
          "created_utc": "2026-02-02 15:27:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36dfal",
          "author": "silurosound",
          "text": "Wait till you see the Mistral AI Studio page... it has a background animation that's pretty cool but really slows things down.",
          "score": 1,
          "created_utc": "2026-02-02 16:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bc081",
          "author": "ExtentHot9139",
          "text": "What is sad is that you use Safari",
          "score": -1,
          "created_utc": "2026-02-03 09:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3beddh",
              "author": "Eddybeans",
              "text": "What is sad is trolls like you. Enjoy your sad life",
              "score": 1,
              "created_utc": "2026-02-03 09:49:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3bfzc0",
                  "author": "ExtentHot9139",
                  "text": "Safari is the troll and you still use it",
                  "score": -1,
                  "created_utc": "2026-02-03 10:05:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34gaod",
          "author": "nycigo",
          "text": "Chatting on the web is something else lmao ðŸ¤£",
          "score": 0,
          "created_utc": "2026-02-02 08:23:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qustvg",
      "title": "14.99 USD vs 17.99 EUR for Pro ??",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qustvg/1499_usd_vs_1799_eur_for_pro/",
      "author": "SubstantialFinance89",
      "created_utc": "2026-02-03 14:06:38",
      "score": 13,
      "num_comments": 13,
      "upvote_ratio": 0.67,
      "text": "How is that possible??",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qustvg/1499_usd_vs_1799_eur_for_pro/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3clke9",
          "author": "NovaDarkFox",
          "text": "perhaps, they are trying to attract American users, who use ChatGPT and others much more frequently, to Le Chat.",
          "score": 11,
          "created_utc": "2026-02-03 14:49:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3cehfp",
          "author": "telsaton",
          "text": "Euro includes tax",
          "score": 26,
          "created_utc": "2026-02-03 14:12:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ci2oi",
              "author": "DrPinguin98",
              "text": "14,99USD are 12.7190â‚¬ + tax (Germany 19%) that's just 15,14â‚¬",
              "score": 17,
              "created_utc": "2026-02-03 14:31:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dzblk",
                  "author": "HebelBrudi",
                  "text": "Yeah, their pricing unfairly penalizes EU customers. People who say this is because of VAT apparently have never heard of an exchange rate.",
                  "score": 9,
                  "created_utc": "2026-02-03 18:41:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ktze5",
                  "author": "WildStar_81",
                  "text": "They can't adjust usd prices every month. The dollar lost 20% in the last year to Euro.",
                  "score": 2,
                  "created_utc": "2026-02-04 18:50:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3codme",
          "author": "Cool-Chemical-5629",
          "text": "European signing up to Mistral be like\n\nhttps://preview.redd.it/xl8e52q8oahg1.jpeg?width=374&format=pjpg&auto=webp&s=0af92085bd710eb0c7a6ca5825ae5465c563fb8c",
          "score": 19,
          "created_utc": "2026-02-03 15:03:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hhsz8",
              "author": "nycigo",
              "text": "Mistral's API software is very good.",
              "score": 1,
              "created_utc": "2026-02-04 06:11:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3hxm0t",
                  "author": "Jebble",
                  "text": "\"API software\" is a pleonasm.",
                  "score": 1,
                  "created_utc": "2026-02-04 08:31:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cxjnm",
          "author": "BrucellaD666",
          "text": "I have since canceled my Mistral account but when I was paying for it and I'm in the US it was $18 or 17.99.",
          "score": 2,
          "created_utc": "2026-02-03 15:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f49ma",
          "author": "crazyserb89",
          "text": "Prices in the USA usually exclude sales tax, while in the EU, VAT is always included in the final price.",
          "score": 2,
          "created_utc": "2026-02-03 21:52:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwz8gw",
      "title": "A small quick and dirty, vscode extension for mistral vibe",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qwz8gw/a_small_quick_and_dirty_vscode_extension_for/",
      "author": "alexd_dev",
      "created_utc": "2026-02-05 22:05:54",
      "score": 11,
      "num_comments": 2,
      "upvote_ratio": 0.93,
      "text": "Hey guys,\n\nI rolled out a vscode extension tonight, to better integrate vibe in vscode, inspired by the opencode extension.\n\nThis is an early draft with rough edges, but it offers two command :\n\n\\- Open vibe terminal : create or focus a vibe terminal in side panel\n\n\\- Add selection : it will send \\`@path\\` of your current file , if you have a selection it will send \\`@path:LM-N\\` to the terminal\n\nSource is available here:  \n[https://gitlab.com/alexandre.delattre/vibe-ext](https://gitlab.com/alexandre.delattre/vibe-ext)\n\nDonwload is manual for now :\n\n[https://gitlab.com/alexandre.delattre/vibe-ext/-/wikis/home](https://gitlab.com/alexandre.delattre/vibe-ext/-/wikis/home)\n\nA small video showcasing the extension in action is on the wiki link above if you are curious.\n\nI'll publish a marketplace version, if there is further interest. I guess a better official integration will come sooner or later, but feel free to use it as an interim :)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwz8gw/a_small_quick_and_dirty_vscode_extension_for/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3v3khd",
          "author": "Intelligent-Form6624",
          "text": "canâ€™t wait for the big, lumbering and filthy second version",
          "score": 2,
          "created_utc": "2026-02-06 07:18:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v4bdp",
          "author": "Tanuki__",
          "text": "Nice!",
          "score": 1,
          "created_utc": "2026-02-06 07:25:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvs8zm",
      "title": "Le chat mixing informationfrom unrelated chats?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvs8zm/le_chat_mixing_informationfrom_unrelated_chats/",
      "author": "Inconspicuouswriter",
      "created_utc": "2026-02-04 15:54:58",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "So I've  come across an odd feature (don't  think its intentional...) so I've created various project folders for different projects, all with unrelated themes. \n\nWhen i ask it to complete an independent task in a totally unrelated project and new chat window, it somehow references concepts from the other project folders and windows. Is this normal? I tell it not to and correct it of course, however when you straight out ask it if it can draw info. From another chat, it tells you it can't and each chat is self-contained. Very odd?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvs8zm/le_chat_mixing_informationfrom_unrelated_chats/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3k6dyg",
          "author": "Square-Definition29",
          "text": "There is a box above your project library that allows you to include discussions from other projects as context. I believe the box is checked by default.",
          "score": 3,
          "created_utc": "2026-02-04 17:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lucla",
          "author": "andriatz",
          "text": "It uses memory. I disabled it because, in addition to this problem, it also limits the comprehension of long documents.",
          "score": 3,
          "created_utc": "2026-02-04 21:42:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}