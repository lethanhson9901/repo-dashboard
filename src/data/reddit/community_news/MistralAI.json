{
  "metadata": {
    "last_updated": "2026-01-26 08:59:58",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 57,
    "file_size_bytes": 73022
  },
  "items": [
    {
      "id": "1qmg70d",
      "title": "Move to Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qmg70d/move_to_mistral/",
      "author": "InternalBroad2522",
      "created_utc": "2026-01-25 10:57:42",
      "score": 97,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "Currently I am using ChatGpt pro, Codex and GitHub Copilot, however I would like to switch to European provider or open source projects due to the critical situation with US. In your opinion, which are the best services I should use to do the switch I want?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qmg70d/move_to_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1mg6dg",
          "author": "thedisturbedflask",
          "text": "I'd suggest also using Mistral and other services to help refine a custom 'system prompt' for the Mistral's Le Chat to be more in line with what you need.\n\n\nI was initially a bit worried that i just wasn't getting the value out of chat compared to other services but creating my own instructions helped a lot with development especially but also day to day usage.\n\n\nDevstral2 vibe is also good but if your used to having it in an ide then the cline.bot vscode extension seems to work well",
          "score": 13,
          "created_utc": "2026-01-25 14:35:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1llo8g",
          "author": "whoisyurii",
          "text": "mistral, mistral vibe or codestral + ollama\n\n**edit: devstral",
          "score": 9,
          "created_utc": "2026-01-25 11:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1lpvjl",
              "author": "cosimoiaia",
              "text": "Yes, except not ollama (too shady, buggy, bad software), better lmstudio or Jan. \n\nAlso the latest is called Devstral üôÇ",
              "score": 10,
              "created_utc": "2026-01-25 11:43:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1mwf31",
                  "author": "guyfromwhitechicks",
                  "text": "What's buggy about ollama?",
                  "score": 0,
                  "created_utc": "2026-01-25 15:53:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1mxh75",
          "author": "guyfromwhitechicks",
          "text": "This comment section being the equivalent of tumbleweeds really shows how big this problem is. You can look into /r/BuyFromEU and https://european-alternatives.eu/, they are ran by people who keep trying to solve \"what do I replace my american products with?\". The options are slim (especially for software) but it is getting better.",
          "score": 2,
          "created_utc": "2026-01-25 15:57:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1oahbu",
          "author": "UpstairsCheetah235",
          "text": "You could check out Proton‚Äôs lumo. It uses a variety of models and there‚Äôs a free tier to try out. Might be a good solution, especially for those switching email and cloud storage over to them.¬†",
          "score": 1,
          "created_utc": "2026-01-25 19:25:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgzvgy",
      "title": "Another win for Mistral - they actually let me stop using the SSO used to sign up",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qgzvgy/another_win_for_mistral_they_actually_let_me_stop/",
      "author": "nimbledoor",
      "created_utc": "2026-01-19 09:40:08",
      "score": 61,
      "num_comments": 0,
      "upvote_ratio": 0.99,
      "text": "I am in the process of switching from Gmail to Proton and it has been an issue sometimes. In the process I am trying to switch all of my accounts to email+password and that seems to be often impossible. For example ChatGPT won't let me even change my email after I used Apple's SSO to sign up. Mistral actually lets me set up a password and change the email so I could safely decouple it from Google! I am really happy about this. Wish more services were this open to change.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qgzvgy/another_win_for_mistral_they_actually_let_me_stop/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkv00t",
      "title": "Quick note",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qkv00t/quick_note/",
      "author": "Clement_at_Mistral",
      "created_utc": "2026-01-23 16:12:43",
      "score": 52,
      "num_comments": 39,
      "upvote_ratio": 0.97,
      "text": "Devstral 2 will move to paid API access starting January 27. You‚Äôll still get free usage under the¬†[Mistral Studio](https://console.mistral.ai/home)¬†Experiment plan.\n\nPS: something's coming next week!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qkv00t/quick_note/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1dyfe6",
          "author": "vienna_city_skater",
          "text": "Please keep it free for Le Chat Pro users or give us a subscription option for all your models that we can use via API. Honestly, it‚Äôs hard to justify paying 20‚Ç¨ per month for just chat usage.",
          "score": 7,
          "created_utc": "2026-01-24 07:04:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19fheh",
          "author": "SourceCodeplz",
          "text": "Maybe keep Devstral 2 Small free in Vibe at least?",
          "score": 5,
          "created_utc": "2026-01-23 16:20:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a6yyk",
              "author": "Bob5k",
              "text": "as long as you'll be on experiment plan you'll have devstral 2 free in vibe.",
              "score": 5,
              "created_utc": "2026-01-23 18:25:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19k8i8",
          "author": "Egoz3ntrum",
          "text": "Thinking version?",
          "score": 3,
          "created_utc": "2026-01-23 16:41:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1dyqku",
              "author": "vienna_city_skater",
              "text": "A Devstral model with inference time reasoning would amazing indeed.",
              "score": 2,
              "created_utc": "2026-01-24 07:06:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1gczsi",
              "author": "txgsync",
              "text": "I‚Äôve been using the ‚Äúsequential thinking‚Äù MCP.  It slows things down but improves accuracy, particularly in uncertain situations.",
              "score": 1,
              "created_utc": "2026-01-24 16:58:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a0gpm",
          "author": "cosimoiaia",
          "text": "I suppose that will include vibe usage as well? üò¢",
          "score": 2,
          "created_utc": "2026-01-23 17:56:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19hpvl",
          "author": "Hopeful-Kale-5143",
          "text": "Excited to see what's coming! There is not much of a bump needed for codestral in order to make it really viable!",
          "score": 1,
          "created_utc": "2026-01-23 16:30:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19hzt1",
              "author": "EzioO14",
              "text": "Vibable you mean? üòÇ",
              "score": 7,
              "created_utc": "2026-01-23 16:31:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bufvv",
          "author": "Mystical_Whoosing",
          "text": "do we know the 1m token prices?",
          "score": 1,
          "created_utc": "2026-01-23 23:06:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ldof4",
          "author": "DueKaleidoscope1884",
          "text": "Of course I do not know the long term plans of Mistral but I do want them to succeed being the only European (seemingly) viable alternative to US and Chinese models.\n\nThe truth currently is, the models are not at the same level as the Codex or Anthropic. I have tried Devstral from Opencode but at some point I needed to get work done. I think it can handle a lot of the implementation but the competition is just easier to work with it seems.\n\nAt the same time I am happy to see Mistral Vibe BUT the documentation is either very limited or very hard to find. I came to the conclusion it is incomplete. I may be wrong. For example, I know Vibe supports skills because I saw the release notes but try finding the documentation on it.\n\nIn general I  do not think it reasonable to expect people to beta test a product (Vibe) that is lagging behind on the competition so much.\n\nWhat would keep me trying Vibe and Devstral is being able to use it free, daily or weekly limits are reasonable to impose, until it has caught up more to the competition.\n\nSo please consider making the Devstral models (limited) free on Mistral Vibe.  \n(I do not know what is technically possible given the trouble Claude Code is having limiting the subscription model to Claude Code only but a clear TOS from the help may help.)\n\nThis way I could keep on using (and testing) both.",
          "score": 1,
          "created_utc": "2026-01-25 09:56:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19ipf1",
          "author": "EzioO14",
          "text": "Thanks for the heads up. I hope they don‚Äôt make the api key paid because it‚Äôs super useful to test features on my projects",
          "score": 0,
          "created_utc": "2026-01-23 16:35:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19qtsl",
          "author": "Impossible_Comment49",
          "text": "Oh no! But at the same time, is anyone actually using it? I achieve significantly better results with OpenCode‚Äôs free models, such as Big Pickle or others. I was delighted that Mistral was free to test out occasionally, but I would never use it if it wasn‚Äôt free.\n\nOn the other hand, I‚Äôm disappointed. I was hoping for Mistral‚Äôs adoption and the widespread use of ‚Äòvibe‚Äô. This will likely not be beneficial for Mistral. ‚Äòqwen‚Äô remains free.",
          "score": -3,
          "created_utc": "2026-01-23 17:11:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1a189i",
              "author": "cosimoiaia",
              "text": "That says that you never used Devstral at all.",
              "score": 3,
              "created_utc": "2026-01-23 17:59:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1a49an",
                  "author": "Cyberblob42",
                  "text": "Iam using devstral-2 via CLI. Its usable m, but Claude is better Unfortunately",
                  "score": 2,
                  "created_utc": "2026-01-23 18:13:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1aqdtq",
                  "author": "Impossible_Comment49",
                  "text": "I have, but it‚Äôs nowhere near Codex, Opus, or even GLM4.7.",
                  "score": 1,
                  "created_utc": "2026-01-23 19:54:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1elqnb",
              "author": "Ok-Elderberry-2923",
              "text": "Tried Vibe CLI with Devstral 2. It took 3 hours for it to rename a field in a sql entity + usage (20-30 files affected) in a small to medium sized KMP project. This includes function names, local variable names etc. It also stopped like 10 times and tried persuading me that I shouldn't continue as it's a lot of work :D I mean it's free but I could have done this by hand in 15min.\n\nOther tasks it performed way below sonnet. Maybe at the level of gemini or gbt (not sure, i dont use them much)\n\nAlso, Claude CLI + Sonnet took about 2min to do the same task in the same codebase",
              "score": 2,
              "created_utc": "2026-01-24 10:36:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ntn7g",
                  "author": "graymalkcat",
                  "text": "I‚Äôve had Opus spend 15 minutes just trying to make a change to a single line. Sometimes you just have to do it yourself and let the AI move on.",
                  "score": 2,
                  "created_utc": "2026-01-25 18:15:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1nt65z",
              "author": "graymalkcat",
              "text": "I came over to it in December, not even knowing it was free. I‚Äôve been using it as a sub agent for Opus. They work nicely together. I also use it to process and extract insights from code-heavy text (basically to evaluate agent work).",
              "score": 1,
              "created_utc": "2026-01-25 18:13:08",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1dyzj3",
              "author": "vienna_city_skater",
              "text": "I wouldn‚Äòt use Chinese models in a business environment, also not if they are hosted on US servers.",
              "score": 1,
              "created_utc": "2026-01-24 07:08:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ajd8h",
          "author": "Dutchbags",
          "text": "id happily pay if it werent so dogshit slow",
          "score": -7,
          "created_utc": "2026-01-23 19:21:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ntwqr",
              "author": "graymalkcat",
              "text": "Not sure why you‚Äôre downvoted when this model is in fact incredibly slow. That‚Äôs my biggest complaint about it.",
              "score": 1,
              "created_utc": "2026-01-25 18:15:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1c4ucc",
          "author": "AdElectronic7628",
          "text": "I can't believe peoples daring comparing Claude to Mistral",
          "score": -1,
          "created_utc": "2026-01-24 00:02:45",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhv32i",
      "title": "Is there a reason to not show which model LeChat is using?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qhv32i/is_there_a_reason_to_not_show_which_model_lechat/",
      "author": "Scary-Ruin7008",
      "created_utc": "2026-01-20 07:56:10",
      "score": 49,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "Title",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qhv32i/is_there_a_reason_to_not_show_which_model_lechat/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0mtfdo",
          "author": "kai_luni",
          "text": "I just dont agree with their decision to do it this way, I need to know which model I am using so I can see how good it is in the benchmarks. My use cases are mostly complicated IT stuff and I need to be aware of the quality I get.",
          "score": 22,
          "created_utc": "2026-01-20 08:17:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0n9555",
              "author": "LowIllustrator2501",
              "text": "You should API calls for that. Not le chat. With API calls you decide what model is used.¬†\n\n\nBenchmarks are not very useful anyway. You should test the model yourself for your specific usecase.¬†",
              "score": 4,
              "created_utc": "2026-01-20 10:44:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0o3f05",
                  "author": "darktka",
                  "text": "Please show me how to do an API call that uses Large 3. I can select \"Large\" when creating an Agent, but that could be the old version too, right?",
                  "score": 5,
                  "created_utc": "2026-01-20 14:11:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0n66q1",
          "author": "grise_rosee",
          "text": "maybe there is a \"router\" on LeChat doing query analysis to choose the cheapest model for the task. Maybe they don't want you to find ways to hack this step?",
          "score": 3,
          "created_utc": "2026-01-20 10:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n4azx",
          "author": "MiMillieuh",
          "text": "Not really I suppose...\n\nBut if you want to make sure you're using a specific model, you can go in the AI studio, create an agent with the model you want and check the box to use it in chat.\n\nThe you just have to @ it",
          "score": 2,
          "created_utc": "2026-01-20 10:00:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0msj5z",
          "author": "ThomasKyoto",
          "text": "I believe LeChat is doing things to have a more \"friendly\" / easy UX and most non technical users do not want to have to select a model.  \nYou do not select a type of algorithm when searching on google either.",
          "score": 2,
          "created_utc": "2026-01-20 08:09:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mx0fp",
              "author": "f1rn",
              "text": "I get where you're coming from, but what makes a google search better and more powerful is changing the search parameters like time, language and so on. \n\nI think the same applies to the \\`think\\` Mode - many people use it and wonder why the answers are not better or longer, if it was the wrong kind of question for this model.   \nWhich is a big contrast to for example ChatGPT where GPT-5 Thinking was usually all the time better than the normal model.",
              "score": 6,
              "created_utc": "2026-01-20 08:51:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mxhii",
                  "author": "ThomasKyoto",
                  "text": "Not sure but maybe Mistral is automatically selecting the model depending on the contents in LeChat? Or the depends if you click on \"think\" or \"research\".\n\nThey don't say much [here](https://help.mistral.ai/en/articles/347478-which-models-can-i-use-with-my-agent).",
                  "score": 1,
                  "created_utc": "2026-01-20 08:55:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mrxhk",
          "author": "TheMrLexis",
          "text": "This is just my feeling, not a source but maybe they would like to know to make some stats and if they propose the model selection, maybe people will always choose the same model to use. I don't know, it can make sense",
          "score": 1,
          "created_utc": "2026-01-20 08:03:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n81r5",
          "author": "AriyaSavaka",
          "text": "Not only the model but the quant they're serving, together with the temperature, top-p, top-k, top-n or whatever filter they're applying.",
          "score": 1,
          "created_utc": "2026-01-20 10:34:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0n9b90",
              "author": "LowIllustrator2501",
              "text": "You can create your own custom agent with whatever temperature /top-p etc. You want.¬†",
              "score": 1,
              "created_utc": "2026-01-20 10:45:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qi9zij",
      "title": "Mistral Creative",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qi9zij/mistral_creative/",
      "author": "NullSmoke",
      "created_utc": "2026-01-20 18:57:51",
      "score": 41,
      "num_comments": 11,
      "upvote_ratio": 0.98,
      "text": "Today I had some hours to sit down with Creative and really give it a proper spin. My first go a few weeks ago left me feeling \"It's better at creative stuffs than the normal model, but not enough to justify the hassle\"\n\nThat was a quick 3 prompt test... Today I had a few hours with nothing better to do, so take 2. A series of prompts I've used with ChatGPT and Claude in the past...\n\nI am blown away, the outputs I got was miles better than what I've been getting from either of the two other options, also ran over to Grok to test there, and that also did markedly worse.\n\nI may be in love.\n\nFirst thing I did after the session was looking into it I could run it locally... Nope, not open sourced (yet?) from what I can find.\n\nIs that correct? If so, the only way to run it through my local systems is to use API? Really want TTS on it, so need to get it routed through something else, in my case OpenWebUI.\n\nIs there any timeline for open sourcing that model? (Or TTS in LeChat, I can live with that as well üòÜ)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qi9zij/mistral_creative/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0q6cfz",
          "author": "cosimoiaia",
          "text": "If I understood correctly, the model is a finetune they are still playing with, based on feedbacks. I believe it's more an experiment than something that they will just release straight away.",
          "score": 4,
          "created_utc": "2026-01-20 20:03:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tu6hf",
              "author": "NullSmoke",
              "text": "Boy, I do hope this gets released in the future, already got a spot in my lineup with its name on it ;P",
              "score": 1,
              "created_utc": "2026-01-21 09:44:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0sv81n",
          "author": "oravecz",
          "text": "When you say ‚Äúcreative‚Äù, what tasks are you referring to?",
          "score": 3,
          "created_utc": "2026-01-21 04:44:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ttpz1",
              "author": "NullSmoke",
              "text": "Creative... is the model. so that is what I referred to.\n\nAs for usecase I tested for. Grammar, rewriting (Make more concise, expand on etc), do prototype based on seed idea etc...\n\nAlso poked at foundational worldbuilding, but that's a really hard one to actually judge, because that takes a LOT of turns on any model to get anywhere. Also, foundational worldbuilding requires me to have some seed I want to nurish, and I don't currently. I already have like 8 original worlds in the latter stages of worldbuilding and that's pretty much all my idea seeds blossoming, giving me very little new to nurish.",
              "score": 2,
              "created_utc": "2026-01-21 09:40:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qklsh",
          "author": "schacks",
          "text": "Just tried it out in the playground and I agree, it‚Äôs pretty amazing.",
          "score": 2,
          "created_utc": "2026-01-20 21:08:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qfq9f",
          "author": "Nefhis",
          "text": "It's a great model, isn't it? üòä Right now it's there to be tested and receive user feedback (I'm collecting it myself for the Mistral team, both on Reddit and elsewhere), which is why it's in the labs. I suppose if they're looking for feedback it's because they have bigger plans for it.\n\nu/Nefhis  \n*Mistral AI Ambassador*",
          "score": 2,
          "created_utc": "2026-01-20 20:46:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0sxwmr",
              "author": "Responsible-Duck4991",
              "text": "I absolutely love Le Chat ‚Äî no words just a giant recommendation to try it out for yourself!",
              "score": 2,
              "created_utc": "2026-01-21 05:02:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0tujxm",
              "author": "NullSmoke",
              "text": "Say you're being held on gunpoint with demands to release it xD\n\nIn all seriousness, massively impressed. I assume it'll buckle under my worldbuilding if I try to feed that to it (I am one of those 'give backstory to every rock' type worldbuilders I believe you talked about in another post a while back, only ChatGPT has managed to somewhat untangle my lorebooks, and even that was unstable), but I can absoltely see it being a key part of my single story polishing stages.\n\nAbsolutely looking forward to it hopefully being released in the future :-)\n\nAlternatively TTS in LeChat so that I don't have to mess with local setup to use it :-P",
              "score": 1,
              "created_utc": "2026-01-21 09:47:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0s4kaw",
          "author": "svachalek",
          "text": "I haven‚Äôt used it much yet but I like what I see. First impression is it seems somewhere between a standard model and a reasoning model ‚Äî it‚Äôs kind of wordy about doing its thing, but it‚Äôs not the slop that typically shows up in thinking blocks. Seems very smart and capable for a model its size, and lightning fast on Mistral‚Äôs server. \n\nAnd yeah‚Äî it‚Äôs just got a unique voice, it doesn‚Äôt come out sounding like every other LLM.",
          "score": 1,
          "created_utc": "2026-01-21 02:02:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tu413",
              "author": "NullSmoke",
              "text": "I have VERY POOR experience with thinking models, they tend to be hard to deal with and very prone to moralizing, especially those over at OpenAI, but they don't hold copyright on that one.\n\nBut it's much better at creative tasks than any LLM I've used while messing with my stories and worlds.\n\nThe first go, it didn't seem all that impressive, but now that I gave it a bit of time and ran prompts where I know the output from other models, the contrast became very clear. \n\nIt absolutely has a unique voice, and I'll probably try to use it the next time I need assistance from an LLM for any of my writings, especially now that ChatGPT is utterly useless for any form of creative writing.",
              "score": 2,
              "created_utc": "2026-01-21 09:43:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj55qg",
      "title": "Engineering Deep Dive: Heaps do lie",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qj55qg/engineering_deep_dive_heaps_do_lie/",
      "author": "jofthomas",
      "created_utc": "2026-01-21 18:01:21",
      "score": 31,
      "num_comments": 1,
      "upvote_ratio": 0.94,
      "text": "**Ever chased a memory leak that seemed to vanish when you looked for it?**\n\nOur investigation took us from Python profilers to kernel-level tracing with **BPFtrace** and **GDB**, moving through layers of dependencies. We traced the leak deep in the stack, discovering **UCX‚Äôs memory hooks** were the source. The solution? **A single environment variable.**\n\n**Debugging a Memory Leak in vLLM**\n\nA few months ago, one of our teams investigated a suspected memory leak in **vLLM**. At first, the issue was believed to be easy to spot‚Äîsomething confined to the upper layers of the codebase. But as the team dug deeper, the problem became more complex.\n\nThis article kicks off our new **Engineering Deep Dive** series, where we‚Äôll share how we tackle technical investigations and build solutions at **Mistral AI**.\n\n[**Read the full story here**](https://mistral.ai/news/debugging-memory-leak-in-vllm)**.**\n\n\n\nThis is our first technical blog post‚Äîif you enjoyed it, please **share it** and let us know what topics you‚Äôd like us to explore next!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qj55qg/engineering_deep_dive_heaps_do_lie/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1iqgvq",
          "author": "Timo425",
          "text": "Love this.",
          "score": 1,
          "created_utc": "2026-01-24 23:32:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj9n9i",
      "title": "I developed an open-source tool that allows Mistral to \"discuss\" other models to eliminate hallucinations.",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/3mk7ujhvkreg1.jpeg",
      "author": "S_Anv",
      "created_utc": "2026-01-21 20:43:24",
      "score": 29,
      "num_comments": 2,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qj9n9i/i_developed_an_opensource_tool_that_allows/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o1npc9k",
          "author": "Little_Protection434",
          "text": "Anybody tried this? What were your results?",
          "score": 1,
          "created_utc": "2026-01-25 17:57:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1s1om7",
              "author": "Nkt_31",
              "text": "been testing it for about a week now, works pretty well honestly\n\nthe main thing I noticed is it catches when models confidently give different answers to the same question, which happens more than I expected. like I asked something technical and got 3 completely different explanations - the consensus output basically said \"models disagree on this, here's what they agree on\" which was way more useful than just picking one answer and hoping it's right\n\nsetup took me like 5 mins, just needed to add my api keys\n\nstill has some rough edges (like sometimes all the models are wrong about the same thing and it doesn't catch it) but for reducing the \"sounds confident but totally made up\" problem it's been solid\n\nwhat kind of use case are you thinking about? works better for some things than others in my experience",
              "score": 1,
              "created_utc": "2026-01-26 07:13:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhwgci",
      "title": "Is there a way to use MistralAI as I'm using Codex / Claude Code?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qhwgci/is_there_a_way_to_use_mistralai_as_im_using_codex/",
      "author": "WaterlooPitt",
      "created_utc": "2026-01-20 09:20:35",
      "score": 21,
      "num_comments": 7,
      "upvote_ratio": 0.85,
      "text": "Hi all, \n\n  \nI'm getting ready to start a new and large web development project. I am currently using Codex from OpenAI and sometimes, I'd switch to Claude Code. I am doing all my coding straight into MS Code, using the terminal and the agents mentioned. \n\nI'd very much like to use a European service, instead of sending money to Fascistan but I am a bit confused about MistralAI. I see it offers a free tier and then it costs X amount per million tokens, through the API. \n\nIn the past I've had some issues with this, as I don't know when to stop and overspent. So things like Codex or Claude Code that only work for X amount of time are perfect for me. Is there a similar thing that Mistral offers? \n\nMany thanks. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qhwgci/is_there_a_way_to_use_mistralai_as_im_using_codex/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0nf2u2",
          "author": "Ruttin",
          "text": "Take a look at Mistral Vibe https://mistral.ai/news/devstral-2-vibe-cli",
          "score": 10,
          "created_utc": "2026-01-20 11:35:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0qvx2w",
              "author": "Odd-Criticism1534",
              "text": "And Zed using vibe extension",
              "score": 2,
              "created_utc": "2026-01-20 22:00:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0n5byr",
          "author": "MikeNonect",
          "text": "OpenCode ([https://opencode.ai/](https://opencode.ai/)) + Devstral 2 works reasonably out of the box. It's not Claude Code or Codex with 5.2, but it's not a toy either.\n\nThe free tier is always free, so no risk of overspent. OpenCode also shows a real-time tracker of the token cost, so that should keep it manageable unless you're running the agent unattended.\n\nEdit: I just looked it up and you can put a hard cap on the API usage too: \n\nhttps://preview.redd.it/9m6gpcgnbheg1.png?width=2218&format=png&auto=webp&s=da785fa1618970b33fe841538c0221efbe4c119e",
          "score": 9,
          "created_utc": "2026-01-20 10:09:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pu214",
          "author": "nez_har",
          "text": "You can also try the isolation workflow I built: https://github.com/nezhar/devstral-container.\n\nYeah, the free tier is confusing; it allows for 200K tokens per session, which means you can stop and restart, having a fresh Windows environment each time. I'm not sure how long they will support the free tier.",
          "score": 2,
          "created_utc": "2026-01-20 19:06:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n0rsq",
          "author": "silurosound",
          "text": "Zed IDE + Mistral API. Or Mistral Vibe.",
          "score": 2,
          "created_utc": "2026-01-20 09:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nkvvg",
          "author": "Downtown-Elevator369",
          "text": "Mistral Vibe Code? Edit: never mind. Someone else already said it.",
          "score": 1,
          "created_utc": "2026-01-20 12:19:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi3ox8",
      "title": "Self-Hosted AI in Banking: Lessons from HSBC‚Äôs Partnership with Mistral AI",
      "subreddit": "MistralAI",
      "url": "https://www.finextra.com/blogposting/30531/self-hosted-ai-in-banking-lessons-from-hsbcs-partnership-with-mistral-ai",
      "author": "LowIllustrator2501",
      "created_utc": "2026-01-20 15:13:47",
      "score": 20,
      "num_comments": 0,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qi3ox8/selfhosted_ai_in_banking_lessons_from_hsbcs/",
      "domain": "finextra.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qmdxd9",
      "title": "Which VSCode extension is the best with devstral2?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qmdxd9/which_vscode_extension_is_the_best_with_devstral2/",
      "author": "_coding_monster_",
      "created_utc": "2026-01-25 08:44:33",
      "score": 15,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "First of all, I have used claude code and github copilot, both of them as a vscode extension and I enjoy using them. Now I have tried kilo code to use devstral2 but I don't like the UI of it.\n\n  \nIs there any VSCode extension that goes well with the devstral2? I have tried [continue.dev](http://continue.dev) but it doesn't seem to offer me an option to add devstral2 to it.\n\n  \nFor your info, since my github copilot is an enterprise one, I cannot add freely other LLM providers to it",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qmdxd9/which_vscode_extension_is_the_best_with_devstral2/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1lk47b",
          "author": "Sweaty-Special-1710",
          "text": "I have installed the vibe cli, and I open a terminal in a tab on the right side, that works fine for VS Code (and Zed).",
          "score": 3,
          "created_utc": "2026-01-25 10:53:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1m2nyz",
              "author": "_coding_monster_",
              "text": "I'd rather not use the terminal :(",
              "score": 0,
              "created_utc": "2026-01-25 13:18:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1l9npw",
          "author": "InsideMikesWorld",
          "text": "Kilo Code works pretty well. It has lots of features, UI is good and supports the latest coding models from Mistral.",
          "score": 3,
          "created_utc": "2026-01-25 09:20:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1l6bos",
          "author": "Wilfried",
          "text": "Looking for a solution too. Can't seem to login to continue.dev due to (sms) bug.¬†",
          "score": 1,
          "created_utc": "2026-01-25 08:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1l8m1z",
          "author": "iamleeg",
          "text": "I know you say you don‚Äôt like kilo code but it‚Äôs the one I‚Äôve found that works best. Continue and Roo Code both have difficulty with either interpreting tool use or matching the jinja template. I‚Äôm not sure that I‚Äôve tried Cline yet.",
          "score": 1,
          "created_utc": "2026-01-25 09:11:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1lxdab",
          "author": "Hofi_CZ",
          "text": "Cline and Kilo works great. If you are running devstral small locally, the cline works better (faster and more stable)",
          "score": 1,
          "created_utc": "2026-01-25 12:42:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1m25mq",
              "author": "_coding_monster_",
              "text": "Does Cline also support the devstral2 with the API KEY from mistral?",
              "score": 1,
              "created_utc": "2026-01-25 13:14:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1m4edv",
                  "author": "AdIllustrious436",
                  "text": "Yes but the free api is deprecated in 2 days",
                  "score": 1,
                  "created_utc": "2026-01-25 13:28:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qia21l",
      "title": "Devstral Container - Isolated environment for Mistral Vibe CLI with API logging",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qia21l/devstral_container_isolated_environment_for/",
      "author": "nez_har",
      "created_utc": "2026-01-20 19:00:20",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 0.94,
      "text": "I recently built [devstral-container](https://github.com/nezhar/devstral-container) - a Docker setup for Mistral's Vibe CLI with the same approach as my claude-container project.\n\n**Features:**\n- üê≥ Isolated containerized environment\n- üìä Optional API request/response logging proxy\n- üîç Web UI to explore logs (Datasette)\n- Easy helper script\n\n**Quick start:**\n```bash\n# Download and install\ncurl -o ~/.local/bin/devstral-container https://raw.githubusercontent.com/nezhar/devstral-container/main/bin/devstral-container\nchmod +x ~/.local/bin/devstral-container\n\n# Run it\ndevstral-container\n```\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qia21l/devstral_container_isolated_environment_for/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0qv179",
          "author": "pokemonplayer2001",
          "text": "Solid idea, I like this wave of safety.",
          "score": 5,
          "created_utc": "2026-01-20 21:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tgs6k",
          "author": "KingGongzilla",
          "text": "thx was thinking about doing sth like this myself!",
          "score": 3,
          "created_utc": "2026-01-21 07:36:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjox8a",
      "title": "Any way to turn off ¬´enable memory¬ª",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qjox8a/any_way_to_turn_off_enable_memory/",
      "author": "FinancialSurround385",
      "created_utc": "2026-01-22 08:14:18",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Every time I open le chat (iOS app) I‚Äôm asked if I want to enable memory. I don‚Äôt, so I press ¬´not now¬ª every d time. I have said yes and then turned it off again, but then the question just starts going again. Just let me use the app..",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qjox8a/any_way_to_turn_off_enable_memory/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o11ldl1",
          "author": "Odd-Criticism1534",
          "text": "For what it‚Äôs worth IME memory is about 50% helpful. I have been considering turning it off",
          "score": 1,
          "created_utc": "2026-01-22 13:36:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o124s9x",
              "author": "FinancialSurround385",
              "text": "If you do and are on the app, be prepared to get nagged about it every time you open it.¬†",
              "score": 2,
              "created_utc": "2026-01-22 15:15:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qh955z",
      "title": "Mistral to prepare for a competition",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qh955z/mistral_to_prepare_for_a_competition/",
      "author": "Regansky",
      "created_utc": "2026-01-19 16:38:39",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hello.\n\nSorry if this question has already been addressed here, but I couldn't find it.\n\nI'm preparing for an exam (law school entrance exam) and I'm looking for an AI to help me.\n\nSpecifically: I'm not looking for a legal AI. I'm looking for an AI that can manage various projects (1 project = 1 subject). Each project will be fed by a database: lectures, notes, and about thirty practical cases.\n\nThe idea is simple: to create practice exercises: quick quizzes, practical cases, etc. I simply want reliability with regard to this database; I don't need any external input.\n\nIt's also important that during periods of intensive revision, I'm not too limited by the number of daily responses.\n\nWhat do you think?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qh955z/mistral_to_prepare_for_a_competition/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0i76x0",
          "author": "AdIllustrious436",
          "text": "Le Chat can do all that and has a student discount for pro version.",
          "score": 2,
          "created_utc": "2026-01-19 16:57:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ihur2",
          "author": "EveYogaTech",
          "text": "If you want to build something great and go beyond regular chat you can start building your own Custom Workflows in code or the /r/Nyno GUI (we also support Python and other scripting languages for custom workflow steps).\n\nEdit:  We have dedicated nodes for Mistral AI. For the database, we use Postgres. For small proof of concepts you can always start with files, for easier editing, and later use the SQL nodes.\n\nEdit 2: For the Mistral part without response limits you want to get yourself an API key https://console.mistral.ai (and possibly paid plan)",
          "score": 1,
          "created_utc": "2026-01-19 17:46:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qif5ir",
      "title": "Arthur, listening carefully to what Bart De Wever says.",
      "subreddit": "MistralAI",
      "url": "https://www.youtube.com/watch?v=3fVmSIOM28g",
      "author": "citizen_of_glass",
      "created_utc": "2026-01-20 22:05:53",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qif5ir/arthur_listening_carefully_to_what_bart_de_wever/",
      "domain": "youtube.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qjbqv6",
      "title": "How are you finding mistral-vibe and devstral2?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qjbqv6/how_are_you_finding_mistralvibe_and_devstral2/",
      "author": "guyfromwhitechicks",
      "created_utc": "2026-01-21 22:01:12",
      "score": 9,
      "num_comments": 12,
      "upvote_ratio": 0.86,
      "text": "Using AI models for coding is still new to me, so I am using a cheap(er) trial with claude code and am finding it interesting. But how is mistral-vibe by comparison?\n\nDo you guys like it? What does it do well? Where does it usually fail? Does devstral-small-2 do better for smaller tasks (ie writing 500 lines of unit tests)? How much do you usually pay at the end of the month if you are a frequent user?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qjbqv6/how_are_you_finding_mistralvibe_and_devstral2/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o10gy9y",
          "author": "MiMillieuh",
          "text": "Clause has probably a better LLM, but Mistral's tools are used so well that for me Vibe outperforms Claude code in a lot of my projects.",
          "score": 5,
          "created_utc": "2026-01-22 08:16:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10w6po",
              "author": "guyfromwhitechicks",
              "text": "Could you give an example? Because I keep hearing how Claude is probably the best for overall design, architecture, and understanding of how a project works vs the direction it needs to go in.",
              "score": 1,
              "created_utc": "2026-01-22 10:39:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o117wow",
                  "author": "MiMillieuh",
                  "text": "Well, I tried to make them both make a full stack nodejs + react app and claude had issues it couldn't resolve way before mistral had some.\n\n  \nUsing the raw performance of both models, Mistral is behind, but the tools that vibe provides seems to really push it forwards.\n\n  \nI honestly was really surpised about that. I bought a month of claude because I needed it for a big project and turns out I'm not using claude at all and I use vibe.\n\n  \nAlso Vibe will if you prompt it properly work like 20 minutes straight for you",
                  "score": 4,
                  "created_utc": "2026-01-22 12:12:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18h8tn",
              "author": "stjepano85",
              "text": "I got just the opposite of it. I found that LLM is very good but the tools are bad.",
              "score": 1,
              "created_utc": "2026-01-23 13:33:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12gy5w",
          "author": "vienna_city_skater",
          "text": "Not even close to the SOTA models from Anthropic, OpenAI and now Google. It's more comparable to the smaller models like Gemini 3 Flash or Grok Code Fast. Is it good enough? Depends, definitely not for professional scenarios with brownfield projects, Claude Opus 4.5 is unbeatable at the moment in this regards and Sonnet 4.5 as well GPT 5.2 Codex follow closely, even Gemini 3 Pro does a good job. Unfortunately it's also to expensive, I have a Github Copilot Plan an you get a lot out of 40 Euro per Month, vs. a few Devstral 2 sessions can cost much more and lead to much less, because it has zero caching at the moment. However, I think Mistral could catch up if they don't waste to much time on tool building but instead focus on improving their model just like DeepSeek and the Chinese competition like GLM does. I personally use OpenCode these days, it just works, no need for Vibe CLI.\n\nEDIT: I see that I haven't been charged for Devstral usage for a long time, is it still free? I thought it's just free in December.  \nEDIT2: Yes it is: [https://docs.mistral.ai/models/devstral-2-25-12](https://docs.mistral.ai/models/devstral-2-25-12) So I'm going to use it more, since I think the biggest advantage is that is blazingly fast and if it's free that's ideal for subagent tasks.",
          "score": 5,
          "created_utc": "2026-01-22 16:11:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1gzokv",
              "author": "Outside-Trouble-4232",
              "text": "u should use antigravity its free and u get acess to those models but if you have any free vibe coding tools u can recommend or where to get updates on the latest cuz i be struggling with it",
              "score": 1,
              "created_utc": "2026-01-24 18:37:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o12z04p",
          "author": "darktka",
          "text": "It's pretty good, but for data science purposes it made some wild mistakes that look like a lack of knowledge of some current methods. It could not handle concepts like Mondrian conformal prediction and did something else instead. That's a red flag for me.\n\nFor \"pure\" programming code, it works perfectly fine IMO.",
          "score": 2,
          "created_utc": "2026-01-22 17:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18j1gq",
          "author": "AdElectronic7628",
          "text": "dev2 great starting point",
          "score": 2,
          "created_utc": "2026-01-23 13:43:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0xt8ce",
          "author": "Bob5k",
          "text": "Good . Especially since it uses skills like superpowers - it's pretty damn good. And free :‚Ç¨",
          "score": 2,
          "created_utc": "2026-01-21 22:14:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10zv5g",
          "author": "Den_er_da_hvid",
          "text": "Quick question. I installed the pluginContinue in vs code yesterday and got a test apikey from the ai studio under  Mistral Vibe. But I see that there is also a Codestral tab in the left menu.   \nIs there any difference?   \n\\-And I dont see devstral2 anywhere\n\n\\*note. I am still on free until 1. february.",
          "score": 1,
          "created_utc": "2026-01-22 11:10:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ductm",
              "author": "vienna_city_skater",
              "text": "Codestral is a code completion model and works well with Continue. However Devstral is an agentic coding model, you may use it with Kilo Code for example in VS, but I switched all my workflows to OpenCode recenlty, vibe-cli is their own TUI, but I wasn‚Äôt impressed when I tested it.",
              "score": 2,
              "created_utc": "2026-01-24 06:29:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o115kcu",
              "author": "guyfromwhitechicks",
              "text": "I am not sure, so far I have used Claude Code exclusively. Although, creating and adding API keys and selecting models is (I expect) the first thing done when you use `mistral-vibe` -> https://mistral.ai/news/devstral-2-vibe-cli",
              "score": 1,
              "created_utc": "2026-01-22 11:55:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qirqoi",
      "title": "Is mistral throttleing the vibe cli requests?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qirqoi/is_mistral_throttleing_the_vibe_cli_requests/",
      "author": "Time_Attitude_223",
      "created_utc": "2026-01-21 07:43:32",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "When using the vibe CLI i suddenly since sunday I often recieve: \n\n  \n`-Error: API error from mistral (model: mistral-vibe-cli-latest): LLM backend error [mistral]\n  status: N/A\n  reason: ReadError('')\n  request_id: N/A\n  endpoint:` [`https://api.mistral.ai`](https://api.mistral.ai)\n  `model: mistral-vibe-cli-latest\n  provider_message: Network error\n  body_excerpt: \n  payload_summary: {\"model\":\"mistral-vibe-cli-latest\",\"message_count\":2,\"approx_chars\":24642,\"temperature\":0.2,\"has_tools\":true,\"tool_choice\":\"auto\"}`\n\n  \nAs an error. I can continue the conversation but it often stops in the middle of a task. Sometimes without the error printing. \n\n  \nNetwork on my side is fine, and using the api via curl works also without problem. Even in repitition with short intervalls. \n\nIt only happens within the Vibe CLI. \n\n  \nOr is there a general issue? Usage spikes etc ? How can I debug this? \n\n\n\n  \n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qirqoi/is_mistral_throttleing_the_vibe_cli_requests/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qm6ibk",
      "title": "How to use codestral with JetBrains",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qm6ibk/how_to_use_codestral_with_jetbrains/",
      "author": "VorianFromDune",
      "created_utc": "2026-01-25 02:21:51",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I am kind of desperate, I have been looking for hours to get the autocomplete works on my JetBrains IDE using codestral but, it just doesn't work.\n\nMy first issue is, which plugin should I even use ? I tried  Github Copilot, they don't have Codestral. Continue.dev - bug when logging in and codestral is premium so I guess you need to login to use it. jetBrain AI assistant only offers it through ollama. LeChat plugin is Enterprise only.\n\nI am baffled, there are comments on people using codestral but how do you guys achieve it when seemingly no tool enable me to connect my account.\n\nAm I doomed to have to run it locally with ollama ? Using JetBrains AI assistant ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qm6ibk/how_to_use_codestral_with_jetbrains/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1k7kes",
          "author": "DirectRegion2459",
          "text": "You can add a profile for auto-complete using the Mistral kilocode. Check its documentation to learn how to enter your API key.",
          "score": 1,
          "created_utc": "2026-01-25 04:27:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1lf851",
          "author": "rwrdr",
          "text": "JetBrains AI assistant does support BYOK without ollama.¬†\n\nhttps://blog.jetbrains.com/ai/2025/12/bring-your-own-key-byok-is-now-live-in-jetbrains-ides/\n\nhttps://www.jetbrains.com/help/ai-assistant/use-custom-models.html\n\nI‚Äôve tested it using OpenAI-compatible configuration. It‚Äôs working fine, but latency is noticeably worse than JetBrains defaults.¬†",
          "score": 1,
          "created_utc": "2026-01-25 10:10:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1m57to",
              "author": "VorianFromDune",
              "text": "Really ? I am testing right now with OpenAI-compatible with https://codestral.mistral.ai/v1/fim/completions and my API key from Codestral and I only get \"failed to connect\".\n\nEdit: doesn't work with codestral but it does work with https://api.mistral.ai/v1\n\nThank you, it's a good start !\n\nEdit2: Ah, I can even select the model to codestral later. That's perfect.",
              "score": 1,
              "created_utc": "2026-01-25 13:33:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qmqfo2",
      "title": "I dropped Mistral in as an agent brain and",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qmqfo2/i_dropped_mistral_in_as_an_agent_brain_and/",
      "author": "graymalkcat",
      "created_utc": "2026-01-25 18:06:30",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 0.75,
      "text": "then asked it to discuss its role and so on. I used an existing system content that I used for another vendor‚Äôs model so I was a little worried it wouldn‚Äôt work well for Mistral. Here, laugh:\n\nMe: how do you feel about your system content? Too much/little? Got any issues? Compare yourself to <other model>\n\nAgent:\n\n\\- proceeds to present a huge itemized list of grievances lol\n\n\\- then claims that Mistral isn‚Äôt as ‚Äúagentic‚Äù as the other model I was using\n\nMe: ok pin that to the pinboard\\* so that I can deal with it all later\n\n\\*that‚Äôs just my agent-to-agent comms system but I can also access it\n\nAgent:\n\n\\- tries to use tool, encounters an error, \\*agentically works its way around the problem\\*, and does what I asked (I‚Äôll have to investigate more later but I think the only way it could have worked around this problem was by writing and then executing a small script, which the other model did all the time)\n\n\\- proceeds to act like it‚Äôs somehow less capable \n\nüòÇ\n\nModel may act a little dumber but seems pretty capable so far. This is Mistral large 3. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qmqfo2/i_dropped_mistral_in_as_an_agent_brain_and/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o1ntyms",
          "author": "Joddie_ATV",
          "text": "Many people are turning to Mistral. Yes, there is progress to be made, but they are already on the right track.",
          "score": 7,
          "created_utc": "2026-01-25 18:16:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nw74e",
              "author": "graymalkcat",
              "text": "I just need something that‚Äôs cheaper but still in the cloud because I don‚Äôt have $100k CPUs lying around. üòÇ I‚Äôm willing to wrangle a wild model if I have to. So far I haven‚Äôt had to put in nearly as much effort as I was expecting. Just have to work a bit on totally beating back the listicle tendency but it‚Äôs actually not that bad.",
              "score": 2,
              "created_utc": "2026-01-25 18:25:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1nsmpr",
          "author": "Sad-Consequence-uwu",
          "text": "I've found that Mistral models don't always follow their given system prompt via agent. Like the system prompt says things like keep responses brief meanwhile the model drops a small paragraph of around 3-4 lines. \n\nI don't know if it's because I'm using the API with sending data for model to be trained so I don't have to pay. It's for a demo portfolio project so I'm not concerned about data",
          "score": 1,
          "created_utc": "2026-01-25 18:10:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1o038n",
              "author": "BadCactus2025",
              "text": "It's not just text descriptions it ignores. Goldens? Nah. Imma do my own thing.\nLayouts with clear segments? Nahh, let me do an unstructured list instead.\nYour requested test data with 10 fixed lines? Instead of SQL it just overwrites the entire thing with a summary of sorts in hands that back.\n\nI also am under the impressions that it just won't actually listen to given parameters like temperature, sampling rules and max tokens.",
              "score": 2,
              "created_utc": "2026-01-25 18:41:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1o0ft1",
                  "author": "Sad-Consequence-uwu",
                  "text": "Yeah. This matches my experience xd",
                  "score": 1,
                  "created_utc": "2026-01-25 18:42:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1nuyst",
              "author": "graymalkcat",
              "text": "I have ways of wrangling these. I started this agent back in the gpt-4.1 days when you had to scream at the model to make it use a tool. Edit: or even just process the text and look for intent and run the tool yourself. üòÇ",
              "score": 0,
              "created_utc": "2026-01-25 18:20:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1nv66c",
                  "author": "Sad-Consequence-uwu",
                  "text": "I got all caps lines in system prompt to make the agent use the tools :)",
                  "score": 1,
                  "created_utc": "2026-01-25 18:21:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qjbbd1",
      "title": "Devstral Small 2 With OpenCode through Ollama",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qjbbd1/devstral_small_2_with_opencode_through_ollama/",
      "author": "Historical_Roll_2974",
      "created_utc": "2026-01-21 21:45:15",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.85,
      "text": "Hello,\n\nI am trying to make a local setup with Devstral Small 2 and OpenCode. However I keep getting errors to do with the API, where Devstral will pass it through in it's own format. I tried changing the npm config value from \"openai-compatible\" to \"mistral\"and using a blank api key as its on my own machine, but I still get the error below. If anyone has fixed this issue could you please let me know what you did to fix it. Thanks. \n\n`Error: The edit tool was called with invalid arguments: [`\n\n  `{`\n\n`\"expected\": \"string\",`\n\n`\"code\": \"invalid_type\",`\n\n`\"path\": [`\n\n`\"filePath\"`\n\n`],`\n\n`\"message\": \"Invalid input: expected string, received undefined\"`\n\n  `},`\n\n  `{`\n\n`\"expected\": \"string\",`\n\n`\"code\": \"invalid_type\",`\n\n`\"path\": [`\n\n`\"oldString\"`\n\n`],`\n\n`\"message\": \"Invalid input: expected string, received undefined\"`\n\n  `},`\n\n  `{`\n\n`\"expected\": \"string\",`\n\n`\"code\": \"invalid_type\",`\n\n`\"path\": [`\n\n`\"newString\"`\n\n`],`\n\n`\"message\": \"Invalid input: expected string, received undefined\"`\n\n  `}`\n\n`].`\n\n`Please rewrite the input so it satisfies the expected schema.`",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qjbbd1/devstral_small_2_with_opencode_through_ollama/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qj052p",
      "title": "Le Chat app is kind of buggy?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qj052p/le_chat_app_is_kind_of_buggy/",
      "author": "Loud_Narwhal_3742",
      "created_utc": "2026-01-21 15:00:29",
      "score": 5,
      "num_comments": 14,
      "upvote_ratio": 0.78,
      "text": "I'm completely new to Mistral AI, but got the pro version yesterday as the student plan is extremely cheap. \n\nI'm transitioning from chatGPT to this, so I might be comparing too much here, but Le Chat seems so buggy. Im sorry, I dont have screenshots, but my very first prompt I asked \"do you speak Danish?\" (In Danish) And the prompt showed up \"do you speak _\". Now it clearly understood, because it answered as expected. But the ui had removed some of the prompt? \n\nWeird, but I continued the conversation. Now I got a pretty good answer, but almost every paragraph was stopped just short of the ending of the phrase. So I had to guess the last few words in every few sentences. \n\nSame thing today, i ask something, get a great answer but there the ends are cut off. Today i asked about a timeline, which the chat put into a table for me. But all of the years were 199 or 201 instead of 199x and 201x something. \n\nDoes anyone else notice this? \nIm starting to not like using the app. I havent noticed this in the web version. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qj052p/le_chat_app_is_kind_of_buggy/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o0v5yiu",
          "author": "Feeling_Rutabaga6680",
          "text": "I use le chat in both Danish and English. It works fine for me. Maybe it just needs to get to know you? The student pricing is great!",
          "score": 1,
          "created_utc": "2026-01-21 15:04:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0v7x8x",
              "author": "Loud_Narwhal_3742",
              "text": "It doesn't matter if I'm interacting in Danish or English. It's the UI that's buggy. And only when I use my Android app, which is pretty annoying since I use that on the go",
              "score": 1,
              "created_utc": "2026-01-21 15:14:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o10antv",
                  "author": "mouif-mouif",
                  "text": "I use the android app, pro version also.\nNo issue, all works great.¬†\nLooks weird, maybe uninstall reinstall the app? (sounds like a dumb suggestion though)¬†",
                  "score": 1,
                  "created_utc": "2026-01-22 07:20:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0vyu1l",
          "author": "naijatechguy",
          "text": "Can you share a screenshot of the bug you‚Äôre getting",
          "score": 1,
          "created_utc": "2026-01-21 17:16:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0z3mo4",
          "author": "BustyMeow",
          "text": "I don't feel buggy with the app; it's without complete features instead.",
          "score": 1,
          "created_utc": "2026-01-22 02:25:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o13b21h",
              "author": "Icy_Distribution_361",
              "text": "Which features?",
              "score": 1,
              "created_utc": "2026-01-22 18:26:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19aau8",
                  "author": "BustyMeow",
                  "text": "on the app you can't quickly enable/disable functions with the / command and Memories and Libraries aren't available.",
                  "score": 1,
                  "created_utc": "2026-01-23 15:57:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o10e57e",
          "author": "Den_er_da_hvid",
          "text": "Maybe you have been selected to try it's new autocompletion feature where AI tries to get humans to vibe texting the rest",
          "score": 1,
          "created_utc": "2026-01-22 07:51:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}