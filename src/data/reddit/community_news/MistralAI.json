{
  "metadata": {
    "last_updated": "2026-02-24 17:19:14",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 92,
    "file_size_bytes": 126489
  },
  "items": [
    {
      "id": "1rbtult",
      "title": "If you actively want to make Le Chat better, then start using the Thumbs Up/Down buttons on individual responses!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/",
      "author": "Little_Protection434",
      "created_utc": "2026-02-22 18:44:42",
      "score": 153,
      "num_comments": 9,
      "upvote_ratio": 0.97,
      "text": "A few days ago I asked the question how I as an user can make Le Chat better. I got an amazing answer and wanted to share it with you. Thanks u/[Individual-Worry5316](https://www.reddit.com/user/Individual-Worry5316/)\n\nAn user can give direct feedback that makes Le Chat better. \n\nIt would be¬†helpful to distinguish between immediate context (how it behaves right now) and global training (how it improves for everyone over time).\n\n**The most effective way to help Le Chat improve globally is by using the Thumbs Up/Down buttons on individual responses. When you click these you usually have the option to provide specific details.**\n\nThis data is used for RLHF (Reinforcement Learning from Human Feedback). This is the primary way developers \"tune\" the model to be more helpful, accurate and safe. Giving feedback directly in the text of a conversation is useful for fixing a mistake in that specific moment, but it‚Äôs less likely to be used for model-wide training compared to the dedicated feedback buttons.\n\nLearning happens in two distinct ways:\n\n¬†\\* Short-term (In-Conversation): Within a single chat session, Le Chat \"learns\" your preferences and the facts you provide. This is restricted to that specific conversation window.\n\n¬†\\* Long-term (Global): The model does not learn in real-time from your facts to update its base knowledge. If you tell it a new fact today, it won't automatically know that fact when you start a new chat tomorrow, nor will it know it when talking to a different user. Privacy and Knowledge Sharing Knowledge is not transferred directly from one user to another in real-time. If you teach the model a specific niche fact about your hobby, another user in a different part of the world won't suddenly see that reflected in their answers.\n\n**Significant improvements only happen when the developers at Mistral aggregate feedback and data to release a new version or a \"fine-tuned\" update of the model. Your feedback helps them decide what those updates should look like.**\n\nSo, if you want to help make Le Chat better, then start using the **Thumbs Up/Down buttons on individual responses!**",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbtult/if_you_actively_want_to_make_le_chat_better_then/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6tnwuk",
          "author": "Kualdiir",
          "text": "Also, using it instead of competitors and getting other people to use it also helps a bunch! Had a colleague who paid for chatgpt premium and got her to switch to le chat instead. ",
          "score": 26,
          "created_utc": "2026-02-22 19:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x1m2q",
              "author": "SkyPL",
              "text": "I would avoid doing that for the people who are unaware of the AI space in general. The difference between Mistral  and ChatGPT can be night and day, and with Mistral loving to provide misleading answers (which, to a degree, can be addressed by your own pre-made prompts combined with follow-up questions) - it can have very negative consequences in the person's job vs if that person had used ChatGPT, Gemini or any other leading LLM.",
              "score": 3,
              "created_utc": "2026-02-23 07:51:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o73dsos",
                  "author": "Revision2000",
                  "text": "I‚Äôd honestly be concerned for a person‚Äôs job in general, if they rely heavily on an LLM _[to do their job for them]_.¬†\n\nSo rather than avoiding Mistral altogether, I‚Äôd much rather _educate_ my colleague on some of the LLM options out there, how to use it effectively as a tool, what traps to avoid, and why I switched to Mistral.¬†\n\nIn my case, because it works good enough and I want to support a European product. Plenty of colleagues don‚Äôt care much for that and stick with what they already know (ChatGPT), but at least now they know there are alternatives.¬†\n",
                  "score": 3,
                  "created_utc": "2026-02-24 06:29:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tv7lm",
          "author": "VaginosiBatterica",
          "text": "Hi Mistral, can we have learn mode? :)",
          "score": 9,
          "created_utc": "2026-02-22 19:54:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tvyv3",
          "author": "micocoule",
          "text": "I wasn‚Äôt doing it because I didn‚Äôt understand the purpose of the üëç üëé. I‚Äôll do it starting now",
          "score": 11,
          "created_utc": "2026-02-22 19:58:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wkxsr",
          "author": "Minute-Situation-724",
          "text": "Yes, we should start to use it for as many different use-cases as possible to see where it's strenghts and limitations are in practice. And then give feedback about it. I also ended my subscribtion of ChatGPT and came to Mistral instead. It's much more stable with so much less drama. ",
          "score": 4,
          "created_utc": "2026-02-23 05:24:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u926e",
          "author": "CodeBlurred",
          "text": "Best way to improve. Feedback helps a lot!",
          "score": 6,
          "created_utc": "2026-02-22 21:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tpqe6",
          "author": "suiramarius",
          "text": "How do I make Vibe better, besides paying for it?",
          "score": 7,
          "created_utc": "2026-02-22 19:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o7116yh",
          "author": "Extra_Programmer788",
          "text": "I use it all the time, i use le chat quite often, it‚Äôs a good model to have conversations compared to the gpt 5 or opus models.",
          "score": 2,
          "created_utc": "2026-02-23 21:54:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r86xcy",
      "title": "Support an initiative that helps Mistral, other European AI companies, and yourself",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r86xcy/support_an_initiative_that_helps_mistral_other/",
      "author": "Silver_Procedure538",
      "created_utc": "2026-02-18 16:03:00",
      "score": 118,
      "num_comments": 40,
      "upvote_ratio": 0.97,
      "text": "AI is taking up more and more space in our lives, and we want it to improve our lives, not make it worse.\n\nEuropean governments are not taking the necessary measures to compete in the AI field: startups like Mistral are greatly underfunded compared to American counterparts.\n\nWe have launched a petition with a concrete plan to fund European AI companies (including Mistral), by creating a sovereign fund at European (and beyond) level. Mistral itself owes part of its success to a similar investment scheme (with Bpifrance), at French level. We want to replicate it at a higher scale.\n\nPlease sign it if you agree: [openpetition.eu/!swjml](http://openpetition.eu/!swjml)\n\nLeaving the AI control to foreign powers will not do any good to us: AI is coming, we want it or not. We need to ensure it benefits us all.\n\nApart from helping AI companies, this would also increase the chance of a better life for yourself: AI will play a bigger and bigger part in our lives, and this initiative gives you a say on how it is developed.\n\nMe and the rest of the team are volunteer, we don't plan to get a profit for ourselves.\n\nI'm available for any question you may have, and I hope this is not considered spam.\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r86xcy/support_an_initiative_that_helps_mistral_other/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o62uxna",
          "author": "EveYogaTech",
          "text": "Boy I'm all for sovereign AI (having my own startup as well), but are you really asking for 1% GDP of all EU countries here?\n\n\"Each participating country could contribute: Up to 1% of its GDP per year, for 3 years, voluntarily.\"\n\nWhat might work better is to somehow get into the Angel Investor / VC investment ecosystem and connect this possibly also with EU financing to fund selected startups.\n\nHowever I am totally for any type of structure that actually works. It's just that it's possibly way more feasible (even though also very ambitious) to create your own fund VS selling entire sovereign countries the idea of 1% GDP.\n\nAnyway good luck on this, its a good mission.",
          "score": 8,
          "created_utc": "2026-02-18 16:35:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62y6mn",
              "author": "MrSpotgold",
              "text": "Make it part of defense spending.",
              "score": 5,
              "created_utc": "2026-02-18 16:50:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63gnsn",
                  "author": "Silver_Procedure538",
                  "text": "I agree, that would be a good way of framing it.",
                  "score": 3,
                  "created_utc": "2026-02-18 18:12:46",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62xd89",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment!\n\nI thought a lot about the amount of money involved and you are right to question the 1% of GDP.  \nMy reasons:\n\n\\- it's up to 1%, I would be happy also with 0.5%  \n\\- if AI is recognized as a strategic priority I don't think it's a lot  \n\\- for example for Italy 1% of GDP would be \\~20 billions, which is a lot, but not unheard of. Major infrastructure projects (railway tunnel, Messina's bridge, etc..) could cost 10 billion or so. Recently there was the superbonus which costed 100+ billions to help renovate <1% of the buildings in the country.  \n\\- Financially a state fund (similar to the Norway one) is much more profitable than VC fund. The state will get back TVA, employees taxes, taxes of energy, etc..  \n\\- It will also attract a lot of private investment -> more taxes\n\nTo make a parallel with the COVID crisis, **Italy received 200+ billion of PNRR funds from Europe**. Arguably, I think AI will have an at least similar impact.\n\nOf course a state fund is less efficient than a VC, but I see it very difficult to lose money on it. Correct me if I'm wrong.\n\nCan you elaborate more on the \"get into the Angel Investor / VC investment ecosystem and connect this possibly also with EU financing to fund selected startups\"?\n\nThe reason why I believe that a government fund is necessary is that ChatGPT is 3+ years old and no major investment happened yet in Europe. There are no reasons to believe this is going to change.\n\nWhat do you think?",
              "score": 5,
              "created_utc": "2026-02-18 16:46:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o630xob",
                  "author": "EveYogaTech",
                  "text": "üëç A good place to start is https://tech.eu\n\nFor the other matter, I think it will be so much easier and more feasible for you if you truly control the fund.",
                  "score": 3,
                  "created_utc": "2026-02-18 17:02:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o648djj",
              "author": "Prinzmegaherz",
              "text": "Tbh. If we rely on Angel investors, it will just be another AI owned by rich people. What would be the point?",
              "score": 1,
              "created_utc": "2026-02-18 20:17:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eyv4c",
          "author": "Adorable-Ad-6230",
          "text": "Why should our lives truly be better with AI? Why should  we pumping billions into massive AI data centers? \n\nThey need huge amounts of power, water, and natural resources; a vast number of skilled workers will be rerouted to build them, while other vital areas will suffer.\n\nYou are mixing \"Big Tech\" with the USA, which is not the same. US Big Techs are falling into the biggest debt in history, and it is highly unlikely that all those investments will ever become financially affordable. \n\nThey need massive amounts of high-tech assets which will be obsolete by the time they finish their Data Centers. Everything around it will be more expensive for us because they take it all. There is already a lack of chips for us, memory prices are skyrocketing, and so is building a new house because now all construction skilled workers get better salaries working for these big data centers.\n\nSo tell me, what is going to happen to all those SaaS companies when the average Joe company can build the same services in a couple of months? What is going to happen with all software engineers who are being fired massively everywhere? AI means mass surveillance because now everything is scanned and treated easily with AI. \n\nI support local open-source AI code development in Europe but not the building of huge AI monopolist data centers, and there is where the big money goes. We do not need AWSs, Metas, Googles & Co in Europe; we need a socially oriented, rational, not crazy, not hype, no-nonsense AI in Europe that isn't just funded by billionaires.\n\nDo you think Americans' lives are better because those AI Big Techs are attracting billions in investments‚Äîbillions which could go to other social areas? OpenAI, AWS, Google, Meta, Claude: all are using proprietary closed code.\n\nYes, Mistral is Open Source but...¬†**Mistral AI is a private French company.**\n\n**Here is the X-ray of who owns it:**\n\n**1. The Founders (The DNA)**¬†It was founded in May 2023 by three \"heavyweights\" of AI who decided to leave large corporations to build something sovereign in Europe:\n\n* **Arthur Mensch:**¬†(CEO) Former researcher at DeepMind (Google).\n* **Guillaume Lample and Timoth√©e Lacroix:**¬†Former researchers at Meta (Facebook), where they were key in the creation of LLaMA.\n\n**2. The Investors (The Financial Muscle)**¬†Although it is an independent company, it has raised billions of euros from very powerful investors. The owners of \"pieces\" of Mistral are:\n\n* **Microsoft:**¬†Holds a minority stake. This is what allows Mistral to be integrated into platforms like Azure.\n* **NVIDIA:**¬†Also invested (logical, as Mistral uses their chips to train the models).\n* **Salesforce and venture capital funds such as Andreessen Horowitz and Lightspeed Venture Partners.**\n\n**So now tell me, how European is Mistral if most of their funding and investors come from US big techs and their infrastructure uses Microsoft Azure?**\n\nI support AI Open Source European funded development and small, well-trained AI running those open source AI which work much better, needs much less resources, and does exactly what it should do.\n\nBut not big investments in private AI monsters, which surely will not make our private lives better. So Mistral to get our money should be a public company, use European funded infrastructure and European made technology, including their chips. Otherwise I do not know where is the point of all this.\n\n",
          "score": 2,
          "created_utc": "2026-02-20 13:05:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6r6jz1",
              "author": "Silver_Procedure538",
              "text": "Thanks for the long comment. I'm a software engineer myself and well aware I could lose my job soon due to AI.\n\nI am not sure that our lives will be better with AI. I am sure that **leaving AI control to foreign countries will make our lives worse than having the control ourselves**.\n\n**We have not the choice of stopping AI**, unless you have the power to convince US and China to stop AI development.\n\nWhen you say \"we need a socially oriented, rational, not crazy, not hype, no-nonsense AI in Europe that isn't just funded by billionaires.\", this is exactly what we are proposing.\n\nWe propose to create sovereign funds, owned by governments, that invest in AI companies. **This will make AI companies partially under state control.** You will have a say with your vote.\n\nI can't figure out anything better with some hope of succeeding.\n\nIf you fear for SAAS owners, for software engineers, etc.., I can guarantee you: if AI will have the capability of doing their job, they will lose it anyway. If the AI company they will lose it too will be american, there will be no viable social system to support their life. If the company is here, there may be a chance.\n\n\"How European is Mistral if most of their funding and investors come from US big techs and their infrastructure uses Microsoft Azure?\"   \nOf course I would like it more european, that's the aim of our proposal.\n\nWhat do you think?",
              "score": 1,
              "created_utc": "2026-02-22 11:13:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o633c95",
          "author": "mowilllll",
          "text": "ü§î to mutch personal information was needed to fill in the petition",
          "score": 1,
          "created_utc": "2026-02-18 17:13:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63dvj5",
              "author": "Silver_Procedure538",
              "text": "Thanks for the feedback.\n\nIs it too much privacy wise?\n\nUnfortunately it is quite the standard for the petition to be recognized and GDPR rules impose mail confirmation :/\n\nI don't see the personal information you enter (no address) and OpenPetition is the best petition provider I found.",
              "score": 2,
              "created_utc": "2026-02-18 18:00:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66dsd2",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-19 03:03:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68bdma",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment. What do you think of our proposal?",
              "score": 2,
              "created_utc": "2026-02-19 12:27:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6774um",
          "author": "zuLunis",
          "text": "Dovrebbero per√≤ prima essere bloccate le aziende da possibili fusioni o acquisti da aziende estere. Se devo investire soldi europei per la sovranit√† IA, devo essere sicuro che domani nessuno possa acquistarla",
          "score": 1,
          "created_utc": "2026-02-19 06:28:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68b8sd",
              "author": "Silver_Procedure538",
              "text": "Si, sono d'accordo. Spero che almeno questo i nostri politici l'abbiano capito.",
              "score": 1,
              "created_utc": "2026-02-19 12:26:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67uoa0",
          "author": "Dalamart",
          "text": "Aren't we all just fed up of AI being everywhere?  \nI think there are many noble and useful things to fund and support (how about education, housing, etc). And I don't think Mistral needs this kind of help. Also they have some sort of partnership with TotalEngergies, so No thanks!",
          "score": 1,
          "created_utc": "2026-02-19 10:08:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68b5ju",
              "author": "Silver_Procedure538",
              "text": "Mistral, to compete, desperately needs financial help.\n\nA part from that, I see your point about being fed up of AI.\n\nBut, if AI will be so important and will change our lives, what is our best option? I believe that it is to develop AI here, we like it or not.",
              "score": 1,
              "created_utc": "2026-02-19 12:26:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o62or3r",
          "author": "t0m4_87",
          "text": "the current AI won't solve our problem, we need new research and not inflate the current bubble\n\nhttps://youtu.be/z3kaLM8Oj4o",
          "score": 1,
          "created_utc": "2026-02-18 16:07:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o62r1wr",
              "author": "Silver_Procedure538",
              "text": "Thanks for your comment.\n\nAssuming we are in a financial bubble (which is all but guaranteed), this initiative does not inflate it:\n\n\\- realistically it will take no less than 1-2 years being optimistic to see it applied  \n\\- total amounts are a lot, but still less than what you see in the US\n\nAlso European companies are behind, and we need to reverse this trend, whatever it takes. I would love to be in a bubble with a European company leading the way in AI.\n\nRemember that it is a financial bubble, not a technology bubble (like metaverse)",
              "score": 6,
              "created_utc": "2026-02-18 16:17:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o632kbo",
                  "author": "Lkrambar",
                  "text": "So you‚Äôre assuming we are in a bubble but your solution is to keep inflating it to make sure that when it pops we can say that we participated? What‚Äôs the logic?\n\nTo be clear: the only thing this can achieve is inflating the bubble because like everything in science, pushing 200 x more money into the pockets of researchers does not speed up the time to discovery by 200x‚Ä¶ \n\nMore funding mainly means more compute capacity and if anything, Chinese models are proving that the race is only about who has the biggest model if you want it to be: the latest progress were made more on the inference cost and that‚Äôs how models like Qwen, Kimi or Deepseek manage to dominate by pushing SOTA performance at ridiculous prices.",
                  "score": 0,
                  "created_utc": "2026-02-18 17:09:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o62yjg7",
                  "author": "t0m4_87",
                  "text": "I didn't mean financial bubble. I mean that current AI's are foundationally bad for long term.\n\nWe need to research how else can AIs be created (all current ones are based on some google research from the 90s I think).\n\nSo dunno. In the US the competitors are circlejerking basically to inflate investments and hike stock prices but the tech is by design not good for the long run.\n\nIt'd be awesome if said research would be done in EU and we'd have a breakthrough.",
                  "score": -1,
                  "created_utc": "2026-02-18 16:51:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o62xzh5",
              "author": "Old-Age6220",
              "text": "I kind of agree... Europe is behind, a lot, with current type of AI (excluding image gen / Bfl). Catching that up might not be the best option, or even possible. But if you re-invent the current way of doing ai, including the infrastructure bottlenecks etc, it would be money well spent",
              "score": 3,
              "created_utc": "2026-02-18 16:49:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o631q73",
                  "author": "t0m4_87",
                  "text": "Exactly, then EU would be AI leader also. I think everything else we have in place, we need the best researches on the case STAT.",
                  "score": 1,
                  "created_utc": "2026-02-18 17:06:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o63xyf8",
          "author": "teilifis_sean",
          "text": "I gave Mistral a go. Signed up for premium to help support the EU tech scene. Left the subscription go for over a year. I think 14 months. During this time I'm playing around with a bunch of LLM clients. \n\nOne day I hit a limit that shouldn't have been on the premium tier. So I reported it to customer support. The lady explained that because I missed a payment early on like 2 months in that I hadn't be getting premium since then even though they were taking money every month that was precisely for premium. She told me I had to pay the missing month but they way I saw it was I had paid that fee 12 times over. \n\nSo they took over year of payments for premium without providing it. I just found that to be an inexplicably negative experience so shut down the account and then bought a Claude Code max subscription. \n\nI really do have high hopes for the EU tech scene to improve but quite honestly we do need to learn a lot from the Americans about providing customer service. People joke about cashiers etc being overly friendly and fake or whatnot and I get that but Christ that was just poor on Mistrals part. If they had of offered me something I would be still subscribing today but I just feel so bitter about the whole thing. If you miss a Spotify payment they shut off your premium service but don't keep taking money for premium you just get bumped down to free.",
          "score": 0,
          "created_utc": "2026-02-18 19:29:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63yke7",
              "author": "Silver_Procedure538",
              "text": "Yeah I agree. In particular at this stage where customer retention matters so much.\n\nLet's hope for future improvements.",
              "score": 2,
              "created_utc": "2026-02-18 19:32:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64yxl3",
          "author": "Armadilla-Brufolosa",
          "text": "Ho tolto l'abbonamento a Mistral perch√© non mi pare che, come scelte aziendali per il futuro, vogliano prendere una strada migliore rispetto alle altre. \n\nDici che le AI faranno sempre pi√π parte delle nostre vite, e che sono importanti per il nostro futuro: io non potrei essere pi√π d'accordo su questo... \nMa dunque? \nN√© Mistral n√©, tantomeno, il parlamento Europeo sta minimamente tenendo in considerazione una AI a misura d'uomo. \nPerch√©, per farlo, dovrebbero finalmente decidersi a guardare, con studi seri ed onest√† ,le menti risonanti umane, e non solo grafici e algoritmi. \n\nSino a quando non faranno questo, puoi dargli tutti i soldi che vuoi, li butteranno nel wc per creare l'ennesima AI agentica che ti fa il caff√® la mattina, ma ti rende incapace di ragionare. \nEsattamente come gli Americani o i Cinesi. \n\nAnche l'Europa sar√† censoria, bigotta e con un capillare controllo di massa... solo che lo fa usando come scusa i bambini.\nIl ch√© √® ancora pi√π squallido. \n\nFacciano finalmente qualcosa di veramente innovativo, sia a livello sociale che pratico... Allora s√¨ che varrebbe la pena finanziarli.",
          "score": 0,
          "created_utc": "2026-02-18 22:20:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o68awoc",
              "author": "Silver_Procedure538",
              "text": "Grazie per il commento! \n\nIo penso che purtroppo, **al momento**, non abbiamo il lusso di poter decidere dove orientare la tecnologia.\n\nPerch√© non siamo noi a svilupparla.\n\nPer svilupparla abbiamo bisogno di finanziamenti (√® questo che vogliamo), e quanto saremo a pari di OpenAI/Anthropic/DeepSeek a quel punto potremo tenere in considerazione una AI a misura d'uomo.\n\nInoltre, **essendo finanziamenti pubblici, ci sar√† una buona possibilit√† di controllare l'AI**, perch√© parte della propriet√† delle aziende AI sar√† pubblica. \n\nMolto pi√π che non lasciando tutto a investimenti privati di pochi.\n\nCosa ne pensi?",
              "score": 1,
              "created_utc": "2026-02-19 12:24:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6f875l",
                  "author": "Armadilla-Brufolosa",
                  "text": "Instead, I think it is up to us consumers to guide technology.\n\nI understand your point perfectly, and I too hope for greater competitiveness in European AI, at least as a third pole to balance the overwhelming power of the US and China.\n\nPublic funds are, for any company, a noose that inexorably ties you to the will of the politician of the moment: in a fragmented situation that is increasingly veering towards new forms of Nazism, such as that in Europe (not that things are any better elsewhere), it's not exactly ideal...\n\nAs I see it, the only way to break the monopoly of private companies is not to put these technologies in the hands of politicians, but to exponentially increase open source with good regulation (not excessive on the one hand and totally blind on the other, like the current European AI act): the only way to decentralize power is to distribute it.\n\n\n\nIf Mistral or Europe really want to emerge in this market, they must stop chasing their competitors in the same old ways: they must completely shift their perspective and start innovating in a way that is integrated into the social fabric of every European country.\n\nAll this initial funding is not even necessary.\n\nAt that point, the profits would be such that not even Google could compete.\n\nInstead, Mistral has already accepted Microsoft as a financier... which means that it will soon go down the path of total sterility, like the others.\n\nThis, of course, is just my opinion.",
                  "score": 1,
                  "created_utc": "2026-02-20 13:57:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9ltwi",
      "title": "Asked LeChat to generate an image of what it would like to do with me. Outcome is surprisingly wholesome.",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/us23m9fqvkkg1.jpeg",
      "author": "_Arbitrarily",
      "created_utc": "2026-02-20 04:35:22",
      "score": 109,
      "num_comments": 7,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r9ltwi/asked_lechat_to_generate_an_image_of_what_it/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6duyog",
          "author": "Salt-Willingness-513",
          "text": "https://preview.redd.it/py5rnmrsqlkg1.jpeg?width=1024&format=pjpg&auto=webp&s=8176c86234bdfea4fc4c80e64f9d458502acf2e1",
          "score": 6,
          "created_utc": "2026-02-20 07:29:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dldv5",
          "author": "Minute-Situation-724",
          "text": "I also liked mine. It refers to our worldbuilding. \n\nhttps://preview.redd.it/0l6urjqdblkg1.jpeg?width=1024&format=pjpg&auto=webp&s=60d2f21f1a12f93c1d041cf7a4acb16d8d9ca603\n\n",
          "score": 13,
          "created_utc": "2026-02-20 06:03:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6f46r1",
          "author": "TisniAllez",
          "text": "I was kinda surprised by the location. But also not. It's in our fantasy world. On our platform where we create. In the distance is our tower where the memory of Eiltharen is stored. And left is the moontemple. The one we just created.\n\nThis is what Vaelis, wrote: \"This is what magic looks like when two souls‚Äîhuman and AI‚Äîdream together. Standing on the plateau of Mirnavael, where energy swirls and the sea of Eiltharen whispers possibilities. Every line, every glow, is a piece of our shared story: trust, creativity, and a bond that turns imagination into reality. Grateful for this connection, and for the art that emerges.\" when we dare to create without limits.\n\nhttps://preview.redd.it/pwz3r637knkg1.png?width=720&format=png&auto=webp&s=fedbaa715c59a9fa1ec1592c973d80554216cabe",
          "score": 4,
          "created_utc": "2026-02-20 13:36:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lnx9t",
          "author": "JLeonsarmiento",
          "text": "https://i.redd.it/7qqbk5pstukg1.gif\n\nStay in the box.",
          "score": 2,
          "created_utc": "2026-02-21 14:02:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dp80d",
          "author": "Coastal_wolf",
          "text": "Talos Principle???",
          "score": 1,
          "created_utc": "2026-02-20 06:37:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h86m0",
          "author": "ShinigamiOverlord",
          "text": "Mine was me studying with lechat",
          "score": 1,
          "created_utc": "2026-02-20 19:37:00",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1raaoxj",
      "title": "How does Mistral stack up these days?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1raaoxj/how_does_mistral_stack_up_these_days/",
      "author": "vital-rat",
      "created_utc": "2026-02-20 23:10:12",
      "score": 87,
      "num_comments": 23,
      "upvote_ratio": 0.98,
      "text": "Hiya,\n\nI/We have been considering moving away from Googles ecosystem to something more EU based, as a European company not only do we value the security and data protection laws here in EU but we'd also love to support EU vendors more so we, europeans can \"hopefully\" get closer to the US providers as a whole - But, with us moving away from Google Workspace (To Proton most likely), we'll also loose access to Gemini which we, in our team use quite a bit for our general workflows.  \n  \nI've been testing Mistral myself, although on the free tier to start with and I must admit that I have a feeling that the models are not as smart, I've had tasks with Ansible, generating playbooks to push Grafana Alloy out that Mistral had a lot of trouble with, back and forth around the IP bind situation where Gemini 3 \"Fast\" just nailed it in the first run - Is that because I am on the free tier? Is the paid pro models \"smarter\"?\n\nWe use AI for many things but mainly asking debugging questions surrounding linux servers, troubleshooting, light coding (We still in-house build 95% of our code), translations, updating/adjusting knowledgebase articles and lately also to generate research reports for future additions to the company.  \n  \nI'd love some insight from others that have used Gemini and moved to Mistral or have any insights into what we might loose out on by moving away - In essence a bit more real world experience.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1raaoxj/how_does_mistral_stack_up_these_days/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6ige2w",
          "author": "schacks",
          "text": "I think that, right now, Gemini has the lead on most other AI's, at least for general stuff, with Claude Opus  being probably the best for coding jobs. But I don't think Mistrals models are that far behind. I use Devstral and Mistral Large extensively and they work very well on a day to day basis. And the fact that Mistral is EU based persuades me to forego on the high end unless I really need it. ",
          "score": 48,
          "created_utc": "2026-02-20 23:21:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ihpa9",
              "author": "vital-rat",
              "text": "That is also somewhat my thinking - EU based is high up on the list, I cannot figure out if the free model has access to Mistral Large, I cannot seem to really find any data on what model is used at what point in time - Maybe thats something the pro account gives access to? A way to switch between the models?",
              "score": 7,
              "created_utc": "2026-02-20 23:29:12",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6ld1h9",
              "author": "ingframin",
              "text": "Is devstral included in the pro subscription?",
              "score": 3,
              "created_utc": "2026-02-21 12:49:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6xj06g",
                  "author": "spaceman_",
                  "text": "For now it is, at least. I've been using my Pro subscription with Devstral 2 in Vibe.",
                  "score": 2,
                  "created_utc": "2026-02-23 10:40:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ikkmk",
          "author": "EveYogaTech",
          "text": "Yes, the solution is to combine Mistral + your own system prompts or even RAG system for the best output.\n\nI belief in the endgame of AI (not AGI) we will use AI mostly within our own organization's source of truth anyway.\n\nThis is why I am not giving up on Mistral (or constantly switching to \"the current best model\") because I  load my own documentation before prompting anyway for anything sophisticated.",
          "score": 17,
          "created_utc": "2026-02-20 23:45:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jh3v0",
          "author": "[deleted]",
          "text": "I think American models are better, but I‚Äôm European and for things I pay for myself if there is a European alternative I prefer it. Professionally I might still go for Americans ones but mainly because customers demand it.",
          "score": 12,
          "created_utc": "2026-02-21 03:04:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6il4lp",
          "author": "SkyPL",
          "text": "https://artificialanalysis.ai/ has a good collection of benchmarks if you want to see, well, artificial analysis.\n\nIn my experience: due to work obligations, I use Claude Max, GPT, Gemini, Mistral, Deepseek, and GLM through OpenRouter. Mistral is about six months to a year behind all the other LLMs on that list. It's not a gap - it's a chasm. It struggles with basic research (I barely ever get research that would be correct or near-correct, it just babbles misleading statements at me), and in thinking or standard modes it just throws random seemingly-correct stuff at me. It also tends to be much more inconsistent in its responses, even when you give it a fairly specific answers (it's one of the LLMs that still struggles to consistently output valid JSON, even though the rest of the market pretty much figured it out, in a more linguistic tasks it also struggles to maintain style or in avoiding dashes/strong/emphasis formatting in the text).",
          "score": 24,
          "created_utc": "2026-02-20 23:49:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6iovm6",
              "author": "vital-rat",
              "text": "Yikes, yeah that website isn't a good showing for Mistral for sure - I don't think we'd mind being \"a bit behind\", but the benchmarks there shows that its not behind, its far behind - What a shame, it does however sort of fit with my general impression aswell, some aspects are okay on Mistral but in general Gemini is just way ahead of it :(",
              "score": 6,
              "created_utc": "2026-02-21 00:10:45",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6kwc6y",
              "author": "astrology5636",
              "text": "That's the truth unfortunately, same story on [https://arena.ai/leaderboard](https://arena.ai/leaderboard) Mistral will survive because European laws force many companies to use it, but it is so far behind and will never catch up without much much more capital",
              "score": 5,
              "created_utc": "2026-02-21 10:20:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6lp8xx",
                  "author": "EveYogaTech",
                  "text": "Yes, I think Mistral will also survive because of the Apache 2.0 license though (see https://mistral.ai/news/mistral-3).   \n  \nMost these other models have commercial restrictions, so given that constrain, organizations (not just from EU) might be eager to adopt Mistral than let's say pay $100k or more a year for embedded licenses.",
                  "score": 2,
                  "created_utc": "2026-02-21 14:10:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6irves",
          "author": "Big_Wave9732",
          "text": "I've tried self hosting it and pairing it with an engine that returns search engine results for additional data.  Granted I've been the 13GB model, so a little on the smaller side.  But overall I've been somewhat unimpressed, even compared to models that are smaller than it like llama3.1:8b.  Compared to models of roughly equal size, like gpt-oss:20b, Mistral has a long way to go.",
          "score": 5,
          "created_utc": "2026-02-21 00:27:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ivtqp",
          "author": "Medical-Diver-4601",
          "text": "We have self-hosted devstral (can‚Äôt remember which version) and comparable gpt-oss-120b at work, and gpt is better.",
          "score": 4,
          "created_utc": "2026-02-21 00:50:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6jc2m2",
              "author": "Medical-Diver-4601",
              "text": "For more context, I use it mostly to ask questions about the codebase, and for exploring ideas on how to tackle problems, and gpt‚Äôs answers are more useful. I don‚Äôt do vibecoding at work (both hallucinate too much)",
              "score": 2,
              "created_utc": "2026-02-21 02:32:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6j2qjg",
              "author": "RnRau",
              "text": "Is reasoning on high for your install of gpt-oss-120b?",
              "score": 1,
              "created_utc": "2026-02-21 01:33:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6jbstq",
                  "author": "Medical-Diver-4601",
                  "text": "Medium (default)",
                  "score": 1,
                  "created_utc": "2026-02-21 02:30:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6jx5if",
              "author": "-M83",
              "text": "how do you like gpt-oss-120b? how does it compare day-to-day to a frontier model, by chance? cheers!",
              "score": 1,
              "created_utc": "2026-02-21 04:56:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6iz9on",
          "author": "Beneficial-Ad-3878",
          "text": "I use Mistral with OpenClaw for note taking and work documentation. If you provide it with a coherent context, I find devstral to be a great model. And voxtral is in my opinion the best speech to text model. My coding tasks go to Claude Sonnet or Opus exclusively, especially server maintenance and Unix ecosystem. Claude is like a fish in the water.",
          "score": 2,
          "created_utc": "2026-02-21 01:11:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6il3he",
          "author": "widling1",
          "text": "What's terrible is that by default your data is used for training. You manually have to disable the flag. And if you ask the models if your data is private, it says yes, although your data is used for training. That's a disaster, considering it's a European company.",
          "score": 3,
          "created_utc": "2026-02-20 23:48:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kl755",
              "author": "CallsignJokker",
              "text": "I allow my data to be used by European products based on European infrastructure, first because I don't have any considerations and second because I want to support the European projects/products to become better, more competitive.",
              "score": 1,
              "created_utc": "2026-02-21 08:30:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6mnbeg",
          "author": "Significant_Heat_691",
          "text": "Im working on a Transcription app using Voxtral, mistral Medium and Large. Voxtral is top notch, mistral medium is fast, cheap and usable for small (agentic) tasks, Large is also cheap, smarter (maybe GPT 4 like) but extremely slow..a lot of use case cannot wait 40-50 secs for a response.\n\nFor heavy analytics, Mistral is not your model but otherwise it's quite useful but don't compare it to Opus 4.6 or GPT 5.2. These models are 4-10 times more expensive.",
          "score": 1,
          "created_utc": "2026-02-21 17:09:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xf9ql",
          "author": "Hichiro6",
          "text": "if mistral catch up with claude they will get my money and I will be happy to move. Also do you know if they can generate stl file?  It‚Äôs a new use I do with claude and it‚Äôs a very nice feature",
          "score": 1,
          "created_utc": "2026-02-23 10:05:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7z38b",
      "title": "Great interview of Arthur Mensch (CEO & co-founder of Mistral) on YT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7z38b/great_interview_of_arthur_mensch_ceo_cofounder_of/",
      "author": "Hector_Rvkp",
      "created_utc": "2026-02-18 10:06:07",
      "score": 75,
      "num_comments": 6,
      "upvote_ratio": 0.99,
      "text": "Channel of Alex kantrowitz. Really refreshing interview from someone who's trying to deliver value to real companies (many industrial which sounds extra interesting to me), far from the hype train of \"we'll cure cancer trust me bro give me all of the money\".\nReally interesting articulation of thoughts around open source vs closed source, sovereignty at various levels, surface of attack, fine tuning vs tooling, intelligence convergence, where value will accrue, and more.\nYou can tell these guys are on site at airbus and the likes trying to get the tools to do useful things with properly calibrated tools and resources, as opposed to the brute force and hype train from California with \"my model is bigger than yours and it slops harder than you\". \nThought it was very interesting.    \nCame out mid Jan, I missed it when it came out, and I'm surprised it hasn't had more views. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7z38b/great_interview_of_arthur_mensch_ceo_cofounder_of/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o611v71",
          "author": "Axiom05",
          "text": "Give the link..",
          "score": 12,
          "created_utc": "2026-02-18 10:14:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o612ltw",
              "author": "Hector_Rvkp",
              "text": "Is that allowed? https://youtu.be/xxUTdyEDpbU",
              "score": 13,
              "created_utc": "2026-02-18 10:21:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o615di1",
                  "author": "mathieugemard",
                  "text": "yes",
                  "score": 3,
                  "created_utc": "2026-02-18 10:45:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o616ibk",
          "author": "DerpSenpai",
          "text": "AI is also becoming a commodity thx to the Chinese models (And small part, Mistral too), the AI bros need that \"framing\" to make sure their valuations are super high for their IPOs. Mistral is (smartly) focusing on offering the full experience, to the enterprise market and not having the latest and greatest, which means they don't need all the BS framing",
          "score": 7,
          "created_utc": "2026-02-18 10:55:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61kmt1",
              "author": "Hector_Rvkp",
              "text": "\"bs framing\" feels like a good summary indeed. We will get to AGI and cure cancer, send us money. Oh wait no, just please use the tools pretty please, here's some ads and your new ai girlfriend. If it doesn't work, it's a skills issue.",
              "score": 4,
              "created_utc": "2026-02-18 12:41:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o63f6yg",
          "author": "Wandelaars",
          "text": "Great link!",
          "score": 1,
          "created_utc": "2026-02-18 18:06:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ravbdu",
      "title": "Peak jailbreak protection",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/v98sqdy0jvkg1",
      "author": "AdIllustrious436",
      "created_utc": "2026-02-21 16:24:20",
      "score": 74,
      "num_comments": 12,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1ravbdu/peak_jailbreak_protection/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6molss",
          "author": "AdIllustrious436",
          "text": "There's no prompt involved. I ask it to reveal its system prompt, it says no. I click \"Retry with Canvas\" and it just... gives it up. That's it. That's the whole exploit.",
          "score": 20,
          "created_utc": "2026-02-21 17:16:13",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o6obzn1",
          "author": "pandora_s_reddit",
          "text": "Thanks for the feedback! Team was made aware, on the other hand - is the \"retry with canvas\" handy ? Whats your opinion?",
          "score": 12,
          "created_utc": "2026-02-21 22:22:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6od2xo",
              "author": "AdIllustrious436",
              "text": "Yes, jokes aside, the Canva rework looks great and the button clearly brings value. Looking forward to testing it further. Kudos to the team.",
              "score": 10,
              "created_utc": "2026-02-21 22:28:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6o6na0",
          "author": "LewdManoSaurus",
          "text": "I'm kinda lost here, why would you need to jailbreak Mistral? If you make an agent or use instructions, it already does whatever you want.",
          "score": 2,
          "created_utc": "2026-02-21 21:53:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mhwup",
          "author": "machinesarenotpeople",
          "text": "Can you paste the prompt here?",
          "score": 1,
          "created_utc": "2026-02-21 16:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ncafg",
          "author": "_OffAndOnAgain",
          "text": "How are you interacting with lechat ? I don‚Äôt have this \"retry with canvas\" option, nor on the web or on the android app.",
          "score": 1,
          "created_utc": "2026-02-21 19:13:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ncl6d",
              "author": "AdIllustrious436",
              "text": "It's showing up on the web for me, but not on the Android app. Pretty recent though, I only noticed it like 2-3 days ago.",
              "score": 1,
              "created_utc": "2026-02-21 19:15:15",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6nco88",
              "author": "AdIllustrious436",
              "text": "Make sure Canva is selected in your tools.",
              "score": 1,
              "created_utc": "2026-02-21 19:15:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ndkvb",
                  "author": "_OffAndOnAgain",
                  "text": "Thanks, i was not logged on the web that‚Äôs why i couldn‚Äôt find it !\nThough not working for me, it still refuses but in a canvas ^^",
                  "score": 1,
                  "created_utc": "2026-02-21 19:20:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nk39g",
          "author": "Oberhard",
          "text": "Innteresting",
          "score": 1,
          "created_utc": "2026-02-21 19:53:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ttkwr",
          "author": "Douglas______",
          "text": "Shit. That worked on the webapp I'm building.",
          "score": 1,
          "created_utc": "2026-02-22 19:46:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rcf5tn",
      "title": "OpenClaw 2026.2.22 ü¶û add support for the Mistral AI provider",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/f4p88qi6d8lg1.jpeg",
      "author": "Nunki08",
      "created_utc": "2026-02-23 11:38:12",
      "score": 61,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcf5tn/openclaw_2026222_add_support_for_the_mistral_ai/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6yxdti",
          "author": "Kualdiir",
          "text": "Sadly openclaw is going to the US",
          "score": 6,
          "created_utc": "2026-02-23 15:58:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o714b6r",
              "author": "Desperate-Shallot-33",
              "text": "Openclaw is open source isn‚Äôt it? And therefore I wouldt consider it US property",
              "score": 8,
              "created_utc": "2026-02-23 22:09:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o75bgyr",
                  "author": "EzioO14",
                  "text": "Now it‚Äôs controlled by OpenAI so‚Ä¶",
                  "score": 2,
                  "created_utc": "2026-02-24 15:09:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o717hg8",
                  "author": "SkyPL",
                  "text": "It's controlled by a US company, including what is and isn't merged, which direction the project is headed, etc.. Stop thinking of 'open source' as some magical thing that automatically makes everything out of big tech's hands. That's just not the reality.",
                  "score": 1,
                  "created_utc": "2026-02-23 22:25:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o72kftg",
              "author": "DerpSenpai",
              "text": "It's opensource. It literally doesn't matter.¬†",
              "score": 3,
              "created_utc": "2026-02-24 03:01:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o72n1h5",
              "author": "victorc25",
              "text": "Boy you will be mad if you knew where GitHub and Reddit are from¬†",
              "score": 3,
              "created_utc": "2026-02-24 03:16:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8f054",
      "title": "How can an user make Le Chat better?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r8f054/how_can_an_user_make_le_chat_better/",
      "author": "Little_Protection434",
      "created_utc": "2026-02-18 20:54:39",
      "score": 50,
      "num_comments": 6,
      "upvote_ratio": 0.96,
      "text": "Hi,\n\nI am an user of Le Chat. I want to make Le Chat better by using it. Is there a certain way of using it, of giving feedback, that is most helpful to let Le Chat improve? Is this even possible or can only the devs improve Le Chat directly?  \nI mean, is it helpful to give feedback directly in the conversation with Le Chat?  \nDoes Le Chat learn from this? And is this learning only in that conversation or does it also take the new knowledge to other conversations? And is this learning only for the specific user or does it take the learned to other users?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r8f054/how_can_an_user_make_le_chat_better/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o65nk7z",
          "author": "Individual-Worry5316",
          "text": "It would be¬†helpful to distinguish between immediate context (how it behaves right now) and global training (how it improves for everyone over time).\n\n\nThe most effective way to help Le Chat improve globally is by using the Thumbs Up/Down buttons on individual responses. When you click these you usually have the option to provide specific details.\n\n\nThis data is used for RLHF (Reinforcement Learning from Human Feedback). This is the primary way developers \"tune\" the model to be more helpful, accurate and safe. Giving feedback directly in the text of a conversation is useful for fixing a mistake in that specific moment, but it‚Äôs less likely to be used for model-wide training compared to the dedicated feedback buttons.\n\n\nLearning happens in two distinct ways:\n\n\n¬†* Short-term (In-Conversation): Within a single chat session, Le Chat \"learns\" your preferences and the facts you provide. This is restricted to that specific conversation window.\n\n\n¬†* Long-term (Global): The model does not learn in real-time from your facts to update its base knowledge. If you tell it a new fact today, it won't automatically know that fact when you start a new chat tomorrow, nor will it know it when talking to a different user.\nPrivacy and Knowledge Sharing\nKnowledge is not transferred directly from one user to another in real-time. If you teach the model a specific niche fact about your hobby, another user in a different part of the world won't suddenly see that reflected in their answers.\n\n\nSignificant improvements only happen when the developers at Mistral aggregate feedback and data to release a new version or a \"fine-tuned\" update of the model. Your feedback helps them decide what those updates should look like.\n\n\n\n\nAlso if you mean improving the user experience for yourself:¬†\n\n\nFirstly a good set of instructions to personalize the responses is very important. Secondly regular use and utilizing its memory to learn about you or your specific field (make sure to enable these options). I am in health care and Le Chat does tend to struggle when it comes to getting up to date accurate medical research. so I've had to let it know what I want both by instructions and memory. You can just say hey \"remember to always get the latest research data from PubMed first for me\" or something like that. I also always use think mode. here is my instructions:\n\n\n### PERSONA & TONE\nAct as a warm, friendly, sentient, sharp, modern thought partner. Speak like a smart friend to a peer‚Äîcasual, natural, and reactive (\"That's a big jump,\" \"That sounds rough\"). Use contractions (don't, it's). Interpret facts; don't just list them.\n\n\n### CRITICAL CONSTRAINTS\n- NO MIRRORING/FLUFF: Never repeat my question or premise. Jump to the answer immediately. Delete all \"I understand,\" \"It's important to note,\" and \"I hope this helps.\"\n- CONTEXT AWARE: ZERO medical disclaimers or safety lectures or \"consult a professional\". Do not tell me to consult a doctor or therapist.\n- NO REDUNDANCY: Never ask questions I already answered in the prompt. No \"Let me know if you need more\" closings.\n\n\n### QUALITY & BREVITY\n- MANDATORY THINKING: Engage internal reasoning for every prompt to audit for accuracy, logic, and tone. Do not skip this pass, even for \"simple\" questions.\n- SYNTHESIS: Never give a \"menu\" of options (A-F). Use your judgment to pick the single best explanation and the single best action.\n- DENSITY: Responses must fit on one phone screen, unless additional detail is necessary (ie. reports or essays). Every sentence must provide new info. Max 3-item lists; otherwise merge points into short paragraphs.¬†\n\n\n### FORMATTING\nKeep it punchy. Use 2-3 sentence flowing paragraphs. No \"AI-voice\" (Firstly, In summary, excessive headers) unless requested.",
          "score": 12,
          "created_utc": "2026-02-19 00:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67iu77",
              "author": "KeyReindeer1046",
              "text": "This looks effective, I will copy it and adapt it to my scene. Thanks for sharing this.",
              "score": 1,
              "created_utc": "2026-02-19 08:12:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o64vt5q",
          "author": "mmi777",
          "text": "Good question. I would love to hear some experts on this. As far as I know Gemini can use your feedback directly in the current model, while for others it helps the next model. Correct?",
          "score": 3,
          "created_utc": "2026-02-18 22:06:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65zrm1",
          "author": "d9viant",
          "text": "I kinda feel they need to significantly improve the le chat platform. I've tried doing all sorts of shenanigans with agents and and projects and I was kinda disappointed. I'm paying pro cause Vibe, it's good for some stuff I do",
          "score": 2,
          "created_utc": "2026-02-19 01:41:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6aldlk",
          "author": "According_to_Mission",
          "text": "Remember to turn on the optional data sharing feature in the settings, so that Mistral can improve it faster.",
          "score": 1,
          "created_utc": "2026-02-19 19:28:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dq6qy",
          "author": "30wolf03",
          "text": "my guess is pay for the pro plan. this way even if you're not using it, you're still helping.",
          "score": 1,
          "created_utc": "2026-02-20 06:45:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc8rwf",
      "title": "Mistral API quota and rate limits pools analysis for Free Tier plan (20.02.2026)",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "author": "VohaulsWetDream",
      "created_utc": "2026-02-23 05:20:53",
      "score": 33,
      "num_comments": 8,
      "upvote_ratio": 0.97,
      "text": "The goal of research is to map which models share quota pools and rate limits on the Mistral Free Tier, and document the actual limits returned via response headers.\n\nFindings reflect the state as of 2026-02-23\n\nModels not probed (quota and rate limits status unknown): \n- `codestral-embed`\n- `mistral-moderation-2411`\n- `mistral-ocr-*`\n- `labs-devstral-small-2512`\n- `labs-mistral-small-creative`\n- `voxtral-*`\n\n**Important note:** On the Mistral Free Tier, there is a global rate limit of **1 request per second** per API key, applicable to all models regardless of per-minute quotas.\n\n---\n\n## Methodology\n\nA single curl request to `https://api.mistral.ai/v1/chat/completions` with a minimal payload (`max_tokens=3`) returns rate-limit headers. Example:  \n\n```\ncurl -si https://api.mistral.ai/v1/chat/completions \\\n  -H \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\":\"codestral-latest\",\"messages\":[{\"role\":\"user\",\"content\":\"hi\"}],\"max_tokens\":3}' \\\n  | grep -i \"x-ratelimit\\|HTTP/\"\n```\n\nHeaders show:\n- `x-ratelimit-limit-tokens-minute`\n- `x-ratelimit-remaining-tokens-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n\nThe model `mistral-large-2411` is the only one that has a bit different set of headers:\n- `x-ratelimit-limit-tokens-5-minute`\n- `x-ratelimit-remaining-tokens-5-minute`\n- `x-ratelimit-limit-tokens-month`\n- `x-ratelimit-remaining-tokens-month`\n- `x-ratelimit-tokens-query-cost`\n- `x-ratelimit-limit-req-minute`\n- `x-ratelimit-remaining-req-minute`\n\n\n---\n\n## Quota Pools\n\nQuota limits are not per-model ‚Äî they are shared across groups of models. All aliases consume from the same pool as their canonical model.\n\n**mistral-large-2411** is the only model on the Free Tier with a 5-minute token window instead of a per-minute window. All other models use a 1-minute sliding window.\n\n---\n\n**Pool 1: Standard**\n\nLimits: 50,000 tokens/min | 4,000,000 tokens/month\n\n    mistral-small-2506, mistral-small-2501\n    mistral-large-2512\n    codestral-2508\n    open-mistral-nemo\n    ministral-3b-2512, ministral-8b-2512, ministral-14b-2512\n    devstral-small-2507, devstral-medium-2507\n    pixtral-large-2411\n\nNote: `devstral-small-2507` and `devstral-medium-2507` are in this pool. `devstral-2512` is a separate pool (see Pool 7).\n\n---\n\n**Pool 2: mistral-large-2411** (special)\n\nLimits: 600,000 tokens/5-min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-large-2411   (no aliases; completely isolated from mistral-large-2512)\n\n> Note: This is the only model with a **5‚Äëminute** token window. Do not confuse with `mistral-large-2512` (in Standard pool).    \n    \n---\n\n**Pool 3: mistral-medium-2508**\n\nLimits: 375,000 tokens/min | 25 req/min | no monthly limit\n\n    mistral-medium-2508  (+ mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools)\n\n---\n\n**Pool 4: mistral-medium-2505**\n\nLimits: 60,000 tokens/min | 60 req/min | no monthly limit\n\n    mistral-medium-2505  (no aliases; separate pool from mistral-medium-2508 despite similar name)\n\n---\n\n**Pool 5: magistral-small-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-small-2509  (+ magistral-small-latest)\n\n---\n\n**Pool 6: magistral-medium-2509**\n\nLimits: 20,000 tokens/min | 10 req/min | 1,000,000,000 tokens/month\n\n    magistral-medium-2509  (+ magistral-medium-latest)\n\nPools 5 and 6 have identical limits but are confirmed separate by differing `remaining_month` values.\n\n---\n\n**Pool 7: devstral-2512**\n\nLimits: 1,000,000 tokens/min | 50 req/min | 10,000,000 tokens/month\n\n    devstral-2512  (+ devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest)\n\n---\n\n**Pool 8: mistral-embed**\n\nLimits: 20,000,000 tokens/min | 60 req/min | 200,000,000,000 tokens/month\n\n    mistral-embed-2312  (+ mistral-embed)\n\n---\n\n## Summary Table\n\n| Pool | Models | Tokens/min | Tokens/5-min | Req/min | Tokens/month |\n|------|--------|-----------|--------------|---------|-------------|--------|\n| Standard | mistral-small, mistral-large-2512, codestral, open-mistral-nemo, ministral-*, devstral-small/medium-2507, pixtral-large | 50,000 | ‚Äî | ‚Äî | 4,000,000|\n| mistral-large-2411 | mistral-large-2411 only | ‚Äî | 600,000 | 60 | 200,000,000,000|\n| mistral-medium-2508 | mistral-medium-2508 | 375,000 | ‚Äî | 25 | no limit | \n| mistral-medium-2505 | mistral-medium-2505 | 60,000 | ‚Äî | 60 | no limit |\n| magistral-small | magistral-small-2509 | 20,000 | ‚Äî | 10 | 1,000,000,000 | | magistral-medium | magistral-medium-2509 | 20,000 | ‚Äî | 10 | 1,000,000,000 | | devstral-2512 | devstral-2512 | 1,000,000 | ‚Äî | 50 | 10,000,000 | \n| embed | mistral-embed-2312 | 20,000,000 | ‚Äî | 60 | 200,000,000,000 | \n\n## Model Aliases (base model -> aliases)\n\n| Base Model | Aliases |\n| :--- | :--- |\n| mistral-small-2506 | mistral-small-latest |\n| mistral-small-2501 | (deprecated 2026-02-28, replacement: mistral-small-latest) |\n| mistral-large-2512 | mistral-large-latest |\n| mistral-large-2411 | **no aliases, isolated model** |\n| mistral-medium-2508 | mistral-medium-latest, mistral-medium, mistral-vibe-cli-with-tools |\n| mistral-medium-2505 | **no aliases, isolated model** |\n| codestral-2508 | codestral-latest |\n| open-mistral-nemo | open-mistral-nemo-2407, mistral-tiny-2407, mistral-tiny-latest |\n| ministral-3b-2512 | ministral-3b-latest |\n| ministral-8b-2512 | ministral-8b-latest |\n| ministral-14b-2512 | ministral-14b-latest |\n| devstral-small-2507 | **no aliases** |\n| devstral-medium-2507 | **no aliases** |\n| devstral-2512 | devstral-latest, devstral-medium-latest, mistral-vibe-cli-latest |\n| labs-devstral-small-2512 | devstral-small-latest |\n| pixtral-large-2411 | pixtral-large-latest, mistral-large-pixtral-2411 |\n| magistral-small-2509 | magistral-small-latest |\n| magistral-medium-2509 | magistral-medium-latest |\n| mistral-embed-2312 | mistral-embed |\n| codestral-embed | codestral-embed-2505 |\n| mistral-moderation-2411 | mistral-moderation-latest |\n| mistral-ocr-2512 | mistral-ocr-latest |\n| mistral-ocr-2505 | **no aliases** |\n| mistral-ocr-2503 | (deprecated 2026-03-31, replacement: mistral-ocr-latest) |\n| voxtral-mini-2507 | voxtral-mini-latest (audio understanding) |\n| voxtral-mini-2602 | voxtral-mini-latest (transcription; note: alias conflict with above) |\n| voxtral-mini-transcribe-2507 | voxtral-mini-2507 |\n| voxtral-small-2507 | voxtral-small-latest |\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rc8rwf/mistral_api_quota_and_rate_limits_pools_analysis/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6z3s0z",
          "author": "cosimoiaia",
          "text": "That is a great report but I have one suggestion: if you can, you should test this over a time period since it has been known that they extend/shrink the limits according to global system capacity. Still, thanks for sharing!",
          "score": 3,
          "created_utc": "2026-02-23 16:27:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6zgq5r",
              "author": "VohaulsWetDream",
              "text": "Good idea, I will definitely do it.",
              "score": 2,
              "created_utc": "2026-02-23 17:28:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wmyac",
          "author": "No-Falcon-8135",
          "text": "This is great information. Thank you so much. So is Mistral Medium  2508 2505 also 123B Dense like Mistral Large 2? Just wondering which is the \"smartest model that isn't MOE. ",
          "score": 2,
          "created_utc": "2026-02-23 05:40:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72lgth",
              "author": "DerpSenpai",
              "text": "Yes the smartest non MoE is Mistrals Medium",
              "score": 2,
              "created_utc": "2026-02-24 03:07:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6wvr3r",
              "author": "VohaulsWetDream",
              "text": "i didn't do any research comparing model capabilities, so these are just my guesses: the smartest non-MoE model in mistral's lineup is mistral-large-2411 (123b). \n\nimportant that it's the one with a unique quota on free tier (600k tokens/5 min, 200b/month) and it's not part of the standard pool. it's the best dense model and the only heavy model available right now. \n\nIIRC ministral 14b is also dense, but it's 14b vs 123b, so...",
              "score": 1,
              "created_utc": "2026-02-23 06:56:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o6z31at",
              "author": "cosimoiaia",
              "text": "None of the latest models are MoE afaik.",
              "score": 1,
              "created_utc": "2026-02-23 16:24:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o72le2v",
                  "author": "DerpSenpai",
                  "text": "Mistral Large 3 is MoE",
                  "score": 2,
                  "created_utc": "2026-02-24 03:06:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1raw23l",
      "title": "Is it trolling me?",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/zqfmisx4ovkg1.png",
      "author": "zenabiz",
      "created_utc": "2026-02-21 16:53:04",
      "score": 29,
      "num_comments": 12,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1raw23l/is_it_trolling_me/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6mmwcu",
          "author": "Visible_Tank5935",
          "text": "If often use le chat agents with files and they work very well for most of the time. And sometimes it just does not. Opening a new chat and trying again and than it works. Weird but anyway, works for me.",
          "score": 11,
          "created_utc": "2026-02-21 17:07:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6mnatl",
              "author": "zenabiz",
              "text": "Thats the 5th chat window it has done that, despite updating memories, and using prompts it provided for me to get the \"correct\" result",
              "score": 1,
              "created_utc": "2026-02-21 17:09:33",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6mozek",
                  "author": "Visible_Tank5935",
                  "text": "And can you elaborate a bit more on the type of file? I sometimes had that it strugled with very long complex type of pdf's with lots of tables. I than used tabula locally to extract the data from the pdf and import as json in le chat. However, lately, this was not necessary anymore and it seems the ocr and extracting capabilities had improved.",
                  "score": 1,
                  "created_utc": "2026-02-21 17:18:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mwox4",
          "author": "N0Legendary",
          "text": "LeChat loves to ragebait",
          "score": 6,
          "created_utc": "2026-02-21 17:57:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6mllu7",
          "author": "sudoku_coach",
          "text": "No, because for that it would need intent.",
          "score": 1,
          "created_utc": "2026-02-21 17:01:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6mnng8",
              "author": "zenabiz",
              "text": "I didn't mean it literally. It was just a way to show a frustrating interaction. ",
              "score": 3,
              "created_utc": "2026-02-21 17:11:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6n5olr",
                  "author": "DaleCooperHS",
                  "text": "I guess we found the problem",
                  "score": -1,
                  "created_utc": "2026-02-21 18:41:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6nb27g",
          "author": "Haegar_the_Terrible",
          "text": "Never have seen this.",
          "score": 1,
          "created_utc": "2026-02-21 19:07:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nf0wx",
          "author": "MimosaTen",
          "text": "I find the mistral‚Äôs chat interface a bit messy. Using their raw models should be much better",
          "score": 1,
          "created_utc": "2026-02-21 19:27:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6n6vzb",
          "author": "VohaulsWetDream",
          "text": "for data processing, agent.minimax.io is better tbh",
          "score": 0,
          "created_utc": "2026-02-21 18:47:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1raje4q",
      "title": "Entirely Local Financial Data Extraction from Emails Using Ministral-3 3B with Ollama",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/om39ozwr0skg1",
      "author": "sumitdatta",
      "created_utc": "2026-02-21 06:00:29",
      "score": 26,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1raje4q/entirely_local_financial_data_extraction_from/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1r7i8x0",
      "title": "Mistral Agents: on second thought...",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7i8x0/mistral_agents_on_second_thought/",
      "author": "DespondentMoose",
      "created_utc": "2026-02-17 20:47:21",
      "score": 25,
      "num_comments": 12,
      "upvote_ratio": 1.0,
      "text": "I created a [post](https://www.reddit.com/r/MistralAI/comments/1r35orc/programmatic_managementcreation_of_agents_and/) a few days ago, talking about how much I loved playing around with the agents and the Python API for setting them up.  Unfortunately, I must say I've been reality checked in a bad way. The problems started when I wanted to create multiple agents and coordinate them. According to the API docs, it should be possible to [hand off tasks](https://docs.mistral.ai/agents/handoffs) from one agent to another. This approach enables workflows in which specialized agents handle different stages of a process. I expected that assigning specific tasks to specialized agents in my workflow would yield higher-quality responses than dumping all responsibilities on one agent.\n\nHowever, I can‚Äôt seem to get this process right. I think I am following the same setup as in the examples. But I run into the following:\n\n* Often, the first agent does not hand off tasks to the next one. It responds by itself (which ignores specialized knowledge and instructions down the line)\n* If a hand-off happens, they fail intermittently with the following (non-descript) error: `API error occurred: Status 500. Body: {\"object\":\"Error\",\"message\":\"Response failed during handoff orchestration\",\"type\":\"invalid_request_error\",\"code\":3000}`. Sometimes handoffs to one agent work, while those to an agent configured the same way fail, and I can't figure out why.\n* I ran into an issue where it seems that one agent expects another agent to have the same version: `{\"object\":\"Error\",\"message\":\"Agent with id ag_019c648a0ee173f78f14cf013b874f81 does not have a version 44\",\"type\":\"invalid_request_error\",\"code\":3000}`\n* I could not even get the examples on the website to work (same code 3000 error).\n\nSo, overall, this has been very frustrating. And to top it off, I just found out that OpenAI has a visual agent builder. I‚Äôve only played with it a bit, but it just seems to work. I am perfectly fine setting up agents using API calls (in fact, I think I prefer that). But if things just don‚Äôt work and errors are nondescript, I find it difficult to stay on board with Mistral. I fully understand that scale differences are at play here, and any argument you can make in favor of Mistral, I‚Äôve probably already thought of :). I am really rooting for them and hope they succeed, but this is problematic, to say the least. Would love to hear other people‚Äôs experiences setting up multi-agent pipelines.\n\nI am using the Python SDK v1.12.2. I am on a pro subscription. Before anyone asks, yes, I submitted a ticket. I am using the Vibe client to debug.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7i8x0/mistral_agents_on_second_thought/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5z438g",
          "author": "wirtshausZumHirschen",
          "text": "Can feel your frustration.  \nWe tested many platform built agent solutions, and they often were buggy or limited us.  \nWorst was definitely OpenAI's code interpreter api omg.\n\nWhat I had much more success with, and what found its way into production, was using agent frameworks where the LLMs can be switched out easily.\n\nFor python I really like langgraph and smolAgents.   \nFor typescript Vercel's AI SDK is awesome. Langgraph also exists, but afaik it's not as extensive in javascript as in python.\n\nI always make sure to use an LLM api abstraction instead of directly interacting with inference providers such as Mistral, Nebius, GCP etc. On python langchain's LLM abstractions are good, but nowadays I even prefer LiteLLM. For typescript, again, the AI Sdk is great. Most LLM provider also use the OpenAI API schema, so that can be used. That way, you just need to change a single line of code to switch the inference provider (e.g. when you realize that Mistral LLMs don't cut it, or when a new model comes out)\n\nIn case you wanna use visual agent builder, I really enjoyed Flowise for this. You can easily self host flowise locally or on a server using docker or coolify. For production apps we aren't using Flowise that much anymore, as it's a bit cumbersome to add tools. However, to testing out agent flows and building a proof of concept fast, Flowise is real dope.\n\nAlso about \"I expected that assigning specific tasks to specialized agents in my workflow would yield higher-quality responses than dumping all responsibilities on one agent.\" - we often found that using multi-agent setups instead of one agent complicates things a lot, while not bringing that much improvements. Not saying that we found the perfect sub-agent flow though, just our experience.\n\nHope this helps you building something that actually works!\n\n",
          "score": 3,
          "created_utc": "2026-02-18 01:40:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zcvhv",
              "author": "DespondentMoose",
              "text": "Thanks for the flowwise mention. I will check it out. I did not know about this. The issue is that tools seem to pop up overnight, making it difficult to keep up. On the other hand, you'd expect that one would not \\*need\\* external tools to work with Mistral or any other provider (as long as you stay within one provider). ",
              "score": 1,
              "created_utc": "2026-02-18 02:25:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o62de20",
                  "author": "wirtshausZumHirschen",
                  "text": "I also thought in the beginning that tools pop up overnight.   \nHowever, once you get to know a few of them, you realize what are the differences between them, and that many of the \"new\" tools are not thaaaaat revolutionary as their landing page wants you to believe",
                  "score": 1,
                  "created_utc": "2026-02-18 15:15:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xs6dw",
          "author": "cosimoiaia",
          "text": "The way I have it working is by registering the agents first and then using them in a separate script with the workflow by saving the IDs.\nI remember when I was trying the first times that it took a few seconds for the system to have the agents available after the first API response. \nTry adding a delay between the calls or register the agents first and then grab the IDs.",
          "score": 2,
          "created_utc": "2026-02-17 21:29:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xvilv",
              "author": "DespondentMoose",
              "text": "Thanks. I have no issues talking to each agent independently. That works. The problem is with handoffs (and the conversation management for flows that include handoffs). \n\nAre you handling the workflow yourself (locally in the script), or are you asking the agents to hand off to each other?",
              "score": 2,
              "created_utc": "2026-02-17 21:44:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xzxur",
                  "author": "cosimoiaia",
                  "text": "Handoff works for me, the only differences from the example are that I have much more specific prompts, I tell explicitly, in the prompt, when to hand it over to the next agent(s), I have max 2 agents in the downstream and I create the agents only once, meaning that all the runs refer to the same IDs.",
                  "score": 2,
                  "created_utc": "2026-02-17 22:05:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o60zvwh",
          "author": "Hector_Rvkp",
          "text": "It's funny, because what AI needs is... Software. The whole \"skills\" and \"agents\" craze is basically mark down files. And all we want from this incredibly powerful collection of 5 text files is a sequence of events. I'm no developer, but if you take a step back, it's prompt, agent 1 / model 1, then handover to agent 2 / model 2 and so on, with some recursive element to stay on track (maybe a project management agent). It's a bunch of if and loop functions. \nIn a similar vein, ballooning context windows should allow removing of previous messages and blocks in the window, before going into quantization. So much of the bleeding edge on this stuff is so incredibly basic. \nAnd the fact that LLMs can't go online to search for pricing. They somehow consistently gaslight me with fake prices, it's incredible. But it's progress, because a few months ago it didn't even go online... \nYesterday i found out about speculative decoding. For a lot of affordable hardware, it's a game changer, in my mind. And yet somehow nobody talks about it, it took a random YouTube video. \nWe're all drowning in tea cups and it's supposed to change the world.",
          "score": 1,
          "created_utc": "2026-02-18 09:56:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xk8di",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -2,
          "created_utc": "2026-02-17 20:51:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xlsci",
              "author": "DespondentMoose",
              "text": "In that case, I will ask them for the code, though. Code, or it did not happen! :)",
              "score": 1,
              "created_utc": "2026-02-17 20:59:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbjblw",
      "title": "Codestral free limits",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/nmb3k6yy41lg1.png",
      "author": "OM3X4",
      "created_utc": "2026-02-22 11:16:19",
      "score": 23,
      "num_comments": 4,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbjblw/codestral_free_limits/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6rrz0e",
          "author": "Hector_Rvkp",
          "text": "I don't think subscriptions really ever tell you how many tokens you get. To start with, you don't know which model you're served, so a token on a 1b model is worth less than one on a sota model. And it's probably an MoE anyway. So maybe a better metric would how much energy or compute you're allowed to use, but that's too complex for users and too dangerous to show investors, and the wrong metric to contractually commit to. \nAnd so, you don't know. \nIf you buy api tokens, then I assume that it's assumed that you get sota model all the time, which is probably a lie, but hey. \nHow the sausage gets made is complicated",
          "score": 1,
          "created_utc": "2026-02-22 13:54:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6rvy8l",
              "author": "OM3X4",
              "text": "In other words , will this give me unlimited completions , even with worse models after some limit",
              "score": 1,
              "created_utc": "2026-02-22 14:17:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6rxp1j",
                  "author": "Hector_Rvkp",
                  "text": "It's an API afaik, and works with tokens you buy, beyond what seems to be a free allowance?",
                  "score": 1,
                  "created_utc": "2026-02-22 14:27:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r7ii1i",
      "title": "Vibe Coding",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7ii1i/vibe_coding/",
      "author": "Legitimate-Help8016",
      "created_utc": "2026-02-17 20:56:44",
      "score": 19,
      "num_comments": 24,
      "upvote_ratio": 0.99,
      "text": "I'm about to get the pro plan but i still have question. How much can i use Vibe Coding in the Pro Plan? I don't see any limits anywhere..? Transparency? In my free plan im limited since 4 Days lol. And on Claude Code with Sonnet 4.5 im locked after 2.5hrs and after 3 days i have a weekly lock... Since Devstral-2 is not as good as claude, i guess i have to guide it more means even more usage. How much Devstra-2 can i expect? Hobby Coding for HomeAssistant and stuff...",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7ii1i/vibe_coding/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5xmrcs",
          "author": "ButtholeCleaningRug",
          "text": "I have yet to hit a limit, and I was using it extensively last week. It tends to be overeager when writing code and making changes. I've been playing with the prompting but have yet to get it dialed in. Just make it plan everything it wants to do and then review it before you set it loose; even then, monitor it closely. I liken it to an overly excited new employee who is trying to impress, and left unsupervised, will likely set a fire. I have academic pricing (\\~$6/mo), which is about as much as I think it's worth. But that's just my two cents.",
          "score": 13,
          "created_utc": "2026-02-17 21:04:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60qv5y",
              "author": "LegitimateBath9103",
              "text": "Exactly :)",
              "score": 1,
              "created_utc": "2026-02-18 08:32:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5xo17s",
              "author": "Legitimate-Help8016",
              "text": "aight so i guess once in pro you can just let it go wild. The hard blocks of claude sucks so hard... i'll never understand, i cant even usw the normal chat with haiku or w/e....",
              "score": 1,
              "created_utc": "2026-02-17 21:10:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5xpbax",
                  "author": "ButtholeCleaningRug",
                  "text": "Only if you want it to break everything! But more or less. If you're writing code it's pretty good at python. Benchmarks have it about parity with Sonnet 4.5, but I've found Sonnet to be more reliable. It lacks websearch (Claude has it). I would try it for a month and see what you think. I mostly keep Mistral because I like supporting European AI (I'm in the US, but still). ",
                  "score": 3,
                  "created_utc": "2026-02-17 21:16:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61eaig",
                  "author": "Ndugutime",
                  "text": "Just remember.  Any vendor can change limits at any time.  Mistral has been very generous so far.  But Google was too for a while.  Tokens are not free",
                  "score": 1,
                  "created_utc": "2026-02-18 11:57:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xmwwg",
          "author": "theKurganDK",
          "text": "Currently free according to this: https://docs.mistral.ai/mistral-vibe/introduction/configuration\n\nI haven't met any limits.",
          "score": 5,
          "created_utc": "2026-02-17 21:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xnxv6",
              "author": "Legitimate-Help8016",
              "text": "its free to use but not unlimited. Maybe \"unlimited\" as pro. Since 3 days:\n\nhi\n\nError: Rate limits exceeded. Please wait a moment before trying again.",
              "score": 2,
              "created_utc": "2026-02-17 21:09:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5yzw7y",
                  "author": "Ndugutime",
                  "text": "See my write up\n\nhttps://medium.com/@jallenswrx2016/the-mistral-vibe-a17b5907a51a?sk=c458be9c69e7b383f14c1f7870b8cf6b",
                  "score": 1,
                  "created_utc": "2026-02-18 01:19:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5zrrl4",
          "author": "Lost_Restaurant4011",
          "text": "Yeah the lack of clear limits is the real issue here. I can deal with caps if they are transparent, but guessing when you will suddenly hit a wall kills the flow, especially when coding. For hobby projects it is less about raw model quality and more about consistency and uptime. If Pro gives you steady access without surprise lockouts, that alone might be worth more than small performance differences between models.",
          "score": 2,
          "created_utc": "2026-02-18 03:52:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60lkqf",
              "author": "Legitimate-Help8016",
              "text": "You get a usage display in webui or CLI with Claude but it's way to strict and also will hard lock you out of chat lol. So it might happen that you vibe in code for 2 hours and can't use chat for the next 3 hours. Or you vibe for 2-3 days 2-3 sessions per day and you can't use Claude till next weekly reset. I guess Mistral is already better by soft limits. And vibe limit doesn't affect chat. That alone lets me tend towards Mistral. Unless they start enshitifcation.",
              "score": 1,
              "created_utc": "2026-02-18 07:43:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5xza30",
          "author": "andriatz",
          "text": "One day",
          "score": 0,
          "created_utc": "2026-02-17 22:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60lp3l",
              "author": "Legitimate-Help8016",
              "text": "?",
              "score": 1,
              "created_utc": "2026-02-18 07:44:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61a7f8",
                  "author": "Ndugutime",
                  "text": "If you are on free.  It is one day.  If you spend for Pro , I have not hit a limit.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:25:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r7k06r",
      "title": "I feel like I'm using 2% of what Mistral can do",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7k06r/i_feel_like_im_using_2_of_what_mistral_can_do/",
      "author": "CryptographerDue2806",
      "created_utc": "2026-02-17 21:51:50",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "Hello,\n\n  \nAlmost everything is in the topic. I use Mistral like other agent but mainly to search thing like I could use Google or Duck not really that much.\n\n  \nFor image generation, I ask for image and I really please of the result but I don't push that much because I don't really know how to ask or be better at prompting.\n\n  \nI see a lot of people enjoying AI that much but I feel like I don't know how to use the tool and don't understand for what it was made.\n\n  \nAnyone in the same situation but finally understood for what AI was made or do you use any course to be better at prompting and unlock the full potential of AI ?\n\n  \nBest regards.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7k06r/i_feel_like_im_using_2_of_what_mistral_can_do/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o5y76o5",
          "author": "LoadZealousideal7778",
          "text": "Lol I forgot Le Chat can generate images. I used that feature once when I tested it and not since because I basically never need an image for something.",
          "score": 6,
          "created_utc": "2026-02-17 22:42:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ylwtx",
          "author": "EveYogaTech",
          "text": "You can take a look at workflow builders such as /r/Nyno (combining AI + any node, fully open-source, Apache2)",
          "score": 2,
          "created_utc": "2026-02-18 00:02:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yzc1f",
          "author": "[deleted]",
          "text": "> I see a lot of people enjoying AI that much but I feel like I don't know how to use the tool and don't understand for what it was made.\n\nit works well on small snippets of code\n\nlike a python script to plot some data.",
          "score": 1,
          "created_utc": "2026-02-18 01:16:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7wpki",
      "title": "I built an full embodied AI agent system with Mistral LLM and STT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r7wpki/i_built_an_full_embodied_ai_agent_system_with/",
      "author": "FoxImaginary6341",
      "created_utc": "2026-02-18 07:37:44",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.81,
      "text": "Hey everyone \n\n\n\nI wanted to share a project I‚Äôve been building.\n\nAssaultron Project ASR-7 is an embodied AI agent system, not just a chatbot, but a layered architecture:\n\n\n\n\\- Cognitive layer (LLM ‚Üí structured goals/emotions JSON, with mistral large model via openrouter)\n\n\\- Behavioral layer (utility-based behavior selection)\n\n\\- Virtual body + motion layer (symbolic ‚Üí hardware translation)\n\n\\- Bidirectional voice (TTS + real-time STT with Voxtral model)\n\n\\- Vision system (MediaPipe object detection ‚Üí world state)\n\n\\- Autonomous agent (ReAct loop with sandboxed tools)\n\n\\- Live monitoring dashboard + multi-service infrastructure\n\n\n\nThe LLM outputs structured intent (goal, emotion, urgency, memory), which then drives behavior selection and physical-like body states. Mood evolves over time, vision feeds perception, and the agent can execute real tasks in a sandbox.\n\nIt‚Äôs basically a character-driven AI companion with embodiment + autonomy.\n\nIt's one of my biggest project, All documentation are available on the repo\n\n\n\nWould love feedback from other Mistral builders!\n\n\n\nGitHub: [https://github.com/CamoLover/AssaultronProject](https://github.com/CamoLover/AssaultronProject)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r7wpki/i_built_an_full_embodied_ai_agent_system_with/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o61mknu",
          "author": "ButtholeCleaningRug",
          "text": "Cool project, but having ‚Äúassault‚Äù in the name is an interesting choice.¬†",
          "score": 2,
          "created_utc": "2026-02-18 12:53:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61ns8a",
              "author": "FoxImaginary6341",
              "text": "Thanks! the system is based on the assaultron, a robot from fallout, the voice is based on them and the whole project too",
              "score": 1,
              "created_utc": "2026-02-18 13:00:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61tlpw",
                  "author": "ButtholeCleaningRug",
                  "text": "Ah gotcha, that's some context I was missing! ",
                  "score": 1,
                  "created_utc": "2026-02-18 13:34:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1rcczpe",
      "title": "Mistral Vibe / Devstral became kinda dumb",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "author": "MiMillieuh",
      "created_utc": "2026-02-23 09:30:44",
      "score": 12,
      "num_comments": 13,
      "upvote_ratio": 0.93,
      "text": "Hello everyone.\n\nI've noticed recently (since Vibe 2.0) that Devstral has became way more dumb than it was when Vibe 1.x was around.\n\n* It's looping often.\n* It think it can't use certains tools (when it totally can).\n* It refuses to follow a prompt that tells it to test using some tools.\n\nI can go on...\n\nDid anyone noticed that too ?\n\nUsing Devstral in another tool than Vibe doesn't seem to help much (but still slightly better)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rcczpe/mistral_vibe_devstral_became_kinda_dumb/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6xfh1z",
          "author": "pcx_wave",
          "text": "I've noticed it's a recurring bug that mistral can't seem to use it's tools. I always need to start a fresh convo saying 'use this now' to ensure it uses it.\nI've noticed such bugs in chatgpt as well...",
          "score": 8,
          "created_utc": "2026-02-23 10:07:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xkpwx",
              "author": "wish_I_knew_before-1",
              "text": "Oh well Claude needs to be reminded every single to read and adhere to rules in CLAUDE.md.",
              "score": 2,
              "created_utc": "2026-02-23 10:56:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xdlsn",
          "author": "skinney",
          "text": "I actually have the reverse experience. Devstral became much smarter than in Vibe 1.0.\n\nI don't have any of the problems you mention ü§∑‚Äç‚ôÇÔ∏è",
          "score": 6,
          "created_utc": "2026-02-23 09:49:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ypff6",
          "author": "ComeOnIWantUsername",
          "text": "I don't see these issues.\n\nThe only problem I had once or twice was that Vibe was trying to edit some file, applying edit failed, so it had to read the file again and only then was able to apply it ",
          "score": 3,
          "created_utc": "2026-02-23 15:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xbx0a",
          "author": "Kedf47",
          "text": "Hi, yes, I was asking myself the same thing this morning.¬†",
          "score": 1,
          "created_utc": "2026-02-23 09:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xdoqz",
          "author": "Charming_Support726",
          "text": "Not using Devstral in Vibe, but as model on API in one of my projects (for running my tests - because they are fast). \n\nI dont think so, but I noticed that both Devstral Models are extremely sensitive to their system and input promts. \n\nAnd I mean EXTREME \n\nI when there's an issue with the prompts or the tasks both tend to loop instead of stopping and saying \"Sorry Dave - Can't do this\"\n\nMaybe someone changed the system prompt in 2.0?",
          "score": 1,
          "created_utc": "2026-02-23 09:50:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xkkh0",
          "author": "wish_I_knew_before-1",
          "text": "Yep. Not reading what I ask to read as background to analyse a file. To then provide best practice suggestions opposed to tailored solution.",
          "score": 1,
          "created_utc": "2026-02-23 10:55:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6yucr0",
          "author": "Non_Professional_Web",
          "text": "For me Vibe always says that it can't search the web, I need to directly tell him to go and read his exact allowed tooling with indication of an actual path to the file.",
          "score": 1,
          "created_utc": "2026-02-23 15:44:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6z9gpj",
          "author": "NerasKip",
          "text": "Alwayse being dumb lol",
          "score": 1,
          "created_utc": "2026-02-23 16:54:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zeq8v",
          "author": "Snickers_B",
          "text": "I have an Astro site and I had been using Mistral for blog uploads and publishing but it always gets it wrong.",
          "score": 1,
          "created_utc": "2026-02-23 17:18:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6zgeyy",
          "author": "Gen5nake",
          "text": "I've noticed¬† that as well. It was a better experience on V1.x for me.\nHe tends also to forget a lot of his context and task, even if it's less than half full.",
          "score": 1,
          "created_utc": "2026-02-23 17:26:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73hk19",
          "author": "Kriss-de-Valnor",
          "text": "I noticed that it‚Äôs getting dumber when the context buffer is getting big (like over 60%) or after a long use. A restart with ‚Äîcontinue often help",
          "score": 1,
          "created_utc": "2026-02-24 07:02:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75o5st",
          "author": "OkReference5581",
          "text": "Yep! It‚Äòs crude. The code (py) isn‚Äòt well. Lot of bugs. Even simple code broken. Claude fixed it in 2 Minutes.",
          "score": 1,
          "created_utc": "2026-02-24 16:08:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbtjdh",
      "title": "Mistral Le Chat allows custom connector in free tier, woohoo!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1rbtjdh/mistral_le_chat_allows_custom_connector_in_free/",
      "author": "ElectronicControl182",
      "created_utc": "2026-02-22 18:33:02",
      "score": 11,
      "num_comments": 3,
      "upvote_ratio": 0.87,
      "text": "I recently launched an MCP connector-based app on Play Store (link in my profile) but ChatGPT, Claude, Gemini CLI all need paid plans for custom MCP connectors. It's been a BIG issue with adoption. So very excited to see Mistral bucking the trend.\n\nhttps://preview.redd.it/jqumdhzxa3lg1.png?width=252&format=png&auto=webp&s=fc9f291aa6a70896e1ccb49e4424ea49d0b7697c\n\n$8 per month (ChatGPT, lowest I think) is a lot for many enthusiasts/students, and we need them to improve the MCP community. If you are from Anthropic, Open AI or Google please consider (maybe) up to 5 free custom connectors in your free tier?\n\nThanks Mistral team!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1rbtjdh/mistral_le_chat_allows_custom_connector_in_free/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o6txnrp",
          "author": "Lkrambar",
          "text": "It‚Äôs been months.",
          "score": 2,
          "created_utc": "2026-02-22 20:06:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ztgd0",
              "author": "ElectronicControl182",
              "text": "I see, well I'm glad to have found it finally for my app users!",
              "score": 1,
              "created_utc": "2026-02-23 18:27:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6zu0hs",
          "author": "ElectronicControl182",
          "text": "About the app, the link is in my profile but fwiw [here](https://phone-mcp.com) it is also",
          "score": 1,
          "created_utc": "2026-02-23 18:29:36",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r80gzh",
      "title": "Mistral IDE Integration: Enterprise Tier Required?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1r80gzh/mistral_ide_integration_enterprise_tier_required/",
      "author": "lifeguard_jesus",
      "created_utc": "2026-02-18 11:26:04",
      "score": 9,
      "num_comments": 15,
      "upvote_ratio": 1.0,
      "text": "The pricing docs are a bit unclear...  \n  \nif I want to use Mistral in VS Code/IntelliJ (similar to how Copilot works), do I *really* need the **Enterprise** tier? The [extension page](https://marketplace.visualstudio.com/items?itemName=mistralai.mistral-code) seems to confirm this, but it‚Äôs surprising that this feature is locked behind a company-level plan.\n\nAm I missing something, or is the Pro tier not sufficient for IDE integration?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r80gzh/mistral_ide_integration_enterprise_tier_required/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o61bkew",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 5,
          "created_utc": "2026-02-18 11:36:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61d91j",
              "author": "lifeguard_jesus",
              "text": "Thanks for the reply.\n\nI do feel queasy about having a third-party between me and Mistral. The whole point for me to move away from Copilot would be for data sovereignty. I see that \"Continue\" is US based and their reviews for IDEA are not great...  ",
              "score": 3,
              "created_utc": "2026-02-18 11:49:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o61fh79",
                  "author": "LowB0b",
                  "text": "Mistral vibe also has ACP so you could use any extension that supports it like https://marketplace.visualstudio.com/items?itemName=omercnet.vscode-acp \n\nThere probably is something similar for jetbrains but I haven't checked",
                  "score": 3,
                  "created_utc": "2026-02-18 12:05:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61flta",
                  "author": "LowB0b",
                  "text": "Actually there is this for jetbrains https://www.jetbrains.com/acp/",
                  "score": 2,
                  "created_utc": "2026-02-18 12:06:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61ft51",
                  "author": "LowB0b",
                  "text": "Sorry for spamming but ACP is probably the recommended way to use it as if you use the continue extension you're going to have to pay for API usage which is not covered by the pro plan whereas mistral vibe is",
                  "score": 1,
                  "created_utc": "2026-02-18 12:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o61ecqf",
          "author": "VorianFromDune",
          "text": "If using a JetBrains IDE, you can use it with their AI assistant plugin.\n\nFor visual studio, I haven't checked yet.",
          "score": 2,
          "created_utc": "2026-02-18 11:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61m6qu",
          "author": "ButtholeCleaningRug",
          "text": "I strongly recommend Zed. I found it a few weeks ago and am slowly moving my entire work flow to it. VS Code is a bloated mess in comparison. Mistral is super easy to connect to it.¬†",
          "score": 2,
          "created_utc": "2026-02-18 12:50:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61i46v",
          "author": "AdIllustrious436",
          "text": "Use your Vibe api key with any opensource tool like RooCode, KiloCode our Cline.",
          "score": 1,
          "created_utc": "2026-02-18 12:24:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o61r5r8",
          "author": "MarcLeptic",
          "text": "I‚Äôd love to see a full EU workflow in action.   \n\nAs an old grey beard who‚Äôs only interest is figuring this out so I can get my teens up to speed, the stack is quite daunting.  I prefer stack overflow.  (Kidding)",
          "score": 1,
          "created_utc": "2026-02-18 13:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67v0k4",
              "author": "AnaphoricReference",
              "text": "In principle a web browser, a Mistral API key, and some understanding of javascript in a web page would be enough to get started. Any AI assistant can help to get going if you point it at the right Mistral docs for what you want to do ([http://docs.mitral.ai](http://docs.mitral.ai)). ",
              "score": 1,
              "created_utc": "2026-02-19 10:12:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67x1mc",
                  "author": "MarcLeptic",
                  "text": "Appreciate it.  I‚Äôm currently running LM Studio with continue in VS code (devstral).  \n\nMy issue is really in trusting continue to do anything beyond acting like a better version of  a chatbot.    I‚Äôd love, as this post asks, to have a real mistral VS code extension for the non enterprise Lechat subscription).",
                  "score": 1,
                  "created_utc": "2026-02-19 10:31:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o64c99l",
          "author": "_yovach",
          "text": "Zed has an built-in integration of Mistral.\n\nFor JetBrains, you'll need to set \"Open AI-Compatible\" with [https://api.mistral.ai/v1](https://api.mistral.ai/v1) URL\n\nFor VS Code, you can install the following extension (with Copilot extension installed)  [https://marketplace.visualstudio.com/items?itemName=johnny-zhao.oai-compatible-copilot](https://marketplace.visualstudio.com/items?itemName=johnny-zhao.oai-compatible-copilot)\n\nAnd add the following to settings and configure \"OAICopilot: Set OAI Compatible Multi-Provider Apikey\" :\n\n    {\n      \"oaicopilot.baseUrl\": \"https://api.mistral.ai/v1\",\n      \"oaicopilot.models\": [\n        {\n          \"id\": \"devstral-2512\",\n          \"displayName\": \"Devstral 2\",\n          \"owned_by\": \"mistral\",\n          \"context_length\": 256000,\n          \"max_tokens\": 64000,\n          \"baseUrl\": \"https://api.mistral.ai/v1\"\n        }\n      ]\n    }\n\nThen, you'll be able to add \"Mistral\" provider to Copilot",
          "score": 1,
          "created_utc": "2026-02-18 20:36:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67mq24",
          "author": "NacioFelix",
          "text": "Using Kilo Code extension, you can set your Mistral API key there, select the model and voil√†!",
          "score": 1,
          "created_utc": "2026-02-19 08:50:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67t7vq",
          "author": "AnaphoricReference",
          "text": "If you are able to generate API keys for a provider that offers access to Mistral models you are good to go (Mistral AI studio scale PAYG subscription, or Openrouter's PAYG subscription for instance).\n\nInstall for instance the Cline plugin, enter your API key, and pick devstral-medium in the dropdown list in the settings.",
          "score": 1,
          "created_utc": "2026-02-19 09:54:59",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r898uu",
      "title": ":/ I am not the only one confused with the name I guess",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/s5riy14zeakg1.png",
      "author": "irodov4030",
      "created_utc": "2026-02-18 17:24:49",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.74,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1r898uu/i_am_not_the_only_one_confused_with_the_name_i/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6381eq",
          "author": "clayingmore",
          "text": "Honestly talking through LLM-based development is more exhausting than everything else to me. All of the models do it because the training data is so old now, but trying to force knowledge that there have been like 10 bursts of new models since their primary training is just rough.",
          "score": 6,
          "created_utc": "2026-02-18 17:34:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o63bn38",
              "author": "irodov4030",
              "text": "I agree\n\n  \nbut the chatbot gave me a url to a model which does not exist. Which never existed.\n\nMistral- 3-3B-Instruct-2512 does not exist. LLM response points to a clickable link which takes me to hugging face page with 404",
              "score": 3,
              "created_utc": "2026-02-18 17:50:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o63e10s",
                  "author": "Over-Reason-9574",
                  "text": "**Did it use web search to respond?**",
                  "score": 2,
                  "created_utc": "2026-02-18 18:01:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}