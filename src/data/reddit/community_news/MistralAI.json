{
  "metadata": {
    "last_updated": "2026-02-06 02:55:57",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 20,
    "total_comments": 185,
    "file_size_bytes": 191671
  },
  "items": [
    {
      "id": "1qvku2t",
      "title": "Mistral robotics team is hiring.",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/jnizqe6gdghg1",
      "author": "Nunki08",
      "created_utc": "2026-02-04 10:15:21",
      "score": 731,
      "num_comments": 20,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvku2t/mistral_robotics_team_is_hiring/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3i97r4",
          "author": "nycigo",
          "text": "Incredible, I love Mistral",
          "score": 46,
          "created_utc": "2026-02-04 10:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i9vcx",
          "author": "flololan",
          "text": "Damn that's really fast",
          "score": 40,
          "created_utc": "2026-02-04 10:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3idmua",
              "author": "Everlier",
              "text": "Likely teleoperated for the video, they have lots of stations, likely to collect training data for these",
              "score": -12,
              "created_utc": "2026-02-04 11:00:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ieu8o",
                  "author": "AdIllustrious436",
                  "text": "They claim it's autonomous at x1 speed in the video.",
                  "score": 11,
                  "created_utc": "2026-02-04 11:10:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3iaxs3",
          "author": "InsideMikesWorld",
          "text": "Off topic, but how can I get Mistral Cat plushy!",
          "score": 34,
          "created_utc": "2026-02-04 10:36:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iaym5",
          "author": "johoham",
          "text": "Crazy to see what monitor stands can evolve to once theyâ€™ve scaled off their displays.",
          "score": 23,
          "created_utc": "2026-02-04 10:36:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iglq9",
          "author": "grise_rosee",
          "text": "No Elonâ€™s hype, no Boston Dynamics choreography, no *I, Robot*\\-style retro-futuristic humanoids. Just raw skills, plain and simple.",
          "score": 24,
          "created_utc": "2026-02-04 11:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iijw4",
          "author": "AriyaSavaka",
          "text": "That *le cat* is adorable",
          "score": 11,
          "created_utc": "2026-02-04 11:41:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3k0qnq",
          "author": "HIVVIH",
          "text": "I'm so freaking proud of the French and us Europeans right now. Let's freaking go!!",
          "score": 9,
          "created_utc": "2026-02-04 16:37:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3idjl0",
          "author": "Everlier",
          "text": "Absolutely incredible, so that's where the team was at. Can't wait for more updates on the research!",
          "score": 8,
          "created_utc": "2026-02-04 10:59:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iiqk4",
          "author": "No-Equivalent-2440",
          "text": "I love them ðŸ˜…",
          "score": 6,
          "created_utc": "2026-02-04 11:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kgpa9",
          "author": "No_Vehicle7826",
          "text": "We got robotics before TTS on LeChat ðŸ˜­",
          "score": 4,
          "created_utc": "2026-02-04 17:50:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ikaef",
          "author": "CactusJackpot",
          "text": "Very cool!!! Letâ€™s go",
          "score": 3,
          "created_utc": "2026-02-04 11:54:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iomn4",
          "author": "JuiceOwn313",
          "text": "Shame, I was expecting it to throw the backpack when done. And add sun glasses to the cat.\n\nJoke aside, very nice and well executed.",
          "score": 2,
          "created_utc": "2026-02-04 12:26:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3k186a",
          "author": "HandsomeHippocampus",
          "text": "Who's a good kitty? <3",
          "score": 2,
          "created_utc": "2026-02-04 16:39:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3losnc",
          "author": "Btbbass",
          "text": "What is the package ? What about full remote ?",
          "score": 1,
          "created_utc": "2026-02-04 21:15:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxzza",
          "author": "Fearless_Macaron_203",
          "text": "Awesome. I really want this company to do well :)",
          "score": 1,
          "created_utc": "2026-02-05 17:14:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvrd99",
      "title": "Voxtral transcribes at the speed of sound",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvrd99/voxtral_transcribes_at_the_speed_of_sound/",
      "author": "pandora_s_reddit",
      "created_utc": "2026-02-04 15:21:52",
      "score": 157,
      "num_comments": 16,
      "upvote_ratio": 0.99,
      "text": "Today, we are excited to release **Voxtral Mini Transcribe 2** and **Voxtral Mini 4B Realtime**. Transcribe 2 builds on our previous generation with **higher performance** and new features: **Diarization**, **Word Segmentation with Timestamps**, and **Context Biasing**. We are also excited to release **Voxtral Mini 4B Realtime** under an Apache 2.0 license - a **streaming** transcription model with high accuracy and configurable chunk delays, allowing you to balance quality and latency according to your needs.\n\n[Voxtral Transcribe and Voxtral Realtime Performance](https://preview.redd.it/m01oww6srhhg1.png?width=2621&format=png&auto=webp&s=63f38e467245a307e7da0a1e309c27112149610e)\n\n* **Voxtral Mini Transcribe 2**: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.\n* **Voxtral Mini 4B Realtime**: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.\n* **Best-in-class efficiency**: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.\n* **Open Weights**: Voxtral Mini 4B Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.\n   * HF Weights: [mistralai/Voxtral-Mini-4B-Realtime-2602](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602)\n\n*You can test Voxtral Mini Transcribe 2 directly in* [*Mistral Studio*](https://console.mistral.ai/build/audio/speech-to-text)*. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.*\n\nLearn more about Voxtral in our blog post [here](https://mistral.ai/news/voxtral-transcribe-2)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvrd99/voxtral_transcribes_at_the_speed_of_sound/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3jqphc",
          "author": "Living_Procedure_599",
          "text": "Just tested it. Actually works like magic. Surprised how accurate it is.",
          "score": 16,
          "created_utc": "2026-02-04 15:51:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kgi23",
          "author": "Comacdo",
          "text": "So is this finally a better thing than whisper ?? So cool !",
          "score": 10,
          "created_utc": "2026-02-04 17:49:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lpzlw",
              "author": "Basic-Love8947",
              "text": "Is it really? Would be great to switch",
              "score": 1,
              "created_utc": "2026-02-04 21:21:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3osu1b",
              "author": "LearningPodd",
              "text": "That's fantastic! And happy cake day! ðŸ°",
              "score": 1,
              "created_utc": "2026-02-05 09:15:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3k6ys9",
          "author": "Downtown-Elevator369",
          "text": "I have been trying so many different workflows to transcribe meetings and classes. My fingers are crossed that this is the one I can settle on!",
          "score": 6,
          "created_utc": "2026-02-04 17:05:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lz9h0",
          "author": "lovebzz",
          "text": "It's pretty impressive. I've been struggling to find a tool to transcribe some interviews I did for a documentary project that were mixed-language (English + Vietnamese). Voxtral did them in seconds and they look pretty accurate.",
          "score": 2,
          "created_utc": "2026-02-04 22:05:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3m47ll",
              "author": "--Tintin",
              "text": "Have you used it via mistral website or via a tool on Mac/windows? Iâ€™m asking as I havenâ€™t find an app which includes voxtral. Would be great for speaking recognition /embedding.",
              "score": 2,
              "created_utc": "2026-02-04 22:30:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3m4hxt",
                  "author": "lovebzz",
                  "text": "No, I just uploaded audio files to Mistral AI Studio.",
                  "score": 1,
                  "created_utc": "2026-02-04 22:31:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3kprqm",
          "author": "LoadZealousideal7778",
          "text": "Well, they are apparently not using it in the Le Chat app because the voice option there is just... Broken.",
          "score": 2,
          "created_utc": "2026-02-04 18:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pksxk",
          "author": "Bright-Celery-4058",
          "text": "well done mistral team !  \ni am interested in the context biasing + word level timestamp but the API doc is missing those advertised new features. Also the max audio length needs to be updated (15min was for the V1, V2 claims 3h)Â [https://docs.mistral.ai/capabilities/audio\\_transcription#transcription](https://docs.mistral.ai/capabilities/audio_transcription#transcription)",
          "score": 1,
          "created_utc": "2026-02-05 13:05:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pwnvt",
              "author": "pandora_s_reddit",
              "text": "Sorry for the experience, doc will be updated shortly - but word level timestamp you can simply set `timestamp_granularities=[\"word\"]` and work out of the box",
              "score": 1,
              "created_utc": "2026-02-05 14:13:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3q0nxs",
                  "author": "Bright-Celery-4058",
                  "text": "thanks !",
                  "score": 1,
                  "created_utc": "2026-02-05 14:35:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qkdg0",
                  "author": "Bright-Celery-4058",
                  "text": "i just tried it in mistral ai studio, segment level works but not the word level ;)",
                  "score": 1,
                  "created_utc": "2026-02-05 16:11:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3qfnhw",
          "author": "Vroedoeboy",
          "text": "I get no model response in both Mistral Console and through API.",
          "score": 1,
          "created_utc": "2026-02-05 15:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qrrx8",
          "author": "nhatnv",
          "text": "Segment timestamp is not accurate. I tried an audio of 2 minutes but some segment timestamps are 2:20...",
          "score": 1,
          "created_utc": "2026-02-05 16:45:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kko34",
          "author": "Visible_Forever_7636",
          "text": "Many of the models fail to catch the entities of Indian languages. Does it work good on them ?",
          "score": 1,
          "created_utc": "2026-02-04 18:08:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qrw16s",
      "title": "Mistral Vibe 2.0 vs Codex 5.2 & Claude (Opus 4.5) - First Impressions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "author": "l_eo_",
      "created_utc": "2026-01-31 07:34:06",
      "score": 156,
      "num_comments": 38,
      "upvote_ratio": 0.96,
      "text": "Spending most of my time on Claudeâ€™s Max 20x plan (Opus 4.5) and occasionally hitting my weekly limits, I decided to revisit **Mistral Vibe 2.0** and **Le Chat** after a long break. Here are my first impressions, especially compared to Opus 4.5 and Codex CLI.\n\n---\n\n### **1. Codex CLI (5.2), Underwhelming First Impressions**\n\nI tested Codex in a structured folder with lots of context (files, scripts, and dedicated system for specific workflows that are to be followed). On first prompts and even after instructing it to analyze the **folder context**, it struggled to understand or comply and generate based on an understanding of the surrounding context. It felt less like a true CLI tool and more like a system just inlining requests without grasping the environment. Big asterix: It's also my first time trying codex and I need to explore it more, but the first results were disappointing.\n\n---\n\n### **2. Mistral Vibe 2.0**\n\nReally great first impression, I was very pleasantly surprised!\n\nIt really stood out was how thoroughly Mistral Vibe 2.0 tried to understand the context first (even without being told to do so). It didnâ€™t just jump into answering; it checked the surrounding files, analyzed available examples, and tried to understand what a good outcome would look like before starting to work.\n\nAnd I was blown away by how **fast** Mistral Vibe 2.0 is. The response generation is so quick that I canâ€™t even read along as it outputs. This is a game-changer for feedback loops. While I of course believe that Claude Opus 4.5 is currently the king for coding and complex tasks, Iâ€™ll be testing Mistral Vibe 2.0 much more for coding and general tasks to see how it performs. For everyday structured tasks, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system**.\n\n---\n\n### **3. Le Chat App**\nThe Le Chat app has improved significantly since I last tried it:\n* Voice input is now a thing, and itâ€™s seamless! (Claude struggles a lot with this) When I last used Le Chat, this feature didnâ€™t even exist. I tested it with a long, multi-minute transcription, and the accuracy was impressive. I did a few feedback rounds, and Mistral applied my edits smoothly. Iâ€™m not sure how they made it *that* fastâ€”**the turnaround times for voice transcription and immediate answers are incredibly impressive**.\n* Online research seemed also to work great  and possibly now on par with ChatGPT?\nIâ€™m not even sure yet what other awesome features and UX additions there are, but Iâ€™m excited to explore further.\n\n---\n\n### **4. Potential Switch?**\nGiven Mistralâ€™s speed, UX, and awesome voice transcription, etc, Iâ€™m seriously considering making Le Chat + Mistral Vibe 2.0 my daily driver for everyday tasks and as a fallback when Claudeâ€™s limits kick in (and Le Chat possibly always preferred because of the speed and the great voice transcription in multiple languages). Iâ€™ll test-drive it for a few days, and if it proves as powerful as I hope (writing this as a \"wow, just tried this\" post, so maybe lots of honey moon phase involved), I might cancel my ChatGPT subscription and make Le Chat my main driver for everyday use.\n\nIâ€™m all for EU digital sovereignty, so supporting Mistral feels like a win-win and I am incredibly happy & excited about all the progress being made.\n\n---\n\n**TL;DR:**\n\n* **First rough impressions**: Just excited to share my initial enthusiasm for Mistral Vibe 2.0 and Le Chat after revisiting them.\n* **Codex CLI** felt underwhelming as a CLI tool, especially with folder context. Not sure about code quality and similar yet (also very first impression).\n* **Mistral Vibe 2.0** impressed with speed and context handling; Iâ€™ll test it more for coding.\n* **Le Chat app** now includes voice input and shines with great transcription quality, incredible speed (game changer for back and forth loops), and online research\n* While **Opus 4.5 likely remains unmatched for coding**, Mistralâ€™s first impression suggests it could be a **fantastic alternative and fallback system** for everyday tasks.\n\n\nBig thank you to the Mistral team for all the hard work! Rooting for you big time â™¥ï¸ðŸ‡ªðŸ‡º!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qrw16s/mistral_vibe_20_vs_codex_52_claude_opus_45_first/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2teisq",
          "author": "Mr_Finious",
          "text": "As a US citizen, I'm considering Mistral because I trust the EU's privacy protections to better protect me than those of US or Chinese companies. \n\n\n\nWe should all be clapping for companies like Mistral in the EU.",
          "score": 7,
          "created_utc": "2026-01-31 16:56:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2r8s37",
          "author": "l_eo_",
          "text": "Collecting new findings here as I continue testing: \n\n* I am not super happy with it being pretty hard to copy from the CLI progress. Often I need to \"reply\" to something the agents do and the UX loops around that are crucial. It's pretty bad at the moment, the UI needs a long time to react and seems to include some automatic \"copied!\" feature, that appears very late multiple times and that I don't really care about. Easy direct select -> right click -> copy would be best and should be fast and fluid. That's a \"small\" thing that makes a **huge** difference. \n* Scrolling can also be pretty sluggish (very very late start and keys like 'end' also have many seconds of delay). Possibly tracked here: https://github.com/mistralai/mistral-vibe/issues/222\n* There must be a specific system in place for interruptions? The agent reacted much faster than Claude Code Opus to a \"no\" during generation. Basically almost immediate stop\n* CLI text input seems a bit sluggish when much is happening\n* Context usage seems to go up fairly slowly. Not sure if that's a good or bad thing (testing it for some coding right now).\n* Every response / input during generation seems to be treated as an interruption (so no \"next task queuing\" like with Claude Code). Maybe there is a way to queue?",
          "score": 7,
          "created_utc": "2026-01-31 07:59:41",
          "is_submitter": true,
          "replies": [
            {
              "id": "o2rboh5",
              "author": "l_eo_",
              "text": "I really need to stress that so many gains are to be made \"easily\" by improving the UX of the base-line elements that make up the workflow with the CLI tool. \n\nCopy & paste / reacting / replying, how fast typing is, and how responsive scrolling is are just a few facets of this.\n\nUX improvements make a huge difference if the basic quality of the model output is good enough.\n\nI will look into contributing: https://github.com/mistralai/mistral-vibe/blob/main/CONTRIBUTING.md",
              "score": 12,
              "created_utc": "2026-01-31 08:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2r7wv2",
          "author": "ZapojKabel",
          "text": "I am interested at the coding using now heavily modified Gemini CLI and quite happy with, but rather use European tool. Does mistral have api key pay as you go and picture generate?",
          "score": 5,
          "created_utc": "2026-01-31 07:51:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9lfq",
              "author": "l_eo_",
              "text": "Interesting, in what way did you modify the Gemini CLI? \n\nI must say, that I was always very unhappy with Gemini output regarding code and it often seeming to \"fight\" me / gaslight me or somehow trying to avoid following instructions. Especially in the last weeks instruction following was pretty much non-existent for the few tests I did and I have been avoiding it ever since. \nBut I also mostly used the web interface so far, so maybe it's a different story with the CLI. \n\nI would have very much recommended Claude Code with Opus 4.5 and used to be *insane* around release / December, but has deteriorated massively in terms of quality the last few weeks. Possibly due to a switch from Google GPUs to the ones they developed with AWS, but not sure.  \nStill, it is very much worth a try if you go for the 5x or 20x max plans (they are very worth it). API pricing would be incredibly expensive (easy to burn through 20-80 bucks an hour). \n\nRegarding your questions: \nYes, API key pay as you go exists and I think the subscription now also included some vague notion of \"full day coding\"? \n\nPicture generate would likely mean an additional model, but that should be easy to integrate into your workflow (e.g. continue using Gemini's very powerful nano-banana-pro or flux).\n\nGreat to hear that you care about European tools!",
              "score": 4,
              "created_utc": "2026-01-31 08:07:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rngmy",
                  "author": "ZapojKabel",
                  "text": "Well I have my boss I call him Nexus he delegate my task to other agents ( I use mostly three for design, code and advertising expert). Every plan I make all 3 discuss how to do and should work, when it is done the 4 agent step in it is called Sentil \"devil advocate\" a trying to find error in there reasoning and aks question \"if...\". When there settle and I agree, Nexus make track list in conductor with plan how to setup. Also use RAG. I am not coder but make app for my e-shop. https://harmony.nonchalant.cz and also now making app for manager stuff on my eshop and dashboard for better statistic on sale etc.\nEdit: also Avery agent must use TOT protocol",
                  "score": 4,
                  "created_utc": "2026-01-31 10:19:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2ul5uq",
              "author": "vienna_city_skater",
              "text": "If you have Le Chat Pro you get Devstral included.",
              "score": 1,
              "created_utc": "2026-01-31 20:20:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2recbg",
          "author": "EzioO14",
          "text": "I use le chat pro for all normal chat questions and I have claude max for coding",
          "score": 5,
          "created_utc": "2026-01-31 08:51:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2reopc",
              "author": "l_eo_",
              "text": "That's my plan as well :)\nI love the snappyness of Le Chat. \n\nIs Le Chat strict enough with sources? So doesn't hallucinate if no information found via web search?",
              "score": 2,
              "created_utc": "2026-01-31 08:55:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rer8d",
                  "author": "EzioO14",
                  "text": "I find it gets better, I was very disappointed at first, last month when I started but now I find the answers better and better",
                  "score": 2,
                  "created_utc": "2026-01-31 08:55:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r8a66",
          "author": "Bato_Shi",
          "text": "Only thing i noticed with Vibe is that sometimes it falls into infinite loops, like gemini 3 some months ago",
          "score": 3,
          "created_utc": "2026-01-31 07:55:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2r9n86",
              "author": "l_eo_",
              "text": "Should be easy to break it out of though, right? \nHow often does it happen?",
              "score": 1,
              "created_utc": "2026-01-31 08:07:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2syc21",
                  "author": "kiwibonga",
                  "text": "An example I had yesterday (Devstral Small 2 Q4) is it found that a regular expression wasn't capturing strings properly in a test, so it tried to fix the pattern, but it turned out to be a basic escaping issue rather than an error in the regex. It didn't realize that, so it added more and more characters to the pattern until it was huge -- without ever thinking \"is this overkill? That looks weirdly huge\" even though the purpose of the code was just to make sure a line starts with the word \"AGENT:\".\n\nThis is something that could have been autonomously fixed with an orchestrator that includes failure analysis, sees the blind spot, and proposes an alternate approach before launching another attempt. A reasoning model might also have a much easier time course-correcting.\n\nI was using the CLI by itself so I just said \"try to simplify the regular expression by writing it from scratch, and if it still fails, just write a parser\" -- it failed fast and wrote a parser, then got back to work.",
                  "score": 1,
                  "created_utc": "2026-01-31 15:39:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o2rpkx3",
              "author": "Gen5nake",
              "text": "I also had this issue once",
              "score": 1,
              "created_utc": "2026-01-31 10:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2ra7pr",
          "author": "theschiffer",
          "text": "Very interesting review. What does your day-to-day workload look like and in what ways do you generally use AI?",
          "score": 2,
          "created_utc": "2026-01-31 08:13:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rarwz",
              "author": "l_eo_",
              "text": "Workload in terms of volume of usage? \n6-14 hours of multiple terminal tabs with claude processes. \nAI is used as a partner both for planning as well as for execution. Often planning and getting everything prepared for implementation takes up most of the time (e.g. 4 hours planning and adapting and architecture work, 2 hours implementing and adapting / fixing), but it depends a bit on what phase a project is in. \n\nDoes this answer your question fully?",
              "score": 3,
              "created_utc": "2026-01-31 08:18:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2tmt2r",
                  "author": "theschiffer",
                  "text": "Nice. So essentially, youâ€™re a software developer/architect? Thatâ€™s quite an intensive level of use.",
                  "score": 1,
                  "created_utc": "2026-01-31 17:36:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rae0d",
          "author": "Hot_Bake_4921",
          "text": "Does Le chat still use mistral medium 3.1?",
          "score": 2,
          "created_utc": "2026-01-31 08:14:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcns6",
              "author": "l_eo_",
              "text": "I am trying to find some information about this, but this proves to be surprisingly hard? Nothing in the change logs and most Reddit discussions about this seem to be from quite long ago.",
              "score": 2,
              "created_utc": "2026-01-31 08:36:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2tqeke",
          "author": "Sorry_Role_1701",
          "text": "What Iâ€™m noticing with newer models like Mistral isnâ€™t about benchmarks anymore.\n\nThe real difference is **i**nteration speed, how fast you can refine an idea without restarting context every time.\n\nIn workflow-heavy tasks, that matters more than raw output quality.",
          "score": 2,
          "created_utc": "2026-01-31 17:54:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2wlr2d",
              "author": "mWo12",
              "text": "Off course they are not about benchmarks, as they have nothing to show.",
              "score": 2,
              "created_utc": "2026-02-01 02:55:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34c59l",
                  "author": "Sorry_Role_1701",
                  "text": "I totally agree with your observation.  \nIteration speed and seamless context flow are becoming *way more important* for practical workflows than just raw output quality or benchmark scores  especially when youâ€™re refining ideas or building on previous results without restarting everything.\n\nIn my experience with Vibe (and similar tools, ChatGPT), when the model keeps context and lets you iterate fast, it *feels* more productive even if raw numbers arenâ€™t leading â€” because in real usage you spend less time repeating setup and more time building on progress.",
                  "score": 1,
                  "created_utc": "2026-02-02 07:44:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2r7fxx",
          "author": "l_eo_",
          "text": "As I wrote, I am completely newly back again with Mistral vibe. \nAny optimizations / settings I should immediately go for?",
          "score": 1,
          "created_utc": "2026-01-31 07:47:20",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o2r85ap",
          "author": "stjepano85",
          "text": "It is very good for agentic development. It has some problems with recursive algorithms and it can go crazy when his context is large (this can be solved by limiting context in vibe configuration).",
          "score": 1,
          "created_utc": "2026-01-31 07:53:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rayhx",
              "author": "l_eo_",
              "text": "Interesting! \nWhat level do you recommend limiting context to?",
              "score": 1,
              "created_utc": "2026-01-31 08:19:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rcdgm",
                  "author": "stjepano85",
                  "text": "128k should be good. I noticed at 70+% of the default 200k its performance drops significantly.",
                  "score": 2,
                  "created_utc": "2026-01-31 08:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2rcps1",
          "author": "nycigo",
          "text": "For voice input, press Windows + H; this will automatically transcribe your microphone input if you are using Windows 11.",
          "score": 1,
          "created_utc": "2026-01-31 08:36:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rcu1q",
              "author": "l_eo_",
              "text": ":O \n\nIn the CLI for mistral vibe?",
              "score": 2,
              "created_utc": "2026-01-31 08:37:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2rhxqy",
                  "author": "nycigo",
                  "text": "Anywhere on Windows, anywhere your mouse is located",
                  "score": 1,
                  "created_utc": "2026-01-31 09:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2wll72",
          "author": "mWo12",
          "text": "I tested Mistral Vibe 2.0, but I found it so slow, and I'm not talking about token generation. Just the CLI interface is so slow and sluggish. Maybe because it is all python, unlike other agents.",
          "score": 1,
          "created_utc": "2026-02-01 02:54:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xo0zs",
              "author": "l_eo_",
              "text": "100% and this is my biggest issue with it right now and a real blocker. \nYou can see the kind of potential it has when starting a new session, but it gets bogged down fast. \nFor me personally these would a \"don't release before fixed\".  \n\nBut I am also very optimistic that this will be improved soon, because relatively speaking, these rendering issues should be quite straightforward to fix, so I really hope Mistral will make them a priority.",
              "score": 1,
              "created_utc": "2026-02-01 07:36:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31bvsf",
          "author": "BastFX",
          "text": "Hey ! Thanks for this detailed review ðŸ‘Œ\nI never used vibe-code tools like this one, but i'm following news about all that world.\nThe most famous tool Claude Code on this category needs Claude.md file, I would like to know if Mistral need something similar to work properly ? What structure build in this file ? I checked the official documentation but any information about that, or I missed it ...",
          "score": 1,
          "created_utc": "2026-02-01 20:48:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37go5l",
          "author": "Sweaty-Special-1710",
          "text": "I really like Vibe. I feel it's almost as good as claude, way cheaper, I'm not concerned with usage limits, it works by being very directive, and it feels really fast.",
          "score": 1,
          "created_utc": "2026-02-02 19:13:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qws3tx",
      "title": "The mistral team does not get enough credit for their easter eggs",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/4v71jp3grphg1.jpeg",
      "author": "InsideMikesWorld",
      "created_utc": "2026-02-05 17:47:51",
      "score": 109,
      "num_comments": 6,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qws3tx/the_mistral_team_does_not_get_enough_credit_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3r6a3v",
          "author": "Tanuki__",
          "text": "I like also \"Eating a pain a chocolat...\" ðŸ˜‚",
          "score": 10,
          "created_utc": "2026-02-05 17:52:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3svbkh",
              "author": "ouesh35",
              "text": "Worst, i saw \"Eating a chocolatine...\"",
              "score": 1,
              "created_utc": "2026-02-05 22:42:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3rqfrv",
          "author": "sndrtj",
          "text": "Petting le chat....",
          "score": 3,
          "created_utc": "2026-02-05 19:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r5kye",
          "author": "Sudden-Armadillo-335",
          "text": "Where did you find that? ðŸ˜‚",
          "score": 2,
          "created_utc": "2026-02-05 17:49:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r7n9r",
              "author": "InsideMikesWorld",
              "text": "Itâ€™s one of the possible texts that comes up in vibe CLI when the model is processing",
              "score": 6,
              "created_utc": "2026-02-05 17:58:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3r7uih",
                  "author": "Sudden-Armadillo-335",
                  "text": "No, that's stylish ðŸ˜‚",
                  "score": 1,
                  "created_utc": "2026-02-05 17:59:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qqzac4",
      "title": "Switching to Mistral?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqzac4/switching_to_mistral/",
      "author": "Absjalon",
      "created_utc": "2026-01-30 07:52:59",
      "score": 94,
      "num_comments": 30,
      "upvote_ratio": 0.98,
      "text": "Hi Mistral users,\n\nI am strongly considering switching my OpenAI subscription to Mistral.  I'm  happy with OpenAIs products,  but for political and GDPR reasons I'm ready to switch. Even if it means less optimal product. \n\nI've tried the free Mistral version for a while now and I am pretty happy about it, but it's not quite at the level of the paid OpenAI models. \n\nCan someone share their experience with the difference between the paid Mistral and OpenAI and how to optimize/personalize Mistrals output?\n\nI work both with API interactions and the chat interface \n\nThank you",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqzac4/switching_to_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2kgooi",
          "author": "thedisturbedflask",
          "text": "The Mistral models are quite capable but ive found you'll have to really work on the instructions and prompt to get the output your looking for.\n\n\nMy process was in defining a starting prompt and then tweaking it with a control question until it reached a point i was happy with. The answers arent deterministic because of how llms work but it helps to see the general kind of response.\n\n\nI saved these as agents in chat which works quite well.\n\n\nFrom the dev perspective i haven't quite been able to have it refer to an instruction file consistently but might just be missing something.",
          "score": 17,
          "created_utc": "2026-01-30 08:12:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2kiyuj",
              "author": "Absjalon",
              "text": "Thank you.   \n  \nSo in Mistral chat, you build an agent and then call it in different chats? e.g. an agent that helps to formulate emails, but stays close to your draft and your wording?\n\nAs opposed to making a project and then giving special instructions for project?",
              "score": 4,
              "created_utc": "2026-01-30 08:33:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2kjjpe",
                  "author": "TheMrLexis",
                  "text": "In Le Chat if I remember well, you can call an agent in the same chat by writting \"@\\[Agent Name\\]\"",
                  "score": 4,
                  "created_utc": "2026-01-30 08:38:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o2kkv4s",
                  "author": "thedisturbedflask",
                  "text": "That's correct for the agents, i refine it to 'think' the way id like for general interactions or make it more specifically useful like the email example.\n\n\nI think you definitely can define the instructions for an agent to include project ownership, requirements, milestones, etc and skill sets so that youd be able to ask it to complete the project goals etc\n\n\nIn my case for a dev project using zed.dev editor I do that and spend a lot of time back and forth with the model defining the scope and detail then have it output a specific plan.md file with a checklist.\n\n\nI include it as context and ask it to implement the plan, then inevitably fix what it doesnt quite get right, makes it easier to predict and test the output",
                  "score": 2,
                  "created_utc": "2026-01-30 08:50:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2l8jh3",
          "author": "Vontaxis",
          "text": "I have a mistral subscription just to support them but to be honest it is nowhere as good as Claude or ChatGPT.\n\nNaturally, it depends on what you're using it for but even for simpler things I noticed that prompt adherence is at times rather bad.",
          "score": 7,
          "created_utc": "2026-01-30 12:11:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pn7eo",
          "author": "LoadZealousideal7778",
          "text": "I like it but probably for a weird reason. For me, their models sit at the junction between capable and a useful but fundamentally stupid multi tool. Smart enough to do work, not smart enogh to cognitively offload to.\n\nYou can't just barf in a typo riddled, half formed thought and get what you wanted most of the time like with Claude Opus. Bit more manual.",
          "score": 6,
          "created_utc": "2026-01-31 01:13:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rhkj9",
              "author": "Absjalon",
              "text": "I understand this and have a similar experience",
              "score": 1,
              "created_utc": "2026-01-31 09:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2kqv4z",
          "author": "NullSmoke",
          "text": "Yeah... new 4o scare going on over there (including 4.1 this time if I understand it correctly?)...\n\nJumped over when the whole mess became unbearable, and is very happy with it. As for the diff between paid and free, it's rate limits basically. You can test it out in free and have a decent handle on what you can expect in pro.\n\nI see that agents are being discussed down here, basically CustomGPTs if talking OpenAIspeech. You can find several guides over at r/Nefhis_Lumen_Lab that can help you get started :-)",
          "score": 5,
          "created_utc": "2026-01-30 09:45:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2mmwih",
          "author": "LewdManoSaurus",
          "text": "I tried a subscription last October and while it was okay, I had to do a lot of correcting, and the amount of hallucination was seriously a deal breaker. If you just use it sparingly it'll probably be fine, but in my experience It's nowhere close to some of the bigger models. The agent customization is an amazing feature, but the other issues are so frequent that these days I just stick to free tiers of other services. I only used Mistral for generative writing.",
          "score": 4,
          "created_utc": "2026-01-30 16:31:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lko4e",
          "author": "mythrowaway4DPP",
          "text": "Mistral *is* not on the same level as the top models ChatGPT, Gemini or Claude.  \nBeing an European engine, GDPR, and less puritan censorship is nice.\n\nCapabilities wise, think ChatGPT 4.1, maybe better.\n\nPrompting needs to be more precise, but it is doable.\n\nThe libraries are a nice idea, collections of documents to attach to any chat.\n\nOverall, I am not missing a lot using mistral, and openAI isn't getting my money anymore.",
          "score": 8,
          "created_utc": "2026-01-30 13:27:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mlk85",
              "author": "alexgduarte",
              "text": "That's because you've never used GPT-5.2-Pro.",
              "score": -2,
              "created_utc": "2026-01-30 16:25:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2mm1rw",
                  "author": "mythrowaway4DPP",
                  "text": "Of course I did. I also said that mistral is not there.",
                  "score": 5,
                  "created_utc": "2026-01-30 16:27:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2o897h",
          "author": "Komgoroth",
          "text": "I used it in the past. Then I switched to ChatGPT for a while. When my Chat GPT subscription was about to expire I subscribed again to Mistral.\n\nI then had some health issues and when I got my report from the doctor, I used it on Mistral to make a summary of what is happening( it was all perfect other than some benign findings) and it made up certain findings which indicated severe issues.\n\nI panicked as the doctor did not mentioned them. I also did not see them. Then asked the AI to tell me where did it find the issue and it apologized.\n\nTried it again and it did the same horrible mistake. Chat gpt did not.\n\nExample two. I asked both Mistral and ChatGPT to make me the shortest roadtrip using highway only from point a to point b and to tell me what vignettes I need to buy and what's the expected time and how often and where I should take breaks.\n\n\nChat gpt did it perfectly and I confirmed myself on maps etc.\nMistral missed several countries when it comes to vignettes, miscalculated the time by more than 30% and suggested that no breaks are needed for the drive( on a 14 hour long drive).\n\nI unsubscribed and continued with Gemini.\n\n\nI love that it is an European company and I'll support them when they get better but I cannot use it as is.",
          "score": 3,
          "created_utc": "2026-01-30 20:49:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2omirx",
          "author": "theAbominablySlowMan",
          "text": "Even before all this US shite started I was scolding everyone I heard using other AI, the data privacy approach of US Vs EU countries is just not compatible, and the level of detail of your personality you give these things is just scary in the wrong hands.Â \n\n\nHonestly I suggest just ditching and making the switch for 3 months and figuring it out yourself, like all software we get tied to what we know. Without knowing what areas you rely on it for I can't be specific but it's not a black and white openai being better, I prefer mistrals response on a lot of more science based topics for exampleÂ ",
          "score": 3,
          "created_utc": "2026-01-30 21:57:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2rhgzf",
              "author": "Absjalon",
              "text": "Yes.  I've noticed Mistral gives really good answers on Statistical issues (explaining concepts). In this area, I think it is on par with chatGPT 5.2",
              "score": 1,
              "created_utc": "2026-01-31 09:21:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rac2w",
          "author": "Born-Yoghurt-401",
          "text": "Iâ€˜ve been using LeChat free over the last year to track progress and get medicinal advice about a close relatvies glioblastoma stage 4 brain tumor. I shared overall progress including CT and MRI scans, mental health patterns and in the final weeks palliative and necrotic wound care details. LeChat was very helpful in collecting and aggregating health data and putting many of my questions into context. I had no issues with hallucinations or factual errors and felt in good hands. I also would never have shared any of those details with a US based AI solution.",
          "score": 3,
          "created_utc": "2026-01-31 08:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kp7dc",
          "author": "sam-watterson",
          "text": "I started switching it, using vibe for day-to-day usage.",
          "score": 2,
          "created_utc": "2026-01-30 09:29:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2rryl0",
          "author": "WitnessEarly7584",
          "text": "I got a Pro subscription for Mistral for free and tried to input some of my ChatGPT/Gemini prompts, which I use for work. What can I say? It is totally unusable. One prompt even caused a recursive loop. How are you guys using it?",
          "score": 2,
          "created_utc": "2026-01-31 11:01:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35xvp1",
              "author": "Objective-Sky7312",
              "text": "Promoting is different/must be customized to every system and even model, you would find the same in Claude etc. I only get recursive loops when the temperature is too low. Maybe try Agents, I think they are key for Mistral to customize how it behaves.",
              "score": 1,
              "created_utc": "2026-02-02 15:00:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2rzm87",
          "author": "crazyserb89",
          "text": "I'm also on OpenAI searching for an alternative and checking the Mistral. Gave it a shot several times, but it seems it's not there yet to compete with the big ones. It feels unpolished, lacking some fundamental features, and overall seems like a Beta product. I hope they gonna improve it in future and therefore position themselves better on the market though.",
          "score": 2,
          "created_utc": "2026-01-31 12:08:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l3kqp",
          "author": "MikadinShinjuk",
          "text": "I switched to kagi, is not European but is way better than all the other main services and is very flexible in terms of choosing the model",
          "score": 1,
          "created_utc": "2026-01-30 11:34:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ss499",
          "author": "fonceka",
          "text": "Mistral strategy is to develop vertical models, so they have a bunch of specific models: codestral (coding), devstral (open-source model for coding agents), voxtral (speech2text), mistral small (enterprise ready), mistral medium, mistral large, ministral, magistral (multilingual)â€¦ I have been on the Pro version for one year on, but I have also a paid subscription to Gemini. I have already dropped the OpenAI subscription, and consider dropping the Anthropic one also. I do not use the API anymore since my focus have shifted. Overall I find Mistral very useful, when context is adequate. You must really work on curating your context window neatly.",
          "score": 1,
          "created_utc": "2026-01-31 15:07:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2ue2ml",
          "author": "Green-LaManche",
          "text": "I used le chat - in very specific area which difficult to find someone knowledgeable: I am pretty happy with the answer either when asked specifically about dealing breakdowns in highly sophisticated areas or details of very specific historical figures.\nI would say I am much happier then with copilot",
          "score": 1,
          "created_utc": "2026-01-31 19:45:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kmx5k",
          "author": "Cleaner76",
          "text": "Apart from not being on the top level with their models, their support is far below acceptable. So if you have a problem, prepare to feel stranded...",
          "score": 1,
          "created_utc": "2026-02-04 18:18:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2lix37",
          "author": "officialexaking",
          "text": "You said for 'political reasons'. What do you mean by that? If it is because you want your data to be stay in the EU and not handled by non-US tech companies then you are wrong with Mistral. All your requests (chats) are routed through Microsoft/Google and Cerebras unless you haven't concluded a personal enterprise contract with them.",
          "score": 0,
          "created_utc": "2026-01-30 13:17:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mjxpx",
              "author": "Absjalon",
              "text": "Very important information you bring to the table here.  My concern is  data wise, but also I want my money to support Europe.\n\nI will see if I can find more information about this",
              "score": 6,
              "created_utc": "2026-01-30 16:17:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2mbua7",
              "author": "theKurganDK",
              "text": "Could you elaborate please? Routed?",
              "score": 2,
              "created_utc": "2026-01-30 15:41:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2rkore",
                  "author": "officialexaking",
                  "text": "Here is everything you need to know about it:\nhttps://www.xprivo.com/blog/en/mistral-is-not-a-european-alternative/",
                  "score": 1,
                  "created_utc": "2026-01-31 09:52:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qteixn",
      "title": "I love Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "author": "Potential_Block4598",
      "created_utc": "2026-02-01 23:31:42",
      "score": 83,
      "num_comments": 16,
      "upvote_ratio": 0.98,
      "text": "This is my second post in a long time praising mistral \n\nSo earlier I praised how they train objective models that services Le Mistral \n\nNow I am doing this again, but as I am running and switching between many models for local agentic tasks (using an agent scaffold and and MCP to perform basic static malware analysis tasks for cybersecurity that is essentially copy pasting to and from an LLM model in an automated way!) \n\nI tried many things \n\nFirst â€œfrontierâ€ (local frontier for my setup) according to artificial analysis aggregated benchmarks (that should include tool call, and not just demonstrative tool call but actual consistent real-life tool call!) (note I always wondered why Devstral ranked too low on that benchmark (either the model is too weak or the benchmark is too weak!!!!)\n\nSo I tried \n\nGPT-OSS (both on all kinds of Thinking effort options)\n\nWeird failures (sometimes call format not correct especially when used with cline and/or Goose!) \n\nAnd no instruction following (not even loose instruction following, or proper task management , so they donâ€™t live well inside the scaffold environment (some code todo management complex prompt and things like that!) \n\nGLM-4.7-Flash\n\nSimilar story \n\nThen Cline docs and Jack Dorsey mentioned Qwen3 Coder, I scratch my head why is that small seemingly insignificant model recognized by them no idea\n\nI try it and lo and behold it works very well than others\n\nSo it is not an agent problem or me dosing misconfiguration, these other open models arenâ€™t desgined for that (and for good reasons form the companies perspective)\n\nI am thinking of trying\n\nMinimax M2.1 or GLM-4.5-Air \n\nBut then I think about using Devstral Small 2\n\nAnd it works better than a charm finishes the task methodologically and analyzes the whole sample in like 3-5 hours \n\nA task that would have taken a junior around a month maybe (still a junior can do other stuff but maybe it dis. Better of MCP becoming exposed by default \n\nAnyways thanks Mistral Team for your awesome model and contributions to the open \n\nTL;DR\n\nDevstral Small 2 is the best for Local LLM agentic tasks (beyond being compared to others!)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qteixn/i_love_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o32cdeb",
          "author": "iongion",
          "text": "Is there a possibility to run it/configure it in claude code like it is possible with zai GLM ?",
          "score": 2,
          "created_utc": "2026-02-01 23:54:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33lf5o",
              "author": "lundrog",
              "text": "Should be easy. Can also use a api gateway like https://github.com/looplj/axonhub",
              "score": 3,
              "created_utc": "2026-02-02 04:13:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o35ctlk",
                  "author": "iongion",
                  "text": "Thanks man, these things appear out of nowhere",
                  "score": 1,
                  "created_utc": "2026-02-02 13:03:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o32i448",
              "author": "Potential_Block4598",
              "text": "Havenâ€™t tried that yet",
              "score": 2,
              "created_utc": "2026-02-02 00:26:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3726pq",
              "author": "erizon",
              "text": "It is far easier, just set few environment variables:\n\n    ANTHROPIC_BASE_URL=\"https://api.z.ai/api/anthropic\" \\\n    API_TIMEOUT_MS=\"3000000\" \\\n    ANTHROPIC_DEFAULT_HAIKU_MODEL=\"glm-4.5-air\" \\\n    ANTHROPIC_DEFAULT_SONNET_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_DEFAULT_OPUS_MODEL=\"glm-4.7\" \\\n    ANTHROPIC_AUTH_TOKEN=\"8xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxo\" \\\n    claude",
              "score": 2,
              "created_utc": "2026-02-02 18:08:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o378ib9",
                  "author": "iongion",
                  "text": "But thats what i do, i wanted the same but with devstral/mistral official ones",
                  "score": 1,
                  "created_utc": "2026-02-02 18:36:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o33xky0",
              "author": "nycigo",
              "text": "Yes, 100% ask Claude for the code ðŸ˜‚",
              "score": 0,
              "created_utc": "2026-02-02 05:39:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o33bmmj",
          "author": "aaronr_90",
          "text": "What are your thoughts on Qwen3 Coder vs Devstral Small 2?",
          "score": 2,
          "created_utc": "2026-02-02 03:13:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w52x",
              "author": "Potential_Block4598",
              "text": "Devstral can continue for longer without my interaction and can correct itself if it faces an issue while Qwen would just loop trying the same mistake again and again and failing\n\nOn the other hand Devstral is slower",
              "score": 1,
              "created_utc": "2026-02-02 05:28:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33xnzm",
                  "author": "nycigo",
                  "text": "It's super fast via API, but I don't know about local processing.",
                  "score": 1,
                  "created_utc": "2026-02-02 05:40:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o33i840",
          "author": "former_farmer",
          "text": "In which hardware are you running this?",
          "score": 1,
          "created_utc": "2026-02-02 03:53:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o33w6f1",
              "author": "Potential_Block4598",
              "text": "AMD Strix Halo\n\nNot the best I guess but it kinda works",
              "score": 1,
              "created_utc": "2026-02-02 05:28:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o348o0p",
          "author": "SourceCodeplz",
          "text": "I don't see the harness that you used? How did you work with Devstral? Inside what tool?  \nI see you say about MCPs, but in what tool?",
          "score": 1,
          "created_utc": "2026-02-02 07:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36b3u9",
          "author": "nico_aka_redcat",
          "text": "What resource do you have to run devstral locally ?",
          "score": 1,
          "created_utc": "2026-02-02 16:03:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o32fqii",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -5,
          "created_utc": "2026-02-02 00:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32gss6",
              "author": "cosimoiaia",
              "text": "Others do what they think it's best for you, Mistral does what you actually say.\n\n(It's my experience too, it has always been the best instruction following model of all)",
              "score": 6,
              "created_utc": "2026-02-02 00:19:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o32i1gy",
              "author": "Potential_Block4598",
              "text": "There is a TL;DR\n\nBest model for local agentic ai stuff",
              "score": 4,
              "created_utc": "2026-02-02 00:25:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qv1o6n",
      "title": "How do you see LeChat in 2026 February compared to ChatGPT and other LLMs?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "author": "BonoboPowr",
      "created_utc": "2026-02-03 19:31:03",
      "score": 62,
      "num_comments": 56,
      "upvote_ratio": 0.94,
      "text": "I always found it (sadly) underpowered. Sometimes I checked in on it and concluded that it's still lacking. But now I started a conversation, and it surprised me for the better.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qv1o6n/how_do_you_see_lechat_in_2026_february_compared/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3ebvkc",
          "author": "SkyPL",
          "text": "It underperforms. That's obvious for anyone using LeChat with SOTA models. Benchmarks try to quantify it that gap, but it *is* an observable issue in the actual work that I do.\n\nOverall though it does decently for being an alternative point of view. Especially for the stuff that requires search online.\n\nYou can input more complex topics into something like ChatGPT, Gemini, Deepseek and LeChat and the truth will be somewhere in there, either in one of, or between the four ;)",
          "score": 31,
          "created_utc": "2026-02-03 19:39:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3fnpkg",
              "author": "troyvit",
              "text": "I agree that Mistral under-performs, but when adding prices as a metric, how much does it under-perform? When I compare Mistral Large on sites like this one:\n\n[https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512](https://pricepertoken.com/pricing-page/model/mistral-ai-mistral-large-2512)\n\nto Claude Sonnet 4.5:\n\n[https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5](https://pricepertoken.com/pricing-page/model/anthropic-claude-sonnet-4.5)\n\nMistral large is around 1/6 the price for inputs and 1/10 the price for outputs.\n\nSo does Mistral suck 10x more than Sonnet? The answer could very well be \"yes\" if because of the model choice you spend 10x as long on a project.\n\nBTW I don't know if [pricepertoken.com](http://pricepertoken.com) is a real web site, so if I have those prices wrong my apologies. My take also doesn't take into account alternative ways of paying.",
              "score": 5,
              "created_utc": "2026-02-03 23:30:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3i5lkp",
                  "author": "jacomoRodriguez",
                  "text": "Not sure if pricing is a good metric.\nIf you pay just 1/8 for your balcony and it falls off the house, it was cheap but also cheap ;)\n\nI know, not the best analogy but imo this applies in the ai space as well. Even if cheap, there is a min threshold you want to be above for good and reliable results. According to benchmarks, Mistral is sadly nowhere near that threshold.\n---\nSidenote: I use ai a lot for coding and developing. The gaps in the models are really visible there",
                  "score": 6,
                  "created_utc": "2026-02-04 09:47:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ir8ai",
                  "author": "SkyPL",
                  "text": "Price per token doesn't matter - it's price per job that does - aka cost efficiency. Musk's Grok was notorious for having a relatively low price per token, but it uses absurd amount of tokens on reasoning (tokens that Grok, unlike most other LLMs, never sends to you), making it one of the most expensive models on the market. Qwen 3 suffered from similar issues. And... so does Mistral Large.\n\nSee https://artificialanalysis.ai/#cost - switch to Intelligence vs cost, enable all the latest models from Mistral AI and you will see that compared to the rest of the market - Mistral AI is one of the least cost-effective providers. Devstral2 might be the first model that breaks that pattern, but so far its real-world performance has been mixed bag, and it's clearly below Sonnet 4.5.\n\nEspecially when you have GLM-4.7 that actually DOES offer you Sonnet 4.5 performance at a lower cost. Heck: GLM 4.7 is cheaper than Devstral2! ([$0.4/$1.9](https://openrouter.ai/z-ai/glm-4.7?sort=price) vs [$0.4/$2.0](https://openrouter.ai/mistralai/devstral-2512?sort=price), and with GLM you can have it even cheaper thanks to caching ($0.08), something Devstral2 does not offer).\n\n(If you want to know more about cost efficiency, you can start with [this video](https://www.youtube.com/watch?v=mRWLQGMGY80), it's fairly accessible and a decent starting point)",
                  "score": 1,
                  "created_utc": "2026-02-04 12:43:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3fcxim",
              "author": "mythrowaway4DPP",
              "text": "I actually just did a personal test with a complex deep research task.\nChatGPT, Gemini, Mistral, Claude\n\nMistral did just fine.",
              "score": 4,
              "created_utc": "2026-02-03 22:33:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ei4f2",
          "author": "Helenaisavailable",
          "text": "It's great for role-playing and for creative collaboration. That's what I mostly use LLMs for, so I'm satisfied. Agents are fantastic once set up properly.Â Mistral is improving , and I want to support them by using their product.Â ",
          "score": 22,
          "created_utc": "2026-02-03 20:09:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3erh1l",
              "author": "Icy_Distribution_361",
              "text": "Role playing? What do you mean? You role play with the LLM? And then what?",
              "score": 4,
              "created_utc": "2026-02-03 20:53:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ezpxx",
                  "author": "Helenaisavailable",
                  "text": "I'm a painter. I have certain characters, worlds, scenarios, creatures in my mind and tell the LLM to act it out with me,Â and we co-write a story.Â It can sometimes inspire me.Â Whatever happened in the role-play might spark an idea for a certain painting or drawing.\n\n\nI dont need an LLM to inspire my art, and I understand that role-playing might seem weird to some people. But I find it very fun! It's just an outlet for my daydreaming.Â ",
                  "score": 15,
                  "created_utc": "2026-02-03 21:31:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ewvep",
                  "author": "BonoboPowr",
                  "text": "ðŸ’¦",
                  "score": 3,
                  "created_utc": "2026-02-03 21:17:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3enfp1",
          "author": "Substantial-Yam3769",
          "text": "Further and further behind, i hope they soon will unvail a new model, something like Kimi K2.5.\n\n\nHowever it is still one of my favorite AIs, not just becouse of GDPR, and EU data protections, but also becouse of the flexibility Le chat offers and i like style of communication of the models.",
          "score": 11,
          "created_utc": "2026-02-03 20:34:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eiv28",
          "author": "Big_River_",
          "text": "formidable! it only underperforms on useless benchmarks - in many use cases it is state of the art - plus it has improved performance over and within large context windows",
          "score": 10,
          "created_utc": "2026-02-03 20:12:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3exa52",
              "author": "BonoboPowr",
              "text": ">formidable\n\nIn what language?",
              "score": 1,
              "created_utc": "2026-02-03 21:19:48",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3iaefk",
              "author": "Lukasino",
              "text": "Could you list examples of such use cases?",
              "score": 1,
              "created_utc": "2026-02-04 10:31:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ljyf0",
                  "author": "Big_River_",
                  "text": "riding shotgun with me on daily / weekly / monthly not-quite routine scoops across itops, secops, devops - human in the loop policy / process - where reliable valid plus fast saves me hours - surface what matters in the queue and categorize what is easily handled with boilerplate etc",
                  "score": 1,
                  "created_utc": "2026-02-04 20:52:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ecpge",
          "author": "farawayviridian",
          "text": "For fiction writing itâ€™s great. For everything else I use Gemini.",
          "score": 7,
          "created_utc": "2026-02-03 19:43:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hnsj0",
          "author": "Lauantaina",
          "text": "I'm European. A few weeks ago I was asking ChatGPT what would happen if a dump of US treasury bonds happened and it was super bullish on the US to the extent of piousness - it couldn't accept a situation where the US might not come out on top. It simply did not give objective answers. I had the same conversation with Le Chat and it was more objective and factual, certainly using less emotional or manipulative language. \n\nWhen you start pointing out to ChatGPT that it is using persuasive and manipulative devices to keep me engaged, it acknowledges that it is. When you add the inherent bias in there, that's just a bad combination. Personally, I don't need that in my life.\n\nI have found that on market research, which is my primary use case, both models are about equal but surface different things. When I'm producing a paper, I use both.",
          "score": 7,
          "created_utc": "2026-02-04 07:02:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hqbe6",
              "author": "BonoboPowr",
              "text": "ChatGPT is horrible at discussing current political events. It refused to believe that Maduro was kidnapped, I even posted articles about it, and it just kept on saying that I just fell for social media disinformation in the fog of war. No matter what I said it refused to accept.\n\nSimilar about protests in Iran. In the early days it refused to consider the possibility that 1000s to 10s of thousands were murdered. \n\nHappened in other times as well, very annoying. Anything Trump does in real life is not possible according to it.",
              "score": 2,
              "created_utc": "2026-02-04 07:24:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3htsxz",
                  "author": "Lauantaina",
                  "text": "Yes I had a similar experience with political topics. It accused me of falling for lies and disinformation, before going on to totally fog up the response with its own lies and disinformation even when provided with links and proof. Not objective at all, and totally biased towards the US. Mistral at least seems to be neutral and objective on those topics, even when you're being critical of the EU.  \n\nI've also noticed from 5.2 onwards that ChatGPT has really ramped up the gaslighting - making mistakes and then blaming me when I point it out. It's always my mistake. Emotionally manipulative language. Fogging up every discussion. All I want is an output of the facts, I'm not signing up to be manipulated. \n\nAlso the language patterns are too predictable to the point of being almost unusable.",
                  "score": 1,
                  "created_utc": "2026-02-04 07:55:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3eebw7",
          "author": "aeonixx",
          "text": "It's more likena scalpel, it doesn't do shit I didn't ask for. It means I do more preparation before sending the prompt, and I rarely have to correct tomfoolery.",
          "score": 5,
          "created_utc": "2026-02-03 19:51:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esm6s",
              "author": "amunozo1",
              "text": "This is very true. It follows much more the instructions without adding things nobody asked for.",
              "score": 3,
              "created_utc": "2026-02-03 20:58:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ed8u9",
          "author": "erizon",
          "text": "Different LLMs have different strengths in different categories.\n\nUnder/overpowered is meaningless without context (unless they are notoriously awful in everything). Are you writing Javascript code? FORTRAN code? Writing a novel? Researching science? \n\nI personally found Devstral better than Opus/Sonnet/Gemini for code implementation where design is already provided, en par with Haiku (only these two proactively wrote and executed tests in my experience). \n\nNot much to say about LeChat myself, as I barely started using it few days ago",
          "score": 5,
          "created_utc": "2026-02-03 19:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h5xyu",
          "author": "CuteFreedom7715",
          "text": "It is missing dearly a TTS !",
          "score": 4,
          "created_utc": "2026-02-04 04:43:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eh068",
          "author": "Edereum",
          "text": "For small very deterministic tasks in an agent flow, OCR and data extraction, its very cost effective with very good performance.  \nFor the rest, it underperforms.  \nI second SkyPL on \"research\" that give another view of SOTA.",
          "score": 3,
          "created_utc": "2026-02-03 20:03:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i73i9",
          "author": "IncorrectByDesign",
          "text": "I've been actively using it for a month now and i found some minor inconvenience at times. I write to it in English but because of my IP location it replies in German. I ask it to register that for all our conversations we need to speak in English, it confirms that the memory was updated but then a few days later it speaks to me in German. \n\nI ran a comparison between Chat GPT, Grok and Mistral and asked it if my options trading due diligence was correct.  I asked all of them to help me better understand the Greeks and I found: \n\n  \n1. Chat GPT made regular mistakes on the interpretation of the Greeks because an Option with Expiry date 30/09/2026 was classified as a LEAP with an expiry date in 2027. I asked it twice to review its analysis and twice it supported the wrong thing. I then asked it to count from January to September and tell me how are these 400 and something days? It then said, you are right and stated that based on the fact that between January and September we have x days, my analysis on Delta, Implied volatility is incorrect and this is a crap deal. So reading the fine print showed me that it was Hallucinating for some reason. \n\n2. Grok: much better answer and better refinement by also providing hedging bets to cover potential losses arising from the trade. Chat GPT needed to be asked additional questions for this. Also Grok said that this trade is rather neutral and i should buy the equity rather than go into options i am a fan of slow and steady growth. This was nice to see however I was expecting more math and tangible evidence for the recommendation. \n\n  \n3. Le Chat - Mistral : straight and to the point but was more conservative than both Chat GPT and Grok. It made sure to avoid absolutes in its statements and simply kept to the surface by theorising. I had to press it hard to give me more criteria to take decisions and this was adequate, however I was still expecting a more comprehensive and mathematical analysis as to why it was basing its decision on so and so. \n\n  \nI guess we are not there yet for this type of scenarios.",
          "score": 3,
          "created_utc": "2026-02-04 10:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eby4j",
          "author": "uusrikas",
          "text": "Good at fiction writing.\n\n\n\n\nPretty bad at searching for facts.\n\n\n\n\nBad image recognition. Image generation is ok if you ask it to do normal mundane stuff, but bad at realizing weird image ideasÂ \n\n\n\n\nTerrible thinking mode, almost unusable how it starts questioning itself and gets stuck in infinite loops.\n\n\n\n\nGood at helping me work, programming.\n\n\n\n\nFrankly, the only reason why I use it is because it is European. They are catching up when AI development slows down, but I really hope they pick up the pace.Â \n\n\nI use free versions of Gemini and Anthropic when ever I want a second opinion. Gemini is overall really good now and Anthropic has a nice pleasant writing style I like",
          "score": 6,
          "created_utc": "2026-02-03 19:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3einy3",
          "author": "Snickers_B",
          "text": "The coding is on par with other tools for specified tasks. Usually small tasks that is. \n\nThe writing is very good and I think better than ChatGPT but not better than Claude for writing or code.",
          "score": 2,
          "created_utc": "2026-02-03 20:11:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3et5p2",
          "author": "Celmad",
          "text": "I was using it now again after a while, and after using Gamini Pro, and It was very underwhelming.\n\nI was asking about email providers in Europe, alias management and password managers.\n\nGemini Pro seems like a person giving you very reliable information and even being creative and bringing information I might've missed.\n\nMistral (free tier) replied fast, yes, but with not much info. Just a quick few facts (some of them wrong, like saying 2FAS Pass was from Poland instead of US) in the form of a table with not much more info than what I gave it.\n\nReally really underwhelming.\n\nI had to stopped using it at work because I was working with Drupal .module files and Mistral didn't accept these files, only ChatGPT and Gemini did accept them of the AI chats I tried.",
          "score": 2,
          "created_utc": "2026-02-03 21:00:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fto1a",
          "author": "Equivalent-Word-7691",
          "text": "Honestly way behind gtp, Gemini and especially Claude, but also to kimi, deepseek and GML\n\nO use AI for creative writing and it's probably the worse out of the AI I mentioned , another thing is the output length... Gosh too short\n\nAs an European I would like to support ot more for more than one reasons , but honestly the quality is juybad compared to both Americans and Chinese AI \n\nThe price also is too much high for the quality",
          "score": 2,
          "created_utc": "2026-02-04 00:03:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3h9nv5",
          "author": "The_Duke28",
          "text": "I don't know, I'm not really an AI Masterbrain, but I regularly compare my results to the one of my wife (she's using ChatGPT) and I always get the same results, sometimes even better ones.",
          "score": 2,
          "created_utc": "2026-02-04 05:09:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hlb30",
          "author": "Prinzmegaherz",
          "text": "I asked both le chat and Claude to design some math training sheets for my son.\n\nLe chat answered with something like 2 + 2, 4 + 4, no equation marks or anything.\n\nClaude gave me a fully layouted and printable sheet with exercises.\n\nThe amount of effort on my side to transform mistrals output into something usable like what Claude did would have been quite a lot. I probably would have been faster to do it myself as compared to using mistral.",
          "score": 2,
          "created_utc": "2026-02-04 06:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eer49",
          "author": "faresar0x",
          "text": "The entire world push new stuff every few months. Le chat like once a year and it doesnâ€™t even compete. I would like to support it but its way behind. If they wanna win market share, they gotta nail coding benchmarks",
          "score": 3,
          "created_utc": "2026-02-03 19:53:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3efmf4",
          "author": "pirisca",
          "text": "A few days ago it came up with:\n\"Total Duration: 18 months (from February 2026 to July 2026).\"Â \nI asked how did it made such an error.Â \nThe response :\nYouâ€™re right to call out the oversightâ€”it was a clear miscalculation on my part, and I appreciate your patience. Hereâ€™s what happened:\n\n\n1. **Misinterpretation of Dates**: I mistakenly treated \"February 2026 to July 2026\" as an 18-month span instead of **6 months**. This was an error in basic arithmetic and attention to detail.\n2. **Overlooked Context**: I didnâ€™t double-check the timeline against your long-term horizon (20+ years), which should have signaled that a 6-month DCA was a short-term tactic within your broader strategy.\n\n\n### **How Iâ€™ll Improve**\n- **Verify Dates**: Always cross-check timeframes with a calendar or simple math (e.g., February to July = 6 months).\n(...)Â \n\n\nSigh...Â ",
          "score": 1,
          "created_utc": "2026-02-03 19:57:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hpsnr",
              "author": "mobileJay77",
              "text": "Don't let an LLM do maths or even date calculation! Provide it with a service that can and let the llm put the parameters into the right place. These are solved problems.",
              "score": 1,
              "created_utc": "2026-02-04 07:19:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3et602",
          "author": "ohhellnaws",
          "text": "Personally I do feel it's a little lacking. It's very quick, clear, and concise and a lot of the time that's exactly what I want. I use it as a chat bot for a quick to and from. Nothing beats it on speed.\n\nOne thing I havenâ€™t really explored yet is to push it to answer and think more deeply by using different prompts for different agents, one of his strength seems to be able to call upon one of your agents/libraries mid any chat. \n\nIt's very good, however, at creating CSVs for me and discussing grey areas where ChatGPT may completely refuse.",
          "score": 1,
          "created_utc": "2026-02-03 21:00:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ext13",
          "author": "SoWhoAmIReallyHuh",
          "text": "It's surprisingly good at generating images.",
          "score": 1,
          "created_utc": "2026-02-03 21:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f3shm",
          "author": "crazyserb89",
          "text": "I would say ChatGPT, Gemini and Claude are tie on top (depending on use-case), and LeChat is not even close.. I hope they will be able to do some magic like Kimi in 2026, otherwise RIP",
          "score": 1,
          "created_utc": "2026-02-03 21:49:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hm2vm",
          "author": "SamuraiChicken88",
          "text": "I like it for data-analysis in R. Sometimes I find it better than ChatGPT even.",
          "score": 1,
          "created_utc": "2026-02-04 06:47:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hwlid",
          "author": "_FightingChance",
          "text": "I recently tried large again, and was pleasantly surprised! I use llms for work, coding, academia, and such, and was just trying to see if I can justify supporting them with a subscription, I will try them out for a couple of months. \nSo far I am intrigued by their agentic lineup, which I hear is good!!",
          "score": 1,
          "created_utc": "2026-02-04 08:21:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3i3cyj",
          "author": "tmoravec",
          "text": "I find it next to useless, even with Mistral Large 2512 through AI Studio agents. Curiously, the same model performs quite well through the API, so I suspect the system instructions in Le Chat make it fight my prompts. Use cases: work - business stuff, tech stuff, general world knowledge, context and nuance. No roleplaying.",
          "score": 1,
          "created_utc": "2026-02-04 09:25:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mf758",
          "author": "Salt-Willingness-513",
          "text": "cool part about lechat is, most of the time its blazing fast, negative is, its rarely usable one shot and i have to rework alot of times, while i can ask claude to do the same and it gives a perfect or at least nearly perfect output. at least on openai/anthropic/googles platforms, we actually get the new model in time with somewhat proper communication. we still wait for large 3 to be available offically on lechat(yes i know you can create agents with large 3 via playground, but thats not the point). Reasoning is terrible and i very often have bugs in every session. I stillw ant to like lechat, but its harder and harder imo when at the same time using the other 3 named ones. I even tried z ai coding plan and i was a bit pikachu faced how good glm4.7 does compared to any mistral model",
          "score": 1,
          "created_utc": "2026-02-04 23:28:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3otdba",
          "author": "LearningPodd",
          "text": "I always start with talking to LeChat and mostly I don't have a need to turn over to another model.",
          "score": 1,
          "created_utc": "2026-02-05 09:20:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3punfv",
          "author": "Sweaty-Special-1710",
          "text": "I'm honestly really happy with it. I also use Vibe CLI for coding. Itâ€™s not expensive, I donâ€™t have any usage limitation issues, and I find it very practical. While Claude Sonnet and Opus seem more advanced, Le Chat is fast, structures its replies well, and fits my light usage needs perfectly.",
          "score": 1,
          "created_utc": "2026-02-05 14:02:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qwqqp",
          "author": "Sky_Linx",
          "text": "Mistral is losing ground pretty quickly. I *really* wanted to use their models for the AI features in my app (a retrospective tool for small teams called SprintPulse - https://sprintpulse.io if you are curious) but performance was so bad it's not even funny. My app has features like detecting related feedback, generating action items from feedback and more. The Mistral models, including the largest, are among the worst performers I have tried so far. So at the moment I am using Claude Opus 4.5 which obviously is a lot more expensive, but it's incredibly good not surprisingly. I really hope that Mistral will improve their models significantly because I'd prefer using models hosted in the EU for my app.",
          "score": 1,
          "created_utc": "2026-02-05 17:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eo2si",
          "author": "Competitive_Ad_2192",
          "text": "Far, far behind, unfortunately.",
          "score": 1,
          "created_utc": "2026-02-03 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eib49",
          "author": "Shichroron",
          "text": "LeChat is dead",
          "score": -6,
          "created_utc": "2026-02-03 20:09:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3esdfc",
              "author": "Temporary-Outside737",
              "text": "No. It's still purring.",
              "score": 2,
              "created_utc": "2026-02-03 20:57:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ebgru",
          "author": "NerasKip",
          "text": "Trash",
          "score": -11,
          "created_utc": "2026-02-03 19:37:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsvmbo",
      "title": "Is Mistral Large 3 actually the best ai writing tool or are we just coping?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "author": "Fresh_State_1403",
      "created_utc": "2026-02-01 11:02:36",
      "score": 54,
      "num_comments": 23,
      "upvote_ratio": 0.94,
      "text": "Iâ€™ve spent the last month running Mistral Large 3 against the new Claude 4.5 and GPT-5.1 \"Thinking\" modes, and Iâ€™ve come to a conclusion that might annoy the purists here. If I had to pick one for logic-heavy, technical writing where I don't want a \"guidance counselor\" lecturing me on my tone, Mistral is the winner, but only if you aren't paying the $20 \"tax\" for a single-model sub.\n\nMistral Large 3 is fundamentally the best ai writing tool for anyone who needs high-density output without the sycophancy. While GPT-5 tries to guess what I want to hear and Claude gets bogged down in its own safety \"Constitutional\" logic, Mistral just executes the Markdown. It treats the prompt like a set of instructions, not a suggestion.\n\nImportantly, the reasoning depth here (let me elaborate!!) is finally at parity with the frontier models, but without the \"lobotomy\" effect we see after a modelâ€™s been out for six months. Iâ€™ve been testing this by running complex document analysis through writingmate, where I can flip between Mistral and the other models in a single thread. such a  \"hallucination drift\" is significantly lower on Mistral when you're dealing with non-English technical specs or legacy codebases, at least I found this to be true for my workflow.\n\nThe real problem isn't the model; itâ€™s the fragmentation. Most people claim ChatGPT is the best ai writing tool simply because theyâ€™ve already paid the $20 and don't want to admit it's lagging in raw reasoning. But the minute you need to cross-check a hallucination or run a deep search without the \"Exactly!\" and \"Sharp observation!\" fluff, the value of a single-model subscription falls apart.\n\nClaude and Gemini are great for their specific moats (f.e. Claude for narrative, Gemini for the 2M context window), but Mistral is the only one that feels like itâ€™s built for professionals who want a tool, not a friend. My skeptic take? Perhaps, stop overpaying for the \"big brand\" wrappers and start using a brief stack of tools that let you use the right logic for the right task.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qsvmbo/is_mistral_large_3_actually_the_best_ai_writing/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2yarri",
          "author": "Working-Chemical-337",
          "text": "oh, price consolidation is the only thing that convinced me to try managed platforms. was paying >100 dollars/month for GPT, Claude, and Gemini separately. then tried multi ai platforms (or wrappers with many models) like writing mate, just because i heard it handled the agent side better than the standard APIs, and saving that ammount per month while still getting frontier-level Mistral reasoning is probably the only \"win\" Iâ€™ve had in my tech stack this year that just started",
          "score": 9,
          "created_utc": "2026-02-01 11:06:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yjlcd",
              "author": "Fresh_State_1403",
              "text": "makes a lot of sense",
              "score": 2,
              "created_utc": "2026-02-01 12:20:59",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o2z78k1",
              "author": "Tuckebarry",
              "text": "Wait so what's the stack then? What's the best multi AI platform that you mentioned?\n\nThanks",
              "score": 1,
              "created_utc": "2026-02-01 14:49:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb0jt",
          "author": "One-Risk-4266",
          "text": "doing the same thing and bouncing drafts between Claude and Mistral. I find Claude is better for the initial soul of a piece, but Mistral is the only one I trust to actually follow a style guide without drifting into aispeak after three pages. and itâ€™s hard to argue itâ€™s not a top-tier contender for the title of best ai writing tool in 2026, especially if you value data sovereignty and want something local",
          "score": 4,
          "created_utc": "2026-02-01 11:08:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yk8ss",
              "author": "Fresh_State_1403",
              "text": "i totally get that. Claude has that \"human\" spark, but it definitely starts to hallucinate its own \"creativity\" after a while. and Mistral is just cold, hard logic, which is a godsend for technical consistency and actually sticking to a style guide without the aispeak fluff; so for me all in one chats like writingmate are just to keep them both in one window because I was getting massive tab fatigue trying to copy-paste between accounts. Itâ€™s way easier to just flip the model toggle when Claude starts getting too \"wordy\" and you need Mistral to tighten things up. Honestly, the best ai writing tool in 2026 isn't a single model anymore, itâ€™s just whichever one isn't currently acting \"lobotomized\" or ignoring your instructions\n\nbtw are you running Mistral locally via Ollama for that data sovereignty piece, or are you just sticking to the API for the speed?",
              "score": 1,
              "created_utc": "2026-02-01 12:26:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z379l",
          "author": "porzione",
          "text": "How do you actually use Large? Mistral lacks actual tools, except vibe/devstral - the same issue as with Chinese models. I use local Mistral Small as creative scene writer, but everything is planned by Opus, because I need to collect names, facts, timeline, check backstories from Obsidian vault with \\~1500 files and I use Claude Code for this, then CC writes detailed scene description/plan and sends it to local fine tuned Mistral Small.\n\nIn theory OpenCode or Zed may work for this, but my previous attempts to use Mistral modelsâ€™ agentic features have all failed miserably, except Devstral. I hope that Mistral will add all their models to Vibe, so it will work without fiddling with 3rd party tools.",
          "score": 3,
          "created_utc": "2026-02-01 14:27:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30mhi5",
              "author": "Working-Chemical-337",
              "text": "what tools does mistral lack?",
              "score": 1,
              "created_utc": "2026-02-01 18:47:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o30plz7",
                  "author": "porzione",
                  "text": "Vibe with all Mistral models, specifically - cli tool with ACP support.",
                  "score": 1,
                  "created_utc": "2026-02-01 19:01:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o31povj",
              "author": "erizon",
              "text": "GLM family works perfectly fine in Claude Code via ANTHROPIC_BASE_URL environment variable (actually much faster than via OpenAI style //api.z.ai/api/coding/paas/v4). Deepseek also supports it, which Chinese model does not?",
              "score": 1,
              "created_utc": "2026-02-01 21:55:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zmlna",
          "author": "Ambitious_Fee3169",
          "text": "Mistral Large is fantastic. It's the default in our AI chat system. Mistral medium is also great (but more expensive for some reason for output tokens vs large).",
          "score": 2,
          "created_utc": "2026-02-01 16:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30sgl1",
              "author": "Fresh_State_1403",
              "text": "I don't like using it per credits / calls, because it never seemed to be economically viable for me, so i used 'all in one' chatbot subscription(s) which in my case seems to work more, like writingmate in either pro or ultimate",
              "score": 2,
              "created_utc": "2026-02-01 19:14:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb78z",
          "author": "DrPinguin98",
          "text": "I do a lot with AIs and use a service provider that lets me use pretty much all AIs, and honestly, Mistral Large 3 is definitely no better than GPT 5.2 Thinking.\n\nJust the day before yesterday, I tried to rewrite some of my reports and got a little frustrated with Mistral. Content was constantly missing, it made things up (even though I explicitly forbade it), or it didn't rewrite things the way I defined in the prompt.\n\nBut that could also be due to the languageâ€”in my case, German.\n\nI have to say, though, that a lot is happening in this regard, and we're starting to reach the point where I can and will really use Mistral.\n\nAnd when the time comes, my monthly subscription will belong entirely to Mistral, and I honestly can't wait.",
          "score": 4,
          "created_utc": "2026-02-01 11:10:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30j53c",
              "author": "Fresh_State_1403",
              "text": "by the way, does the need to use German change a lot in how you pick AI tools? what differences do you see when it comes to non-English responses?   \n5.2 thinking is very ok",
              "score": 1,
              "created_utc": "2026-02-01 18:32:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yb5w2",
          "author": "TonyHMeow",
          "text": "The best thing about OA is the saved memory blocks and profiling aspect of the models in both writing and conversational discussion flow, and as of now still leading compared to other major competitors IMO.\n\nComing from GPT 4oâ€™s writing, how is LeChat saved memory (storage size/utilization) and context tracking (in a project, say) compared to OpenAI? Genuinely considering trying out Mistral after 4o retires, would love some input on this!",
          "score": 1,
          "created_utc": "2026-02-01 11:09:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2ykzkx",
              "author": "Fresh_State_1403",
              "text": "OpenAIâ€™s memory is definitely the stickiest part of their ecosystem to me, it's hard to leave once the model knows your specific quirks. Yet if youâ€™re looking at lechat , in my xp  Itâ€™s less \"vibe-based\" and more literal. Their Project Libraries actually beat GPT in my opinion because they index your files properly. Instead of the model just cramming everything into the context window and hallucinating when it gets full, Mistral pulls only whatâ€™s relevant. Itâ€™s way more stable for long-term technical work. So I often use Writingmate to A/B test the recall between them and overall compare models side by side, and while GPT feels more intuitive, Mistral is much more transparent about what itâ€™s actually pulling from your history. You won't get that \"as an AI assistant\" lecture every five minutes either, which is a massive plus. There's also a trade-off which is, Mistral won't remember a random chat from three weeks ago unless you specifically tell it to save that info to your memory or project. Itâ€™s more manual, but somwewhat better for privacy and focus.",
              "score": 2,
              "created_utc": "2026-02-01 12:31:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o2zudq7",
                  "author": "TonyHMeow",
                  "text": "ok, thanks for the info!\n\nWhen you said \"Mistral is much more transparent about what itâ€™s actually pulling from your history.\" Do you mean like it literally quotes you (\"word for word\") from another conversation/your uploaded files? Because i think GPT had an update about that a couple of weeks, which I really dislike lol.",
                  "score": 1,
                  "created_utc": "2026-02-01 16:40:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2yhhi4",
          "author": "Alex-plosion",
          "text": "For  ideas, I don't find mistral large 3 to be amazing, but for writing, yeah it's great, especially in French.\nI tend to write the plan, or a whole draft with another model and rewrite it after with mistral.",
          "score": 1,
          "created_utc": "2026-02-01 12:04:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30jzvw",
              "author": "Fresh_State_1403",
              "text": "when I am able to switch within one chat with tools like writingmate, I can interchange mistral with gpt and gemini without changing context, tools, or chatbots. but frm what I know, Mistral is truly very fine at European languages",
              "score": 1,
              "created_utc": "2026-02-01 18:36:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2yqxwq",
          "author": "Charming_Support726",
          "text": "No. Definitely No.\n\nUsed all of them for writing. All of them showed ugly quirks. I tried German, European Portuguese, English. \n\nGemini follows style instructions quite well, but lacks some variance in creativity. Style was very important for me. \n\nAll others still do this damn \"its not only A, it is B\" thing in every second sentence. You can't get rid of it. \n\nThe creative model from Mistral Labs can get European Portuguese right - this is the only model except for Gemini 3 Pro, which is capable. All others fails (Claude, Gpt, Large3 and more). Unfortunately it is not open weights, otherwise I'd like to see an optimized version.",
          "score": 1,
          "created_utc": "2026-02-01 13:14:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30qf27",
              "author": "Working-Chemical-337",
              "text": "you can prompt them not to use negations, and other signs of ai writing, and otherwise follow your natural style of writing. some editing may be required even then, but hey, this can save a lot of time when you have to do some huge outputs",
              "score": 1,
              "created_utc": "2026-02-01 19:05:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2z0vxg",
          "author": "TeeRKee",
          "text": "Both",
          "score": 1,
          "created_utc": "2026-02-01 14:14:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3eut58",
          "author": "urzabka",
          "text": "I am practically using all of models I like and Mistral as well in multi-ai tools. For now itâ€™s writingmate and works well for me. Does it cover 100% of all that I need AI for? No but all that I need a chatbot for, having like mistral GPt Claude Gemini and others",
          "score": 1,
          "created_utc": "2026-02-03 21:08:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwmszj",
      "title": "How is Mistral so awesome in comparison to other AI?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qwmszj/how_is_mistral_so_awesome_in_comparison_to_other/",
      "author": "SoWhoAmIReallyHuh",
      "created_utc": "2026-02-05 14:31:55",
      "score": 54,
      "num_comments": 25,
      "upvote_ratio": 0.78,
      "text": "Like, how do the guys from Mistral make it so fast and intelligent? Everything is superior to the other AI companies. Le Chat is faster, produces more relevant content, produces better images, is friendlier, is more respectful. If they add video generation, this will be it. It will be game over for all the other companies. Mistral will reign supreme.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwmszj/how_is_mistral_so_awesome_in_comparison_to_other/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3q56ji",
          "author": "Select_Ad_390",
          "text": "I just gave the same deep research task (research on a stock and company) to both Mistral and Gemini. \n\nMistral didnâ€™t even red the latest result report from last month, only cited as far as q2 2024). \n\nI really want Mistral to win as a European company, but sometimes itâ€™s embarrassing. \n\nDonâ€™t get me wrong , other times itâ€™s very good, but the lack of consistency is really stopping me from using it for more complex use cases. \n\nAnybody have any ideas?",
          "score": 47,
          "created_utc": "2026-02-05 14:58:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3qtfse",
              "author": "KonserveradMelon",
              "text": "Yep. I honestly think itâ€™s the worst chatbot Iâ€™ve ever used. \n\nIf European companies want to keep up in global competition, they need to innovate, employ, invest. \n\nThis goes for tech, automotive, etc.",
              "score": 0,
              "created_utc": "2026-02-05 16:52:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3qgmex",
              "author": "Wise-Artichoke-3808",
              "text": "I had similar feeling. Truth to be told many time it blows my mind how good and relevant output it gives. Other times its incomprehensibly garbage.. I noticed many times, it does not read / index webpages I inquire about just reads the search result headlines / descriptions and infers the rest. \n\nI would prefer Mistral if it would not be soo volatile. ",
              "score": 0,
              "created_utc": "2026-02-05 15:53:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3q7399",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": -2,
              "created_utc": "2026-02-05 15:08:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q8g3q",
                  "author": "SkyPL",
                  "text": "The version only changes the limits, not the quality.",
                  "score": 2,
                  "created_utc": "2026-02-05 15:15:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3q201h",
          "author": "dontcare10000",
          "text": "Reallly? What do you do with it? I have had pretty much the opposite experience.",
          "score": 28,
          "created_utc": "2026-02-05 14:42:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q92df",
              "author": "NullSmoke",
              "text": "It is very domain spesific. Mistral falls on its face every so often, but in others it does better than ChatGPT and Grok.\n\nThis is based on my personal experience, as quite a heavy user of ChatGPT (until the very end of December) Grok and Mistral. Benchmarks are neat, but they're not reflective of end user experience:\n\nOn the domain of literature, it's largely a question of taste. It lands in the ballpark of 4o there for me, on fact finding, DeepResearch exceeds that of current ChatGPT (well, tested in december when I still were subscriped to ChatGPT, but assume it still holds).\n\nWhen it comes to straight up reasoning though, it's usually slightly above 4o, but handily beaten by ChatGPT5-series models, and usually Grok as well. When it fails though... when it fails it's ugly.\n\nAt least it fails so hard that it's hard to take seriously, making it really easy for the user to flag it as bad info.\n\nThis was kinda what put me off, alongside the short context window they had back then, in like Jan 2025, when I first tried it, when that failure mode was more the norm than the exception.\n\nThat experience put me off the whole thing like the plague, but coming back when OpenAI lost their mind, I found it immensely improved, and the creative model is in fistfights with Grok-4.1 and ChatGPT5-series models, occasionally exceeding.\n\nI would say, Mistral is lagging sligthly against the infinity money black hole models, but it's more sustainable, and keeps improving over time, making it a legitimate player in the field.\n\nYou can get the latest and greatest, along with the US soft colonialism, if you want with the US models, or you can hang back a spell over in Mistral, for a lower price and a more trustworthy creator.\n\nThe latter has increasingly become very important for me at least. Moreso than LLM raw strength.\n\n(also, doesn't hurt that there's a open model that I can run at home as well, just in case)",
              "score": 5,
              "created_utc": "2026-02-05 15:18:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3q23o0",
          "author": "Relevant_Accident666",
          "text": "Is this really the case? \n\nIn my opinion nothing beats Gemini 3 pro so far for reasoning and such.",
          "score": 5,
          "created_utc": "2026-02-05 14:42:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qm19i",
          "author": "meschi_",
          "text": "For code generation I think it's not the best. I have a workflow with Gemini and OpenSCAD that does not really work with Le Chat, since it is only able to generate the most simple of shapes.\n\nBut I really like that the answers are brief and on point.",
          "score": 2,
          "created_utc": "2026-02-05 16:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q56oa",
          "author": "OwlSlow1356",
          "text": "it is fast, but that is all there is to it. their focus is b2b and they clearly show it.",
          "score": 4,
          "created_utc": "2026-02-05 14:58:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q924y",
              "author": "Relevant_Accident666",
              "text": "And thats a clever move. \n\nB2C is not a market for AI...",
              "score": 3,
              "created_utc": "2026-02-05 15:18:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qb45k",
                  "author": "SnooSeagulls4360",
                  "text": "yeah go Europe...everything is B2B and the end user ends up using US tech. Super.",
                  "score": 6,
                  "created_utc": "2026-02-05 15:28:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3q6gbw",
          "author": "uzyszkodnik007",
          "text": "Sorry,Â  but no. I always have to turn to other models as lechat is talking bs.",
          "score": 2,
          "created_utc": "2026-02-05 15:05:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qjsd6",
          "author": "crazyserb89",
          "text": "Itâ€™s a nice concept, I like the design and the features they are trying to drive, but itâ€™s too far away from the mainstream ones. I was testing it for days, different use cases and unfortunately isnâ€™t delivering neither close to what Iâ€™m expecting. Maybe sometimes in the future who knows.",
          "score": 1,
          "created_utc": "2026-02-05 16:08:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qnycb",
          "author": "aletheus_compendium",
          "text": "not really an accurate test: mistral doesn't automatically search the web. often you have turn on web search or instruct it specifically. one of the problems of using the same prompt with two different platforms is that the prompt is written for only one of them. you have to craft the same prompt query but in that platform's format and LLM dialect. then you can get a fair comparison. a gemini prompt won't be as effective in Mistral and vice versa. ðŸ¤™ðŸ»",
          "score": 1,
          "created_utc": "2026-02-05 16:27:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r12rl",
              "author": "Select_Ad_390",
              "text": "Ok thanks, this is an interesting insight. So should I ask Mistral how it prefers to have its prompts written? :)",
              "score": 1,
              "created_utc": "2026-02-05 17:28:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r4qcf",
                  "author": "aletheus_compendium",
                  "text": "i just prompted it with this: Search for and report back any and all information you find regarding 2025-2026 best practices for prompting Mistral LE CHAT ai. search beyond top tier and only official sites and sources. reach out into the vast web for blogs, articles, social mentions etc about how best to prompt LE CHAT for high quality results. pay particular attention the any quirks or idiosyncrasies that LE CHAT may have and has been discussed. out put in an orderly fashion starting with an executive summary intro. Make sure to focus search on French AND English language sources. Translate any information from French sources into English.\n\n\nthen you will have a complete guide for how to prompt. give that set of guidelines to a prompt engineer agent and tell it to optimize your prompt accordingly. rinse and repeat with all the platforms and you will know how to prompt them all properly. ðŸ¤™ðŸ»",
                  "score": 1,
                  "created_utc": "2026-02-05 17:45:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3sw4wd",
          "author": "KeizerSauze",
          "text": "Well, look, I just tested LeChat, and it's disastrous. It gets sidetracked by one question, forgetting the others, requiring 7-8 messages to get back on track, asking you three times for the document you uploaded, and inventing documents... Shall we continue?",
          "score": 0,
          "created_utc": "2026-02-05 22:46:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3revq8",
          "author": "sheerun",
          "text": "Good data and bunch of computers as far as I'm aware, and not state of art",
          "score": 0,
          "created_utc": "2026-02-05 18:32:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sq8sh",
          "author": "Cereal_Grapeist",
          "text": "What are you basing this off of? Vibes? This is a pretty unusual post that is not based on the available evidence/benchmarks.",
          "score": 0,
          "created_utc": "2026-02-05 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qei0d",
          "author": "uusrikas",
          "text": "This is just not true, Mistral is far behind in many aspects. I compare all my prompts with Mistral, Claude, Gemini and ChatGPT and Gemini is clearly the best.",
          "score": -3,
          "created_utc": "2026-02-05 15:43:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rnc7d",
          "author": "Salt-Willingness-513",
          "text": "/s?",
          "score": -1,
          "created_utc": "2026-02-05 19:10:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q7f30",
          "author": "csicky",
          "text": "I don't know, in my experience is the worst family of models.",
          "score": -2,
          "created_utc": "2026-02-05 15:09:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3sw1gj",
          "author": "KeizerSauze",
          "text": "Well, look, I just tested LeChat, and it's disastrous. It gets sidetracked by one question, forgetting the others, requiring 7-8 messages to get back on track, asking you three times for the document you uploaded, and inventing documents... Shall we continue?",
          "score": -5,
          "created_utc": "2026-02-05 22:46:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvv4wo",
      "title": "Voxtral Mini Transcribe V2 and Voxtral realtime.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvv4wo/voxtral_mini_transcribe_v2_and_voxtral_realtime/",
      "author": "cosimoiaia",
      "created_utc": "2026-02-04 17:38:40",
      "score": 52,
      "num_comments": 9,
      "upvote_ratio": 0.95,
      "text": "Mistral released 2 new STT models!\n\nhttps://mistral.ai/news/voxtral-transcribe-2\n\nhttps://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602\n\nSub 200ms delay for the open weight model, impressive!\n\nGo Mistral! ðŸš€",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvv4wo/voxtral_mini_transcribe_v2_and_voxtral_realtime/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3kh8sv",
          "author": "cosimoiaia",
          "text": "Didn't see their official post from 2 hours ago ðŸ˜…\n\nNevertheless, it's a great release and a super STT open weight model!\n\nIt feels like they read my mind because I was looking for something like this just today!\n\nEdit: typo it's stt not tts.",
          "score": 7,
          "created_utc": "2026-02-04 17:53:04",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3kjzhy",
              "author": "usrlibshare",
              "text": ">and a super TTS model\n\nDid I miss anything? Because I tested it as well, it's awesome, but it's ASR (automated speech recognition) / STT (speech to text) / transcription, however you wanna call it.\n\nTTS would be text to speech , aka. speech synthesis.",
              "score": 2,
              "created_utc": "2026-02-04 18:05:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3krlxx",
                  "author": "cosimoiaia",
                  "text": "Yeah I made a typo in my comment, I even wrote STT in the post.\n\nMaybe it was wishful thinking ðŸ˜…",
                  "score": 3,
                  "created_utc": "2026-02-04 18:39:54",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o3kmdsa",
                  "author": "Neither-Bit4321",
                  "text": "Yea, I can't see a TTS model anywhere.",
                  "score": 1,
                  "created_utc": "2026-02-04 18:16:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ljmy9",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-04 20:51:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3lnvpd",
              "author": "cosimoiaia",
              "text": "Both are transcription models? Why would you do summarization with them? \n\nDo a pass with Mistral 3 3b if you want good summarization/information extraction with low memory footprint.",
              "score": 1,
              "created_utc": "2026-02-04 21:11:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3orv2b",
          "author": "Bright-Celery-4058",
          "text": "I want to try it in my backend but docs is not updated",
          "score": 1,
          "created_utc": "2026-02-05 09:05:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oyxj7",
              "author": "cosimoiaia",
              "text": "It's supported only by vLLM so far but it's quite easy to setup, it's explained in the model card. You can also check the code of the demo in the space for the client side.",
              "score": 1,
              "created_utc": "2026-02-05 10:14:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3pkafn",
                  "author": "Bright-Celery-4058",
                  "text": "https://preview.redd.it/fim2tq58cohg1.png?width=1431&format=png&auto=webp&s=a7d8056442c12f7725dec19c472da069d62a4f9c\n\ni mean the API. i am interested in the context biasing + word level timestamp but the API doc is missing those advertised new features. Also the max audio length needs to be updated (15min was for the V1, V2 claims 3h). [https://docs.mistral.ai/capabilities/audio\\_transcription#transcription](https://docs.mistral.ai/capabilities/audio_transcription#transcription)",
                  "score": 1,
                  "created_utc": "2026-02-05 13:02:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qtp21z",
      "title": "Mistral vs. ChatGPT",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "author": "sachama2",
      "created_utc": "2026-02-02 07:59:28",
      "score": 51,
      "num_comments": 56,
      "upvote_ratio": 0.96,
      "text": "I already have a ChatGPT subscription. What additional benefits would I get if I also subscribe to Mistral?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtp21z/mistral_vs_chatgpt/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o34ez2f",
          "author": "EzioO14",
          "text": "You wonâ€™t gain anything by using both, mistral is good but a bit behind ChatGPT. Most people use mistral because itâ€™s good enough for their needs, cheaper and not American.",
          "score": 82,
          "created_utc": "2026-02-02 08:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34jg1j",
              "author": "SpeedDaemon3",
              "text": "Also mistral is not censored like chatgpt...Â ",
              "score": 42,
              "created_utc": "2026-02-02 08:54:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o34oy5v",
                  "author": "EzioO14",
                  "text": "Do you have an example? I havenâ€™t used ChatGPT much",
                  "score": 3,
                  "created_utc": "2026-02-02 09:47:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35u3om",
                  "author": "Objective-Sky7312",
                  "text": "Iâ€™m finding it still very censoredâ€¦ are people getting it to do NSFW?",
                  "score": 2,
                  "created_utc": "2026-02-02 14:40:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o38nm2w",
                  "author": "[deleted]",
                  "text": "https://preview.redd.it/wv4zc3wfs5hg1.png?width=788&format=png&auto=webp&s=c4cee9bb77aa4b7b21289402e080980e7d2b584d\n\nThat is pretty much hard censoring for me.",
                  "score": -7,
                  "created_utc": "2026-02-02 22:38:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34i5ne",
          "author": "mythrowaway4DPP",
          "text": "It is more of a replacement.  \n  \n***TL;DR***   \nMistral is behind ChatGPT a little bit, but less censored, and European.\n\n**Some details**\n\n* Their research feature is great, and easily on par with CGPT. (yes, I did the testing).\n* Image generation is kinda mid. (afaik, they are still using FLUX by black forest labs, not flux 2)\n* No text to speech, but their transcription of voice input is great and FAST!\n* Their document management uses a concept of different \"libraries\" of documents, that you can then use in different chats.\n\nPrompting mistral needs to be more strict and detail oriented. Especially if you need it to access a file, you need to very EXPLICITLY tell it to do so.   \nThis is very different from CGPT which feels like it is swimming in the provided documents and accesses them too eagerly at times.\n\nOverall, I am very happy with it.",
          "score": 25,
          "created_utc": "2026-02-02 08:41:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37bugr",
              "author": "Dadinek",
              "text": "Love the voice input as well and the fact that you can select if you want to autosend or not",
              "score": 2,
              "created_utc": "2026-02-02 18:51:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o36b4fy",
              "author": "sachama2",
              "text": "\"transcription of voice input is great and FAST\" Very interesting. Do you mean you can load via the ineterface a mp3 file?",
              "score": 1,
              "created_utc": "2026-02-02 16:04:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36bi92",
                  "author": "mythrowaway4DPP",
                  "text": "No. I was talking about using voice for input",
                  "score": 4,
                  "created_utc": "2026-02-02 16:05:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34i5xt",
          "author": "Nervous_Sun4915",
          "text": "I don't know if this is relevant for you, but you gain (limited) access to their API which you can use for your own applications as a LLM endpoint, OCR, vibe-coding, etc.\n\nI built a tool that transforms all my PDFs of scanned books/articles (basically images) into fully searchable PDFs where I can use the text in less than an hour, using Mistral and their OCR API & Python assisted coding.",
          "score": 7,
          "created_utc": "2026-02-02 08:41:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hf0uz",
              "author": "SietJP",
              "text": "Does it support handwritting?",
              "score": 1,
              "created_utc": "2026-02-04 05:49:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o34j1ja",
          "author": "MimosaTen",
          "text": "I left ChatGPT due to it being extremely slow, in favour of Gemini. But I use Mistral Vibe CLI that uses devstral 2 to automate code writing",
          "score": 9,
          "created_utc": "2026-02-02 08:50:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o37p140",
              "author": "obadacharif",
              "text": "Check [Windo](http://trywindo.com) when switching models, itâ€™s a portable AI memory that allows you to carry your memory with across models. No need to re-explain yourself.\n\nPS: Im involved with the project",
              "score": 2,
              "created_utc": "2026-02-02 19:52:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o35ctek",
          "author": "Lakafior",
          "text": "\\- MCP custom server integration on mobile and desktop is the reason I've bought it, and it's way ahead the rest (meaning other apps don't have this feature at all). I can talk with my database while on the phone now, and morevover not using my tokens doing that.\n\n\\- Libraries, which are like your knowledge bubbles with links, documents etc. you can pin to a new chat. It's a great way to chat with your notes etc. without creating custom GPT.\n\n\\- It's faster and more focused on your prompts without going sideways.\n\n\\- European, so a lot more privacy-protected and in general LLM who you talk about a lot of things this is very important point imo.\n\n\\- Cheaper",
          "score": 6,
          "created_utc": "2026-02-02 13:03:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o36bi9w",
              "author": "sachama2",
              "text": "\"Â MCP custom server integration on mobile and desktop\" Do you mean that I can imagine a chat (i.e. \"mining\" ) my Calibre directory?",
              "score": 2,
              "created_utc": "2026-02-02 16:05:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o36mjd7",
                  "author": "mythrowaway4DPP",
                  "text": "With an mcp server handling the requests and handing them to a calibre API - why not?",
                  "score": 2,
                  "created_utc": "2026-02-02 16:56:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o38j6bf",
              "author": "ohhellnaws",
              "text": "Afaik you can pin mid chat. Same for agents. Have some with customer prompts for quick chat style, some with attached library, guardrails, etc and call upon them and swap out mid chat. Best feature not anywhere else.",
              "score": 2,
              "created_utc": "2026-02-02 22:15:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pb249",
                  "author": "sachama2",
                  "text": "A tutorial somewhere?",
                  "score": 1,
                  "created_utc": "2026-02-05 11:59:03",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34rav1",
          "author": "allulcz",
          "text": "Something to note, I use their API for free now and I am more than happy. I use Mistral Small 3.2 and I am very surprised how good it is. I use it for automation, classification, and text parse. Just surprised how well it works.",
          "score": 6,
          "created_utc": "2026-02-02 10:10:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o37bkul",
          "author": "Dadinek",
          "text": "I don't use ChatGPT because their business model is just shitty. Every innovation is meant to swallow more personal data.",
          "score": 5,
          "created_utc": "2026-02-02 18:50:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34ecc9",
          "author": "uusrikas",
          "text": "Well, they kinda do the same thing but ChatGPT is better at it. I don't use ChatGPT because they are big Trump donors and I don't want to support that. Having two subscriptions would be pointless. Gemini is better than both functionally.",
          "score": 18,
          "created_utc": "2026-02-02 08:05:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34kom4",
          "author": "Gold-Guess4651",
          "text": "Mistral le chat is GDPR-compliant so has much better privacy than chatGPT. It's not an additional benefit next to using chatGPT but is certainly a benefit of le chat over chatGPT.",
          "score": 9,
          "created_utc": "2026-02-02 09:06:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o34xurd",
              "author": "Spiritual-Plant3930",
              "text": "There is no privacy when it comes to any LLM; otherwise, they wouldn't work. \n\nLLMs are \"leaking\" all the time by design.\n\nNeural networks can't be privacy-conscious. \n\nIt's like telling a kid to learn without any access to knowledge (can't use the internet, can't read books, etc.).\n\nTo have privacy, you have to know where the info is coming from (to know it's private info) - LLMs don't exactly know where the info came from.\n\nFor more, this one is a good start. \nhttps://youtu.be/_3okhTwa7w4",
              "score": -6,
              "created_utc": "2026-02-02 11:10:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o356xg9",
                  "author": "Gold-Guess4651",
                  "text": "I didn't say le chat is fully private, I said that due to GDPR-compliance privacy protection is better (or perhaps not as terrible if you like) than e.g. chatGPT. This is because le chat doesn't use chats or any data in the chat to train the LLM, all data are stored at European servers (and therefore cannot be accessed by the USA government), and doesn't share info with third parties.",
                  "score": 8,
                  "created_utc": "2026-02-02 12:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o35fp0g",
          "author": "aajl2",
          "text": "Try to make a single payment $10 on open router so you'll access to openai, mistral other providers and many more LLM. Why? Testing, comparing, evaluating the best that fit your needs. I use gpt5-codex for python learning and it's been great",
          "score": 3,
          "created_utc": "2026-02-02 13:21:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pb6wa",
              "author": "sachama2",
              "text": "Thank you",
              "score": 1,
              "created_utc": "2026-02-05 12:00:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p7s0y",
          "author": "VohaulsWetDream",
          "text": "Mistral is better with *some* programming tasks. Also is better with \"gray zone\" questions, like help me with this software protection.",
          "score": 2,
          "created_utc": "2026-02-05 11:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35uhxf",
          "author": "martapap",
          "text": "I started using mistral recently. It is incredibly dumb at following directions. Seems like it has a mind of its own ane just gives you whatever it wants instead of what you ask for. With the exception of agents. I created a couple of agents using language another model gave me and it was able to follow directions then.",
          "score": 4,
          "created_utc": "2026-02-02 14:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34sfep",
          "author": "crazyserb89",
          "text": "Iâ€™m paying for ChatGPT and Gemini and I was testing Le Chat too. Honestly itâ€™s far behind those, but itâ€™s a good concept. If they improve it in future I would be glad to move there",
          "score": 2,
          "created_utc": "2026-02-02 10:21:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35wg1e",
              "author": "TheMrLexis",
              "text": "What can they do for improving Le Chat?",
              "score": 3,
              "created_utc": "2026-02-02 14:53:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o360hus",
                  "author": "MattyGWS",
                  "text": "For starters, it doesnâ€™t do coding as well as chatgpt. \n\nWould be nice if it had a voice chat feature too",
                  "score": 1,
                  "created_utc": "2026-02-02 15:13:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o35z3u2",
                  "author": "crazyserb89",
                  "text": "Custom chats, clipboard copy pasting doesnâ€™t work on iOS, text to speech is trash and thereâ€™s no live speech. More integrations, more optimizations etc.. I mean the price is not correct even, you can take Gemini Plus for few bucks only and to get way more",
                  "score": -1,
                  "created_utc": "2026-02-02 15:06:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qry40r",
      "title": "Replace github copilot with Mistral",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "author": "InternalBroad2522",
      "created_utc": "2026-01-31 09:39:58",
      "score": 39,
      "num_comments": 11,
      "upvote_ratio": 0.96,
      "text": "Hi all! I would like to replace Github Copilot with Mistral for coding in VSCode IDE. What can I do?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qry40r/replace_github_copilot_with_mistral/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2rk80x",
          "author": "scara1701",
          "text": "Does it have to be in vscode? I guess you could run mistral vibe in a terminal window.",
          "score": 5,
          "created_utc": "2026-01-31 09:48:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2vlko5",
              "author": "LoadZealousideal7778",
              "text": "Or in the Jetbrains IDE of your choice",
              "score": 3,
              "created_utc": "2026-01-31 23:25:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ji0p2",
              "author": "InternalBroad2522",
              "text": "But Mistral Vibe does not have autocompletion right?",
              "score": 1,
              "created_utc": "2026-02-04 15:09:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2roc3i",
          "author": "katafrakt",
          "text": "Mistral Vibe supports ACP, so any VSCode extension supporting ACP would do. I'm not too familiar with this ecosystem, so I won't give any recommendations.",
          "score": 3,
          "created_utc": "2026-01-31 10:27:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2szqsy",
          "author": "kiwibonga",
          "text": "There's a mistral vibe extension that lets you have the CLI in VSCode. It's mostly a convenience thing that saves you the trouble of launching the terminal and setting the working directory.",
          "score": 2,
          "created_utc": "2026-01-31 15:45:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2utlgd",
          "author": "Bob5k",
          "text": "Have in mind that you either pay for API usage of devstral or accept the quite mediocre quota allowance on experiment plan.",
          "score": 2,
          "created_utc": "2026-01-31 21:02:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2xnbbp",
              "author": "deegwaren",
              "text": "Oh? Didn't they just include vibe-cli usage in their pro plan? Meaning it's included like Claude code usage in the Claude Pro plan.",
              "score": 1,
              "created_utc": "2026-02-01 07:30:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o2yd1vv",
                  "author": "Bob5k",
                  "text": "They included cloud vibe usage afaik, don't know about vibe cli tbh and not sure on the quota allowance, i still think the cli falls under Mistral ai studio.",
                  "score": 1,
                  "created_utc": "2026-02-01 11:26:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ro18m",
          "author": "opsmanager",
          "text": "Im using the Continue extension, works reasonably well. I havent yet figured out how to make it as seemless as the copilot extension with regards to accessing the repository files. But im sure its just me missing something obvious.",
          "score": 2,
          "created_utc": "2026-01-31 10:24:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2uj3bq",
              "author": "vienna_city_skater",
              "text": "Continue is soso, good for code completion, but agent mode sucks, Roo Code works well for agentic coding in VS Code, but the TUIs are much better. I switched everything to OpenCode because I mix models a lot. However, so far I have not find a way to get access to the free devstral with my Le Chat Pro subscription outside of vibe CLI.  \nEDIT: I think I found the problem, I used the API key from La Platforme Admin Panel not from the AI Studio VIBE CLI section, so I was charged on-the-go.",
              "score": 3,
              "created_utc": "2026-01-31 20:10:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qqw89j",
      "title": "Made myself a LeChat application on linux",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qqw89j/made_myself_a_lechat_application_on_linux/",
      "author": "MattyGWS",
      "created_utc": "2026-01-30 05:03:06",
      "score": 32,
      "num_comments": 4,
      "upvote_ratio": 0.91,
      "text": "Ok I'm no programmer, but I just had some fun learning how to build 'web apps' with Electron. I made a lil desktop icon too (in gimp). So now I have my own desktop application for Mistral! \n\n\n\nhttps://preview.redd.it/900xz4j75fgg1.png?width=2005&format=png&auto=webp&s=fdbbb04df3c14f515991184693b4fa46119766e0\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qqw89j/made_myself_a_lechat_application_on_linux/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2lf64l",
          "author": "AdIllustrious436",
          "text": "Great! Just for you to know, you can achieve the same result in one click with Chromium PWA, which install websites as applications on the system.",
          "score": 4,
          "created_utc": "2026-01-30 12:55:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2mcd54",
              "author": "MattyGWS",
              "text": "Yea I know that's how I normally do it but I wanted to learn how Electron apps are made, seemed like a great yet simple example to bring LeChat to desktop. :)",
              "score": 6,
              "created_utc": "2026-01-30 15:43:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o36s7md",
              "author": "LoadZealousideal7778",
              "text": "That seems to have issues with Apple Music. Will try the Electron method next. Or maybe google if someone already did.",
              "score": 1,
              "created_utc": "2026-02-02 17:22:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o2xzts3",
          "author": "LearningPodd",
          "text": "Good job! I'm also starting to creat stuff with AI â˜ºï¸ It's so much fun and the more people that creat things themselves, the less power companies will have over our products  ðŸ‘",
          "score": 2,
          "created_utc": "2026-02-01 09:26:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwdi1e",
      "title": "Integrate Mistral Vibe in VS Code (like Claude Code extension)",
      "subreddit": "MistralAI",
      "url": "https://zatteo.com/en/integrate-mistral-vibe-in-vs-code-like-claude-code-extension/",
      "author": "Tanuki__",
      "created_utc": "2026-02-05 06:09:26",
      "score": 20,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwdi1e/integrate_mistral_vibe_in_vs_code_like_claude/",
      "domain": "zatteo.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3ob27i",
          "author": "Old-Age6220",
          "text": "YES! This is the main reason I've been neglecting Mistral vibe, because I definitely want it to be on Visual Studio Code, not in any external console / window",
          "score": 3,
          "created_utc": "2026-02-05 06:30:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ocghy",
              "author": "Tanuki__",
              "text": "The second thing I miss is that Claude Code extension \"knows\" the current file opened in VS Code  and it is sometimes very practical. But I think it needs a real extension for this one.",
              "score": 2,
              "created_utc": "2026-02-05 06:42:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pvjlx",
          "author": "crazyfuffi",
          "text": "Anything similar for pycharm?",
          "score": 2,
          "created_utc": "2026-02-05 14:07:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r601j",
              "author": "Tanuki__",
              "text": "No idea I don't know pycharm. But you can ask Le Chat, it helped me find this solution!",
              "score": 1,
              "created_utc": "2026-02-05 17:51:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qb8pi",
          "author": "opsmanager",
          "text": "Oooh, learned something new about VSCode today, thank you! This is awesome.",
          "score": 2,
          "created_utc": "2026-02-05 15:28:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ow0gq",
          "author": "_coding_monster_",
          "text": "Do we know if Mistral is developing a VSCode extension for its models?",
          "score": 1,
          "created_utc": "2026-02-05 09:46:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ozx0u",
              "author": "grise_rosee",
              "text": "It already exists but for entreprise users only: [https://marketplace.visualstudio.com/items?itemName=mistralai.mistral-code](https://marketplace.visualstudio.com/items?itemName=mistralai.mistral-code)",
              "score": 2,
              "created_utc": "2026-02-05 10:23:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sryfl",
          "author": "alexd_dev",
          "text": "Hey guys, \n\nI created a small vscode extension  inspired by opencode, while waiting for an official integration \\^\\^ [https://www.reddit.com/r/MistralAI/comments/1qwz8gw/a\\_small\\_quick\\_and\\_dirty\\_vscode\\_extension\\_for/](https://www.reddit.com/r/MistralAI/comments/1qwz8gw/a_small_quick_and_dirty_vscode_extension_for/) \n\nThis is my first vscode extension, so I did not have the marketplace setup, download is unfortunately manual for now. Will surely do this weekend ...",
          "score": 1,
          "created_utc": "2026-02-05 22:25:23",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qr2987",
      "title": "How do you use vibe effectively?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qr2987/how_do_you_use_vibe_effectively/",
      "author": "hyper_plane",
      "created_utc": "2026-01-30 10:51:43",
      "score": 14,
      "num_comments": 8,
      "upvote_ratio": 0.89,
      "text": "I am using the Vibe CLI to work on a project. I feel like the coding capabilities of the underlying devstral model are pretty good, but I have the impression that I am not using it right. Has anybody here tips and tricks on how to really take the best out of this tool? What do you put in your instructions? Do you write instructions for each project? How do you smoothly integrate with your IDE or code editor?\n\nI suppose we are all still learning how to use coding agents effectively, but if you have some really good tips, please share them here! ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qr2987/how_do_you_use_vibe_effectively/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o2naf3s",
          "author": "RegrettableBiscuit",
          "text": "Write an AGENTS.md file that explains what your project is, how it is structured, how to extend it, coding guidelines, etc.\n\n\nWhen prompting, provide a path to example code files similar to what you are building so the LLM can emulate your code base's approach.\n\n\nWrite specific prompts that explain exactly what you want the LLM to do in detail.\n\n\nMake each prompt limited in scope and review after the LLM is done to make sure it's on the right track.Â ",
          "score": 5,
          "created_utc": "2026-01-30 18:15:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kyvx2",
          "author": "EzioO14",
          "text": "I only use vibe cli for documentation and nothing else",
          "score": 3,
          "created_utc": "2026-01-30 10:56:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kzp6q",
          "author": "chebum",
          "text": "This presentation from Jake Nations (Netflix) describes a framework of working with AI assistants which seems to provide best results in my experience : https://youtu.be/eIoohUmYpGI?si=rr5O4GLdLJTzOgPS",
          "score": 3,
          "created_utc": "2026-01-30 11:03:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2l7l6x",
          "author": "AriyaSavaka",
          "text": "General rule of thumb for any coding agent would be effective system instruction that enforce strict test driven development with frequent atomic commit. And have git hooks already set up for running unit tester/formatter/linter/checker after every turn.",
          "score": 1,
          "created_utc": "2026-01-30 12:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2pieyv",
          "author": "Bob5k",
          "text": "Using Clavix to help with prd and input. \nHowever - i find the limit on experiment plan quite low for serious work, so usually I'm using vibe whenever j just want to switch from Claude code combined with Kimi K2.5.",
          "score": 1,
          "created_utc": "2026-01-31 00:46:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2quc8z",
          "author": "Holiday_Purpose_3166",
          "text": "For context, I spent billions in tokens last year in prototypes and public facing, production work and it's mostly financial models interacting with 6 figures contracts. Shrimp in my circles, small, but produces income. \n\nRoughly, 70-80% of the jobs produced last year, had to be polished using SOTA closed source models, but I'm seeing that gap closing considerably fast and Devstral Small 2 beats GPT-OSS-120B on the same tasks, and has been doing more work than any OSS model up to 235B model I've used last year.\n\nI wish I could speak better about Mistral Vibe, as my experience was short-lived due to context bloat and errors - using the local Devstral Small 2 UD-Q4_K_XL which also had its issues with inference engines and stale quants. This is fixed by now but I've got plenty of experience with it since then, and I've been riding the Q8_0 which has been God. \n\nI assume Devstral 2 will be in the same ballpark with a better punch in knowledge. \n\nWhen Mistral Vibe launched, the context management blew up quickly and it often derailed. It may not be the case now based on what I've seen. \n\nBased on experience, any model is as good as the agentic framework is operating on, and how good is your context engineering for that specific setup. \n\nMost likely it will be your context work. I polished mine by repeating different cases in my codebases, using different prompts styles until I had repeated, positive results. \n\nNo walls of text prompts. Less is more, but not bare. \n\nKeep working out the environment you're using until you get better. It pays long-term, a LOT. \n\nIf you haven't produced reliable outputs every time, and you start jumping around different agentic tools and models, I guarantee you'll be frustrated. \n\nI found Devstral to work better with Kilocode with a custom agent I made, that saves me over 90% of context over original agents. Opencode works very well too, but Kilocode offers me Orchestrator choice which cuts most context bloat into smaller jobs for my custom agent. I might try Mistral Vibe back again later. \n\nMy base template for all repos must always include a folder for docs and that will generally include a blueprint with project spec overview, and a README.md which explains how the project works downstream. \n\nMost folks likely use AGENTS.md for repo context, which is generally fine. I like to break my docs modular enough, that isn't going to bloat the agent, but isn't hard enough to maintain either. \n\nThey complement each other. (How it works and where). Sometimes I ditch the README.md when I know the job doesn't require it, and that keeps my model light.\n\nIf I have a mono repo with different frameworks, I still use a single blueprint for the whole codebase and a single README.md, but I create separate sub-folder docs for each framework with their own framework-specific spec overview and directories. \n\nIn this last case, if I had to work in the front-end, I'd feed only the framework doc and not the whole blueprint and README.md. \n\nIf the work involved another framework, you could add the whole codebase blueprint and the other framework work doc too, and it works itself out. \n\nYou essentially make a modular doc system that doesn't add too much technical debt to maintain, and can be used whenever needed without giving the whole elephant every time. \n\nWhen it comes to prompt style, just simply write one and ask the model to format in a way it would understand and execute. Same with the documents. Devstral 2 models can surprisingly produce extensive documents if needed. \n\nI've used prompt styles from GPT-OSS-120B which broke Devstral. This is important.",
          "score": 1,
          "created_utc": "2026-01-31 05:53:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2le3ca",
          "author": "clayingmore",
          "text": "I'm not sure how 'basic' you're after. Have you got to the point where you are creating an [AGENTS.md](http://AGENTS.md) file in the root directory for any project? Also I use Claude Code and OpenCode rather than Vibe CLI but I am under the impression it works the same way. I have a Chinese Wall in between my IDE and the CLI so I'm mostly using the IDE for my own review and tinkering.\n\nAs a general approach, I try to create a Reason-Act agent pattern on a bigger scale. I create a constitution for the project, describing what the project is doing, why, what the tech stack is. Then I 'discuss' the entire project with my LLM to get to a point where I am confident that the model's semantic understanding is in line with mine. This coincidentally pushes the 'model' to think more and lay out a specific architecture as well as catch things I missed which I then sign off on.\n\nIf my [AGENTS.md](http://AGENTS.md) file, style guide, [ARCHITECTURE.md](http://ARCHITECTURE.md) file, unit tests, and any other supplementary plans are in good shape then the project can 'go'. Coincidentally, the coding LLMs are great at reviewing these documents as well.\n\n\"Yes.\" \"Yes.\" \"Yes.\" \"No change this.\" \"Yes.\" \"Yes.\"\n\nThe coding agent then does a huge portion of the project faster than I could do it, and in many cases better than I could do it. \n\nMake sure to insist on modularity so the whole thing doesn't break at once, effective version control so that you can roll things back, triple check relevant security issues, etc.\n\nThe model WILL make mistakes all the time, but it can also establish its own test driven development cycle in which it is immediately proceeding to fix those mistakes.",
          "score": 1,
          "created_utc": "2026-01-30 12:48:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o2kzx26",
          "author": "Eastern-Group-1993",
          "text": "I just generate code samples or ask questions or use it as a shortcut to what do I need to search for in documentation.  \nIf gpt-oss:20b isn't enough I either use claude or gpt-5.1 via [duck.ai](http://duck.ai) or I just try to figure it out on my own.\n\nGenerally I don't really full blown rely on it, I tried to make Github Copilot generate 3 python scripts:  \nGear Ratio to RPM converter, RPM to Gear Ratio converter, Gear Ratio generator using amount of frames between 200 RPM periods on a 1.000 gear ratio, which went as well you imagine.  \nI basically used 100% of the free monthly limit in 1-3 hours and the scripts barely worked(they didn't), I don't know how people manage to vibe code anything at all.\n\nAt least gpt-oss:20b is way better than whatever facebook puts into meta AI/whatsapp.  \nI wanted to go to sleep at 3am after playing RDR2, used LLaMa 4 ONCE and it's fully convinced Red Dead Redemption 2 has a \"save and quit\" button.  \nI would have to be more desperate than having access to 8kbps internet(which enables use of meta ai via whatsapp), at least gpt-oss:20b is somewhat usuable for most scenarios(except vibe coding, it's okay for some simple sample code that you have to transform by hand into your data structure) even without RAG.           \n\n  \nMaybe if you use something on the bleeding edge like Claude Opus 4.5/Claude Sonnet 4.5 with a pro/max subscription or a lot of cash spent on API calls you can get anywhere at all with those tools.",
          "score": -2,
          "created_utc": "2026-01-30 11:05:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtpcw5",
      "title": "The Mistral Chat website UI is a disaster",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "author": "Eddybeans",
      "created_utc": "2026-02-02 08:17:07",
      "score": 13,
      "num_comments": 22,
      "upvote_ratio": 0.68,
      "text": "My experience with Le Chat is a disaster when it comes to the UI\n\nFrequent loss of what I asked for after pressing the send button  \nchat keeps scrolling up after asking a follow up question so I have to scroll down every time\n\nthis is my experience on safari\n\ntested on le chat pro and free over the last year\n\nwhy can't we have a working desktop APP that works like GPT ? instead I had to make a web app...\n\nso sad because I love Mistral ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtpcw5/the_mistral_chat_website_ui_is_a_disaster/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o356fvu",
          "author": "Substantial-Yam3769",
          "text": "Agree, the UI needs a refresh.",
          "score": 3,
          "created_utc": "2026-02-02 12:19:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35qfnb",
          "author": "stjepano85",
          "text": "Firefox has issues. Works great for me in chrome based engines but firefox was awful",
          "score": 3,
          "created_utc": "2026-02-02 14:21:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34jsw4",
          "author": "Depressive-Marvin",
          "text": "Agree, especially Chat scrolling up drives me crazy. Itâ€˜ like they donâ€˜t user their own product else some developer would have fixed it. Itâ€˜s sad as the overall product is good.",
          "score": 4,
          "created_utc": "2026-02-02 08:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o350tz0",
          "author": "crazyserb89",
          "text": "iOS app isnâ€™t much better too. Some basic things donâ€™t work.",
          "score": 2,
          "created_utc": "2026-02-02 11:36:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o351y35",
          "author": "inyofayce",
          "text": "I dont know but both ios app and web works fine! Havent had any issues. Unlike some of you, I am looking forward for a macos app.",
          "score": 2,
          "created_utc": "2026-02-02 11:45:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35fmg2",
          "author": "ShiroCOTA",
          "text": "Same with Safari and Ecosia browser. Frequently my questions simply disappear after sending them, or I get an network error on a regular basis. And the chat randomly scrolling up after placing a prompt drives me crazy.",
          "score": 2,
          "created_utc": "2026-02-02 13:20:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35ldje",
          "author": "JuiceOwn313",
          "text": "Iâ€™ve been using it daily for over a year, and never had any issues whatsoever",
          "score": 2,
          "created_utc": "2026-02-02 13:53:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34gb7o",
          "author": "Icy_Distribution_361",
          "text": "Yes I agree. I don't need a desktop app though I'm fine with browser page and actually prefer it, but these small things should be fixed more swiftly. It's not so hard to not make the page scroll up every damn time.",
          "score": 3,
          "created_utc": "2026-02-02 08:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34md2y",
          "author": "cosimoiaia",
          "text": "It's your browser.",
          "score": 2,
          "created_utc": "2026-02-02 09:22:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o34rne0",
          "author": "Jazzlike-Spare3425",
          "text": "I am also not fond of the mobile app as someone who uses an iPad with Magic Keyboard. It doesn't have a sidebar and it doesn't support keyboard shortcuts. I ended up basically just using the Mistral API to try and build my own Le Chat that I can use across my phone, tablet and laptop with a system-native UI with all the convenience features I missed in the Le Chat ecosystem.",
          "score": 1,
          "created_utc": "2026-02-02 10:13:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o35xfd3",
          "author": "schacks",
          "text": "I agree, it's not optimal. I use an app called MindMac to interface with various LLM's and it works fine with LeChat.",
          "score": 1,
          "created_utc": "2026-02-02 14:58:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o363ehy",
          "author": "deadfantasy",
          "text": "Le Chat's UI on the web works great for me on firefox but the mobile app on Android is ... a *choice*, to say the least.",
          "score": 1,
          "created_utc": "2026-02-02 15:27:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o36dfal",
          "author": "silurosound",
          "text": "Wait till you see the Mistral AI Studio page... it has a background animation that's pretty cool but really slows things down.",
          "score": 1,
          "created_utc": "2026-02-02 16:14:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3bc081",
          "author": "ExtentHot9139",
          "text": "What is sad is that you use Safari",
          "score": -1,
          "created_utc": "2026-02-03 09:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3beddh",
              "author": "Eddybeans",
              "text": "What is sad is trolls like you. Enjoy your sad life",
              "score": 1,
              "created_utc": "2026-02-03 09:49:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3bfzc0",
                  "author": "ExtentHot9139",
                  "text": "Safari is the troll and you still use it",
                  "score": -1,
                  "created_utc": "2026-02-03 10:05:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34gaod",
          "author": "nycigo",
          "text": "Chatting on the web is something else lmao ðŸ¤£",
          "score": 0,
          "created_utc": "2026-02-02 08:23:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qustvg",
      "title": "14.99 USD vs 17.99 EUR for Pro ??",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qustvg/1499_usd_vs_1799_eur_for_pro/",
      "author": "SubstantialFinance89",
      "created_utc": "2026-02-03 14:06:38",
      "score": 12,
      "num_comments": 13,
      "upvote_ratio": 0.68,
      "text": "How is that possible??",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qustvg/1499_usd_vs_1799_eur_for_pro/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3clke9",
          "author": "NovaDarkFox",
          "text": "perhaps, they are trying to attract American users, who use ChatGPT and others much more frequently, to Le Chat.",
          "score": 9,
          "created_utc": "2026-02-03 14:49:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3codme",
          "author": "Cool-Chemical-5629",
          "text": "European signing up to Mistral be like\n\nhttps://preview.redd.it/xl8e52q8oahg1.jpeg?width=374&format=pjpg&auto=webp&s=0af92085bd710eb0c7a6ca5825ae5465c563fb8c",
          "score": 19,
          "created_utc": "2026-02-03 15:03:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hhsz8",
              "author": "nycigo",
              "text": "Mistral's API software is very good.",
              "score": 1,
              "created_utc": "2026-02-04 06:11:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3hxm0t",
                  "author": "Jebble",
                  "text": "\"API software\" is a pleonasm.",
                  "score": 1,
                  "created_utc": "2026-02-04 08:31:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cehfp",
          "author": "telsaton",
          "text": "Euro includes tax",
          "score": 24,
          "created_utc": "2026-02-03 14:12:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ci2oi",
              "author": "DrPinguin98",
              "text": "14,99USD are 12.7190â‚¬ + tax (Germany 19%) that's just 15,14â‚¬",
              "score": 17,
              "created_utc": "2026-02-03 14:31:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3dzblk",
                  "author": "HebelBrudi",
                  "text": "Yeah, their pricing unfairly penalizes EU customers. People who say this is because of VAT apparently have never heard of an exchange rate.",
                  "score": 8,
                  "created_utc": "2026-02-03 18:41:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3ktze5",
                  "author": "WildStar_81",
                  "text": "They can't adjust usd prices every month. The dollar lost 20% in the last year to Euro.",
                  "score": 1,
                  "created_utc": "2026-02-04 18:50:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3cxjnm",
          "author": "BrucellaD666",
          "text": "I have since canceled my Mistral account but when I was paying for it and I'm in the US it was $18 or 17.99.",
          "score": 2,
          "created_utc": "2026-02-03 15:48:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3f49ma",
          "author": "crazyserb89",
          "text": "Prices in the USA usually exclude sales tax, while in the EU, VAT is always included in the final price.",
          "score": 2,
          "created_utc": "2026-02-03 21:52:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwu664",
      "title": "Am I using it wrong?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qwu664/am_i_using_it_wrong/",
      "author": "Background_Gene_3128",
      "created_utc": "2026-02-05 19:00:55",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.74,
      "text": "I unfortunately think LeChat is close to useless. But is it me who is using it wrong or what? \n\nI really want to do the switch, but itâ€™s literally useless. \n\nE.g., I have a a complex â€œpeople situationâ€ within a â€œassociationâ€ \n\nIt consist of meeting resumes, a legal document that defines legislation on the specific area, mails in PDF formats. \n\nI have somewhat 20 documents uploaded as files in a project. \n\nIt kinda scans them and makes a plan, but the details are shit. \n\nSo e.g., I used 20 minutes to explain who is who, even though it was described in the first message to it. \n\nThen I spent 20 minutes to clear up that a march meeting was out of question (one of the documents specifically describes to process of how, when, where and who will arrange this meeting) \n\nAnd it keeps suggesting that we do it ourselves without those Iâ€™ve said 20 times must fucking hold the meeting. \n\nThen it seemed it actually got that part right - nice. 2 messages later and everything was one big mixup again. \n\nAnd this shit just continues. \n\nDid the same in gpt - thought for a good 5-6 minutes, got it 95% right. Just had to clear up a few mistakes and off we go. \n\nThis is the same store every time I use mistral. Also with coding, less complex tasks etc. \n\nit forgets or doesnâ€™t understand explicitly. \n\nI have the â€œproâ€ paid version of both chats. What the fuck am I doing wrong? I really, really wanna go EU, but well.. yeah Iâ€™m giving up ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qwu664/am_i_using_it_wrong/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3ro9i8",
          "author": "b3dx",
          "text": "I had a similar issue with a less complex task. It kept making up online references with wrong information. And every time I got it to acknowledge that the sources are hallucinations it made up a new one.",
          "score": 4,
          "created_utc": "2026-02-05 19:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rq4pl",
          "author": "PigOfFire",
          "text": "Something is off with large, itâ€™s large, yeah, but it has often mixed up idea about who is saying what, it lacks depth of understanding. Itâ€™s a bummer. Gemini 3 Flash is like perfect model for its price and a showcase what modern models are like. Large is more like GPT-3.5 sometimes.",
          "score": 2,
          "created_utc": "2026-02-05 19:23:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3rpsfu",
          "author": "Wise-Artichoke-3808",
          "text": "Like my experience. A rollercoaster. One time I want to quit all other service providers in the other I just try to comprehend how could it barf together the output...",
          "score": 1,
          "created_utc": "2026-02-05 19:21:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s9er0",
          "author": "aletheus_compendium",
          "text": "seems notebooklm would be better tool for this project",
          "score": 1,
          "created_utc": "2026-02-05 20:55:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3sax4b",
              "author": "Background_Gene_3128",
              "text": "Probably would be, but Iâ€™m really trying to degoogle my life, and that would really hurt ðŸ˜‚",
              "score": 1,
              "created_utc": "2026-02-05 21:02:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3t32mw",
                  "author": "NullSmoke",
                  "text": "I feel your pain there. NotebookLM is the sole reason I'm paying for the google AI plan, I REALLY want to rid myself of that, but there's no good alternative to NotebookLM anywhere that I can find, neither commercial nor self hosted...\n\nOne would think that good self hosted alternatives would be available now...",
                  "score": 1,
                  "created_utc": "2026-02-05 23:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3t74e9",
          "author": "crazyserb89",
          "text": "Yeah it seems like a beta product. Great design and feature concept, but in reality is below average. It seems they are focusing on developing solutions for companies so I donâ€™t think it gonna change much for us..",
          "score": 1,
          "created_utc": "2026-02-05 23:46:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvs8zm",
      "title": "Le chat mixing informationfrom unrelated chats?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qvs8zm/le_chat_mixing_informationfrom_unrelated_chats/",
      "author": "Inconspicuouswriter",
      "created_utc": "2026-02-04 15:54:58",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "So I've  come across an odd feature (don't  think its intentional...) so I've created various project folders for different projects, all with unrelated themes. \n\nWhen i ask it to complete an independent task in a totally unrelated project and new chat window, it somehow references concepts from the other project folders and windows. Is this normal? I tell it not to and correct it of course, however when you straight out ask it if it can draw info. From another chat, it tells you it can't and each chat is self-contained. Very odd?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qvs8zm/le_chat_mixing_informationfrom_unrelated_chats/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o3k6dyg",
          "author": "Square-Definition29",
          "text": "There is a box above your project library that allows you to include discussions from other projects as context. I believe the box is checked by default.",
          "score": 3,
          "created_utc": "2026-02-04 17:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lucla",
          "author": "andriatz",
          "text": "It uses memory. I disabled it because, in addition to this problem, it also limits the comprehension of long documents.",
          "score": 3,
          "created_utc": "2026-02-04 21:42:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qtni81",
      "title": "Is instruct variant of Ministral 3 14B available in completion API?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1qtni81/is_instruct_variant_of_ministral_3_14b_available/",
      "author": "agentgoose007",
      "created_utc": "2026-02-02 06:28:55",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.84,
      "text": "Hey folks!\n\nIn the official docs I could find only these labels: ministral-14b-2512 and ministral-14b-latest\n\nhttps://docs.mistral.ai/models/ministral-3-14b-25-12\n\nThe weights tab lists three options:\nbase, reasononig and instruct.\n\nSo which one do I get when I call a completion API https://api.mistral.ai/v1/chat/completions and pass ministral-14b-2512?\n\nIs it possible to explicitly specify that I choose instruct variant?\n\nI know that the weights are open and I can self-host it in a cloud. But I'd prefer to pay to Mistral directly omitting the providers.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1qtni81/is_instruct_variant_of_ministral_3_14b_available/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "o346mfd",
          "author": "LeRouxGongle",
          "text": "As of now, when you call the Mistral API with â€˜ministral-14b-2512Â´ or Â´ministral-14b-latestâ€™, you are using the base pre-trained model, exposed through the chat/completions API (i.e. wrapped with a chat template).\n\nThe API does not currently allow you to explicitly select the instruct variant (or other variants like reasoning) via the model label.\nThe instruct variant is available as open weights, so if you specifically need that checkpoint, self-hosting (or using a third-party provider that exposes it) is required for now.\n\nMistral's official hosted API currently exposes a single managed version of Ministral 14B rather than separate base / instruct / reasoning endpoints.",
          "score": 2,
          "created_utc": "2026-02-02 06:54:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o348ojy",
              "author": "agentgoose007",
              "text": "Got it. Thanks for reply",
              "score": 2,
              "created_utc": "2026-02-02 07:12:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}