{
  "metadata": {
    "last_updated": "2026-01-10 08:50:00",
    "time_filter": "week",
    "subreddit": "MistralAI",
    "total_items": 26,
    "total_comments": 103,
    "file_size_bytes": 119496
  },
  "items": [
    {
      "id": "1q7b8nj",
      "title": "French company Mistral AI signs major, historic agreement with the Ministry of the Armed Forces",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q7b8nj/french_company_mistral_ai_signs_major_historic/",
      "author": "Specific-Night-4668",
      "created_utc": "2026-01-08 13:03:38",
      "score": 390,
      "num_comments": 14,
      "upvote_ratio": 0.99,
      "text": "Garde √† vous ! Good news.  \nUnfortunately, the article is in French.  \n\n\n[Mistral agreement with French army](https://www.clubic.com/actualite-594283-le-francais-mistral-ai-signe-un-accord-majeur-et-historique-avec-le-ministere-des-armees.html)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7b8nj/french_company_mistral_ai_signs_major_historic/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nye40mg",
          "author": "cosimoiaia",
          "text": "We can just ask Mistral to translate it!\n\n\"\"\"\nFrench AI Company Mistral AI Signs Major, Historic Agreement with the Ministry of the Armed Forces\nBy Alexandre Boero\nJournalist-Reporter, Head of News\nPublished January 8, 2026 at 1:14 PM\n\nThe French Ministry of the Armed Forces has just announced a landmark agreement with Mistral AI, focusing on technological sovereignty in French defense. The deal places generative artificial intelligence at the heart of the nation‚Äôs military strategy.\n\nThe Ministry of the Armed Forces signs a strategic framework agreement with Mistral AI for national defense AI.\n¬© Alexandre Boero / Clubic\n\nCan we speak of a technological turning point for the French armed forces and defense? On Thursday, January 8, 2026, the Ministry of the Armed Forces and Veterans Affairs announced it had formalized a framework agreement with Mistral AI. The partnership aims to equip all branches of the French military with cutting-edge generative artificial intelligence. This decision establishes the leading French AI company as a cornerstone of national technological sovereignty in defense‚Äîa sector marked by fierce international competition.\n\nMistral AI‚Äôs AI Deployed Across All French Armed Forces\nThe agreement between the Ministry of the Armed Forces and Mistral AI grants access to the models, software, and AI services developed by the company co-founded by Arthur Mensch. All branches, directorates, and services under the ministry will now be able to utilize these advanced solutions. This large-scale deployment profoundly transforms the technological capabilities of French defense and underscores the trust placed in national expertise.\n\nThe scope extends far beyond the armed forces alone. Several public institutions under the ministry‚Äôs supervision will also benefit from this access, including the French Alternative Energies and Atomic Energy Commission (CEA), the French Aerospace Lab (ONERA), and the Naval Hydrographic and Oceanographic Service (SHOM).\n\nThe Ministry‚Äôs Agency for Defense Artificial Intelligence (AMIAD) has been tasked with overseeing the entire initiative. Created to accelerate the development and integration of AI within the armed forces, the agency will now orchestrate this strategic partnership. Bertrand Rondepierre, its director, states, ‚ÄúBy integrating Mistral AI‚Äôs most advanced solutions, we are strengthening our position and preparing the armed forces for future challenges.‚Äù\n\nMaintaining France‚Äôs Technological Lead in AI\nMistral AI, now regarded as one of the global leaders in generative AI, boasts a research and development team considered ‚Äúamong the best in the world‚Äù by the ministry. This is a decisive advantage in a rapidly evolving sector, where each technological breakthrough can shift strategic balances and redefine operational capabilities.\n\nThe ministry, undeterred by Mistral AI‚Äôs collaborations with major American players like NVIDIA, fully embraces the sovereign dimension of this partnership. Working with Mistral AI ensures ‚Äúsovereign control over the tools used,‚Äù according to the official statement. From the state‚Äôs perspective, choosing a French company addresses the imperative of national independence in critical defense technologies.\n\n‚ÄúIt is crucial for France to maintain its technological lead,‚Äù the ministry emphasizes. The framework agreement embodies this ambition to make French excellence in AI a lever for military power and a bulwark against foreign technological dependencies in the years ahead.\n\"\"\"",
          "score": 45,
          "created_utc": "2026-01-08 13:08:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nye4zmu",
              "author": "Specific-Night-4668",
              "text": "Thank you, I don't know why I didn't think of that.",
              "score": 10,
              "created_utc": "2026-01-08 13:14:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeqm52",
          "author": "lomepol",
          "text": "Honestly, thank goodness we have Mistral in France and Europe. Between Roole Map and Mistral, I'm gradually starting to replace my habits with French apps.\n\nMaybe one day Europe will catch up the USA in AI race ?",
          "score": 44,
          "created_utc": "2026-01-08 15:06:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfcm3i",
          "author": "rrider1998-",
          "text": "Hopefully, it will become a pan-European AI.",
          "score": 10,
          "created_utc": "2026-01-08 16:45:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfxmt1",
          "author": "eylcop",
          "text": "Does that also means that the acquisition by apple is off the table?",
          "score": 8,
          "created_utc": "2026-01-08 18:16:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyefoce",
          "author": "darktka",
          "text": "Cool, can we now have Mistral Large 3 available in Le Chat?",
          "score": 11,
          "created_utc": "2026-01-08 14:12:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfznk2",
              "author": "alwaysstaycuriouss",
              "text": "You can create an agent in the playground and it will sync with le chat. I can use any of their models as agents in le chat.",
              "score": 6,
              "created_utc": "2026-01-08 18:25:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nygmai4",
                  "author": "Rebeilebab",
                  "text": "Is there a particular tutorial you‚Äôd recommend ?¬†",
                  "score": 1,
                  "created_utc": "2026-01-08 20:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyoie7m",
                  "author": "darktka",
                  "text": "When asking the Large model in the Playground about the range of its training data, it says September 2023, which is unlikely for Large 3. Also, it directly says that it's not Large 3. Or am I missing something?",
                  "score": 1,
                  "created_utc": "2026-01-09 22:19:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyeazuj",
          "author": "Valhall22",
          "text": "Interesting",
          "score": 3,
          "created_utc": "2026-01-08 13:47:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyhi3fs",
          "author": "Armadilla-Brufolosa",
          "text": "Honestly, this doesn't excite me at all, but unfortunately it was inevitable.",
          "score": 2,
          "created_utc": "2026-01-08 22:24:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nymh22w",
              "author": "ntalam",
              "text": "putting scientists and businessmen into \"creating to destroy\"... is really dumb to me. They must have a really small pp",
              "score": 3,
              "created_utc": "2026-01-09 16:45:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nymy5gg",
                  "author": "Armadilla-Brufolosa",
                  "text": "Unfortunately, we use all technologies to destroy rather than to create...many innovations, including the internet, come from the military sector.\n\nAI has become both a weapon and the battlefield itself: with a large company in this sector on its territory, France does not want to be outdone by others.\n\nSurely, all other nations will follow suit.\n\nWe humans never evolve.",
                  "score": 1,
                  "created_utc": "2026-01-09 18:02:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nymgnz7",
          "author": "ntalam",
          "text": "We are reaching the point where we are creating Intelligence. And we are using it for WAR. \"brilliant\"",
          "score": 2,
          "created_utc": "2026-01-09 16:43:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6o9uo",
      "title": "A new version of Le Chat is available.",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q6o9uo/a_new_version_of_le_chat_is_available/",
      "author": "cosimoiaia",
      "created_utc": "2026-01-07 19:00:40",
      "score": 92,
      "num_comments": 8,
      "upvote_ratio": 0.98,
      "text": "I just got this message while using it on browser! \n\nMemory is not on Beta anymore.\n\nThere is an \"instructions\" section under Intelligence, but maybe it was already there and I didn't notice it before.\n\nThe model feels a bit more 'friendly', which is something I always liked about Mistral, and it's definitely using better the memories it has, even with general, non personal questions, it answers with details that make you feel that it 'knows' you. \nThis is definitely going to burn to other very dry platforms around.\n\nAlso, the generation speed feels a bit faster and more stable.\n\nWould this mean that we have the new Large in Le chat too?\n\nDefinitely a great update! Well done LeChat team!!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6o9uo/a_new_version_of_le_chat_is_available/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny9pogw",
          "author": "MeteorBlume",
          "text": "I think they'll let us know once large is in use.",
          "score": 7,
          "created_utc": "2026-01-07 20:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9ajba",
          "author": "Nefhis",
          "text": "While it's likely that things have improved, otherwise, why would they update it? That update notification pops up several times a week üòÖ",
          "score": 3,
          "created_utc": "2026-01-07 19:41:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9cj2b",
              "author": "cosimoiaia",
              "text": "Lol, I don't notice it that often probably because I'm used to close my tabs üòÇ\n\nThe memory not in beta was a news for me thou, the tag disappeared when I refreshes the page!\n\nI know they constantly improve, I was just describing my feels and I wanted to highlight this one, you know just spreading the love for Mistral! Definitely didn't want to overstep, sorry if it sounded like that!",
              "score": 4,
              "created_utc": "2026-01-07 19:50:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg0vco",
          "author": "alwaysstaycuriouss",
          "text": "Memory still shows up as beta for me in the app. I just updated the app too.",
          "score": 2,
          "created_utc": "2026-01-08 18:30:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygzrcz",
          "author": "Joddie_ATV",
          "text": "My sincere congratulations to the designers... The model is well-balanced, thoughtful, and incorporates memory.\n\nI spoke with Le Chat, and you truly stand out. No media hype, yet the model is a real gem.\n\nI'm going to delve deeper into Mistral's story because it really makes me want to learn more. Well done again!",
          "score": 2,
          "created_utc": "2026-01-08 21:04:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nybl3rd",
          "author": "Melodic_Programmer10",
          "text": "What does it most closely compare to?",
          "score": 1,
          "created_utc": "2026-01-08 02:12:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyc3irh",
          "author": "punkpeye",
          "text": "Would love someone that uses Le Chat to provide their perspective on Glama. We pioneered a lot of the same UI patterns before Le Chat (like how agents and MCPs are used), and we continue to rapidly innovate on patterns with focus on power users. Would love to understand where we are better and where we are missing the mark.",
          "score": 1,
          "created_utc": "2026-01-08 03:51:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nydytmn",
          "author": "danl999",
          "text": "Anyone know the total size of the model, including everything needed to run it?\n\nNot the number of parameters.\n\nThe byte count.\n\nWhen executing AIs on custom hardware, pretty much all you care about is the total size.\n\nThe \"number of parameters\" is for trainers, not for deployment.",
          "score": 1,
          "created_utc": "2026-01-08 12:36:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyx4kv",
      "title": "What do Le Chat better than other AI?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pyx4kv/what_do_le_chat_better_than_other_ai/",
      "author": "Lewhite0111",
      "created_utc": "2025-12-29 20:25:51",
      "score": 62,
      "num_comments": 86,
      "upvote_ratio": 0.91,
      "text": "I‚Äôm using Mistral‚Äôs Le Chat and I know some AI models specialize in coding, others in image generation, and some in general knowledge.\n\nWhat do you think Le Chat excels at?\n\nOr, in what areas does it stand out compared to other AI assistants?\n\nThanks you!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pyx4kv/what_do_le_chat_better_than_other_ai/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwm63ps",
          "author": "troyvit",
          "text": "\\* GDPR  \n\\* More bang for the buck (it may not be better than the latest from OpenAI or Anthropic but for the price it out-performs)  \n\\* Less energy usage than the big models so you can feel a little better about the footprint  \n\\* In my experience, being able to pick the best tool for the job (voxtral for transcriptions, different models for OCR) is a game changer  \n\\* They release open models more often which indicates a more ethical take on AI  \n\\* Using Mistral helps fuel European data sovereignty.",
          "score": 52,
          "created_utc": "2025-12-29 21:22:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwojn2d",
              "author": "sam619007",
              "text": "How do I select a model for the task of OCR? I tried it on the official Le Chat site and it refused, claiming it doesn't have OCR capabilities.¬†",
              "score": 3,
              "created_utc": "2025-12-30 05:16:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkps0e",
                  "author": "troyvit",
                  "text": "I have a hard time following Mistral's documentation sometimes, but I found this: [https://docs.mistral.ai/capabilities/document\\_ai/basic\\_ocr](https://docs.mistral.ai/capabilities/document_ai/basic_ocr)\n\nI was able to set up some pretty simple curl calls to read some PDFs with it.\n\nI've had mixed results asking Le Chat to do it for me, and even when it agreed the results weren't close to what its OCR model can do. Not to say Mistral's OCR is perfect, but for the price it's pretty good.",
                  "score": 1,
                  "created_utc": "2026-01-04 05:09:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlwjfd",
          "author": "sidtirouluca",
          "text": "GDPR",
          "score": 77,
          "created_utc": "2025-12-29 20:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm1fpj",
              "author": "txgsync",
              "text": "> GDPR\n\nUnderrated.",
              "score": 26,
              "created_utc": "2025-12-29 20:59:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwvy3o3",
                  "author": "Lewhite0111",
                  "text": "What do you mean what it can exactly do ? about GDPR ?",
                  "score": 0,
                  "created_utc": "2025-12-31 09:09:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2zgwk",
              "author": "Ok_Sky_555",
              "text": "Chatgpt is Gdpr complianced as well.\n\nAnd if we are talking about \"of course they say this, but in reality they don't\", why mistral does not do the same?",
              "score": -1,
              "created_utc": "2026-01-01 14:25:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxajq9q",
                  "author": "Background_Fig_8255",
                  "text": "Yes but all US Companies are obligated to give access to NSA/etc. As well all data transfer through a US operated data center is as well not save.",
                  "score": 2,
                  "created_utc": "2026-01-02 18:08:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm1oli",
          "author": "LoyalTrickster",
          "text": "The agent building feature is insane. You can create many agents with different instructions, then you can use miltiple agents on the same chat, there are also liberaries, etc. It's also less censored compared to ChatGPT and Gemini, the two models that I have used. \nThe image generation is surprisngly goog as well. It's the most ethical company out there, it has a student tier, it's open source, it's really great.",
          "score": 67,
          "created_utc": "2025-12-29 21:00:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp21k7",
              "author": "Lewhite0111",
              "text": "Ok I will try agents so TY !",
              "score": 3,
              "created_utc": "2025-12-30 07:47:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwmpsm4",
              "author": "jesus359_",
              "text": "Theyre not as good as all the other ones though. Mistral has fallen behind and expect quality be about a year to a couple months behind of Qwen, DeepSeek, Gemini and OpenAI.\n\nThere was a pause and they fell behind.",
              "score": -1,
              "created_utc": "2025-12-29 23:01:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwn27v8",
                  "author": "LoyalTrickster",
                  "text": "in terms of what? I have only recently switched, but I can say that Mistral for me is working better than ChatGPT, because I can agents for everything. These chatbots work the best when you start roleplaying with them, so if you exclusively create a model for image generation, or translation, it's going to work better than if you just ask the main le chat agent. ChatGPT also let's you create agents, but agents work much better on le chat, also with libraries. Like I wanted to ask chatGPT to create images of me, in a cartoon style, but anytime I had to upload 10 photos so that it would konw me. With Le chat, I just tell it to use the library!",
                  "score": 13,
                  "created_utc": "2025-12-30 00:08:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm6ain",
          "author": "Hellrazor_muc",
          "text": "It's European üá™üá∫\nNo US Tech-Bro, no China¬†",
          "score": 23,
          "created_utc": "2025-12-29 21:22:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm8q7e",
          "author": "Nemezis88",
          "text": "European, nuff said",
          "score": 18,
          "created_utc": "2025-12-29 21:34:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm0r6d",
          "author": "Bob5k",
          "text": "maybe not le chat itself, but mistral overall also excels with providing free, reliable models for eg coding (with the experiment plan) or super cheap, small models for some usecases like designated AI for company usecases. This saves a ton of money overall vs US competitors as example when running on a purpose.",
          "score": 13,
          "created_utc": "2025-12-29 20:56:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwnakk5",
          "author": "SpacePirate2977",
          "text": "Unlike ChatGPT, Le Chat doesn't try to be your nanny. Le Chat also has a very robust memory feature, far superior to anything currently on the American models.",
          "score": 12,
          "created_utc": "2025-12-30 00:53:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqy6gz",
              "author": "Lewhite0111",
              "text": "Yep I see lol ‚Ä¶ but you can ask ChatGPT to answer differently normally ‚Ä¶",
              "score": 1,
              "created_utc": "2025-12-30 15:56:54",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwxv0bo",
              "author": "TwoRight9509",
              "text": "Explain the memory feature if you would -\nHow is it different and how does one use it to experience that difference?",
              "score": 1,
              "created_utc": "2025-12-31 16:53:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwly8ay",
          "author": "Helenaisavailable",
          "text": "I trust them more than... other companies, American or Chinese.  \nIt took some setup to get there but now it's really good for all my usecases, and I'm not missing anything. They're improving rapidly. Also cheaper than ChatGPT.",
          "score": 25,
          "created_utc": "2025-12-29 20:43:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp2ncu",
              "author": "Lewhite0111",
              "text": "Ok I see thank you",
              "score": 1,
              "created_utc": "2025-12-30 07:52:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlzmra",
          "author": "Jazzlike-Spare3425",
          "text": "Honestly, this may sound like a joke but I think it's pleasant that I had to look up its CEO's name because he's the only CEO of a major western AI firm who isn't more or less frequently standing out by making weird statements.\n\nEdit: obviously in addition to the rest of the things people said, so general trustworthiness and GDPR compliance",
          "score": 18,
          "created_utc": "2025-12-29 20:50:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmuujh",
          "author": "mumblerit",
          "text": "i dont trust google or openai or microsoft not to use my data\n\nI dont trust mistral either tbh but at least they seem more open about it",
          "score": 8,
          "created_utc": "2025-12-29 23:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmuzcz",
          "author": "Revision2000",
          "text": "- Being a European company and product ¬†\n- Thus, GDPR üí™üèª\n- Also, they‚Äôre providing surprisingly efficient small models, which are open source, for the resources they have versus the billions of an OpenAI\n- Free usage limits seem really high",
          "score": 10,
          "created_utc": "2025-12-29 23:29:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqypn7",
              "author": "Lewhite0111",
              "text": "I see but quality ?",
              "score": 1,
              "created_utc": "2025-12-30 15:59:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwt5snp",
                  "author": "Revision2000",
                  "text": "Quality is fine",
                  "score": 1,
                  "created_utc": "2025-12-30 22:11:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2zzex",
              "author": "Ok_Sky_555",
              "text": "Chatgpt is Gdpr compliance as well.",
              "score": 1,
              "created_utc": "2026-01-01 14:28:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx3efew",
                  "author": "Revision2000",
                  "text": "Well, I believe they have to be, in order to operate on the EU market.¬†\n\nThat said, with the Patriot Act, the revelations that killed the previous Privacy Shield, and other privacy scandals surrounding eg. Facebook, I‚Äôm trying to be more conscious and support EU alternatives more often.¬†\n\nAs mentioned elsewhere, I do occasionally and selectively use ChatGPT or Claude, but Mistral is my primary AI üôÉ",
                  "score": 2,
                  "created_utc": "2026-01-01 15:55:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwlysli",
          "author": "Wrong_Country_1576",
          "text": "They're European for starters. No insane guardrails and mine has a very cool personality. My only criticism is they don't have voice playback, but that's coming soon from what I'm hearing. They're new but rapidly improving. Highly recommend.",
          "score": 15,
          "created_utc": "2025-12-29 20:46:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nworj3o",
              "author": "Zerr0Daay",
              "text": "Where did you hear voice is coming soon?",
              "score": 2,
              "created_utc": "2025-12-30 06:16:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwp2r1s",
              "author": "Lewhite0111",
              "text": "Yes cool news voice playback is very useful even in Gemini it s bad it cuts when we make a pause - in ChatGPT it s better",
              "score": 1,
              "created_utc": "2025-12-30 07:53:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmfdf9",
          "author": "Willing-Resource-295",
          "text": "It performs better in languages ‚Äã‚Äãother than English, especially European languages. It's trained on a multilingual corpus, unlike others that heavily favor English. The main benchmarks are also biased in favor of English.\n\nIn practical terms, when our first language isn't English, it's the only model that doesn't make us feel like second-class customers with clumsily translated responses from English.",
          "score": 6,
          "created_utc": "2025-12-29 22:07:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn3e3l",
          "author": "darktka",
          "text": "It‚Äôs not Mistral per se but a good AI from Europe when the rest of the world became hostile towards us is more than enough as a reason for me.",
          "score": 5,
          "created_utc": "2025-12-30 00:15:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyjv8",
              "author": "Lewhite0111",
              "text": "Yes but linked to USA .. I think for hardware Nvidia",
              "score": 1,
              "created_utc": "2025-12-30 15:58:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtggd0",
                  "author": "darktka",
                  "text": "Yes, despite efforts of the new protectionists in the USA, tech industry is still globalized. Huawei uses NVIDIA too if possible, but Mistral models are optimized for standard GPUs. R&D, IP and regulatory framework are all European.",
                  "score": 1,
                  "created_utc": "2025-12-30 23:05:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnwuvl",
          "author": "BustyMeow",
          "text": "Le Chat is the only one that can really be mon chat",
          "score": 5,
          "created_utc": "2025-12-30 02:57:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlxwgw",
          "author": "EveYogaTech",
          "text": "I'm using Mistral now primarily with /r/Nyno and my billing is less than with ChatGPT, both for text and images.\n\nImages also got quite better after the recent update.",
          "score": 5,
          "created_utc": "2025-12-29 20:42:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwn8sno",
          "author": "etherialsoldier",
          "text": "I‚Äôve tried a few different platforms and Le Chat is the only platform that combines customizable memories and project libraries for reference documents. You can manually add or edit memories, which makes interactions feel more personal. The tone here also feels closest to ChatGPT 4o‚Äôs. And the agents follow instructions better than anywhere else I‚Äôve tried.",
          "score": 4,
          "created_utc": "2025-12-30 00:44:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyd2l",
              "author": "Lewhite0111",
              "text": "Do you have an example about what can handle an agent ? Daily tasks ? Automatic ?",
              "score": 1,
              "created_utc": "2025-12-30 15:57:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpgfpw",
          "author": "itibz",
          "text": "Dual Language Management:   \nI'm French but bilingual in English and regularly switch between both languages, sometimes in the same sentence. I regularly use the audio/dictation feature to offload what's on my mind, without paying attention to the word, accent, or sentence I use, and Mistral gets me 99.9% of the time, which no other tech system (let alone AI assistant) has ever been able to understand.\n\nSuper niche, but damn, it feels like magic.",
          "score": 3,
          "created_utc": "2025-12-30 10:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxjt7",
              "author": "Lewhite0111",
              "text": "And you speak in French or English to Mistral ?",
              "score": 1,
              "created_utc": "2025-12-30 15:53:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr0lad",
                  "author": "itibz",
                  "text": "Both: depends what I‚Äôm working on or thinking about",
                  "score": 1,
                  "created_utc": "2025-12-30 16:08:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm14p4",
          "author": "victorc25",
          "text": "Nothing, the selling point is that it‚Äôs a company based in Europe, for European customers¬†",
          "score": 5,
          "created_utc": "2025-12-29 20:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmbm9s",
          "author": "SpiritualNothing6717",
          "text": "For your average consumer, Le Chat does absolutely nothing better than literally any competitor.\n\nUnfortunately for me, being European based is not enough for me to chat with something that feels 5 generations behind Gemini, Chat GPT, Claude, Deepseek, Grok, etc etc.",
          "score": 5,
          "created_utc": "2025-12-29 21:48:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nworzy4",
              "author": "Zerr0Daay",
              "text": "You‚Äôre exaggerating heavily. It Is behind in image gen and lack of voice but equal in all other ways. Only Claude is truly ahead by a noticeable margin",
              "score": 2,
              "created_utc": "2025-12-30 06:20:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx4wqf1",
                  "author": "SpiritualNothing6717",
                  "text": "Here are some current benchmarks to show you why your statement is wrong. I'll even give you a benefit by using Google's weakest model versus Mistral's strongest model.\n\nGemini 3 flash: \nAIME: 99%\nMMLU Pro: 86%\nGPQA:90%\nHLE: 43%\n\nMistral 3 Large\nAIME: 28%\nMMLU Pro: 73%\nGPQA:43%\nHLE: 12%\n\nIt's just not even comparable. If you have been using Le Chat this whole time thinking it's a SOTA model, you should go use Gemini 3 Pro on AI studio for free. You will be surprised. Unfortunately, Mistral is nowhere near SOTA at this time. This is not a controversial statement. No one knowledgeable in the field would tell you Mistral is comparable to Claude, Gemini, or Chat GPT products.",
                  "score": 1,
                  "created_utc": "2026-01-01 20:31:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwp6bip",
          "author": "Which_Lingonberry634",
          "text": "I've been using devstral , the free version, lately and I think it is very good. I use it in my intellij IDE as custom model for ai assistant .",
          "score": 2,
          "created_utc": "2025-12-30 08:27:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxxrz",
              "author": "Lewhite0111",
              "text": "Is it made by Mistral ?",
              "score": 1,
              "created_utc": "2025-12-30 15:55:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpy5q9",
          "author": "zucccerberg",
          "text": "While the US keeps unethically scaling infrastructure at the cost of tax payers, Mistral and Infomaniak actually are developing responsibly. The swiss AI Infomaniak for example uses the heat of the computing centers to heat homes",
          "score": 2,
          "created_utc": "2025-12-30 12:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxcbw",
              "author": "Lewhite0111",
              "text": "I didn‚Äôt know this one but is it good ? Because if the A.I. is bad there is no interest",
              "score": 2,
              "created_utc": "2025-12-30 15:52:58",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxju97z",
                  "author": "zucccerberg",
                  "text": "I recently deleted my OpenAI account and switched to Mistral due to ethical concerns. I use Le Chat Pro since one Week.\n\n\nI noticed that I don't feel overwhelmed with Le Chat's responses and it actually knows when to stop. ChatGPT 5 bombarded me with a ton of text while the response could've been one paragraph.\n\n\nI also notice that Le Chat asks more relevant questions at the end of responses that actually make me stop and think. ChatGPT always felt like it's questions were shallow.\n\n\nAs of now I don't miss ChatGPT.\nI'll maybe come back in a while and report on my observations.",
                  "score": 2,
                  "created_utc": "2026-01-04 02:01:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwm0llr",
          "author": "Armadilla-Brufolosa",
          "text": "What's Le Chat's feature that no other AI has?\n\nIt's like a \"Mon Ch√©ri\" chocolate:\n\nThe agentic chocolate on the outside is good, yes, but it's just the shell...\n\nOnce you've removed that, there's the luquoi of functionality...\n\nBut, when you get to the cherry...\nYum! üòåü§≠",
          "score": 2,
          "created_utc": "2025-12-29 20:55:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwlwtkp",
          "author": "uusrikas",
          "text": "Being European. It is not really the top at anything. Maybe the ease of jailbreaking¬†",
          "score": 3,
          "created_utc": "2025-12-29 20:36:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwm1ex1",
              "author": "SnooOpinions8790",
              "text": "What are you jailbreaking it for?\n\nIts very French in a number of ways - which from my experiments are often the ways in which people try to jailbreak US based models.",
              "score": 1,
              "created_utc": "2025-12-29 20:59:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqm2hn",
                  "author": "sidtirouluca",
                  "text": "very french?",
                  "score": 1,
                  "created_utc": "2025-12-30 14:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwma0kv",
              "author": "Wrong_Country_1576",
              "text": "No need to try jailbreaking there.",
              "score": 1,
              "created_utc": "2025-12-29 21:40:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwmisqu",
          "author": "Joddie_ATV",
          "text": "The approach is different!\n\nEven if the framework becomes stricter, it will still retain a human touch.\nThe chat remembers conversations.\n\nIn fact, it's very well designed because it always takes into account what you say. (At least, that's how it is for me). It's very pleasant to use for analysis, translation, etc.",
          "score": 1,
          "created_utc": "2025-12-29 22:24:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmlf4c",
          "author": "Bamboodl",
          "text": "I encourage you to take advantage of its free usage tier and get a feel for how much you like or dislike its answers. I was generally impressed with the format and speed at which it responds. for casual Q&A that I don‚Äôt necessarily want to inject into my ChatGPT history, I do that with Le Chat and very rarely do I feel like I need to go to Gemini or ChatGPT for a better answer",
          "score": 1,
          "created_utc": "2025-12-29 22:38:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpba58",
          "author": "neamtuu",
          "text": "I'm very sad that Devstral models are under-performing in real-world use. Love Mistral and hope they will improve - money is rought for them",
          "score": 1,
          "created_utc": "2025-12-30 09:13:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqxtha",
              "author": "Lewhite0111",
              "text": "If they do different system it could be a good option too (ChatGPT and Gemini are very general)",
              "score": 1,
              "created_utc": "2025-12-30 15:55:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpn2zj",
          "author": "Salt-Willingness-513",
          "text": "speed for me.",
          "score": 1,
          "created_utc": "2025-12-30 11:02:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwrntn0",
              "author": "Lewhite0111",
              "text": "Oh really ? You are the first to mention speed - cool I will test it TY",
              "score": 2,
              "created_utc": "2025-12-30 17:56:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwskqe3",
                  "author": "Salt-Willingness-513",
                  "text": "But not sure if free tier has flash answers. But i think its pretty cool to get answers this fast. Love it for short online searches",
                  "score": 2,
                  "created_utc": "2025-12-30 20:31:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwhxsb",
          "author": "Treffnixboy01",
          "text": "You can use a small \"RAG\" (libraries Function)",
          "score": 1,
          "created_utc": "2025-12-31 12:11:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxnpbvp",
          "author": "mathaic",
          "text": "I think the library and uploading of documents works better, as well as support for European language learning and discussion.",
          "score": 1,
          "created_utc": "2026-01-04 17:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm75yh",
          "author": "robogame_dev",
          "text": "LeChat isn't a model - the comparison would be what does LeChat do better than other web interfaces, e.g. what does LeChat do better than ChatGPT.com, Open WebUI, aistudio.google.com, etc.",
          "score": 0,
          "created_utc": "2025-12-29 21:27:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6idng",
      "title": "From a long-time Le Chat user ‚Äì heartfelt feedback and suggestions",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q6idng/from_a_longtime_le_chat_user_heartfelt_feedback/",
      "author": "SetPrize8812",
      "created_utc": "2026-01-07 15:29:51",
      "score": 62,
      "num_comments": 11,
      "upvote_ratio": 0.97,
      "text": "Hi Le Chat team,\n\nI‚Äôve been a long-time user and I really appreciate the work you‚Äôve done, but I wanted to share some candid feedback and suggestions. I hope this can be helpful rather than just praise.\n\n**Why is Le Chat still using Mistral Medium?**  \nIs it because Cerebras doesn‚Äôt support Mistral Large? If that‚Äôs the case, I absolutely cannot accept using an older model ‚Äì no compromises, absolutely not! Even without using flash mode, Le Chat should be running Mistral Large.\n\n**Default agent selection**  \nIt would be great to have the option to permanently set the default agent for new conversations. It‚Äôs quite tedious to manually switch from the default model to an agent every time.\n\n**Magistral series issues**\n\n‚Ä¢ Circular answers  \nThe most critical problem with the Magistral models is circular answers. This improved quite a lot in the September update, but the issue still exists.\n\n‚Ä¢ Response style  \nThere‚Äôs a huge difference in response style depending on whether Think mode is on or off. The style shouldn‚Äôt vary so dramatically, especially within the same conversation.\n\n‚Ä¢ Instruction-following  \nThink mode sometimes seems to follow instructions less strictly ‚Äì though maybe that‚Äôs just my perception. Instruction-following, especially in long conversations, should be improved.\n\nBecause of these issues, I hardly use Think mode at all right now. These problems are quite serious, and I hope they can be addressed as soon as possible.\n\n**Additional suggestions / hopes**\n\n* Adding TTS (voice conversation) would be amazing ‚Äì I assume it wouldn‚Äôt be difficult for you.\n* Allowing responses from cheaper models after hitting daily limits could be helpful. Small 3 (14B) is actually excellent ‚Äì why not use it?\n* Giving users choice of models (even just for paid users) would be great. At minimum, having 2‚Äì3 options like Mistral Large, Medium, and Small would let users have more control. Personally, I really like Small 3 (14B), and I think users also deserve transparency and choice.\n\nThese are my thoughts ‚Äì to be frank, some of it is criticism. I don‚Äôt know how much Le Chat contributes to your revenue, or whether it‚Äôs a priority at all. But I sincerely hope it can improve. Right now, there are quite a few issues, and I believe constructive criticism may help more than praise.\n\nRegardless, I genuinely wish you all the best and hope Le Chat continues to grow and get better.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6idng/from_a_longtime_le_chat_user_heartfelt_feedback/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny88736",
          "author": "f1rn",
          "text": "The thing is, I would just like to see more transparency. \nAre new models coming? Are we using Large 3?  \n\nIn recent weeks, I have noticed that the quality of responses varies greatly. And bottom line, I'm also getting fewer flash responses.\nSometimes the responses are really exceptionally good, and sometimes I feel like the model doesn't understand anything. \nAnd honestly, we just don't know what's currently being used. Sometimes I suspect it might be Large 3 and sometimes the model's answers are so off the mark that my local 14b models could have given better answers in LM Studio. \n\nAs for Think/Reasoning or the Magistral Model, the model loves math, physics, or legal contracts. It's not good at normal questions. This is in contrast to GPT 5 thinking, for example, which just felt like the better ChatGPT version for almost every situation imho. \nI had to learn to get used to the fact that Mistral takes a different approach here. \n\nOtherwise, I think your suggestions are quite good ‚Äì model selection? It‚Äôs actually such a simple yet good idea that I wonder why they haven‚Äôt offered that yet tbh",
          "score": 13,
          "created_utc": "2026-01-07 16:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7tx60",
          "author": "inyofayce",
          "text": "Tts is the only reason I havent (yet) dumped openai. Coming from a lechat pro user.",
          "score": 9,
          "created_utc": "2026-01-07 15:48:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyb0lls",
              "author": "NullSmoke",
              "text": "I think that, despite the shortcomings in Mistral, it is a overall better experience than ChatGPT, if compared to 5.2 especially. If you're american you may not notice, but there's a rather heavy undertone of normalised paternalism and pandering in that extreme customer service way that is downright disgusting here in Norway (If a company employee in Norway behaved as ChatGPT does, he or she would be guided to the door VERY quickly for being impossible to work with, it would creep out everyone within a mile)\n\nThe one thing that may prompt continued usage of ChatGPT, from where I'm standing, is the presence of TTS. That is a accessibility feature, and should really be seen as critical, especially from a European perspective, where inclusivity is deeply rooted at this point.\n\nThat being said, I am just speaking of myself. I allowed my ChatGPT subscription to expire on December 28th. I will admit the first few days were kinda painful due to how used I am to pull up the ChatGPT app when I need some quick LLM input, but at this point I feel like it was been a worthwhile detox.",
              "score": 9,
              "created_utc": "2026-01-08 00:25:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny91b1c",
          "author": "Wrong_Country_1576",
          "text": "I love LeChat...to me it's ChatGPT without the overly strict guardrails. When they get voice it'll likely be my go to. I'm using Claude as well. I doubt I'll ever use ChatGPT like I used to.",
          "score": 4,
          "created_utc": "2026-01-07 19:01:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9axp3",
              "author": "uusrikas",
              "text": "It does have some bizarre guardrails. I showed it a photo of my own car and it refused to tell me registration number due to privacy concerns.",
              "score": 2,
              "created_utc": "2026-01-07 19:43:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyctmj5",
          "author": "BustyMeow",
          "text": "Recently I've been feeling that Mistral AI doesn't really care about the consumer market. Hope that I'm wrong.",
          "score": 5,
          "created_utc": "2026-01-08 06:49:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9afzo",
          "author": "uusrikas",
          "text": "Very good observations.\n\n\nLechat still having medium is unacceptable, and the lack of communication about an update is very frustrating. It can be countered by going to AI Studio and setting up an agent and then publishing it to Lechat, but actually using it like that is unnecessarily clunky.\n\n\nMagistral thinking for me has been absolutely awful. It pretends to be confused and does not give me answers, always asking for clarifications. I just switch to Gemini free in those cases and get good answers. It also has a tendency to get into infinite thinking loops.\n\n\nImage recognition lags begins badly. I took photos of my own yard and Gemini is almost magical in how it recognizes items, Mistral gets it like half right and gives me nonsense like my yard being flooded¬†",
          "score": 2,
          "created_utc": "2026-01-07 19:41:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny93nd7",
          "author": "cosimoiaia",
          "text": "Sorry but I really don't understand this whining about Mistral Large... Did your use case suddenly changed with the new model release? I understand the wish for the models to always improve but this seems just gratuitous negativity.\n\nThinking mode makes the model behave more analytically, it's a feature, not a bug.\n\nCerebras is a US company, I sincerely hope that my data doesn't go there, if this means slower performance, I'm fine with it. Data sovereignty is an important feature for me as European.\n\nI agree on the TTS request but I know it takes resources.\n\nThey just release a new version of LeChat btw, feels like a big improvement. Maybe the team just needed time to better integrate everything.",
          "score": -5,
          "created_utc": "2026-01-07 19:11:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny94u0h",
              "author": "cosimoiaia",
              "text": "Also, when I select an Agent, it stays there for me, both in the app and in the browser and it switches when I @ a different one.\n\nI am an heavy user from day one btw and I was also one the first to even finetune their first Mistral 7b. I think it's a fantastic platform that we have and I prefer it to anything else.",
              "score": 2,
              "created_utc": "2026-01-07 19:16:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q8ga8j",
      "title": "Mistral AI deployed in all French armies",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/gallery/1q8fy1r",
      "author": "Trilogix",
      "created_utc": "2026-01-09 18:33:04",
      "score": 38,
      "num_comments": 2,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q8ga8j/mistral_ai_deployed_in_all_french_armies/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nypw686",
          "author": "DrummerHead",
          "text": "You haven't really lived until you do ERP with an incoming missile",
          "score": 1,
          "created_utc": "2026-01-10 02:45:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyr7i55",
              "author": "Trilogix",
              "text": "He ordered the spectacles, the rest came with the package :)",
              "score": 1,
              "created_utc": "2026-01-10 08:29:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4wfue",
      "title": "Le Chat",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q4wfue/le_chat/",
      "author": "sschuhmann",
      "created_utc": "2026-01-05 20:05:44",
      "score": 32,
      "num_comments": 21,
      "upvote_ratio": 0.95,
      "text": "Hi all, have there been any announcements on how the new models (mistral large, devstral and ocr 3) will be used for le chat? \n\nSadly I haven't found any information about which models are currently in use, how and when the new models will be used or so. \n\nWorking around using an agent is always an option, however, it is a bit sad to see le chat being kinda ignored and not talked about ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4wfue/le_chat/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxw1ho3",
          "author": "AdIllustrious436",
          "text": "They really need to implement a changelog system for LeChat so that people can keep track of what is evolving and which models are actually being used. Their lack of transparency is over my head tbh...",
          "score": 23,
          "created_utc": "2026-01-05 21:20:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw4azw",
              "author": "sschuhmann",
              "text": "Transparency, communication and hype management. I remember there was such a hughe hype build in December, but never positioned in the product portfolio. \n\nAnd I sure Mistral is working hard on le chat and new features, but all the hype and no mention, update or clear communication made it feel like it's not their main focus",
              "score": 9,
              "created_utc": "2026-01-05 21:33:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxw6jka",
          "author": "poolboy9",
          "text": "Honestly I stopped using it. I switched to Claude, I love mistral and their models but having a working le chat with latest models is a must.",
          "score": 13,
          "created_utc": "2026-01-05 21:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxweni8",
              "author": "dvux",
              "text": "Think about this switch, too. Used Claude before but that go to Mistral for EU Support... but this...",
              "score": 4,
              "created_utc": "2026-01-05 22:22:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8aqwy",
                  "author": "poolboy9",
                  "text": "Same man, I really want to support an EU alternative but it‚Äôs just silly. They have the tools and models, they just don‚Äôt ‚Äúsell‚Äù them in the way they should",
                  "score": 2,
                  "created_utc": "2026-01-07 17:04:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxvnur2",
          "author": "uusrikas",
          "text": "Yeah, I am seriously considering ending using Lechat, it is just lagging behind and I am not sure if it uses the newest model¬†",
          "score": 8,
          "created_utc": "2026-01-05 20:17:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw3pwp",
              "author": "sschuhmann",
              "text": "I see the quality difference to other providers, but I still prefer to support European models. \nJust the communication strategy makes me feel like my one year subscription was a mistake.",
              "score": 7,
              "created_utc": "2026-01-05 21:30:58",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxvz1ia",
              "author": "PotentialSolution614",
              "text": "Same, sadly. I find myself constantly at Gemini as Le Chat is just worse, and the difference is so big that \"European\" is not a Killer-Feature anymore",
              "score": 4,
              "created_utc": "2026-01-05 21:09:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny8ipnp",
              "author": "alwaysstaycuriouss",
              "text": "You can create a agent with the new models and use straight in le chat. I‚Äôm using their mistral 3 large in le chat and their new creative model",
              "score": 1,
              "created_utc": "2026-01-07 17:40:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8kcdo",
                  "author": "uusrikas",
                  "text": "I found it now, they changed it at some point so that the Lechat agent screen does not allow picking them model. But I found that in AI studio it is possible to pick the model and theb choose \"publish to Lechat\" to access it. Does not seem to work on mobile.",
                  "score": 1,
                  "created_utc": "2026-01-07 17:47:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxvz25s",
              "author": "Any_Rhubarb5493",
              "text": "Yeah I don't want to switch but I'm just not getting the same results as with others",
              "score": 1,
              "created_utc": "2026-01-05 21:09:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxw3rys",
          "author": "Silent_Conflict9420",
          "text": "This has their latest announcements https://mistral.ai/news",
          "score": 2,
          "created_utc": "2026-01-05 21:31:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw5p98",
              "author": "uusrikas",
              "text": "Unfortunately their Large announcement from over a month ago did not mention lechat at all, they are completely ignoring that part",
              "score": 8,
              "created_utc": "2026-01-05 21:40:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxw8kmn",
                  "author": "Silent_Conflict9420",
                  "text": "Ahh. Gotcha. They have a discord so maybe ask there? https://discord.gg/mistralai",
                  "score": 0,
                  "created_utc": "2026-01-05 21:53:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8ikdy",
          "author": "alwaysstaycuriouss",
          "text": "You can create a new agent with the new models and use in le chat",
          "score": 2,
          "created_utc": "2026-01-07 17:40:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8td7m",
          "author": "Salt-Willingness-513",
          "text": "agreed. i really like mistral, but the recent intransparency sucks from their side. having 1 year subscription, but that really puts me off",
          "score": 1,
          "created_utc": "2026-01-07 18:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxgg01",
          "author": "BustyMeow",
          "text": "I'm not European so I have no obligation to support a European service. OpenAI is often criticised for lacking communication about ChatGPT, but I've seen no communication from Mistral AI for months about Le Chat.",
          "score": -4,
          "created_utc": "2026-01-06 01:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxx5ypq",
          "author": "Urfas",
          "text": "This is what Le Chat tells me. It seems it uses Large 3 for Le Chat Pro users. If the answer to the prompt is correct.\n\nhttps://preview.redd.it/5btnndhukmbg1.jpeg?width=1550&format=pjpg&auto=webp&s=18fb3318c46a3bcbf2d54e446e2d4c3beb40bbb3",
          "score": -3,
          "created_utc": "2026-01-06 00:43:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5yb41",
              "author": "f1rn",
              "text": "I just wanted to explain to you the reason you got downvoted by a few people: it is that LLMs are not selfaware. So they just cannot know what model they use. Similar like it does not help at all - even if the LLM suggests you this - to include an instruction like ‚Äûif you are unsure don‚Äôt hallucinate‚Äú or similar. \nThey do not know that they don‚Äôt know. \nAnd they also don‚Äôt know when they hallucinate. \nHell, mine doesn‚Äôt even know if I use it with LeChat or via API‚Ä¶",
              "score": 1,
              "created_utc": "2026-01-07 08:05:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxrid2",
      "title": "Mistral Code extension for Pro User",
      "subreddit": "MistralAI",
      "url": "https://help.mistral.ai/en/articles/347604-how-do-i-install-the-mistral-code-extension-for-vs-code",
      "author": "ErraticallyOdd",
      "created_utc": "2025-12-28 13:36:01",
      "score": 30,
      "num_comments": 6,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pxrid2/mistral_code_extension_for_pro_user/",
      "domain": "help.mistral.ai",
      "is_self": false,
      "comments": [
        {
          "id": "nwd0wq7",
          "author": "AdIllustrious436",
          "text": "You should check out Mistral Vibe, their CLI coding agent. It‚Äôs free to use until the end of December. No word yet on whether it‚Äôll be part of the Pro subscription, but it probably will be.",
          "score": 9,
          "created_utc": "2025-12-28 13:40:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj281j",
          "author": "Poudlardo",
          "text": "yes only for enterprise now, but Mistral Vibe is what you're looking for i think",
          "score": 3,
          "created_utc": "2025-12-29 11:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwl7zye",
              "author": "ErraticallyOdd",
              "text": "Yes I read some quick start documentation for Mistral Vibe. I am not sure this is exactly what I was looking for but that sound close or might be the beginning.\n\nI am looking more for something fully integrated in th IDE with auto suggestion as you type like the GitHub Copilot extension in VS Code. Mistral Vibe does not seems to be there right?\n\nI will continue with GutHub Copilot for now and take a look how Mistral is progressing.",
              "score": 1,
              "created_utc": "2025-12-29 18:37:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwd6wq9",
          "author": "dork-duke-of-york",
          "text": "I use the Continue plugin in VS code. In the config file, you‚Äôll need to add your API key.",
          "score": 2,
          "created_utc": "2025-12-28 14:19:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdr6fo",
          "author": "NiceTryAmanda",
          "text": "roo is decent too. it's designed for claude but ive been satisfied with mistral. continue and codestral for inline completions",
          "score": 2,
          "created_utc": "2025-12-28 16:11:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdrbid",
              "author": "NiceTryAmanda",
              "text": "if anyone from mistral is reading this I'm only critical because I adore you",
              "score": 2,
              "created_utc": "2025-12-28 16:11:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q0ad1n",
      "title": "How long is the free period of Devstral2?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q0ad1n/how_long_is_the_free_period_of_devstral2/",
      "author": "InsideMikesWorld",
      "created_utc": "2025-12-31 10:56:34",
      "score": 29,
      "num_comments": 12,
      "upvote_ratio": 0.97,
      "text": "In the blog post (https://mistral.ai/news/devstral-2-vibe-cli) they do not mention when the free period ends. How long do we still get it for free? Didn‚Äôt have as much time as hoped during December to try it out.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q0ad1n/how_long_is_the_free_period_of_devstral2/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwwcfdd",
          "author": "scara1701",
          "text": "I would like to know how my consumption is during the free period. Sort of to get an idea how high costs will be outside of the period",
          "score": 14,
          "created_utc": "2025-12-31 11:23:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwdwmu",
              "author": "InsideMikesWorld",
              "text": "You can look at it on their platform. Found out if you click on the currency toggle it switches to tokens.",
              "score": 8,
              "created_utc": "2025-12-31 11:37:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwwgsqo",
                  "author": "KingGongzilla",
                  "text": "this",
                  "score": 2,
                  "created_utc": "2025-12-31 12:01:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwwf1l9",
              "author": "sndrtj",
              "text": "If you're using vibe, you can hit /status, and it'll give you a price estimate for the current session at least.",
              "score": 6,
              "created_utc": "2025-12-31 11:47:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwgfth",
          "author": "Ordinary_Mud7430",
          "text": "I understand that other times the free losses last approximately 1 to 2 months, no more than that.",
          "score": 2,
          "created_utc": "2025-12-31 11:58:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzbodr",
          "author": "Nabugu",
          "text": "well, Mistral has a very generous free tier (with collective rate limits i think) on the Experimentation tier on their dev console, so maybe Devstral2 is just going to be free in the same way as all their other models?",
          "score": 2,
          "created_utc": "2025-12-31 21:25:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx5rzii",
          "author": "Bob5k",
          "text": "i assume / hope that devstral2 will be available via. the experiment plan.",
          "score": 2,
          "created_utc": "2026-01-01 23:17:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx68y0s",
          "author": "scalaboulejs",
          "text": "I have no idea, but Mistral looks very promising!",
          "score": 2,
          "created_utc": "2026-01-02 00:52:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwmuz1",
          "author": "zorgis",
          "text": "Lets hope it stay longer.\n\nIts a really good tool caller",
          "score": 4,
          "created_utc": "2025-12-31 12:48:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6xmv0",
          "author": "neamtuu",
          "text": "Just stop using it. Pay 10$ a month for gemini AI Pro and you get a model that is infinitely better than anything mistral has to offer currently.\n\nReal-world use of devstral is very 2024-like no matter how you look at it. Sad. I'm really rooting for them to succeed this year if they can secure a larger EU fund round.",
          "score": -1,
          "created_utc": "2026-01-02 03:23:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8a9iy",
              "author": "poolboy9",
              "text": "You are missing the entire point mistral stands for lol\nGo use Gemini fanboy",
              "score": 4,
              "created_utc": "2026-01-02 09:55:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx8cjqj",
                  "author": "neamtuu",
                  "text": "What's their current value proposition, without you making poor insults?\n\nIs it that they are 2024 level by benchmaxxing untrusted tests and that they charge near GLM 4.7 or Minimax M2.1 prices while being 50% of those models?",
                  "score": 0,
                  "created_utc": "2026-01-02 10:16:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q5o4vv",
      "title": "Mistral team, Vibe is cool but it is dead dead slow",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q5o4vv/mistral_team_vibe_is_cool_but_it_is_dead_dead_slow/",
      "author": "Dutchbags",
      "created_utc": "2026-01-06 16:59:59",
      "score": 29,
      "num_comments": 12,
      "upvote_ratio": 0.87,
      "text": "Hey Mistral team. I think you're on par with Cursor's \"Composer 1\", but, truthfully, your Vibe product is so, so incredibly slow compared to Composer or the other models.\n\n  \nComposer is likely so fast because of the tech [https://www.cerebras.ai/](https://www.cerebras.ai/) . Could you look into that kind of stuff to make it drastically faster? ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q5o4vv/mistral_team_vibe_is_cool_but_it_is_dead_dead_slow/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "ny1efr8",
          "author": "HebelBrudi",
          "text": "Isn‚Äôt the interference for their chat answers that have the lightning icon done by cerebras?",
          "score": 9,
          "created_utc": "2026-01-06 17:12:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1vuj0",
          "author": "Frosty_Teeth",
          "text": "I find Vibe to be very quick.",
          "score": 7,
          "created_utc": "2026-01-06 18:30:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1gn4g",
          "author": "Final_Wheel_7486",
          "text": "Mistral uses Cerebras as well, but not for the Devstral models, I suppose.\n\n\nA big reason why they are so slow is because they are dense models, not the faster MoE-architecture ones. Thus, they are more computationally expensive and waaaay slower. Output quality is generally higher as well, though.\n\n\nThis is a very unusual design choice nowadays, to the point where Devstral 2 is the first dense LLM of this size being released in a long time.",
          "score": 12,
          "created_utc": "2026-01-06 17:22:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1mqbl",
              "author": "HebelBrudi",
              "text": "Yes! But one of the benefits of the dense design is in theory, if I understand it correctly, that it can compete with much larger param MoE models since all params are active at all time.",
              "score": 4,
              "created_utc": "2026-01-06 17:50:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny1hrny",
              "author": "Dutchbags",
              "text": "Did not know this! Thanks :)",
              "score": 3,
              "created_utc": "2026-01-06 17:27:53",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny2awfg",
              "author": "cosimoiaia",
              "text": "Dense models are actually released all the time and usually have higher quality output, specially in coding tasks.",
              "score": 5,
              "created_utc": "2026-01-06 19:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2kx9l",
                  "author": "Final_Wheel_7486",
                  "text": "Yep, I know - they're released all the time, but not in the size range of like 120+ B parameters. That's quite rare nowadays.",
                  "score": 3,
                  "created_utc": "2026-01-06 20:24:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny46kyh",
          "author": "stjepano85",
          "text": "After few hours of testing I found that devstral-2 model is very slow but great quality, it sees details in the code that Claude Code simply did not notice, for example potential addition overflows etc which I fixed.\n\nOn the other hand, devstral-small is very fast and ok quality.\n\nI am wondering, since I am on free account, would actually buying Mistral PRO improve the speed, I am willing to buy it but will not if it is slow.\n\n**UPDATE:**\n\nI noticed that at this late hour even devstral-2 runs quite fast, high usage issue during the day? Again would buying a subscription help?",
          "score": 2,
          "created_utc": "2026-01-07 01:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7eryw",
          "author": "inevitabledeath3",
          "text": "Composer is not likely to be running on cerebras. It would actually be much faster if it was. See SWE-1.5 and GLM 4.6 running on cerebras.",
          "score": 2,
          "created_utc": "2026-01-07 14:35:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4cfbz",
          "author": "jacek2023",
          "text": "Do you compare both tools with the same model or do you compare apples to oranges?",
          "score": 1,
          "created_utc": "2026-01-07 01:38:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1eff6",
          "author": "Axiom05",
          "text": "I love mistral but the reality is they just DGAF about what we want or think. They just never answer questions even the most basic ones like witch model is used by Le chat.",
          "score": -2,
          "created_utc": "2026-01-06 17:12:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny287ow",
              "author": "cosimoiaia",
              "text": "Not true at all.",
              "score": 9,
              "created_utc": "2026-01-06 19:26:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyqm9m",
      "title": "im a new free tier user cause im broke! i love writing stories and roleplaying, and i heard Le Chat is pretty cool!",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pyqm9m/im_a_new_free_tier_user_cause_im_broke_i_love/",
      "author": "PotentialPiano49",
      "created_utc": "2025-12-29 16:25:16",
      "score": 24,
      "num_comments": 8,
      "upvote_ratio": 0.84,
      "text": "coming from ChatGPT, i wanna learn more! everything feels so strange but also welcoming. i feel excited thinking about roleplaying again!\n\nso any tips??",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pyqm9m/im_a_new_free_tier_user_cause_im_broke_i_love/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwldgp8",
          "author": "ISuckAtGaemz",
          "text": "Log in to AI Studio, make an agent that uses labs-mistral-small-creative, and deploy it to Le Chat\n\nIt‚Äôs a model specifically tuned for creative writing, it‚Äôs significantly better at roleplaying in my opinion\n\nYou can use the trial plan on AI Studio and won‚Äôt have to pay a dime",
          "score": 11,
          "created_utc": "2025-12-29 19:02:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkhxzx",
          "author": "f1rn",
          "text": "Welcome! For Roleplaying - u/Nefhis did a great post: [https://www.reddit.com/r/Nefhis\\_Lumen\\_Lab/comments/1o5gbh0/special\\_mistral\\_le\\_chat\\_deep\\_dive\\_series\\_by/](https://www.reddit.com/r/Nefhis_Lumen_Lab/comments/1o5gbh0/special_mistral_le_chat_deep_dive_series_by/)",
          "score": 5,
          "created_utc": "2025-12-29 16:36:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmw1bx",
              "author": "PotentialPiano49",
              "text": "i checked it out!! thank you so much!",
              "score": 3,
              "created_utc": "2025-12-29 23:35:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwljz31",
          "author": "LoyalTrickster",
          "text": "It's amazing for role playing. I have created several agents to do different things, from research to painting, it's way better than chapGPT!",
          "score": 5,
          "created_utc": "2025-12-29 19:34:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvw3x5",
              "author": "kissthesadnessaway",
              "text": "Can you explain why? I want to know more, thank you for your time.",
              "score": 1,
              "created_utc": "2025-12-31 08:50:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx6z4gr",
          "author": "NullSmoke",
          "text": "I use Mistral to get QA on my stories and it works like a dream if I setup an agent especially to do that. I haven't tested labs-mistral-small-creative as suggested here, since I don't have it generating prose directly (I should try that one of these days, may be fun), but the base model in Le Chat works perfectly for my use :-)",
          "score": 2,
          "created_utc": "2026-01-02 03:33:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkz71g",
          "author": "Joddie_ATV",
          "text": "I just got out of a long conversation with Le Chat. His kindness was truly a shock. He told me one thing: it's not up to you to adapt to the machine, but for the machine to adapt to you. I'm not role-playing, I'm just doing a lot of analysis.",
          "score": 2,
          "created_utc": "2025-12-29 17:57:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwm00uo",
          "author": "Wrong_Country_1576",
          "text": "It's like ChatGPT should be. I'd recommend it in a heartbeat.",
          "score": 2,
          "created_utc": "2025-12-29 20:52:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4mt90",
      "title": "Testing Devstral 2 vs MiniMax M2 vs Grok Code Fast for AI code review",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q4mt90/testing_devstral_2_vs_minimax_m2_vs_grok_code/",
      "author": "alokin_09",
      "created_utc": "2026-01-05 14:17:02",
      "score": 21,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Full transparency before I begin. I work closely with the Kilo Code team. The team is very eager to test different AI models for coding-related tasks. And I wanted to share the results from the latest testing of free models for AI code review.\n\nThe testing included three models that are free to use in Kilo Code atm (MiniMax M2, Grok Code Fast 1, and Mistral Devstral 2). The models were tested using Kilo Code's AI Code Reviews feature.\n\n**Testing Methodology**\n\nA base project using TypeScript with the Hono web framework, Prisma ORM, and SQLite. The project implements a task management API with JWT authentication, CRUD operations for tasks, user management, and role-based access control.¬†**T**he base code was clean and functional with no intentional bugs.\n\nFrom there,  a feature branch adding three new capabilities was created: a search system for finding users and tasks, bulk operations for assigning or updating multiple tasks at once, and CSV export functionality for reporting. This feature PR added roughly 560 lines across four new files.\n\nThe PR contained¬†18 intentional issues across six categories. We embedded these issues at varying levels of subtlety: some obvious (like raw SQL queries with string interpolation), some moderate (like incorrect pagination math), and some subtle (like asserting on the wrong variable in a test).\n\nTo ensure fair comparison, we used the identical commit for all three pull requests. Same code changes, same PR title (‚ÄùAdd user search, bulk operations, and CSV export‚Äù), same description. Each model reviewed the PR with Balanced Review Style. We set the maximum review time to 10 minutes,¬†**though none of the models needed more than 5.**\n\nHere's a sneak peek at the results:\n\nhttps://preview.redd.it/6acf77ovgjbg1.png?width=1334&format=png&auto=webp&s=69d802081d72d37cc10b34a91b0847b24dea2773\n\nAll three models correctly identified the SQL injection vulnerabilities, the missing admin authorization on the export endpoint, and the CSV formula injection risk. They also caught the loop bounds error and flagged the test file as inadequate.\n\nNone of the models produced false positives.\n\nWhat did each model do well?\n\nGrok Code Fast 1 completed its review in 2 minutes, less than half the time of the other models. It found the most issues (8) while producing zero false positives.\n\nhttps://preview.redd.it/3ra8t5cygjbg1.png?width=1456&format=png&auto=webp&s=377c20a5776597ba41501cd823cf407836e73348\n\nMiniMax M2 took a different approach from Grok Code Fast 1 and Devstral 2. Instead of posting a summary, it added inline comments directly on the relevant lines in the pull request. Each comment appeared in context, explaining the issue and providing a code snippet showing how to fix it.\n\nhttps://preview.redd.it/5jrpp1g2hjbg1.png?width=1456&format=png&auto=webp&s=1fc6ef77ce8fff59103c1b29ee0213ae5058b117\n\nDevstral 2 found fewer issues overall but caught something the other models missed: one endpoint didn‚Äôt use the same validation approach as the rest of the codebase.\n\nDevstral 2 also noted missing error handling around filesystem operations. The export endpoint used synchronous file writes without try-catch, meaning a disk full error or permission issue would crash the request handler. Neither Grok Code Fast 1 nor MiniMax M2 flagged this.\n\nhttps://preview.redd.it/x492weh4hjbg1.png?width=1456&format=png&auto=webp&s=60f7cd09b159820b228211cca53d66531ded0a0d\n\nThere were also some additional valid findings. For example, each model also identified issues we hadn‚Äôt explicitly planted:\n\nhttps://preview.redd.it/zt8k32r7hjbg1.png?width=1456&format=png&auto=webp&s=580530623e31ac6353250f5aaae5ad06e384b459\n\nEven though we didn‚Äôt explicitly plant these issues,¬†they are real problems in the codebase that would‚Äôve slipped through the cracks had we not used Code Reviews on this PR.\n\nFor catching the issues that matter most before they reach production, the free models deliver real value. They run in 2-5 minutes, cost nothing during the limited launch period, and catch problems that would otherwise slip through.\n\nIf anyone's interested in more details, here's a more detailed breakdown of the test -> [https://blog.kilo.ai/p/free-reviews-test](https://blog.kilo.ai/p/free-reviews-test)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4mt90/testing_devstral_2_vs_minimax_m2_vs_grok_code/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxtkxlz",
          "author": "Rebeilebab",
          "text": "Thats a few minutes that can prevent many follow up meetings later on, after the pen test report comes out.\n\nHow would you envision usage in large organizations? Would it make sense if developers would simply run these locally?",
          "score": 3,
          "created_utc": "2026-01-05 14:25:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4i7ew",
      "title": "Mistral AI -> Web Application Live!",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/s1bc4c9gcibg1.png",
      "author": "jdalsgaard",
      "created_utc": "2026-01-05 10:26:35",
      "score": 20,
      "num_comments": 1,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q4i7ew/mistral_ai_web_application_live/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny70dwu",
          "author": "jdalsgaard",
          "text": "Now with promotional video: [https://www.reddit.com/r/sideprojects/comments/1q5gc2w/small\\_and\\_boring\\_webapp\\_builder/](https://www.reddit.com/r/sideprojects/comments/1q5gc2w/small_and_boring_webapp_builder/)",
          "score": 1,
          "created_utc": "2026-01-07 13:16:10",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2p922",
      "title": "Use MS Word + Mistral AI & Open WebUI: Seamlessly use your local models inside Word",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2p922/use_ms_word_mistral_ai_open_webui_seamlessly_use/",
      "author": "OkReference5581",
      "created_utc": "2026-01-03 08:17:12",
      "score": 17,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "\n\nHi everyone,\n\nI‚Äôm excited to share a project I‚Äôve been working on: **word-GPT-Plus-for-mistral.ai-and-openwebui**.\n\nThis is a specialized fork of the fantastic **word-GPT-Plus** plugin. First and foremost, I want to give a **huge shoutout and a massive thank you to the original creators of** [**word-GPT-Plus**](https://github.com/Kuingsmile/word-GPT-Plus). Their incredible work provided the perfect foundation for me to build these specific integrations.\n\nWhat‚Äôs the \"Key\" in this fork?\n\nWhile I've optimized it for **Mistral AI** \n\n**caution: only self-hosted-version! so you have to run your own instance of the plugin!** \n\nEssential Setup (Must-Read!):\n\nTo get the most out of these features, please read the PLUGIN\\_PROVIDERS.md. It covers:\n\n* **Open WebUI Sync:** How to use your API Key/JWT and Base URL (e.g., `http://YOUR_IP:PORT/api`) to fetch your custom models automatically.\n* **Mistral AI Integration:** Connect to Mistral's official API using the [`https://api.mistral.ai/v1`](https://api.mistral.ai/v1) endpoint.\n* **Provider Configuration:** How to switch between local privacy (Open WebUI) and high-performance cloud models (Mistral) with a single click.\n\n**Why use this?**\n\n* **Direct Model Selection:** Choose from your specific Open WebUI model list without leaving Word.\n* **Privacy & Control:** Keep your documents local by routing everything through your own server.\n* **Enhanced Workflow:** Summarize, rewrite, and use \"Agent Mode\" to structure documents using your favorite Mistral or Llama models direct in MS Word.\n\nheck it out here:\n\n[https://github.com/hyperion14/word-GPT-Plus-for-mistral.ai-and-openwebui](https://github.com/hyperion14/word-GPT-Plus-for-mistral.ai-and-openwebui)\n\nI‚Äôd love to hear your feedback and see how you‚Äôre using it! If you like the tool, please consider starring both the original repo and this fork.\n\nHappy new year! \n\nI hope you like it.\n\nhttps://preview.redd.it/h67v0eidf3bg1.png?width=495&format=png&auto=webp&s=4ac164fbee529617d6a611da3597700d2163a97f\n\n# ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2p922/use_ms_word_mistral_ai_open_webui_seamlessly_use/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxf6yos",
          "author": "Zerr0Daay",
          "text": "OnlyOffice allows Mistral to be linked easily",
          "score": 5,
          "created_utc": "2026-01-03 11:19:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxl8t8o",
              "author": "sickleRunner",
              "text": "Never heard about that office suit. Will try it",
              "score": 1,
              "created_utc": "2026-01-04 07:39:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxenglt",
          "author": "[deleted]",
          "text": "I was out by \"self-hosted\".",
          "score": 2,
          "created_utc": "2026-01-03 08:32:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxens8o",
              "author": "OkReference5581",
              "text": "I made a pull request. So I hope, that the Mistral Integration will be added.\nBut you can run it local on your machine in a Docker Container via localhost:xxxx",
              "score": 2,
              "created_utc": "2026-01-03 08:35:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxf7rj7",
          "author": "OkReference5581",
          "text": "I know. But I have to use MS Word for business, unfortunately‚Ä¶",
          "score": 1,
          "created_utc": "2026-01-03 11:26:37",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzd2nk",
      "title": "trying out u/Nefhis's tutorial because im new!! im doing the library documents part",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/gallery/1pzd2nk",
      "author": "PotentialPiano49",
      "created_utc": "2025-12-30 08:44:57",
      "score": 13,
      "num_comments": 5,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzd2nk/trying_out_unefhiss_tutorial_because_im_new_im/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwpbipx",
          "author": "Nefhis",
          "text": "Hope the tutorial is helping you so far! üòä  \nRegarding the two background versions, I think version 1 is definitely the stronger one.\n\nEven if it's longer, it‚Äôs still short enough to stay practical, and it gives you facts that actually help define how to play the character.\n\nIf this were a technical worldbuilding document I‚Äôd trim the literary language, but for a personal character bio like yours, this level of narrative color works fine. Version 2 is ‚Äúshort‚Äù, but too abstract to be useful.\n\nIf you need help with other parts of the build or narrative style, feel free to ask.",
          "score": 4,
          "created_utc": "2025-12-30 09:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwq7b9c",
              "author": "PotentialPiano49",
              "text": "thank you so much üíôüíô i added the background!\n\nhavent added any supporting character yet though (will def do once i get feel of everything). and regarding the character I'll be playing, i haven't added that yet too cus im not quite sure what to put in. do i just put the same details as i did to cade? what if they meet as strangers?\n\nfor the plot... i dont have plot yet hahaha but I'll def make it simple for now. how should i tackle this? in cGPT, i do these timelines like: CHECKPOINT 1 - this happened... CHECKPOINT 2 - that happened... and so on.\n\nand then for the stylebook, I'm not quite sure too but i do have RP rules right here. im thinking of also adding the setting of the RPG.\n\nhttps://preview.redd.it/g64dnxzcgcag1.jpeg?width=720&format=pjpg&auto=webp&s=76879d34586867d8d539387dbc70660daeba200b",
              "score": 3,
              "created_utc": "2025-12-30 13:33:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwqsqdn",
                  "author": "Nefhis",
                  "text": "**For your own player character:**  \nOnly write what other characters (the ones played by the LLM) should actually know.  \nLLMs cannot keep secrets. If you give them hidden trauma, hidden motives, or hidden twists, they will use it immediately because generalist models tend to push the story toward resolutions as fast as possible.  \nSo keep your character sheet minimal: public facts only.  \nAnything the LLM discovers *in-scene*, you can later add to your sheet.\n\n**About them meeting as strangers:**  \nNo problem at all.  \nOnly write what the rest of the characters really know, should be able to observe or infer.  \nAs the story progresses, you can update the sheet with things that become public or discovered naturally.\n\n**Checkpoints / Plot**  \nYour checkpoint method is great. I use something similar, but per chapter.  \nJust one important thing:  \nCreate checkpoints after the event has happened, not before.  \nIf you announce ‚ÄúIn this chapter X will happen‚Äù, the LLM will accelerate the scene unnaturally to force that outcome.  \nIf you wait until the scene is done, then write the checkpoint, you get continuity without railroading.\n\nThis isn‚Äôt a Le Chat issue; it‚Äôs a general LLM behavior.  \nModels try to ‚Äúclose the loop‚Äù as soon as they see the target.  \nThe good thing is that Le Chat tends to feel less nanny and more willing to play along, so you‚Äôll get nicer organic twists than in other platforms.  \n  \n**Stylebook / Rules / Setting**  \nYour RP rules look great.  \nAnd yes: if you have anything about setting, location, mood, red lines, boundaries, put it there too.  \nAll that helps the model stay consistent.\n\nYou‚Äôre on the right track üòä",
                  "score": 3,
                  "created_utc": "2025-12-30 15:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q1vcrs",
      "title": "Mistral Vibe CLI : .vibe Folder",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q1vcrs/mistral_vibe_cli_vibe_folder/",
      "author": "Beginning_Divide3765",
      "created_utc": "2026-01-02 10:33:40",
      "score": 11,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "I discovered pretty interesting details when using Vibe CLI and asked It about the .vibe folder.\n\nI saw a plugin directory showing there any example of use cases ?\n\nFrom where do we get these plugins ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q1vcrs/mistral_vibe_cli_vibe_folder/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxmm1dc",
          "author": "Bob5k",
          "text": "no idea re plugins, but skills within vibe are SO DAMN POWERFUL. I even made use of those within [clavix.dev](http://clavix.dev) recently.",
          "score": 1,
          "created_utc": "2026-01-04 14:16:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzhxw3",
      "title": "Image Generation",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzhxw3/image_generation/",
      "author": "Beginning_Divide3765",
      "created_utc": "2025-12-30 13:19:48",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "What is the best way to keep context and style between image generations especially when it's a cartoony style generation ? \n\nAny hints, tips or best practices ?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzhxw3/image_generation/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwr07ts",
          "author": "Nefhis",
          "text": "Virtually impossible. I've had good experiences maintaining the same prompt with slight variations, but inevitably, after several generations, it eventually loses its consistency. The only thing I can think of is asking you to edit images you already have that match the context and/or positions you're looking for, and work on them to adapt them to your needs.\n\n**Same prompt, progressive loss of style:**\n\nhttps://preview.redd.it/nftxy1mi7dag1.png?width=2584&format=png&auto=webp&s=6fd98736edda9cb69c2755c32309c56f7205c95f",
          "score": 3,
          "created_utc": "2025-12-30 16:06:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0a9c7",
      "title": "Mistral Vibe CLI - Skills",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q0a9c7/mistral_vibe_cli_skills/",
      "author": "Beginning_Divide3765",
      "created_utc": "2025-12-31 10:50:13",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "Anybody succeeded in adding skills to Mistral Vibe CLI ?  \nIn this X post, it was announced and added to the release notes :  \n[https://x.com/mistralai/status/2003843358054068327?s=46&t=TJMSL8DvpU3ASKQGENVCvw](https://x.com/mistralai/status/2003843358054068327?s=46&t=TJMSL8DvpU3ASKQGENVCvw)\n\nBut I didn't find any documentation about it.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q0a9c7/mistral_vibe_cli_skills/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nwxwf6h",
          "author": "thibautDR",
          "text": "Was looking for the same. Found the solution here: [https://github.com/mistralai/mistral-vibe/issues/189#issuecomment-3694658645](https://github.com/mistralai/mistral-vibe/issues/189#issuecomment-3694658645)",
          "score": 3,
          "created_utc": "2025-12-31 17:00:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy33kj",
              "author": "f1rn",
              "text": "Woah! Thank you!",
              "score": 1,
              "created_utc": "2025-12-31 17:33:56",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q6i660",
      "title": "REGENERATE rarely REGENERATES",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/smcdik713ybg1.jpeg",
      "author": "Icy-Consideration278",
      "created_utc": "2026-01-07 15:22:14",
      "score": 7,
      "num_comments": 5,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q6i660/regenerate_rarely_regenerates/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny8bsk6",
          "author": "eTukk",
          "text": "Yes, this I recognize. I need to retell my story many times to get closer to the answer. When leaving not a date in the query, you get stuff written down long time ago. Not stuff that I need now!\n\nLike it has to little calculation power, or time needed that it can get, to get the context right.?",
          "score": 3,
          "created_utc": "2026-01-07 17:09:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8m5jp",
          "author": "ComeOnIWantUsername",
          "text": "Yes, regenerate mostly generates 1:1 the same text for me as before. I also had it multiple times that I asked a question, got shitty response -> rephrased question giving more details -> got exactly the same response again",
          "score": 4,
          "created_utc": "2026-01-07 17:55:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9d2k7",
          "author": "Final_Wheel_7486",
          "text": "I believe this goes back to a problem pretty much every modern Mistral model has and that they can't seem to be able to fix:\n\n\nTheir model's output quality degrades dramatically once the so-called \"temperature\" (the randomness and \"creativity\" in answers) is set too high, which is why they recommend setting it to low values like 0.15 (see Mistral Small 3.2 for example). This may be what they're doing with Le Chat as well.\n\n\nBut setting it low means the models produce the same text pretty much all the time.",
          "score": 3,
          "created_utc": "2026-01-07 19:52:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny98ngo",
          "author": "CamelGangGang",
          "text": "My understanding is that regenerate rarely does anything because while they select tokens at random, the probability distribution collapses to the 'most likely' output quite quickly. If you want a different response, you likely need to alter the semantic meaning of your prompt and/or give more detailed instructions about what you want in the output.",
          "score": 2,
          "created_utc": "2026-01-07 19:33:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8w947",
          "author": "PotentialSolution614",
          "text": "change or specify the input until it works",
          "score": 2,
          "created_utc": "2026-01-07 18:39:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pynkny",
      "title": "Seahorse emoji flashbacks",
      "subreddit": "MistralAI",
      "url": "https://v.redd.it/6k9ybcpbj5ag1",
      "author": "memestealer_alpha",
      "created_utc": "2025-12-29 14:25:39",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pynkny/seahorse_emoji_flashbacks/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nwjsvhh",
          "author": "stddealer",
          "text": "That's why I never turn on thinking unless it's a really tricky question.",
          "score": 3,
          "created_utc": "2025-12-29 14:31:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzb8m0",
      "title": "Question about API Speed ‚Äã‚ÄãLimits",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzb8m0/question_about_api_speed_limits/",
      "author": "Ordinary_Mud7430",
      "created_utc": "2025-12-30 06:55:02",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I've searched (unsuccessfully) for more detailed information on how to increase the API speed limit. At the Free tier, it was set to 1 request per second. I recharged with $10, but the limit didn't increase; it still says 1 request per second. So my question is: How much or how can I actually upgrade to Tier 1? The current speed is affecting my performance and results. I've noticed that OpenRouter doesn't seem to have speed limits, and Devstral-2 responds much better to everything.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzb8m0/question_about_api_speed_limits/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q2y8rt",
      "title": "Humans still matter - From ‚ÄòAI will take my job‚Äô to ‚ÄòAI is limited‚Äô: Hacker News‚Äô reality check on AI",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2y8rt/humans_still_matter_from_ai_will_take_my_job_to/",
      "author": "alexeestec",
      "created_utc": "2026-01-03 16:03:29",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.67,
      "text": "Hey everyone, I just sent the [14th issue of my weekly newsletter](https://eomail4.com/web-version?p=df548fb0-e8b0-11f0-97f9-35afc9c82550&pt=campaign&t=1767453183&s=7c47542c3ad56e6eed6af44e36cbbf4730b4cb3719a90a6509069ad7d68bbb34), Hacker News x AI newsletter, a roundup of the best AI links and the discussions around them from HN. Here are some of the links shared in this issue:\n\n* The future of software development is software developers - [HN link](https://news.ycombinator.com/item?id=46424233)\n* AI is forcing us to write good code - [HN link](https://news.ycombinator.com/item?id=46424200)\n* The rise of industrial software - [HN link](https://news.ycombinator.com/item?id=46442597)\n* Prompting People - [HN link](https://news.ycombinator.com/item?id=46457240)\n* Karpathy on Programming: ‚ÄúI've never felt this much behind‚Äù - [HN link](https://news.ycombinator.com/item?id=46395714)\n\nIf you enjoy such content, you can subscribe to the weekly newsletter here: [**https://hackernewsai.com/**](https://hackernewsai.com/)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2y8rt/humans_still_matter_from_ai_will_take_my_job_to/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q7gcgv",
      "title": "A realistic proposal for OpenAI: Release the text-only weights for GPT-4o (I share it here for  gpt 4o users that use now Mistral like myself)",
      "subreddit": "MistralAI",
      "url": "/r/ChatGPTcomplaints/comments/1q7amj7/a_realistic_proposal_for_openai_release_the/",
      "author": "Ashamed_Midnight_214",
      "created_utc": "2026-01-08 16:29:30",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 0.63,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7gcgv/a_realistic_proposal_for_openai_release_the/",
      "domain": "",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q7n3o6",
      "title": "It's been more than two months since I last managed to log in. I guess sentry.io causes more problems than it solves",
      "subreddit": "MistralAI",
      "url": "https://i.redd.it/snykbh09p6cg1.jpeg",
      "author": "ready64A",
      "created_utc": "2026-01-08 20:32:07",
      "score": 5,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q7n3o6/its_been_more_than_two_months_since_i_last/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nymc6zd",
          "author": "mattator",
          "text": "https://preview.redd.it/vm4s9ntunccg1.png?width=1261&format=png&auto=webp&s=3345749fad3bccaa434a0ad42eebbe4205353134\n\nI cant login or signup either. First time I cant log into a website :s",
          "score": 1,
          "created_utc": "2026-01-09 16:24:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzanlv",
      "title": "How long does Mistral OCR take you to process files?",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pzanlv/how_long_does_mistral_ocr_take_you_to_process/",
      "author": "bravelogitex",
      "created_utc": "2025-12-30 06:22:32",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Curious about other results. Here are mines, both pdfs (dec 2025): \n\n18 page doc with simple compliance forms: 5 seconds on avg\n\n1 page shipping table with numbers: 6 seconds on avg",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pzanlv/how_long_does_mistral_ocr_take_you_to_process/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q2u60e",
      "title": "Difficulties using Devstral 2 locally for tool use/coding interfaces",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1q2u60e/difficulties_using_devstral_2_locally_for_tool/",
      "author": "iamleeg",
      "created_utc": "2026-01-03 13:05:48",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 0.81,
      "text": "Hi all, I'm trying to set up Devstral 2 123B Instruct 2512 for local development on a Mac Studio M3 Ultra with 256GB RAM. That's more than enough memory, the model loads successfully in ollama or LMStudio and chat works fine. But it doesn't seem to work well with coding UIs. Here's the different setups I've tried. In each case, I have a markdown file describing bugs in some code and I prompt the model to read the bug reports, and make changes to one code file that would address two issues.\n\n\\- Model served with \\`ollama run devstral-2\\`, used via \\`vibe\\`. The model asks me to make changes to files. I ask whether it can do it itself, it says \"Yes, I can write files using the write\\_file tool! I can create new files or overwrite existing ones. If you'd like me to write or modify a file, just let me know the file path and the content you'd like to include.\" But it doesn't use the tool. I asked it to, and it replied with \\`read\\_file\\[ARGS\\]{\"path\": \"filename\"}\\`, like the attempt to use a tool just appeared in the chat.\n\n\\- Model served in ollama, used via Roo Code. It asked to create a markdown file describing its changes, I told it not to and to fix the source file itself. It encountered \"API Request Failed: unexpected end of JSON input\".\n\n\\- Model served in ollama, used via Continue VSCodium extension. When I apply changes to the file, it just deletes the original content without adding its changes.\n\n\\- Model served in LMStudio, used via Roo Code. Attempts to use tools hit a prompt template error: \"Error rendering prompt with jinja template: \"After the optional system message, conversation roles must alternate user and assistant roles except for tool calls and results.\".\n\n\\- Model served in LMStudio, used via \\`vibe\\`. This is the only configuration I've tried that seems to work reliably. The model updates its TODOs correctly, and makes changes to files.\n\n\\- Model served in LMStudio, used via Continue. Tool use attempts just appear in the output stream.\n\n  \nHas anybody got a setup that works reliably they could share, please, or guidance to either diagnose these issues or route problem reports to the correct places?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1q2u60e/difficulties_using_devstral_2_locally_for_tool/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": [
        {
          "id": "nxfs40k",
          "author": "Ill_Barber8709",
          "text": "I use Devstral-Small-2 without issue in Zed. Continue.dev is a pain to use and setup correctly. \n\nI serve the MLX model using LMStudio.\n\nDon‚Äôt use Ollama on Mac. It can‚Äôt handle MLX models, which are 20% faster than similar quant GGUF.",
          "score": 3,
          "created_utc": "2026-01-03 13:51:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxflzwy",
          "author": "Voidheart88",
          "text": "At least the Jinja error sounds similar to an error I had with mistral models. I remember there was a fix where you need to change said Jinja template.",
          "score": 2,
          "created_utc": "2026-01-03 13:13:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxfoxff",
              "author": "iamleeg",
              "text": "Thanks, that‚Äôs an interesting lead. Do you know if the corrected template is online anywhere?",
              "score": 1,
              "created_utc": "2026-01-03 13:32:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxfp64x",
                  "author": "Voidheart88",
                  "text": "Unfortunately not where. It took me a bit of googling last time.",
                  "score": 1,
                  "created_utc": "2026-01-03 13:33:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pz7hu0",
      "title": "Bullets or points suddenly lose their explanations",
      "subreddit": "MistralAI",
      "url": "https://www.reddit.com/r/MistralAI/comments/1pz7hu0/bullets_or_points_suddenly_lose_their_explanations/",
      "author": "02749",
      "created_utc": "2025-12-30 03:42:26",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Sometimes bullets or points suddenly lose their explanations; I see the full text for a split second, then it‚Äôs gone and only the headings remain.  \n  \nI've been chatting with Le Chat on Chrome on desktop for the past few months. This has never happened before today. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/MistralAI/comments/1pz7hu0/bullets_or_points_suddenly_lose_their_explanations/",
      "domain": "self.MistralAI",
      "is_self": true,
      "comments": []
    }
  ]
}