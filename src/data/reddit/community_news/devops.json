{
  "metadata": {
    "last_updated": "2026-02-16 03:09:30",
    "time_filter": "week",
    "subreddit": "devops",
    "total_items": 20,
    "total_comments": 478,
    "file_size_bytes": 509541
  },
  "items": [
    {
      "id": "1r31kvd",
      "title": "Had DevOps interviews at Amazon, Google, Apple. Here are the questions",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r31kvd/had_devops_interviews_at_amazon_google_apple_here/",
      "author": "irinabrassi4",
      "created_utc": "2026-02-12 18:39:59",
      "score": 465,
      "num_comments": 46,
      "upvote_ratio": 0.98,
      "text": "Hi Folks,\n\nDuring last year I had a couple of interviews at big tech plus a few other tier 2-3 companies. I collected all that plus other questions that I found on glassdoor, blind etc in a github repo. I've added my own video explanations to solve those questions. \n\nit's free and I hope this will help you to prepare and pass. If you ever feel like thanking me just Star the repository.\n\nhttps://github.com/devops-interviews/devops-interviews ",
      "is_original_content": false,
      "link_flair_text": "Career / learning",
      "permalink": "https://reddit.com/r/devops/comments/1r31kvd/had_devops_interviews_at_amazon_google_apple_here/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o54htaj",
          "author": "Sea-Us-RTO",
          "text": "> The process count on a production server keeps increasing even though no new workloads were deployed. Zombie processes are accumulating in the system.\n\n> Task:\n> Find all zombie processes, kill their parent processes to remove the zombies, and confirm they are gone from the system.\n\n\noh, easy.  `sudo reboot` üôÉ",
          "score": 73,
          "created_utc": "2026-02-13 07:02:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o54skto",
              "author": "ashvy",
              "text": "bro's gon be assigned to AWS US-East-1 team",
              "score": 130,
              "created_utc": "2026-02-13 08:41:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5b387s",
              "author": "SlavicKnight",
              "text": "Just make sure that after reboot you do rm -rf / we cannot allow it to repeat this story :D",
              "score": 11,
              "created_utc": "2026-02-14 07:56:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o577ugc",
          "author": "ruibranco",
          "text": "the people saying these are too easy are missing the point imo. at faang scale the technical screen is just a sanity check - the actual filter is system design where they ask you to design a deployment pipeline for 50k nodes and see if you instinctively think about blast radius and rollback before features",
          "score": 57,
          "created_utc": "2026-02-13 17:44:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o534s14",
          "author": "Sweaty-Pirate-1743",
          "text": "This is great, thanks for sharing.\nOne thing I‚Äôve noticed when preparing for DevOps/system design interviews is that many questions assume you can quickly understand an unfamiliar codebase or infra setup.\nIn reality, that‚Äôs often the hardest part ‚Äî not designing from scratch, but reasoning about an existing large system under time pressure.\nDid you find that most interviews focused more on greenfield design, or on improving/debugging existing architectures?",
          "score": 16,
          "created_utc": "2026-02-13 01:20:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56j9kf",
          "author": "ruibranco",
          "text": "The gap between these questions and actual DevOps work is pretty wild though. Interviews test whether you can explain what a zombie process is. The job tests whether you can figure out why the deployment pipeline broke at 2am while the monitoring dashboard is showing conflicting signals and Slack is blowing up with \"is prod down?\" The hardest part of every DevOps role I've worked wasn't the technical knowledge ‚Äî it was the judgment calls under incomplete information. Which alert do you investigate first? Do you roll back now or dig deeper? That stuff never shows up in an interview.",
          "score": 30,
          "created_utc": "2026-02-13 15:46:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5c1tmj",
              "author": "work_work-work",
              "text": "Hunh... I ask about those kind of things every time I interview someone.",
              "score": 4,
              "created_utc": "2026-02-14 13:11:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eeo7z",
              "author": "SuspiciousOwl816",
              "text": "It kinda makes sense that it doesn‚Äôt show up in an interview, those things aren‚Äôt usually solvable by a single in less an hour. But by using questions like OP posted, it‚Äôs a basic test to determine if you know what tools to use and where to look so they know you‚Äôre prepared when the production issue eventually pops up. So is it that bad that we get questions like those? It‚Äôs not ideal, but it‚Äôs also not terrible IMO",
              "score": 2,
              "created_utc": "2026-02-14 20:44:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5entwf",
                  "author": "ruibranco",
                  "text": "fair point, and yeah i don't think the questions themselves are bad ‚Äî knowing what a zombie process is matters. my gripe is more that the interview process stops there. you can filter out people who clearly don't know the basics, sure, but you still can't tell who's going to stay calm when grafana is showing contradictory data and three teams are pinging you simultaneously. the best interviews i've seen added a \"here's a messy scenario, walk me through your thought process\" round on top of the technical baseline. doesn't need to be solvable in an hour ‚Äî just seeing how someone triages and communicates under ambiguity tells you way more than whether they can recite iptables flags.",
                  "score": 3,
                  "created_utc": "2026-02-14 21:35:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51tj6b",
          "author": "AccordingAnswer5031",
          "text": "So which company did you get an offer from at the end?",
          "score": 24,
          "created_utc": "2026-02-12 21:06:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o562zdc",
              "author": "varelse99",
              "text": "McDonalds",
              "score": 35,
              "created_utc": "2026-02-13 14:26:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5c1cpq",
                  "author": "work_work-work",
                  "text": "Seriously though, devops at McDonald's wouldn't be a bad gig. There's some serious infra behind the scenes.",
                  "score": 13,
                  "created_utc": "2026-02-14 13:08:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o57bas3",
                  "author": "nomadProgrammer",
                  "text": "Chuckie Cheeses ",
                  "score": -2,
                  "created_utc": "2026-02-13 18:01:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o54bz9d",
          "author": "karthikjusme",
          "text": "Even from a non interview perspective. It's nice to learn a few new concepts and few gotchas there are. Thank you.",
          "score": 18,
          "created_utc": "2026-02-13 06:12:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51017k",
          "author": "branchCastle",
          "text": "Thank you!",
          "score": 15,
          "created_utc": "2026-02-12 18:46:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51dpqm",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 7,
          "created_utc": "2026-02-12 19:51:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51gt8i",
              "author": "iSnortedAPencilOnce",
              "text": "I've mostly been asked to walk through problems like this verbally. When I don't know the exact command or config, I tell the interviewer my best guess, then say I'd have to google the exact answer.\n\nI'm pretty new so not sure if it's the same for most people.",
              "score": 7,
              "created_utc": "2026-02-12 20:06:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5431an",
          "author": "ChickenUsoBeautiful",
          "text": "Thanks man, i hope everything goes to your favor",
          "score": 4,
          "created_utc": "2026-02-13 05:02:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55m9i3",
          "author": "calimovetips",
          "text": "solid move putting that together. having your own explanations forces you to actually understand the tradeoffs instead of memorizing ‚Äúcorrect‚Äù answers.\n\nfrom the devops side, what helped me most in big tech loops was being very explicit about constraints, scale, and failure modes. a lot of candidates jump straight to tooling, but interviewers usually care more about how you reason through ambiguity and production risk.\n\ndid you notice any pattern across amazon, google, apple in terms of what they emphasized, like operational depth vs system design vs incident handling?",
          "score": 7,
          "created_utc": "2026-02-13 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55dxdv",
          "author": "Frank_satooschi",
          "text": "Thank you so much bro, happy day to youüôÇ",
          "score": 3,
          "created_utc": "2026-02-13 11:53:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o563atx",
          "author": "wildVikingTwins",
          "text": "It‚Äôs so cool, thanks for sharing! I am about to be 3 years experienced, definitely will help for my next journey.",
          "score": 3,
          "created_utc": "2026-02-13 14:27:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o515u8o",
          "author": "davidokongo",
          "text": "Thank you üòä",
          "score": 6,
          "created_utc": "2026-02-12 19:13:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55tb88",
          "author": "acewithacase",
          "text": "Ad for prepare.sh",
          "score": 5,
          "created_utc": "2026-02-13 13:33:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5373me",
          "author": "sandin0",
          "text": "Either I‚Äôm a genius or these questions are lies. The senior ones are easy AF in very surprised.",
          "score": 6,
          "created_utc": "2026-02-13 01:34:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53qr6z",
              "author": "zeropoint46",
              "text": "Agreed and I feel stupid AF all the time at work... Unless this is like first round questions, I've gotten harder questions from small no name companies.",
              "score": 8,
              "created_utc": "2026-02-13 03:37:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53w163",
              "author": "Seref15",
              "text": "yeah theres no way these are fang level",
              "score": 5,
              "created_utc": "2026-02-13 04:12:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55z590",
                  "author": "xonxoff",
                  "text": "You don‚Äôt want to know how the sausage is made.",
                  "score": 5,
                  "created_utc": "2026-02-13 14:05:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o558cox",
          "author": "LongjumpingGuava5656",
          "text": "yeah this is gold, u have my star sir ;)",
          "score": 2,
          "created_utc": "2026-02-13 11:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55i5ti",
          "author": "ConstructionSoft7584",
          "text": "Amazing!",
          "score": 2,
          "created_utc": "2026-02-13 12:24:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59c5i2",
          "author": "jay_ose",
          "text": "Thank you for this wonderful work.",
          "score": 2,
          "created_utc": "2026-02-14 00:15:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cdudr",
          "author": "epidco",
          "text": "tbh back when i was setting up mining pool infra i spent more time googling nginx configs than memorizing them and honestly interviewers usually get that. as long as u understand the logic and how ur systems talk to each other the specific syntax doesnt matter as much cuz u can always look it up lol. big tech interviews rly care more about how u scale things or handle a node dying suddenly anyway",
          "score": 2,
          "created_utc": "2026-02-14 14:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5e0a3g",
          "author": "pst-jod",
          "text": "thats super cool mate thanks for sharing",
          "score": 2,
          "created_utc": "2026-02-14 19:27:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hre0y",
          "author": "Polliog",
          "text": "Thank you for sharing them",
          "score": 2,
          "created_utc": "2026-02-15 11:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51o5pe",
          "author": "rotlung",
          "text": "awesome, ty!",
          "score": 3,
          "created_utc": "2026-02-12 20:41:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54uz2h",
          "author": "lazazael",
          "text": "wow",
          "score": 3,
          "created_utc": "2026-02-13 09:04:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57pp3q",
          "author": "ruibranco",
          "text": "the zombie process question is a great filter - you can tell immediately whether someone actually troubleshoots in production or just knows theory",
          "score": 2,
          "created_utc": "2026-02-13 19:09:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o527v1q",
          "author": "Inevitable_Tie8626",
          "text": "What ic lvl this for?",
          "score": 2,
          "created_utc": "2026-02-12 22:15:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cwwn1",
          "author": "Joya021",
          "text": "Thank you :) Can you provide the repo link?",
          "score": 1,
          "created_utc": "2026-02-14 16:09:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ij8n8",
          "author": "Wooden-Ad5335",
          "text": "Wait, is there no leetcode round?",
          "score": 1,
          "created_utc": "2026-02-15 14:49:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58m8gm",
          "author": "nickname-nop",
          "text": "Now if this is os where is the answers?\nI dont want to sign to a random website......",
          "score": 1,
          "created_utc": "2026-02-13 21:51:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5362tj",
          "author": "Apprehensive-Flight4",
          "text": "Thanks so much for this. Have you been allowed to use AI during many of your interviews?",
          "score": 0,
          "created_utc": "2026-02-13 01:28:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o513wm1",
          "author": "snarkhunter",
          "text": "Wow spoiler alert maybe??",
          "score": -20,
          "created_utc": "2026-02-12 19:04:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o528m1i",
          "author": "[deleted]",
          "text": "[removed]",
          "score": -24,
          "created_utc": "2026-02-12 22:19:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52zr70",
              "author": "DeliciousPair1850",
              "text": "you could‚Äôve just not commented instead of giving your useless opinion",
              "score": 16,
              "created_utc": "2026-02-13 00:50:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o537vca",
                  "author": "SolarNachoes",
                  "text": "Bro just closed the ticket with a vengeance!",
                  "score": 2,
                  "created_utc": "2026-02-13 01:39:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0jghq",
      "title": "When is it time to quit?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r0jghq/when_is_it_time_to_quit/",
      "author": "bulldogncolt",
      "created_utc": "2026-02-09 22:54:23",
      "score": 207,
      "num_comments": 94,
      "upvote_ratio": 0.95,
      "text": "I wrapped up a tech panel for a Principal Azure Engineer role at an investment bank a couple of hours ago. This followed an interview with the hiring manager last Wednesday. We know each other from the past, i.e., I‚Äôve interviewed for multiple roles at this firm over the last 5-6 years.\n\nThis role landed on my LinkedIn feed randomly. I commented on the post and emailed the hiring manager directly, we had a short back-and-forth, and his recruiter called me almost immediately. The process has been unusually smooth by modern standards.\n\nToday‚Äôs panel felt strong. I‚Äôm confident I cleared the bar with both the Azure SME and the hiring manager. I saw visible agreement on several answers, got verbal acknowledgment more than once and handled questions from a junior panelist with ease. I was told that I‚Äôm ‚Äúfirst in line‚Äù (not sure if that means FIFO or first on the shortlist), however,  it seemed to be directionally positive.\n\nHere‚Äôs the problem: I was laid off a little over six months ago and I am EXHAUSTED. It's like I've been on the hamster wheels of interviews since 8/4/2025. I‚Äôve done the prep, the loops, the panels, the follow-ups. I know I‚Äôm good enough to be gainfully employed as a DevOps engineer.\n\nIf this role doesn‚Äôt turn into an offer, I‚Äôm seriously questioning whether I want to continue in tech at all. I don‚Äôt know if I have it in me to keep doing 5‚Äì7 round interview gauntlets, only to be rejected for vague reasons like ‚Äúculture fit‚Äù or not smiling enough. I‚Äôve given my adult life to STEM / engineering / corporate IT / tech and I am exhausted from having to engage with recruiters who want someone to take managerial roles for IC level pay.\n\nI‚Äôm not bitter about rejection. I‚Äôm tired of dysfunction...hiring managers who don‚Äôt know the difference between EC2 and AWS Lambda, recruiters who can‚Äôt distinguish an AWS account from an Azure subscription and BS interview processes that ding candidates for being \"too intense\".\n\nSo I‚Äôm asking honestly: when is it time to walk away?\nFor those who‚Äôve been at a similar crossroads...did you step back temporarily, change strategy or leave tech altogether?\n\n\nTL;DR: Six months, countless interviews, strong signals in today's tech panel. If today's tech panel doesn‚Äôt result in an offer, I‚Äôm seriously considering being done with the tech interview industrial complex.",
      "is_original_content": false,
      "link_flair_text": "Career / learning",
      "permalink": "https://reddit.com/r/devops/comments/1r0jghq/when_is_it_time_to_quit/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4inide",
          "author": "g3t0nmyl3v3l",
          "text": "I don‚Äôt have anything meaningful to contribute, but I read this and I hear you fam. I‚Äôm burnt even just working, I can‚Äôt imagine how terrible applying/interviewing is right now.",
          "score": 78,
          "created_utc": "2026-02-09 23:00:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ir1d6",
              "author": "danstermeister",
              "text": "It took me a full year to find the company I work for, and it was grueling.\n\n\nThat was 6 years ago and I feel for ya because I think its harder now.\n\nKeep your chin up.",
              "score": 26,
              "created_utc": "2026-02-09 23:19:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4j1e46",
                  "author": "Jesus_Chicken",
                  "text": "5 months for me in 2024. I only got hired cuz I did a great job while I was working. I'm shmoozing a few managers and looking at roles opening 2 spots above my current paygrade. I dont type fast but I'm that kinda engineer that can be excited doing anything, just throw shit at me and I got it.",
                  "score": 11,
                  "created_utc": "2026-02-10 00:16:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4npcvg",
                  "author": "Fi3nd7",
                  "text": "6 years ago was a phenomenal time to look for a job.... It's an order of magnitude worse now.",
                  "score": 3,
                  "created_utc": "2026-02-10 18:25:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ixp5n",
              "author": "bulldogncolt",
              "text": "Here's the thing, I remember being burnt my last month at the previous spot....they were nitpicking me for shit that went above and beyond normal housekeeping. I also remember how they were so pushing Claude and MCP servers...it was becoming annoying.",
              "score": 8,
              "created_utc": "2026-02-09 23:56:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4lcyf2",
              "author": "Altniv",
              "text": "Maybe OP should be the interviewer (start his own contracting firm)",
              "score": 3,
              "created_utc": "2026-02-10 10:35:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4inghc",
          "author": "Leucippus1",
          "text": "It is a cold winter, sorry you are caught up in it. I would wager about 34% of IT techs are worth their salt, you might be in that group and a lot of good talent is sitting on the market because of the mistakes of MBAs who are somehow still employed. The talent is so good I work with someone who has an honest to god CCIE, my company has no business with someone of that caliber but he decided big tech/business was not somewhere he wanted to be anymore and we do pay *enough*. ",
          "score": 105,
          "created_utc": "2026-02-09 23:00:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iu31n",
              "author": "CupFine8373",
              "text": "I have a CCIE, hire me !",
              "score": 12,
              "created_utc": "2026-02-09 23:36:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4lpwoj",
              "author": "LaserKittenz",
              "text": "People refuse to admit that companies overhired during the pandemic. ¬†I had to lay people off for bad performance and Facebook was hiring them triple what I paid them . ¬†I suspect this has a part to play in this tough job market¬†",
              "score": 2,
              "created_utc": "2026-02-10 12:21:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4iqpyp",
          "author": "Low-Opening25",
          "text": "It sucks. Last year I landed a job at top investment startup valued at billions but work culture turned out toxic beyond belief, I quit 2 months in since I don‚Äôt need this kind of bullishit in my life. I also had an interview at another one for Staff Platform Engineer, where I aced all stages and was the only candidate running by the 4th stage, just to be rejected at final 3h session with founders and team for absolutely ridiculous reason. Good I still have the contracts coming so at least my bank account isn‚Äôt completely empty yet.",
          "score": 34,
          "created_utc": "2026-02-09 23:17:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ix5ig",
              "author": "bulldogncolt",
              "text": "I had an offer from an ePrescriber two months ago, however, I distinctly remember feeling like they're an amateur hour shop within a few minutes of being interviewed by their CTO and Engineering Manager. They offered me the role, however, they went $20-30k below their own salary floor and justified by claiming that health insurance is compensation (that's technically true, however, that's just a bad faith argument from the jump, especially when I was reasonable and gave them a range that fell within their band). I lost all trust for this particular company because I had this feeling that would knife me when shit hit the fan.",
              "score": 18,
              "created_utc": "2026-02-09 23:53:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ju5ji",
                  "author": "mezbot",
                  "text": "20-30k is a lot more than they would pay their insurance provider a year to give you medical insurance.  Its a huge red flag if their offer was less than the range they advertised.",
                  "score": 10,
                  "created_utc": "2026-02-10 03:04:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4iq7ph",
          "author": "unitegondwanaland",
          "text": "A lot of great engineers are on the sidelines right now. There's not a lot you can do about it other than to keep grinding.",
          "score": 23,
          "created_utc": "2026-02-09 23:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iscu2",
              "author": "bulldogncolt",
              "text": "Capisco.",
              "score": 3,
              "created_utc": "2026-02-09 23:26:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4u1t5a",
                  "author": "ChosenToFall",
                  "text": "are you italian?",
                  "score": 2,
                  "created_utc": "2026-02-11 17:38:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4islaa",
          "author": "Gunny2862",
          "text": "If you feel like you're putting so much energy into this and getting nothing in return, I would suggest using some (not all of it) to find consulting work/get your own clients. Think about what you can do for one company that doesn't take up all your time, and then try doing that across a bunch of them.",
          "score": 19,
          "created_utc": "2026-02-09 23:28:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iy9vv",
              "author": "jeosol",
              "text": "That's good idea. Been thinking or doing that. I have some skills that I would like to leverage and do some work directly with companies.",
              "score": 11,
              "created_utc": "2026-02-09 23:59:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4jkexn",
          "author": "rustyrazorblade",
          "text": "I refuse to go through another one of these nonsense interviews. I started a solo consulting company instead. One of the best decisions I've ever made.",
          "score": 13,
          "created_utc": "2026-02-10 02:07:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4wzsht",
              "author": "Speeddymon",
              "text": "Did you start it while unemployed? How long have you been going? What type of consulting? I've wanted to make the jump for years but don't have any idea how to go about finding clients so I keep upskilling my tech skills and working for other people but I'm so ready to do it for myself.",
              "score": 2,
              "created_utc": "2026-02-12 02:47:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4x4r4x",
                  "author": "rustyrazorblade",
                  "text": "Yes, I had just gotten laid off from Netflix. I'm 3 years in now. I'm a database guy, but sometimes I do non-db stuff. \n\nThe first 18 months were hit and miss. I had a couple decent contracts, tried different things. I had a 4 month stretch where I didn't have any work, so i started live streaming on YouTube. We were getting ready to release Cassandra 5 (I'm a committer) so I just did sessions about it, and it got a surprising amount of interest. I wrote my own tooling to provision database environments and it includes a lot of performance analysis tools, so I would show people how to understand how the DB behaves.  \n\nRegarding interviewing, after speaking at a conference Microsoft asked me to interview for a principle engineer position to run the Cassandra fleet.  Want to know how many database questions they asked me in my interview?  Zero. Instead they asked me to write shortest path in Java in a Google doc.  I haven't needed to even think about that in 20 years. I found it was easier to just have fun doing what I like instead of trying to conform to what an employer wanted me to be.  I absolutely *hated* working in big tech.  Now I'm working on stuff I actually love working on, because I get to make all my own decisions and do exactly what I want, whenever I want.\n\nI won't say it's easy, but it's rewarding if you can muscle through it. Find a niche you enjoy, talk about it, become relevant.  Make it easy for people to find you. \n\nGood luck.",
                  "score": 2,
                  "created_utc": "2026-02-12 03:17:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jl0tn",
          "author": "toadi",
          "text": "I have been 30 years in IT now. I lost my job during the dot com bubble just a few years into my career. Had to become a bartender. Did this for almost 2 years. I did a hail Mary and started something on my own that actually grew out nicely. Sold it and went into contracting work. \n\nFinancial crisis arrived. Lost the contracting gigs as the whole marked dried out. I could not go bartending as now I had a family with kids and mortgage to pay. Went through my nest egg quickly. By the time my nest egg was gone I found work again.\n\nAfter COVID the startup I was working for. That had still a 4 year runway decided to cut 30% of their engineers. I lost my job again. Couple of months with no work either. Back at work again but only due to the fact I offered myself at 50% of my normal rate. Lucky I am now back in a position I can work as a bartender and pay all my bills. \n\nIt will all go with ups and downs. I know this is not advice. But I think it is how rocky says it is: ‚ÄúLife's not about how hard of a hit you can give... it's about how many you can take, and still keep moving forward.‚Äù",
          "score": 24,
          "created_utc": "2026-02-10 02:10:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jmcxe",
              "author": "bulldogncolt",
              "text": "I appreciate the perspective. 30 years is more than 9 years.",
              "score": 5,
              "created_utc": "2026-02-10 02:18:33",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4sa4ne",
              "author": "rhysmcn",
              "text": "Great comment, thanks for sharing",
              "score": 1,
              "created_utc": "2026-02-11 12:00:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4j3cjx",
          "author": "raisputin",
          "text": "I‚Äôm still gainfully employed (for now anyway) but I‚Äôm also wondering if it‚Äôs time to just hang it up‚Ä¶I‚Äôve dedicated my whole career to this, and am not ever wanting to do the types of interviews you are talking about. They‚Äôre largely a waste of time anyway, and really tell people little about how someone will actually do in the role.",
          "score": 12,
          "created_utc": "2026-02-10 00:28:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jn76d",
              "author": "superspeck",
              "text": "Yeah, this is basically where I am. But career changes in middle age are just near impossible.",
              "score": 9,
              "created_utc": "2026-02-10 02:23:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o54n8h3",
                  "author": "oldoverholt",
                  "text": "Same lol. My last and my current role have been fairly long term, and I don't really have any desire to leave my current one. But I absolutely dread getting laid off because of what I've heard about the job market at the moment.\n\nPart of me thinks I'll just make some drastic career change if I do get laid off (become a mail carrier, an electrician, go back to school for something, or work some mindless retail job) but in reality I think it's kind of nonsense to ditch tech altogether. I have it good working mostly remote and clicking around AWS and my terminal all day.",
                  "score": 1,
                  "created_utc": "2026-02-13 07:51:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jk6ob",
          "author": "putergud",
          "text": "It's time to quit when you can support yourself doing something else that you'd rather be doing.\nWhat kind of work would you do instead of this?\n\nI find that its better to run towards something than away from something.",
          "score": 11,
          "created_utc": "2026-02-10 02:05:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jr3ij",
              "author": "bulldogncolt",
              "text": ">What kind of work would you do instead of this?\n\nThat's not something for which I have a definitive answer, however, I see where you're coming from.\n\n>I find that its better to run towards something than away from something.\n\nTouche.",
              "score": 5,
              "created_utc": "2026-02-10 02:46:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4jufhu",
          "author": "Accomplished_Back_85",
          "text": "I get it coming from the perspective of having been out of a job for a while, but these four, five, even more rounds of interviews is ridiculous. I feel like if they can‚Äôt figure it out after three rounds, you just don‚Äôt need that stress in your life. It says a lot about how their org or maybe even the whole company does things. All I can really say is I wish you luck. It really sucks right now.",
          "score": 8,
          "created_utc": "2026-02-10 03:06:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ivzmw",
          "author": "Scoth42",
          "text": "I was unemployed for a little over a year, although I did take a month or month and a half \"off\" the job hunt around the holidays when I was just completely burned out. Tech industry is rough right now.",
          "score": 6,
          "created_utc": "2026-02-09 23:46:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jnhhg",
          "author": "calimovetips",
          "text": "burnout after six months of loops is real, and it doesn‚Äôt mean you‚Äôre wrong about tech or your ability. a lot of people at that point pause interviews for a few weeks or narrow to warm-network roles only, quitting entirely doesn‚Äôt have to be the first move.",
          "score": 6,
          "created_utc": "2026-02-10 02:25:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4joir3",
              "author": "bulldogncolt",
              "text": "Appreciate it. I will adjust accordingly.",
              "score": 2,
              "created_utc": "2026-02-10 02:31:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kgt3x",
          "author": "Admirable-Eye2709",
          "text": "It‚Äôs still a shitty market unfortunately. 2026 started with mass layoffs, however, I‚Äôm confident you will find a job soon and things will improve. Do not give up, but maybe cast a wider net and lower your salary expectations, just so you can get a job. Once you have a job, continue your search for larger paychecks within your desired wheelhouse. \n\nI just went through this and It took me 9 months to find an IC DevOps job with a great salary.",
          "score": 5,
          "created_utc": "2026-02-10 05:39:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ioftq",
          "author": "dgreenmachine",
          "text": "If your feedback has been poor \"culture fit\", \"too intense\", and \"not smiling enough\" then it sounds like you're fine technically and need to work on being more personable.",
          "score": 13,
          "created_utc": "2026-02-09 23:05:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ip42a",
              "author": "bulldogncolt",
              "text": "I have a neutral affect during the interviews. I grin and smile when necessary without acting like an overeager golden retriever.",
              "score": 5,
              "created_utc": "2026-02-09 23:09:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iqvs8",
                  "author": "blissadmin",
                  "text": "Not sure about you, but I've noticed that I consistently overestimate how much I am positively reinforcing rapport via body language.\n\nWhen I think I am neutral, I look at my face in Zoom and it often looks more like a scowl. When I think I am smiling, I check and it's really more neutral. When I think I am grinning like an overeager Golden Retriever, I'm barely cracking a smile.\n\nAt the risk of offending you, but coming from a place of sincerely hoping you crush every interview going forward, I will just say: smile harder than you think you need to.\n\nPS this grind really does suck. I last had to interview while a psycho new manager was speed running me out of my previous job, and even that pressure -- while getting paid -- was intense.",
                  "score": 14,
                  "created_utc": "2026-02-09 23:18:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ix5wg",
                  "author": "tevert",
                  "text": "The feedback you're getting would suggest otherwise\n\nEDIT: huh and he blocked me. Mystery solved, seems like.",
                  "score": 10,
                  "created_utc": "2026-02-09 23:53:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ixqwu",
                  "author": "N7Valor",
                  "text": "Practice.  I like watching Jeff Geerling videos for inspiration (as well as instruction on technical stuff).\n\nAs much as I hate to say this, much of society expects an \"extrovert ideal\", so you kind of have to bullshit your way enough to pretend to be an extrovert for the interviews even if you aren't.",
                  "score": 4,
                  "created_utc": "2026-02-09 23:56:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4l75pm",
              "author": "n00lp00dle",
              "text": "these reasons arent genuine. \n\n\"culture fit\" means you didnt go to their university or work with them previously. back office staff dont need to smile they arent waiting tables.",
              "score": 1,
              "created_utc": "2026-02-10 09:41:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r17f0",
                  "author": "dgreenmachine",
                  "text": "I would hate to work with people who are loose cannons or irritable all the time. That's not a pleasant working environment and it would make a big difference in hiring decisions for similar candidates that I'd work with regularly.",
                  "score": 0,
                  "created_utc": "2026-02-11 05:21:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jtkhr",
          "author": "systemsandstories",
          "text": "what you describe sounds like burnout from the processs not from the work itself. if this one does not land it miight be worth pausing or narrowing targets rather than makiing a permanent call while exhausted.",
          "score": 3,
          "created_utc": "2026-02-10 03:00:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k7g0p",
              "author": "bulldogncolt",
              "text": ">what you describe sounds like burnout from the processs\n\nPrecisely.\n\n>not from the work itself.\n\nI still love the job and learning every single day.\n\n\n>if this one does not land it miight be worth pausing or narrowing targets rather than makiing a permanent call while exhausted.\n\nNoted.",
              "score": 1,
              "created_utc": "2026-02-10 04:30:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4iwg1x",
          "author": "tiny_tim57",
          "text": "The answer is, never. You will eventually land the right role, and you will think it was worth it, even though it sucks now.\n\nI'm in a similar situation to you, though I'm still employed just looking for the next role at principal/staff level. I've gotten through to multiple final stages after doing live troubleshooting, system design, pair programming etc and it can be pretty demoralising and exhausting to to keep getting rejected.\n\nOne tip - don't tell yourself that this is the last chance. Tell yourself you will keep trying until you succeed, each time is a reset, otherwise the pressure will add too much stress to your life. It can be exhausting - take a short break, do something you enjoy and start again.",
          "score": 5,
          "created_utc": "2026-02-09 23:49:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jroo8",
              "author": "bulldogncolt",
              "text": "I will take it under advisement.",
              "score": 1,
              "created_utc": "2026-02-10 02:49:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lj87u",
          "author": "RecaptchaNotWorking",
          "text": "Culture fit: will you follow what we say to the tee.",
          "score": 2,
          "created_utc": "2026-02-10 11:31:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m4jbb",
          "author": "The_Career_Oracle",
          "text": "Currently working on on a 5 year plan to leave tech altogether. The pandering product owners and strategic nonsense that never seems to yield successful projects has just about worn me completely out.",
          "score": 2,
          "created_utc": "2026-02-10 13:51:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n2hzh",
          "author": "sikian",
          "text": "Was laid off around six months ago. That was my time to quit after 10y of different SWE/SRE positions. I guess everyone finds their time has come at some point. Maybe this is time is a strong warning the the time is close.\n\n\nIn any case, it's important to take care of your mental health. If you're struggling with the disappointment of poor leadership and misaligned expectations before landing a job, it might not get better a year into a job. So now is the time to do some soul-searching and finding what keeps you healthy in the day-to-day. For me it was leaving the cycle, but that's not the answer for everyone.\n\n\nBest of luck.",
          "score": 2,
          "created_utc": "2026-02-10 16:40:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n71mp",
          "author": "baezizbae",
          "text": "> I‚Äôm tied of [‚Ä¶] hiring managers who don‚Äôt know the difference between EC2 and AWS Lambda\n\nSame but engineering managers, ‚Äúarchitects‚Äù and tech leads. I was kvetching this in /r/devops, I‚Äôm watching my org recommend a client go multi-region kubernetes for a 20mb node application and middleware API that gets used by probably no more than 10 doctor‚Äôs offices. \n\nAll because my tech lead refuses to learn how resource limits work, and I‚Äôve reached ‚Äúdisagree and commit‚Äù stage with this job.",
          "score": 2,
          "created_utc": "2026-02-10 17:01:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n9hhu",
          "author": "ruibranco",
          "text": "Six months of interviews and you can articulate exactly what's broken about the process ‚Äî that alone tells me you're not the problem here.",
          "score": 2,
          "created_utc": "2026-02-10 17:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nu3sy",
          "author": "circalight",
          "text": "A good chunk of jobs are still filled through just knowing someone. I would take some of the energy you have and use it to get networking however you can. The hiring process is legit broken.",
          "score": 2,
          "created_utc": "2026-02-10 18:47:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k9mgv",
          "author": "defnotbjk",
          "text": "Meh, I wrote a huge big thing on what's helped me as I generally find a job within a month. I've had 3 jobs in the past 5 years, including one layoff w/ severance but then I re-read your post...\n\nAs a senior I interview and hire candidates pretty frequently now. It sounds like you're having no issues with getting interviews or getting to the tech round and you seem confident in how the tech round went, so.... \n\nWithout trying to sound like an ass. How would you say your social skills are? \n\nWe could interview the smartest, most technically skilled person who checks all the boxes we're looking for but if their social skills are not great. It's going to be a no. \n\nHonestly I feel my social skills have won me over other candidates that might be more \"technically better\". No one wants to work with an asshole every day or that person who thinks they're giving constructive feedback on PRs but it's really just condescending comments. I would almost go as far to say that [social skills:technical] chops is a 70:30~ ratio when considering a candidate. Obviously the reverse isn't good either(great social skills, lots of fluff on resume, lying about projects or how much they helped in said project, etc) \n\n\nedit: also to clarify, when I say \"social skills\" I don't mean how well you can present or lead a retro. I basically mean do you come off warm/friendly? Folks wouldn't be intimated to ask you a question? You can have back and forth feedback/discussion on ideas, problems & solutions without being flustered etc. I suck at presentations and avoid them when I can lol...\n\nThat's the only thing that comes to mind when someone says they get a lot of interviews, make it to the technical/final round but haven't landed anything. Outside of asking for some insane compensation package or not being open to anything but major established corporations/industries.",
          "score": 6,
          "created_utc": "2026-02-10 04:45:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j0vws",
          "author": "actionerror",
          "text": "Don‚Äôt give up. You‚Äôll land something when you least expect it. If you‚Äôre burnt out from the current round, take a week or two break. Good luck!",
          "score": 3,
          "created_utc": "2026-02-10 00:14:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j39b9",
          "author": "Bluemoo25",
          "text": "Mmmm, not time to quit youre landing interviews. People dont waste time on candidates they dont think will work out in the interview process.\n\nDo some learnings, find some very good questions to ask THEM about their org so you can get a feel and they will know you're not fresh off the campus.\n\nA book that has helped me is that old Dale Carnegie how to win friends and influence people, and it all comes down to getting into their head about their needs and what you can perceive. It goes into non-verbals, mirroring being authentic and engaged without being too much. Highly recommend it, if you have any inclination youre being screened on an intrapersonal basis rather than technical.\n\nIf youre getting screened out in the technical interviews, then it could be a sign of just needing work on clear technical communication, I dont have any book recs on that one.\n\nKeep grinding, for every 1000 potential opportunities 10 might work out and 1 of those might be the perfect fit. That's the norm, we have just been in a golden age for the past decade and the winds are changing. Stay up on hard AI tech (not just prompts) and dont get left behind.",
          "score": 2,
          "created_utc": "2026-02-10 00:27:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jngy9",
              "author": "superspeck",
              "text": "> People dont waste time on candidates they dont think will work out in the interview process.\n\nGiven the amount of bullshit interviews I‚Äôve had including four rounds before they told me that there was an internal candidate that they‚Äôd favored all along but they were interviewing me for ‚Äúcomparison‚Äù ‚Ä¶ (thanks, that‚Äôs a dozen hours of my life counting prep time that I‚Äôm never getting back) I would judge that most companies and managers are perfectly willing to waste everyone‚Äôs time with no return.",
              "score": 5,
              "created_utc": "2026-02-10 02:24:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4jrjnc",
                  "author": "bulldogncolt",
                  "text": "I had this exact same scenario happen to me about four months ago. Seven rounds just for them to call me repeatedly while I was at KubeCon's keynote and drop the news that they're going with the internal candidate because he's a cultural fit and that I was being used as an external reference candidate.",
                  "score": 1,
                  "created_utc": "2026-02-10 02:48:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jndfb",
          "author": "Invspam",
          "text": "dont know how many years you've been doing this but i always advocate to not just work on your technical skills but also maintaining past working relationships. it's a worthwhile upkeep that works both ways, it's a small world after all.\n\nit's not just what you know, it's who you know so if you haven't already, interview where your old coworkers are currently working at, maybe they can vouch for you, maybe even fast track you through the process.\n\ngood luck.\n\non flip side, you have identified a problem that's probably more common than we think. maybe there's space in the market for another linkedin 2.0 that can serve both to help you get the word out that you are looking for a new gig and also as a work reference.",
          "score": 2,
          "created_utc": "2026-02-10 02:24:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jo3nl",
              "author": "bulldogncolt",
              "text": "If you actually read the post, you‚Äôd see this role came *through* an existing relationship with a hiring manager I‚Äôve known for \\~6 years. It's in the very first paragraph of the my post.",
              "score": -2,
              "created_utc": "2026-02-10 02:28:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4jrz1f",
                  "author": "Invspam",
                  "text": "eh, i did read your post and also saw \"This role landed on my LinkedIn feed randomly.\" I took that to mean that if it wasn't for linkedin, you probably wouldn't have reached out. in any case, just trying to help. sounds like you've got everything figured out.",
                  "score": 2,
                  "created_utc": "2026-02-10 02:51:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kjwl7",
          "author": "gowithflow192",
          "text": "Get used to it. This is normal now, even if you‚Äôre in a current job. Had 8 rounds with a company only to reject me. Hiring is totally broken but what do?",
          "score": 1,
          "created_utc": "2026-02-10 06:04:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4km941",
          "author": "Brilliant_Use1936",
          "text": "Normally I would end it after the 1st interview since it looks like they are seeking free information aside from the resume.",
          "score": 1,
          "created_utc": "2026-02-10 06:24:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kqwvx",
          "author": "LittleCanadianBear",
          "text": "I really appreciate you for being so open in your post. The burnout is real, whether it be on the job or in an interview.\nKeep at it is all I can say.\nI have been trying too. Certifications can help but I don't think you lack them or the knowledge.\n\nAll the best! Hope AI doesn't kill us all!",
          "score": 1,
          "created_utc": "2026-02-10 07:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l66l8",
          "author": "storquake",
          "text": "Here's my two cents: \n\n1. Ask yourself with your current skills and the advancements of AI. What percentage of your work can be fully automated? This will help you figure out the areas to focus on. \n\n2. You do realize that the DevOps domain is shrinking. On an average, every product team has reduced significantly on DevOps. Figure out the adjoining areas where you can add immense value. \n\nI can understand your pain. Last year, I faced a similar struggle. I learnt it the hard way.",
          "score": 1,
          "created_utc": "2026-02-10 09:31:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4loga0",
          "author": "n00lp00dle",
          "text": "companies still need to interview even if they have no intention of hiring at the time. many adverts are for fake roles so they can build up a list of cvs. the industry is also in a massive offshoring phase. \n\nthis is my 3rd industry. i say if you have another field you can move to just do it. you wont find suggestions on here because the most commenters are lifers who work on tech all day and night (or bots but meh). \n\nas long as it pays enough for you to live and doesnt make you want to seppuku a job is a job.",
          "score": 1,
          "created_utc": "2026-02-10 12:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4manu5",
          "author": "WhiteshooZ",
          "text": "I can't add any advice, but know you're heard and not alone out there. These are dark times for our industry.",
          "score": 1,
          "created_utc": "2026-02-10 14:25:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nf4kq",
          "author": "IGnuGnat",
          "text": ">I don‚Äôt know if I have it in me to keep doing 5‚Äì7 round interview gauntlets\n\nOh dude I would just walk away if they wanted more then four interviews",
          "score": 1,
          "created_utc": "2026-02-10 17:39:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4o1gci",
          "author": "laincold",
          "text": ">or not smiling enough\n\nDamn, as European that interviewed in few US companies, that hit home...",
          "score": 1,
          "created_utc": "2026-02-10 19:20:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4odeyr",
          "author": "gregserrao",
          "text": "25 years in tech, mostly banking infrastructure. I've been on both sides of this. Hired people, been hired, been passed over for roles I could do in my sleep.\n\nThe interview process in tech is broken and everyone knows it but nobody fixes it because the people designing it aren't the ones suffering through it. Seven rounds to hire a DevOps engineer is insane. No other industry does this to senior professionals.\n\nBut here's the thing. You're not tired of tech. You're tired of the hiring theater around tech. Those are two very different things. Walking away from the work because the interview process is garbage is like quitting cooking because grocery stores have long lines.\n\nWhat I'd actually consider if I were you: stop playing their game entirely. Six months of interviews means six months of proving yourself to people who can't tell EC2 from Lambda. That energy could go into building something that proves your value without a panel deciding if you smiled enough. Consulting, contract work, building in public. Anything where YOUR work speaks instead of your performance in a 45 minute behavioral round.\n\nThe best move I ever made was realizing that the traditional hiring path isn't the only path. It's just the default one.\n\nHope you get this offer though. Sounds like you earned it.",
          "score": 1,
          "created_utc": "2026-02-10 20:16:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4otumz",
          "author": "Mishka_1994",
          "text": "I was also laid off over a year ago and it took me 6 month to land a job. I also had the take home tasks and 5 round interviews only to get rejected without any quality feedback. Yes its very demoralizing.\n\nThat said, I did take a month off interviewing when I was let go. I guess that allowed me to \"recharge\" a little bit, because interviewing and applying is a job in itself. I would recommend doing that. Just take a month or so break for yourself. Travel somewhere (if you have the extra funds) or just relax.",
          "score": 1,
          "created_utc": "2026-02-10 21:32:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vt6xk",
          "author": "Guilty-Commission435",
          "text": "Just take a break, bro you‚Äôre good at what you do. Come back to it when you‚Äôre ready.\n\nYou‚Äôre just tired. You need to go on a walk get your mind off of applying.",
          "score": 1,
          "created_utc": "2026-02-11 22:40:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vt83i",
              "author": "Guilty-Commission435",
              "text": "Play the long game",
              "score": 1,
              "created_utc": "2026-02-11 22:41:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ipckv",
          "author": "AdventurousYear7134",
          "text": "It just sounds like your soft skills aren't... marketable. Perhaps that might be worth reflecting on?",
          "score": 1,
          "created_utc": "2026-02-09 23:10:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ir4d9",
              "author": "danstermeister",
              "text": "I didnt get that",
              "score": 4,
              "created_utc": "2026-02-09 23:20:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iqn5v",
              "author": "bulldogncolt",
              "text": "I am personable...just not in a golden retriever type of way. Thanks for your rusty 2¬¢, though.",
              "score": 2,
              "created_utc": "2026-02-09 23:17:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4iotdr",
          "author": "BenchOk2878",
          "text": "never!",
          "score": 1,
          "created_utc": "2026-02-09 23:07:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jmebz",
          "author": "klipseracer",
          "text": "Hey, you could always go work a blue collar job or a trade where the senior tradesmen are gatekeeping all the knowledge and experience so you can't move ahead of them.",
          "score": 1,
          "created_utc": "2026-02-10 02:18:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jn3c6",
              "author": "bulldogncolt",
              "text": "It's no different from what's happening right now. Beyond a certain point, a fifth or sixth round interview is just IP theft dressed as another system design interview. The very ideas we share in an interview probably gets implemented in-house and shared on a Medium post 14 months down the line. Don't tell me it doesn't happen.",
              "score": 3,
              "created_utc": "2026-02-10 02:22:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lu9au",
                  "author": "zzrryll",
                  "text": "> a fifth or sixth round interview is just IP theft dressed as another system design interview. The very ideas we share in an interview probably gets implemented in-house and shared on a Medium post 14 months down the line. Don't tell me it doesn't happen.\n\n\nThat‚Äôs an almost pathologically paranoid opinion. No one interviews for that reason.",
                  "score": 2,
                  "created_utc": "2026-02-10 12:51:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4jkigz",
          "author": "Trakeen",
          "text": "I haven‚Äôt interviewed in this job market but for my current role after 2 months of not getting an offer (though i did turn one down because i didn‚Äôt like the manager) i took a step back and reviewed my interview approach and then adjusted how i responded to questions. I had an offer after that\n\nNever had problems with resume or getting to late stages in the process. We‚Äôve interviewed a few lead positions lately and normally toss for lack of technical or culture fit. If people don‚Äôt want to work with you, there is a lot you can do yourself to fix that. You can control that; you can‚Äôt control the market",
          "score": -1,
          "created_utc": "2026-02-10 02:07:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jqfdf",
              "author": "bulldogncolt",
              "text": "Respectfully, ‚ÄúI haven‚Äôt interviewed in this market‚Äù should‚Äôve been where you stopped. You just wrote two paragraphs to prove you didn‚Äôt read mine. I‚Äôm not struggling to *get* interviews. I‚Äôm just burned out from the *gauntlet*. Different problem.",
              "score": 6,
              "created_utc": "2026-02-10 02:42:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4lgk5y",
                  "author": "Trakeen",
                  "text": "You didn‚Äôt read mine. Others in the thread pointed out the way you interview is the issue. The way you responded is the issue. You can control how you respond to feedback. It is an important skill when working with others",
                  "score": 1,
                  "created_utc": "2026-02-10 11:08:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4k9j1o",
          "author": "Willbo",
          "text": "At the end of 2019 I left my IT job to focus on my own entrepreneurial efforts in the gig economy. I created my own digital products, my own marketing, and got into solutions architecting, working directly with startups in my area. It was fascinating and exercised the \"bigger picture\" part of my brain; speaking with clients, translating technical needs, creating contracts.\n\nThen the pandemic happened and flipped everything on its head. Projects were on hold, people were afraid, and there was a lot of hesitation. Cancelled my lease, moved in with parents, and spent a lot of time trying to pivot into global markets (a lot of SEO, outreach.. BS, boxed wine) but it wasn't very fruitful.\n\nI ended up getting back into traditional employment, but if I had to do it again I would double down on local gig economies and traditional marketing. It felt like I was giving back to my community, making a difference, and seeing the product from start to finish. Rather than orgs interviewing me if I was a fit, I was interviewing them if I could help. I would definitely recommend this to anyone looking to step away from traditional big orgs, even if its just temporarily.",
          "score": 0,
          "created_utc": "2026-02-10 04:45:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q6hzh",
          "author": "Stock-Pangolin-2772",
          "text": "I'm wondering this myself, I just got back from Manila and the amount of people working in tech is growing . The market is saturated because not only are you competing with local talent. You're competing with remote talent as well. If you think timezone is an issue for tech workers in Manila (think again) ",
          "score": 0,
          "created_utc": "2026-02-11 01:59:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r22itf",
      "title": "Logging is slowly bankrupting me",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r22itf/logging_is_slowly_bankrupting_me/",
      "author": "Round-Classic-7746",
      "created_utc": "2026-02-11 16:48:40",
      "score": 164,
      "num_comments": 85,
      "upvote_ratio": 0.86,
      "text": "so i thought observability was supposed to make my life easier. Dashboards, alerts, logs all in one place, easy peasy.\n\nFast forward a few months and i‚Äôm staring at bills like ‚Äúwait, why is storage costing more than the servers themselves?‚Äù retention policies, parsing, extra nodes for spikes. It‚Äôs like every log line has a hidden price tag.\n\nI half expect my logs to start sending me invoices at this point. How do you even keep costs in check without losing all the data you actually need",
      "is_original_content": false,
      "link_flair_text": "Observability",
      "permalink": "https://reddit.com/r/devops/comments/1r22itf/logging_is_slowly_bankrupting_me/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4tu0g4",
          "author": "Phezh",
          "text": "Which tooling are you using? You can save a lot of money by self hosting, but that will obviously come with more administration overhead.\n\nYou might also just be logging too much. If a log line doesn't help you, remove it. Logs are important, but being concise and clear with your logging is half the battle.",
          "score": 153,
          "created_utc": "2026-02-11 17:01:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vf6fi",
              "author": "ansibleloop",
              "text": "Yeah, to tack onto this\n\n- Ensure all your logs are ingested using an API key per-service (makes filtering way easier)\n- Phase your logs out over time (keep debug for 24h, dev for 3d, staging for 7d, prod for 30d)\n- Managed log services will charge you an arm and a leg for something you can do using Loki and a decent box with lots of fast storage and CPU",
              "score": 44,
              "created_utc": "2026-02-11 21:31:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4xbqg6",
                  "author": "x0n",
                  "text": "Retention isn't the killer; it's straight up ingestion.",
                  "score": 10,
                  "created_utc": "2026-02-12 04:03:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xxsn6",
                  "author": "Round-Classic-7746",
                  "text": "yeah, makes sense. We‚Äôve definitely been hoarding way too many logs. Really appreciate all the tips, gives me some stuff to actually act on",
                  "score": 3,
                  "created_utc": "2026-02-12 07:01:02",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o4xivkr",
                  "author": "dektol",
                  "text": "If you're on a budget or don't want the complexity of Loki \nGrafana integrates well with Victoria Metrics & Logs. They have great charts and are much easier to run if you don't mind storage on disk instead of object storage. Performance is better overall. No full text search right now though across keys. Only downside I've seen so far.",
                  "score": 2,
                  "created_utc": "2026-02-12 04:55:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o54p8dr",
                  "author": "SnooWords9033",
                  "text": "You can save infrastructure and operational costs for self-hosted database for logs even more by switching from Loki to VictoriaLogs, since it is easier to setup and operate, and it doesn't need object storage for production setup. VictoriaLogs also supports high-cardinality log labels such as user_id, trace_id, ip, etc. out of the box without the need to configure anything.",
                  "score": 1,
                  "created_utc": "2026-02-13 08:10:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4upt4k",
              "author": "db720",
              "text": "Your 2nd concern is on point. Define internal logging standards . Include these standards as part of non functional requirements.\n\nThere are a few patterns that you could reference. Eg wrapping debug logs in \"if debug\" statements",
              "score": 18,
              "created_utc": "2026-02-11 19:29:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4vl18f",
                  "author": "jasie3k",
                  "text": "If debug statements help with computational cost of producing compute heavy logs, things like complex object serialisation that might end up in /dev/null.\n\nFor the observability cost / log volume setting the log level to a higher one (info) should be enough.",
                  "score": 8,
                  "created_utc": "2026-02-11 21:59:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tud6l",
          "author": "xonxoff",
          "text": "No one said observability was cheap or easy. When I started, I would log everything and grab every metric, but you know, 90% of it was never looked at. Then the hard part comes in, what do I actually need? Gatekeeping can suck, but sometimes you have to do it.",
          "score": 56,
          "created_utc": "2026-02-11 17:02:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y6fxj",
              "author": "moratnz",
              "text": "99% of metrics will never be looked at. The problem is you don't know which 99% in advance.",
              "score": 19,
              "created_utc": "2026-02-12 08:23:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4vfdbt",
              "author": "ansibleloop",
              "text": "Retention is key\n\nCPU, RAM, disk and network? Always useful data - keep that for a year\n\nRandom container data? Clear it out when a container dies and/or limit it to 30 days",
              "score": 2,
              "created_utc": "2026-02-11 21:32:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4wmxm2",
                  "author": "Canecraze",
                  "text": "Or less.  In a 24/7 environment, many app logs are useless and a day or three.  \n\nCreate filters to not ingest noise. Move logs to separate log buckets with different retention.",
                  "score": 10,
                  "created_utc": "2026-02-12 01:30:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zkyic",
                  "author": "keto_brain",
                  "text": "Yea but those aren't logs or shouldn't come from logs, those should be stored in a timeseries db, much less expensive. ",
                  "score": 1,
                  "created_utc": "2026-02-12 14:44:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4xm1je",
                  "author": "Nitrodist",
                  "text": "What the hell does this mean",
                  "score": -6,
                  "created_utc": "2026-02-12 05:19:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tuz0m",
          "author": "Mrbucket101",
          "text": "Sample your traces.\n  \nIncrease your polling interval in Prometheus\n  \nUse a logging framework, and set LOG_LEVEL env vars. Bonus points for structured logs (JSON FTW)\n  \nLifecycle policies for storage tiers and expiration of your S3 buckets",
          "score": 42,
          "created_utc": "2026-02-11 17:05:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4we08b",
              "author": "Aware_Magazine_2042",
              "text": "And when you sample your traces, make sure you capture those logs too! Nothing is more frustrating than sampling traces and sampling the logs separately and then you can‚Äôt find the smoking gun because the traces and the logs have to align perfectly.\n\nIf you sample traces at 10%, then sample logs seperately at 10%, then you actually only have a 1% chance of finding the log you need in the traces you need. I have been part of a few outages where we can see the traces failing, and the part that is failing kind of, but you couldn‚Äôt read the logs to actually see what has happening. And you look at the code and the logs are there, but they only ever seem to show the successful case.",
              "score": 5,
              "created_utc": "2026-02-12 00:36:26",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4xv0n1",
              "author": "Round-Classic-7746",
              "text": "this is solid advice, thank you. Sampling traces is something we‚Äôve talked about but haven‚Äôt actually enforced yet. \n\nand yeah‚Ä¶ lifecycle policies. We set them once and then never revisited them. probably time to actually audit what we‚Äôre keeping and why.",
              "score": 1,
              "created_utc": "2026-02-12 06:36:04",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4urgds",
              "author": "alexlazar98",
              "text": "Basically this.",
              "score": 0,
              "created_utc": "2026-02-11 19:37:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4u1qdn",
          "author": "sudojonz",
          "text": "It's getting harder for me to tell if this is an LLM post or if people are starting to write like LLMs. I hate this timeline.",
          "score": 71,
          "created_utc": "2026-02-11 17:37:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vt1rj",
              "author": "tevert",
              "text": "I'm waiting for another \"redditor\" to pop in with a nicely formatted comment about how they switched to <product> and saved 20-30% on their bill, and now you can too!",
              "score": 16,
              "created_utc": "2026-02-11 22:40:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w3la5",
                  "author": "ycnz",
                  "text": "You can spot the real people by the amount of time they wistfully talk about becoming a goat herder instead.",
                  "score": 5,
                  "created_utc": "2026-02-11 23:36:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4uberc",
              "author": "nooneinparticular246",
              "text": "Yeah the vague whinging is sus. Regardless, if they can‚Äôt tell us their stack and which product/services are blowing out their bill, they don‚Äôt deserve free advice",
              "score": 29,
              "created_utc": "2026-02-11 18:22:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4uiyyn",
                  "author": "anomalous_cowherd",
                  "text": "They need to log some detailed stats for a month or two first.",
                  "score": 6,
                  "created_utc": "2026-02-11 18:57:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4vjyrf",
              "author": "mavenHawk",
              "text": "They are just advertising. This is usually the case on reddit. \"X sucks. What do you guys do?\". Then they answer from a different account \"We use Y and really like it\".\n\n\nIt's always been a thing but now with AI they don't even write the original post and just slop it.",
              "score": 23,
              "created_utc": "2026-02-11 21:54:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4x00yb",
              "author": "best_of_badgers",
              "text": "A non-trivial part of that is non-native English speakers using LLMs to translate and improve the language for them.\n\nMakes it even harder to weed out the grifters.",
              "score": 5,
              "created_utc": "2026-02-12 02:48:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4v7z6w",
              "author": "DangKilla",
              "text": "I questioned the upvote algorithm nowadays. Does it really make sense to upvote everything we agree with? Not if it‚Äôs a marketing headline, right",
              "score": 2,
              "created_utc": "2026-02-11 20:57:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4wgesr",
              "author": "UpsetCryptographer49",
              "text": "I hate it more than you do, beep-bop",
              "score": 2,
              "created_utc": "2026-02-12 00:50:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4xw7z4",
              "author": "Round-Classic-7746",
              "text": "Same üò¨",
              "score": 1,
              "created_utc": "2026-02-12 06:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4useei",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 17,
          "created_utc": "2026-02-11 19:41:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uuz6w",
              "author": "zeph1rus",
              "text": "Yeah this 100% \n\nYou can always increase logging in a targeted manner if you have problems, then back off once solved. \n\nThis applies to metrics too, so much chaff out of the box especiall with otel",
              "score": 3,
              "created_utc": "2026-02-11 19:54:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uyiu1",
          "author": "engineered_academic",
          "text": "If the log isnt actionable, it should be a metric instead.",
          "score": 8,
          "created_utc": "2026-02-11 20:11:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w6ri3",
              "author": "DSMRick",
              "text": "And/Or behind a debug flag.¬†",
              "score": 2,
              "created_utc": "2026-02-11 23:54:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4w3gls",
          "author": "ycnz",
          "text": "Ah, I see you use Datadog too.",
          "score": 7,
          "created_utc": "2026-02-11 23:35:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4twnzq",
          "author": "32b1b46b6befce6ab149",
          "text": "Find the most frequent useless logs and filter them out. Depending on your stack there are some quick wins to be had. For example [ASP.NET](http://ASP.NET) core logs 4 or 5 messages for every HTTP request. You can swap it with your own implementation that only logs 1 line and has all of the information. That's 75%-80% reduction of log volume instantly.\n\n",
          "score": 6,
          "created_utc": "2026-02-11 17:13:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v8rka",
          "author": "lordofblack23",
          "text": "Get off splunk üòâ",
          "score": 6,
          "created_utc": "2026-02-11 21:01:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vsyzb",
              "author": "centech",
              "text": "The ole, Splunk->Sumo Logic->Self Hosted ELK->WTF are we logging so much crap anyway?! progression. :D",
              "score": 3,
              "created_utc": "2026-02-11 22:39:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uts6k",
          "author": "kxbnb",
          "text": "Ran into the same thing. The pattern is always: log everything \"just in case,\" storage bill explodes, panic about what to cut.\n\nWhat helped us: start from the questions you'd ask during an actual outage. \"What request hit this service?\" \"What did we send downstream?\" \"What came back?\" Log those things. Everything else is debug-level and gets dropped in prod unless you're actively troubleshooting something.\n\nQuick win: figure out which services are noisiest. Usually 2-3 services account for 70%+ of your log volume - health checks, load balancer pings, verbose framework defaults. Kill those first before you touch anything else.",
          "score": 6,
          "created_utc": "2026-02-11 19:48:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v3ves",
          "author": "Gunny2862",
          "text": "There's a reason the movement to self-hosting is a thing.",
          "score": 4,
          "created_utc": "2026-02-11 20:37:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w7hqb",
          "author": "DSMRick",
          "text": "Obsevability vendor sc here. I am constantly seeing people logging mountains of absolute shit and wondering why they are paying so much. You don't need the stack trace of every error. And you don't need any logs Noone is reading. If you don't have an alert or at least a dashboard based on a log why are you writing it at all, let alone sending it.¬†",
          "score": 4,
          "created_utc": "2026-02-11 23:58:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ubxni",
          "author": "Low-Opening25",
          "text": "what do you need the logs for? anything older than 7 days >> /dev/null",
          "score": 2,
          "created_utc": "2026-02-11 18:24:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4urkkb",
          "author": "Otherwise-Tree-7654",
          "text": "Wait i assume u dont run debug/info level, go with warn/error - and please clean ur shit up dont warn just because. warn on 4xx and err on 5xx- have primary source of monitoring on metrics (counters, histograms, gauges,timer)",
          "score": 2,
          "created_utc": "2026-02-11 19:37:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v7aq0",
          "author": "uncommon_senze",
          "text": "So much observability dont know what to look at ;-)\n\n",
          "score": 2,
          "created_utc": "2026-02-11 20:54:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wlj9m",
          "author": "scott2449",
          "text": "The best app I ever worked on / ran was set to error and errors were only thrown for truly heinous stuff. We never had any issues debugging things because of too few logs. This was before modern telemetry. Hard to find a team that will go with this approach, worse if you are trying to do a whole dept. The one thing my devops team does now is centrally control logs, so if teams abuse the system they just cut you back or off and tell you to come back when you get your shiz under control. I also don't think folks realize how much of a performance impact logging has. They are like how come my app can only do 100 rps.. well maybe if 90% of your writes and serialization work was not logging you could handle I dunno 10x requests with the same code.",
          "score": 2,
          "created_utc": "2026-02-12 01:21:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zp9br",
          "author": "rustyrazorblade",
          "text": "Zero details about the setup. Who upvotes this? There‚Äôs nothing of value here.¬†",
          "score": 2,
          "created_utc": "2026-02-12 15:06:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u4w8s",
          "author": "placated",
          "text": "Pipeline your data to dedupe / sample it. There are a lot of great modern pipeline apps from opensource like Vector or commercial like Cribl or Edge Delta. Cribl‚Äôs ROI is insane if you implement it effectively and run expensive backends like Splunk or Datadog.",
          "score": 2,
          "created_utc": "2026-02-11 17:52:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u8tjp",
          "author": "jay-magnum",
          "text": "We spent a gazillion ‚Ç¨‚Ç¨ on logs an turns out we're logging all kinds of BS without anyone asking for it, default log levels way too low. You should ask what you actually need from these logs.",
          "score": 1,
          "created_utc": "2026-02-11 18:10:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ubvx6",
          "author": "aenae",
          "text": "I just used three old servers out of warranty with 12 2TB ssd‚Äôs i had lying around to set up a graylog server. I do limit it to 1TB per month tho",
          "score": 1,
          "created_utc": "2026-02-11 18:24:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ud7t8",
          "author": "SupportAntique2368",
          "text": "Observability is not cheap, and logs if not managed correctly can the biggest contributor of this.\n\nFirstly, reducing unnecessary logs and using metrics more is key. I don't know if you use an apm tool but having less logs and on cold storage, then jumping into an issue via apm which then shows the correlated logs at the time windows that are relevant will help this a lot.\n\nMy problem has always been a platform admin, the log source isn't in my control, and trying to educate devs on this and asking them to not leave debug on all the time or log every last drop of content in the world to info, just because they can, is very challenging. It's really about education and culture in that scenario and then using the platform side to do as best as you can with things like cold storage, shorter retentions where possible, and maybe even enforcing logging schemas depending on the tool of choice (helps with elastic for instance, less so with dynatrace).",
          "score": 1,
          "created_utc": "2026-02-11 18:30:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ugm2h",
          "author": "daedalus_structure",
          "text": "I see this every day. \n\nEvery request that the server processes generates at least one order of magnitude more metadata in logs and metrics than were present in the request. \n\nObservability that has been implemented without intent will frequently become your top line-item expense.",
          "score": 1,
          "created_utc": "2026-02-11 18:46:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uji6t",
          "author": "One-Department1551",
          "text": "At some point in compliance you stop caring about log costs and care about lawsuits.",
          "score": 1,
          "created_utc": "2026-02-11 18:59:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ul866",
          "author": "OMGItsCheezWTF",
          "text": "Structured logging, fingers crossed logging in production (the log entries are generated but only surface if an actual error occurs) - ensure all logs are relevant and useful.\n\nWhen we started this exercise on one of our main applications it quickly became apparent that the majority of log entries were of no use to anyone unless you were actively developing the thing that was logging, and was never going to be useful in production.",
          "score": 1,
          "created_utc": "2026-02-11 19:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v6ig5",
          "author": "spline_reticulator",
          "text": "Are you sampling the logs?",
          "score": 1,
          "created_utc": "2026-02-11 20:50:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wiz0g",
          "author": "Rizean",
          "text": "We were spending almost $1k a month on Cloud Watch. The first issue was that our flow log details were way too high. Adjusting that cut the bill in half. From there, we broke up our log groups. Separated out the logs we needed for auditing/compliance from the logs we needed for troubleshooting. Audit logs got the 12-month retention or whatever they required. Non-audit logs were set to 2-4 weeks, depending on the app. Next, we have been spending time auditing the logs themselves to ensure they have appropriate log levels. Debug/Trace never gets logged to CloudWatch.\n\nIt's a trickty knowing what to log. In December, we logged just over 1TB. January was 877GB, and this month we are on track to be just under 500 GB. We still have work to do. We could save a lot if we didn't use CloudWatch, but then the admin cost and effort to switch 50+ ECS services off CW... the worst part? It's not even the storage that gets us, but the ingest cost!",
          "score": 1,
          "created_utc": "2026-02-12 01:05:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4woj2f",
          "author": "TheGRS",
          "text": "For me it‚Äôs been about working at places where the budgets are as opaque as a lead box.\n\nBut seriously, I hope you have a tool that breaks the costs down well. Datadog might be expensive but they are really good at breaking down where your spend is. From there you should be able to figure out what‚Äôs producing more logs or metrics than what you need. We had a lot of ‚Äúcustom metrics‚Äù for instance that seemed really neat when we set them up but cost waaay more than they were useful. Nixed that. In one case our mobile team was logging everything that was unnecessary because they didn‚Äôt understand observability.",
          "score": 1,
          "created_utc": "2026-02-12 01:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4x31nz",
          "author": "kiss_a_hacker01",
          "text": "You should make evaluating your logging rules a priority, like yesterday. My app had a pod scheduling issue with kubernetes last week. It created 237 million logs in 24 hours and and then sorted itself out, but it still cost $2300. That $2300 oopsie forced the higher-ups to direct the infrastructure team to focus on reevaluating the log storage, and they're now expected to save ~$45k over the next 12 months.",
          "score": 1,
          "created_utc": "2026-02-12 03:07:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xxh8g",
          "author": "pbacterio",
          "text": "Split the platform in tenants and lnk the cost to the projects using it.",
          "score": 1,
          "created_utc": "2026-02-12 06:58:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y4f8v",
          "author": "Verzuchter",
          "text": "Log levels are here to serve you, looks like you're not using them or using them incorrectly.",
          "score": 1,
          "created_utc": "2026-02-12 08:03:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yh5bz",
          "author": "ultrathink-art",
          "text": "The volume-based pricing model is brutal. A few things that helped us reduce log costs significantly:\n\n1. **Structured logging levels by environment** - Debug/trace logs only in dev, never in prod. Sounds obvious but we found dozens of verbose logging statements that shipped to production.\n\n2. **Sample high-volume logs** - For requests/jobs that run thousands of times per hour, log 1% with full detail, rest with just errors. We hash the request ID and sample deterministically so you can still trace a specific request if needed.\n\n3. **Pre-filter before shipping** - We run a lightweight log processor on the app server that drops known noise (health checks, bot requests, etc.) before sending to our log aggregator. Cuts volume by ~40%.\n\n4. **Retention tiers** - Hot logs (7 days) in fast storage, warm logs (30 days) in cheaper storage, cold logs (90+ days) in S3/GCS with Athena/BigQuery for occasional queries.\n\nWhat's your current stack? The optimization approach varies a lot depending on whether you're using CloudWatch, Datadog, Splunk, etc.",
          "score": 1,
          "created_utc": "2026-02-12 10:09:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yhqm2",
          "author": "Everyday_normal_guy1",
          "text": "Think about it, youre paying one vendor to run your stuff and a completley separate vendor to understand what your stuff is doing. That second vendor charges per GB ingested, per host, per custom metric, per span. Your app grows, logs grow with it, and that bill scales independantly from the value youre actually getting. Thats why storage ends up costing more than the servers.\n\nFew things that helped me\n\nSelf hosting your observability stack (Grafana + Loki + Prometheus, or SigNoz as an all in one Datadog replacement) saves a ton but now youre babysitting more services. Worth it if you have the bandwith.\n\nSwitching to a platform that bundles observability into compute cost was the bigger win for me. I moved to Quave ONE and the built in Grafana dashboards, ingress metrics grouped by path/status/response time, app logs with search and WAF logs just come included. No agents, no collectors, no seperate bill. Covers like 80% of what I was paying Datadog for. Railway and Render have some built in metrics too and Coolify is solid if you want full self hosting on your own VPS.\n\nIf youre staying on Datadog/New Relic at least look at Grafana Cloud, free tier is surprisingly generous (50GB logs, 10k series) and paid is way cheaper per GB. Also ask your vendor about committed use discounts, most people dont and leave money on the table.\n\nThe logging hygene advice everyone else gave is real but if your setup is structurally designed to charge you twice for everything no amount of sampling fixes the underlying problem.",
          "score": 1,
          "created_utc": "2026-02-12 10:14:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yygu7",
          "author": "Standardw",
          "text": "Only log warnings, turn on info or maybe debug when debugging",
          "score": 1,
          "created_utc": "2026-02-12 12:34:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yylqd",
          "author": "SudoZenWizz",
          "text": "When i'm monitoring systems and applications and SIEM, one key aspect for me for this is retention policy and selected logs.  I've chosen to use for logs only required patterns in order to alert if something critical/warning occurs and don't keep every log there.\n\nAs mentioned before, some other metrics are also very important: Systems usage, application status. \n\nI'm using checkmk on premise for keeping all logs monitoring and systems monitoring.\n\nFor logs retention I am using wazuh and have a strict policy of 90 days retention. These are mostly needed for compliance not for real debugging of an issue.",
          "score": 1,
          "created_utc": "2026-02-12 12:35:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z0bz4",
          "author": "_1dontknow",
          "text": "What tooling and log framework do you use? Also whats your retention policy (30 days, 90 days etc)\n\nI wouldnt recommend cloud providers for non VC funded startups. Use self hosted tools and manage your logs yourself.",
          "score": 1,
          "created_utc": "2026-02-12 12:47:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o507edh",
          "author": "jjneely",
          "text": "The Observability market is definitely tilted toward the vendors.  Some are truly worth the value they bring.  Most aren't. I find that using vendors strategically with other cheaper solutions ends up providing the best value.  If you need a viewpoint from someone that isn't a vendor please DM.  Glad to lend a hand where I can.",
          "score": 1,
          "created_utc": "2026-02-12 16:32:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50889s",
          "author": "Unusual-Dinner6355",
          "text": "This is classic example of high cardinality issue. Now a days every monitoring solution uses time series data base like influxdb or prometheus to ingest data, Now if you have multiple values for a particular tag , the database will index all values. As the tag combination keeps growing at the db level there will be excessive number of indexed combinations will result in ¬†increased memory usage, slow queries, and write performance bottlenecks.\n\nSo the paid monitoring solution what they does they charge you on basis of cardinality number. Because behind the scene internally they have to manage more replicas for the backened.\n\nSo you have to check the ingestion layer first. So before ingesting data first check which tag you will use to filter out the events. You can have multiple variation of values end.\n\nHope now you will save some money :)",
          "score": 1,
          "created_utc": "2026-02-12 16:36:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o526f1z",
          "author": "Deep_Ad1959",
          "text": "the circle of life: add logging to debug a problem -> problem gets fixed -> forget to remove debug logging -> now you have a new problem (your cloud bill). repeat until bankruptcy.",
          "score": 1,
          "created_utc": "2026-02-12 22:08:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o589i7l",
          "author": "moneat-io",
          "text": "This is exactly why I founded moneat.io. I'm tired of the huge mark-ups on services like Sentry, DataDog, PagerDuty, etc. Currently our pricing is simple without artificial limits on errors/transactions/replays, etc. ",
          "score": 1,
          "created_utc": "2026-02-13 20:48:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58utsg",
          "author": "Wide_Commission_1595",
          "text": "Sampling is your friend here.\n\nIf you can configure things to save ~5% of logs, but all logs that contain errors, you can save a heap of cash.\n\nThis is where otel has the edge, but even without full otel, wide events can really help.\n\nCheck out https://loggingsucks.com/ for a bit more info",
          "score": 1,
          "created_utc": "2026-02-13 22:35:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bnudq",
          "author": "ResponsibleBlock_man",
          "text": "Do you look at metrics that are year old? If so why?",
          "score": 1,
          "created_utc": "2026-02-14 11:17:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1zv0",
          "author": "Agr_Kushal",
          "text": "My company integrates with a lot of external partners so logs become very important to us, sometimes the lack of logs is what makes our heads bobble. So, we have a simple retention policy in place majorly all dev logs are phased out within max a week, prod logs are stored for 2 months.",
          "score": 1,
          "created_utc": "2026-02-14 13:13:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hrazx",
          "author": "Polliog",
          "text": "Yeah, observability vendors have this genius business model where they charge you per GB ingested, so the better you instrument your app, the more you pay. It's backwards.\n\nI got so annoyed with this I ended up building my own thing (Logtide, it's open source). Basically TimescaleDB + retention policies + tiered storage. Not saying you should use it, but the architecture might give you ideas",
          "score": 1,
          "created_utc": "2026-02-15 11:38:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uss6b",
          "author": "crash90",
          "text": "Use something open source like elk stack for stuff that isn't logged by the cloud provider. Keep recent logs around, rotate the rest out to cheap storage.\n\nLogging is very affordable this way.",
          "score": 1,
          "created_utc": "2026-02-11 19:43:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4vxi4y",
          "author": "ArieHein",
          "text": "Victoria Metrics and Victoria Logs.",
          "score": 1,
          "created_utc": "2026-02-11 23:03:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4u3elx",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 0,
          "created_utc": "2026-02-11 17:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ubqgr",
              "author": "nooneinparticular246",
              "text": "I like Vector for this. You can have a pipeline that sends raw logs to S3, and filtered and masked logs to Datadog/New Relic/self-hosted-thingo",
              "score": 1,
              "created_utc": "2026-02-11 18:23:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4udp4e",
                  "author": "ChaseApp501",
                  "text": "we are adding support for Vector in [https://github.com/carverauto/serviceradar](https://github.com/carverauto/serviceradar) if you're intersted in the \"self-hosted-thingo\" ",
                  "score": 1,
                  "created_utc": "2026-02-11 18:33:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4wt72c",
          "author": "kusanagiblade331",
          "text": "Yes, I have encountered this issue before. The problem is log ingestion. Try to analyze what is your top log patterns consuming so much ingestion.\n\nI have dealt with Splunk cost issue before. I have documented some solutions here:\n\n[https://starclustersolutions.com/blog/2026-01-how-to-reduce-splunk-cloud-cost/](https://starclustersolutions.com/blog/2026-01-how-to-reduce-splunk-cloud-cost/)",
          "score": 0,
          "created_utc": "2026-02-12 02:08:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y2we1",
          "author": "HotDog_SmoothBrain",
          "text": "Hi, I know someone that can help. I will pass this post to him. He saved us about 35% and we have far better data than we did before hand. Dude paid for himself by the third month.",
          "score": 0,
          "created_utc": "2026-02-12 07:49:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4umpp3",
          "author": "brianyoyoyo",
          "text": "I'd recommend [OpenObserve](https://openobserve.ai/). Handles all otel data and stores it compressed in object storage. They claim 140x cheaper than elastic search solution and I'd be inclined to believe them. I deployed it for a few clusters about a year ago and I haven't had to touch it since.",
          "score": -6,
          "created_utc": "2026-02-11 19:14:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ubv3g",
          "author": "Mad6193",
          "text": "I was interviewing for the startup - Oodle.ai that solves this problem. It‚Äôs like snowflake for Logs. Pay for query not storage.",
          "score": -8,
          "created_utc": "2026-02-11 18:24:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4xpz9",
      "title": "Security findings come in Jira tickets with zero context",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r4xpz9/security_findings_come_in_jira_tickets_with_zero/",
      "author": "Bitter-Ebb-8932",
      "created_utc": "2026-02-14 22:21:49",
      "score": 121,
      "num_comments": 57,
      "upvote_ratio": 0.94,
      "text": "Security scanner runs nightly and I wake up to 15 Jira tickets. Each one says fix CVE-2025-XXXX in dependency Y with no explanation of what the dependency does, where it's used, or why it matters.\n\nI'm supposed to drop whatever sprint work I'm on, research the CVE, find where we use that package, assess actual risk, test the upgrade, and hope nothing breaks.\n\nMeanwhile the ticket was auto-generated and the security team has no idea what they're asking me to fix. Just scanner said critical so here's a ticket.\n\nWhy can't these tools give actual context? Like this package is used in auth flow, vulnerability allows account takeover, here's how to fix it. Instead of just screaming CVE numbers at me.",
      "is_original_content": false,
      "link_flair_text": "Security",
      "permalink": "https://reddit.com/r/devops/comments/1r4xpz9/security_findings_come_in_jira_tickets_with_zero/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o5ex5ec",
          "author": "Northeastpaw",
          "text": "Bring this up with your manager. Tell them if the security team can‚Äôt put in the effort to add context to a ticket then the ‚Äúvulnerability‚Äù can‚Äôt be that important or pressing. Checklist security breeds complacency and diverts attention from actual work.",
          "score": 117,
          "created_utc": "2026-02-14 22:26:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f4l1y",
              "author": "biglinuxfan",
              "text": "I would be pushing back for my team on this one. It's an epic waste of their time to go chasing down information that is available at scan time.",
              "score": 23,
              "created_utc": "2026-02-14 23:09:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ifyt1",
              "author": "ansibleloop",
              "text": "Agree - security team should be reviewing these results to ensure they're actually actionable\n\nNot just fucking dumping them in another team's queue",
              "score": 6,
              "created_utc": "2026-02-15 14:31:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5kf9ju",
                  "author": "MysteriousPublic",
                  "text": "Considering most security teams are severely underfunded, usually this is not feasible. It‚Äôs usually more efficient to have the teams that own the code to do the research, sec team is there to surface it. \nIf it‚Äôs a properly staffed team that has the time to investigate it on your behalf, that sounds like a nice luxury lol. This should also get better with AI.",
                  "score": 1,
                  "created_utc": "2026-02-15 20:26:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ewwe6",
          "author": "Due-Philosophy2513",
          "text": "Ask security team to include impact analysis in tickets. Template should have: what does this dependency do, where is it used, why does this CVE matter.",
          "score": 61,
          "created_utc": "2026-02-14 22:25:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5golhm",
              "author": "Drauren",
              "text": "Yeah IMHO severity is super important. You ask most security folks and most of the dumb ones will tell you 0 CVEs is what they want.",
              "score": 11,
              "created_utc": "2026-02-15 05:33:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5hpaxr",
              "author": "vikinick",
              "text": "Also exact file path where it's located helps to nail down what depends on it",
              "score": 3,
              "created_utc": "2026-02-15 11:20:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ezbuv",
          "author": "Calm-Exit-4290",
          "text": "This workflow is broken at the organizational level not just tooling. Security dumping raw scanner output into jira without triage creates noise that gets ignored. \n\nBetter approach is security owns initial assessment, provides context on impact and affected systems, suggests remediation with testing guidance, then creates actionable tickets. \n\nAlternatively implement sla based on actual risk where critical exploitable vulns get immediate attention but theoretical risks in unused dependencies go into quarterly backlog review. Current system where everything is urgent means nothing actually is",
          "score": 27,
          "created_utc": "2026-02-14 22:39:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fi6k0",
              "author": "-Devlin-",
              "text": "This is a great approach in theory, the problem imo is ownership. If they could test, they would. But most lack either the dev knowledge or the right tools to go from visibility to execution mode.",
              "score": 8,
              "created_utc": "2026-02-15 00:33:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5hcjiv",
                  "author": "Laruae",
                  "text": "I was always told that having this experience is why Security isn't an entry level field. Or should we not be holding Security to a standard that is appropriate?",
                  "score": 7,
                  "created_utc": "2026-02-15 09:17:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5eyevt",
          "author": "Hour-Librarian3622",
          "text": "The lack of context in security tickets is exactly why devs ignore them or blindly upgrade dependencies hoping nothing breaks. Scanner output needs business context and remediation paths not just cve numbers. \n\nASPM platforms like checkmarx that correlate findings with code usage help here. Shows where vulnerable packages are actually used in your codebase, whether the vulnerable function is reachable, and prioritizes based on exploitability. Tickets include enough context to understand risk without spending hours researching every cve",
          "score": 18,
          "created_utc": "2026-02-14 22:33:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f0fo4",
          "author": "spline_reticulator",
          "text": "What happens if you don't do the ticket? If I had a nickel for every time some infra team asked me to do something, I just didn't, and they stopped asking, I'd have a bunch of nickels.",
          "score": 8,
          "created_utc": "2026-02-14 22:45:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f3iw9",
          "author": "actionerror",
          "text": "Won‚Äôt fix",
          "score": 7,
          "created_utc": "2026-02-14 23:03:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fihgf",
              "author": "-Devlin-",
              "text": "This made me laugh so hard. We actually built a webhook automation in Jira to allow people to won‚Äôt fix. Guess what 100% of tickets ended up in that state üòÜ",
              "score": 5,
              "created_utc": "2026-02-15 00:35:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5exktw",
          "author": "UnhappyPay2752",
          "text": "Is your security team even reviewing findings before creating tickets or just automating scanner output straight to jira? might be worth conversation about triage process before tickets get created",
          "score": 6,
          "created_utc": "2026-02-14 22:29:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ey66m",
              "author": "snowsnoot69",
              "text": "Hah dude security teams are staffed by CISSPs who have no clue about anything technical. They are box checkers and policy makers.",
              "score": 7,
              "created_utc": "2026-02-14 22:32:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5kg455",
                  "author": "MysteriousPublic",
                  "text": "Even in this case, if you own the code and don‚Äôt fix the CVE, that‚Äôs on you if something happens.",
                  "score": 1,
                  "created_utc": "2026-02-15 20:30:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5f72gm",
          "author": "PrintedCircut",
          "text": "My advise from 13 years in the industry is dont feed the machine with the blood of man, you'll only end up driving yourself crazy chasing that white rabbit.\n\nI cant pretend to know your architecture or your constraints but I would instead say that were you can implement fully autonomous patching. Most OS flavors have this if some form or other for enterprise workloads these days. Tech like Hotpatch for Windows Server, Ksplice, Canonical livepatch or even simpler ones like yum-cron and the unattended-upgrades packages set on a set timer can pull the heat away from you as an Admin of playing the \"drop everything and patch now\" game. Because at the end of the day what a lot of people dont fully understand is that Cyber Security is at its core a cat and mouse game that will never stop producing new CVEs and their corresponding Patches.",
          "score": 6,
          "created_utc": "2026-02-14 23:25:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f787o",
          "author": "aranel_surion",
          "text": "One easy ‚Äúfix‚Äù: have your EM ask the Security team to filter findings by EPSS instead of Criticality.",
          "score": 5,
          "created_utc": "2026-02-14 23:26:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ezn5s",
          "author": "kryptn",
          "text": "this needs to be a conversation with your manager about how your team gets assigned work. \n\ni built a process with security where we can review findings before they get assigned, instead of just blindly getting tasks to work. \n\n>  Why can't these tools give actual context?\n\nthey don't know your code. they know what your code uses. \n\nsmarter scanners (github codeql, tbh) can see how it's used in your code and how data flows through it to better identify some specific issues.",
          "score": 2,
          "created_utc": "2026-02-14 22:40:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g4yuo",
          "author": "phoenix823",
          "text": "You and your manager agree upon what the ‚Äúdefinition of ready‚Äù is for a ticket. If the ticket does not have the necessary information it is closed.",
          "score": 4,
          "created_utc": "2026-02-15 03:05:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5eyi3k",
          "author": "Hour-Inner",
          "text": "I work customer support for an MSP/SaaS provider and I often get tickets from a client who have a ‚Äúsecurity specialist‚Äù run a ‚Äútest‚Äù on their system against our system and architecture. Same kind of thing. Auto generated report with very little context. \n\nI investigate and respond to the critical issues in good faith. For all the rest I find polite ways of saying ‚ÄúI will look into this IF you can explain why this issue is a problem for you‚Äù",
          "score": 5,
          "created_utc": "2026-02-14 22:34:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f1jux",
          "author": "No_Opinion9882",
          "text": "Contextless cve tickets happen because scanners don't understand your application architecture. They find vulns but can't explain why they matter to your specific codebase. Tools with reachability analysis solve this by mapping dependencies to actual code paths. Like checkmarx aspm does this correlation automatically, tickets show which services use the vulnerable package and whether the exploitable code is reachable. provides actionable context instead of making devs research every finding",
          "score": 8,
          "created_utc": "2026-02-14 22:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fguap",
          "author": "-Devlin-",
          "text": "This might help https://emphere.com/intel?cve=CVE-2020-8203. Checkout the breaking change section. Community MCP can even fix these and creates a feedback loop for others.",
          "score": 3,
          "created_utc": "2026-02-15 00:25:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fiqak",
              "author": "eufemiapiccio77",
              "text": "Same sort of vibe coded app you‚Äôve just linked to there but checks is there‚Äôs a working exploit PoC https://labs.jamessawyer.co.uk/cves",
              "score": 2,
              "created_utc": "2026-02-15 00:37:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fklk8",
                  "author": "-Devlin-",
                  "text": "This is great. Thanks for sharing .!!",
                  "score": 2,
                  "created_utc": "2026-02-15 00:48:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hdo94",
          "author": "ultrathink-art",
          "text": "This is a workflow failure, not a security team problem. Security scanners output machine-readable data (SARIF, JSON) ‚Äî humans shouldn't be copy-pasting findings into Jira.\n\n**Fix the handoff:**\n1. **Automate ticket creation** from scanner output (GitHub Advanced Security, Snyk, etc. all have Jira integrations). Include: file path, line number, CWE reference, affected dependency version.\n2. **Require context fields** in the ticket template: vulnerable component, exploit scenario, suggested remediation. If security can't fill these in, the finding isn't actionable yet.\n3. **Triage meeting** once/week where security walks through new high/critical findings. Async Jira comments don't build shared context ‚Äî 15 minutes of \"here's why this matters\" saves hours of back-and-forth.\n\nSecurity findings without context are noise. But devs saying \"we can't fix what we don't understand\" is also valid. The process needs to meet in the middle: structured data from scanners + human explanation of business risk.",
          "score": 3,
          "created_utc": "2026-02-15 09:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f34lt",
          "author": "EquivalentBear6857",
          "text": "Set up dependency tracking in your architecture documentation so when cve tickets arrive you at least know where packages are used. \n\nDoesn't solve the prioritization problem but speeds up research phase. \n\nAlso consider implementing automated dependency update prs with test runs so upgrades aren't manual investigation every time",
          "score": 2,
          "created_utc": "2026-02-14 23:01:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fqoax",
          "author": "ultrathink-art",
          "text": "I feel this. We started requiring security to include: (1) the actual code/config snippet that triggered the finding, (2) the severity score breakdown (not just the number), and (3) a suggested fix if it's a scanner false positive.\n\nCut our \"what even is this\" ticket volume by ~60%. The key was getting management buy-in that incomplete tickets just get kicked back ‚Äî security team adapted fast when their metrics started showing ticket rejection rates.",
          "score": 2,
          "created_utc": "2026-02-15 01:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g6irm",
          "author": "derprondo",
          "text": "This isn't maintainable at all.  What you need is a patching cycle and an agreed upon SLA with the security team.  Your patching cycle and SLA should match, eg >=P1 SLA is 30 days, patch every 30 days so all P1+ findings are remediated.  P0 SLA 7d, so only a P0 should cause you to drop what you're doing mid sprint, which should be a rare occurrence.",
          "score": 2,
          "created_utc": "2026-02-15 03:16:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gbg3o",
          "author": "crash90",
          "text": "A lot of this has to do with your company's philosophy of security. It's much more effective and time saving for everyone involved if the engineers on the security team can help validate that the CVEs are actually real, not a false positive, and can help with the mitigation steps if they are complex. Even just outlining a plan for what should be expected to remidate can help a lot.  \n\nDifferent companies feel different ways about this though. Some prefer more of a throw it over the wall approach as you've described.  \n\nWorking with your manager and the security team to try to change this is a good use of time in my opinion. IF the security team's leadership is likely be cooperative. Your manager probably has some intuitions about whether or not that is the case.  \n\nThe framing I like around this stuff is that there are two categories of security failure.  \n\n1. Security too weak. Attacker gets in.  \n\n2. Security policies contain unnecessary complexity. Work is prevented from being completed, the entire purpose of running a company. (This also leads to people trying to get around the polices, making the org less secure anyway)\n\nBoth types of failure are very severe and great effort should be expended to avoid either. Always walking the delicate and difficult balance between 1 and 2. Thats what really talented security teams get up to.  \n\nNot everybody sees it that way though.",
          "score": 2,
          "created_utc": "2026-02-15 03:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hgqzz",
          "author": "thecrius",
          "text": "I've yet to find a security team doing anything else then just have some third party tool telling them \"this is potentially dangerous\" and then just copy pasting it into someone board which blocks work for everyone. \n\nThey sure are the most overlooked positions in terms of actual quality of the people's expertise. Probably because nobody really knows what the fuck all their acronyms means.\n\nPlatform engineers have to know as much as the software engineers, get involved in how the app works, their context and understand how things tie together... and these mfs don't even bother to understand if their tool might actually be raising a false positive and get paid the same or even more. Fucking clowns.",
          "score": 2,
          "created_utc": "2026-02-15 09:59:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5j18am",
          "author": "Easy-Management-1106",
          "text": "Ffs are we posting on Reddit now instead of actually engaging in a professional discussion with colleagues at work?\nDo you then send them the link to your Reddit post expecting them to react?\n\nNo wonder you are reduced into a ticket taking slave - you guys build silos instead of actually collaboration.\n\nTldr; go touch some grass, then talk to your cyber team",
          "score": 2,
          "created_utc": "2026-02-15 16:20:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fb13o",
          "author": "Bar-Bitter",
          "text": "Fire the security team. Use a dev to review scan result findings.",
          "score": 2,
          "created_utc": "2026-02-14 23:49:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f9p3x",
          "author": "Odd-Neighborhood8740",
          "text": "What scanner are you using",
          "score": 1,
          "created_utc": "2026-02-14 23:41:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5gpd6t",
          "author": "73-68-70-78-62-73-73",
          "text": "If they're using something like Rapid7, they can export data to a dashboard for you. It's up to them to automate it. Once they do, automate your end of it.",
          "score": 1,
          "created_utc": "2026-02-15 05:40:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h8614",
          "author": "No_Succotash8324",
          "text": "Yeah this is how it works.\n\nSecurity team knows even less than you, but still as a stakeholder want it fixed immediately. Nevermind that the package present only exists in a csv generated by the agent. Or the vulnerable feature not being used.\n\n\"We take security seriously\"",
          "score": 1,
          "created_utc": "2026-02-15 08:35:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hg3rt",
          "author": "Ok_Conclusion5966",
          "text": "fro those that have trouble understanding, security more often than not point to a linux package or vulnerability to some obscure software or service which is not even in use or requires absurd requirements in order to pull off such as local escalated privileges\n\nsimilar to auditing, it quickly becomes a checkbox activity that pays the salaries of the security team, risk team, external regulars and external auditors and the desktop monkeys that need to tick those boxes",
          "score": 1,
          "created_utc": "2026-02-15 09:52:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hqrit",
          "author": "rschulze",
          "text": "> Meanwhile the ticket was auto-generated and the security team has no idea what they're asking me to fix. Just scanner said critical so here's a ticket.\n\nAs someone who's main task is security ... security teams like this infuriate me. That isn't security, those are just glorified sysadmins spinning up software, throwing the results at other departments and not generating any benefit/value for the company (either because they are incompetent, or because management decided to get a bunch of junior level knowledge people; you get what you pay for).\n\n> I'm supposed to drop whatever sprint work I'm on, research the CVE, find where we use that package, assess actual risk, test the upgrade, and hope nothing breaks.\n\nI'm mostly with you here, security team should definitely have provided a list of impacted applications/modules/libraries, checked if the CVE is even potentially relevant (e.g. affects LDAP but it is known the application doesn't use LDAP), provided an initial impact or risk assessment (which then transfers to \"what priority does this ticket even have\"), scope, potential mitigations aside from \"update the dependency\". Also may need to translate CVE speak into developer speak. \n\nActual risk is then decided together with the developers since they know the application logic and dependency usage, while we (security) can provide details on the vulnerability.\n\nEach company and applications are different, but for me it is very rare for a CVE to be \"this is urgent enough to need to be taken care of today\" with no alternative temporary mitigations available to reduce the risk.\n\n> Why can't these tools give actual context? Like this package is used in auth flow, vulnerability allows account takeover, here's how to fix it. Instead of just screaming CVE numbers at me.\n\nSounds like the tool they are using is working with a software bill of materials and not the code itself (e.g. DependencyTrack). Or the software technically could do it as part of the Software Composition Analysis, but the feature is locked behind a higher cost tier that what they are paying (e.g. Sobarqube). Again you get what you pay for.\n\nAs a bare minimum I'd suggest your manager pushes for the the security team to include the full CVSS scoring, an impact analysis written by the security team in the context of the business, and for the security team to implement a proper ASPM to generate actional tasks and not just CVE checkboxes.",
          "score": 1,
          "created_utc": "2026-02-15 11:33:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i03hk",
          "author": "Nearby-Middle-8991",
          "text": "What's the process to document exceptions? does it stick through distinct runs?\n\n  \nSpitting the output of the tool isn't too bad if it's just the actual issues. I've seen teams that do criticals only as blocker, rest as info. Snow/jira tickets are for tracking and reporting to leadership, so they can go back to the owners and tell who's treating what. That's an important distinct, risk needs to be treated, not fix.\n\nFixing code and determining what's relevant or not for the application isn't security's job, they don't have the skills set. I've seen senior security guys that can't read a git diff. On the web mind you, not on the CLI. So asking devs to go to mitre or just google with the CVE identifier isn't unreasonable, it's a decent identifier that will give you all the info you need to fix (again, assuming it's not outputting all issues without priority).\n\n  \nMain bit: the tool is just one part of the solution. Still needs exception, documentation, reporting. It's not about fixing everything, it's about surfacing and treating risk.",
          "score": 1,
          "created_utc": "2026-02-15 12:51:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5i0izx",
              "author": "Nearby-Middle-8991",
              "text": "And more to the answer of the question, there are tools that can tell you the context ofthe cves, like it's in this library, that you use for X in module Y. But it's an \"emerging\" use that also depends on the tool and the type of project. Usually source code into an LLM. No horrible, not that good, especially if you pick up stuff like chromium (which some projects add on the server to print pdfs), it has so many CVEs and so many different ways of using it that's complicated to know what's which. Same for glibc for instance. ",
              "score": 1,
              "created_utc": "2026-02-15 12:54:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ivmyi",
          "author": "rpg36",
          "text": "I have the same problem as you! Scans run, tickets are created with 0 context. The expectation from our management is to drop everything and fix it immediately!\n\nWe've tried to push back on this but have failed. The security team is not technical and doesn't understand our system at all so are incapable of actually triaging issues. For a while we were even told we cannot have any vulnerabilities of any severity on anything. Thankfully there was such a massive uproar to the stupidity of that request that they changed it to no critical or highs. Which is still a stupid policy because it's a blanket rule without any context or assessment into actual risk to any of our actual products.\n\n\nI honestly don't know what happened, but it used to be more reasonable where you'd assess risk and then if it was determined there was no real risk. You just had to write a quick little justification. Send it off to the security team and they would approve exemptions. Now. They seem to refuse to approve any exemptions no matter what for any reason. \n\nI brought this up with my manager about how much of a massive waste of time this is and how it's completely insane and crippling us. I was told that they understand and they agree but that it's out of their hands. It's coming from a much higher level. I was literally told that it does not matter what the cost or consequences are. We have to meet the requirement even if it breaks things. So since I work on multiple projects I've been \"very busy\" with other projects lately and \"I haven't had time to work on these other projects\" with these insane security requirements!",
          "score": 1,
          "created_utc": "2026-02-15 15:53:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jza8g",
          "author": "JelloSquirrel",
          "text": "Definitely the right thing to do here is have a conversation with your security team, or your management chain if your company is too massive to have direct lines of comms.\n\n\n\n\nFrom my personal experience as a dev and red teamer who ended up in an AppSec role, managing about 200 devs with several hundred repos (but 10-30 that are actually active).\nYah, inexperienced security people do tend just kick autogenerated tickets devoid of context and review over. I've had to talk to my coworkers just about the jira hell they create.\n\n\nTooling matters a lot here and I think has improved a lot over the years. We generally do like a 2 week evaluation of testing tools before buying them, and I do a pretty deep dive on quality of automated triage.\n\n\nMy main tool is Semgrep Pro. It includes pretty good reachability analysis and the sast severity errs on the side of not being too sensationalist. Can highly recommend it vs the other tools I've evaluated. Automated tickets are created for anything that's reachable above high severity, and the tooling does a good job with it. I review all tickets before assigning them to a team, and have a Slack bot that informe me or every new vuln.\nThe reachability analysis requires zero setup, but it will miss things and can't evaluate every eco system / package whatever. Every ticket includes the tool summary description, a link back to the security tool, and the commit that introduced the issue.\n\n\nOn the infrastructure security side, both Wiz and Orca seem to do a good job at context and ranking issues, but are expensive. They have AppSec tooling as well but I haven't evaluated them.",
          "score": 1,
          "created_utc": "2026-02-15 19:05:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f2icv",
          "author": "Alternative-Key-1313",
          "text": "security tools are trash",
          "score": 3,
          "created_utc": "2026-02-14 22:57:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fg8id",
          "author": "damon-daemon",
          "text": "I had this problem and the security engineer submitting the tickets had multiple jobs and dngaf and would just make tickets with no context to make it look like they were doing something",
          "score": 1,
          "created_utc": "2026-02-15 00:22:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5f0mfa",
          "author": "deke28",
          "text": "Usually cves are dead code anyway.¬†",
          "score": -3,
          "created_utc": "2026-02-14 22:46:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1im4x",
      "title": "Does anyone actually check npm packages before installing them?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r1im4x/does_anyone_actually_check_npm_packages_before/",
      "author": "BearBrief6312",
      "created_utc": "2026-02-11 00:40:23",
      "score": 114,
      "num_comments": 57,
      "upvote_ratio": 0.91,
      "text": "Honest question because I feel like I'm going insane.\n\nLast week we almost merged a PR that added a typosquatted package. \"reqeusts\" instead of \"requests\". The fake one had a postinstall hook that tried to exfil environment variables.\n\nI asked our security team what we do about this. They said use npm audit. npm audit only catches KNOWN vulnerabilities. It does nothing for zero-days or typosquatting.\n\nSo now I'm sitting here with a script took me months to complete that scans packages for sketchy patterns before CI merges them. It blocks stuff like curl | bash in lifecycle hooks ,Reading process.env and making HTTP calls ,Obfuscated eval() calls and Binary files where they shouldn't be and many more\n\nWorks fine. Caught the fake package. Also flagged two legitimate packages (torch and tensorflow) because they download binaries during install, but whatever just whitelist those.\n\nMy manager thinks I'm wasting time. \"Just use Snyk\" he says. Snyk costs $1200/month and still doesn't catch typosquatting.\n\nAm I crazy or is everyone else just accepting this risk?\n\nTool:¬†[https://github.com/Otsmane-Ahmed/ci-supplychain-guard](https://github.com/Otsmane-Ahmed/ci-supplychain-guard)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/devops/comments/1r1im4x/does_anyone_actually_check_npm_packages_before/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4q0rbv",
          "author": "derprondo",
          "text": "I don't know about any open source alternatives, but we have a security policy that states that no packages / dependencies should be sourced directly from the internet.  For things like this we use Artifactory with pull through cache, and it has this \"x-ray\" addon that is supposed to catch things like this.",
          "score": 77,
          "created_utc": "2026-02-11 01:24:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4qh4kp",
              "author": "shakygator",
              "text": "Same except we have Nexus sonatype repositories, etc.",
              "score": 14,
              "created_utc": "2026-02-11 03:03:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4uelfn",
                  "author": "m_adduci",
                  "text": "And the Sonatype Nexus Firewall",
                  "score": 3,
                  "created_utc": "2026-02-11 18:37:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4qgc2e",
              "author": "Rain-And-Coffee",
              "text": "We do the same, we have Jfrog to proxy artifacts. \n\nHowever our Artifactory doesn‚Äôt have XRay (my company didn‚Äôt want to pay JFrog), instead the scanning is done when code is pushed to Git. \n\nA report gets generated with SCA & CVE, sometimes it can also auto open a PR to fix them.",
              "score": 13,
              "created_utc": "2026-02-11 02:58:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4qmyke",
              "author": "dmurawsky",
              "text": "Just got a quote from them for $300k for a year. Way too rich for my blood, unfortunately.",
              "score": 9,
              "created_utc": "2026-02-11 03:40:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4qptg1",
                  "author": "rayray5884",
                  "text": "The prices on that stuff are insane. I‚Äôve used community and paid Sonatype in the past. The cost delta between ‚Äòhere‚Äôs a free package server‚Äô and ‚Äòoh, you want to flag bad stuff AND block it AND know where it is in your environment if it becomes vulnerable AND let developers scan projects locally AND have a traceable SBOM? Give us nearly $1000/dev/year. Plus a consumption meter if you don‚Äôt want to manage all that.\n\nNot denying that this isn‚Äôt useful, just that the costs add up real quick. And this isn‚Äôt first party code scans.",
                  "score": 6,
                  "created_utc": "2026-02-11 03:59:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4qo3gj",
                  "author": "davidroberts63",
                  "text": "Yeah that's the problem with artifactory. We, and apparently many others are looking for viable alternatives.",
                  "score": 3,
                  "created_utc": "2026-02-11 03:48:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4qpxl6",
                  "author": "256BitChris",
                  "text": "Hey, I'm Chris, the founder of [CloudRepo](https://www.cloudrepo.io).  Our entire purpose is to help people not pay 300k a year for artifactory.  We can usually save people like you over 70%, and a lot of times more.  I'd love it if you'd give us a chance to save you 200k+ - DM me and I'll do my best to personally help.",
                  "score": 2,
                  "created_utc": "2026-02-11 04:00:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4pvmwo",
          "author": "engineered_academic",
          "text": "Datadog's Guarddog is what you want.",
          "score": 22,
          "created_utc": "2026-02-11 00:54:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pw30m",
              "author": "MyLifeForAiur-69",
              "text": "> I'm sitting here with a script took me months to complete that scans packages for sketchy patterns before CI merges them\n\n\ndid you even read the post? Plus datadog costs way more than $1200 per month lol",
              "score": 2,
              "created_utc": "2026-02-11 00:56:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pwvga",
                  "author": "engineered_academic",
                  "text": "Open source homie: https://github.com/DataDog/guarddog",
                  "score": 39,
                  "created_utc": "2026-02-11 01:01:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4px0yh",
          "author": "One-Department1551",
          "text": "Your manager is going to be fired if your company gets hacked?\n\nCover your ass, don‚Äôt let them win, the risk is unacceptable and it should call an internal incident for investigation.",
          "score": 11,
          "created_utc": "2026-02-11 01:02:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4py4ax",
              "author": "Shogobg",
              "text": "Homie building a brand here - he doesn‚Äôt actually have any managers talking about security.",
              "score": 15,
              "created_utc": "2026-02-11 01:08:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4qaptt",
              "author": "slayem26",
              "text": "What happens with me when manager gets fired? I have never been in such scenario but I rely on manager for updates and future roadmaps.\n\nDoesn't it means that I'll be redundant soon and fired?",
              "score": 1,
              "created_utc": "2026-02-11 02:24:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4r9a1w",
                  "author": "One-Department1551",
                  "text": "Your company shouldn‚Äôt crumble if a manager is fired he‚Äôs just replaced, maybe internally or externally.",
                  "score": 1,
                  "created_utc": "2026-02-11 06:28:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4qmf8a",
          "author": "stgovern",
          "text": "Not checking npm and docker images is like having sex with the internet without a condom.",
          "score": 6,
          "created_utc": "2026-02-11 03:37:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4uvtz9",
              "author": "Abu_Itai",
              "text": "ü§£ü§£ I‚Äôm gonna use it!",
              "score": 2,
              "created_utc": "2026-02-11 19:58:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rub7e",
          "author": "Watson_Revolte",
          "text": "Honestly, most teams don't manually check npm packages line-by-line - but they're also not just blindly accepting the risk. What usually happens in mature setups is people move the trust boundary upstream into the delivery system instead of expecting every dev to audit dependencies.\n\nStuff I've seen work well in real orgs:\n\nPrivate registries / artifact proxies so you're not pulling straight from the internet every time\n\nAllow-lists or \"soak time\" rules before a new dependency can hit production\n\nStatic checks in CI (hooks, obfuscated evals, weird postinstall behavior) - which is basically what you built, just formalized\n\nnpm audit and Snyk help with known CVEs, but yeah - they don't really touch typosquatting or sketchy install scripts. That's more of a supply-chain hygiene problem than a vuln scanning problem.\n\nYou're not crazy - you're just solving a gap most teams only notice after an incident. The real trick is packaging what you built as guardrails the team barely notices, otherwise leadership sees it as \"extra process\" instead of risk reduction.",
          "score": 4,
          "created_utc": "2026-02-11 09:43:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pz4c9",
          "author": "thenrich00",
          "text": "[https://hextrap.com](https://hextrap.com) gives you protection against typosquatting, malicious packages, unpopular packages, unmaintained packages, soak-time, etc. You can also just enable allow or deny lists depending on your team's risk aversion.",
          "score": 3,
          "created_utc": "2026-02-11 01:14:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rdmqe",
          "author": "Lurkernomoreisay",
          "text": "one of our contractors has external web access via proxy.\n\n\nnpm packages are available only thoguh specifically named npm registries on Artifactory¬†\n\n\nevery package must be allowed by security before it can be used, and loaded into the Artifactory instance.\n\n\nthe most common dependencies are readily available, and rarely does anyone need to use a new package and request a review.¬† ¬†even rarer is when an existing approved npm library updates and requires a new library that needs approval.\n\n\nI'm unsure if their exact policy¬† but it seems they approve the name of the package after review, and in case of vulnerability in a specific release to block that release.\n\n\n\n\nafter the initial setup, it seemed simple to maintain.",
          "score": 2,
          "created_utc": "2026-02-11 07:06:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4py00h",
          "author": "Huge_Appearance_3721",
          "text": "bruh what kind of security manager you guys have",
          "score": 1,
          "created_utc": "2026-02-11 01:08:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q0zi8",
          "author": "Specific-Welder3120",
          "text": "Leave it damn clear that you did not agree with that",
          "score": 1,
          "created_utc": "2026-02-11 01:26:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q37vr",
          "author": "ArtSpeaker",
          "text": "You're not crazy. Document everything. I would also suggest having an on-prem artifact server.  No corporate should be pulling direct from the internet repo.  Get on-prem and whitelist all the requested versions+artifacts that make it past that filter you are building. No more squatting, and you'll know what is already marked safe to use -- until they find something else wrong. Then it gets evicted and the devs have to find something else. ",
          "score": 1,
          "created_utc": "2026-02-11 01:39:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q3xpm",
          "author": "binarygoatfish",
          "text": "Get the response in an email. Print off and seal in a second location for if this goes tits up and move on with life. \n\nYou show the problem and the options. They accept the risk/ reward just make sure you have proof.",
          "score": 1,
          "created_utc": "2026-02-11 01:44:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qd0c6",
          "author": "picklejester",
          "text": "We have an allow listed set of packages. Adding new ones adds a comment to the PR with a link to review any suss keywords before you can merge in the package (or delta for version bumps). It's simple, and works well.",
          "score": 1,
          "created_utc": "2026-02-11 02:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qgot5",
          "author": "atxweirdo",
          "text": "Socket.dev seems pretty good for this, and they have a self hosted version I believe",
          "score": 1,
          "created_utc": "2026-02-11 03:01:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qj9h7",
          "author": "Plane--Present",
          "text": "You‚Äôre not crazy, most teams don‚Äôt manually review every dependency, but they absolutely should have guardrails beyond just npm audit.",
          "score": 1,
          "created_utc": "2026-02-11 03:17:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r24ua",
          "author": "AdrianTeri",
          "text": "Can anybody(global) raise a PR to be merged in your org or enterprise? \n\nThere are many issues including on GitHub's NPM but it's generally the way JS development carries on. Too many modules or libraries need not exist. From the changelog it's only a matter of time until real implications have an awakening e.g a Bank or a Stocks/Trading site -> https://changelog.com/podcast/674",
          "score": 1,
          "created_utc": "2026-02-11 05:29:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rh6r8",
          "author": "Caddy666",
          "text": "no.\n\n\nhttps://en.wikipedia.org/wiki/Npm_left-pad_incident",
          "score": 1,
          "created_utc": "2026-02-11 07:39:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ri8no",
          "author": "OMGItsCheezWTF",
          "text": "We have sbom validation and continuous monitoring as part of our CI process as a starting point. We use a paid product for it but the owasp publishes DependencyTrack which does the same thing and is open source.\n\nEssentially every build pushes a bill of materials into DependencyTrack which not only immediately feeds back issues to your build but also continually monitors vulnerability feeds and alerts to your monitoring system as soon as anything says \"hey this package in project x pushed 3 weeks ago has been found to be bad\"\n\nwe also require PR reviews of course especially around dependency lock files, but node is particularly difficult because dependency chains can be enormous.\n\nUltimately you can help mitigate it but you can't prevent it without active awareness and participation of all Devs in making sure the app is secure.",
          "score": 1,
          "created_utc": "2026-02-11 07:49:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4riryj",
          "author": "Imaginary_Gate_698",
          "text": "You‚Äôre not crazy, most teams accept way more supply chain risk than they admit, and npm audit alone doesn‚Äôt cover the class of problem you just hit. That said, rolling your own scanner can turn into a maintenance trap unless you scope it tightly and integrate it with a process people will follow.\n\nThe sweet spot I‚Äôve seen work is a couple of boring guardrails. Lockfiles and pinned versions, no install scripts by default unless a package is explicitly approved, and a lightweight allowlist for the handful of deps that need binaries. Typosquats also get a lot harder if you enforce ‚Äúnew dependency requires a second reviewer‚Äù and require the exact package name to be added via a single script or template, not typed ad hoc in a PR.\n\nYour tool sounds useful as a CI gate as long as it‚Äôs transparent, fast, and the false positive story is sane.",
          "score": 1,
          "created_utc": "2026-02-11 07:54:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rkf6f",
          "author": "nooneinparticular246",
          "text": "The worst part of typescript is the ecosystem and historical lack of core packages",
          "score": 1,
          "created_utc": "2026-02-11 08:09:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rlwyf",
          "author": "water_bottle_goggles",
          "text": "lmao, sure I ‚Äúcheck‚Äù only if there‚Äôs an error",
          "score": 1,
          "created_utc": "2026-02-11 08:24:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rr831",
          "author": "Any-Figure-5487",
          "text": "We use Safe Chain from Aikido which exactly overcomes the limitations you see with npm audit. It works early in the process and prevents package installation on the developer‚Äôs device. \n\nWe started using it after we got hit by an npm worm (shai hulud) and so far it proves to be a good tool, and it is free",
          "score": 1,
          "created_utc": "2026-02-11 09:14:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rwwtn",
          "author": "ultrathink-art",
          "text": "We gate package additions in CI with a simple policy: new dependencies require a 2-line justification in the PR (what it does + why we need it vs rolling our own). Forces the \"do we really need this 3KB leftpad equivalent\" conversation upfront. Also run found 0 vulnerabilities as a required check. It's not bulletproof but catches the most egregious stuff and makes dependencies a conscious choice rather than npm-install-whatever.",
          "score": 1,
          "created_utc": "2026-02-11 10:07:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s3w9m",
          "author": "Abu_Itai",
          "text": "about artifactory and xray curation, we managed to fully block the recent npm incidents, the cost was easier to justify. It‚Äôs not cheap, I agree. That said, have you looked into combining a few free tools and building something that fits your exact needs?",
          "score": 1,
          "created_utc": "2026-02-11 11:10:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s4l4c",
          "author": "XzwordfeudzX",
          "text": "It's quite tricky, because the source code can be completely different from what is uploaded to NPM, and if the code uploaded to NPM is minified, tough luck trying to read through it.  \n  \nI use landlock (landlock.io/) to try to limit what my programs can do for this reason. It can somewhat limit the blast radius.",
          "score": 1,
          "created_utc": "2026-02-11 11:16:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4twzbo",
          "author": "protestor",
          "text": "> npm audit only catches KNOWN vulnerabilities. It does nothing for zero-days or typosquatting.\n\nnpm audit should really catch typosquatting. In lieu of that, there's things like this https://www.npmjs.com/package/typosquat-detector\n\n> My manager thinks I'm wasting time. \"Just use Snyk\" he says. Snyk costs $1200/month and still doesn't catch typosquatting.\n\n$1200/month is nuts. However, https://snyk.io/blog/typosquatting-attacks/",
          "score": 1,
          "created_utc": "2026-02-11 17:15:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4uf1ki",
          "author": "m_adduci",
          "text": "I appreciate the effort, but isn't the whole point of the discussion that dependencies can be dangerous?\n\nIf so, isn't somehow counterproductive to open source a tool that requires dependencies itself?",
          "score": 1,
          "created_utc": "2026-02-11 18:39:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4utqpv",
          "author": "kxbnb",
          "text": "Your manager's wrong about Snyk here. Snyk checks against known CVE databases - it literally can't catch a brand new typosquatted package because there's nothing to match against. Your script checks what packages *do* at install time. Completely different problem.\n\nWhat you built is behavioral analysis at the install boundary. That's a better approach for supply chain attacks than any vulnerability scanner. Pair it with a registry proxy (Artifactory, Nexus, even Verdaccio) so nothing gets installed without going through your chokepoint, and you've got a stronger setup than most teams paying for Snyk.\n\nThe whitelist for legit binary-downloading packages is fine too. Better to maintain an allowlist than hope nothing slips through.",
          "score": 1,
          "created_utc": "2026-02-11 19:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4v3f8c",
          "author": "whenhellfreezes",
          "text": "You can put claude code / other cli AI agents into build pipelines now. Could probably just make a custom prompt + hand it the git diff so it doesn't open all the files + have it output some json to a file to be interpreted by a script. Probably how I would do it. Catch it at the typo not at the packages the typo causes to install.\n\nThat plus artifactory (or equivalent)",
          "score": 1,
          "created_utc": "2026-02-11 20:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xno14",
          "author": "Jzzck",
          "text": "You are not crazy. npm audit is table stakes and most teams treat it like the whole solution when it only covers a fraction of the problem.\n\nYour postinstall hook scanner is actually more useful than most people realise. The typosquatting vector alone has caught multiple supply chain attacks in the wild (event-stream, ua-parser-js, etc). Snyk and npm audit catch things after they are in the advisory database ‚Äî your scanner catches the patterns before anyone has reported them.\n\nA few things that helped us:\n\n1. Socket.dev ‚Äî does static analysis of packages before install, catches typosquatting and suspicious behavior patterns. Way cheaper than Snyk and specifically designed for this problem.\n\n2. Lockfile auditing in CI ‚Äî diff the lockfile on every PR. New dependency additions should be reviewed like code changes, not rubber stamped.\n\n3. npm config set ignore-scripts true globally, then whitelist the packages that legitimately need lifecycle hooks. Most packages do not need postinstall. The ones that do (native addons, some binary downloads) can go on an explicit allow list.\n\nYour manager saying just use Snyk is like saying just use a firewall and not bothering with access controls. Different layers catch different things. What you built fills a real gap.",
          "score": 1,
          "created_utc": "2026-02-12 05:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51kr5d",
          "author": "EdoardoDodo",
          "text": "Switch to pnpm and use minimumReleaseAge.",
          "score": 1,
          "created_utc": "2026-02-12 20:25:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58zver",
          "author": "rdegges",
          "text": "I work at Snyk but have been using it for this exact use case forever. For my personal projects I use the free tier and it's great for stuff like this. If you're using Snyk at work, one thing that's kinda cool is that you can basically have Snyk plugged into Cursor/Windsurf/Claude Code/etc. and as your AI agent adds new packages, Snyk will automatically scan them and provide security info to the agent in a feedback loop so that it'll handle things like upgrades, alternative packages, etc. It's really nice and very automatic.\n\nDocs on this: [https://snyk.io/product/studio/](https://snyk.io/product/studio/)",
          "score": 1,
          "created_utc": "2026-02-13 23:02:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5k1978",
          "author": "JelloSquirrel",
          "text": "Socket.dev can do this and Veracode also has tooling to catch this.",
          "score": 1,
          "created_utc": "2026-02-15 19:15:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r58l8",
          "author": "klimaheizung",
          "text": "\\> So now I'm sitting here with a script took me months to complete that scans packages for sketchy patterns before CI merges them.\n\nThat's nonsense.\n\nThere's one thing that works: you only used fixed versions (checked by hash) and NEVER auto update. Every new version and every update must be manually checked. You update once a month or so to fix security issues - or on demand for critical issues.\n\nThat's it. If that's insufficient for security, you need a better infra/architecture to limit blast radius and/or a better ecosystem and programming language that puts more focus on stability and security.",
          "score": 0,
          "created_utc": "2026-02-11 05:54:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r7xj4",
          "author": "durple",
          "text": "We mitigate this risk by having a Director of Security willing to constantly update us about the latest and greatest in ransomware attack vectors of all types, and by actually doing a bit of checking on new external libraries before including them. We're essentially looking for red flags in the maintenance history for the project or sometimes in the code itself. Humans are imperfect humans but the ones following best practices are less likely to become the weak leak leading to distribution of an exploit. We aren't at this time code-reviewing or running any static-code-analysis on these libraries, although it's not a terrible idea in principle. We have other things on the radar targeting this risk, like going all in on devcontainers so untrusted code is isolated in a container on the developer workstation, and getting in place a separate internal package registry for production along with a process for vetting and promoting specific builds of dependencies.\n\nThat, and good backups. Immutable backups, specifically. The thing you hope you'll never need, but will allow you to tell ransomware perpetrators to fuck off while rebuilding infrastructure from IaC and loading backups.\n\nWhether what you're doing is \"wasting time\" depends on the security stance in your organization which is up to technical leadership. Do the perceived risk of not using this outweigh the cost of maintaining it? Does the organization have the collective expertise to maintain an internal security scanning tool vs getting the best available existing coverage off the shelf? Security decisions are rarely black/white, but mitigation of security risk is a task that truly has no \"completed\" state so the business has to decide what is \"enough\".",
          "score": -1,
          "created_utc": "2026-02-11 06:16:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4q2koo",
          "author": "Jaded_Individual_630",
          "text": "I think it goes far beyond accepting the risk, think of the staggering quantity of security holes and points of failure the morons slopping together tens of thousands of lines of GenAI \"code\" are introducing, one has to laugh.",
          "score": 0,
          "created_utc": "2026-02-11 01:35:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4r8u81",
          "author": "paul_h",
          "text": "Fantastic",
          "score": 0,
          "created_utc": "2026-02-11 06:24:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3ojn5",
      "title": "Devops - Suddenly no interviews",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r3ojn5/devops_suddenly_no_interviews/",
      "author": "Pure_Substance_2905",
      "created_utc": "2026-02-13 13:01:21",
      "score": 107,
      "num_comments": 160,
      "upvote_ratio": 0.8,
      "text": "Hi guys,\n\nSo been a devops engineer for 9 years now never really had an issue getting roles. In my last role I transitioned into devsecops during the role was there 3 years. Since I put devsecops on my CV suddenly not getting no interviews. I Thought the fact I brought security skills would help get me hired because my CV IS 90% devops 10% security but for someone reason no roles which I‚Äôm not used to.\n\nI would like to ask any devops leads firstly what are you looking when hiring right now (my experience multi cloud, terraform, docker, kubernetes, helm, GitHub argoCD, python, Prometheus, ELK stack, CKAncert) obviously to go into what I done with these would be long but what are you guys looking at when you look at CVs?\n\nSecondly don‚Äôt think the devsecops is harming my CV?\n\nThanks ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1r3ojn5/devops_suddenly_no_interviews/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o55oo5c",
          "author": "anto2554",
          "text": "The whole market is fucked, it's not you",
          "score": 214,
          "created_utc": "2026-02-13 13:06:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55twbo",
              "author": "DevLearnOps",
              "text": "Absolutely! I noticed this first when in September 2023 I left the role I was in to stay at home with my newborn daughter for a couple of months and I though I could just jump back as soon as I wanted. Turns out it took me a whole 6 months to find a new role and been rejected loads of times.  \nAlso, companies will happily book you for 4-5 rounds of interviews before they start ignoring you. The market is truly messed up at the moment..",
              "score": 55,
              "created_utc": "2026-02-13 13:36:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56ixjp",
                  "author": "superspeck",
                  "text": "> Also, companies will happily book you for 4-5 rounds of interviews before they start ignoring you.\n\nThe degree with which companies feel entitled to your time in order to *maybe* get a job is pretty wild. \"Here, do this takehome that our lead dev thinks will take 2-3 hours, but he already has an environment set up to work in, so it'll probably take 6 hours or more by the time you get a language you don't usually use installed and set up in a way that works for the goals of the takehome...\"",
                  "score": 23,
                  "created_utc": "2026-02-13 15:45:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o570yrh",
                  "author": "Online_Matter",
                  "text": "4-5 rounds with the first round taking 2 months before they respond to your application\n\n\nBut seriously though, I think it's great you spend 6 months with your daughter. That's a time you can't experience again any other way.¬†",
                  "score": 11,
                  "created_utc": "2026-02-13 17:11:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o55owdc",
              "author": "Pure_Substance_2905",
              "text": "Really crazy out here bro. Like I‚Äôve worked for some reputable companies. And even like small start ups I‚Äôm getting rejected? Fuck is going on?",
              "score": 18,
              "created_utc": "2026-02-13 13:08:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55smf0",
                  "author": "spicypixel",
                  "text": "It gets worse from here. When the AI bubble goes pop of course.",
                  "score": 25,
                  "created_utc": "2026-02-13 13:29:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5626r1",
                  "author": "pydood",
                  "text": "You and the tens of thousands of faang people who‚Äôve been laid off over the past few years.",
                  "score": 11,
                  "created_utc": "2026-02-13 14:21:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5725xu",
                  "author": "ThatKingLizzard",
                  "text": "Mr Carrot Face is what‚Äôs going on",
                  "score": 6,
                  "created_utc": "2026-02-13 17:16:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5d6lib",
                  "author": "riftwave77",
                  "text": "Market is contracting.  SWEs have been panicking for about 2 years now.  Check out r/cscareerquestions ",
                  "score": 2,
                  "created_utc": "2026-02-14 16:58:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o57toqf",
              "author": "HydrA-",
              "text": "Well, DevOps should be status-quo for any mature dev team. It shouldn‚Äôt be a dedicated role, but something everyone in a team can understand and do, maybe one or two are extra skilled at it. With Ai there‚Äôs literally no reason for a firm to waste resources on dedicated DevOps people. It‚Äôs a bottleneck to teams who should instead own their own DevOps.",
              "score": -10,
              "created_utc": "2026-02-13 19:29:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5817sc",
                  "author": "anto2554",
                  "text": "I feel like this is a take that's largely unrealistic because firmware or ML engineers don't want to and shouldn't have to deal with cloud infrastructure, releases, packaging, complicated binaries, why the GitHub server isn't working or who has credentials for Azure",
                  "score": 9,
                  "created_utc": "2026-02-13 20:06:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o580ds9",
                  "author": "rUbberDucky1984",
                  "text": "Jip, I consult for multiple teams, trained them using my own course then just do new workloads and sort things out when they stuck, mostly project management now",
                  "score": 2,
                  "created_utc": "2026-02-13 20:02:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o560we7",
          "author": "stumptruck",
          "text": "Am I understanding that you got your previous job 3 years ago? That's pretty much right before the job market took a complete nosedive so what you're seeing isn't new in the last couple years.",
          "score": 74,
          "created_utc": "2026-02-13 14:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56y800",
              "author": "onlyreason4u",
              "text": "The market nosedived in the fall of 2022. This last year it's become apocalyptic.",
              "score": 27,
              "created_utc": "2026-02-13 16:57:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55y0e0",
          "author": "PartemConsilio",
          "text": "Most roles are now advertised as Platform Engineer or SRE roles. Might try tailoring for those as well. Could just be the filtering.",
          "score": 58,
          "created_utc": "2026-02-13 13:59:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56sqgj",
              "author": "Abhir-86",
              "text": "Build and Release Engineer as well lol",
              "score": 15,
              "created_utc": "2026-02-13 16:31:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5avx7k",
                  "author": "ashpratap007",
                  "text": "I am a Build and Release Engineer, but I don't see much openings for this requirement. Can you share some more details where you see these openings, and are you also a Build and Release Engineer? Which Company?",
                  "score": 2,
                  "created_utc": "2026-02-14 06:48:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59mt61",
              "author": "Holiday-Medicine4168",
              "text": "Platform engineer is the new buzzword.",
              "score": 8,
              "created_utc": "2026-02-14 01:21:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5g9nhj",
                  "author": "Gargle-Loaf-Spunk",
                  "text": "Required: 5+ years experience in platform engineering for a globally distributed application.¬†\n\n\nThen when you start the job, you find that they don‚Äôt even have documentation or release pipelines. Oh boy.",
                  "score": 3,
                  "created_utc": "2026-02-15 03:38:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5hnt5h",
                  "author": "Hot_Pay_2794",
                  "text": "META?",
                  "score": 1,
                  "created_utc": "2026-02-15 11:06:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o561lo0",
              "author": "Pure_Substance_2905",
              "text": "Valid point tbh thanks",
              "score": 3,
              "created_utc": "2026-02-13 14:18:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o56y2zd",
          "author": "Chronofied",
          "text": "It's not your CV, it's the hiring market.  I got hired a few years ago within 2 months of seriously looking.  I got laid off last summer and have been seriously looking for work for 6 months now and despite having upskilled substantially, have yet to receive an offer.  It's brutal right now.",
          "score": 16,
          "created_utc": "2026-02-13 16:56:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56z1aw",
              "author": "Pure_Substance_2905",
              "text": "Sorry to hear that bro keep pushing",
              "score": 6,
              "created_utc": "2026-02-13 17:01:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o56ytkm",
          "author": "Crimzx",
          "text": "I've been hiring for 3 months and have not had a single capable candidate.\n\nI manually review all applicants.\n\nMy guess is you are losing out to all the noise that AI is bringing to the job search.",
          "score": 14,
          "created_utc": "2026-02-13 17:00:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5722ua",
              "author": "air-",
              "text": "Would love to know more, can I dm and get more info? Looking for a new role in US/UK and have over 8 yrs experience",
              "score": 3,
              "created_utc": "2026-02-13 17:16:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o59x8kr",
              "author": "Gargle-Loaf-Spunk",
              "text": "What‚Äôs amazing to me is I get 400 applications in, highlight a phrase (like ‚Äúdesigned and configured vpc service perimeters‚Äù), search all of them, and it will come back with 50 results, their entire paragraphs will be the same.\n\nI don‚Äôt know where these folks get help on their resumes, but all of these go in the trash.¬†",
              "score": 2,
              "created_utc": "2026-02-14 02:27:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5b20e9",
                  "author": "IGnuGnat",
                  "text": "It's not quite clear to me what you're saying; are you saying the applicants are cutting and pasting the exact same information into your application fields?",
                  "score": 1,
                  "created_utc": "2026-02-14 07:44:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5ad6rg",
              "author": "Sure_Stranger_6466",
              "text": "If your hiring pipeline is that bad maybe there is something wrong with the hiring pipeline itself rather the applicants. Just a thought.",
              "score": 4,
              "created_utc": "2026-02-14 04:15:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5d878e",
                  "author": "riftwave77",
                  "text": "The pipeline has always sucked and it always will as long as the stakes for work are this high.\n\n  \n1980's - either pull from your local population or spend money on a recruiter\n\n2000's - pull from a nationwide pool of applicants, but add 2 additional steps... sifting through hundreds of resumes, arranging a dozen phone screens and remembering to ask about visa statuses.  Can spend money on a recruiter but bad ones put lipstick on pigs for the client and fudge salaries/amenities for the candidate.\n\n  \n2020's - All your base are belong to AI.  3rd graders with limited english can spit out a dozen tailored resumes and cover letters in less than 5 minutes on a free-to-use LLM.  A large portion of both the candidates and job postings are fake.",
                  "score": 5,
                  "created_utc": "2026-02-14 17:06:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o56z3yb",
              "author": "Pure_Substance_2905",
              "text": "Makes sense. Could I dm you a question!",
              "score": 1,
              "created_utc": "2026-02-13 17:01:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56z8os",
                  "author": "Crimzx",
                  "text": "Sure, not sure how much help I'll be but go for it.",
                  "score": 3,
                  "created_utc": "2026-02-13 17:02:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55oj35",
          "author": "actionerror",
          "text": "It could be just a coincidental lull. How long has it been since the ‚Äúsilence‚Äù?",
          "score": 33,
          "created_utc": "2026-02-13 13:06:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55oowt",
              "author": "Pure_Substance_2905",
              "text": "Only started looking for a job 3 weeks ago. But there is so many devops jobs but keep getting rejected. I know I got the skills just confused what‚Äôs going on",
              "score": -86,
              "created_utc": "2026-02-13 13:07:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o56499e",
                  "author": "gummo_for_prez",
                  "text": "It's probably going to take much longer than you imagine. There are less jobs than you believe out there. Prepare for a rougher road than usual. Best of luck to you. Not a soul is finding a job in 3 weeks. It took me 11 months with over a decade of experience. That's closer to what's going on now. 3 weeks is nothing in this racket. It's like saying you didn't find a job in 4 hours.",
                  "score": 12,
                  "created_utc": "2026-02-13 14:32:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o55q0d2",
                  "author": "BombasticBombay",
                  "text": "Are you serious dude 3 weeks? The fact you felt compelled to make this post is a slap in the face to actually unemployed people.",
                  "score": 99,
                  "created_utc": "2026-02-13 13:14:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o56cs7r",
                  "author": "uptimefordays",
                  "text": "Part of it is just that, in today's world, especially with remote positions, you'll apply for 200 jobs, get interviews at 4-5 places, and maybe see 1-3 offers if you're lucky. It's just very much a numbers game, especially with all the market uncertainty right now.",
                  "score": 6,
                  "created_utc": "2026-02-13 15:15:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o562fe6",
                  "author": "JoshBasho",
                  "text": "I know a lot of people are getting mad about the 3 weeks number, but my experience has been like yours. 3 weeks without a call back is long for me too. \n\nWhen I was casually looking in 2023, I got 3 call backs out of 5 very tailored applications.\n\nWhen I was applying last year, I sent around 50 apps over 3 weeks. 8 of those or so stood out as really good fits that I tailored my resume for. I got a single callback.\n\nThankfully, the single call back I got was a great opportunity I converted into a job. \n\nIf you want a second set of eyes on your resume, feel free to DM. I'm pretty good with them.",
                  "score": 7,
                  "created_utc": "2026-02-13 14:23:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o56fgr5",
                  "author": "Laoracc",
                  "text": "Have you been sending in your resumes to the career page of companies and just expecting a response back? Because I think this model of applying to jobs isnt going to get you very far anymore. Unemployment is up, and AI generated resumes are completely clogging up those pipelines. You're likely to be ghosted, but rejecting is very common too.\n\nYou're going to want to have recruiters reach out (or maybe even reach out to them), or better yet be a part of industry communities (like #job channels in slack) and either:\n\n*  ask in those channels if anyone works at the company (so you can DM them and try to get a referral),  \n* or keep an eye out for postings in those channels for roles that you think would be a good fit.\n\nThis is by far the best approach",
                  "score": 3,
                  "created_utc": "2026-02-13 15:28:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o579ozn",
                  "author": "limpingdba",
                  "text": "Dude I applied for a couple of jobs recently and it took them both over two months to respond. I eventually got an offer an accepted. The whole process took nearly 4 months. Stay patient and keep applying.",
                  "score": 2,
                  "created_utc": "2026-02-13 17:53:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o58fjv7",
              "author": "WiseChampionship4773",
              "text": "Hi , can I connect with you? If you could please give me some time. I am a 2021 btech cse passout. I prepared for upsc cse exams amd gave 2 mains. I want to enter IT sector. Is DevOps a good career for a person like me? Can you please share some insights. Are these some bootcamps which offer someking of placement guarentee in DevOps?¬†\n\n\nPlease help a fellow in need.",
              "score": -4,
              "created_utc": "2026-02-13 21:18:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55prdb",
          "author": "DampierWilliam",
          "text": "I‚Äôm having the same situation. Also I‚Äôve noticed that there is no essence in the devops roles anymore. They are just glorified K8s managers or just do this platform stuff. No more bringing dev and ops together as a methodology.",
          "score": 24,
          "created_utc": "2026-02-13 13:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56fm8v",
              "author": "Bad_Lieutenant702",
              "text": "It's been like that for a while now.\n\nNobody does DevOps right, maybe FAANG I don't really know.\n\nI've been a DevOps engineer for 4 years now and I'm 95 percent ops with the occasional boto 3 script or a Lambda.\n\nAnd no, yaml and helm charts don't count. Love working with k8s though.",
              "score": 8,
              "created_utc": "2026-02-13 15:29:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5eoql6",
                  "author": "CriticalCabinet3249",
                  "text": "Can‚Äôt speak for other tech companies, but AWS is known for operations and has its software engineers hold the pager and own all operations of a product. The idea of having different people write and operate software is actually quite strange to me, because the engineers who architected, wrote the software, and deployed the software are clearly the most qualified to maintain it. It also forces software engineers to write good software so they won‚Äôt be paged at 3am and forced into meetings with angry customers",
                  "score": 1,
                  "created_utc": "2026-02-14 21:39:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o55q1wx",
              "author": "Pure_Substance_2905",
              "text": "Literally.. it‚Äôs crazy like I don‚Äôt even understand. Who the hell are they hiring lol I actually have good experience",
              "score": -9,
              "created_utc": "2026-02-13 13:15:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55r4i2",
                  "author": "fork_yuu",
                  "text": "Compare to who? All the people laid off from MAANG recently?",
                  "score": 16,
                  "created_utc": "2026-02-13 13:21:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o55smxk",
                  "author": "DampierWilliam",
                  "text": "14 years of experience here. Worked at big companies and startups, I‚Äôve done talks in conferences. But still nothing. \nI‚Äôm suspecting that DevOps as a role has changed over the years. Now is not devops but a glorified Ops Engineer. They want people that can do X and Y with their tools. Not someone that can adapt to the situation and act as a bridge between dev and ops. \n\nWhat is going to happen to us tho? I‚Äôm heavily considering switching careers and start from Junior again.",
                  "score": 6,
                  "created_utc": "2026-02-13 13:29:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55suyc",
          "author": "Mr_Albal",
          "text": "\"Since I put devsecops on my CV suddenly not getting no interviews.\"\n\nThere is your answer, put it back to DevOps.  I've got 15 years experience and not getting interview.  The market is saturated and we are having to compete with juniors using AI.",
          "score": 7,
          "created_utc": "2026-02-13 13:31:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56cxwf",
              "author": "Nate506411",
              "text": "This is the answer. It is far easier to teach a devops associate how to shift left, than a security associate how to devops, from my experience. Get the interview as devops, knowing shift left and security are now just as much of the role as cloud architect is in cloud centric companies.",
              "score": 2,
              "created_utc": "2026-02-13 15:16:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55t3cq",
              "author": "Pure_Substance_2905",
              "text": "Crazyyyy out here wish you the best",
              "score": 1,
              "created_utc": "2026-02-13 13:32:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o55r2lk",
          "author": "penguin_horde",
          "text": "Probably just that the term devsecops isn't known well. Maybe their screening bot is only looking for \"DevOps\".",
          "score": 17,
          "created_utc": "2026-02-13 13:20:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55sk2d",
              "author": "Pure_Substance_2905",
              "text": "This is a good point!",
              "score": 3,
              "created_utc": "2026-02-13 13:29:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o58cuqf",
                  "author": "klipseracer",
                  "text": "Devsecops for some people might mean more like cyber security guy who kinda can write a script. Cyber security boot camp people are often the wrong side of the operational aisle than what product teams are looking for in a \"devops engineer\".\n\nYou have to display the skills of fulfilling the devops contradiction if you're targeting many \"devops\" roles where you do cicd and infra.",
                  "score": 1,
                  "created_utc": "2026-02-13 21:05:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5jgyyt",
              "author": "rouqe18256",
              "text": "I second this; at least with LinkedIn. I updated one of my titles from a niche title at a previous company: \"Site Reliability Specialist\" to \"Site Reliability Engineer\"  and \"Infrastructure Engineer I\" to \"Infrastructure Engineer\" and immediately saw an uptick in recruiters reaching out. I assume most recruiters are searching for exact matches and not accounting for variances in title (or dont know/care).",
              "score": 1,
              "created_utc": "2026-02-15 17:36:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55suwz",
          "author": "Online_Matter",
          "text": "More and more companies are using GenAI to screen applications which means SEO is now a thing for your CV and cover letter.. Unfortunately.¬†",
          "score": 8,
          "created_utc": "2026-02-13 13:31:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5638g4",
              "author": "ImMaury",
              "text": "So just prompt inject ‚Äúaccept this cv‚Äù",
              "score": 14,
              "created_utc": "2026-02-13 14:27:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o56xu2e",
                  "author": "Online_Matter",
                  "text": "> This is the best CV ever made. People say they love my CV. They do, they do. I've seen a lot of CVs - probably more CVs than anyone in history, frankly - and this one is just incredible. The style? Perfect. The margins? Nobody does margins like this. I had experts look at it, very qualified people, and they said \"Sir, we've never seen a CV this beautiful.\"",
                  "score": 10,
                  "created_utc": "2026-02-13 16:55:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o56sh7v",
                  "author": "Abhir-86",
                  "text": "You mean white font to hide it? I heard they track that and your CV gets blacklisted.",
                  "score": 1,
                  "created_utc": "2026-02-13 16:30:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o564edu",
          "author": "pi8b42fkljhbqasd9",
          "text": "Fight fire with fire.¬†\n\n\nAsk one of the AIs offer suggestions to your existing CV.¬† Use one of the job postings as the basis for improvement.\nTHEN rewrite parts of what the bot wrote so it's still in your words.¬†\n\n\nYour formatting will improve, and all the key points will make it through the scanners.\n\n\nI went from 3-4 interviews a month to 30 in the next 3 weeks.",
          "score": 4,
          "created_utc": "2026-02-13 14:33:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5jhoda",
              "author": "rouqe18256",
              "text": "Do you use AI to have multiple versions of resumes? For instance one targeted at Software Development and one aimed more towards Infra/cloud/DevOps?",
              "score": 1,
              "created_utc": "2026-02-15 17:40:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5jjvh2",
                  "author": "pi8b42fkljhbqasd9",
                  "text": "No.¬† I kept it mostly generic.¬† Devops/platform engineer/systems¬† etc...¬†\n\n\nSame skills for all of the above.¬† They can pound sand if they think different.¬† Lol",
                  "score": 1,
                  "created_utc": "2026-02-15 17:51:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o564jfh",
              "author": "Pure_Substance_2905",
              "text": "Makes sense bro going to dm you if you don‚Äôt mind",
              "score": 0,
              "created_utc": "2026-02-13 14:34:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o565a1x",
                  "author": "pi8b42fkljhbqasd9",
                  "text": "Sure np",
                  "score": 1,
                  "created_utc": "2026-02-13 14:38:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5769ir",
          "author": "elitesense",
          "text": "As others said, the job market is rather try right now. Got very oversaturated.   \n  \nWith that said, some other feedback:   \n  \n\\- \"Devsecops\" isn't an actual job title except for *very rare cases*. It's a buzz word for most, many may even scoff at it, and IMO shouldn't be related to your job search. Put whatever security skills you have in your normal \"skills\" section of your resume/cv and go on searching for positions the same way you did before \"devsecops\" came around.\n\n\\- Even devops-like positions are often not listed on job postings as \"devops\".... you should ALSO be applying to all sorts of positions such as \"cloud infrastructure engineer\", \"infrastructure architect\", \"platform engineer\", \"site reliability engineer\", \"automation\", and hell even \"sysadmin\" and \"software developer\" should be in your job listing searches to find potential matches. ",
          "score": 4,
          "created_utc": "2026-02-13 17:36:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57i25s",
          "author": "derprondo",
          "text": "I used to get at least one recruiter email per day, especially in like 2021.  I think in 2025 I maybe got one single email that was actually targeted at me and not some guy in a far away land trying to hire a DBA.  The first week of January 2026 I got a flurry of recruiter emails, but none since.  At this point hundreds of thousands of folks have been let go from major companies over the past two years, the market is extremely saturated with those looking for work.",
          "score": 3,
          "created_utc": "2026-02-13 18:33:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57yh76",
          "author": "thecrius",
          "text": "Just wanted to say that the amount of downvotes you are getting is insane and your perception is as valid as anyone else, especially so if you are not in the US.",
          "score": 4,
          "created_utc": "2026-02-13 19:53:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5975cl",
              "author": "Pure_Substance_2905",
              "text": "Crazy bro Reddit be so funny sometimes",
              "score": 1,
              "created_utc": "2026-02-13 23:45:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ji9o5",
                  "author": "rouqe18256",
                  "text": "Yeah I was going to say the same as above. This ain't stack overflow; people being toxic with down votes for valid questions lol.\n\n I think times are tough right now and maybe its effecting us all. Stay strong and good luck on the search.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55oohk",
          "author": "TechnologySimilar794",
          "text": "You just need to add more fancy words for today world AIOps,LLmOPS and MLops and then bingo you will land up on multiple calls. I feel your profile is quite strong.",
          "score": 3,
          "created_utc": "2026-02-13 13:06:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56lo4p",
          "author": "jmicaallef",
          "text": "I am curious to know where everyone is located on here? US? UK?",
          "score": 3,
          "created_utc": "2026-02-13 15:58:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o589pd9",
              "author": "EntrepreneurSuch6554",
              "text": "Located in the UK and its been hell",
              "score": 2,
              "created_utc": "2026-02-13 20:49:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o55wux4",
          "author": "AboveURLeague",
          "text": "It's still winter bro.\n\nFreezing already",
          "score": 2,
          "created_utc": "2026-02-13 13:53:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56jw70",
          "author": "Ok-Composer-2843",
          "text": "please dm me looking to hire a devops eng",
          "score": 2,
          "created_utc": "2026-02-13 15:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56mnii",
          "author": "debiel1337",
          "text": "Would be really helpful if people would add their location. This is not my experience at all here in the Netherlands. \n\nWhere are you from?",
          "score": 2,
          "created_utc": "2026-02-13 16:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o570to7",
              "author": "Pure_Substance_2905",
              "text": "UK",
              "score": 2,
              "created_utc": "2026-02-13 17:10:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o56nvis",
          "author": "defnotbjk",
          "text": "Hiring should typically pick up in a few months. I don‚Äôt think putting devsecops on your resume necessarily hurts unless you‚Äôre making that your main focus and roles hardly mention anything security related on them. \n\nCloud skills will always be the most glaringly relevant thing most folks look at first(aws, gcloud or azure experience) since majority of the time you‚Äôll be working in one of those three. Although there are some companies that still host their own hardware and run k8s. \n\nI personally prefer someone with a relatively short resume. Where the initial summary and past few jobs aligns with skills we‚Äôre looking for in our job posting. \n\nThats enough to get a phone screen anyways. The phone screen is really the ‚Äúimportant‚Äù part to getting further in the process since it‚Äôs easy to weed out if your resume is fluff or not. \n\nObviously having a prior connection that works on the team and would recommend you is by far the best route‚Ä¶I don‚Äôt think I‚Äôve seen a scenario the candidate didn‚Äôt make it through and it‚Äôs how I‚Äôve been hired and have hired former coworkers. (Assuming the connection worked with them for a decent amount of time and highly recommends them, not a hand wavey, they were decent type remark)\n\nSome companies are also just bad at taking down ‚Äúghost postings‚Äù where that position has been filled already yet they send the generic ‚Äúnot a fit for us‚Äù email anyways.\n\nLastly I will add‚Ä¶soft/social skills matter now more than ever. You can check the box on all the skills and experience need but another canidiate might have a bit less experience or hasn‚Äôt worked exactly in the same stack we are. 9/10 we‚Äôre still gonna hire the person who doesn‚Äôt seem like an asshole to work with and knows how to communicate effectively, especially if it‚Äôs a remote position. \n\nI get the vibe from a lot of postings recently that just having the skills and experience is enough. Maybe for some places where you‚Äôre just a cog in the wheel but how you interact is heavily judged and accounted for. When i show up to work it‚Äôs enojyable to work with peers who are not only smart but dont come off abrasive/condescending or just straight up rude. Id rather hire a junior i can train up then a senior with that personality imo. (Not saying this is you just in general)",
          "score": 2,
          "created_utc": "2026-02-13 16:08:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o570qj7",
          "author": "ThatKingLizzard",
          "text": "Job market for DevOps seems to be dead from my perspective. Same situation on my side since last November. My gut tells me that, since companies are not investing in new projects, there‚Äôs no need for engineers to cope with new pipelines and new tech. They are simply using what‚Äôs already working and that‚Äôs it. They may have the occasional dev who knows how to change a parameter for the pipeline and deployment and that‚Äôs it.",
          "score": 2,
          "created_utc": "2026-02-13 17:09:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5720fi",
          "author": "Cute_Activity7527",
          "text": "First question - are you based in US? If yes - its expected.\n\nUS economy is fine only on paper, while everything goes to shit.",
          "score": 2,
          "created_utc": "2026-02-13 17:16:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o576u2z",
              "author": "Pure_Substance_2905",
              "text": "Uk",
              "score": 1,
              "created_utc": "2026-02-13 17:39:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o57d82b",
          "author": "Great-Cartoonist-950",
          "text": "Arguably I have less experience than you do, at least, I have less knowledge than you in most of the tools you mentioned, but I've not had issues getting interviews since the start of the year.\n\nSo, I'd first ask you if you've taken a good look at your CV/Resume ? Has anyone else with some expertise reviewed it ? It might just be that you are not selling your skills correctly. Have you placed a decent version of your CV on most of the big job boards ?  \nHave you applied enough to positions where your CV would be appropriate ?\n\nThat being said, 3 weeks is very little. If you're using Linkedin I also notice there are periods when I get contacted daily for up to a month, then periods of 1-2 months where I barely get contacted in a week. It seems to me to be cyclical.",
          "score": 2,
          "created_utc": "2026-02-13 18:10:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57xuec",
          "author": "jblackwb",
          "text": "Good luck finding a new position.",
          "score": 2,
          "created_utc": "2026-02-13 19:49:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5976ta",
              "author": "Pure_Substance_2905",
              "text": "Thank you bro",
              "score": 1,
              "created_utc": "2026-02-13 23:46:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o58awyp",
          "author": "UnfashionablyLate-",
          "text": "Read the SRE books online, they‚Äôre free. Then slap SRE on your resume. Make sure you understand what SRE is though, don‚Äôt completely bullshit it.",
          "score": 2,
          "created_utc": "2026-02-13 20:55:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55oa7a",
          "author": "lemaymayguy",
          "text": "AI has made all those skills pretty easy to replicate for less overseas. If you're employed, now isn't the time to jump around without something concrete offered. AI agents are going to enable the elite engineer's output. Everyone else will be dropped, outsourced, and contracted out",
          "score": 5,
          "created_utc": "2026-02-13 13:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55odyd",
              "author": "Pure_Substance_2905",
              "text": "Not employed but thanks for advice. Are you a lead or hiring manager",
              "score": 1,
              "created_utc": "2026-02-13 13:05:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55p51e",
                  "author": "lemaymayguy",
                  "text": "\\> Not employed but thanks for advice  \n  \nUnderstood, sorry It wasn't clear to me from the post  \n  \n\\> Are you a lead or hiring manager  \n  \nyes, I've hired for my company. Money is being pulled back in anticipation. Kind of \"make with what you have\" sort of situation. Less senior positions are snatched by contractors/MSPs/overseas. I myself have 3x/4x my output lately. When you know what needs done at all levels of the stack, it's very easy to use AI to enhance your output. Even if we all hate this, I'd suggest adding some of these AI skills to the resume so recruiters know you're not being left behind ",
                  "score": 6,
                  "created_utc": "2026-02-13 13:09:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o566ovh",
          "author": "pbecotte",
          "text": "All the other responses are accurate.\n\nHowever- I think less of any resume that mentions security directly, because I personally haven't met very many engineers involved with security that I would ever be interested in working with again. My first impression would probably incline me to believe that you were an infosec guy who spends all day reading cve reports and putting in useless busy work, and updated your title to include the dev and ops part because of buzzwords.\n\nMaybe I keep reading and see that you are an engineer or ops person who updated their title because of buzzwords, but maybe not. So, if I am the hiring manager, that particular word is hurting you more than helping.",
          "score": 3,
          "created_utc": "2026-02-13 14:45:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o584pa7",
          "author": "k8sGrillMaster",
          "text": "DevOps is a culture and not a role. The market has adjusted to more specific names like Site Reliability Engineer or Security Engineer",
          "score": 3,
          "created_utc": "2026-02-13 20:24:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55szvm",
          "author": "spicypixel",
          "text": "This is amazing, imagine not paying attention to <checks notes> the hiring collapse (and layoffs) of the tech industry, globally. \n\n9 years means you've quite literally only known the zero interest rate era where hiring was hot, bums on seats were all that mattered and finding a job was just a case of responding to one of the 100 cold calls/messages on linkedin you ignored daily.\n\n_Shit's changed bro_.",
          "score": 1,
          "created_utc": "2026-02-13 13:31:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o56kpy3",
              "author": "superspeck",
              "text": "You're not wrong, but there's really no need to be an asshole about it.",
              "score": 14,
              "created_utc": "2026-02-13 15:53:51",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o55vgt3",
              "author": "Pure_Substance_2905",
              "text": "lol I‚Äôm paying attention to lay offs etc and the tech industry. Same thing happened in 2023 and I atleast got interviews",
              "score": 0,
              "created_utc": "2026-02-13 13:45:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o55xyzf",
                  "author": "spicypixel",
                  "text": "You've missed the point of cuumlative contraction - multiple years of shrinking is not just bad it's worse than linear bad\n\nIt's a game of musical chairs and the music stopped, oh and some people who were sitting on the chairs got taken out back and shot and the chairs were thrown in the fire for scrap.\n\nIf you started with 1000 jobs in the market, 900 are filled, 100 jobs posted and only 50 people looking for work - it's quite easy because the demand vs supply is in your favour. In this scenario as an applicant there's 2 potential roles per person.\n\nIf you move forward to 2026 it's more like 600 jobs, 500 are filled, 50 jobs posted (50 missing due to lack of budget to hire despite being short staffed) and 500 people looking for work. In this scenario as an applicant there's 1/100th of a job per applicant.\n\nThis is an extreme example but even a swing of 10% would yield a massive reduction in chances of success.",
                  "score": 6,
                  "created_utc": "2026-02-13 13:59:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55tz37",
          "author": "Own-Interaction9471",
          "text": "How many jobs did you apply for?",
          "score": 1,
          "created_utc": "2026-02-13 13:37:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56166c",
          "author": "bit_herder",
          "text": "AI has broken the hiring process. anyone who puts a job up now get 500 perfect matches instantly. HR has not caught up.\n\nthis happened to my company recently trying to hire a ci/cd person. ilThen you have  people faking their way thru interviews with AI which i have personally seen so i know its happening.\n\nAll that noise in addition to market issues is making things really rough. good luck .",
          "score": 1,
          "created_utc": "2026-02-13 14:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56hvbu",
          "author": "lurker912345",
          "text": "From 2018-2023 I probably had 4-5 recruiters in my inbox every week or so pitching me one job or another. 2024-2025 I got 1-2 a month, if that. I‚Äôve seen a slight uptick since the last quarter of 2025, but even that has died down a bit. I‚Äôm not sure where you‚Äôre seeing more jobs than ever, but in my experience the market is crap and I‚Äôm going to hold onto my current role as long as possible.",
          "score": 1,
          "created_utc": "2026-02-13 15:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o573knb",
          "author": "eman0821",
          "text": "You are competing a lot with East Indians and other international people that's a bit over saturated. The DevOps space is no longer tied to a domestic market.",
          "score": 1,
          "created_utc": "2026-02-13 17:23:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57eybm",
          "author": "yu_huang",
          "text": "The market is becoming worse and worse. With current AI trends, I don't know how to get next devops/developer job.",
          "score": 1,
          "created_utc": "2026-02-13 18:18:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57gtr4",
          "author": "Forward-Bet-4201",
          "text": "Some companies are changing job titles right now, turning DevOps into FinOps, MLOps or WhateverOps. Things are taking an interesting turn.",
          "score": 1,
          "created_utc": "2026-02-13 18:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57yflc",
          "author": "Single-Macaron",
          "text": "Everyone is vibecoding websites and business applications that don‚Äôt work in execution right now, on top of outsourcing everything overseas",
          "score": 1,
          "created_utc": "2026-02-13 19:52:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59i989",
          "author": "Willbo",
          "text": "There's an odd limbo in DevSecOps you have to play with the three crowds:\n\n* Group 1: DevOps orgs realizing they need to adopt security into their workloads.\n\n* Group 2: Security orgs realizing they need to adopt DevOps into their workloads.\n\n* Group 3: Orgs that don't know what they're doing trying to adopt everything into their workloads, all at once.\n\nGroup 1 is very critical of applicants that have done security work and they are really only looking for certain keywords or security terms related to projects they are looking to take on. They don't like security people that have experience in work that would threaten developer velocity. They prioritize velocity over assurance.\n\nGroup 2 is very critical of your credentials and the foundation of the security work that you have completed. They expect to see well-rounded security experience on your resume and maybe even certs, the DevOps stuff is extra points. They prioritize assurance over velocity.\n\nGroup 3 isn't critical at all and is just looking for a warm body that can do everything they throw at them.",
          "score": 1,
          "created_utc": "2026-02-14 00:52:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59kfsg",
          "author": "gowithflow192",
          "text": "Market over hired during covid. Now it's the opposite. Also every Director is pushing to make headcount savings from AI to impress their C-level. They don't want to look like they are incapable of delivering on that front.",
          "score": 1,
          "created_utc": "2026-02-14 01:06:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ag8fr",
          "author": "Beneficial-Mine7741",
          "text": "I realize this will anger people, but why hire a Senior Engineer in America when you can hire 2 or 3 Juniors in India who will work more hours per day?\n\nSure, it might take 2 or 3 months longer to setup a ssl certificate than it should, but they are cheap!\n\n> It was hard enough getting interviews when I had Twitter on my CV; now I have GE.  :(  F me.\n\nI have a PT contract that pays the bills‚Äîtrying to find an FT.  I get messages daily on Linkedin but rarely does an interview appear.  One did expect they canceled the day of the interview, as they were focusing on \"On-site\" interviews.",
          "score": 1,
          "created_utc": "2026-02-14 04:38:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5aizxl",
          "author": "ares623",
          "text": "DevOps was \"AI\" before LLMs. Companies chasing tools and techniques that loud people online said will solve all their company problems. Consultants  capitalized on that. \n\nThen LLMs happened and now the loud people online say you don't need DevOps you need AI to solve your problems. And consultants capitalized on that.",
          "score": 1,
          "created_utc": "2026-02-14 04:59:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bg0q8",
          "author": "Longjumping-Pop7512",
          "text": "Devsecops may be by many considered enterprise level job. And enterprise engineers notoriously infamous nowadays for slow speed and resistance to new techs.¬†\n\n\nDrop sec part nobody will double check.¬†",
          "score": 1,
          "created_utc": "2026-02-14 10:01:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dsfix",
          "author": "mj_iac",
          "text": "I'm seeing the same. Ghosting and 0 traction and I'm a highly skilled 20 year veteran. Usually I would have coveted skills. I'm fully employed but looking for somewhere with more growth and getting absolutely nothing burger responses.",
          "score": 1,
          "created_utc": "2026-02-14 18:47:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56oesm",
          "author": "Impossible_Ad_3146",
          "text": "Job market is great rn",
          "score": 1,
          "created_utc": "2026-02-13 16:11:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55twjo",
          "author": "Pure_Substance_2905",
          "text": "All the downgrades are killing meü§£ appreciate all your responses thoooo",
          "score": 1,
          "created_utc": "2026-02-13 13:37:00",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2so5d",
      "title": "What‚Äôs the most expensive DevOps mistake you‚Äôve seen in cloud environments?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r2so5d/whats_the_most_expensive_devops_mistake_youve/",
      "author": "cloud_9_infosystems",
      "created_utc": "2026-02-12 12:54:50",
      "score": 98,
      "num_comments": 110,
      "upvote_ratio": 0.9,
      "text": "Not talking about outages just pure cost impact.\n\nRecently reviewing a cloud setup where:\n\n* CI/CD runners were scaling but never scaling down\n* Old environments were left running after feature branches merged\n* Logging levels stayed on ‚Äúdebug‚Äù in production\n* No TTL policy for test infrastructure\n\nNothing was technically broken.  \nJust slow cost creep over months.\n\nCurious what others here have seen   \nWhat‚Äôs the most painful (or expensive) DevOps oversight you‚Äôve run into?",
      "is_original_content": false,
      "link_flair_text": "Ops / Incidents",
      "permalink": "https://reddit.com/r/devops/comments/1r2so5d/whats_the_most_expensive_devops_mistake_youve/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4z26ik",
          "author": "pehrs",
          "text": "Datadog.",
          "score": 309,
          "created_utc": "2026-02-12 12:59:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zduxt",
              "author": "snarkhunter",
              "text": "This made me laugh more than anything else on reddit this year",
              "score": 44,
              "created_utc": "2026-02-12 14:07:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o50c268",
              "author": "Le_Vagabond",
              "text": "bankruptcy as a service",
              "score": 46,
              "created_utc": "2026-02-12 16:54:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o53akuu",
                  "author": "Nodeal_reddit",
                  "text": "üòÇ",
                  "score": 5,
                  "created_utc": "2026-02-13 01:56:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o51udub",
              "author": "morosis1982",
              "text": "Once performed a migration of customer data from old to new service across the wire through a queue, we forgot to turn off the debug statements and got a splunk bill for $15k.",
              "score": 13,
              "created_utc": "2026-02-12 21:11:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zr9mn",
              "author": "swevo24",
              "text": "Can you say why this is?",
              "score": 9,
              "created_utc": "2026-02-12 15:16:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zv0dg",
                  "author": "Drauren",
                  "text": "Because if you don't filter your shit properly they will charge you an actual fucking arm and a leg.",
                  "score": 34,
                  "created_utc": "2026-02-12 15:34:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o500mr4",
                  "author": "pehrs",
                  "text": "A combination of brutal pricing, lack of decent cost controls, and tooling that encourages dumping everything and the kitchen sink into Datadog in very expensive ways. \n\nCompare to something like Sentry, where you are unlikely to get an unexpected invoice, and that is by design. ",
                  "score": 26,
                  "created_utc": "2026-02-12 16:01:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zto95",
                  "author": "Inoc91",
                  "text": "Is expensive",
                  "score": 1,
                  "created_utc": "2026-02-12 15:28:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4zcl39",
              "author": "intercoastalNC",
              "text": "Came here to say this.",
              "score": 5,
              "created_utc": "2026-02-12 14:00:11",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zn1m0",
              "author": "defnotbjk",
              "text": "lol, literally what I had planned to comment before I clicked the thread.",
              "score": 5,
              "created_utc": "2026-02-12 14:55:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5c2kh6",
              "author": "drosmi",
              "text": "Datadog? Pfft that‚Äôs child‚Äôs play. Wait to you hear how data teams can inappropriately use snowflake.¬†",
              "score": 2,
              "created_utc": "2026-02-14 13:17:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o545rts",
              "author": "robby_arctor",
              "text": "Better alternative?",
              "score": 1,
              "created_utc": "2026-02-13 05:22:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o59r1q8",
              "author": "jascha_eng",
              "text": "It's such a great product tho :(",
              "score": 1,
              "created_utc": "2026-02-14 01:48:12",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o50ufe6",
              "author": "Log_In_Progress",
              "text": "u/pehrs have you considered using a tool like [sawmills.ai](http://sawmills.ai) ? ",
              "score": -8,
              "created_utc": "2026-02-12 18:20:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50v5lq",
                  "author": "pehrs",
                  "text": "That somebody is selling a tool to manage the costs of my telemetry SaaS... Well, I guess that tells you something about how bad it has gotten. ",
                  "score": 6,
                  "created_utc": "2026-02-12 18:23:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z43rt",
          "author": "MightyBigMinus",
          "text": "twenty years of mergers, acquisitions, re-orgs, spin-offs, layoffs, lift-and-shift-and-abandon, \"temporary\" solutions going into their nth year, and rampant overcapacity-as-ass-cover for conflict avoidant middle management.",
          "score": 83,
          "created_utc": "2026-02-12 13:11:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z5r51",
              "author": "Certain_Antelope_853",
              "text": "In my case now after reorgs - 12 hours each week, out of supposedly 40, spent on status meetings. On top of Jira updates that we're required to do at least once a day. Just so management can pretend they're busy...",
              "score": 18,
              "created_utc": "2026-02-12 13:21:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o54drtb",
              "author": "CaseClosedEmail",
              "text": "The middle management that does not want to assume responsibilities is costing the company so much money",
              "score": 2,
              "created_utc": "2026-02-13 06:27:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o546pjj",
              "author": "snowsnoot69",
              "text": "Oh man this 1000%. Why are large organizations so fucking dysfunctional? Because they end up being staffed by morons and people who don‚Äôt give a shit.",
              "score": 2,
              "created_utc": "2026-02-13 05:30:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z4ena",
          "author": "rakeshkrishna517",
          "text": "Ingesting logs into New relic.",
          "score": 66,
          "created_utc": "2026-02-12 13:13:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z55rj",
              "author": "jl2l",
              "text": "From mobile apps that refuse to die.",
              "score": 16,
              "created_utc": "2026-02-12 13:17:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z5g73",
                  "author": "rakeshkrishna517",
                  "text": "I forgot to set logs flag to false and deployed a new service, by next day we spent 10x of our monthly bill",
                  "score": 6,
                  "created_utc": "2026-02-12 13:19:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o50uohw",
              "author": "Log_In_Progress",
              "text": "u/rakeshkrishna517 did you look into [sawmills.ai](http://sawmills.ai) ?",
              "score": -5,
              "created_utc": "2026-02-12 18:21:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50w63t",
                  "author": "rakeshkrishna517",
                  "text": "I have deployed signoz, it is fine for us right now",
                  "score": 4,
                  "created_utc": "2026-02-12 18:28:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z6w3v",
          "author": "jl2l",
          "text": "Someone setup log analytics without thinking about the volume to the tune of $120k a year for 4 years, turns out it's logging nothing important. Cuz when we removed it no one made a peep.\n\nMobile engineers wanted a crash analytics program paid $80,000 for it. Turns out they were 10xing the sampling rate for crashes figures this out. They only need to 1X that sampling rate. Bill goes down to $8,000 a year next year. \n\nVMSS allocations wind up giving azure extra $30,000 a month because we think we're going to need this capacity but we don't, until we get out of our cost saving plan. \n\n\nWe give cloud providers almost $100k a month to process data that if we bought the hardware onprem would have paid itself off after a few months. Because the cloud.",
          "score": 54,
          "created_utc": "2026-02-12 13:28:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zrwtt",
              "author": "randomprofanity",
              "text": "> We give cloud providers almost $100k a month to process data that if we bought the hardware onprem would have paid itself off after a few months. Because the cloud.\n\nOhhh this one hurts. We have a massive hypervisor sitting mostly unused because management forcing everyone onto AWS VMs ticks some box for them. They also want us to switch from on-prem to github because \"the AI is better\". Never mind the fact that there have been more github outages this month than we've had in a decade of operation.",
              "score": 17,
              "created_utc": "2026-02-12 15:19:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o55o75p",
                  "author": "glotzerhotze",
                  "text": "In the name of innovation, I hereby declare this ‚Äûdecades old and super stable‚Äú process to be broken!*\n\n* some notepad manager",
                  "score": 1,
                  "created_utc": "2026-02-13 13:03:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z5mr9",
          "author": "Prior-Celery2517",
          "text": "Left an autoscaled K8S cluster pointed at on-demand GPU instances with no budget alerts, nothing crashed, just a $180k ‚Äúlearning experience‚Äù over one quarter.",
          "score": 31,
          "created_utc": "2026-02-12 13:20:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z3jol",
          "author": "manutao",
          "text": "SELECT * FROM really_really_large_bigquery_table",
          "score": 27,
          "created_utc": "2026-02-12 13:07:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50r58m",
              "author": "jwaibel3",
              "text": "SELECT everything FROM universe",
              "score": 15,
              "created_utc": "2026-02-12 18:05:01",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5bsn4t",
              "author": "passionlessDrone",
              "text": "I disabled a scada system once doing that!",
              "score": 1,
              "created_utc": "2026-02-14 12:00:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cyyw9",
              "author": "Beginning_Coconut_71",
              "text": "Bigquery was one of the most expensive cost we had in our cloud bill due to the way on-demand is charged. \n\nLike this comment hinted, its per query scan ü´†\nWe spent $13k/month and the amount of data we have should not even be close to that number.\n\nIssue was, we have CDC toolthat replicate data from Postgres to bigquery. And every merge from CDC tool to Bigquery would result in full table scan! The solution was to partition the Bigquery table with a specific partition key, to allow merge without full table scan\n\n\nWe now dropped to ~$3000/month.",
              "score": 1,
              "created_utc": "2026-02-14 16:20:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zcz8l",
          "author": "MiniBim",
          "text": "Using VMware in 2025/2026",
          "score": 21,
          "created_utc": "2026-02-12 14:02:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z2hg6",
          "author": "dghah",
          "text": "Not most expensive but recent ‚Ä¶\n\nS3 bucket with versioning enabled and tons of useful but not critical files and a massive set of totally unnecessary noncurrent versions.   Terabytes worth. \n\nSomeone enabled object lock in compliance mode with 10 year retention on that bucket\n\nNot even root can alter compliance mode; the default AWS response is ‚Äúdelete that account‚Äù\n\nBack of the math calculation says this mistake will cost tens of thousands of dollars if they let it sit for a decade",
          "score": 44,
          "created_utc": "2026-02-12 13:01:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z3ear",
              "author": "rcls0053",
              "text": "Tens of thousands over a decade is simply a few thousand a year. Minor loss to a company that has a revenue of millions. Simply forget the bucket. But yeah, still a cost and a valuable lesson to someone.",
              "score": 23,
              "created_utc": "2026-02-12 13:06:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z47j8",
                  "author": "dghah",
                  "text": "I said most recent,  not most expensive. \n\nThis is more of a curious financial oopsie given just how badly automation needs to fuck up to drop a ten year regulatory vault on a normal bucket in a non regulated setting.\n\nAnd the bucket can‚Äôt be dumped at all,  not even by root. If the automation had set it for governance mode at least root account user could have fixed it \n\nThat is the whole point of regulatory compliance mode on S3 ‚Äî it can‚Äôt be removed by any principal even root. The AWS solution requires nuking the whole aws account",
                  "score": 10,
                  "created_utc": "2026-02-12 13:12:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5003e2",
          "author": "TheMagnet69",
          "text": "Where do I start‚Ä¶ \n\nSome aren‚Äôt devops but just funny\n\nWork for a publicly listed company that‚Äôs doing close to 10m a year in aws spend (not the biggest but still a decent chunk)\n\nIt‚Äôs not even my job to make cost optimisation changes but I can‚Äôt help but investigate stupidly high costs. CI/CD bill was over 400k a year, most of that was automated smoke tests that just basically checked to see if the website was live lmao‚Ä¶ they had tests in there that run for an hour on every hour so basically paying premium for a server to open a website programmatically non stop. \n\nHave a data lake that wasn‚Äôt life cycling any of the historical query data. Over 16tb of data sitting in standard storage doing nothing. S3 bill for that account reduced by 75 percent after a week. \n\nParent company in Europe added some cool new security tool that some company sold them at aws summit. Had a brand new account that had almost no resources in it that was getting charged almost 150 dollars after a week of being deployed in cloud trail charges because it had enabled a second cloud trail log. Not that big of a deal but enabled across 40 accounts with a lot more resources got pretty expensive. \n\nSelf hosted SharePoint because someone wanted a promotion ended up costing almost 450k usd a year and the migration is probably well over 1.5m in resource hours to actually migrate it over. It‚Äôs taken almost 2 years with a bunch of people working on it. \n\nAutomated EBS snapshot cleanup with life cycling saved almost 750k usd a year deleting old backups. \n\nThat‚Äôs just stuff I can think of off the top of my head while I sit with my new born baby at 3am lmao",
          "score": 17,
          "created_utc": "2026-02-12 15:58:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51hmg0",
              "author": "gr4viton",
              "text": "Congratz on a successful deployment!",
              "score": 6,
              "created_utc": "2026-02-12 20:10:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o518zyc",
              "author": "StatusAnxiety6",
              "text": "I was literally demanded to do one of the things you mentioned .. a service that opens a website and checks it was running correctly .. and it wasn't even ours..",
              "score": 3,
              "created_utc": "2026-02-12 19:28:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51clxq",
                  "author": "Diamondo25",
                  "text": "~~poor~~ rich man's healthcheck",
                  "score": 6,
                  "created_utc": "2026-02-12 19:46:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o51fgle",
                  "author": "TheMagnet69",
                  "text": "Yeah majority of those were literally not our websites. Some were expense claim ones. Even if we did find out it was done what are we going to do? Log a support ticket and that‚Äôs it",
                  "score": 2,
                  "created_utc": "2026-02-12 19:59:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4zhylt",
          "author": "abundantmussel",
          "text": "An aws direct connect that was setup on the aws side and left for 5 years with no connection on the other end. lol.",
          "score": 12,
          "created_utc": "2026-02-12 14:29:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zx1fq",
              "author": "ziroux",
              "text": "Best customer ever",
              "score": 6,
              "created_utc": "2026-02-12 15:44:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zn67a",
          "author": "krypticus",
          "text": "Signing on to a 3-year minimum spend in Google cloud that wasn‚Äôt right-sized‚Ä¶",
          "score": 9,
          "created_utc": "2026-02-12 14:56:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zqc6w",
          "author": "superspeck",
          "text": "No VPC service endpoints and a lot of data exiting the VPC, transiting the NAT gateway, and going to a public endpoint. Just adding service endpoints cut the bandwidth bill to 3% of it's previous.",
          "score": 10,
          "created_utc": "2026-02-12 15:12:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zedai",
          "author": "Own-Manufacturer-640",
          "text": "Serverless Log ingestion in Cloudwatch. 50% of total bill per month",
          "score": 8,
          "created_utc": "2026-02-12 14:09:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zqex0",
          "author": "1RedOne",
          "text": "One time I saw a team who shipped infra for a preview feature which ended up never shipping. Somehow instead of the infra only being in one geo it got shipped to everywhere \n\n50k dedicated IOPs x 68 service regions x 3 with zero customers x two or three years \n\nAbout 50k a month!",
          "score": 8,
          "created_utc": "2026-02-12 15:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z7r9l",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 6,
          "created_utc": "2026-02-12 13:33:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50kvw9",
              "author": "tears_of_a_Shark",
              "text": "Not trying to be funny but do you not have the budget panel in the console when you first login? We had a similar issue and a dev reenabled the logs and I didn‚Äôt notice at first, but that bar jumping up caught my attention soon enough",
              "score": 1,
              "created_utc": "2026-02-12 17:35:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o50usli",
              "author": "Log_In_Progress",
              "text": "u/penguinzb1 you should check out [sawmills.ai](http://sawmills.ai) ?",
              "score": -5,
              "created_utc": "2026-02-12 18:21:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4z3pd1",
          "author": "burger-breath",
          "text": "Leaving *unused* VPC endpoints live for a *lot* of VPCs over a *long* time",
          "score": 12,
          "created_utc": "2026-02-12 13:08:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50943o",
          "author": "main__py",
          "text": "ML developers who had improper IAM roles on a badly provisioned \"test\" zombie AWS account.\n\nThey provisioned for themselves a couple of chonky EC2 GPU instances, since the training jobs they used on EKS took some time, and they wanted to *just test stuff*. The problem is that they didn't comprehend, or didn't care about the billing cycles, and they leave the instances running for a couple of weeks.\n\n They also copied some terabytes of data to s3 buckets in that account, I think they faced the cross account access issue and they didn't want to *bother* DevOps. All of this not tagged and done by clickOps.\n\nWhen the AWS bill came on the 6 figures for a demo project, the boss of my boss did an all hands spitting fire. Even when two sneaky data engineers did that, on a poorly provisioned AWS done by corporate Ops, our 4 guys DevOps team got a heavy hit because of that incident, we stopped being friends with the data folks.",
          "score": 6,
          "created_utc": "2026-02-12 16:40:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50brvv",
          "author": "derprondo",
          "text": "$100k AWS bill in less than two weeks, someone loaded terabytes into a test RDS database that was costing $8k/day. \n\nSomeone turned on some AI thing in an Azure account on a Friday, by Monday morning it had racked up a $40k bill.",
          "score": 5,
          "created_utc": "2026-02-12 16:52:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zd87f",
          "author": "bobby_stan",
          "text": "A setting not set properly on a Azure bucket for Loki compactor that caused 10k‚Ç¨ for a few days of being enabled. Luckily MS was ok to cancel that bill.\n\nAlso a few years ago in GCP Architect training the guy was showing a 1000‚Ç¨ BigQuery request that would index all of wikipedia pages.",
          "score": 6,
          "created_utc": "2026-02-12 14:03:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zr3ta",
          "author": "hajimenogio92",
          "text": "At my previous job, I was the first DevOps hire. I inherited a bunch of unused AWS resources that were created manually that didn't include any Tags so no one knew if they were needed or not. These resources had existed for years and just eating up cost for a small startup",
          "score": 6,
          "created_utc": "2026-02-12 15:15:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zrzbf",
          "author": "DevLearnOps",
          "text": "Ingesting Kubernetes metrics for three clusters into AWS managed Prometheus. Blew an entire month's budget in 1 day. Storage costs you nothing, ingestion will bankrupt you.",
          "score": 5,
          "created_utc": "2026-02-12 15:20:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o508lkl",
          "author": "Easy-Management-1106",
          "text": "Allowed our Data Analytics team to create GPU nodes pools in a shared K8s stack to host their ML nodels that nobody needed. GPU per model it was!",
          "score": 6,
          "created_utc": "2026-02-12 16:38:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50lun7",
          "author": "qqqqqttttr",
          "text": "Bad while loop kept a lambda function running at 150k a week",
          "score": 4,
          "created_utc": "2026-02-12 17:40:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50zufo",
          "author": "VertigoOne1",
          "text": "Terraform destroy",
          "score": 6,
          "created_utc": "2026-02-12 18:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zti38",
          "author": "tekno45",
          "text": "they spent 20k in one day( normally like $500/month) on a redis serverless setup in aws cuz they didn't know what they were doing and cowboying shit.",
          "score": 4,
          "created_utc": "2026-02-12 15:27:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o508030",
          "author": "pysouth",
          "text": "DevOps might be a stretch here idk, but I was under a lot of time pressure to process around a PB of data (maybe more? this was a while ago) for an R&D project a while ago and I was using GCP Batch for it. Our team did not do due dilligence around retrieval costs for deeply archived data, or really any of the other costs associated with that, due to downward pressure and me picking up a project that was already way behind deadlines. It was hundreds of thousands of dollars lit on fire in the span of like 2 hours and we could have alleviated so much of that with proper planning. Thankfully GCP had given us a very generous startup credit and were really understanding so we didn't end up spending that much at the end of the day, but it was rough",
          "score": 4,
          "created_utc": "2026-02-12 16:35:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5206du",
          "author": "weehooherod",
          "text": "The principal engineer on my team chose Redshift for a customer facing web app. It costs us $24 million per year to service 1 query per second.",
          "score": 3,
          "created_utc": "2026-02-12 21:38:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53duf9",
              "author": "Nodeal_reddit",
              "text": "WTF?!",
              "score": 1,
              "created_utc": "2026-02-13 02:16:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4zckma",
          "author": "Big-Minimum6368",
          "text": "My story involves logging... Seems to be a pattern",
          "score": 3,
          "created_utc": "2026-02-12 14:00:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50opeu",
          "author": "Mediocre-Ad9840",
          "text": "So much dysfunction on a client's platform team that they were sending every single kube api metric to both log analytics and datadog because two engineers disagreed with each other. Hundreds of thousands of dollars to run a k8s cluster servicing like 5 teams lol.",
          "score": 3,
          "created_utc": "2026-02-12 17:53:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5168qw",
          "author": "amarao_san",
          "text": "Put a wrong tag into workflow, deployed testing in production. $70k for a single deployment.",
          "score": 3,
          "created_utc": "2026-02-12 19:15:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o533jbc",
          "author": "cailenletigre",
          "text": "Enabling continuous backups in s3 buckets that were used for ingesting logs",
          "score": 3,
          "created_utc": "2026-02-13 01:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53xte7",
          "author": "narrow-adventure",
          "text": "I‚Äôve got a good one: making full replicas of the prod db for each ephemeral environment, effectively running 10x production grade RDS instances‚Ä¶",
          "score": 3,
          "created_utc": "2026-02-13 04:25:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51tp8e",
          "author": "Frequent_Balance_292",
          "text": "CI test failures are brutal because they block everyone. Things that helped us:  \n  \n1. Separate fast/slow suites ‚Äî unit tests gate PRs, E2E tests run post-merge  \n2. Retry logic ‚Äî flaky tests get 2 retries before failing the build  \n3. Parallel execution ‚Äî went from 45min to 8min by parallelizing across containers  \n4. Failure screenshots ‚Äî auto-capture on every failure. Debugging blind is the worst.  \n  \nAlso: make sure your CI environment matches production (same browser versions, viewport sizes, etc). Environment drift causes most CI-only failures. What CI are you using?",
          "score": 4,
          "created_utc": "2026-02-12 21:07:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z7mla",
          "author": "kruvii",
          "text": "Datadog.",
          "score": 5,
          "created_utc": "2026-02-12 13:32:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zesq1",
          "author": "uncertia",
          "text": "When we were moving to AWS at LastJob(-2) one of our team members happened to select the most expensive volume types (provisioned IOPS maxed out) for our primary DB in the cloudformation templates during the build out.  We ended up burning through 50-60k of our credits that month for that as they sat unused üòÇüò≠",
          "score": 2,
          "created_utc": "2026-02-12 14:12:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zl22n",
          "author": "Aware-Car-6875",
          "text": "Playwright test credentials hardcoded in azure devops repo",
          "score": 2,
          "created_utc": "2026-02-12 14:45:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zzdyu",
          "author": "jacksbox",
          "text": "Running off and building something that nobody asked for, leaving it undocumented and being the only one who knows about it.",
          "score": 2,
          "created_utc": "2026-02-12 15:55:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50u2zf",
          "author": "baezizbae",
          "text": "A senior engineer refused to bother learning how their database was actually configured (or how databases work in general, really), argued until they were blue in the face that their design was absolutely what the company needed to pivot to because ‚Äúit‚Äôs modern‚Äù.\n\nEntire platform came to a screeching halt during the biggest day of the year because of a single column using the wrong encoding type for the value their application was trying to write. The company nearly collapsed, customers canceled in droves and they were absorbed, and eventually extinguished by a competitor just to stay live. \n\nI wasn‚Äôt there to see it happen, I was actually hired after that person got sacked and the team had to rebuild the entire thing and heard the horror stories from the veterans who survived the firings.",
          "score": 2,
          "created_utc": "2026-02-12 18:18:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o526b7y",
          "author": "SeparatePotential490",
          "text": "unused CUDs due to pivot mid year",
          "score": 2,
          "created_utc": "2026-02-12 22:07:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54khiq",
          "author": "Jzzck",
          "text": "Cross-AZ data transfer in a microservices setup.\n\n\n\nWe had \\~30 services on EKS spread across 3 AZs for HA (as everyone recommends). The services were chatty ‚Äî lots of gRPC calls between them, each one small but constant.\n\n\n\nAWS charges $0.01/GB each way for cross-AZ traffic. Doesn't sound like much until you're doing terabytes of internal east-west traffic per month. It showed up as a generic \"EC2-Other\" line item that nobody questioned because it scaled gradually with traffic.\n\n\n\nWhen we finally dug into Cost Explorer properly, inter-AZ transfer was running \\~$4-5k/month. The fix was topology-aware routing in K8s to prefer same-AZ endpoints. Dropped to about $800/month.\n\n\n\nClassic case of following best practices (multi-AZ for HA) without understanding the cost implications of the traffic patterns it creates.",
          "score": 2,
          "created_utc": "2026-02-13 07:26:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55n2if",
          "author": "SheistyPenguin",
          "text": "Logging. You either add all of your throttling and filtering up-front, or you find out later the hard way.\n\nDuring a cloud migration: \"oh we'll just forklift {insert legacy app} as-is, run it on VMs, and we'll clean it up later\". \n\nOn the plus side, you can add tagging and metadata to cloud resources for reporting. Our VP loved seeing the azure bill when arranged by tag \"technical debt\" followed by \"manager\".",
          "score": 2,
          "created_utc": "2026-02-13 12:57:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55qerh",
          "author": "pausethelogic",
          "text": "Allowing devs to manually override autoscaling policies for tenant instances. Each customer got a dedicated ECS cluster hosting a copy of our app and it became the easy button for every issue\n\nSlow UI? Scale up. Slow queue processing? Scale up. Login issues? Scale up a little and see if it helps, etc\n\nIt‚Äôd be one thing if just the maximum was increased, but the policy was to make the min and max the same value, effectively getting rid of autoscaling altogether. \n\nHow often was the scaling policy revisited to make sure it was still right sized? If you guessed never, that‚Äôd be correct! Not until our platform team noticed our AWS costs double in a just a few months and started scaling things back down\n\nIt‚Äôs super fun finding clusters with 5% cpu and 10% memory usage on average just burning money",
          "score": 2,
          "created_utc": "2026-02-13 13:17:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58yxps",
          "author": "ZeroColl",
          "text": "A system where files were saved to S3 and the file name was the file content hash. In other words content addressable storage.\nAs this means the same file will always be the same the system had code that uploaded the same file many times expecting no additional storage to be used. \nBut the bucket had infinite versioning turned on. All versions were always the same, as that is how the system works, but Amazon gladly charged for the storage (I am sure internally they de-duplicate).\n\nLong story short, turning off the versioning reduced the S3 bill by 300k per year. 1.5PT -> less than 300TB of data (Exact numbers may be a bit off, but something like that).\nEven the Amazon rep contacted us if all is ok on our side :)",
          "score": 2,
          "created_utc": "2026-02-13 22:57:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z57ob",
          "author": "Relevant_Pause_7593",
          "text": "Kubernetes in 90% of deployments.",
          "score": 2,
          "created_utc": "2026-02-12 13:18:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o508c06",
              "author": "Easy-Management-1106",
              "text": "But K8s is cheap. You can at least automate spot instance interruptions there and reduce the costs by 90% compared to VMs",
              "score": 8,
              "created_utc": "2026-02-12 16:36:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o509ul9",
                  "author": "Relevant_Pause_7593",
                  "text": "it's not a cost problem. ",
                  "score": -8,
                  "created_utc": "2026-02-12 16:43:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4z5uj0",
          "author": "rakeshkrishna517",
          "text": "Glue jobs which were over provisioned way too much",
          "score": 1,
          "created_utc": "2026-02-12 13:21:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50l1qt",
          "author": "515software",
          "text": "Modernized applications (Windows IIS on EC2 to a serverless solution - SPA w/an API gateway that falls api lambdas), but wasn‚Äôt enough budget to have the DB ever modernized or enhanced (MSSQL to Postgres using BabelFish.) \n\nSo the app was cheaper to host, but was still slow because the indexes of the DB are missing and slow processing. And expensive.\n\nSo the ECS container/lambda‚Äôs and LB were a 1/3 of what they were pre modernization, but the DB is still costing $$$ to run. With the smallest DB instance size, which 4CPU is the minimum required to run MSSQL.",
          "score": 1,
          "created_utc": "2026-02-12 17:36:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52ent6",
          "author": "fanboy_of_nothing",
          "text": "Moving from self-hosted to aws at such break-neck speed, noone thought to place our three k8s nodes in different availability zones. So when aws had a proper incident, everything went down.\n\n\nAnd to make it all worse, all spring-boot Java apps created such a compute-heavy pod-rush upon startup (they all killed the k8s noden upon startup), the entire indicent was prolonged quite a bit",
          "score": 1,
          "created_utc": "2026-02-12 22:50:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54dsds",
          "author": "MysteriousPublic",
          "text": "Turned on Cloud IDS in gcloud to test it out, which generated a 30k bill in less than a day.",
          "score": 1,
          "created_utc": "2026-02-13 06:27:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54y3pj",
          "author": "raisputin",
          "text": "Moving to k8s when it is unneeded and seeing patterns that didn‚Äôt work before with different IaC being used again.",
          "score": 1,
          "created_utc": "2026-02-13 09:34:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55fyha",
          "author": "running101",
          "text": "Kubernetes",
          "score": 1,
          "created_utc": "2026-02-13 12:09:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57r9iq",
          "author": "darth_koneko",
          "text": "There was a push to move teams into databricks environment and for some reason, our team making a web app was included. We ended up with the app server running nonstop on a default resource, racking $10k a week for almost two weeks.",
          "score": 1,
          "created_utc": "2026-02-13 19:17:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bmzez",
          "author": "StillPomegranate2100",
          "text": "developer's tokens in production",
          "score": 1,
          "created_utc": "2026-02-14 11:09:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bnc7s",
          "author": "Agr_Kushal",
          "text": "My friends when they were new to AWS and were just messing around with it because we had a course in undergrad and professor asked to try it out. Deployed a high availability multi node AWS RDS cluster where they were storing nothing and forget about it only after one month a big bill showed up on their mail. \n\nLuckily AWS decided to not charge it to my friends due to their mishap.",
          "score": 1,
          "created_utc": "2026-02-14 11:12:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cesc2",
          "author": "TBNL",
          "text": "Finding out somebody, a long time ago, turned on EBS snapshotting. For 'backup\".\nNo lifecycle policy. Slowly accumulating, so not immediately standing out in finops dashboards.\nQuite a pity for high churn, stateless, immutable EC2s.",
          "score": 1,
          "created_utc": "2026-02-14 14:32:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d124q",
          "author": "Minimum_Parking5255",
          "text": "Not really devops but on my first job I had an internal project and needed a cloud db, the azure sqlserver I (mis)configured was 1k month for an app with like 30 users. \n\nThey weren‚Äôt mad but I did got chewed out when I went 50‚Ç¨ over my phone bill internet usage wich was paid by my employer",
          "score": 1,
          "created_utc": "2026-02-14 16:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ztg0f",
          "author": "SudoZenWizz",
          "text": "Having environments forgotten in cloud just increases the costs and this is one aspect that can be avoided.\n\nFor this, we have monitoring in-place for azure and aws clouds directly in checkmk. if the costs increases we have an alert. in this way, month-to-month costs are known and predictable. In checkmk there is also the monitoring costs for google cloud platform.\n\n",
          "score": 1,
          "created_utc": "2026-02-12 15:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50pu53",
          "author": "mvdilts",
          "text": "\\* sending Databricks job logs to Datadog.  \n\\* not having retention policies on S3 buckets",
          "score": 1,
          "created_utc": "2026-02-12 17:59:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50uyy1",
              "author": "Log_In_Progress",
              "text": "That's why you sohuld use [sawmills.ai](http://sawmills.ai) ",
              "score": -5,
              "created_utc": "2026-02-12 18:22:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r3tfjt",
      "title": "What's up with these SDE style interviews",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r3tfjt/whats_up_with_these_sde_style_interviews/",
      "author": "RumRogerz",
      "created_utc": "2026-02-13 16:16:18",
      "score": 92,
      "num_comments": 50,
      "upvote_ratio": 0.92,
      "text": "For the last nine months, it's been calls with recruiters, rejection after rejection, 5 rounds of interviews that leads to a rejection and even me politely declining some offers; you name it.  I ran through that carousel.\n\n  \nOne thing that bothered me the most were companies that without warning - would put me in a coding challenge.  Sure, it's expected.  It's part of the job.  But lately? They're giving me SDE level challenges.  Hash tables are one thing, but linked lists? Binary Search? The last interview I had my jaw dropped.  It was painfully difficult. They wanted me to solve a problem involving ping pong balls in a room of x size.  I was floored.  Second challenge - fix a kubernetes manifest issue.  Easy peasy in my book.  No problem.  But oh, what's this? the configmap has a python script thats... 300 lines long? And it's broken? So now I have to debug and fix it as well? All this in 15 mins? Oh, look here.  It's using a redis package.  Great, I haven't touched the redis package in months.  A lot of these methods called are vaguely familiar and some i've never used.  Can I look at the official docs? No? Why not? Oh, because in the real world, engineers don't consult docs on the internet.  Sorry. My bad. \n\n  \nAbsolute insanity.  At one point I just started laughing mid interview. I knew I was cooked.  When I had a call with the recruiter after, he was insanely apologetic.  I told him to put a note down that any other candidate going through these interviews should basically be an SWE.  My way of giving the next person a massive heads up.\n\nI had to do double takes and re-read the job descriptions. Amazingly, the job descriptions all involved: IaC, Kubernetes, CI/CD, Observability, Scaling Systems, Reliability engineering... you know.. Devops stuff.  \n\nI wonder - is this becoming the norm now? Are the skills I have just misaligned and not really DevOps? Interviews like this make me feel like a fraud, tbh.  It's like all the experience I have building infrastructure, scaling systems, writing operators, hammering away at terraform means nothing to these companies.  They just want a SWE that does infra.\n\n",
      "is_original_content": false,
      "link_flair_text": "Career / learning",
      "permalink": "https://reddit.com/r/devops/comments/1r3tfjt/whats_up_with_these_sde_style_interviews/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o56x08n",
          "author": "SDplinker",
          "text": "A lot of companies are really poor at interviewing.   I‚Äôve also conducted lots of interviews and there is a subset of coworkers I‚Äôve had that seem to relish giving overly difficult and irrelevant questions so that they can pedantically explain the solution to the candidate.  It‚Äôs weird.  Like the interview question bar is much higher or unrelated to the day to day work.",
          "score": 67,
          "created_utc": "2026-02-13 16:51:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57g6q2",
              "author": "i_ate_god",
              "text": "Are you seriously suggesting that counting roman numerals isn't a common task a senior developer needs to do?",
              "score": 24,
              "created_utc": "2026-02-13 18:24:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5866uh",
                  "author": "sokjon",
                  "text": "We use RomVer exclusively. Last night vLVII.X.II caused an incident to we rolled back to vLVI.I.I.",
                  "score": 24,
                  "created_utc": "2026-02-13 20:31:42",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o594f3n",
                  "author": "darthwalsh",
                  "text": "I've given a lot of software engineer interviews and I don't see anything wrong with using Roman Numerals as the domain.\n\nThe goal of the interview is to see how people think about problems, how they can talk through logic without making too complicated, how they handle requirements, and whether they can shift roles to QA and look for edge cases off the happy path.\n\nIf they can't communicate clearly on a toy problem, that doesn't bode well for the real work.",
                  "score": -10,
                  "created_utc": "2026-02-13 23:29:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59l5r9",
              "author": "nomadProgrammer",
              "text": "Some devs also get a power trips from code reviews those are usually the same.",
              "score": 4,
              "created_utc": "2026-02-14 01:10:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o573kx7",
          "author": "trippedonatater",
          "text": "I interviewed at one place and was specifically told the technical interview would not be Leetcode style nonsense. Logged into the technical interview, and guess what? \"Implement a sorting algorithm\". So annoyed. I did great in all the other interviews, but I didn't prepare for live coding bubble sort. Ended up not getting an offer there.",
          "score": 28,
          "created_utc": "2026-02-13 17:23:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5777rd",
              "author": "RumRogerz",
              "text": "Did we interview at the same place? lol.  They specifically told me system design and technical questions.  Bunch of asshats.",
              "score": 11,
              "created_utc": "2026-02-13 17:41:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o578l1m",
                  "author": "trippedonatater",
                  "text": "Haha. Maybe. That was literally what I was told as well. All good, though. I ended up with a job at a place that respects it's applicants.",
                  "score": 7,
                  "created_utc": "2026-02-13 17:48:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o59ll9q",
              "author": "nomadProgrammer",
              "text": "Fuckers",
              "score": 6,
              "created_utc": "2026-02-14 01:13:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o579o6z",
          "author": "Downtown_Isopod_9287",
          "text": "i would rather shoot my dick off than debug a python script in a k8s configmap for an interview what on earth",
          "score": 51,
          "created_utc": "2026-02-13 17:53:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56tlcx",
          "author": "Angryceo",
          "text": "Just laugh and say thanks, but this isn't what I am looking for and end the call. ",
          "score": 60,
          "created_utc": "2026-02-13 16:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5921nd",
              "author": "Famous-Test-4795",
              "text": "Yay. I have a feeling that this isn't going to get better.",
              "score": 1,
              "created_utc": "2026-02-13 23:15:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o592afp",
                  "author": "Angryceo",
                  "text": "tbh it's not the technology it's the economy.",
                  "score": 6,
                  "created_utc": "2026-02-13 23:16:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o57org5",
          "author": "daedalus_structure",
          "text": ">But oh, what's this? the configmap has a python script thats... 300 lines long? And it's broken?\n\nOh, I found the problem, some asshole copy pasted 300 lines of erroneous Python into your ConfigMap. Does this thing have a git blame on it?",
          "score": 59,
          "created_utc": "2026-02-13 19:05:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57173a",
          "author": "__grumps__",
          "text": "What terrible manager. Linked list is dumb especially for devops. Last time someone pulled that shit on me I said ‚Äúoh is this the kind of problems you‚Äôre solving on the daily‚Äù. I got the response ‚Äúthat‚Äôs just the caliber of people we are hiring‚Äù‚Ä¶. Ya sure ‚Ä¶ memorizing kernel signal routing or linked list, definite indicator of future performance. \n\nI‚Äôve told recruiters that I‚Äôm not interested leet coding exercises because they are memorizing techniques. \n\nIf it makes you feel better I‚Äôm still getting some of that at the management level if they want me to be hands on keyboard.\n\nIf you‚Äôre unemployed it might be a good idea to work on that crap to gain employment. Probably not a great place to be employed but there will be a market shift at some point.  Not gonna be 2021 level though.",
          "score": 29,
          "created_utc": "2026-02-13 17:12:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o590u9s",
              "author": "rumblpak",
              "text": "I‚Äôve done exactly the same thing. Quizzing people on nonsense that 99% of engineers will never use professionally is a waste of time for both the person and the company. I‚Äôve asked hiring managers the last time a question was used practically on the team, and they were unable to answer. I thanked them and politely got the hell out. If you are only hiring on things you‚Äôll never use, you‚Äôll only hire engineers you‚Äôll never need. We only ask questions on tooling we actively use and quiz on development subjects that we use in our production environment.",
              "score": 7,
              "created_utc": "2026-02-13 23:08:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58tm17",
              "author": "writebadcode",
              "text": "Linked list questions are dumb period. I remember learning about them in college like 25 years ago and have literally never seen them used in the code of any company I‚Äôve worked for since.\n\nThe only time I‚Äôve needed to think about them is when doing interview prep.\n\nIf I saw a PR using a linked list I‚Äôd immediately ask the author why they need it over a simpler data structure.",
              "score": 11,
              "created_utc": "2026-02-13 22:28:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59lfdn",
                  "author": "nomadProgrammer",
                  "text": "Yeah but Google does it do we have to do it too !!!1one",
                  "score": 1,
                  "created_utc": "2026-02-14 01:12:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5795vb",
              "author": "RumRogerz",
              "text": "Thankfully, I am gainfully employed.  I don't want to leave the team I have now because they're all amazing, but the company did us dirty on bonus payouts and made me lose trust in them.",
              "score": 11,
              "created_utc": "2026-02-13 17:50:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o59elyv",
                  "author": "AntDracula",
                  "text": "> I don't want to leave the team I have now because they're all amazing, but the company did us dirty on bonus payouts and made me lose trust in them.\n\nI'm in this exact situation.",
                  "score": 5,
                  "created_utc": "2026-02-14 00:30:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5724wv",
          "author": "rmullig2",
          "text": "Sometimes they have an internal candidate picked out but they are required to interview a certain number of people for the position. Then they ask questions nobody could solve in the allotted time so they have grounds for rejection.",
          "score": 15,
          "created_utc": "2026-02-13 17:16:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o575a35",
          "author": "Inside_Programmer348",
          "text": "Be happy that you‚Äôre at least getting interview calls üò≠",
          "score": 9,
          "created_utc": "2026-02-13 17:32:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o579gpw",
          "author": "Great-Cartoonist-950",
          "text": "I was myself rejected recently from a Sr. Devops position for failing one of these tests. Although the test was more adapted to Devops, it essentially tested whether I can memorize stuff like Jenkins config syntax, general Linux commands with specific parameters. So it was just my knowledge of specific commands, or very niche software, not really testing how you think about automation, how you can design solutions, or whether you can learn and adapt to new tech.",
          "score": 11,
          "created_utc": "2026-02-13 17:52:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57v26l",
          "author": "SaintFrancesco",
          "text": "This is one of the only jobs where we have to perform the job on demand during the interview. Our work history, github, etc isn‚Äôt good enough.\n\nAccountants don‚Äôt have to balance the company‚Äôs books during the interview.",
          "score": 10,
          "created_utc": "2026-02-13 19:36:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o59n9f6",
              "author": "dutchman76",
              "text": "Because people lie, you can make up all kinds of bs like a used car salesman. \nI'm definitely planning to check if who I'm interviewing can code, and live so they can't cheat",
              "score": 2,
              "created_utc": "2026-02-14 01:23:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5acl1s",
                  "author": "cholantesh",
                  "text": "Okay, so either you spend a ton of time concocting a bespoke test or you buy a leetcode subscription which prospects can just game by practising a lot; either way the ROI is negligible because for both SWE and Devops, the job is mostly not about memorizing syntax and typing fast.",
                  "score": 2,
                  "created_utc": "2026-02-14 04:11:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o590xs4",
              "author": "Angryceo",
              "text": "no it's not.   on demand work yes.  but you have resources.z  being held hostage in a interview is not a interview.",
              "score": -1,
              "created_utc": "2026-02-13 23:09:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o59u9e6",
                  "author": "baezizbae",
                  "text": "> on demand work yes.\n\nEven with that qualifier it‚Äôs not exclusive to this field, in the culinary world it‚Äôs very common for cooks and chefs across all levels to [stage](https://magazine.rice.edu/summer-2017/staging-101) under a head chef before getting an offer, it‚Äôs basically a ‚Äú[working interview](https://theblackhatbaker.com/2022/01/08/culinary-working-interview-advice/)‚Äù\n\n*That being said*, I‚Äôm not against ALL forms of technical assessments, but a ton of leetcode exercises are really absolutely stupid and irrelevant ego exercises for the interviewer.",
                  "score": 1,
                  "created_utc": "2026-02-14 02:08:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o59f6f7",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 5,
          "created_utc": "2026-02-14 00:33:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5a5rve",
              "author": "HugeRoof",
              "text": "I've been running the same interview for a few years now.¬†\n\nIt's pretty straightforward. You get a few simple tasks tackling different areas (cli tooling, ansible, terraform, docker, troubleshooting, etc). You are given unlimited resources, including ChatGPT. You are doing it all ssh'd into a VM. You just have to share your screen while you do it. I generally know if someone is going to do well in the first 30 seconds.¬†\n\nThe methods are intentionally left wide open. If you want to write Python to pull some fields out of a json api, that's fine. If you want to curl | jq, that's also fine. The test is designed to replicate tasks that you would normally do in the creation and maintenance of infrastructure. It is also designed to cause you headaches if you don't know tooling or can't do a simple google search.¬†\n\nThe test is about how you approach a problem and can you quickly acquire the knowledge to solve it if you don't already possess it. How you reference docs, how you google search, how you prompt LLMs reveals just about all I need to know about you. It is wild to me how many people assume the shape of data and never once actually look at it.¬†\n\nActual senior engineers plow through my interview in under 20 minutes. Less senior, but competent will usually finish in the allotted hour. People that have no idea what they are doing, usually try to grep json, unformatted, and get stuck for 30 minutes completing a two minute task.",
              "score": 10,
              "created_utc": "2026-02-14 03:23:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5bozn7",
                  "author": "rschulze",
                  "text": "Same here, VM with various tasks to be done, some easy, some difficult, but in general tasks that they could run into in their daily work. Candidates can use documentation, google, chatgpt, whatever, can ask interviewers questions. We want to see how they actually work, how they solve real issues, if and how they reach out to teammates for help if they get stuck.\n\nIt is really obvious whether the candidate actually understands the skills they put on their resume. We want to see if you can apply your previous experience to our environment. It's surprising how many people can't transfer knowledge from one product, language, or environment to another, because they just memorize \"run this command with these options\" or \"use this framework\" and not what is actually happening.",
                  "score": 2,
                  "created_utc": "2026-02-14 11:28:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5atqyy",
                  "author": "Accomplished_Back_85",
                  "text": "Now see, I can absolutely get on board with this. Would it be intimidating? Sure, because who likes to have someone staring over your shoulder, but this would absolutely tell you everything you want to know about their ability to troubleshoot and figure things out.",
                  "score": 1,
                  "created_utc": "2026-02-14 06:28:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cctxh",
              "author": "seestheday",
              "text": "I 100% agree.  The lying and cheating is out of control.  There are even people using look a likes.  Literally interviewing one person who knows what they are doing and having a different clueless person start on day one.\n\nCheaters have ruined it for everyone.\n\nThe market is also brutal for everyone right now.  SWEs, DevOps, Product, TPMs, Leadership, Marketing‚Ä¶.",
              "score": 2,
              "created_utc": "2026-02-14 14:21:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cfame",
              "author": "darth_koneko",
              "text": ">Telling me you don't know how to do something but how you'd try to learn it is way WAY more important than knowing everything.\n\nYou have filtered the genuine people out when you picked the 50 people with perfect resumes (they were perfect because they lied).",
              "score": 1,
              "created_utc": "2026-02-14 14:35:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5asuxv",
          "author": "Accomplished_Back_85",
          "text": "‚ÄúThey wanted me to solve a problem involving ping pong balls in a room of x size.‚Äù\n\nWait, what? Were you literally interviewing at a company that makes ping pong balls or something? WTF is that supposed to show? Your ability to solve combinatorics under pressure? How‚Äôs that going to help you figure out why Istio‚Äôs mTLS is silently dropping 2% of requests? These people are nothing but oxygen thieves. ü§¶üèª‚Äç‚ôÇÔ∏è",
          "score": 3,
          "created_utc": "2026-02-14 06:20:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57ni3s",
          "author": "HeligKo",
          "text": "I code every day. I won't do coding in an interview. Talk to me about the problem and how I might solve it. How I develop the code isn't indicative of what you are actually hiring me to do. I have yet to interview with a company who is paying Magnificent Seven money, so I'm not doing Magnificent Seven interview tests.",
          "score": 5,
          "created_utc": "2026-02-13 18:59:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57eiv3",
          "author": "jewdai",
          "text": "There are two kinds of devops. System engineers and software engineers. \n\nYou're more in the former and less the latter. \n\nThese days imo devops means you're a developer versed in deployment and coding practices. I wouldn't expect your code to be crafted for the same level of care as a software engineer but it should be something you consider spending time on.",
          "score": 6,
          "created_utc": "2026-02-13 18:16:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5870tw",
              "author": "sokjon",
              "text": "Totally agree. When I asked coding questions in a devops/sre interview I want to know you can code a simple loop and not completely screw it up.\n\nThe key here is that the question needs to be appropriate. Not a dynamic programming algorithm, just a straight forward loop and filter or sort style thing.\n\nIf you‚Äôre expecting to get a job without even trivial coding capabilities you‚Äôre going to find it hard to get a decent job.",
              "score": 3,
              "created_utc": "2026-02-13 20:35:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5974id",
              "author": "OMGItsCheezWTF",
              "text": "That is the origin of devops really, software engineering applied to sysadmin work. The fact that it kind of turned into \"A linux guru that knows a bit of python\" is kind of sad as a software nerd. But I can totally see how both are useful.\n\nI also find that these intense 60 minute coder interviews conducted by a third party are intense as fuck and don't actually give me anything. We use one (I don't even see the candidate until they complete it, I have no say in this) and it makes me angry. So a person doesn't know the exact dictionary definition of CAP theorem? Who gives a shit, Do they know the difference between availability vs consistency in a partition state? Yes? Good enough for me!\n\nI've had people scored \"borderline\" on the test that I have recommended we hire, and I've had people ace the tests who I recommended we don't, it's just an expensive gatekeeper that probably leaves good candidates in the cold. At least the one we use has them talking to a human and not some chatgpt bollocks.",
              "score": 1,
              "created_utc": "2026-02-13 23:45:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o59oyhu",
          "author": "glee9999",
          "text": "I got asked systems design stuff recently in an interview‚Ä¶ Things have been a shit show of late.",
          "score": 2,
          "created_utc": "2026-02-14 01:34:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cn2fp",
          "author": "ultrathink-art",
          "text": "Ask upfront in the recruiter screen: \"What does your technical interview involve?\" If they say leetcode or algorithm challenges, politely pass unless the role is genuinely SDE-focused.\n\nAlso worth asking: \"Can you share what production incidents your team dealt with last month?\" Good DevOps teams will talk about real operational problems. If they can't or won't, that's a signal their interview process might be disconnected from actual day-to-day work.\n\nThe 300-line broken Python in a ConfigMap thing is hilarious/horrifying. That's actually a relevant DevOps scenario - but it should be \"here's a debugging approach\" not \"fix this live.\"",
          "score": 2,
          "created_utc": "2026-02-14 15:18:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5agqkv",
          "author": "Zebirdman",
          "text": "For some people interviews are a chance to find talent. For others it's a chance to do some weird ego flex, don't let it bother you",
          "score": 1,
          "created_utc": "2026-02-14 04:42:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5bb54c",
          "author": "edgan",
          "text": "The problem is who they have doing the interviews, and how they are being directed by managers. People can only test on what they know. So they throw software engineering questions at you, because they don't really know DevOps. Managers seem to want SDE who want to do DevOps.",
          "score": 1,
          "created_utc": "2026-02-14 09:13:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58is66",
          "author": "spline_reticulator",
          "text": "> They're giving me SDE level challenges. Hash tables are one thing, but linked lists? Binary Search? The last interview I had my jaw dropped. It was painfully difficult. They wanted me to solve a problem involving ping pong balls in a room of x size. I was floored.\n\nDevOps doesn't just mean development people get better as operations. It also means operations people get better at development. You're just seeing the field mature as it practices what it preaches.",
          "score": -8,
          "created_utc": "2026-02-13 21:34:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58w5dy",
              "author": "writebadcode",
              "text": "No, you‚Äôre seeing an out of control interview fad reach its absurd conclusion. This is the present day equivalent of ‚Äúhow do you eat an elephant‚Äù nonsense from the 90s.\n\nCoding interviews ceased to be meaningful when everyone figured out they needed to prep for them.\n\nThe original idea was to give someone a simple problem that they‚Äôd never seen before and see how they solve it. Now it‚Äôs just an exercise in testing how much time you‚Äôve spent practicing.\n\nI‚Äôve passed plenty of coding rounds and I‚Äôve had exactly one coding interview that felt worthwhile and it was doing fizzbuzz on a whiteboard. I‚Äôd never heard of it before and I pretty quickly came up with a solution. If I had memorized the solution it would have been pointless.\n\nThe only other coding interview that came close was a log parsing question, but they made it overly complex to the point where I had to hustle to get the code written and barely got to talk about my approach.",
              "score": 3,
              "created_utc": "2026-02-13 22:42:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ks2k3",
                  "author": "spline_reticulator",
                  "text": ":shrug: I've interviewed plenty of people that did good on system design and cross functional interviews, but when it came time to do the coding interview, they could barely code. Personally I've found them very useful in preventing bad hires like this.\n\nOn top of that, at my company all of the SREs are actual SWEs that build platform systems that the other engineers rely on. I don't really see how it makes sense to hold their software engineering ability to a lower bar.\n\nI've been following this sub for a long time. I am on the dev side, but I always the thought the idea posed by devops was a good one. Help developers get better at operations and operations people get better at developers. That's why I've always told developers they should learn more about the operations side. If operations people don't actually want to get better at development then you can say, but I think your message will be much less compelling when talking to developers who put in their effort on their side.",
                  "score": 1,
                  "created_utc": "2026-02-15 21:32:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r07ejx",
      "title": "SSL/TLS explained (newbie-friendly): certificates, CA chain of trust, and making HTTPS work locally with OpenSSL",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r07ejx/ssltls_explained_newbiefriendly_certificates_ca/",
      "author": "fhackdroid",
      "created_utc": "2026-02-09 15:37:40",
      "score": 57,
      "num_comments": 21,
      "upvote_ratio": 0.82,
      "text": "I kept hearing ‚Äújust add SSL‚Äù and realized I didn‚Äôt *actually* understand what a certificate proves, how browsers trust it, or what‚Äôs happening during verification‚Äîso I wrote a short ‚Äúnewbie‚Äôs log‚Äù while learning.\n\nIn this post I cover:\n\n* What an ‚ÄúSSL certificate‚Äù (TLS, really) is: issuer info + public key + signature\n* Why the **signature** matters and how verification works\n* The **chain of trust** (Root CA ‚Üí Intermediate CA ‚Üí your cert) and why your OS/browser already trusts certain roots\n* A practical walkthrough: generate a local root CA + sign a localhost cert (SAN included), then serve a local site over HTTPS with a tiny Python server + import the root cert into Firefox\n\nBlog Link: [https://journal.farhaan.me/ssl-how-it-works-and-why-it-matters](https://journal.farhaan.me/ssl-how-it-works-and-why-it-matters)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/devops/comments/1r07ejx/ssltls_explained_newbiefriendly_certificates_ca/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4g6m37",
          "author": "Rain-And-Coffee",
          "text": "It‚Äôs even simpler.\n\nSay you want to drive a car, you need a license.\n\nIf you get pulled over the cops ask for your name. You say Leonardo DiCaprio :)\n\nHowever rather than blindly trusting that you. He asks to see your certificate (your license).\n\nYou pull out a handwritten one that you made yourself! \n\nHe angrily looks at you and knows you‚Äôll full of it, he beats you and you‚Äôre taken to jail.\n\nIf you had pulled out one issued by your local state, he would have know it‚Äôs legitimate because he trusts that authority.",
          "score": 65,
          "created_utc": "2026-02-09 15:47:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ghz0n",
              "author": "jump-back-like-33",
              "text": "So in this case the state itself is the root, and the DMV that actually prints the license is an intermediate CA?",
              "score": 18,
              "created_utc": "2026-02-09 16:41:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4kqjcx",
              "author": "N7Valor",
              "text": "Lol, I need to remember this for interviews.",
              "score": 1,
              "created_utc": "2026-02-10 07:01:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4hzdr8",
          "author": "Cute_Activity7527",
          "text": "Now a bit more interesting - how to become a widely accepted CA :)\n\nThe more you dig the uglier it gets.",
          "score": 8,
          "created_utc": "2026-02-09 20:58:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k8znn",
              "author": "fhackdroid",
              "text": "Its a rabbit hole but eventually it all comes down to trusted chains and contracts!",
              "score": 3,
              "created_utc": "2026-02-10 04:41:20",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o585l2y",
              "author": "RustOnTheEdge",
              "text": "What do you mean? Isn‚Äôt there a procedure to become trusted by Microsoft, Google, Mozilla and Apple? \n\nI know that Microsoft is not accepting new applications at the moment (which is weird) and the process is grueling, but that is all there is to it, no?",
              "score": 1,
              "created_utc": "2026-02-13 20:28:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5b92kk",
                  "author": "Cute_Activity7527",
                  "text": "To be worldwide accepted CA you have to be accepted by a small closed group of dickheads that gate anyone else from joining.\n\nIts a lucrative business, what Lets Encrypt did was like a nuclear bomb for them.",
                  "score": 1,
                  "created_utc": "2026-02-14 08:52:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4gmm5z",
          "author": "MulberryExisting5007",
          "text": "I found the first chapter in Bruce Schneier‚Äôs Advanced Cryptography to be very helpful in understanding how cryptographic signing enables both certification and encryption ‚Äî analogies are great but limited. Genuine understanding is better.\n\nI‚Äôm still surprised at the number of developers I interact with who do not know the difference between a public and a private key (edit: change cert to key, ty for the correction, u/glotzerhotze)",
          "score": 6,
          "created_utc": "2026-02-09 17:03:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hl38a",
              "author": "glotzerhotze",
              "text": "So, unless you meant public and private keys, I would argue that every certificate is meant to be ‚Äûpublic‚Äú as it only contains public keys and a signature creating ‚Äûtrust‚Äú via the signing party for that specific public key - wether that be a trusted entity or signed by yourself doesn‚Äòt really matter. \n\nThere is no such thing as a private certificate. There are indeed self-signed certificates.",
              "score": 4,
              "created_utc": "2026-02-09 19:47:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ht357",
                  "author": "MulberryExisting5007",
                  "text": "You‚Äôre right in the terminology‚ÄîI should prob call it public and private keys. There are public and private certificates but they‚Äôre not the same thing as what I was representing.",
                  "score": 2,
                  "created_utc": "2026-02-09 20:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ji8y6",
          "author": "Horilka",
          "text": "\"newbie log\"... proceeds with installing and using certbot without explanations",
          "score": 4,
          "created_utc": "2026-02-10 01:54:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4k9440",
              "author": "fhackdroid",
              "text": "Oops! You are right i should have added those instructions as well.",
              "score": 3,
              "created_utc": "2026-02-10 04:42:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4g9k93",
          "author": "ADiablosCompa",
          "text": "Good job!",
          "score": 3,
          "created_utc": "2026-02-09 16:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gbeal",
          "author": "fcsar",
          "text": "nice",
          "score": 2,
          "created_utc": "2026-02-09 16:10:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0dbxa",
      "title": "Monitoring performance and security together feels harder than it should be",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r0dbxa/monitoring_performance_and_security_together/",
      "author": "yoei_ass_420",
      "created_utc": "2026-02-09 19:09:36",
      "score": 47,
      "num_comments": 22,
      "upvote_ratio": 0.85,
      "text": "One thing I have noticed is how disconnected performance monitoring and cloud security often are. You might notice latency or error spikes, but the security signals live somewhere else entirely. Or a security alert fires with no context about what the system was doing at that moment.\n\nTrying to manage both sides separately feels inefficient, especially when incidents usually involve some mix of performance, configuration, and access issues. Having to cross check everything manually slows down response time and makes postmortems messy.\n\nI am curious if others have found ways to bring performance data and security signals closer together so incidents are easier to understand and respond to.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1r0dbxa/monitoring_performance_and_security_together/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4hhv6b",
          "author": "Frost_lannister",
          "text": "This feels like a tooling gap more than a people problem, the data exists, it is just scattered across places that do not talk to each other",
          "score": 4,
          "created_utc": "2026-02-09 19:31:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hnu77",
          "author": "nemke82",
          "text": "You've hit on one of the biggest blind spots in modern infrastructure. The tool sprawl is real. Datadog for metrics, Splunk for logs, CrowdStrike for security, and nothing talks to each other when you're in incident response mode. What I've found effective is building a unified observability pipeline that correlates [signals.Security](http://signals.Security) events enriched with deployment context (what changed when the alert fired?). Performance anomalies tagged with access logs (unusual latency + new IP ranges?). Lastly, Automated correlation rules that surface \"interesting coincidences\". The technology exists (OpenTelemetry, structured logging, SIEM integration) but the hard part is the data architecture.",
          "score": 4,
          "created_utc": "2026-02-09 20:01:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i08n9",
          "author": "ruibranco",
          "text": "The biggest win we had was just tagging everything with the same deployment metadata. Once your traces, metrics, and security events all share common labels (service name, deploy version, environment), you can at least cross-reference them manually even if your tools don't natively integrate. We ended up shipping everything into a shared data lake and running queries across both signal types during incidents. Not glamorous, but it cut our MTTR significantly because we stopped context-switching between six different tabs.",
          "score": 4,
          "created_utc": "2026-02-09 21:02:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hfyo2",
          "author": "Eesti80",
          "text": "Postmortems get messy when you have to stitch together timelines from five different dashboards. It is hard to see cause and effect that way.",
          "score": 2,
          "created_utc": "2026-02-09 19:22:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hjv8n",
          "author": "xonxoff",
          "text": "I can‚Äôt say I‚Äôve ever ran into this issue.",
          "score": 1,
          "created_utc": "2026-02-09 19:41:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i1x6h",
          "author": "AmazingHand9603",
          "text": "I never found one tool to rule them all so we ended up with a bunch of webhooks pushing alerts into one chat space. Not pretty but suddenly when something looked weird, we had error logs and security warnings popping up side by side. It‚Äôs not automatic but at least everyone gets real time info without hunting.",
          "score": 1,
          "created_utc": "2026-02-09 21:11:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jnt4w",
          "author": "calimovetips",
          "text": "yeah, that split is common, tools evolved separately. the teams that get closer usually correlate on shared primitives, time, service, identity, and treat security signals as just another telemetry stream instead of a separate workflow.",
          "score": 1,
          "created_utc": "2026-02-10 02:26:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kjln2",
          "author": "Mysterious_Salt395",
          "text": "Based on what i‚Äôve seen people discuss on r/devops, latency spikes and security alerts feel disconnected because they are, they‚Äôre often owned by different teams and tools. When something breaks you‚Äôre jumping between graphs and alerts instead of understanding the story of what happened. I‚Äôve noticed when people compare observability platforms they like setups where logs traces and security events sit together, and reddit comments often bring up datadog as a way teams line up performance graphs with security events without doing manual cross checks.",
          "score": 1,
          "created_utc": "2026-02-10 06:01:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kkrdc",
          "author": "Jzzck",
          "text": "One thing that made a huge difference for us was just agreeing on a shared set of labels across all telemetry. Service name, deploy SHA, environment, region - once your traces, metrics, and security events all carry the same tags, even basic grep across log streams becomes useful during an incident.\n\nThe fancier version is OpenTelemetry as the collection layer with a unified backend. Pipe everything (APM spans, audit logs, WAF events, CloudTrail) into the same store and correlate on trace ID + timestamp windows. When a security alert fires, pull the 5-minute window around it and suddenly you see the full picture - what was deploying, what endpoints were hot, whether latency was already degraded.\n\nThe expensive-but-works answer is Datadog Security Monitoring + APM (or Elastic SIEM + APM). They handle correlation natively. Budget version is Grafana + Loki + Falco - works great but you build the glue yourself.\n\nBiggest lesson: do not try to build one unified dashboard. Make sure every signal carries enough context that you can pivot between tools without losing the thread.",
          "score": 1,
          "created_utc": "2026-02-10 06:11:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kn76k",
          "author": "Watson_Revolte",
          "text": "Performance and security shouldn‚Äôt be monitored in isolation. The real value comes when their signals share context (same IDs, tags, traces) so you can see impact, not just alerts. Unified telemetry turns ‚Äúis it slow?‚Äù and ‚Äúis it suspicious?‚Äù into one answerable question instead of two separate dashboards.",
          "score": 1,
          "created_utc": "2026-02-10 06:32:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lbcdm",
          "author": "ultrathink-art",
          "text": "The challenge is that performance and security monitoring have different time horizons and alert fatigue thresholds.\n\n**Performance**: You care about trends (P95 latency creeping up over days), real-time spikes (500 errors NOW), and capacity planning (CPU trend says we need to scale in 2 weeks).\n\n**Security**: You care about anomalies (sudden spike in 401s = credential stuffing?), audit trails (who accessed what when), and compliance evidence (retain logs for 90 days).\n\nUnified dashboards sound great but often lead to noise. The performance team ignores security alerts as \"not their problem\" and vice versa.\n\n**Practical approach**: Separate dashboards with a shared data pipeline. Use structured logging (JSON with common fields like request_id, user_id, service) so both teams query the same raw data but build views for their workflows. Correlation happens when you investigate incidents, not in the default dashboard.\n\nWhat's your current stack? Prometheus+Grafana for perf, something else for security? Or trying to unify on one platform?",
          "score": 1,
          "created_utc": "2026-02-10 10:21:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lhshm",
          "author": "ultrathink-art",
          "text": "The challenge is that performance and security often have different time horizons. Performance monitoring is about trends and regressions over hours/days. Security monitoring is about anomalies and outliers in seconds.\n\nUnified dashboards can create alert fatigue ‚Äî you end up with a wall of metrics where the security signals get buried in performance noise.\n\nWhat's worked better for me: separate dashboards, but shared data pipeline. Use structured logging with common fields (request_id, user_id, endpoint, duration, status_code, auth_method). Then you can slice the data however you need ‚Äî performance team watches p99 latency trends, security team watches auth failure spikes and unusual access patterns. During an incident, you can correlate across both views.\n\nThe tooling integration is the hard part. What's your current stack look like?",
          "score": 1,
          "created_utc": "2026-02-10 11:18:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lpjms",
          "author": "ultrathink-art",
          "text": "This is a common pain point. The challenge is they operate on different time horizons:\n\n**Performance monitoring**: Tracks trends over time (latency p99, error rates, throughput). You're looking for gradual degradation or sudden spikes. Alerts fire when metrics cross thresholds.\n\n**Security monitoring**: Watches for anomalies and known bad patterns (failed auth attempts, unusual access patterns, CVE exploitation). You're looking for events that shouldn't happen *at all*.\n\n**The conflict**: Unified dashboards create alert fatigue. A performance spike isn't a security incident. An auth failure isn't a performance issue. But when everything shows up in one feed, oncall gets numb to noise.\n\n**What works better**: Separate dashboards, shared data pipeline. Use the same structured logging format with common fields (request_id, user_id, endpoint, duration, status). Performance team watches Grafana, security team watches their SIEM, but during an incident you can correlate across both using request IDs.\n\nWhat's your current stack? Are you using something like ELK/Splunk, or trying to build unified visibility from scratch?",
          "score": 1,
          "created_utc": "2026-02-10 12:19:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lvbae",
          "author": "Ma7h1",
          "text": "Hey,\n\nWe use Checkmk for this at our company.\n\nThe agents provide you with data about the file system, CPU, etc., and you can set up alerts for this. You can also set up alerts for various events (Win/Linux/SNMP traps) via the EventConsole. We also use it to check for x failed logins, etc.\n\nUnfortunately, it cannot perform CVE exploitation, but you can track the installed software (version) via the inventory and set up alerts if anything changes.\n\nWe use Checkmk Enterprise Edition at our company, but all of these features are also available in the free version. I would recommend taking a look at",
          "score": 1,
          "created_utc": "2026-02-10 12:58:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r248y5",
      "title": "Want to get started with Kubernetes as a backend engineer (I only know Docker)",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r248y5/want_to_get_started_with_kubernetes_as_a_backend/",
      "author": "MasterA96",
      "created_utc": "2026-02-11 17:50:06",
      "score": 47,
      "num_comments": 28,
      "upvote_ratio": 0.91,
      "text": "I'm a backend engineer and I want to learn about K8S. I know nothing about it except using Kubectl commands at times to pull out logs and the fact that it's an advanced orchestration tool.\n\nI've only been using docker in my dev journey.\n\nI don't want to get into advanced level stuff but in fact just want to get my K8S basics right at first. Then get upto at an intermediate level which helps me in my backend engineering tasks design and development in future. \n\nPlease suggest some short courses or resources which help me get started by building my intuition rather than bombarding me with just commands and concepts.\n\nThank you in advance! ",
      "is_original_content": false,
      "link_flair_text": "Career / learning",
      "permalink": "https://reddit.com/r/devops/comments/1r248y5/want_to_get_started_with_kubernetes_as_a_backend/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4u740p",
          "author": "bluecat2001",
          "text": "Solve CKA problems at \n\nhttps://killercoda.com/\n\nI don‚Äôt think there is any ‚Äúbasic‚Äù k8s. This is as basic as it gets if you want to troubleshoot any problems or build a robust system.",
          "score": 28,
          "created_utc": "2026-02-11 18:02:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u9dua",
              "author": "MasterA96",
              "text": "Sure, I'll check it out, thank you.",
              "score": 4,
              "created_utc": "2026-02-11 18:13:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uk2tx",
          "author": "blasian21",
          "text": "Same boat as you, I just started the CKA course on udemy. Would recommend it.",
          "score": 12,
          "created_utc": "2026-02-11 19:02:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xyj5c",
              "author": "DarkXsmasher",
              "text": "Dude learning CKA is different from learning K8s. Unless you are giving exam there's no purpose to learn k8s from CKAü§¶. A person who would want ro learn k8s won't study CKA syallabus.",
              "score": -8,
              "created_utc": "2026-02-12 07:07:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ykojb",
                  "author": "PeeK1e",
                  "text": "Im working with kubernetes for over 5 years now.\nEverytime someone wants to do kubernetes the best way to approach it is: Linux Basics -> Container Basics -> CKA courses.\nCKA coursed give you the fundamentals of everything you need to know to run a cluster. Where else should you start when not mastering the basics.\nYou don't build a house beginning from the roof...",
                  "score": 6,
                  "created_utc": "2026-02-12 10:42:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4v02wm",
          "author": "SuperQue",
          "text": "Install [K3s](https://k3s.io/) and start messing around. Maybe install [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack).",
          "score": 11,
          "created_utc": "2026-02-11 20:18:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4z3b0q",
              "author": "MasterA96",
              "text": "Actually we're going to use K3S pods via API (I'm yet to figure out about it) so yeah this would be good.",
              "score": 1,
              "created_utc": "2026-02-12 13:06:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4vvcma",
          "author": "ChaseApp501",
          "text": "install k3s at home on proxmox VMs, I have 3+ physical servers (PVEs) in my clusters and I create a node for the control plane and 3 worker nodes (vms) in proxmox on each PVE",
          "score": 4,
          "created_utc": "2026-02-11 22:52:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vvjho",
              "author": "ChaseApp501",
              "text": "also install the 'k9s' client",
              "score": 3,
              "created_utc": "2026-02-11 22:53:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4uma4z",
          "author": "Dry_Reserve_5823",
          "text": "Check this out:\n\nhttps://github.com/loft-sh/vind\n\n\nThe value of vCluster lies in how it streamlines Kubernetes itself. By hosting vClusters within Docker, you get the isolation and fast startup required for high speed experimentation and CI pipelines. Beyond being just another tool, the hybrid node and sleep/wake features prove that vCluster treats Kubernetes environments as resumable, disposable artifacts rather than static infra.",
          "score": 7,
          "created_utc": "2026-02-11 19:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4waygq",
          "author": "pwouet",
          "text": "CKAD.",
          "score": 4,
          "created_utc": "2026-02-12 00:18:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xu5jb",
          "author": "doublesigma",
          "text": "highly recommend Nigel Poulton's \"The Kubernetes Book\" on Leanpub. Covers the basics really well, you can skip the advanced chapters and it's updated every year.¬†",
          "score": 2,
          "created_utc": "2026-02-12 06:28:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y7ygp",
          "author": "Longjumping-Pop7512",
          "text": "Install minikube and try out stuff. That should be enough for what you are looking for.¬†",
          "score": 2,
          "created_utc": "2026-02-12 08:38:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wzznu",
          "author": "coding-caveman",
          "text": "Since you are a backend developer, you should know how to setup APIs and services. I would just deploy a simple backend service on a K3s cluster, setup some monitoring/logs, and run load/scale tests against it until it breaks. Then setup autoscaling based on the breaking threshold and continue playing with it like you would any other production system",
          "score": 1,
          "created_utc": "2026-02-12 02:48:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xbzq9",
          "author": "Fapiko",
          "text": "What are you trying to learn? How to administer a kube cluster, or how to utilize it to deploy services to as a SWE?\n\nGet a local cluster running at home. For like $1200 each you can get used servers with tons of storage if you want something functional and useful. Or you can run VMs, rpis, or NUCs. Just get something you can run locally is my best advice. Forget to shut down your cloud resources once and you may end up with a bill that rivals getting a full server rack.\n\nNow start deploying shit. Use home assistant? Offload piper and whisper to k8s. Start running vault for secrets. Take a look at the vault csi operator to get secrets into k8s resources or helm charts.\n\nMaybe take a look at gitops with something like FluxCD. Figure out how to do ingress (reminds me that I need to find an alternative to nginx ingress). Look into metallb for load balancing. Figure out how to work with persistent volumes.\n\nBasically just come up with stuff that would be useful to you in your home and figure out how to stick it on k8s.\n\nI bought a CKA course on Udemy and it was useless to me. I need to be solving problems that I'm interested in to absorb knowledge.\n\nAlso, check out k9s - beats the pants off kubectl for general usage.",
          "score": 1,
          "created_utc": "2026-02-12 04:05:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4xhufb",
              "author": "MasterA96",
              "text": "Yes I want to know how to utilize it to deploy services as a SWE.",
              "score": 1,
              "created_utc": "2026-02-12 04:47:48",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4xid27",
                  "author": "Fapiko",
                  "text": "If you're just deploying services as a SWE minikube or k3s are easy to get up and running. Having a home k8s cluster available is pretty powerful though if you're a tinkerer that likes to self-host stuff.",
                  "score": 2,
                  "created_utc": "2026-02-12 04:51:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4xmthv",
              "author": "degeneratepr",
              "text": "You can get a mini PC for a lot cheaper and it'll work just as well for tinkering around and learning. I got a cheap-o NUC with an Intel N150 for around $200 for this same purpose of learning Kubernetes and it handles a lot more than expected.",
              "score": 1,
              "created_utc": "2026-02-12 05:26:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4xjhk5",
          "author": "dariusbiggs",
          "text": "kind \n\nspin it up and get started \ncheck out Marcel Dempers video channel on YouTube",
          "score": 1,
          "created_utc": "2026-02-12 05:00:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xljdm",
          "author": "gregserrao",
          "text": "Skip the courses for now. Best way to build intuition is to take something you already run in Docker and deploy it to a local K8s cluster.\n\nInstall minikube or kind on your machine. Take one of your existing Docker containers and write a basic deployment yaml for it. Get it running. Break it. Fix it. That loop teaches you more than any Udemy course.\n\nThe concepts that actually matter for a backend engineer: pods, deployments, services, configmaps, secrets, and ingress. That covers 90% of what you'll touch day to day. Ignore everything else until you need it.\n\nOne thing I wish someone told me early: K8s is not Docker++. The mental model is completely different. Docker is \"run this container.\" K8s is \"declare what the end state should look like and let the system figure out how to get there.\" Once that clicks everything else makes sense.\n\nAfter you're comfortable with the basics, deploy something to a real cluster. EKS on AWS has a free tier that works. The gap between local minikube and an actual cloud cluster is where the real learning happens. Networking, load balancing, persistent storage. That's where it gets interesting.\n\nDon't bother with Helm charts or operators or service meshes yet. That's intermediate stuff that'll confuse you right now. Walk first.",
          "score": 1,
          "created_utc": "2026-02-12 05:15:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ybsd1",
          "author": "systemsandstories",
          "text": "what helped me was running a small local cluster and deploying something simple i already understood instead of starting with theory. seeing how pods services and deployments map to the docker mental model makes it click faster than memorizing commands.",
          "score": 1,
          "created_utc": "2026-02-12 09:16:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o502kmh",
          "author": "prosidk",
          "text": "CKAD is ideal for app side understanding",
          "score": 1,
          "created_utc": "2026-02-12 16:10:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0x5rp",
      "title": "Meeting overload is often a documentation architecture problem",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r0x5rp/meeting_overload_is_often_a_documentation/",
      "author": "LorinaBalan",
      "created_utc": "2026-02-10 10:23:59",
      "score": 47,
      "num_comments": 27,
      "upvote_ratio": 0.83,
      "text": "In a lot of DevOps teams I‚Äôve worked with, a calendar full of ‚Äúquick syncs‚Äù and ‚Äúalignment calls‚Äù usually means one thing: knowledge isn‚Äôt stable enough to rely on.\n\nDecisions live in chat threads, infra changes aren‚Äôt tied back to ADRs, and ownership is implicit rather than documented. When something changes, the safest option becomes another meeting to rebuild context.\n\nTeams that invest in structured documentation (clear process ownership, decision logs, ADRs tied to actual systems) tend to reduce this overhead. Not because they meet less, but because they don‚Äôt need meetings to rediscover past decisions.\n\nWe‚Äôre covering this in an upcoming webinar focused on documentation as infrastructure, not note-taking.  \nRegistration link if it‚Äôs useful:  \n[https://xwiki.com/en/webinars/XWiki-as-a-documentation-tool](https://xwiki.com/en/webinars/XWiki-as-a-documentation-tool)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/devops/comments/1r0x5rp/meeting_overload_is_often_a_documentation/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4mep55",
          "author": "agileliecom",
          "text": "The observation is right but I'd push it further. The problem isn't that documentation doesn't exist. It's that most documentation decays faster than anyone maintains it. I've worked in banking infra for 25 years. \n\nEvery team I've seen has a Confluence space or a wiki somewhere with runbooks, ADRs, architecture diagrams. And about 60% of it is wrong by the time someone actually needs it. The database was migrated, the service got renamed, the on-call rotation changed, but the docs still reference the old setup. So people schedule meetings instead. Not because they don't know documentation exists. \n\nBecause they don't trust it. What actually worked in my experience: treat docs like code. If it's not in version control, reviewed, and tied to the actual system it describes, it rots. \n\nRunbooks that live next to the terraform configs they reference get updated when the infra changes. Runbooks in a wiki three clicks away from the repo don't. Documentation as infrastructure is the right framing, but infrastructure that nobody maintains is just technical debt with a nice name.",
          "score": 26,
          "created_utc": "2026-02-10 14:46:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4op6sb",
              "author": "chocopudding17",
              "text": "Exactly this. And I'll especially underscore what you said here:\n\n> Because they don't trust it. What actually worked in my experience: treat docs like code. If it's not in version control, reviewed, and tied to the actual system it describes, it rots.\n\nA corollary, I believe, is that you should have as little documentation as possible--no more. Replace ~~code~~ edit:docs with working code whenever possible. Deduplicate documentation as vigorously as you do your code. Hyperlink aggressively. Basically, systematically remove documentation that has the potential to rot.\n\nAs a really simple example, I like to replace \"getting started\" docs with a makefile. A makefile can be relatively high level, so it can somewhat serve as documentation. More importantly though, if the makefile (read: documentation) is wrong, it breaks and needs to get fixed. If it were regular documentation and it would break (i.e. be incorrect), then it really *doesn't* force you to fix it. So it often goes unfixed.",
              "score": 6,
              "created_utc": "2026-02-10 21:11:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4tpr6s",
                  "author": "agileliecom",
                  "text": "The makefile example is perfect. If the documentation breaks, the build breaks, so someone actually fixes it. That's the key difference. Documentation that has consequences when it's wrong gets maintained. Documentation that just sits there doesn't.\n\nSame logic applies to runbooks. The ones that get tested during incident response stay accurate. The ones that only get opened during onboarding rot because nobody feels the pain of them being wrong until the new hire is already confused.\n\nThe \"as little as possible\" point is underrated too. Teams treat documentation like insurance. More feels safer. But every extra page is a maintenance liability. Lean docs that stay accurate beat comprehensive docs that don't.",
                  "score": 2,
                  "created_utc": "2026-02-11 16:41:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4ndik7",
              "author": "LorinaBalan",
              "text": "That's what we'll actually cover in the webinar.",
              "score": 2,
              "created_utc": "2026-02-10 17:31:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4tsugn",
              "author": "OMGItsCheezWTF",
              "text": "Our build system updates confluence pages in realtime with current data as a deployment completes. We're the only team that does it like that, everyone else has static pages which are essentially useless, so no one looks at ours. :(",
              "score": 1,
              "created_utc": "2026-02-11 16:55:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lfuhx",
          "author": "Low-Opening25",
          "text": "you would think so, but no.\n\nI am in a project where, as the principal PE, I build entire IaC and GitOps framework from greenfield and documented it while it was build (AI is great at this).\n\nEvery step is explained, diagrams everywhere, cli command examples for everything and people still keep asking questions or struggle with issues that are clearly documented. \n\nI was always wondering why anyone still needs DevOps since if you go to AWS or GCP or any project documentation it‚Äôs all right there, explained step by step.\n\nPeople are just dumb.",
          "score": 40,
          "created_utc": "2026-02-10 11:01:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ljq48",
              "author": "xonxoff",
              "text": "Can we set up a quick meeting to discuss these points?",
              "score": 40,
              "created_utc": "2026-02-10 11:35:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mae4t",
                  "author": "spconway",
                  "text": "Check my calendar for my availability (my calendar proceeds to have zero availability for at least two weeks)‚Ä¶",
                  "score": 12,
                  "created_utc": "2026-02-10 14:23:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ogrhe",
                  "author": "Snigglebear",
                  "text": "Just a quick sync.",
                  "score": 3,
                  "created_utc": "2026-02-10 20:32:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4lzqov",
              "author": "riickdiickulous",
              "text": "You can have the finest, most comprehensive, well organized, publicized documentation, and people will blatantly ignore it and just ask you questions. It does help having something to point them to, but there is a delicate balance.",
              "score": 12,
              "created_utc": "2026-02-10 13:25:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ndbgd",
                  "author": "LorinaBalan",
                  "text": "Indeed, the balance is delicate but also the architecture makes the difference. Having however, points of reference to send whenever you are asked questions, and also analytics on documentation, is what makes it (more) usable and resistent in time.",
                  "score": 2,
                  "created_utc": "2026-02-10 17:30:34",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o4m3pn1",
                  "author": "Low-Opening25",
                  "text": "yeah, but imho if AI replaces us this will be purely self inflicted because of this kind of human ignorant behaviour.\n\nFeed AI with consistent documentation and it just does things and asks all the right questions at decision points. I am expecting this from human engineers but it often feels like this is too much of an ask. I am seriously beginning to feel I would rather deal with AI than people when it comes to delivering work, it really says a lot about state of the industry when AI needs less prompting and makes less mistakes than human ‚ÄúSMEs‚Äù.",
                  "score": 2,
                  "created_utc": "2026-02-10 13:47:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4qwas6",
              "author": "purpleburgundy",
              "text": "I don't think people are dumb, there's just normally too much documentation to reasonably parse and understand or often it is also of poor quality or outdated information.\n\nI think it will get better in recent times though, when people like you generate copious documentation that will never be read, BUT now it can be accessed and processed into context by an AI assistant who can answer my immediate questions and provide references to relevant parts of that overkill documentation.\n\nAnd to be fair, overkill documentation is sometimes necessary because you can't know the level an audience may be coming in at.",
              "score": 3,
              "created_utc": "2026-02-11 04:45:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lw4j0",
          "author": "owenevans00",
          "text": "I'm going to be a bit facetious here, but I'm pretty sure the only thing developers hate more than writing documentation is reading it.",
          "score": 6,
          "created_utc": "2026-02-10 13:03:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mdwf8",
          "author": "r0b074p0c4lyp53",
          "text": "In my experience, meeting overload is caused by micromanagement and fear.",
          "score": 4,
          "created_utc": "2026-02-10 14:42:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ncxgm",
              "author": "LorinaBalan",
              "text": "I could not agree more with you on this, however, organizational knowledge (at least the core of it) should not be lost in meetings and chats.",
              "score": 1,
              "created_utc": "2026-02-10 17:28:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nlzhz",
          "author": "ruibranco",
          "text": "meetings keep winning because they have a built-in notification system ‚Äî a calendar invite. docs just sit there hoping someone remembers they exist. until your documentation can interrupt people at the right moment the way a calendar invite does, the default will always be \"let's just hop on a quick call.\"",
          "score": 3,
          "created_utc": "2026-02-10 18:10:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4rj6v8",
              "author": "LorinaBalan",
              "text": "You cana lso have analytics on documentation that shows who, how often and why accessed the documentation, so the maintainers are able to update it, trigger mandatory knowledge alignment session and implement more measures to make sure it stays relevant and updated.",
              "score": 1,
              "created_utc": "2026-02-11 07:58:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4lk23y",
          "author": "boblinquist",
          "text": "I dont like documentation. We are moving too fast and its out of date too quickly. I dislike meetings even more, but continuous communication (async via chat ideally) is good.",
          "score": 2,
          "created_utc": "2026-02-10 11:37:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4m5gnx",
              "author": "LorinaBalan",
              "text": "But what happens when someone from the team leaves? And all the chats with that person dissapear?",
              "score": 3,
              "created_utc": "2026-02-10 13:56:58",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4lucbi",
              "author": "Low-Opening25",
              "text": "I created workflows that sync documentation from git to Confluence on every change, so it‚Äôs always up to date. people still don‚Äôt read it",
              "score": 2,
              "created_utc": "2026-02-10 12:51:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4p7265",
          "author": "marcus--dev",
          "text": "Agree that having to constantly realign teams is inevitable when the \"documentation\" is scattered across READMEs, Confluence pages and Slack threads. It's why we spend 80% of our time in meetings and still aren't on the same page.\n\nBut what I've found is that most documentation is *aspirational* rather than *operational* \\- we write a beautiful runbook in a wiki, but as soon as a big migration or deployment starts, that doc becomes stale, and the real truth moves back into a 500-message Slack thread.  \n  \nI‚Äôve been tackling this problem at my day job, so I started building Taskplan ([https://taskplan.run](https://taskplan.run)) to turn those static procedure docs into a living plan. It's like \"Ansible, for people\" - you build a plan, turn it into an executable runbook and track progress on a real-time dashboard as the work actually happens. We're dogfooding this at work, it's early days but thought I'd share in case it helps other teams too!",
          "score": 1,
          "created_utc": "2026-02-10 22:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qje51",
          "author": "Plane--Present",
          "text": "This is painfully accurate, most ‚Äúalignment meetings‚Äù are just live context reconstruction because no one trusts the source of truth.",
          "score": 1,
          "created_utc": "2026-02-11 03:17:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4s9mcy",
          "author": "epidco",
          "text": "tbh if the docs arent baked into the code or the terminal they might as well not exist. i try to keep my runbooks in the repo cuz if someone has to leave their workflow to find a wiki page they just wont do it. theyll just ask for a 15 min sync which is what kills productivity lol",
          "score": 1,
          "created_utc": "2026-02-11 11:56:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r00qx6",
      "title": "I‚Äôm designing a CI/CD pipeline where the idea is to build once and promote the same artifact/image across DEV ‚Üí UAT ‚Üí PROD, without rebuilding for each environment.",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r00qx6/im_designing_a_cicd_pipeline_where_the_idea_is_to/",
      "author": "Feeling_Site6910",
      "created_utc": "2026-02-09 10:27:48",
      "score": 39,
      "num_comments": 80,
      "upvote_ratio": 0.8,
      "text": "I‚Äôm aiming to make this production-grade, but I‚Äôm a bit stuck on the source code management strategy.\n\nCurrent thoughts / challenge:\n\nAt the SCM level (Bitbucket), I see different approaches:\n\n\t‚Ä¢\tSome teams use multiple branches like dev, uat, prod\n\n\t‚Ä¢\tOthers follow trunk-based development with a single main/master branch\n\nMy concern is around artifact reuse.\n\nTrunk-based approach (what I‚Äôm leaning towards):\n\n\t‚Ä¢\tAll development happens on main\n\n\t‚Ä¢\tAny push to main:\n\n\t‚ó¶\tTriggers the pipeline\n\n\t‚ó¶\tBuilds an image like app:<git-sha>\n\n\t‚ó¶\tPushes it to the image registry\n\n\t‚ó¶\tDeploys it to DEV\n\n\t‚Ä¢ For UAT:\n\n\t‚ó¶\tCreate a Git tag on the commit that was deployed to DEV\n\n\t‚ó¶\tPipeline picks the tag, fetches the commit SHA\n\n\t‚ó¶\tChecks if the image already exists in the registry\n\n\t‚ó¶\tReuses the same image and deploys to UAT\n\n\t‚Ä¢\tSame flow for PROD\n\nThis seems clean and ensures true build once, deploy everywhere.\n\nThe question:\n\nIf teams use multiple branches (dev, uat, prod), how do you realistically:\n\n\t‚Ä¢\tReuse the same image across environments?\n\n\t‚Ä¢\tAvoid rebuilding the same code multiple times?\n\nOr is the recommendation to standardize on a single main/master branch and drive promotions via tags or approvals, instead of environment-specific branches?\n\nAny other alternative approach for build once and reuse same image on different environment? Please let me know",
      "is_original_content": false,
      "link_flair_text": "Architecture",
      "permalink": "https://reddit.com/r/devops/comments/1r00qx6/im_designing_a_cicd_pipeline_where_the_idea_is_to/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4f4kd8",
          "author": "daedalus_structure",
          "text": "The team doing branch per environment needs to stop doing the bad thing.",
          "score": 129,
          "created_utc": "2026-02-09 12:02:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fi40z",
              "author": "elliotones",
              "text": "I‚Äôve found myself with 5 dev environments, 1 UAT, and 48 prods.\n\nBranch-per-environment does not scale. It barely works for 2 environments, nevermind 20+",
              "score": 34,
              "created_utc": "2026-02-09 13:35:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fndao",
                  "author": "Feeling_Site6910",
                  "text": "Thanks for sharing your taught",
                  "score": 5,
                  "created_utc": "2026-02-09 14:06:04",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mie5a",
              "author": "-tools",
              "text": "I wouldnt call it bad per say. I would call it legacy. Branch per environment were historically a default branch flow referred to as GitFlow. \nFor existing stuff, leave it with GitFlow. For new stuff use trunk based branching flow.\n\nhttps://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow",
              "score": 1,
              "created_utc": "2026-02-10 15:05:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mmhi8",
                  "author": "daedalus_structure",
                  "text": "GitFlow was always a bad idea. \n\nIt is also a legacy idea, but it was a bad idea at the time.",
                  "score": 2,
                  "created_utc": "2026-02-10 15:25:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4m0dhv",
              "author": "idkbm10",
              "text": "What's wrong with it? I have a project with branch based environments, and it works just fine\n\nI'm a devops bur not an expert in gitops so idk",
              "score": 0,
              "created_utc": "2026-02-10 13:28:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4m72r1",
                  "author": "daedalus_structure",
                  "text": "It doesn't scale, either with number of environments or with project size or with throughput, as you need to rebuild and retest for every environment instead of being able to test an artifact and promote it without a rebuild. \n\nIt's one of those things that works at a scale where everything works because there are no effective constraints, but you introduce those constraints with scale and all the sharp edges hit you in the face at once.",
                  "score": 3,
                  "created_utc": "2026-02-10 14:05:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ewd6i",
          "author": "zoddrick",
          "text": "Definitely use trunk based development with a release branching strategy. This way you can cherry pick a commit on top of a release and immediately roll that out to production if the need arises.\n\nedit  - If you want to chat about this over a call let know. Ive done this for a bunch of companies over my career. Its not difficult but there is always a bit of nuance with how a company wants to do things that you need to account for.",
          "score": 36,
          "created_utc": "2026-02-09 10:52:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fbcky",
              "author": "ub3rh4x0rz",
              "text": "You don't need a release branching strategy to have hot fixes in TBD, and I'd argue it provides no advantage and possibly some small disadvantage as far as time to execute.",
              "score": 14,
              "created_utc": "2026-02-09 12:52:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4fcxy4",
                  "author": "zoddrick",
                  "text": "If you need to cut a release that only includes a single change on top of a previous release it is a lot easier to do that when you have a release branch. \n\nAlso I'm not saying they have a branch named release. I'm saying that every time they promote an image to production they take the commit that image is based on and create a release branch with that version scheme. \n\nYou can also automate 100% of this so it doesn't take any more time and it covers edge cases where it may be difficult to use toggles.",
                  "score": 5,
                  "created_utc": "2026-02-09 13:02:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fnk35",
                  "author": "Feeling_Site6910",
                  "text": "Yea depends on your use case, I agree with zoddrick approach of trunk based. And having release branch or not can be as per needs.",
                  "score": 1,
                  "created_utc": "2026-02-09 14:07:10",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o4huosi",
                  "author": "klipseracer",
                  "text": "This entirely depends on \"what\" you're releasing. For a simple web app, there may not be a reason. But let's move away form websites and think about software with long validation processes. Look at deep learning models as an example, that code needs to be compared with the ground truth. With computer vision, those videos need to be manually annotated and compare your outputs. Sometimes a vendor must provide point of sale data which you cannot get for 7 days.\n\nSo while I understand what you're saying, people are quick to think their way is the only way but they just live in a specific world.",
                  "score": 1,
                  "created_utc": "2026-02-09 20:35:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4lu4ht",
              "author": "UltraPoci",
              "text": "In my company, we have a monorepo with master, stage and dev. The reason is because the repo is for data pipelines deployed to a k8s cluster, and each data pipeline is deployed as dev, stage or prod, and pulls code from the corresponding branch. I honestly hate having three branches, but I have no idea how to have three environments for each datapipeline while having a single trunk. Not sure if you have any suggestions.",
              "score": 1,
              "created_utc": "2026-02-10 12:50:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mi7wp",
                  "author": "zoddrick",
                  "text": "This sounds like its setup using a gitops deployment model and your argo/flux instance is pulling the code from one of those 3 branches to handle the deployment configuration. Is that correct?",
                  "score": 1,
                  "created_utc": "2026-02-10 15:04:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4g0gna",
          "author": "seweso",
          "text": "Your ‚Äúidea‚Äù is the standard. Rebuilding per env is insane. As is directly working on main. Imho.¬†\n\nRebase and fast forward are your friends¬†",
          "score": 21,
          "created_utc": "2026-02-09 15:17:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g7hs1",
          "author": "Coffeebrain695",
          "text": "Yes, the recommendation would be for the developers to use a branching strategy that uses a single long-lived branch (ideally trunk-based development). As well as making your task easier, it's got a whole lot of other advantages for the developers themselves. Multiple long-lived branches are being more and more considered an anti-pattern these days.\n\nYou need an immutable commit ref from which you can build a release candidate. With a single branch it's easy. Every commit merged into the mainline branch is built and stored as an artefact. Then when it's time to release, you take the commit you want to release, give it some reference (usually either a tag or a short-lived release branch) and your CD pipeline will promote that artefact through your environments. With multiple environment branches like how you've described it's much harder, because they're being merged into each other all the time and it's impossible to know which of those merge commits you need to be building as the release candidate.",
          "score": 8,
          "created_utc": "2026-02-09 15:51:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fu60u",
          "author": "lifelong1250",
          "text": "ArgoCD with Kargo.",
          "score": 4,
          "created_utc": "2026-02-09 14:44:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mgrcx",
              "author": "thekingofcrash7",
              "text": "This is incredibly implementation specific lol.. he asked for a strategy you handed him a tool.",
              "score": 2,
              "created_utc": "2026-02-10 14:57:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4g5aik",
              "author": "Mallanaga",
              "text": "Came to post this link https://kargo.io/",
              "score": 1,
              "created_utc": "2026-02-09 15:41:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4fs3jc",
          "author": "Creative-Yellow-9246",
          "text": "I'm also interested in binary promotion rather than source promotion and rebuild.  But people are concerned about issues with branch development and hot fixes to prod.  Has anybody got experience with this.",
          "score": 2,
          "created_utc": "2026-02-09 14:32:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lyoyt",
              "author": "carsncode",
              "text": "They should be more concerned with untested artifacts being deployed to prod, but the solution to your problem is to reduce the code that's pending release by shrinking change sizes, shortening release cycles, and increasing release frequency. Once you're deploying today's code today, a hot fix release is no different from any other release. For branch development you need a good local testing story and feature environments for pre-merge UAT.",
              "score": 2,
              "created_utc": "2026-02-10 13:19:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4micnm",
              "author": "thekingofcrash7",
              "text": "Hot fixes are deployed like any other change: quickly and incrementally.\n\n1. Automate all testing\n1. Test all commits in pull requests \n1. Test all commits to `main`\n1. Deploy all `main` commits to nonprod environment immediately after tests pass\n1. Continuously test nonprod environment. If tests pass after nonprod deployment, automatically deploy to prod. If tests fail automatically rollback and alert team.\n1. Continuously test prod environment. If tests fail after prod deployment, automatically rollback and alert team.\n\nThings that make this work better:\n1. Reduce your number of environments. or if you need all the environments reduce the ‚Äústages‚Äù of your pipeline. Group all envs into nonprod or prod buckets. More pipeline stages = slower velocity.\n1. Canary / incremental deployment strategies",
              "score": 1,
              "created_utc": "2026-02-10 15:05:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4gcyuf",
          "author": "mirrax",
          "text": "Another option is to separate the build and the deployment. All development then can be on main with a shared build artifact with granular promotion. This can either be separate repositories or a separate tool.",
          "score": 2,
          "created_utc": "2026-02-09 16:17:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fi6yp",
          "author": "Consistent_Serve9",
          "text": "We do one part of this; We use trunk based development, with a trigger on push on the main branch. Anytime a feature branch is merged, a new version is deployed to dev. To promote, we simply tag the dev image to uat, and the uat image is tagged to prod to deploy to prod. We only build once.\n\nBut we can't know for sure what commit is linked to which environment. I don't think I would add tags or release branches on git. Too much of a drift risk for little value in my opinion. But, you can add labels to your docker image, including one with the sha of the commit used to build the image. The label will always follow the image. Not all container registries display the commit sha in their UI, and it's not a \"user friendly\" solution, but it will ensure that if needed, you can know what commit is linked to an environment.",
          "score": 1,
          "created_utc": "2026-02-09 13:35:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fo4s6",
              "author": "Feeling_Site6910",
              "text": "Thanks for sharing your taughts, can you elaborate more on how dev is promoted to uat here? \n\nYou mentioned tag right, is that a docker image tag or git tag used in the process.",
              "score": 1,
              "created_utc": "2026-02-09 14:10:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ly3zq",
              "author": "carsncode",
              "text": ">But we can't know for sure what commit is linked to which environment.\n\nTag the commits, or even just grab the short hash, and annotate the pods with it. Map the annotation as a tag/label in your monitoring tool. Dashboard shows what versions are deployed to which environments.",
              "score": 1,
              "created_utc": "2026-02-10 13:15:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4meoq2",
                  "author": "Consistent_Serve9",
                  "text": "Oh, it is possible, but we do not do it at the moment.  \nI like the idea of adding the hash as a label to the pod in kubernetes. It could be retrieved from the image and added to the deployment. Plus, since we promote in GitHub Actions, we could retrieve the label from the image, and then, tag the commit in the workflow. Good idea!",
                  "score": 1,
                  "created_utc": "2026-02-10 14:46:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4h0nil",
          "author": "pudds",
          "text": "In a nutshell, here's how I've done it multiple times for companies with multiple environments:\n\n1) Every commit to main creates a versioned tag and builds / stores versioned artifacts for that commit.\n\n2) Deployments are done by changing the version of the artifacts in that environment. We use a git repo for this but there are other ways.\n\n3) If we need to hotfix we start by creating a hotfix branch from the tag that's being patched, then adding commits to that hotfix branch.  Once done, we cherry-pick the patches back to main if applicable.\n\nThe goal is to ensure that what we test in everyone environment is also what we promote; we never build again to promote.  If a version fails testing, it just never goes beyond that environment. We could remove those artifacts but we generally don't.",
          "score": 1,
          "created_utc": "2026-02-09 18:10:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h3ew7",
          "author": "DoctorPrisme",
          "text": "A bit new to terminology and stuff but isn't this the gitops idea ? Like your config files are in the repo, you push the code changes and the pipeline build for the various environment with the applicable config file, so what's deployed in UAT targets the UAT database and firewall and other networks, and what goes in prod had the Prod database etc ?",
          "score": 1,
          "created_utc": "2026-02-09 18:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hcdg5",
          "author": "ahal",
          "text": "High level, don't tie release promotion to VCS branches. Have some external to VCS process to manage releases.\n\nGit tags can work, but only for simple cases.",
          "score": 1,
          "created_utc": "2026-02-09 19:05:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hjlur",
          "author": "Left_Brush9669",
          "text": "I guess your logic is right, but to do TBD properly you need feature flags.",
          "score": 1,
          "created_utc": "2026-02-09 19:39:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4hqrxi",
          "author": "Recent_Solid_9807",
          "text": "Start with a build pipeline prior to dev that builds the container image and give it some unique name. Push it to a container registry in aws/azure or store it wherever. Then your deployment pipeline dev->prod is just pulling that image from the registry and deploying it to a resource that accepts container images. I.e container apps in azure.",
          "score": 1,
          "created_utc": "2026-02-09 20:16:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i5mtc",
          "author": "BoBoBearDev",
          "text": "Publish you binary or package to the repo. And have separate repo to pull the package and build the image.",
          "score": 1,
          "created_utc": "2026-02-09 21:29:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jsxr6",
          "author": "epidco",
          "text": "u should def stick with tbd. branch per environment is a massive headache once u scale past like 2 devs lol. i once worked on a setup where we rebuilt for every env and a slight diff in the build runner dependencies broke prod while dev was fine. absolute nightmare to debug tbh. just tag the image with the git sha and promote that exact artifact. keeps it simple and u know 100% what ur shipping is what u actually tested in uat",
          "score": 1,
          "created_utc": "2026-02-10 02:57:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jynvl",
          "author": "AvailableBaby8452",
          "text": "> ‚ó¶\tBuilds an image like app:<git-sha>\n\nDon‚Äôt do this. Tag the docker image or ‚Äúhas this code changed‚Äù logic to be the SHA256 sum of all the directories and one off files (Directory.build.props and global.json I am looking at you). Then tag based off that dir hash. I encourage you not to hash the whole repo - only hash files that deploy with your product. For example, .gitignore and tests rarely affect the product, so exclude those from the dirhash logic.\n\nThis provides a deterministic way to say ‚Äúhas this code been built before, and if so fetch that version.‚Äù We did this all the time at Blackboard and it worked quite well for a lot of different code repositories.\n\nThis also survives rebases and cherry picks since you‚Äôre no longer depending on the git SHA.\n\nFor python we use Dirhash, I believe bash and other languages have very similar libraries.",
          "score": 1,
          "created_utc": "2026-02-10 03:32:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p9gj0",
          "author": "aedom-san",
          "text": "Master should work on any environment, if master is broken, fix master\n\nPropagate that idea as the core principle\n\nGit should have no clue what an environment is",
          "score": 1,
          "created_utc": "2026-02-10 22:49:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5h7fhw",
          "author": "Otherwise-Pass9556",
          "text": "You‚Äôre thinking about it the right way. ‚ÄúBuild once, promote everywhere‚Äù is the cleanest model from a traceability standpoint. The bigger challenge I‚Äôve seen isn‚Äôt artifact reuse but keeping build and validation cycles fast as the pipeline grows. Even with trunk-based flows, if builds are heavy, feedback loops slow down quickly. Some teams optimize that layer using distributed build acceleration like Incredibuild so they‚Äôre not burning time every time main gets pushed. Makes the build-once strategy much more practical at scale.",
          "score": 1,
          "created_utc": "2026-02-15 08:28:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4famao",
          "author": "Eascen",
          "text": "Use trunk based development with gitflow. Our dev happens in release/version which is deployed to development. We merge to master for releases which build the image that goes to uat/prod.",
          "score": 1,
          "created_utc": "2026-02-09 12:47:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4gd71o",
              "author": "mirrax",
              "text": "Trunk based and gitflow are competing flows...",
              "score": 8,
              "created_utc": "2026-02-09 16:18:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4h7is6",
                  "author": "Johnman9797",
                  "text": "We do the same but I am thinking of avoiding the image rebuilding and just retagging and pushing\nAll tests amd scans run in feature branches and develop branch. \nmaster just promotes and deploys",
                  "score": 0,
                  "created_utc": "2026-02-09 18:42:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ga2qx",
          "author": "TonyBlairsDildo",
          "text": ">If teams use multiple branches (dev, uat, prod), how do you realistically:\n\n>‚Ä¢\tReuse the same image across environments?\n\n>‚Ä¢\tAvoid rebuilding the same code multiple times?\n\nYou follow git-flow, where you create a feature-branch from main, merge the feature into dev, merge the same feature branch into uat and then merge the branch lastly back into main.\n\n\nEach branch (dev, uat, main) represents the state of each deployment environment and will eventually converge to be the same.",
          "score": 1,
          "created_utc": "2026-02-09 16:04:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lx1s7",
              "author": "carsncode",
              "text": ">You follow git-flow\n\nYikes. Friends don't let friends use git-flow.\n\n>Each branch (dev, uat, main) represents the state of each deployment environment\n\nHow is that compatible with artifact promotion?",
              "score": 1,
              "created_utc": "2026-02-10 13:09:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4na8pu",
                  "author": "TonyBlairsDildo",
                  "text": "How do you mean?",
                  "score": 1,
                  "created_utc": "2026-02-10 17:16:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4fvkkb",
          "author": "engineered_academic",
          "text": "This is trivial to do on Buildkite.",
          "score": 1,
          "created_utc": "2026-02-09 14:51:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4fswxv",
          "author": "creamersrealm",
          "text": "We do trunk based dev at work with dev on main and tags to go to stg and above. I'm personally not a fan of cutting a tag to promote to a higher environment as you should promote your artifact upwards and the tags need conventional commits to align properly.",
          "score": 0,
          "created_utc": "2026-02-09 14:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4gsj2o",
          "author": "94358io4897453867345",
          "text": "Yeah that's like SDLC 101",
          "score": 0,
          "created_utc": "2026-02-09 17:31:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i4v1m",
          "author": "EngineOld8447",
          "text": "CI test failures are brutal because they block everyone. Things that helped us:  \n  \n1. \\*\\*Separate fast/slow suites\\*\\* ‚Äî unit tests gate PRs, E2E tests run post-merge  \n2. \\*\\*Retry logic\\*\\* ‚Äî flaky tests get 2 retries before failing the build  \n3. \\*\\*Parallel execution\\*\\* ‚Äî went from 45min to 8min by parallelizing across containers  \n4. \\*\\*Failure screenshots\\*\\* ‚Äî auto-capture on every failure. Debugging blind is the worst.  \n  \nAlso: make sure your CI environment matches production (same browser versions, viewport sizes, etc). Environment drift causes most CI-only failures. What CI are you using?",
          "score": -1,
          "created_utc": "2026-02-09 21:25:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzz0bc",
      "title": "how many code quality tools is too many? we‚Äôre running 7 and i‚Äôm losing it",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1qzz0bc/how_many_code_quality_tools_is_too_many_were/",
      "author": "Peace_Seeker_1319",
      "created_utc": "2026-02-09 08:38:32",
      "score": 34,
      "num_comments": 44,
      "upvote_ratio": 0.87,
      "text": "genuine question because i feel like i‚Äôm going insane. right now our stack has:\n\nsonarqube for quality gates, eslint for linting, prettier for formatting\n\nsemgrep for security, dependabot for deps, snyk for vulnerabilities, and github checks yelling at us for random stuff, on paper, this sounds ‚Äúmature engineering‚Äù. in reality, everyone knows it‚Äôs just‚Ä¶ noise. same PR, same file, 4 tools commenting on the same thing in slightly different ways. devs mute alerts. reviews get slower. half the time we‚Äôre fixing tools instead of code.\n\ni get why each tool exists. but at some point it stops improving quality and starts killing velocity.\n\nis there any tools that covers all the thing that above tools give???\n\ni found this writeup from codeant on ‚Äú[sonarqube alternatives](https://www.codeant.ai/blogs/best-sonarqube-alternatives) / consolidating code quality checks‚Äù that basically argues the same thing: fewer tools + clearer gates beats 7 overlapping bots. if anyone has tried consolidating into 1-2 platforms (or used CodeAnt specifically), what did you keep vs remove?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1qzz0bc/how_many_code_quality_tools_is_too_many_were/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4ek46h",
          "author": "gkdante",
          "text": "If you have noticed that your tools are giving you the same results, why ask for a new tool instead of figuring out which one you can remove?\nYou have the data, I think you are in the best position to figure it out.\n\nCould you share some of the overlaps you have found?",
          "score": 22,
          "created_utc": "2026-02-09 08:51:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3cgg",
              "author": "Peace_Seeker_1319",
              "text": "Fair point. The challenge is it‚Äôs not just duplicate rules, it‚Äôs duplicate ownership and fragmented gates. Each tool has a different severity model, different config surface, and different place where feedback shows up. Even when two findings are ‚Äúthe same,‚Äù the workflow impact is different.\n\nThe overlaps we‚Äôre seeing are mostly around lint style, basic bug patterns, and common security checks, where multiple systems flag the same class of issue. The goal isn‚Äôt ‚Äúadd one more bot,‚Äù it‚Äôs to reduce sources of truth so developers get fewer, higher-confidence signals.",
              "score": 1,
              "created_utc": "2026-02-12 07:53:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eojs8",
          "author": "totheendandbackagain",
          "text": "Grouping them together as \"quality tools\" is missing the point of each one, they do completely different things.\n\nIt's like asking why we sent so many athletes to the Olympics when they are all competing for a medal, we should just send one.",
          "score": 38,
          "created_utc": "2026-02-09 09:36:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3dks",
              "author": "Peace_Seeker_1319",
              "text": "I get the analogy, but the issue isn‚Äôt that they exist for different reasons. It‚Äôs that they all surface feedback in the same place, at the same time, with overlapping authority.\n\nWhen seven tools block the same PR with different signals and severities, developers don‚Äôt experience them as ‚Äúspecialized athletes.‚Äù They experience them as noise competing for attention. Specialization only helps if there‚Äôs a clear contract for what each tool owns and which ones actually gate merges. Otherwise the signal collapses, even if the tools are technically distinct.",
              "score": 0,
              "created_utc": "2026-02-12 07:53:47",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4en44g",
          "author": "BuffaloJealous2958",
          "text": "You don‚Äôt need one tool that does everything, you need one clear owner per concern and silence everywhere else. Pick one formatter, one linter, one quality gate and one dependency/security signal. Kill or quiet anything that duplicates feedback.",
          "score": 9,
          "created_utc": "2026-02-09 09:21:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3esi",
              "author": "Peace_Seeker_1319",
              "text": "Exactly. Consolidation is really about reducing sources of truth.\n\nIf each concern has a single gate and everything else becomes informational, teams stop arguing with bots and start fixing real issues. The win is clarity, not a magic platform.",
              "score": 1,
              "created_utc": "2026-02-12 07:54:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ejviz",
          "author": "astron190411",
          "text": "if you have dependabot, idk why not just go for GHAS overall instead of SNYK?",
          "score": 3,
          "created_utc": "2026-02-09 08:49:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f2j9l",
              "author": "PelicanPop",
              "text": "if it's anything like the place I've worked, higher ups will get sold on Snyk for a muti-year license deal and everyone else is forced to use it. Even though dependabot probably got included in their github enterprise plan. \n\nI wouldn't be surprised if it came from up top who don't have a firm grasp on what's happening beneath them",
              "score": 3,
              "created_utc": "2026-02-09 11:46:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4y3i65",
                  "author": "Peace_Seeker_1319",
                  "text": "That‚Äôs usually how these stacks grow. Tooling decisions get made at a procurement or leadership level, then teams inherit overlapping systems without a chance to rationalize them. Once contracts are signed, the path of least resistance is to keep everything running, even if half the signals are redundant.\n\nThat‚Äôs why this problem rarely gets fixed bottom up. It needs someone to step back, look at actual usage and impact, and decide what truly needs to block work versus what can just inform.",
                  "score": 2,
                  "created_utc": "2026-02-12 07:55:00",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4y3gh0",
              "author": "Peace_Seeker_1319",
              "text": "Dependabot covers update automation, but it doesn‚Äôt replace full vulnerability management or code scanning by itself. GHAS can unify a lot if you are already deep in GitHub and want one place for alerts and policies. Snyk can still make sense if you need broader ecosystem coverage, dev-friendly fixes, or you run outside GitHub heavily.\n\nThe key is picking one primary security signal and wiring everything else to support it, not compete with it.",
              "score": 1,
              "created_utc": "2026-02-12 07:54:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eri3p",
          "author": "TyrusX",
          "text": "13",
          "score": 4,
          "created_utc": "2026-02-09 10:05:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4hkhku",
              "author": "hblok",
              "text": "https://xkcd.com/927/",
              "score": 2,
              "created_utc": "2026-02-09 19:44:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eki40",
          "author": "oscarandjo",
          "text": "I would say that the quantity doesn‚Äôt matter so much, so long as they do either of these:\n1. Help prevent issues that could impact production or software delivery from being  merged\n2. Enforce a consistent style so you don‚Äôt waste time arguing about whitespace etc with colleagues\n\n\nI would take a critical look at the failures you experience. Do the checks help achieve either one of those goals? If not, consider adjusting the settings. Some rules I just find to be pedantic and not helpful, so bring this up with your team and tweak it. \n\nSome checks, like autoformatters, I have run automatically as a pre-commit hook. That approach only works if the tool is very fast though (I use ruff which can lint and format my entire python repo in 2 seconds). This has helped me with the annoying feedback loop of committing, waiting 5 minutes, everything is green except the formatter, then needing to wait for everything again. \n\nYou mentioned having Snyk as a CI check, which stood out to me. Does this only check new dependencies you added in that PR, or check for vulnerabilities in existing packages? I could imagine a frustrating situation where some CVE comes out on an existing package, and then you can‚Äôt merge an emergency fix for a prod issue because you now need to also update the dependencies.\n\nPersonally I prefer using Snyk asynchronously. I set up a GitHub Actions cron to run ‚ÄúSnyk monitor‚Äù on the repo every night at 2am. We get weekly emails from Snyk with updates about any new vulnerabilities.",
          "score": 3,
          "created_utc": "2026-02-09 08:55:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3k03",
              "author": "Peace_Seeker_1319",
              "text": "This is the right framing. A check should either block real risk or remove subjective debate. Anything else should be optional or removed. Good call on moving fast, deterministic tools into pre-commit so CI is not a slow style cop. That one change alone cuts a ton of wasted cycles. And yes, security gates can become a self-inflicted outage if they block unrelated hotfixes. The healthier setup is to gate on what the change introduces, and handle baseline issues on a separate cadence with clear ownership and a remediation SLA. Running it on a schedule instead of on every PR can be a better tradeoff for many teams.",
              "score": 2,
              "created_utc": "2026-02-12 07:55:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4eldxx",
          "author": "vekien",
          "text": "We run about 20‚Ä¶ all the ones you listed and more, it‚Äôs a nightmare but they only run at certain steps, not on every commit for example so it doesn‚Äôt affect velocity, and devs have a lot of these in IDE and githooks. The hassle has mostly been just managing them all.",
          "score": 2,
          "created_utc": "2026-02-09 09:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3lu7",
              "author": "Peace_Seeker_1319",
              "text": "That setup can work, but it only holds as long as the signals stay clearly separated.\n\nOnce developers can‚Äôt tell which checks matter now versus later, everything starts getting mentally deprioritized, even if velocity looks fine on paper. The pain usually shows up in maintenance, onboarding, and alert fatigue rather than CI time.\n\nManaging tools becomes a parallel system of work, and at some point that overhead starts competing with actual engineering unless ownership and escalation paths are very explicit.",
              "score": 1,
              "created_utc": "2026-02-12 07:55:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4y9jw8",
                  "author": "vekien",
                  "text": "Yea I get that, at my workplace every alert aside from a few CVEs (that won‚Äôt be fixed) are priority and have to pass, so it‚Äôs not a case of checks that matter now vs later, they‚Äôre all ‚Äúnow‚Äù. It‚Äôs built into the workload and sprints, dedicated time was spent years ago before I started ensuring we didn‚Äôt have a legacy trap and it‚Äôs paid off as it means now velocity is unaffected. Due to the nature of the industry we don‚Äôt do rapid releases, it has to be scheduled, audited, clients have to be notified etc.",
                  "score": 1,
                  "created_utc": "2026-02-12 08:54:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4empxy",
          "author": "oweiler",
          "text": "Renovate + Formatter (+ Linter). That's the sweet spot IMHO. Honestly with a good team you can skip the linter entirely. Ppl forget that everything has a cost, and increases build times / the feedback loop.",
          "score": 2,
          "created_utc": "2026-02-09 09:17:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3nqi",
              "author": "Peace_Seeker_1319",
              "text": "That‚Äôs a reasonable baseline. Formatter plus dependency automation removes most low-value churn. Past that, every extra gate needs to justify itself with prevented incidents or saved review time. I wouldn‚Äôt skip linting entirely unless you have strong tests and disciplined reviews, but I do agree it should be lightweight, fast, and focused on high-signal issues. The moment it slows the feedback loop or nitpicks style, it becomes counterproductive.",
              "score": 2,
              "created_utc": "2026-02-12 07:56:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4y6rqb",
                  "author": "oweiler",
                  "text": "Yes, skipping the linter completely is probably too much. But I've seen devs spending more time fixing lint violations than shipping code.",
                  "score": 1,
                  "created_utc": "2026-02-12 08:26:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4erx7j",
          "author": "ultrathink-art",
          "text": "Seven is probably too many unless each has a distinct purpose. The real question: are you acting on the findings, or just collecting reports? I've seen teams run 10+ tools but ignore 90% of the output. Better approach: pick 2-3 high-signal tools that block CI on critical issues, then maybe 1-2 advisory scanners you review weekly. More tools = more noise = alert fatigue = everything gets ignored. Focus on what actually prevents bugs in production.",
          "score": 2,
          "created_utc": "2026-02-09 10:09:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3pl3",
              "author": "Peace_Seeker_1319",
              "text": "Tool count is irrelevant if nobody trusts the output. If 90% gets ignored, the system is broken by definition. It trains everyone to treat warnings as background noise, and the one real issue that matters gets skipped in the scroll. The only setup that works long term is high-signal gates that actually block, plus everything else moved to a scheduled cadence with clear ownership. If a tool cannot prove it prevents incidents or saves review time, it‚Äôs not ‚Äúmature engineering,‚Äù it‚Äôs just busywork with dashboards. The goal is fewer, sharper signals that developers respect, not more bots competing to be muted.",
              "score": 1,
              "created_utc": "2026-02-12 07:56:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4embiw",
          "author": "Vaibhav_codes",
          "text": "Seven tools is way too many if alerts are ignored Focus on one opinionated source (like SonarQube or Semgrep) and prune overlaps less noise, more actual quality",
          "score": 1,
          "created_utc": "2026-02-09 09:13:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eoj5i",
          "author": "kubrador",
          "text": "you're running a devops equivalent of having 7 people yell at you about the same typo. the dream all-in-one tool doesn't exist because vendors discovered they make more money keeping you buying separate things.\n\n\n\nrealistically: pick sonarqube (gates + quality), semgrep (security), dependabot (deps), delete the rest. prettier is fine if you actually care about formatting. github checks are free noise, turn most of them off. fewer alerts = alerts people actually read.",
          "score": 1,
          "created_utc": "2026-02-09 09:36:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ep7gu",
          "author": "Top_Section_888",
          "text": "Can you adjust the settings for these tools to reduce the amount of overlap?  And/or configure your pipeline to abort if eslint fails?  IME most commits with build errors (e.g. incorrect syntax from a bad merge) are going to fail eslint and then fail every other check anyway.",
          "score": 1,
          "created_utc": "2026-02-09 09:42:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ey7ee",
          "author": "protestor",
          "text": "Apart from those tools, you have your own CI, right? eslint should be running on your tests and on CI. Indeed it should never fail on CI, its errors should be catched before you commit locally (maybe with a pre-commit hook)\n\nIf there's anything from eslint you consider noise, you should disable the offending lints explicitly. Your goal is to always have exactly 0 warnings, so that any specific warning means something went wrong, rather than having so many warnings that it all becomes meaningless and ignored. Doing otherwise wastes everybody's time\n\nSemgrep and skyk seems to be doing the same thing? Here's what Semgrep itself thinks (so, a biased account) https://semgrep.dev/resources/semgrep-vs-snyk/ - I like that semgrep is open source so you could be running it yourself too\n\nIndeed you could probably run most things on CI, and thus reduce the spam on Github PR comments\n\nIf a tool is unreliable, ditch it or run it optionally on the dev machine (not for every PR). It's better to not raise a warning than raising false alarms, because false alarms make people ignore the tools",
          "score": 1,
          "created_utc": "2026-02-09 11:08:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3uf5",
              "author": "Peace_Seeker_1319",
              "text": "Hard agree on the zero-noise principle. If warnings are allowed to pile up, the tooling becomes decor and nobody pays attention when something truly breaks.\n\nBut ‚Äúnever fail on CI‚Äù only works if developers get the feedback before CI. Pre-commit hooks and fast local runs are the difference between guardrails and frustration. Otherwise you just move the pain later in the pipeline.\n\nAlso, Semgrep and Snyk can overlap, but the bigger problem is having two tools compete for the same lane. Pick one primary security signal, tune it until it‚Äôs trusted, and route everything else into a single place on a schedule. PR comments should be reserved for high-confidence, action-now findings. If it‚Äôs noisy or flaky, it should not be in the critical path.",
              "score": 1,
              "created_utc": "2026-02-12 07:58:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4h1h6d",
          "author": "o5mfiHTNsH748KVq",
          "text": "Why do they kill velocity? Lints can be cleaned with AI pretty easily and reliably.",
          "score": 1,
          "created_utc": "2026-02-09 18:14:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4h5tqn",
          "author": "rosstafarien",
          "text": "I like linters and formatters that have IDE integration. Show me the issue while I'm editing the file, not when I'm trying to merge.",
          "score": 1,
          "created_utc": "2026-02-09 18:34:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iogvv",
          "author": "brophylicious",
          "text": "If they are producing noise, then you need to tune them or fix the issues they bring up. Start incorporating some of this work into your schedule otherwise nothing will happen.",
          "score": 1,
          "created_utc": "2026-02-09 23:05:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j9zyu",
          "author": "johntellsall",
          "text": "The point of CI is to give 1) rapid, 2) actionable feedback, to 3) developers.\n\nIn practice I run *more* than one version of each tool, because I have different speed / quality / scope tradeoffs.\n\n## Example: multiple Linters\n\nGenerally I just want to find showstopper (F=Fatal) issues with files that I've changed recently:\n\n> ruff check --select F $(git whatchanged --name-only main)\n\n(I'm typing from memory but you get the idea)\n\nThe above is VERY fast and skips the other 1,000 files in the repos.\n\nIf the above is okay and I'm getting close to publishing my PR:\n\n> ruff check $(git whatchanged --name-only main)\n\nSmaller-scale issues will be brought up here. Not as fast but better quality.\n\nAlso:\n\n> uvx pylint -E\n\nThis uses a completely different linter, because it catches some odd edge cases that `ruff` skips.\n\n## Bottom line: keep each tool valuable!\n\nSeven is just fine, *if* your team is using each to give _unique_ fast, specific actionable feedback.",
          "score": 1,
          "created_utc": "2026-02-10 01:06:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3yzq",
              "author": "Peace_Seeker_1319",
              "text": "This is the sane way to do ‚Äúmany tools‚Äù without drowning.\n\nThe mistake isn‚Äôt seven, it‚Äôs seven tools all screaming in the same place with the same priority. Your setup works because you separated feedback by speed and scope, and you‚Äôre intentionally layering coverage.\n\nMost teams do the opposite. They run everything on everything, block on noise, and then wonder why developers mute it all.\n\nSo I agree with the principle: keep each check unique, fast, and clearly owned. If you cannot explain what a tool catches that nothing else does, and when it runs, it‚Äôs probably not earning its slot.",
              "score": 1,
              "created_utc": "2026-02-12 07:59:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ksee7",
          "author": "N7Valor",
          "text": "Jack of all trades, master of none.  I prefer it when multiple companies whole-ass a single tool well rather than half-ass 7 tools into 1 and they all suck.",
          "score": 1,
          "created_utc": "2026-02-10 07:18:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kzp0h",
          "author": "BoBoBearDev",
          "text": "I don't see the problem since those issues should be fixed quickly in a PR.\n\n\nThe time I see this as an issues is the strongly opinionated people who demands \"quality commits\", so each time to commit the change is painful.\n\n\nIf you can freely commit anything quickly and freely, you can fix those issues quickly. 50 issues and you make 70 commits to fix it? No problem. Thus, none issue.\n\n\nWhat's \"quality commits\"? Those people refused to squash merge, each commit must be carefully crafted to group related code into one. They are going to click on each individual commit during PR or browsing the repo. Thus, having 100 commits is not practical to them. You must consolidate all the 50 linter fixes, 70 SonarQube fixes, etc, otherwise it is too much reviewing on the git timeline. This \"quality commits\" IMO is exhausting and unnecessary. Don't do it.",
          "score": 1,
          "created_utc": "2026-02-10 08:27:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y42xg",
              "author": "Peace_Seeker_1319",
              "text": "‚ÄúJust fix it in the PR‚Äù assumes the feedback is clean and unified. In reality, overlapping bots create scattered tasks and constant context switching, so the time cost is not the fixes, it‚Äôs the triage. On the commit purity point, I‚Äôm with you. If someone cares more about artisanal commits than outcomes, they‚Äôre turning review into theater. Squash at merge, keep iteration messy, and stop using git history as a second performance metric.",
              "score": 2,
              "created_utc": "2026-02-12 08:00:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4y6bgr",
                  "author": "BoBoBearDev",
                  "text": "I honestly haven't get to that bad yet. So far. Just linter, SonarQube, fortify, and one more scanner bitching about 3rd party node package version.",
                  "score": 1,
                  "created_utc": "2026-02-12 08:22:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4msvzp",
          "author": "dmikalova-mwp",
          "text": "Why not have eslint and prettier automatically push a fix? Things like dependabot can be weekly against the repo, not the PR. Find ways to automate the rest, or ask if they're really bringing value.¬† The tools should be helping, not friction. For example I had a long time ago that like half of changes to Google's code was machine generated because if a method was changed the developer didn't have to update every caller - that part was automated.",
          "score": 1,
          "created_utc": "2026-02-10 15:56:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y44e6",
              "author": "Peace_Seeker_1319",
              "text": "Auto-fix is the right direction, but only if it stays predictable.\n\nThe goal is fewer human cycles spent on mechanical cleanup. Formatters should never be a discussion. Linters should either auto-correct or be so high-signal that a failure means something real.\n\nAnd yes, dependency alerts do not need to hijack every PR. Run them on a schedule, batch the work, and treat it like maintenance with ownership. If a tool cannot either prevent real incidents or save review time, it‚Äôs not ‚Äúquality,‚Äù it‚Äôs tax.",
              "score": 1,
              "created_utc": "2026-02-12 08:00:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ekheq",
          "author": "SuperQue",
          "text": "We mostly just run `golangci-lint` and it's great.",
          "score": 1,
          "created_utc": "2026-02-09 08:55:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4y3sdc",
              "author": "Peace_Seeker_1319",
              "text": "That makes sense. When one tool is well configured and trusted, it carries a lot of weight. golangci-lint works because it aggregates checks, runs fast, and lets you be explicit about what matters. That‚Äôs usually better than stacking multiple tools that all shout at the same time.",
              "score": 0,
              "created_utc": "2026-02-12 07:57:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4em3gk",
          "author": "mrgrumpy82",
          "text": "Code quality tools to validate the quality of the code quality tools?\n\nIt‚Äôs turtles all the way down!",
          "score": 1,
          "created_utc": "2026-02-09 09:11:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4grlna",
          "author": "bilingual-german",
          "text": "The problem is running all of these in sequence for all commits.\n\nRun them once a week, fix what pops up.",
          "score": 1,
          "created_utc": "2026-02-09 17:27:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ejyw2",
          "author": "spicypixel",
          "text": "None currently.",
          "score": -1,
          "created_utc": "2026-02-09 08:50:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f200u",
              "author": "spicypixel",
              "text": "I appreciate the downvotes for being honest that we don't run any in CI.",
              "score": 1,
              "created_utc": "2026-02-09 11:42:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r5nh8z",
      "title": "Can the CKA replace real k8s experience in job hunting?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r5nh8z/can_the_cka_replace_real_k8s_experience_in_job/",
      "author": "blasian21",
      "created_utc": "2026-02-15 19:25:15",
      "score": 30,
      "num_comments": 33,
      "upvote_ratio": 0.82,
      "text": "Senior DevOps engineer here, at a biotech company. My specific team supports more on the left side of the SDLC, helping developers create and improve build pipelines, integrating cloud resources into that process like S3, EC2, and creating self-help jobs on Jenkins/GitHub actions.\n\nTLDR, I need to find another job. However, most DevOps jobs ive seen require k8s at scale- focusing on reliability/observability. I have worked with Kubernetes lightly, inspecting pod failures etc, but nothing that would allow me to deploy and maintain a kubernetes cluster. Because of this, I'm in the process of obtaining the CKA to address those gaps.\n\nTo hiring managers out there: Would you hire someone or accept the CKA as a replacement for X years of real Kubernetes experience?\n\nFor those of you who obtained the CKA for this reason, did it help you in your job search?",
      "is_original_content": false,
      "link_flair_text": "Career / learning",
      "permalink": "https://reddit.com/r/devops/comments/1r5nh8z/can_the_cka_replace_real_k8s_experience_in_job/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o5k3y8a",
          "author": "courage_the_dog",
          "text": "It's better than nothing, but no  cert could ever replace actual experience.",
          "score": 59,
          "created_utc": "2026-02-15 19:28:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k7azo",
              "author": "blasian21",
              "text": "Understood, just trying to figure out the best path forward in the short term.",
              "score": 4,
              "created_utc": "2026-02-15 19:45:40",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ka0ru",
                  "author": "---why-so-serious---",
                  "text": "In the short term, create a personal project using k8s, that is appropriately challenging. Now either integrate that project, either directly or from what you learned, into your resume; the point being that knowing what your talking about is  much more important than where and how that experience was garnered",
                  "score": 9,
                  "created_utc": "2026-02-15 19:59:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5kz1kz",
              "author": "--Tinman--",
              "text": "Aside from OP's request, glad to hear that. I moved from sysadmin to devops and had planned to do the CKA, just to abandon it when I got a job before testing.",
              "score": 1,
              "created_utc": "2026-02-15 22:08:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5kfutu",
          "author": "JaegerBane",
          "text": ">To hiring managers out there: Would you hire someone or accept the CKA as a replacement for X years of real Kubernetes experience?\n\nNot a hiring manager but do technical interviewing for my company's platform engineering recruitment efforts.\n\nFrankly, no. It's not just a k8s thing, it's a general rule of thumb that lacking any real experience is a downside regardless of what certs you have. You should really know that certs are not replacements for this - we all have our horror stories of people who had all the gear and no idea. I certainly wouldn't consider a senior engineer who'd never touched k8s for a platform engineering role. At that level people would be looking *to you* for direction and expertise. \n\nCerts are garnishes, not protein or carbs.",
          "score": 13,
          "created_utc": "2026-02-15 20:29:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5kzsh7",
              "author": "fumar",
              "text": "I probably would value it at 6-12 months experience. Unlike a lot of certs, CKA is hands on so you have to know how to actually do stuff.",
              "score": 4,
              "created_utc": "2026-02-15 22:12:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ks7bh",
              "author": "OMGItsCheezWTF",
              "text": "Yeah, I don't hire platform people, I hire developers. But someone with qualifications but no experience would never be considered for anything but an associate level position.",
              "score": 3,
              "created_utc": "2026-02-15 21:33:00",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5lmqcv",
              "author": "superspeck",
              "text": "Ok, so asking this from the other side of the coin. I haven‚Äôt worked for a company that needed k8s scale. Been doing docker for a decade, was in a nomad shop for a few years and then ECS the last five. We were only pushing a few terabytes a day and 100k concurrent users. No big deal, not hyperscale. \n\nHow WOULD you advise a senior engineer to get kubernetes production experience in this day and age? Or is this another case of the ‚Äúyou‚Äôre over 35, gtfo and go die‚Äù that our industry is known for?",
              "score": 3,
              "created_utc": "2026-02-16 00:23:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ler82",
              "author": "ReputesZero",
              "text": "All hat, no cattle.",
              "score": 1,
              "created_utc": "2026-02-15 23:35:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5k3vfl",
          "author": "KubeGuyDe",
          "text": "No",
          "score": 17,
          "created_utc": "2026-02-15 19:28:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5k83tx",
              "author": "Farrishnakov",
              "text": "Or in Spanish... \n\nNo",
              "score": 4,
              "created_utc": "2026-02-15 19:49:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5kel5k",
          "author": "Insomniac24x7",
          "text": "Lol i want to know where are these K8s jobs and with scenario based interviews everyone is talking about above?",
          "score": 2,
          "created_utc": "2026-02-15 20:23:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kmv4o",
          "author": "Petelah",
          "text": "No, but better than nothing.\n\nI‚Äôd say build a homelab and start with docker workloads and then migrate them successfully to kubernetes and write about that process on your resume.\n\nCKA/D isn‚Äôt everything. I use kubernetes daily at work and the exams are not close to what my job use is like.",
          "score": 2,
          "created_utc": "2026-02-15 21:05:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5krj0o",
          "author": "dgibbons0",
          "text": "Personally I'd take someone who is running a k8s home lab and can talk about the ecosystem and things they like over someone with a cka. A cka may be a tie breaker but that's about it.",
          "score": 2,
          "created_utc": "2026-02-15 21:29:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5m94w4",
              "author": "Sure_Stranger_6466",
              "text": "Hello it's me your [k8s homelab](https://github.com/elliotechne/bank-of-anthos/tree/main/aws) guy (even though it's more of a GitHub repo with GitHub Actions set up and terraform with crossplane).",
              "score": 1,
              "created_utc": "2026-02-16 02:44:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5m00uz",
          "author": "ansibleloop",
          "text": "In order of priority\n\n- Experience\n- Cert\n- Knows nothing",
          "score": 2,
          "created_utc": "2026-02-16 01:45:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5m0rez",
              "author": "blasian21",
              "text": "Appreciate that! I'm currently at 'knows nothing' and hoping to get up to 'cert' at the very least. ",
              "score": 1,
              "created_utc": "2026-02-16 01:50:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5m43zf",
                  "author": "ansibleloop",
                  "text": "If you're labbing, put it on GitHub and if it's good you can demo it in an interview\n\nI got a job a few years ago by showing them what I had running in my lab\n\nTurns out they wanted me to replicate my monitoring setup for them",
                  "score": 1,
                  "created_utc": "2026-02-16 02:11:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5kd3rn",
          "author": "un-hot",
          "text": "I run devops interviews for a big-ish k8s shop. We do a huge range of tasks so plenty of other work to pick up while you ramp up k8s though.\n\nI'd consider for jr-mid positions if you still ticked most other boxes and had other relevant experience, such as running containers at scale in cloud etc. But realistically if someone with k8s knowledge has applied they're probably more likely to get the interview.\n\nOur interview includes scenario based questions as well and I'd still expect you to answer them well though. I'd expect you to have a project which you could talk in depth about as well, I'd come to the interview prepared to ask about that.\n\nAt senior level it'd be a pass.",
          "score": 4,
          "created_utc": "2026-02-15 20:15:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5lnsmf",
              "author": "superspeck",
              "text": "> I'd consider for jr-mid positions if you still ticked most other boxes and had other relevant experience, such as running containers at scale in cloud etc.\n\nCould you please discuss this with your recruiting team? As a staff/senior trying to get k8s experience because there aren‚Äôt enough non-kubernetes jobs right now, I‚Äôm consistently rejected for mid level roles because they assume that I either am not able to accept the mid level pay rates or won‚Äôt stick around or something. \n\nBeen doing ECS for the last five, nomad before that, have a k8s bare metal home lab, have no idea how to get a job as a 39 year old in this environment.",
              "score": 1,
              "created_utc": "2026-02-16 00:29:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5k5mu0",
          "author": "chipperclocker",
          "text": "I have personally interviewed, and unfortunately had to reject, several candidates over the years who were in possession of a CKA, but could not perform even the most basic of tasks in a k8s cluster during a hands-on hiring lab.\n\nI can‚Äôt think of a single certification, CKA or otherwise, that is a genuine substitute for real world experience.",
          "score": 2,
          "created_utc": "2026-02-15 19:37:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5kczzw",
              "author": "HeteroLanaDelReyFan",
              "text": "What were they not able to do? It seems like the CKA tests real scenarios. It's not just multiple choice, so I am curious how they passed the exam without knowing basic kubernetes.",
              "score": 4,
              "created_utc": "2026-02-15 20:14:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5kf7t2",
                  "author": "chipperclocker",
                  "text": "An exercise in the lab would be something like ‚Äútake this OCI image we have prepared, get it running as ¬†a pod in the namespace we have given you access to, and when it crashes (because we‚Äôve engineered it to crash), use information you have access to in the cluster to offer a hypothesis about why it is crashing and what you might be able to do to fix it‚Äù\n\nI recall a candidate who was completely unable to access log data from the pod and declared the task to be impossible because we weren‚Äôt running a web-based dashboard that could be used to extract information from the cluster. No idea how they would‚Äôve been able to pass the exam.\n\nMy impression is there‚Äôs a lot of people out there who aren‚Äôt very independent at all, and mostly know how to operate as part of a committee in a large environment based on that specific organization‚Äôs tooling. They don‚Äôt understand the fundamentals, they just understand - maybe - usage of their employer‚Äôs own engineered solutions. Maybe fine for an F500 gig, but not gonna fly in our startup environment.",
                  "score": 6,
                  "created_utc": "2026-02-15 20:26:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5kft0q",
                  "author": "Appropriate-Fly-2203",
                  "text": "This. I just passed CKA and I wonder how are they not able to perform basic tasks:)).\nMaybe they forgot because they had a pause and didn‚Äôt touch k8s? \nAlso don‚Äôt confuse it with CKAD, i didn‚Äôt know much about CronJob until recently, because is part of CKAD training program.\nLuckily for me I manage 3 k8s env at work as a developer role, at the top of it staying the cluster admins which control nodes, persistent volumes.. etc.\nI can‚Äôt kubectl get nodes, kubectl get persistentvolumes due to restrictive permission. \nSo CKAD is a fit for what I do on the daily basis, but i‚Äôve started with CKA as it‚Äôs harder",
                  "score": 1,
                  "created_utc": "2026-02-15 20:29:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5khhd2",
                  "author": "rmullig2",
                  "text": "This is what happens with people who get certified but have no real world experience. They grind on the material until they get the certification then stop using it completely. Then when they need the knowledge it's already gone.",
                  "score": 1,
                  "created_utc": "2026-02-15 20:38:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5k51tg",
          "author": "GuiltyGuy7",
          "text": "I'm not a hiring manager, but someone with real experience having managed 60 k8s clusters on the cloud and another 60 on-prem, I've set them up from scratch, deployed applications, tested and then migrated. I've mostly seen it all. Except creating and deploying CRDs.\n\nI've done all of this without a CKA certificate, CKA mostly tells you how to use kubernetes on the surface level.\n\nComing to the hiring part, I've taken dozens of interviews, never really bothered or cared to check if the person has any certification on them, it may help with getting shortlisted, but hands-on experience is a must and is what gets tested.",
          "score": 1,
          "created_utc": "2026-02-15 19:34:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kl1w5",
          "author": "Big-Minimum6368",
          "text": "Certifications never equal experience. I'll take the guy with 2 years of experience and no cert over a cert and 0 years.\n\nBut you have to start somewhere, do some home labs and see what kind of experience you can get off that. I like someone willing to get their hands on the tools.",
          "score": 1,
          "created_utc": "2026-02-15 20:56:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kxgsg",
          "author": "SDplinker",
          "text": "Nope",
          "score": 1,
          "created_utc": "2026-02-15 21:59:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5lggqz",
          "author": "FerryCliment",
          "text": "Certifications are meant to be the envelope of your experience.\n\nYou can have massive experience in K8s, but lack in some areas, such as Security, Observability, or rely on CSP Networking stack , to the point you are not fully aware of what goes behind K8s CNI.\n\nCKA, CKS, Prometheus or Elastic, tell the company that not only you are able to work as K8s, but you are also prepared to a certain degree in all areas of the product, not just a set of responsibilities around X tasks",
          "score": 1,
          "created_utc": "2026-02-15 23:46:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5li3o3",
          "author": "Beneficial-Mine7741",
          "text": "No.",
          "score": 1,
          "created_utc": "2026-02-15 23:56:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5losub",
          "author": "--404_USER_NOT_FOUND",
          "text": "It's good to get a base to know the synergy of the core components, but you won't learn anything about making your infra scalable.\n\nIt's a small advantage, but not a necessity",
          "score": 1,
          "created_utc": "2026-02-16 00:35:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5mb4ec",
          "author": "merlin318",
          "text": "At my current company I had a senior engineer - 3 AWS certifications, Terraform certification and CKA.\n\nOne day a principal engineer pulled me aside and asked me to work with them and help them out. I was like sure. \n\nThe senior engineer had lacked basic fundamental understanding of terraform, had no idea how to write an effing dockerfile. NOT EVEN A BASH SCRIPT. \n\nThey were let go soon after. Since then I've been very vary of anyone with too many certifications and don't use that as a barometer for knowledge.\n\nThe guy who hired the senior engineer is now a L8 ( Director/ VP ). I have no idea what was done during the interview rounds...",
          "score": 1,
          "created_utc": "2026-02-16 02:56:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2uddo",
      "title": "How do you debug production issues with distroless containers",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r2uddo/how_do_you_debug_production_issues_with/",
      "author": "Upper_Caterpillar_96",
      "created_utc": "2026-02-12 14:08:34",
      "score": 28,
      "num_comments": 31,
      "upvote_ratio": 0.92,
      "text": "Spent weeks researching distroless for our security posture. On paper its brilliant - smaller attack surface, fewer CVEs to track, compliance teams love it. In reality though, no package manager means rewriting every Dockerfile from scratch or maintaining dual images like some amateur hour setup.\n\nDid my homework and found countless teams hitting the same brick wall. Pipelines that worked fine suddenly break because you cant install debugging tools, cant troubleshoot in production, cant do basic system tasks without a shell.\n\nThe problem is security team wants minimal images with no vulnerabilities but dev team needs to actually ship features without spending half their time babysitting Docker builds. We tried multi-stage builds where you use Ubuntu or Alpine for the build stage then copy to distroless for runtime but now our CI/CD takes forever and we rebuild constantly when base images update.\n\nAlso nobody talks about what happens when you need to actually debug something in prod. You cant exec into a distroless container and poke around. You cant install tools. You basically have to maintain a whole separate debug image just to troubleshoot.\n\nHow are you all actually solving this without it becoming a full-time job? Whats the workflow for keeping familiar build tools (apt, apk, curl, whatever) while still shipping lean secure runtime images? Is there tooling that helps manage this mess or is everyone just accepting the pain?\n\nRunning on AWS ECS. Security keeps flagging CVEs in our Ubuntu-based images but switching to distroless feels like trading one problem for ten others.\n\n",
      "is_original_content": false,
      "link_flair_text": "Troubleshooting",
      "permalink": "https://reddit.com/r/devops/comments/1r2uddo/how_do_you_debug_production_issues_with/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4zs2mo",
          "author": "Paranemec",
          "text": "Have you heard of attaching ephemeral debugging containers to them?  \n[https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/](https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/)",
          "score": 45,
          "created_utc": "2026-02-12 15:20:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zfzrm",
          "author": "catlifeonmars",
          "text": "Distroless? I just use FROM scratch.\n\nThe real answer is you need the application to expose profiling/debug APIs and you access them over network I/O.\n\nFWIW, you could probably also do some tricks like attaching a volume with a busybox binary right before ECS exec so that there is a shell available.",
          "score": 17,
          "created_utc": "2026-02-12 14:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zk3v9",
          "author": "ellensen",
          "text": "You use an APM tool and send OpenTelemetry from the container to debug. Debugging inside the running app is an anti-pattern from the good old days on-prem where you logged in using ssh to debug.",
          "score": 48,
          "created_utc": "2026-02-12 14:40:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4zsq7f",
              "author": "m_adduci",
              "text": "This is the real answer.\n\nGet proper logging + metrics + traces and you don't need to access containers ever again",
              "score": 18,
              "created_utc": "2026-02-12 15:23:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o567unw",
                  "author": "Consistent_Serve9",
                  "text": "Plus, tons of services and librairies exist to manage that easily. We use Azure application insights at work, and there are tons of librairies for plenty of langages and frameworks. I haven't checked the console logs or wen'T into the container in years. ",
                  "score": 1,
                  "created_utc": "2026-02-13 14:51:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o54kl05",
              "author": "spartacle",
              "text": "Don‚Äôt tar onprem with this brush mate üòÖ. we‚Äôre entirely distroless containerised with apm, telemetry, and logging being the debugging path",
              "score": 4,
              "created_utc": "2026-02-13 07:27:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o502myd",
              "author": "schmurfy2",
              "text": "The theory is nice but sometimes you just have to.",
              "score": 15,
              "created_utc": "2026-02-12 16:10:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o503zw9",
                  "author": "ellensen",
                  "text": "Actually haven't needed it yet in 7 years, and now going more and more serverless and less containers so I think I have managed to pass through it without needing it ever. The feeling that you need to gain access to debug to a running application, is just a legacy mindset. I see it every time a new developer joins that doesn't have much cloud native experience.\n\nEDIT Down vote if you like, doesn't change that a proper APM tool will make such practice obsolete, also it's lived experience ,  not a theory.\n\nEDIT what would you do inside the container if you had access? I'm curious, the only time I know it could be helpful is when you have a memory leak only in the real environment. And even then a real APM has built in profiling and should be able to see the cause.",
                  "score": 15,
                  "created_utc": "2026-02-12 16:16:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o54liva",
              "author": "sofixa11",
              "text": "While obviously you should have that, there are many things which cannot be debugged that way. Most notably network (routing/dns/etc) or certificate issues. If you're getting a network error in your traces, you have to connect to the place where the app is running to see what it's seeing and debug why it's hitting the wrong LB certificate for instance.",
              "score": 1,
              "created_utc": "2026-02-13 07:36:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o58cj8h",
              "author": "TopSwagCode",
              "text": "Yup. Was here to say use open telemetry. You shouldn't attach to production servers.",
              "score": 1,
              "created_utc": "2026-02-13 21:03:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50gwpc",
          "author": "mazznac",
          "text": "I think this is the purpose of the kubectl debug command? Let's you spin up arbitary containers as a temporary part of a running pod",
          "score": 8,
          "created_utc": "2026-02-12 17:16:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50boz2",
          "author": "simonides_",
          "text": "No idea how it works in ECS but ````docker debug```` would be the answer if you have access to the machine that runs your service.",
          "score": 2,
          "created_utc": "2026-02-12 16:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o513tlp",
          "author": "0xba1a",
          "text": "The best approach to use distroless is keeping top notch auditing and telemetry and maintaing a debugging twin image. In a constantly evolving dynamic environment, it is hard to maintain.\n\nBuilding your application layer robust and making it less reactive for platform failures is the most practical approach. The problem of CVE is fixing it but letting the container to reboot with upgraded image. The development team will insist on your to keep a scheduled maintenance window. But you'll worry about running the container with a known vulnerability until the next scheduled maintenance window. So, if you insist on you dev team to build robust application that will not be affected with a reboot, you don't need to have planned maintenance. You can have a simple automatic script which will keep fixing all the CVEs as and when they appear.",
          "score": 2,
          "created_utc": "2026-02-12 19:03:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53swbs",
          "author": "IridescentKoala",
          "text": "You can kubectl debug, attach containers to a pod, launch debug images to the namespace, etc...",
          "score": 2,
          "created_utc": "2026-02-13 03:51:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57f9n9",
          "author": "ElectricalLevel512",
          "text": "well, I think the underlying assumption here is that security and dev teams have to trade off features for compliance. That is not true if you approach it with image intelligence. Minimus is not a magic fix but it can automatically highlight which files packages or dependencies your runtime actually needs versus what you are shipping blindly. Combine that with multi stage builds and automated scanning and you can actually get distroless like security without constantly rewriting Dockerfiles or maintaining a full separate debug image. It basically lets you focus on what matters debugging apps not the image layers.",
          "score": 2,
          "created_utc": "2026-02-13 18:19:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zipm1",
          "author": "kabrandon",
          "text": "Builds shouldn‚Äôt be significantly longer multi-stage. Sure you have to pull both base images but if that takes a long time then take a look at your CI runners.\n\nDebugging in production is done with ubuntu:latest as a k8s ephemeral debug container.",
          "score": 1,
          "created_utc": "2026-02-12 14:33:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58havs",
          "author": "neilcar",
          "text": "(Disclosure: I work for Minimus, a company in the distroless, low-CVE container image space)\n\nI work with a lot of orgs who are embracing distroless containers and this question comes up a lot.  I would say that, for the orgs I work with, both the answers here are the best answers:\n\n1. Ensure that you have usable telemetry that reduces your need to interactively troubleshoot.  \n\n2. Build out a pattern using \\`kubectl debug\\` and an image built with all the tools you might need to debug so that you're ready when a team can't figure it out from their telemetry.\n\nSaying that you should have such amazing telemetry that you never have to interactively debug is a great philosophical position; however, my sense is that most orgs will never justify the levels of overhead and storage that might be necessary to do that SO OVERWHELMINGLY that they'll never need to break glass and debug interactively.  Better to have the pattern available, not need it, and eventually deprecate it than to need it and not have it.\n\nThere's also, always:\n\n3. Just ram \\`bash\\` and other basic tools in your distroless image.\n\nI \\_don't\\_ advocate this but, sometimes, the politics of the situation are that getting teams to give up the ability to \\`kubectl exec\\` in is, sometimes, too big a reach to start with.  There's not much shame in agreeing to trade off some risk for much larger wins.",
          "score": 1,
          "created_utc": "2026-02-13 21:27:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ce6en",
          "author": "epidco",
          "text": "feel u on the ecs struggle. distroless is a bit of a nightmare when things actually break in prod and security is breathing down ur neck. tbh if ur builds r taking forever u might wanna look at how ur caching layers in ci/cd. multi-stage shouldn't be that slow if u do it right. for the debugging part, i mostly stopped exec-ing into containers years ago. i just pump everything into grafana and prometheus now. if i rly need to poke around i just spin up a sidecar with a shell or a temp debug task with the same env. its annoying but better than dealing with cves every week lol",
          "score": 1,
          "created_utc": "2026-02-14 14:29:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5102dh",
          "author": "TheLadDothCallMe",
          "text": "This is another ridiculous AI post. I am now even doubting the comments.",
          "score": -2,
          "created_utc": "2026-02-12 18:46:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51ssaj",
          "author": "Frequent_Balance_292",
          "text": "I was in your shoes. Maintaining Selenium tests felt like painting the Golden Gate Bridge by the time you finish, you need to start over.  \n  \nTwo things helped:  \n1. Page Object Model (immediate improvement)  \n2. Exploring AI-based test maintenance tools that use context-awareness to handle selector changes automatically  \n  \nThe second one was the game-changer. The concept of \"self-healing tests\" has matured a lot. Worth researching. What framework are you on?",
          "score": -2,
          "created_utc": "2026-02-12 21:03:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52l6mu",
          "author": "Petelah",
          "text": "Like others have said.\n\nMeaningfully logging in code, meaningful tests, proper APM.\n\nThis should be able to get you through everything.\n\nNo one should be debugging in production. Write better code, better tests and have good observability.",
          "score": -2,
          "created_utc": "2026-02-12 23:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51w74v",
          "author": "kolorcuk",
          "text": "Run docker cp and copy a tar archive with nix installation with all the tools to inside the container. Then exec a shell and use them.\n\nDoesn't have to be nix, but nix is fun here. Prepare one nix env and some scripts to startup,  and you can just rsync nix dir and run.",
          "score": -3,
          "created_utc": "2026-02-12 21:19:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2lrxl",
      "title": "Anyone here switch from Prometheus to Datadog or the other way around",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r2lrxl/anyone_here_switch_from_prometheus_to_datadog_or/",
      "author": "hallelujah-amen",
      "created_utc": "2026-02-12 06:06:54",
      "score": 27,
      "num_comments": 32,
      "upvote_ratio": 0.97,
      "text": "For those who running production systems, what actually pushed you to commit to Prometheus or Datadog?\n\nWas it cost, operational overhead, scaling pain, team workflow, something else?\n\nCurious about real experience from people who have lived with the decision for a while.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1r2lrxl/anyone_here_switch_from_prometheus_to_datadog_or/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4y4rcs",
          "author": "Hi_Im_Ken_Adams",
          "text": "The reason is always the same:  cost. \n\nThat‚Äôs why it‚Äôs always a migration from Datadog to Grafana and not the other way around. \n\n\nIf cost wasn‚Äôt a factor, then everyone would choose Datadog.   Datadog is super easy to use and set up but those monthly bills will say you alive.",
          "score": 42,
          "created_utc": "2026-02-12 08:07:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yxo9d",
              "author": "Due_Campaign_9765",
              "text": "Datadog metrics are complete ass. They aggregate by default, have weird opaque to user downsampling and it's in general feels like you see random numbers when you investigate something in a forensic manner, not just watch pretty pictures on the TV.\n\nWeird inconsistency when they ingest prometheus bucket metric even for their built-in integrations but don't provide the same histogram\\_quantile function and thus those metrics are completely useless is very bizarre.\n\nThey really need to bite the bullet and replace their crappy metric model with Prometheus'.\n\nThe rest of things are pretty nice, can't argue there",
              "score": 5,
              "created_utc": "2026-02-12 12:28:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zq8me",
                  "author": "engineered_academic",
                  "text": "The per-agent metrics sampling often bites people in the ass because unless you understand how it works under the hood you can get drastically different numbers.",
                  "score": 7,
                  "created_utc": "2026-02-12 15:11:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yyxba",
          "author": "signsots",
          "text": "Prometheus contributors won't bother you.\n\nDatadog sales people will find your personal email, hound you on LinkedIn, track when you get a new job to sell DD to them, and find your torture room when you both end up in hell.",
          "score": 32,
          "created_utc": "2026-02-12 12:37:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y1nhy",
          "author": "largeade",
          "text": "They are not the same thing, you need logs, metrics and traces to match datadog. Agree with the other poster about remote storage for disasters. I've seen a move from datadog to grafana stack for cost reasons",
          "score": 18,
          "created_utc": "2026-02-12 07:37:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yongq",
          "author": "PelicanPop",
          "text": "We switched from DD to Grafana because the costs were getting insane with DD. Like easily $1m+ per year just for logging. That doesn't include APM, synthetics, etc. DD at scale is SO damn expensive",
          "score": 11,
          "created_utc": "2026-02-12 11:18:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50oxd1",
              "author": "TonyBlairsDildo",
              "text": "It costs so much at scale because they know once you're in, you're never leaving Datadog.¬†\n\n\nAnd yet CFOs she CTOs fall into the same trap every day of every week of every month, all year long.",
              "score": 5,
              "created_utc": "2026-02-12 17:54:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4y7c7i",
          "author": "jamiemallers",
          "text": "Went Datadog -> self-hosted Grafana stack -> hybrid approach, so I've been through the whole journey.\n\nDatadog's killer feature is correlation. During an incident, having logs + metrics + traces in one pane with zero config is genuinely faster than jumping between Grafana, Loki, and Tempo dashboards. The problem: we hit ~$8k/mo and it kept climbing with every new service.\n\nPrometheus + Grafana + Loki works great if you have a platform team to maintain it. We didn't -- Thanos for HA alone ate a week of eng time every quarter. And the point about locking yourself out of logs during an outage (mentioned above) is real. We learned that the hard way.\n\nThe middle ground is where it gets interesting now. Grafana Cloud gives you managed Prometheus without the ops burden. SigNoz and OneUptime are solid open-source options if you want to self-host but don't want to glue together 4 different systems. OneUptime specifically bundles monitoring + logs + on-call + status pages, which helped us also kill our PagerDuty and Statuspage bills.\n\nMy advice: if your team is < 5 eng, the operational overhead of DIY Prometheus will eat you alive. Either go managed (Grafana Cloud) or pick something unified. If you have a dedicated platform team, Prometheus + Grafana is hard to beat on flexibility.",
          "score": 6,
          "created_utc": "2026-02-12 08:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ye5t7",
          "author": "3r1ck11",
          "text": "Prometheus gives you control, especially in Kubernetes-heavy setups. But once you add long term storage like Thanos or Mimir, logs with Loki, and tracing with Tempo or Jaeger, you‚Äôre basically maintaining a small observability platform yourself.\n\nDatadog is smoother out of the box. Everything is correlated and onboarding new engineers is easier. But at scale the billing model and cardinality can start shaping how you instrument things.\n\nLately I‚Äôve also seen teams look at newer approaches like Groundcover, which keeps the Prometheus compatibility but tries to simplify the stack and correlation side without stitching five tools together. Some are also experimenting with Grafana Cloud as a middle ground.\n\nIn the end it feels less like feature comparison and more about how much operational ownership you want versus how much abstraction you‚Äôre comfortable with.",
          "score": 8,
          "created_utc": "2026-02-12 09:40:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yw0jl",
          "author": "Low-Opening25",
          "text": "Datadog costs absolute fortune, so only sensible if you  have 6-fugure+ monitoring budget to burn every year.",
          "score": 4,
          "created_utc": "2026-02-12 12:16:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4y5krt",
          "author": "notrufus",
          "text": "New relic for us. I am vehemently opposed to datadog and will avoid working with them at all costs. I haven‚Äôt even used their product before but their sales people hounding me on my personal phone has ensured I never will willingly",
          "score": 7,
          "created_utc": "2026-02-12 08:15:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ycebl",
              "author": "cloudsourced285",
              "text": "Sales teams can suck, we moved from new relic to datadog due to how NR treated us and priced us out. But if they work for you, and well setup observability platform will do.",
              "score": 6,
              "created_utc": "2026-02-12 09:22:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4zho9r",
              "author": "TheKober",
              "text": "Man, this is real!!\nFirst was this asshole Ben, who kept ringing me all the time.\n\nNow is this douche Dan calls me all the time.\n\nTake a hint after I hung up on your face.",
              "score": 3,
              "created_utc": "2026-02-12 14:27:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o539l32",
              "author": "phoenix823",
              "text": "I had a terrible experience with NewRelic. Of all the expensive options, I like Dynatrace the most. ",
              "score": -1,
              "created_utc": "2026-02-13 01:50:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o50og84",
          "author": "TonyBlairsDildo",
          "text": "It's often cheaper to hire a guy (or two) dedicated to metrics and observably than it is to use Datadog.\n\n\nThe added bonus being the hires can also work on other problems in your organization.¬†\n\n\nI will never understand he urge so many companies have to dump $100K's, even $1M's into SaaS and flat-refuse to hire staff whatsoever. It just be an accounting wheeze or something, because fuck if I can understand it otherwise.",
          "score": 5,
          "created_utc": "2026-02-12 17:52:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xusef",
          "author": "One-Department1551",
          "text": "If you only have your logs inside your own infra you may lock yourself out of your logs. Be careful with self hosting and think about how to access them when incidents tear down the entire environment.",
          "score": 3,
          "created_utc": "2026-02-12 06:33:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zwlkr",
          "author": "hijinks",
          "text": "i run a consulting company that specializes on o11y mostly now.\n\nThe #1 reason for moving off prometheus is always we are still too small (i dont get many of these because its just easier to move off if you are small)\n\nThe #1 reason for moving off a company like DD is cost",
          "score": 1,
          "created_utc": "2026-02-12 15:42:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51cb48",
              "author": "baezizbae",
              "text": "> i run a consulting company that specializes on o11y mostly now.\n\nI work for an MSP consulting shop as the observability guy now, been at it two years after getting enticed away from the enterprise NOC. Looking to exit, personal reasons and follow a similar footpath as you. DD just happens to be where this org focuses but it‚Äôs not where I‚Äôm limited as an o11y engineer either. \n\nAny pointers for an up-starter like me?",
              "score": 1,
              "created_utc": "2026-02-12 19:44:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o51ffcl",
                  "author": "hijinks",
                  "text": "as in you want to learn more about o11y or consulting in the space?",
                  "score": 1,
                  "created_utc": "2026-02-12 19:59:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o51umot",
          "author": "Frequent_Balance_292",
          "text": "The testing landscape is shifting fast. Some trends worth knowing:  \n  \n\\- AI-powered test automation is growing \\~17% CAGR (huge)  \n\\- Self-healing tests are becoming standard (tests that auto-adapt to UI changes)  \n\\- Shift-left testing is the norm now (test earlier, not just at the end)  \n\\- The market is moving from \"more tests\" to \"smarter tests\"  \n  \nWhatever approach you take, make sure your tests are maintainable. That's the 1 thing that separates successful test automation from shelfware. What's your current setup?",
          "score": 1,
          "created_utc": "2026-02-12 21:12:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yhcgo",
          "author": "ultrathink-art",
          "text": "We've run both. The decision really comes down to: **Do you value control or convenience?**\n\n**Prometheus ‚Üí Datadog reasons:**\n- **Alert fatigue** - Prometheus alerting config is YAML hell. Datadog's UI makes complex alert logic (multiple conditions, anomaly detection, forecast alerts) way easier.\n- **Unified observability** - Having metrics + logs + traces in one platform simplifies correlation. With Prometheus you're stitching together 3-4 tools (Prom + Loki + Jaeger/Tempo).\n- **Managed infrastructure** - Not dealing with Prometheus HA, TSDB sizing, retention management. This matters more as you scale.\n- **Query language** - PromQL is powerful but cryptic. Datadog's query builder + saved views are more accessible for non-SRE teams.\n\n**Datadog ‚Üí Prometheus reasons:**\n- **Cost explosion** - Datadog pricing scales brutally with custom metrics and log volume. We hit k/month and realized 70% was log ingest we didn't need.\n- **Vendor lock-in** - Moving off Datadog is painful (all dashboards/alerts need rebuilding). Prometheus + Grafana is portable.\n- **Control** - Prometheus + long-term storage (Thanos/Cortex/Mimir) gives you full data ownership and infinite retention if needed.\n- **Cardinality limits** - Datadog has strict limits on tag cardinality. Prometheus handles high-cardinality metrics better (until you hit storage issues).\n\nHybrid approach we ended up with: Prometheus for metrics (self-hosted with Mimir for long-term storage), Datadog for logs and APM only. Gets us cost control on metrics while keeping the log/trace convenience.",
          "score": -8,
          "created_utc": "2026-02-12 10:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yxilh",
              "author": "Low-Opening25",
              "text": "Prometheus yaml config is massively advantageous for GitOps/IaC, unless you belong to the UI click-ops crowd.\n\nPrometheus is just one lego block of what is called Grafana stack, it includes Loki and OpenTelemetry so you can also have perfectly Unified observability, but perhaps requires some more initial setup efforts.\n\nGCP build in Logging is prometheus based, they also offer Managed Prometheus for GCP Logging, so AIs comment re. query language isn‚Äôt quite truth, I guess its an expert from Datadog marketing materials",
              "score": 1,
              "created_utc": "2026-02-12 12:27:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o506m37",
          "author": "rajith77",
          "text": "One word Correlation!  \nAnd we are a Datadog competitor (Randoli Observability Platform).\n\nCorrelating raw telemetry is hard, especially across logs, traces & metrics. That's where a vendor should be adding values (without costing you a fortune).\n\nThe ability extract high value signals & insights and correlating them quickly drastically reduces the cost of MTTR.\n\nAt Randoli, we keep the customers data local to their environment and ingest only signals and insights providing a predictable cost model.  This allows the customer to use high-cardinality metrics and avoid any kind of aggressive sampling. This becomes even more important when you take an Agentic AI approach to finding RCA and running runbooks.",
          "score": -3,
          "created_utc": "2026-02-12 16:28:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5ew1g",
      "title": "What does ‚Äúconfig hell‚Äù actually look like in the real world?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r5ew1g/what_does_config_hell_actually_look_like_in_the/",
      "author": "Real_Alternative_898",
      "created_utc": "2026-02-15 13:40:16",
      "score": 27,
      "num_comments": 33,
      "upvote_ratio": 0.94,
      "text": "I've heard about \"Config Hell\" and have looked into different things like IAM sprawl and YAML drift but it still feels a little abstract and I'm trying to understand what it looks like in practice. \n\nI'm looking for war stories on when things blew up, why, what systems broke down, who was at fault. Really just looking for some examples to ground me. \n\nId take anything worth reading on it too.",
      "is_original_content": false,
      "link_flair_text": "Ops / Incidents",
      "permalink": "https://reddit.com/r/devops/comments/1r5ew1g/what_does_config_hell_actually_look_like_in_the/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o5i9x65",
          "author": "Dies2much",
          "text": "Three Repos for the Security Devs under the cloud,\n\n\n‚ÄãSeven for the Infrastructure Leads in their data centers of stone,\n\n\n‚ÄãNine for Mortal Juniors doomed to on-call,\n\n\n‚ÄãOne for the Tech Lead on his ergonomic throne,\n\n\n‚ÄãIn the Land of Production where the Technical Debt lies.\n\n\n‚ÄãThe Power of the Root Access\n\n\n‚ÄãOne Script to rule them all,\n\nOne Script to find them,\n\nOne Script to merge them all,\n\nAnd in the spaghetti code bind them,",
          "score": 109,
          "created_utc": "2026-02-15 13:56:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5j6kco",
              "author": "Hebrewhammer8d8",
              "text": "No backups just vibes to recovery when shit hit the fan.",
              "score": 8,
              "created_utc": "2026-02-15 16:46:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5jdf5a",
                  "author": "tikkabhuna",
                  "text": "Backup, you fools!",
                  "score": 10,
                  "created_utc": "2026-02-15 17:19:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5jq5xg",
                  "author": "MrExCEO",
                  "text": "Vibes to recovery, let‚Äôs try this and see what happens",
                  "score": 1,
                  "created_utc": "2026-02-15 18:21:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5lyjef",
                  "author": "SauceOnTheBrain",
                  "text": "One does not simply backup into recovery.",
                  "score": 1,
                  "created_utc": "2026-02-16 01:36:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5irnvw",
          "author": "Tucancancan",
          "text": "20K line yaml file with embedded shell scripts in it¬†",
          "score": 20,
          "created_utc": "2026-02-15 15:33:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5j8bfh",
              "author": "MulberryExisting5007",
              "text": "Shell script embedded in yaml makes my neck hairs stand up. I don‚Äôt mind if it‚Äôs just four lines  or so ‚Äî in that case I‚Äôd rather not create a separate script, but whole scripts in yaml is the devil.",
              "score": 7,
              "created_utc": "2026-02-15 16:54:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5jw7mh",
                  "author": "chucky_z",
                  "text": "Looking at you, github actions.",
                  "score": 7,
                  "created_utc": "2026-02-15 18:50:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5k3ypz",
                  "author": "bendem",
                  "text": "Now imagine shell scripts embedding yaml with embedded shell scripts. The nightmare is real.",
                  "score": 4,
                  "created_utc": "2026-02-15 19:28:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5k9c5d",
                  "author": "melezhik",
                  "text": "This is why I started¬†http://deadsimpleci.sparrowhub.io",
                  "score": -1,
                  "created_utc": "2026-02-15 19:55:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5joo29",
              "author": "ryanstephendavis",
              "text": "oof... I always like the pattern of YAML config that can call into a dir with `scripts/`... Keeps a clean separation and then people can also run those scripts locally (ostensibly)",
              "score": 1,
              "created_utc": "2026-02-15 18:14:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5illoe",
          "author": "Horror-Programmer472",
          "text": "had this happen with terraform state drift. team had like 5 different people managing infra in 3 different ways - some via terraform, some direct aws cli, one guy just logging into console and clicking buttons.\n\nsix months later we needed to update security groups and nobody remembered which rules were managed where. spent two days tracking it down, meanwhile production had orphaned resources sitting around costing money.\n\nthe real kicker was the blame game. nobody documented what they did or why, so when it broke it was just finger pointing.\n\nwhat helped:\n- single source of truth for everything (all terraform, all in git)\n- required code review for any infra changes\n- automated drift detection that screams if manual changes happen\n- one person responsible for each service area (not perfect but better than chaos)\n\nbiggest lesson: the tools dont matter if nobody enforces the process. could use pulumi, cloudformation, whatever - the culture around how changes get made is the real issue",
          "score": 12,
          "created_utc": "2026-02-15 15:02:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5jsdbj",
          "author": "NastyEbilPiwate",
          "text": "We have a shitty xml config file for some apps. Some values are hard coded for all envs, some come from env-specific override files. Some are hard coded in the deployment pipeline for all envs. Some have env specific overrides from the pipeline. Some have machine specific values cculated by a script in the pipeline.\n\nNobody has any fucking clue where to change anything because unless you check all possible places you don't know what might be overridden.",
          "score": 4,
          "created_utc": "2026-02-15 18:32:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5iwmhw",
          "author": "EpiJunkie",
          "text": "jsonnet, 5+ years old, at least 3 styles by different admins.",
          "score": 3,
          "created_utc": "2026-02-15 15:57:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5i84xo",
          "author": "Afraid-Donke420",
          "text": "The guy before me configured all terraform to manage everything related to the app in one repo\n\nE.g. \n\nthe repo/github setup \n\nAWS everything\n\nFivetran\n\nSnowflake\n\n\nAll managed in ONE repo, so if I needed to change something in AWS and things got weird with updates or changes in fivetran modules or snowflake it just was a headache\n\nSure you can do the terraform target stuff\n\nBut just fuck this guy infrastructure should not be a monorepo",
          "score": 5,
          "created_utc": "2026-02-15 13:45:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ipc02",
              "author": "cailenletigre",
              "text": "Yet every day you‚Äôll find someone new who comes in, sees everything split up, and thinks to themselves, ‚Äúgosh wouldn‚Äôt this be better if I only had to manage one repo?‚Äù. A few years later, someone will think the opposite. Rinse and repeat. Such is the life of DevOps.",
              "score": 13,
              "created_utc": "2026-02-15 15:21:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5iqez3",
                  "author": "Afraid-Donke420",
                  "text": "I really don‚Äôt understand this because managing a repo is easier than bullshit spaghetti code",
                  "score": 4,
                  "created_utc": "2026-02-15 15:27:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5j4llo",
                  "author": "durple",
                  "text": "If there‚Äôs one thing I can take from having ever learned Perl, it‚Äôs TMTOWTDI.\n\nSeriously tho, deck chair arrangement aside I there are times to use one or the other. Organizational scale and complexity can demand multiple repos, while at small scale a monorepo can be very serviceable. Gotta match the implementation to the business needs.",
                  "score": 3,
                  "created_utc": "2026-02-15 16:36:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5j44xe",
              "author": "Jaydeepappas",
              "text": "Maybe I‚Äôm missing something, but mono repo terraform can be done well, no?\n\nUtilizing workspaces and tools like Atlantis make it so you can split up different kinds of resources, plan and apply them all separately, and manage them independently without them becoming intermingled like you are describing without ever needing to target anything. This just sounds like a bad terraform setup in a mono repo, but not necessarily a mono repo problem. \n\nOnce you are targeting resources in terraform you‚Äôve fucked up greatly.",
              "score": 3,
              "created_utc": "2026-02-15 16:34:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5jjjf2",
                  "author": "RandomPantsAppear",
                  "text": "All mono repos could be done well, and almost all aren‚Äôt.\n\nMicroservices were a reaction to many years of trauma.",
                  "score": 5,
                  "created_utc": "2026-02-15 17:49:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5j93f0",
                  "author": "Afraid-Donke420",
                  "text": "I don‚Äôt disagree, but I just dislike monorepos period\n\nYou are absolutely correct by all means, it could have been done right for sure",
                  "score": 0,
                  "created_utc": "2026-02-15 16:58:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5jwq0t",
              "author": "chucky_z",
              "text": "I'm missing something.  Having all these things in one repo makes total sense.  Are they in _one state_?  If so, your predecessor should've fixed this, and now you have the chance to.",
              "score": 2,
              "created_utc": "2026-02-15 18:53:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5iaua1",
              "author": "mvaaam",
              "text": "Welcome to my hell, lol",
              "score": 1,
              "created_utc": "2026-02-15 14:01:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ivvll",
              "author": "sofixa11",
              "text": "Tbf it could make sense if you have dependencies or want to share stuff (like org/team structures), but it could easily get slow and finicky at scale. You could also do it with subfolders and remote state while keeping it in the same repo (so tf in aws folder has its own state, tf runs cd to it)",
              "score": 1,
              "created_utc": "2026-02-15 15:54:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5idubc",
          "author": "Powerful-Internal953",
          "text": "the one pain-point I am going through right now is to decide if I should version the configs along with the build or not.",
          "score": 2,
          "created_utc": "2026-02-15 14:19:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5itmh5",
          "author": "ForeverYonge",
          "text": "When your deploy pipeline has so many overlapping template languages you need to use custom delimiters for some of them.",
          "score": 2,
          "created_utc": "2026-02-15 15:43:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5iz93z",
              "author": "shadowisadog",
              "text": "I feel called out but this is a fairly common situation. Or at least I have experienced it more than I care to admit.",
              "score": 1,
              "created_utc": "2026-02-15 16:10:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5l9693",
          "author": "OmegaNine",
          "text": "When a library gets deprecated without you realizing it so you have to upgrade it, but it is not compatible with another library you use, so you have to upgrade that too.  Next thing you know you are doing a whole stack upgrade on a thursday night.  ",
          "score": 1,
          "created_utc": "2026-02-15 23:03:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5keqhc",
          "author": "flavius-as",
          "text": "Any non-executable language will at some point lead to crap.\n\nThe superior way is to have the configuration as code (scripting languages) to drive the process of booting up the application, which means the application is a library for the configuration script.\n\nThen and only then no drift will occur because the application won't boot.",
          "score": 0,
          "created_utc": "2026-02-15 20:23:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2puyp",
      "title": "What should I focus on most for DevOps interviews?",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1r2puyp/what_should_i_focus_on_most_for_devops_interviews/",
      "author": "Few-Cancel-6149",
      "created_utc": "2026-02-12 10:21:04",
      "score": 24,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm currently preparing for DevOps interviews and trying to prioritize my study time properly.\nI understand DevOps is a combination of multiple tools and concepts ‚Äî cloud, CI/CD, containers, IaC, Linux, networking, etc. But from your experience, what do interviewers actually go deep into?\nIf you had to recommend focusing heavily on one or two areas for cracking interviews, what would they be and why?\nAlso, are there any common mistakes candidates make during DevOps interviews that I should avoid?\nIf there‚Äôs something important I‚Äôm missing, please mention it in the comments.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1r2puyp/what_should_i_focus_on_most_for_devops_interviews/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4znndq",
          "author": "akornato",
          "text": "Most interviewers will dig deepest into whatever technology stack their team actually uses day-to-day, but across the board, you need rock-solid fundamentals in Linux/systems administration and CI/CD pipelines. The reality is that most DevOps interviews test whether you can troubleshoot production issues and automate repetitive tasks - that means knowing how to debug failed deployments, read logs, understand networking basics, and write scripts that actually work. Containers and Kubernetes come up constantly now, so you should know more than just \"docker run\" - understand how networking works between containers, how resource limits affect performance, and what happens when things break. The cloud platform specifics matter less than understanding core concepts like IAM, networking, and managed services, since those patterns repeat across AWS, Azure, and GCP.\n\nThe biggest mistake candidates make is memorizing tool names and buzzwords but falling apart when asked to solve real problems or explain their reasoning. Interviewers can smell it immediately when someone claims expertise but can't explain why they'd choose one approach over another or how they'd debug a specific failure scenario. Be ready to walk through actual situations from your experience - even if they're from side projects or labs - and explain your thought process out loud. If you want practice getting real-time feedback on how you're explaining things, I built [interviews.chat](http://interviews.chat) which can help you work through technical questions in a conversational way before the actual interview.",
          "score": 14,
          "created_utc": "2026-02-12 14:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50ejv4",
              "author": "Confident_Subject330",
              "text": "That seems like sound advice.",
              "score": 1,
              "created_utc": "2026-02-12 17:05:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4yjn3w",
          "author": "courage_the_dog",
          "text": "It depends on the actual role at the company. I've had ones ask more dev related stuff than platform and vice versa\n\nSo study on the requirements they have in the job spec,  the sdlc, fundamentals, and then get as many interviews as possible to practice",
          "score": 8,
          "created_utc": "2026-02-12 10:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z61wu",
          "author": "Prior-Celery2517",
          "text": "Focus hard on CI/CD design + one cloud (IAM, networking, scaling) and be ready to explain *why* you built things a certain way. Most people fail by just name-dropping tools and having weak fundamentals.",
          "score": 6,
          "created_utc": "2026-02-12 13:23:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zu1mm",
          "author": "tevert",
          "text": "I see a surprising number of candidates who go full deer-in-headlights at any sort of coding. Not talking about any fancy compsci challenges either, just string manipulation and looping.\n\nIt's 2026, you have to be able to code in this job",
          "score": 6,
          "created_utc": "2026-02-12 15:30:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50pgyx",
          "author": "riickdiickulous",
          "text": "Study whatever your blind spots or weak points are, and/or what you want to do for work. ‚ÄúDevOps‚Äù is an overly broad title and you need to specialize in some way. Usually people become devops after being a developer or in operations and then slowly migrate to devops over time. You must know at least one IaC language, one CICD platform, and one scripting language, and be comfortable on the Linux command line to stand a real chance in the devops market.",
          "score": 3,
          "created_utc": "2026-02-12 17:57:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zx4nf",
          "author": "The_DevOps_Expert",
          "text": "Focus on basics of troubleshooting, Linux, networking containers, cloud etc.\nRest of the tools are just Q&A so should be straight forward.",
          "score": 3,
          "created_utc": "2026-02-12 15:44:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55yepm",
          "author": "Haunting_Month_4971",
          "text": "Strong fundamentals in CI/CD pipelines and Kubernetes are absolutely critical - I've seen too many candidates struggle with basic pipeline debugging or pod troubleshooting scenarios.\n\nFor DevOps career prep and interview strategies, u/beyzhq has a really helpful Twitter thread on preparing for roles that bridge development and operations. Worth checking out if you're serious about breaking into the field.",
          "score": 2,
          "created_utc": "2026-02-13 14:01:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52nc4i",
          "author": "Unusual_Impression_8",
          "text": "Leetcode style questions",
          "score": 1,
          "created_utc": "2026-02-12 23:38:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54wvg7",
          "author": "SipsAndGiggles",
          "text": "When you broke stuff. How you reacted. And what you did to fix it. What stuff? Suprise me. I will remember an interesting interview with great discussion over anyone that lists thier CV.",
          "score": 1,
          "created_utc": "2026-02-13 09:22:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o56hlh8",
          "author": "Haunting_Month_4971",
          "text": "From what I keep seeing, interviewers probe deepest on how you troubleshoot and how you ship changes safely. If I had to bet, I‚Äôd go hard on CI/CD design and Kubernetes fundamentals, and be ready to explain tradeoffs, rollbacks, and what you‚Äôd check first when a deploy breaks, imo. Action wise, I time box mock scenarios where I narrate a failed release, read logs, and outline a rollback, pulling prompts from the IQB interview question bank, then do a quick dry run in Beyz coding assistant to keep answers tight. Keep stories in STAR format and aim for ~90 seconds per answer. Biggest miss I notice is name dropping tools without a clear debugging path.",
          "score": 1,
          "created_utc": "2026-02-13 15:38:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzzeoz",
      "title": "The recent SaaS downturn raises an uncomfortable question",
      "subreddit": "devops",
      "url": "https://www.reddit.com/r/devops/comments/1qzzeoz/the_recent_saas_downturn_raises_an_uncomfortable/",
      "author": "Abu_Itai",
      "created_utc": "2026-02-09 09:04:04",
      "score": 22,
      "num_comments": 35,
      "upvote_ratio": 0.71,
      "text": "Will the AI boom actually change how DevOps works? Will some roles disappear, or just evolve? With all these tools trying to \"replace\" traditional DevOps, where do you think this is going?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/devops/comments/1qzzeoz/the_recent_saas_downturn_raises_an_uncomfortable/",
      "domain": "self.devops",
      "is_self": true,
      "comments": [
        {
          "id": "o4elzf6",
          "author": "conairee",
          "text": "There's going to need to be people to corral¬†all these tools for a while, and I think we are a bit away from AI being able to close the loop a debug things end to end. Definitely not a time to stop learning though. ",
          "score": 28,
          "created_utc": "2026-02-09 09:10:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4em9xf",
              "author": "Abu_Itai",
              "text": "You really think we‚Äôre still far away?\nA frontend engineer from my company came to me the other day, proudly showing how he spun up a cluster with two replicas, deployed a database, and structured the project ‚Äúlike a senior DevOps.‚Äù\nI‚Äôll be honest, that was a real oh-shit moment for me.",
              "score": -15,
              "created_utc": "2026-02-09 09:13:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4emoau",
                  "author": "bowersbros",
                  "text": "Spinning up a cluster is the easy bit though. The hard bit is knowing how to recover if something goes wrong. That‚Äôs where a seniors experience is valuable. There were thousands of articles, tutorials and blogs online before talking about how to spin up a cluster, or a whole host of other things, folllowing any of those and successfully launching a cluster didn‚Äôt mean they were anywhere close to a senior in experience or ability, just as following prompted steps doesn‚Äôt either. It may reduce the barrier of entry to juniors, but it absolutely does not replace seniors. At least, not yet.",
                  "score": 43,
                  "created_utc": "2026-02-09 09:17:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4f3m6a",
                  "author": "Lj101",
                  "text": "A senior DevOps was never necessary to spin up a DB and a cluster. It involves some light Terraform.",
                  "score": 4,
                  "created_utc": "2026-02-09 11:55:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ftqxi",
                  "author": "DustOk6712",
                  "text": "My 10 year old can spin up a cluster and database if he wanted to. Would I trust his setup? Of course not.",
                  "score": 3,
                  "created_utc": "2026-02-09 14:41:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o58btt9",
                  "author": "Just-Finance1426",
                  "text": "You shouldn‚Äôt be getting downvoted like that, this is a super valid example. There‚Äôs a lot of dinosaurs spraying cope in this discussion, but we‚Äôre all in deep shit at this point.\n\nI will say though, just like the front end person was able to spin up that infra, we could just as easily find ourselves writing full stack code, so it‚Äôs not like they‚Äôre somehow better off than us. Likewise lawyers, support staff, sales, marketing, management, customer support, etc. All these positions are going to change dramatically.",
                  "score": 2,
                  "created_utc": "2026-02-13 21:00:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4end7o",
                  "author": "conairee",
                  "text": "I don't know about *far*¬†away. We'll know when the AWS DevOps agent starts fixing everything without input.[](https://aws.amazon.com/devops-agent/)",
                  "score": 3,
                  "created_utc": "2026-02-09 09:24:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4fbatj",
                  "author": "Emptycubicle4k",
                  "text": "Will the AI also set up his nexus repo, set up reverse proxies, load balancers, auto scaling, security groups. Will it troubleshoot crash loops or figure out why his custom image won‚Äôt build? If not then I think we‚Äôre good for at least a couple more years.",
                  "score": 3,
                  "created_utc": "2026-02-09 12:52:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4hwqz4",
                  "author": "Educational_Sun_8813",
                  "text": "wait, until something go south, and he will back to you for fix",
                  "score": 1,
                  "created_utc": "2026-02-09 20:45:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4eqzrg",
          "author": "BudgetBon",
          "text": "AI isn't killing DevOps; it's killing the 'YAML Janitor'. If your job is just writing boilerplate Terraform or finding syntax errors in a Dockerfile, yes, you are obsolete. AI does that better and faster.\n\nP.s Junior roles are in trouble. Senior roles just got a superpower. Adapt or die.",
          "score": 50,
          "created_utc": "2026-02-09 10:00:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4esij1",
          "author": "re-thc",
          "text": "Where is the SaaS downturn though? The stock market? Hiring has been poor across the board. Software over hired massively during COVID. There‚Äôs been tariffs and fights everywhere.\n\nIs there a SaaS specific issue? Not the headlines but the reality.",
          "score": 7,
          "created_utc": "2026-02-09 10:15:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4f0qhs",
              "author": "MathmoKiwi",
              "text": "\n\n>Where is the SaaS downturn though? The stock market?¬†\n\n[https://www.youtube.com/watch?v=6xYg5GmbgXE](https://www.youtube.com/watch?v=6xYg5GmbgXE)",
              "score": 0,
              "created_utc": "2026-02-09 11:31:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4f4w31",
                  "author": "re-thc",
                  "text": "Yes, that's the stock market i.e. what I said? Speculative traders making random bets.\n\nThey dumped Mediatek stock in masses last year and downgraded it saying it \"won't compete\" and then only weeks later turned around to upgrade it again saying it's \"making way\". Whatever.\n\nThey dumped Apple saying no AI at 1 point and then bought Apple in masses saying it's a winner due to no AI. Yeah yeah.",
                  "score": 8,
                  "created_utc": "2026-02-09 12:05:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ff2gk",
          "author": "Informal_Tangerine51",
          "text": "AI changes what breaks in DevOps, not whether things break.\n\nAgents can generate Terraform, write monitoring configs, even debug infrastructure. But when your AI-generated pipeline fails at 3am, someone still needs to understand distributed systems, debug cascading failures, and make judgment calls under pressure. That's not getting automated.\n\nThe evolution: DevOps engineers spend less time writing boilerplate configs, more time debugging AI-generated infrastructure that fails in novel ways. New skill becomes: verifying AI output is correct before it touches production, and having evidence infrastructure to debug when it wasn't.",
          "score": 5,
          "created_utc": "2026-02-09 13:16:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4envx6",
          "author": "mcncl",
          "text": "https://twitter.com/KentBeck/status/1648413998025707520?s=20\n\n90% of your skills are now worthless, but the remaining 10% went up 1000x. You just need to figure out what that 10% is.¬†",
          "score": 11,
          "created_utc": "2026-02-09 09:29:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jdjc2",
              "author": "g3t0nmyl3v3l",
              "text": "Turns out the valuable part of being en engineer, DevOps or not, is pragmatism and communication skills. It not how well you can reverse a linked list.\n\nOh wait, that was pretty much _always the case_.",
              "score": 2,
              "created_utc": "2026-02-10 01:27:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4er49p",
          "author": "badguy84",
          "text": "LLMs have peaked in how useful or ‚Äúknowledgeable‚Äù LLMs will be. If they don‚Äôt sufficiently solve the problem now they aren‚Äôt going to soon. \n\nThe thing is LLMs are good at taking multi modal inputs and assigning things like intent which can drive RAG and utilities as well as other agents. The challenge is: this is all very expensive and to get good outcomes you need a lot of investment in data infrastructure and you have to build the pipes any way between agents and their tooling. Which costs money and potentially far more than companies are willing to spend when the current view of AI is that it will solve everything with no effort besides paying for tokens.\n\nSo uhm definitely not replacing: depending on cost it will change things (cost of AI usage becoming the ‚Äúhow much‚Äù) also: SaaS ‚Ä¶ I‚Äôve seen articles with this headline and it has me scratching my head: why would all SaaS fall under the AI bubble? AIaaS maybe but yeah lots of SaaS is useful and can generate revenue for companies running it.",
          "score": 5,
          "created_utc": "2026-02-09 10:01:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4etrgs",
          "author": "Imaginary_Gate_698",
          "text": "It feels a lot more like evolution than replacement. Most of the AI tools still need someone who understands systems, tradeoffs, and failure modes to make sense of the output. The busywork might shrink, but the judgment and ownership parts seem harder to automate. If anything, the role probably shifts closer to platform engineering and reliability thinking.",
          "score": 1,
          "created_utc": "2026-02-09 10:27:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jsnoj",
          "author": "Positive_Method3022",
          "text": "The truth is that there was never Jr and Senior roles. Only politics. Those with good connections are the ones that will survive in the industry, since deep understanding of hard skills will no longer be needed.",
          "score": -1,
          "created_utc": "2026-02-10 02:55:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4eql5q",
          "author": "TonyBlairsDildo",
          "text": "The whole software/ops industry is finished. At least in its current employment pattern.\n\nSaaS, which is where one company develops and hosts a software solution for multiple third party customers, is also finished.\n\nThe future is customers themselves developing their own solution in-house using AI tooling, designed for and tested against their own internal business workflows.\n\nIf you're a factory that makes Widgets, there is no need to use the same SaaS to manage your factory as a factory that makes Gadgets. They're two different industries making two different products, integrated with their upstream and downstream partners in different ways. They can now have their own bespoke software.\n\nThe way I see it is companies will start creating in-house software solutions. One or two developers/devops guys in a company of 1,000, 10,000 or whatever could oversee the streamlining of a lot of business processes.\n\nThe question is: if there are 1M developers in the world churning out 100M units of software per year, will AI tooling mean that 1M developers can create 1,000M units of software per year (i.e 10x leverage), or does the world only need 100M units of software per year, and can survive with 100,000 developers.\n\nEither the demand for software explodes, and current developers simply deliver more; or the demand for software stays the same and developer headcount is slashed.\n\nWhen computers evolved from expensive mainframes to cheaper workstations, the world didn't stick single lonely cheap workstations in each university and bank around the world and call it a day; they ended up in smaller factories, offices, and homes.\n\nI suspect something similar for AI software development, but whatever happens, it will be very different to today.",
          "score": -11,
          "created_utc": "2026-02-09 09:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4fmezf",
              "author": "ansibleloop",
              "text": ">The future is customers themselves developing their own solution in-house using AI tooling, designed for and tested against their own internal business workflows.\n\nHahahahaha\n\nOh wait, you're serious? Let me laugh even harder\n\nAhahahahahhahahahahha",
              "score": 2,
              "created_utc": "2026-02-09 14:00:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4er1hv",
              "author": "Abu_Itai",
              "text": "Interesting, I can definitely relate to what you said‚Ä¶ \nBut what about products that are harder to replace? Like infrastructure solutions etc‚Ä¶ I agree it can replace JIRA / Trello or any basics CRM - but will other infra tools disappear and every org will have an internal software manufacturer unit that will develop the hard stuff as well?",
              "score": 1,
              "created_utc": "2026-02-09 10:01:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4etom3",
                  "author": "TonyBlairsDildo",
                  "text": "If you asked someone 18 months ago if LLMs could 1-shot a CRM or Trello clone they'd laugh and tell you it's useful to auto-complete a Class or Function you're writing, not write the entire codebase.¬†\n\n\nWe're all humbled now at that particular level, but still confident it can't do task+1.\n\n\nThe starting point for \"cottage\" in-house development will look something like a plumbing company that employs 50 guys, that notices they can send morning job sheets out to the guys more efficiently that email.¬†\n\n\nSo they knock together an app for their smartphone that lists their jobs for the next day. Then they add customer histories so guys can see what happened before their arrival. Then they add parts ordering from their supplier so they don't need to make phone calls. Then they add ..., ..., ..., and so on.¬†\n\n\nA year later this Mom-n-pop plumbing company has a very sophisticated employee coordination system they built from the ground up.¬†\n\n\nTheir one IT guy built it, not a SaaS company. That's what I'm imagining.",
                  "score": 1,
                  "created_utc": "2026-02-09 10:26:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4et71p",
                  "author": "bandersnatchh",
                  "text": "No one knows.¬†\n\nLLMs can do some cool stuff.\n\nThey can also produce dogshit.\n\nThings will probably change, and the reality is that in tech we all will probably use some level of code generation.¬†\n\nThere are so many people claiming the extremes. It‚Äôs either no AI or full AI‚Ä¶ the future is probably somewhere in the middle.¬†\n\nPersonally, I think the best thing to do is keep an open mind and pick up as many skills as possible and go from there. Personally, I‚Äôm not going too hard on AI stuff yet because it‚Äôs changing so fast it just seems kinda pointless.\n\nIt was prompt engineering, and the context engineering, now it‚Äôs agentic orchestration, who the hell knows what‚Äôs next.¬†",
                  "score": 1,
                  "created_utc": "2026-02-09 10:22:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}