{
  "metadata": {
    "last_updated": "2026-01-26 08:59:58",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 169,
    "file_size_bytes": 229548
  },
  "items": [
    {
      "id": "1ql9hn8",
      "title": "AWS IP Ranges hit 100 million IPv4 IP addresses.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1ql9hn8/aws_ip_ranges_hit_100_million_ipv4_ip_addresses/",
      "author": "seligman99",
      "created_utc": "2026-01-24 01:33:27",
      "score": 178,
      "num_comments": 19,
      "upvote_ratio": 0.98,
      "text": "Mildly interesting milestone:  AWS's ip-ranges just crossed the 100 million IPv4 IPs threshold.  They've been on an adding spree in the last few days.\n\nComplete history available in [my repo](https://github.com/seligman/aws-ip-ranges) for those that are curious.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1ql9hn8/aws_ip_ranges_hit_100_million_ipv4_ip_addresses/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o1d8fjq",
          "author": "PeteTinNY",
          "text": "I couldnâ€™t imagine how much that cost them. ARIN managed IPv4 is incredible these days.",
          "score": 69,
          "created_utc": "2026-01-24 03:51:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1e499m",
              "author": "SureElk6",
              "text": "for them its a one time cost, for users its a monthly rent.\n\npure profit in couple of years.",
              "score": 53,
              "created_utc": "2026-01-24 07:55:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1e5ieo",
                  "author": "PeteTinNY",
                  "text": "But even so, I can only dream of owning even a few /24.  Heck a /20 would be a fantasy.     I currently own a   Portable direct allocated IPv6 /40 - but thatâ€™s cheap.",
                  "score": 14,
                  "created_utc": "2026-01-24 08:06:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1iyl9z",
                  "author": "PeteTinNY",
                  "text": "There is an annual fee to keep the IP though. For my personal micro IPv6 and ASN itâ€™s about $300/year. It goes up based on how much space and ASNs you have. So if I add more - the annual membership fee to ARIN goes up.",
                  "score": 5,
                  "created_utc": "2026-01-25 00:15:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1eim8x",
              "author": "religionisanger",
              "text": "Iâ€™m sorry if this is a daft question, but arenâ€™t they free? I worked in a datacenter some 20 years ago and I think we needed to do a course but we then requested a /24 and got it without any costs.",
              "score": 3,
              "created_utc": "2026-01-24 10:07:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ejeyl",
                  "author": "profmonocle",
                  "text": "That was before IPv4 exhaustion. The RIRs ran out of space years ago - now the only way to get a public IPv4 block is to buy it from someone.",
                  "score": 35,
                  "created_utc": "2026-01-24 10:15:07",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1elz3k",
                  "author": "AndrewTyeFighter",
                  "text": "I was working at an ISP 20 years ago and even then it was a hassle trying to buy enough IPv4 addresses.",
                  "score": 6,
                  "created_utc": "2026-01-24 10:38:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1f0x3m",
          "author": "schizamp",
          "text": "In the mid 2010s I worked for GE and we had internal servers and endpoints get assigned an IP from the public 3.x Class A range. Shortly after, GE sold the Class A to AWS and we had to update all of our firewall and security group rules. I think it's funny seeing the old range get used for public instances in AWS now.",
          "score": 19,
          "created_utc": "2026-01-24 12:43:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ivtnq",
              "author": "GolfballDM",
              "text": "I used to work for the company that owned 47.0.0.0/8, quite a surprise for me to see my game master for an online RPG campaign use one of those IP addresses for his VTT server.",
              "score": 7,
              "created_utc": "2026-01-25 00:00:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1dvspn",
          "author": "Thinguist",
          "text": "Even for AWS, thereâ€™s no need to have that many. IPv6 is never going to get pushed out when they can just collect IPv4 rents instead.",
          "score": 4,
          "created_utc": "2026-01-24 06:41:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1e7l6f",
              "author": "hatchetation",
              "text": "Huh? What does that mean? \n\nAWS is acquiring addresses to fulfill demand. It's a great reason to have that many.",
              "score": 38,
              "created_utc": "2026-01-24 08:25:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1eirju",
                  "author": "religionisanger",
                  "text": "Indeed I would argue itâ€™s not a reason and itâ€™s a necessity.",
                  "score": 6,
                  "created_utc": "2026-01-24 10:09:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fjgym",
                  "author": "wlonkly",
                  "text": "I dunno, NAT gateway pricing is still terrible. It's cheaper for me to spin up instances in a public subnet and block incoming traffic via a security group than it is for me to bother putting them on a private subnet with a NAT gateway.  I have no need for those IPs but I have them anyway.",
                  "score": 3,
                  "created_utc": "2026-01-24 14:37:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1leq8h",
                  "author": "zan-xhipe",
                  "text": "Demand they help create because of how many of their services still can't do IPv6",
                  "score": 1,
                  "created_utc": "2026-01-25 10:06:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qjr0s7",
      "title": "ECR finally supports layer sharing",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ecr-cross-repository-layer-sharing/",
      "author": "waitingforcracks",
      "created_utc": "2026-01-22 10:24:53",
      "score": 79,
      "num_comments": 4,
      "upvote_ratio": 0.99,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qjr0s7/ecr_finally_supports_layer_sharing/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o13jwjl",
          "author": "TechDebtSommelier",
          "text": "TLDR: ECR can now reuse identical image layers across different repos, so pushes are faster and you stop paying to store the same base image over and over. Turn it on once at the registry level and it just works, which is especially nice if you have lots of microservices built on the same images.",
          "score": 41,
          "created_utc": "2026-01-22 19:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13l0os",
          "author": "waitingforcracks",
          "text": "Now just waiting for terraform to support the setting so we can enable it.",
          "score": 18,
          "created_utc": "2026-01-22 19:10:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o11g115",
          "author": "aviboy2006",
          "text": "Wow this great addition. Love it.",
          "score": 9,
          "created_utc": "2026-01-22 13:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16odyq",
          "author": "wwsean08",
          "text": "As a note this only works for your repositories that are using the same KMS key, if they are using different KMS keys, then the layers won't be shared, which should be expected but at least wasn't initially called out when i read about it earlier this week and asked my TAM to confirm.",
          "score": 7,
          "created_utc": "2026-01-23 04:59:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkm3sa",
      "title": "What AWS service would you not recommend using today unless absolutely necessary and why?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qkm3sa/what_aws_service_would_you_not_recommend_using/",
      "author": "ApprehensiveBar7701",
      "created_utc": "2026-01-23 09:12:05",
      "score": 71,
      "num_comments": 208,
      "upvote_ratio": 0.9,
      "text": "",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qkm3sa/what_aws_service_would_you_not_recommend_using/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o17mqc0",
          "author": "hashkent",
          "text": "Amplify and elastic beanstalk",
          "score": 197,
          "created_utc": "2026-01-23 09:47:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18fpeh",
              "author": "dkode80",
              "text": "Came here to say this. I hate amplify so much. It's such a bloated, broken mess with little support and swaths of bugs. 450+ open issues on GitHub. \n\nI inherited an architecture that uses it heavily and have been moving things out of it. Such a horrid product that's broken in so many ways.",
              "score": 37,
              "created_utc": "2026-01-23 13:25:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18ng5k",
              "author": "mr_mgs11",
              "text": "I was going to post Elastic Beanstalk. It's basically containers for people who don't know how to use ecs. My last job there was a huge initiative to get all the container work loads off of it.",
              "score": 19,
              "created_utc": "2026-01-23 14:06:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ae98n",
                  "author": "criminalsunrise",
                  "text": "I use elastic beanstalk to standup POCs quickly. I donâ€™t know another way to do it so quickly and without hassle. I wouldnâ€™t use it for prod stuff though.",
                  "score": 7,
                  "created_utc": "2026-01-23 18:57:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18r7v1",
                  "author": "SpAwN_gUy",
                  "text": "Unless you are not using the containers and enjoy minimal system overhead closer to the metal. + cli deploy + spot instances + better right-sizing + fleet manager, load balancing, rotation, sys updates\n\nIn my head: container = instance, docker/kube cluster = aws region, docker cluster node = aws az\n\nAm I missing some crucial advance of ecs? I'm on ebtalk since 2011",
                  "score": 5,
                  "created_utc": "2026-01-23 14:26:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fv7o3",
                  "author": "fartingdoor",
                  "text": "EBS originated and was used before containers became popular.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:37:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18i51c",
              "author": "acorah",
              "text": "We are looking at using amplify - we have it on some smaller projects and it works great for just deploying minimal frontend code (note: this is with a separate backend on ec2, we dont use the backend functionality) - is there something you would recommend instead? Just hosting the frontend code on ec2?",
              "score": 6,
              "created_utc": "2026-01-23 13:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18vx5k",
                  "author": "coolcosmos",
                  "text": "Use cdk to make a stack with a S3 website bucket to host, then a CloudFront distribution with the bucket as it's source.\n\n\nhttps://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_s3_deployment-readme.html",
                  "score": 15,
                  "created_utc": "2026-01-23 14:49:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1aasdu",
                  "author": "30thnight",
                  "text": "Amplify is a little confusing because itâ€™s better to think about it as 2 separate services, frontend hosting and fullstack app SDK. \n\n\\1. Frontend Hosting \n\nThis is an alternative to Vercel, Netlify, and Cloudflare Pages for deploying SPAs and static websites of all types on AWS.\n\nItâ€™s based on the traditional method (S3 + Cloudfront) but includes additional features that are a bit harder to an SRE team to build out of the box (feature branch deploys, password protection, redirect management)\n\nI honestly think this is best way to handle frontend deployments on AWS so long as you set this up with IaC\n\n\\2. Backend SDK\n\nGen 1 was heavily opinionated, bound to its CLI, and had unclear boundaries with how interfaced with existing IaC. 90% of pain and strife associated to Amplify in general can be attributed here. \n\nGen 2 fixes many these issues and create clear separation of boundaries between your existing infra as itâ€™s largely based on CDK. \n\nIf you are mostly running lambda backends or need to support older Next.js versions, Iâ€™d consider it safe to use\n\nThat said, amplify wouldnâ€™t be my first choice.\n\nI strongly believe sticking to containers simplifies life for everyone, especially when ECS Express Mode or App Runner exist.",
                  "score": 4,
                  "created_utc": "2026-01-23 18:42:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18nu2c",
                  "author": "mr-nobody1992",
                  "text": "Would also love to know why? We use amplify only for frontend as well",
                  "score": 3,
                  "created_utc": "2026-01-23 14:08:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1b1nkv",
                  "author": "Zenin",
                  "text": "Amplify v1 made trivial things easy and hard things impossible.\n\nAmplify v2 made easy things trivial and hard things are a massive pain in the ass.\n\nEvery Amplify project I've been involved with the team spent *most* of their development time working *around* Amplify.  It was very tempting to use *some* kind of framework for all the boiler plate work, but Amplify v1 got this extremely wrong and v2 is very much a \"too little, much too late\" story.\n\nThis is especially true today in the age of AI where AI can get you a *real* stack without all that opinionated cruft and lock in for much the same time and level of effort that you were looking to big frameworks to address.\n\nI've never worked with or even talked to anyone who's moved away from Amplify and regretted it or even missed it.",
                  "score": 1,
                  "created_utc": "2026-01-23 20:47:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18no96",
                  "author": "InsolentDreams",
                  "text": "Itâ€™s not an AWS service but we use fly.io for super cheap and affordable hosting for simpler frontends.  Still better than amplify and more affordable and less fiddly than manual ec2 and way less than ecs/eks",
                  "score": 1,
                  "created_utc": "2026-01-23 14:07:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18t5uu",
                  "author": "progres5ion",
                  "text": "Try ECS Express Mode for your frontend app https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-amazon-ecs-express-mode/",
                  "score": 0,
                  "created_utc": "2026-01-23 14:36:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17vjw1",
              "author": "Legal-Butterscotch-2",
              "text": "I'm using amplify only, why not? so easy to plug to a repository and its works as CI/CD for you",
              "score": 6,
              "created_utc": "2026-01-23 11:05:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1841js",
                  "author": "SpoddyCoder",
                  "text": "Creates extremely bloated lambdas and is quite limited in a lot of respects. \n\nThis is one of their products thatâ€™s a response to competitor action - itâ€™s not unusual for these to see limited internal development and support - and to eventually be turned off in 5 years time when they realise to actually compete they would need to spend considerable resources on it.",
                  "score": 12,
                  "created_utc": "2026-01-23 12:11:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o17wscx",
                  "author": "Positive_Method3022",
                  "text": "Doesn't fit with cdk projects well",
                  "score": 2,
                  "created_utc": "2026-01-23 11:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18s280",
              "author": "thamesr",
              "text": "Genuine question - what would be an alternative to amplify? I use it all the time and haven't had any issues with it, but I'm not really a frontend person so I'm ignorant.\n\nElastic beanstalk is trash.",
              "score": 2,
              "created_utc": "2026-01-23 14:30:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19j920",
              "author": "Valkiie",
              "text": "On a frontend only standpoint:\n\nAmplify only if you need ssr.\n\nOtherwise go for the classic static sites s3 to cloud front",
              "score": 1,
              "created_utc": "2026-01-23 16:37:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bl2s0",
              "author": "Asleep_Fox_9340",
              "text": "I have a product running on beanstalk (NodeJS) and Amplify (ReactJS) for the past 6 years. I have a team of 10 developers working on it. There are more QA, DevOps and even more people on the business side like account managers, sales, customer support, etc. The product in question made 3+ million USD revenue last year. \n\nI don't understand all the hate here ðŸ˜…",
              "score": 1,
              "created_utc": "2026-01-23 22:19:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1du2zn",
              "author": "SupaMook",
              "text": "I use amplify for basically all my side projects and it works a charm ðŸ¤”",
              "score": 1,
              "created_utc": "2026-01-24 06:26:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18s88k",
              "author": "thetall0ne1",
              "text": "Just use Kiro CLI and vibe deploy stuff to AWS. You never have to touch the console. AWS even has a prompt library you can use to get started: https://aws.amazon.com/startups/prompt-library",
              "score": -3,
              "created_utc": "2026-01-23 14:31:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18w2b4",
                  "author": "skat_in_the_hat",
                  "text": "\"Hey Kiro, why is my bill 1000/mo?\"",
                  "score": 6,
                  "created_utc": "2026-01-23 14:50:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17l0xl",
          "author": "CanaryWundaboy",
          "text": "ElasticBeanstalk, itâ€™s horrible.",
          "score": 90,
          "created_utc": "2026-01-23 09:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o188uol",
              "author": "HanzJWermhat",
              "text": "Itâ€™s a zombie product at this point anyway",
              "score": 20,
              "created_utc": "2026-01-23 12:44:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18cso1",
                  "author": "yourparadigm",
                  "text": "Yet somehow their AL2023 AMIs got Ruby 3.4 support a year ago!",
                  "score": 3,
                  "created_utc": "2026-01-23 13:08:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o19j913",
              "author": "AWSSupport",
              "text": "Hi there,\n\nSorry to hear that, we're always looking for ways to enhance our services. If you've suggestions that could help improve our Elastic Beanstalk application, share your feedback using this option: http://go.aws/feedback.\n\n\\- Elle G.",
              "score": 4,
              "created_utc": "2026-01-23 16:37:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17l6mb",
              "author": "ApprehensiveBar7701",
              "text": "Elastic Beanstalk. Tries to be simple PaaS but ends up giving you EC2/ASG/ALB complexity plus an opaque magic layer. Hard to debug, customize, or migrate off. In 2026, ECS/Fargate or EKS are almost always better.",
              "score": 15,
              "created_utc": "2026-01-23 09:33:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1avwfj",
                  "author": "elsefirot_jl",
                  "text": "EBS was already old when I was using it in 2015. Just let that crap die already",
                  "score": 2,
                  "created_utc": "2026-01-23 20:20:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1b3kqw",
                  "author": "Defiant-Ad-3243",
                  "text": "While I understand this take, it's worth mentioning that Beanstalk has been improving lately after years of stagnation. Also it's apples and oranges to compare Beanstalk (app management) to ECS/EKS (infra management).",
                  "score": 1,
                  "created_utc": "2026-01-23 20:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17q34f",
              "author": "soulseeker31",
              "text": "We have an instance of metabase running for internal use only on it. Haven't touched it because it hasn't broken __yet__.",
              "score": 3,
              "created_utc": "2026-01-23 10:18:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1akcug",
              "author": "fonde_la",
              "text": "Surprised to see all the hate for EB. We've used it in production for 10 years and never had an issue. Sure, if I were to set it up from scratch today I might choose a solution with containers but it works well enough that we've had no reason to migrate yet.",
              "score": 1,
              "created_utc": "2026-01-23 19:26:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1c1rn9",
              "author": "ownlessminimalist",
              "text": "I took the leap on my last project to go with ECS/Fargate and thank goodness I did. So much easier to work with",
              "score": 1,
              "created_utc": "2026-01-23 23:46:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1aq5j6",
              "author": "EitherAd5892",
              "text": "Why is elastic beanstalk bad? I thought itâ€™s a great tool for managing AWS servicesÂ ",
              "score": 0,
              "created_utc": "2026-01-23 19:53:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1fvqk7",
                  "author": "CanaryWundaboy",
                  "text": "ElasticBeanstalk, when it was created it was one of the only ways you could run containers in AWS. Thereâ€™s just lots of better ways now that donâ€™t result in a whole stack of resources, a poor management interface and a bad resilience experience.\n\nUse fargate instead, it made EB obsolete.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:40:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1898a4",
          "author": "santhab",
          "text": "DMS is trash",
          "score": 42,
          "created_utc": "2026-01-23 12:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18ttrg",
              "author": "Icy_Tumbleweed_2174",
              "text": "Wondered how long Iâ€™d have to scroll to see this. If anyone has tried to use this with force this would be closer to the top. POS.",
              "score": 9,
              "created_utc": "2026-01-23 14:39:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19qwrf",
              "author": "wtf",
              "text": "So true. We had to work directly with their team and get a custom patch from them to get it working for us.",
              "score": 3,
              "created_utc": "2026-01-23 17:12:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19roak",
              "author": "AntDracula",
              "text": "It's so bad. Forget about it if you get an error. Just blow it away and try again from scratch.",
              "score": 3,
              "created_utc": "2026-01-23 17:15:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1afa8h",
              "author": "maddcox",
              "text": "I agree. It has a lot of problems for example CDC is useless for large production database replication. \nBut if you need to migrate db over from one system to another it is very useful. \nI was working on transfering very large outdated mysql from on prem to aws and I needed to have 0 downtime. It was running on Widnows so I couldnt use Percona Xtraboot so my only option was DMS. After a fee tries I got it to work and it saved me a lot of time.",
              "score": 3,
              "created_utc": "2026-01-23 19:02:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1ajfmj",
              "author": "joelrwilliams1",
              "text": "Works pretty well for us when we need it.  There a few glitches, but we tent to push through them.",
              "score": 4,
              "created_utc": "2026-01-23 19:21:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1ae1w0",
              "author": "saleableautumn5",
              "text": "It's gotten less terrible imo but it took a long time to get there.\n\nEdit: though I still wouldn't say it's not trash",
              "score": 1,
              "created_utc": "2026-01-23 18:57:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17mg69",
          "author": "-Melchizedek-",
          "text": "Pretty much the entirety of AWS IoT, unless you can guarantee that you will always and forever use it exactly like they intended (and that's very narrow). It's a mess, so many strange decisions like forcing immutability on a bunch of things that do not need to be immutable.",
          "score": 30,
          "created_utc": "2026-01-23 09:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1825pa",
              "author": "curiousEnt0",
              "text": "Do you suggest any better alternatives? If so, could you please explain why they are better?",
              "score": 5,
              "created_utc": "2026-01-23 11:58:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1865zh",
                  "author": "-Melchizedek-",
                  "text": "Depends what you need. If you need to handle OTA software updates and similar things something like Mender is a better solution. \n\nWe ended up rolling our own system for managing, updating and communicating with devices, with SWUpdate for actually handling updates. But there are platforms out there too.\n\nAWS IoT is probably good if your IoT are extensions of your AWS cloud infra, maybe, but I'm still not convinced.",
                  "score": 2,
                  "created_utc": "2026-01-23 12:26:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1eky6s",
                  "author": "burn_in_flames",
                  "text": "We rolled our own using MQTT servers on EC2 with load balancing and lambdas to handle events, provisioning etc.",
                  "score": 1,
                  "created_utc": "2026-01-24 10:29:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1a5p6u",
              "author": "bastion_xx",
              "text": "What are some of the immutable things? I'd agree that the AWS IoT services aren't getting more love (deprecation of Events, Analytics, FleetWise, Fleet Hub, etc.). I would say IoT Core, Rules Engine, and the general fleet provisioning services will be there a long time. And to your point, pretty much as-is.\n\nI will say they have rolled more features to the Rule Engine, early provider of TLS 1.3, and some other security features over time.\n\nThen there is Greengrass. v1. v2. Lite. lol.",
              "score": 2,
              "created_utc": "2026-01-23 18:19:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1epb5e",
                  "author": "-Melchizedek-",
                  "text": "IoT core has fields for things or thing groups that can never be updated once created, or more fields added. Something like that, was a while since I used it so I don't remember exactly.",
                  "score": 1,
                  "created_utc": "2026-01-24 11:08:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1a8g7o",
              "author": "x86brandon",
              "text": "I wouldn't say it's trash, it's just very opinionated.  It was fairly reliable for me when I used it.   Just, like you said, strongly opinionated on things that aren't aligned with our use case.  We launched some features on it, built some support services and eventually deprecated most of it in favor of our home grown stuff as we scaled.",
              "score": 1,
              "created_utc": "2026-01-23 18:32:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ep01a",
                  "author": "-Melchizedek-",
                  "text": "I did not say it is trash either, so. But yeah, pretty much exactly the same journey as we had.",
                  "score": 1,
                  "created_utc": "2026-01-24 11:05:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18cb6w",
          "author": "ppernik",
          "text": "Amplify - not even if it's necessary. Just migrate, run away or quit software development. It's a failed attempt at a Firebase competitor. Buggy, hard to work with in a team, undocumented edge cases, doesn't work well with IaC, and most importantly it fucking hides away the actual infrastructure used. Like you won't be able to access and tweak any of the Lambdas, S3 or CloudFront distributions used. I've spent so much time working around Amplify it's ridiculous.\n\nCognito - for such an integral service it's severely undercooked with tons of weird undocumented edge cases. Once you know your way around it, it's fairly reliable, but it's definitely frustrating to get there.",
          "score": 30,
          "created_utc": "2026-01-23 13:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18fscu",
              "author": "vyle_or_vyrtue",
              "text": "What do you recommend as alternatives?\n\nIâ€™m using cognito and amplify as part of a small saas, and I agree amplify keeps hitting walls. I havenâ€™t had issues with cognito but based on this thread, I need to do more research.",
              "score": 2,
              "created_utc": "2026-01-23 13:25:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18jkyr",
                  "author": "ppernik",
                  "text": "Cognito will work. Just be aware there can be weird edge cases. Given how integrated with the rest of AWS it is, if you're mostly or fully on AWS, it's worth it.\n\nAmplify - depends what you're hosting there. If it's a static web app, you'll be fine with an S3 + CloudFront combo. For Next.js, you're probably best off putting it in Docker and throwing it on Fargate or something similar. OpenNext didn't work well for me.\nFor Amplify backend it depends entirely on what you need, whether it's Lambdas, API Gateway, EC2, Fargate or a combination. I'm running a GraphQL server on Lambda + API Gateway combo and it's been working well. Moved away from AppSync, too. Everything Amplify CLI can create you can create yourself using CloudFormation, CDK or Terraform. Plus it's going to be more reliable.",
                  "score": 6,
                  "created_utc": "2026-01-23 13:46:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19w9r1",
          "author": "suur-siil",
          "text": "Redshift.Â  It just doesn't scale well beyond a certain point.Â  Every solution proposed is basically \"gib more money\" and doesn't improve anything.",
          "score": 12,
          "created_utc": "2026-01-23 17:37:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17mi5c",
          "author": "baronas15",
          "text": "Cognito. Yuck ðŸ¤¢",
          "score": 126,
          "created_utc": "2026-01-23 09:45:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17xjbq",
              "author": "ManBearHybrid",
              "text": "I know it used to be terrible, but I've heard there have been recent overhauls. Is it still bad?",
              "score": 16,
              "created_utc": "2026-01-23 11:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18p4te",
                  "author": "TheSpaceFace",
                  "text": "My favourite thing in Cognito, though I think they fixed it, is that the hosted login page would throw a weird error until you set up branding guidelines for it, like it wouldn't give you a default, it would just throw a weird 500 Error or something with no explanation xD",
                  "score": 12,
                  "created_utc": "2026-01-23 14:15:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18369p",
                  "author": "baronas15",
                  "text": "Last time I had to use it was 2 years ago. If they had massive changes, that would be great, but at the time competition was far better in comparison. And I bet it still is",
                  "score": 4,
                  "created_utc": "2026-01-23 12:05:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bco9f",
                  "author": "Fyunculum",
                  "text": "If by overhauls you mean adding a higher price tier that fixes some of the limitations then yeah.",
                  "score": 1,
                  "created_utc": "2026-01-23 21:39:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o192m28",
              "author": "IntermediateSwimmer",
              "text": "I actually disagree with this. It's good for what it does, but I think people expect it to do a lot more than what it was built for",
              "score": 17,
              "created_utc": "2026-01-23 15:22:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o194toa",
                  "author": "OGwadds",
                  "text": "Iâ€™m with you on this, no one ever has alternatives that are as close in pricing or not unnecessarily convoluted for the use case.\n\nItâ€™s certainly not perfect but it does enough and takes no time to set up.",
                  "score": 9,
                  "created_utc": "2026-01-23 15:32:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1dh7t3",
                  "author": "doyouevencompile",
                  "text": "It has a good set of features, but the process of getting set up is super convoluted, requires a lot of trial and error and it has poor CDK support.",
                  "score": 2,
                  "created_utc": "2026-01-24 04:50:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o19gddp",
                  "author": "PeteTinNY",
                  "text": "Thatâ€™s exactly the problem.   Customers have been very very vocal about what they need from cognito but AWS and all the product / specialists turn around and decline meetings giving a document that essentially gives a decision chart that says cognito is the wrong product. \n\nWhy not make the right product then?",
                  "score": 1,
                  "created_utc": "2026-01-23 16:24:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1874dx",
              "author": "Kralizek82",
              "text": "I find it to work well enough ðŸ¤”",
              "score": 13,
              "created_utc": "2026-01-23 12:32:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17uz92",
              "author": "SuperDooperX",
              "text": "Opened the thread just to make sure this was listed lol",
              "score": 28,
              "created_utc": "2026-01-23 11:00:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o186k9c",
                  "author": "Sensi1093",
                  "text": "What alternatively are as cheap as cognito?\n\nIâ€™m using it with ~5k users and it costs nothing. None of the competitors I have checked were free beyond like 100 users the last time I checked",
                  "score": 14,
                  "created_utc": "2026-01-23 12:29:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1avguv",
              "author": "kuda09",
              "text": "My only beef with Cognito is that you can't edit or delete custom attributes after a user pool is created.",
              "score": 10,
              "created_utc": "2026-01-23 20:18:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18zugs",
              "author": "atlasmountsenjoyer",
              "text": "Always heard people talk bad about it. Have used it in two large corporate apps and personal one..no issues so far. Maybe our case isn't all that complex though? Not sure what kinda issues you all run into?",
              "score": 7,
              "created_utc": "2026-01-23 15:09:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o181xb9",
              "author": "curiousEnt0",
              "text": "What are the best alternatives? And why?",
              "score": 3,
              "created_utc": "2026-01-23 11:56:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1av3tw",
                  "author": "kuda09",
                  "text": "Keycloak is pretty much flexible",
                  "score": 2,
                  "created_utc": "2026-01-23 20:16:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1b3l4v",
              "author": "Zenin",
              "text": "I use it constantly and have little issue with it, but my use cases might be different.  I work in corporate space mostly, not end user, so for me it's much more about hooking auth into ALBs, API Gateway, etc and linking that into Okta or Identity Center.\n\nGetting actual IAM credentials via Identity Pools on per-user basis is also a *HUGE* win architecturally for me as I can then use IAM directly to auth users by policy to API Gateway or direct writes to dynamodb, etc from the browser.  IAM policy based access controls and full audit traceability is a great win in my space especially vs trusting backend code to correctly handle RBAC decision trees.  My API code then only has to care about its actual task knowing the security is handled upstream.",
              "score": 3,
              "created_utc": "2026-01-23 20:56:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1a8tpw",
              "author": "x86brandon",
              "text": "Yup.  I launched some internal tools on it and then replaced it with a Rust/Actix based home made service.",
              "score": 2,
              "created_utc": "2026-01-23 18:33:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1dgl7l",
              "author": "TheMightyTywin",
              "text": "Prefer Auth0 or something else?",
              "score": 2,
              "created_utc": "2026-01-24 04:45:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1a49st",
              "author": "defel",
              "text": "I disagree. It can do everything, it works, is performant, the big issues from years ago are fixed.",
              "score": 2,
              "created_utc": "2026-01-23 18:13:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17ur7h",
              "author": "Safeword_Broccoli",
              "text": "Oh boy, someone suggested it to me yesterday. Why should I avoid it?",
              "score": 1,
              "created_utc": "2026-01-23 10:59:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1873w1",
                  "author": "ReturnOfNogginboink",
                  "text": "No multi region support.",
                  "score": 9,
                  "created_utc": "2026-01-23 12:32:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o188nr8",
                  "author": "pint",
                  "text": "just one example to get a taste of the service, but expect a lot of this:\n\nthe user can define multiple mfa methods, and optionally can select a default. if a default is selected, mfa choice is not offered at all, but the login flow automatically proceeds with the default one. there is no way to select another one at all. the user can change or remove the default only after a successful login. thus, if the method is temporarily not available, bad luck, the user can't log in. the conclusion is that you should never allow users to select a default method, the functionality is defective.",
                  "score": 10,
                  "created_utc": "2026-01-23 12:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o181zp0",
              "author": "mixxituk",
              "text": "My god the new British gov app is horrific for loginÂ ",
              "score": 0,
              "created_utc": "2026-01-23 11:56:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17ufjb",
          "author": "Beautiful_Spot5404",
          "text": "Amplify",
          "score": 24,
          "created_utc": "2026-01-23 10:56:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19r2am",
          "author": "AntDracula",
          "text": "REDSHIFT\n\nBecause even though it's like 12 years old, it still behaves as if it's a beta product.",
          "score": 19,
          "created_utc": "2026-01-23 17:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1awnei",
              "author": "DoINeedChains",
              "text": "And hasn't had any meaningful features added since Spectrum.  And is still based on an ancient PostgreSQL 9 core\n\nI kind of suspect the original engineers that forked PostgreSQL are no longer involved and the current team is just sustainingthe thing",
              "score": 9,
              "created_utc": "2026-01-23 20:24:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1b3xik",
              "author": "KipT800",
              "text": "Data sharing helps and you can create a multi cluster architecture â€¦.. but but but â€¦ yeah it is pants.Â ",
              "score": 1,
              "created_utc": "2026-01-23 20:58:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1fqvxh",
              "author": "wunderspud7575",
              "text": "And EMR and DMS. In fact really anything of their data analytics services is utter garbage. They really can't compete with Snowflake, Databricks, and all the other emerging SaaS offerings in this space.",
              "score": 1,
              "created_utc": "2026-01-24 15:16:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19dbh6",
          "author": "Ok_Whole_1665",
          "text": "Opensearch serverless. It sounds good on paper: Less management than a full Opensearch cluster and reduced cost due to serverless infrastructure.\n\nIn reality it's buggy, performance is lagging and it becomes \\_very\\_ expensive very quickly!",
          "score": 7,
          "created_utc": "2026-01-23 16:11:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1cynl1",
              "author": "mezbot",
              "text": "Im a big consumer of provisioned Opensearch, its reasonably priced and very barebones, perfect for a lot of my use cases.  But the serverless costs are insane.  They are way overpriced for the convenience, and by magnitudes.  Itâ€™s wild that shipping data to ElasticCloud, with egress charges out of AWS, can be cheaper and Elastic is superior for many use cases.",
              "score": 4,
              "created_utc": "2026-01-24 02:52:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19iv8q",
              "author": "BitterDinosaur",
              "text": "Expensive is an understatement.",
              "score": 3,
              "created_utc": "2026-01-23 16:35:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18pvsu",
          "author": "TwoWrongsAreSoRight",
          "text": "This one is very controversial but IMO Cloudformation.  It's a good idea in theory, in practice it's severely lacking and will cause you many hours of frustration.  A few examples of why I find it problematic. \n\n\\* It doesn't have any real state management so if someone changes something outside cloudformation, it won't pick up that change when you run the stack, no warning just silently ignore unless it conflicts and the whole stack will fail.\n\n\\* It treats the whole stack as a single entity so it'll deploy all or nothing.  Some consider this a pro, most just find it annoying because say for example you mistype a security group id you're referencing.  Instead of refusing to create the resource that relies on that group so you can quickly fix it, you need to wait for it to rollback (remove all changes in that stack, get to a good state (UPDATE\\_ROLLBACK\\_COMPLETE) and then you can try again.  That means depending on your stack size, it could take over an hour to fix that simple problem.\n\n\\* It can be difficult to figure out what actually went wrong during stack creation and depending on the state it ends up in, can be difficult to fix and sometimes require you to delete the stack and redeploy.  Another fun feature is the first time you deploy a stack, if it errors out, you have to delete the stack manually.\n\n\\* Some strange behaviors that aren't well documented.  Example: when changing a db subnet group, you remove subnets 1234 and 5678 and add 1919.  It will add 1919 but fail to delete the other 2 even if nothing is using them.\n\nI'm sure others will give many more examples.",
          "score": 34,
          "created_utc": "2026-01-23 14:19:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o197ref",
              "author": "dr_barnowl",
              "text": "It's bloody awkward to refactor as well, whereas refactoring Terraform configs is relatively easy.\n\nThe sole advantages of CloudFormation are\n\n- It's the \"official\" thing, which means all the docs and examples use it\n- There are lots of community examples in it\n- There's a cloud-side execution platform for it out of the box\n\n... on the other hand, it's relatively simple to port CF templates to Terraform\n\nCreating a cloud-side Terraform executor isn't super awful to do.\n\nSomeone will say \"CDK\" to which I say, CDK just generates CloudFormation which means it just generates all these problems faster.",
              "score": 14,
              "created_utc": "2026-01-23 15:46:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19jn1u",
                  "author": "chesterfeed",
                  "text": "Not really. Cdkv2 isnâ€™t a bijection to CFT",
                  "score": 1,
                  "created_utc": "2026-01-23 16:39:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o19xmno",
              "author": "blooping_blooper",
              "text": "yeah the delete thing is so annoying, like why can't I just push again after I fix the template errors instead of having to go in and delete the stack.",
              "score": 1,
              "created_utc": "2026-01-23 17:43:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1d6ekx",
                  "author": "KingJulien",
                  "text": "Thereâ€™s a flag that will delete it for you if it fails. And this only happens on the first deploy.\n\nI like cloud formation. Thereâ€™s no equivalent to stacks in terraform.",
                  "score": 2,
                  "created_utc": "2026-01-24 03:39:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1a8v5w",
              "author": "guterz",
              "text": "Itâ€™s really nice for general account bootstrapping though. I use it to deploy a stackset in my clients CFT delegated admin account to setup our access roles and terraform execution roles so any new account we create has the necessary permissions from the jump.",
              "score": 1,
              "created_utc": "2026-01-23 18:33:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1aw492",
              "author": "jesusrambo",
              "text": "Lambdas taking 2 hours to deploy when it has to create a new ENI ðŸ™ƒ\n\nThis is only tangentially/vaguely documented, and in like a single place",
              "score": 1,
              "created_utc": "2026-01-23 20:21:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1fdzka",
                  "author": "Moresty",
                  "text": "Creating lambdas is pretty fast nowadays in my experience. Deleting lambda ENIs takes ages, but I don't think it's Cloudformations fault",
                  "score": 2,
                  "created_utc": "2026-01-24 14:06:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o188lu3",
          "author": "candyman_forever",
          "text": "Glue, it basically just creates abstractions on top of Spark and doesn't let you do anything easily. It has weird python shell jobs you can run that are not using newer versions of python.",
          "score": 22,
          "created_utc": "2026-01-23 12:42:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18au04",
              "author": "leeharrison1984",
              "text": "Glue is such a strange beast. The UI looks like someone banged it out in a weekend as a POC and then went on holiday, never to return.",
              "score": 29,
              "created_utc": "2026-01-23 12:56:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19ryav",
                  "author": "AntDracula",
                  "text": "> I must go, my people need me",
                  "score": 3,
                  "created_utc": "2026-01-23 17:17:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ayy8t",
              "author": "DoINeedChains",
              "text": "Glue was clearly not designed by anyone who had any expertise in designing or managing ETL flows at scale",
              "score": 3,
              "created_utc": "2026-01-23 20:35:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19m2hg",
          "author": "Solopher",
          "text": "Cognito and Elastic Beanstalk",
          "score": 6,
          "created_utc": "2026-01-23 16:50:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19caza",
          "author": "SecureConnection",
          "text": "Cognito. They are not so good in user facing identities and access management, as demonstrated by AWS and Amazon sign ins.  \n\nCloudWatch is poor for what it costs. \n\nSecurity Hub. You end up needing to manage state for the different findings. It doesnâ€™t integrate with other AWS services without adding some Lambda spackle yourself. The API is terribly slow and rate limited.",
          "score": 10,
          "created_utc": "2026-01-23 16:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b6eh9",
              "author": "Contrandy_",
              "text": "\\+1 on SecurityHub issues. Very slow response rate and the rate limiting is terrible.",
              "score": 2,
              "created_utc": "2026-01-23 21:10:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bdv1f",
                  "author": "AWSSupport",
                  "text": "Hi there, \n\nI've sent our Support team your feedback about SecurityHub for further review. \n\n\\- Gee J.",
                  "score": 2,
                  "created_utc": "2026-01-23 21:44:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bd113",
              "author": "AWSSupport",
              "text": "Hi there, \n\nI have forwarded this feedback to our internal teams for further review. \n\n\\- Gee J.",
              "score": 2,
              "created_utc": "2026-01-23 21:41:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18d7k2",
          "author": "CanyonSlim",
          "text": "I recommend against using Control Tower even if you're starting fresh in AWS. There are some benefits to it, especially if you're unfamiliar with managing multiple AWS accounts in an environment, but its neither flexible nor robust, so you're likely going to put a lot of work into supplementing it anyway while being unable to change things that are locked down by the service.",
          "score": 10,
          "created_utc": "2026-01-23 13:11:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18rae7",
              "author": "k3mjay",
              "text": "What's the alternative?",
              "score": 3,
              "created_utc": "2026-01-23 14:26:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1b5tny",
                  "author": "Ihavenocluelad",
                  "text": "Put the minimum in control tower and organisations and apply the rest via iac/scps/bootstrapping",
                  "score": 6,
                  "created_utc": "2026-01-23 21:07:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o19yrfk",
                  "author": "CanyonSlim",
                  "text": "I don't think there is really one tool that quite does what Control Tower does, but that's for a good reason. Under the hood, Control Tower is just a bunch of existing AWS services stitched together, but with added restrictions because AWS doesn't want you changing too much.\n\nI would recommend getting familiar with underlying services that Control Tower relies on - AWS Organizations, IAM Identity Center, CloudFormation StackSets, etc - and building your own version of Control Tower that is suited to your exact needs and preferences. Even with Control Tower we've largely wound up doing that anyway.",
                  "score": 4,
                  "created_utc": "2026-01-23 17:48:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18bne9",
          "author": "dobby96harry",
          "text": "Inspector - but mostly due to costÂ ",
          "score": 8,
          "created_utc": "2026-01-23 13:01:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b6821",
              "author": "Contrandy_",
              "text": "Yeah especially if you use primarily lambdas, it's CRAZY compared to EC2-only scanning.",
              "score": 1,
              "created_utc": "2026-01-23 21:09:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cgswy",
                  "author": "dobby96harry",
                  "text": "Yup that's what got us to stop using it",
                  "score": 1,
                  "created_utc": "2026-01-24 01:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19r511",
          "author": "mattingly890",
          "text": "Code Commit \n\nIt was a zombie before, then they tried to kill it, now I think it is back to being a zombie.\n\nWe have a just a few legacy things that still have to go through code commit, and it is very unreliable.",
          "score": 4,
          "created_utc": "2026-01-23 17:13:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1avbip",
              "author": "JackBauerTheCat",
              "text": "Five or so years ago I helped a startup with their initial build out, so I used code commit just so everything was under one roof for whatever engineer they got to pickup the full time job.\n\n\nand that person was me. \n\n\n\nfirst project: move to github",
              "score": 2,
              "created_utc": "2026-01-23 20:17:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cefev",
                  "author": "_chrisdunne",
                  "text": "Now GitHub is down all the time and only care about AI",
                  "score": 1,
                  "created_utc": "2026-01-24 00:54:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19z095",
          "author": "Dej28",
          "text": "SES, because you have to do 3 backflips and spin around three times when the moon is a waning gibbous to get approval, and then it's still more of a pain in the ass than just using another provider",
          "score": 3,
          "created_utc": "2026-01-23 17:49:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d37jt",
              "author": "mezbot",
              "text": "Itâ€™s ok if you can even get approved for production usage.  But yeah, a Sendgrid or whatever account with better metrics and stuff is typically much better.  It almost seems like AWS doesnâ€™t want people to use SES, which is actually understandable.  Itâ€™s hard enough to stay off of blacklists with well managed email systems with SPF, DKIM, DMARC, etc these days.",
              "score": 3,
              "created_utc": "2026-01-24 03:19:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18m75y",
          "author": "intelignciartificial",
          "text": "Cloudformation its very akward",
          "score": 10,
          "created_utc": "2026-01-23 14:00:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18u6gp",
              "author": "distresssignal",
              "text": "This would be my choice. I have built things with Cloudformation in the past. It is rarely the best tool for the job. In my experience, it's a tool of convenience and it really isn't even great there.",
              "score": 2,
              "created_utc": "2026-01-23 14:41:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bexvc",
                  "author": "dazedmusiclover",
                  "text": "What other resources would you recommend instead?",
                  "score": 1,
                  "created_utc": "2026-01-23 21:49:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1891mv",
          "author": "BeyondLimits99",
          "text": "AWS Personalize\n\nIts also incredibly expensive",
          "score": 3,
          "created_utc": "2026-01-23 12:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19eo38",
          "author": "CheekkyNandos",
          "text": "App Runner - Itâ€™s handy for a quick PoC, but the limitations are frustrating.",
          "score": 3,
          "created_utc": "2026-01-23 16:17:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19xin2",
              "author": "nekokattt",
              "text": "Last I checked it capped apps at 100 concurrent calls, is that still the case?",
              "score": 1,
              "created_utc": "2026-01-23 17:43:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1el2r6",
                  "author": "CheekkyNandos",
                  "text": "I believe it does. The most annoying part for me is the inability to work with web sockets!",
                  "score": 1,
                  "created_utc": "2026-01-24 10:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1af1lf",
          "author": "saleableautumn5",
          "text": "The worst I've ever used is AWS Managed Workflows for Apache Airflow. \n\nExpensive and if you make it VPC only it becomes a nightmare to configure. I actually gave up on it after a week of trying and got self hosted running in half a day.",
          "score": 3,
          "created_utc": "2026-01-23 19:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ah6i0",
              "author": "AWSSupport",
              "text": "Sorry to hear about that experience with AWS Managed Workflows for Apache Airflow.\n\nIf you're interested in sharing ways that we can improve, feel free to submit your feedback these ways: http://go.aws/feedback. \n\n\\- Aimee K.",
              "score": 1,
              "created_utc": "2026-01-23 19:11:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1frpr3",
              "author": "wunderspud7575",
              "text": "Expensive is am understatement!",
              "score": 1,
              "created_utc": "2026-01-24 15:20:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1c6pcc",
          "author": "tonybenbrahim",
          "text": "Elastic beanstalk and aws batch, or any abstraction over ECS. It's a beginner s trap, and actually harder than ECS over time",
          "score": 3,
          "created_utc": "2026-01-24 00:12:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17xbyq",
          "author": "HighlightFrosty3580",
          "text": "Athena/Redshift/Glue. Fucking hate them all",
          "score": 13,
          "created_utc": "2026-01-23 11:20:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18e1di",
              "author": "titos_and_mojitos",
              "text": "Athena is good from my experience.\n\nRedshift is steaming shit. Literally try any other data warehouse solution and theyâ€™re all light years ahead of Redshit. Weâ€™d get random segfaults and assertion errors WITH NO CONTEXT.",
              "score": 20,
              "created_utc": "2026-01-23 13:16:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1azf97",
                  "author": "DoINeedChains",
                  "text": "> Athena is good from my experience.\n\nPresto/Trino are good.  Athena is just a wrapper around those that doesn't give you access to the underlying engine",
                  "score": 2,
                  "created_utc": "2026-01-23 20:37:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18a03q",
              "author": "vxd",
              "text": "Athena is great.",
              "score": 28,
              "created_utc": "2026-01-23 12:51:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o182jih",
              "author": "pazarr",
              "text": "Don't forget DMS. Absolutely unreliable. I have found critical bugs they are unable to solve and gaslighting me for half a year now. Memory leak forces me to restart CDC daily basis, otherwise it crashes every night.It's just the tip of the iceberg. Not production ready.",
              "score": 14,
              "created_utc": "2026-01-23 12:00:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18dpwf",
                  "author": "titos_and_mojitos",
                  "text": "Oh my god managing DMS was horrendous. We also were constantly restarting tasks, sometimes they would just â€œpeter outâ€ and do nothing (with no easy way of alerting!)\n\nI hope AWS really improves this shite software soon, it could be so useful.",
                  "score": 5,
                  "created_utc": "2026-01-23 13:14:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18321u",
                  "author": "HighlightFrosty3580",
                  "text": "Never used it but I can imagine. Think all AWSs data tools are shit. QuickSight more like QuickShite",
                  "score": 4,
                  "created_utc": "2026-01-23 12:04:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1fsfe9",
                  "author": "wunderspud7575",
                  "text": "I heard a rumour that DMS is just white labelled Qlik Attunity (or possibly replicate). My unfounded suspicion is that DMS is a really old version of that product that's never been updated since AWS licensed it, which is why it bitrots year after year. \n\nWhat a buggy piece of crap DMS is.",
                  "score": 1,
                  "created_utc": "2026-01-24 15:24:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o19lps9",
                  "author": "AWSSupport",
                  "text": "Hi there.\n\nApologies for the experience you've shared.\n\nIf you happen to have a support case, share it via chat message with additional details, so we can pass this along to our internal teams.\n\n\\- Elle G.",
                  "score": 1,
                  "created_utc": "2026-01-23 16:48:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18d67i",
              "author": "yourparadigm",
              "text": "Going to have to disagree with you on Athena. Some much cheaper to store our logs in S3, but still have them queryable. Sick of paying crazy expensive vendors just to search logs occasionally.",
              "score": 9,
              "created_utc": "2026-01-23 13:10:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19ctp6",
              "author": "Ok_Whole_1665",
              "text": "I find Athena as a service very useful in a lot of use cases.",
              "score": 5,
              "created_utc": "2026-01-23 16:08:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18ujr9",
              "author": "preinheimer",
              "text": "I hate athena's documentation, but I love the service.",
              "score": 3,
              "created_utc": "2026-01-23 14:43:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19s8ig",
              "author": "AntDracula",
              "text": "> Redshift\n\nAHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH",
              "score": 2,
              "created_utc": "2026-01-23 17:18:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d1x4c",
              "author": "mezbot",
              "text": "Athena is a godsend for not needing a database to run queries on files while storing the data cheaply.",
              "score": 2,
              "created_utc": "2026-01-24 03:11:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18w93q",
          "author": "mkmrproper",
          "text": "Hey AWS, nice try.",
          "score": 6,
          "created_utc": "2026-01-23 14:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19ff6x",
          "author": "adamousg",
          "text": "Bedrock Agents",
          "score": 2,
          "created_utc": "2026-01-23 16:20:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkwt8",
          "author": "Bad_Runner",
          "text": "CodeCommit, lack of features, bad performance",
          "score": 2,
          "created_utc": "2026-01-23 22:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dt0pc",
          "author": "EvenCriticism5244",
          "text": "EC2. I hate the overhead of deploying and maintaining servers. I prefer the serverless architecture using Lambda which can effectively work the same way as a full fledged server running 24*7.",
          "score": 2,
          "created_utc": "2026-01-24 06:18:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ashwe",
          "author": "Avocado_Infinite",
          "text": "Appstream",
          "score": 1,
          "created_utc": "2026-01-23 20:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bf2js",
          "author": "Fyunculum",
          "text": "Transfer Family is my personal pet peeve.",
          "score": 1,
          "created_utc": "2026-01-23 21:50:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cengz",
          "author": "_chrisdunne",
          "text": "Audit Manager was pretty shit when I tried it a few years ago.",
          "score": 1,
          "created_utc": "2026-01-24 00:55:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dia3i",
          "author": "thunderfroggum",
          "text": "How about SimpleDB",
          "score": 1,
          "created_utc": "2026-01-24 04:57:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1elt68",
          "author": "fts_now",
          "text": "DynamoDB and Amplify. Horrid",
          "score": 1,
          "created_utc": "2026-01-24 10:37:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1eui86",
          "author": "deadliftboi",
          "text": "Amplify x1000000",
          "score": 1,
          "created_utc": "2026-01-24 11:53:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fm9eq",
          "author": "Koyaanisquatsi_",
          "text": "all code\\* services",
          "score": 1,
          "created_utc": "2026-01-24 14:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fq6m6",
          "author": "wunderspud7575",
          "text": "EMR and Redshift. Two abandonware turds.",
          "score": 1,
          "created_utc": "2026-01-24 15:12:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o188hro",
          "author": "jkz88",
          "text": "CodeBuild and CloudFormation",
          "score": 1,
          "created_utc": "2026-01-23 12:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18vhe9",
          "author": "Dear-Walk-4045",
          "text": "Bedrock. It basically only works in us-east-1 for many of the features and the requests per minute rate limiting is low. Getting the limits raised is not easy. It will probably be better in a year or so.",
          "score": 0,
          "created_utc": "2026-01-23 14:47:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f3m20",
              "author": "CTOfficer",
              "text": "I am deep into the Bedrock ecosystem, and itâ€™s been an interesting journey. I like it, and there is a lot of capability, but can be frustrating and confusing. \n\nThe rate limits on one of my AWS accounts have been lifted, and I donâ€™t know how as I havenâ€™t requested it. But then on another account I canâ€™t even make a reasonable amount of requests without hitting a request limit. Iâ€™ve received nothing but boilerplate garbage response from AWS support, and instead have decided to hit the Anthropic APIs directly.",
              "score": 1,
              "created_utc": "2026-01-24 13:02:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18cx5j",
          "author": "Perryfl",
          "text": "RDS is overpriced... your not really getting a managed service just a configured one...\n\nEC2 you are paying 6 to 8 times the what it should cost to rent a dedicated server and your on essentially a glorified VPS.\n\nPremium support... cool i get to talk to a jr engineer in pakistan....\n\ncognito... 1 it sucks but its also expensive and auth is actually very easy to roll on your own...\n\nto not be too negative some great serives: sqs, sns, ses, eventbridge",
          "score": -11,
          "created_utc": "2026-01-23 13:09:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19yb07",
              "author": "blooping_blooper",
              "text": "If you hate AWS support you should try Azure, where they will tell you you're wrong because <insert answer they quoted from copilot>.",
              "score": 2,
              "created_utc": "2026-01-23 17:46:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19mhod",
          "author": "hudvin",
          "text": "Lambda. Extremely useful for handling spike loads, but for generic use cases itâ€™s a pain in the ass when it comes to deployment, development, and debugging.",
          "score": -6,
          "created_utc": "2026-01-23 16:52:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19ref6",
              "author": "Gasp0de",
              "text": "Why is it more painful than any other service? We deploy via terraform, log to Loki. You can even run lambdas locally to debug them.\n\n\nEspecially for interfacing with queues such as Kinesis or SQS I find it much easier than running code yourself that keeps Kinesis checkpoints etc.",
              "score": 2,
              "created_utc": "2026-01-23 17:14:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1d3tom",
              "author": "mezbot",
              "text": "It all depends, lambda is amazing for many use cases but is a square peg in a round hole for others.  However Iâ€™d disagree on dev and deployment, in fact in most cases itâ€™s usually the polar opposite.",
              "score": 1,
              "created_utc": "2026-01-24 03:23:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19pue0",
              "author": "Straight_Waltz_9530",
              "text": "CDK",
              "score": -2,
              "created_utc": "2026-01-23 17:07:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17myia",
          "author": "ducki666",
          "text": "Any. Why should I use it if not necessary?",
          "score": -15,
          "created_utc": "2026-01-23 09:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o190w4y",
          "author": "KayeYess",
          "text": "I would add R53 ARC (Application Recovery Controller) to the list. It is a complicated and expensive service that AWS pushed to customers because of limitations with R53 Contol Plane.\n\n\nAWS recently announced HA for R53 Public Hosted Zone control plane but with a 1 hour SLA, it's does not meet requirements for most enterprises.",
          "score": 0,
          "created_utc": "2026-01-23 15:14:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o197f7n",
              "author": "x86brandon",
              "text": "I would argue most enterprises don't have the software proficiency to use ARC or have multi-region redundancies.  A lot of software that is bought simply doesn't have the architecture to support multi-region active/active.  AWS isn't geared towards Enterprise, it's geared towards tech companies, which at this point, have considerably more infrastructure than your average F500 \"enterprise\".   Being able to recover on the other side of the country in under an hour surviving a control plane failure would be a dream come true for most.\n\nI'm not aware of another DNS provider that isn't single control plane design.  Cloudflare, etc.  Amazon's ability to guarantee a DNS control plane failover in under an hour is unique and a step up above anyone else.   Remember, this isn't a region redundancy, R53 is any cast globally.  This is so if the R53 control plane has issues, you can fail over to a secondary control plane of R53.",
              "score": 3,
              "created_utc": "2026-01-23 15:44:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17k034",
          "author": "elchicodeallado",
          "text": "API Destination, Bedrock, Step Function HTTP Task so literally every AWS managed service",
          "score": -15,
          "created_utc": "2026-01-23 09:21:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o182i59",
              "author": "curiousEnt0",
              "text": "Why Bedrock?",
              "score": 5,
              "created_utc": "2026-01-23 12:00:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17kr08",
              "author": "ApprehensiveBar7701",
              "text": "Canâ€™t even argue. Use them when they solve a real problem, not just because they exist.",
              "score": 1,
              "created_utc": "2026-01-23 09:28:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17rr14",
                  "author": "elchicodeallado",
                  "text": "not even sure why it got so many downvotes, people here probably donâ€˜t use these services in scale, but I faced only issues with those mentioned. With managed services I donâ€™t refer to lambda, dynamo etc. but with those higher level wrapper services AWS often build and then dont iterate on",
                  "score": 4,
                  "created_utc": "2026-01-23 10:33:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o190ame",
          "author": "yarrowy",
          "text": "Aws",
          "score": -10,
          "created_utc": "2026-01-23 15:11:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhutpm",
      "title": "If a person spends a billion dollars and buys all the compute on EC2 for today, what happens to the rest of the people requesting it?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "author": "PrestigiousZombie531",
      "created_utc": "2026-01-20 07:40:30",
      "score": 42,
      "num_comments": 69,
      "upvote_ratio": 0.77,
      "text": "- Just an honest question / showerthought, whatever you want to call it",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0mpzwk",
          "author": "Murky-Sector",
          "text": "Amazon would still limit your capacity. They would looove to setup all kinds of dedicated capacity just for you though, which you could use with wild abandon. For a price of course.",
          "score": 115,
          "created_utc": "2026-01-20 07:46:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mscs4",
              "author": "katatondzsentri",
              "text": "This. We actually use \"aws assisted capacity reservations\" which basically means they deployed a few racks with servers in the AZ we needed it.",
              "score": 31,
              "created_utc": "2026-01-20 08:07:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rgst7",
                  "author": "x86brandon",
                  "text": "Those aren't even deploying racks, that's just earmarking things in the scheduler.   Their large customers have earmarked fleet allocations and don't run into the same capacity problems as most.  And when you get big enough, you stop fussing with reservations, etc and just get a fixed EDP discount across all services and you generally will never see an unavailable error.  From experience anyways.",
                  "score": 11,
                  "created_utc": "2026-01-20 23:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0rgcuz",
              "author": "x86brandon",
              "text": "You don't need dedicated capacity.   Amazon simply limits spend in incremental amounts as a credit risk management.  Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.",
              "score": 7,
              "created_utc": "2026-01-20 23:47:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rlypo",
                  "author": "Murky-Sector",
                  "text": ">Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.\n\nI think its hysterical youre taking such great pains to analyze a hypothetical question about spending $1,000,000,000 on EC2. But ok.",
                  "score": -7,
                  "created_utc": "2026-01-21 00:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mpmrf",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 87,
          "created_utc": "2026-01-20 07:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oikm4",
              "author": "yarenSC",
              "text": "This would only be if somehow the account had gotten infinite quotas approved, which wouldn't be the case",
              "score": 12,
              "created_utc": "2026-01-20 15:28:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rftzz",
                  "author": "x86brandon",
                  "text": "Depends on the relationship, I have no limits on my accounts, but that's a 10 digit account spend.",
                  "score": -1,
                  "created_utc": "2026-01-20 23:44:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sjhbi",
              "author": "mr_jim_lahey",
              "text": "Kind of moot given account limits/quotas, and that the question is more generally about \"all the compute\", but I think it's possible AWS could provision a billion dollars' worth of on-demand instances in a single (major) region, assuming they were somewhat spread across instance types. Certainly they could accommodate it easily if spread across multiple regions. They have an unfathomable amount of capacity. $1B is like 1% of their ARR.",
              "score": 1,
              "created_utc": "2026-01-21 03:28:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqkhb",
          "author": "casce",
          "text": "It happens occasionally that AWS temporarily runs out of specific instance type in specific regions.\n\nWhat happens is you can't deploy new ones in that case but your running stuff is fine. Just don't stop and start it or you might be unable to start it again.\n\nThe same would happen if someone literally requested all of AWS' instances without AWS stopping them. AWS would most certainly stop them though (wouldn't be worth it to anger ALL other customers).",
          "score": 14,
          "created_utc": "2026-01-20 07:51:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w28xt",
              "author": "look_of_centipede",
              "text": "If you need to stop/start it, a brief capacity reservation can prevent someone from sniping it out from under you.",
              "score": 1,
              "created_utc": "2026-01-21 17:31:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mq6ph",
          "author": "No_Pomegranate7508",
          "text": "Reminds me of another similar question: \"Would you still love me if I were a worm?\"",
          "score": 26,
          "created_utc": "2026-01-20 07:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mpp3u",
          "author": "soundman32",
          "text": "The people who really need have paid for reserved instances for years ahead.",
          "score": 10,
          "created_utc": "2026-01-20 07:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mq8ke",
              "author": "Tall-Reporter7627",
              "text": "Like....if they bought a Dell server and stuffed it in their own rack, but at twice the cost?",
              "score": 3,
              "created_utc": "2026-01-20 07:48:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mqxsu",
                  "author": "Loko8765",
                  "text": "No. AWS allows you to reserve instances in advance. You actually pay a lower price, but of course you commit to the duration. If you know you will use it, it is win-win.",
                  "score": 7,
                  "created_utc": "2026-01-20 07:54:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0u47g2",
                  "author": "SlinkyAvenger",
                  "text": "More like two ISPs, two gateways, four switches, four firewalls, eight servers, two power connections, and two generators",
                  "score": 2,
                  "created_utc": "2026-01-21 11:14:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0msv40",
                  "author": "mba_pmt_throwaway",
                  "text": "2x the cost of a server isnâ€™t bad, actually. Just the ops overhead maintaining the servers + DC costs could cost more than the raw server costs. Ofc at a certain scale the math tips back in favor of self managing, but for most customers 2x would be great value.",
                  "score": 2,
                  "created_utc": "2026-01-20 08:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0nc08x",
              "author": "pint",
              "text": "yes, because, you know, there are no use cases where you need ephemeral instances. none.",
              "score": 1,
              "created_utc": "2026-01-20 11:09:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rh9ji",
              "author": "x86brandon",
              "text": "However, their billion dollar customers just get a flat discount and don't deal with this stuff at least.  EDP ends up being a revenue commitment and a flat discount off list without dealing with the micro managing of instance types, etc.",
              "score": 1,
              "created_utc": "2026-01-20 23:52:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0w31oe",
              "author": "look_of_centipede",
              "text": "Capacity reservations generally don't tie to long term cost, cost reservations generally don't reserve capacity.  There are edge cases but they're rare.",
              "score": 1,
              "created_utc": "2026-01-21 17:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqm02",
          "author": "vacri",
          "text": "System isn't set up for putting on that much compute at once - you'll run into Limits, and you're not going to be able to set them particularly high without satisfying AWS\n\nAssuming that it was all prepped beforehand and they could buy up the compute power and pay double the going rate to make it worth AWS's time, AWS still wouldn't do it because the damage to the brand by taking everyone's servers off them for 1 day would have many substantial customers fleeing to other vendors.",
          "score": 8,
          "created_utc": "2026-01-20 07:51:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rh2g1",
              "author": "x86brandon",
              "text": "System is set up for a lot of load.   Credit limits are not.  :)\n\nI have launched groups of 5,000 p4.24xd's at a time.",
              "score": 2,
              "created_utc": "2026-01-20 23:51:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0sqi2q",
                  "author": "Alborak2",
                  "text": "Ive probably seen the downsteam effects of that launch lol. ML workloads move sooooo much data around.\n\nAnd yeah your other comments about limits are right. If you have the keys to the castle we'll pretty much let you run until the physical capacity is gone. Not many of those around. Our internal test accounts are unlimited and will launch thousands of instances with 20+ EBS volumes on each.",
                  "score": 1,
                  "created_utc": "2026-01-21 04:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mt5c1",
          "author": "FlyingFalafelMonster",
          "text": "Insufficient capacity. Happens already for GPU instances. Unless you buy capacity reservations, then even if you do not use instance it still is reserved for you.Â ",
          "score": 7,
          "created_utc": "2026-01-20 08:14:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rizzh",
              "author": "x86brandon",
              "text": "For what it's worth, east-1 is the only place I see GPU issues...  the other regions I haven't had problems with since 2021.  west-2 I have very high launch rate success.",
              "score": 1,
              "created_utc": "2026-01-21 00:01:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vd1go",
                  "author": "nagyz_",
                  "text": "I haven't been able to reserve the p6 gb200. Does it show as reservable for you as in you get an actual time slot with a price?",
                  "score": 1,
                  "created_utc": "2026-01-21 15:38:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o10gn1t",
                  "author": "CategoryRepulsive699",
                  "text": "Try Australia",
                  "score": 1,
                  "created_utc": "2026-01-22 08:14:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qlnfz",
          "author": "ComplianceAuditor",
          "text": "You can't do that even with a billion dollars, because it would cause a lot more than a billion dollars in \"damage\" to their other customers if they suddenly have no capacity.\n\nIt's also not possible. There is no scenario ever, where AWS takes away an on demand instance from a customer just because another customer wants to use it.\n\nIdk why this is being downvoted though. Guess being curious is off limits for the internet.",
          "score": 5,
          "created_utc": "2026-01-20 21:13:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n1m87",
          "author": "TekintetesUr",
          "text": "Unfortunately nothing, doesn't matter how hard we try. In-use on-demand capacity will not be taken away from current users. Existing reservations won't be cancelled by a higher bid. Etc.",
          "score": 5,
          "created_utc": "2026-01-20 09:34:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rg41y",
          "author": "x86brandon",
          "text": "AWS has an internal allocation mapping.  A single customer and account can't hit the entire fleet.  And also, a billion dollars at retail prices would not actually consume the entire fleet.   Their fleet is probably much larger than you might imagine.",
          "score": 3,
          "created_utc": "2026-01-20 23:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p4pfm",
          "author": "Quinnypig",
          "text": "The more interesting version of this question revolves around spending that billion dollars in S3 storage. There are no known quotas around that.",
          "score": 5,
          "created_utc": "2026-01-20 17:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0muov0",
          "author": "danizumi",
          "text": "In the AWS management console, look at the Service Quotas page, each service has hard and soft limits for each service. You should definitely be looking at these limits before putting a service into a production environment to ensure you donâ€™t hit a limit, or at least be aware of the limits.",
          "score": 2,
          "created_utc": "2026-01-20 08:29:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nkrre",
          "author": "KayeYess",
          "text": "Quotas and other limitations will kick in long before a single customer can purchase and use even a small fraction of all the available resources.",
          "score": 2,
          "created_utc": "2026-01-20 12:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s2own",
          "author": "Sowhataboutthisthing",
          "text": "Nice try, Elon.",
          "score": 2,
          "created_utc": "2026-01-21 01:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s4cjx",
          "author": "Human-Job2104",
          "text": "Service Quotas will stop them.",
          "score": 2,
          "created_utc": "2026-01-21 02:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vsr0s",
          "author": "FinOps_4ever",
          "text": "All of the people who purchased ODCR's to properly cover their EC2 needs will all get substantial bonuses.\n\nBut the proper answer is account limits and usage quotas.",
          "score": 2,
          "created_utc": "2026-01-21 16:48:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thzu2",
          "author": "oscarolim",
          "text": "Billion dollars? Thatâ€™s like 5 instances for a week.",
          "score": 2,
          "created_utc": "2026-01-21 07:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mts6b",
          "author": "Complex86",
          "text": "This is impossible. Each family is not equal and it would be honestly really difficult for 1 person to consume 100% of instances across all zones in all regions",
          "score": 1,
          "created_utc": "2026-01-20 08:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rhg2n",
              "author": "x86brandon",
              "text": "Not to mention, a billion dollars probably wouldn't get you there.   :)",
              "score": 4,
              "created_utc": "2026-01-20 23:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mwzk3",
          "author": "Soccer_Vader",
          "text": "If you are consuming all of the instances that aws has available at any given point, and not reserved for any internal/external use case, you are spending some developing countries gdp in a day. They would love that tho.",
          "score": 1,
          "created_utc": "2026-01-20 08:50:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oinsm",
          "author": "plaaam",
          "text": "What type of question is that :skull:",
          "score": 1,
          "created_utc": "2026-01-20 15:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p0n8q",
          "author": "SpecialistMode3131",
          "text": "You can't buy it all precisely because that would be bad for Amazon's overall business, so they have limits across all services.",
          "score": 1,
          "created_utc": "2026-01-20 16:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ro677",
          "author": "Top-Shopping410",
          "text": "Keep getting out of capacity I guess. I had this issue when I worked for another cloud provider and we just waited for the hardware installed",
          "score": 1,
          "created_utc": "2026-01-21 00:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rpzjg",
          "author": "Storage-Proper",
          "text": "They would continue to sell it",
          "score": 1,
          "created_utc": "2026-01-21 00:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t3yg1",
          "author": "Burekitas",
          "text": "He won't be able to do that, he will need so much accounts and quota increase requests, it will take 20 years to get to that position. \n\n  \nBut if he did, people asking for EC2 will encounter issues, but in a couple of weeks AWS will fill the gap.",
          "score": 1,
          "created_utc": "2026-01-21 05:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tg5t0",
          "author": "suur-siil",
          "text": "They have the official quotas on your account, and all kinds of other hidden limits too.\n\nI used to have a quota of 20k across various instance-types in a fairly small region and ended up having interesting chats with AWS engineers after trying to spin up large jobs.\n\nThere's also reserved capacity for those who think ahead.",
          "score": 1,
          "created_utc": "2026-01-21 07:31:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tme95",
          "author": "alapha23",
          "text": "This happens all the time for c8g in where binance is running. And gpus as well.",
          "score": 1,
          "created_utc": "2026-01-21 08:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yd3yn",
          "author": "Expensive-Virus3594",
          "text": "Rest of the people will get insufficient capacity errors. This will trigger a severity 2 incident of not a sev 1. \n\nIn reality you canâ€™t make a huge allocation due to account level caps etc.  \n\nThis issue happens in AWS time to time  when something internally breaks.",
          "score": 1,
          "created_utc": "2026-01-21 23:57:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0znyge",
          "author": "plinkoplonka",
          "text": "Nothing. It's limited by account quota.",
          "score": 1,
          "created_utc": "2026-01-22 04:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10h936",
          "author": "CategoryRepulsive699",
          "text": "There are various limits including how much you can procure per second. But I do remember moving sliders in the internal UI that caused truckloads of equipment delivered into the datacenters...",
          "score": 1,
          "created_utc": "2026-01-22 08:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12h6t3",
          "author": "PeteTinNY",
          "text": "People get ICEâ€™d all the time.   Insufficient Capacity Error.   \n\nI helped a major broadcast network that wanted wanted to move their TV content from onprem to the cloud and we needed gpu instances.   Unfortunately there wasnâ€™t enough capacity and we had to work with the EC2 team for months to get things sorted.",
          "score": 1,
          "created_utc": "2026-01-22 16:12:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19gopz",
          "author": "messiah-of-cheese",
          "text": "In the early early days of AWS they had intel and amd CPUs for VMs and the intel CPUs were far superior for the same price, but the CPU was allocated randomly.\n\nAn engineer found he could request a VM and check if it was intel or amd, if it was amd he would discard it and if it was intel he would hold it.\nHe ended up with all the AWS intel VMs and all everyone else could get was amd.\n\nHe talked about it at the first AWS conference and while he was talking someone from the audience working for AWS had his account banned.\n\nEdit: I believe the guy worked for github and was an early employee. We had him as a contractor at our business, he told us the story at the pub.",
          "score": 1,
          "created_utc": "2026-01-23 16:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mqct9",
          "author": "lasthunter657",
          "text": "You cant buy all of them AWS have limit on how many EC2 you can have at the same time",
          "score": 1,
          "created_utc": "2026-01-20 07:49:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhotxo",
      "title": "Infrastructure as Software: Beyond Infrastructure as Code",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "author": "whudduptho",
      "created_utc": "2026-01-20 02:36:43",
      "score": 20,
      "num_comments": 17,
      "upvote_ratio": 0.65,
      "text": "I've been working on a topic over the last 4 years: building out infrastructure using AWS CDK through an SRE lens.\n\nBeing in the DevOps, SRE, and Platform Engineering domains, I kept asking myself why aren't all the key NFRs built into the constructs we use as golden paths? Focused on reliability and developer experience, I put together a construct library where services have cost-savings, reliability, security, and scalability baked in from the start.\n\nThis is where I want to introduce a phrase I'm calling Infrastructure as Software. The idea is that these constructs, with minimal input, can be stitched together to build fault-tolerant systems. I built this site as a forcing function to showcase what I've been working on, but more importantly it's how an SRE approaches building self-healing infrastructure.\n\nThere's still more to this project, but for now I want to introduce the philosophy of Infrastructure as Software as I continue to illustrate how these constructs work together to build autonomous systems.\n\nWould love to get the communityâ€™s input. \n\n[https://github.com/crmagz/cdk-constructs-library](https://github.com/crmagz/cdk-constructs-library)\n\n[https://thepractitioner.cloud/blog/infrastructure-as-software](https://thepractitioner.cloud/blog/infrastructure-as-software)\n\n[https://thepractitioner.cloud/guides/infrastructure-as-software/introduction](https://thepractitioner.cloud/guides/infrastructure-as-software/introduction)\n\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0lppjt",
          "author": "lost12487",
          "text": "This looks like a vibe-coded [SST ](https://sst.dev/docs/examples)with your opinion of the \"golden path\" baked in. It sounds like you generally have good ideas about the topic, but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.",
          "score": 43,
          "created_utc": "2026-01-20 03:26:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lv0i0",
              "author": "whudduptho",
              "text": "I believe you are referring to the site [https://thepractitioner.cloud](https://thepractitioner.cloud/blog/infrastructure-as-software). It uses [https://vite.dev/](https://vite.dev/). And no not vibe coded. Some of us actually know how to write software and use AI as the tool it is.\n\nThe project I'm discussing is a culmination of years of multi-region active-active systems building. If you know infra and can read code then taking a look at the constructs [https://github.com/crmagz/cdk-constructs-library/tree/main/packages](https://github.com/crmagz/cdk-constructs-library/tree/main/packages) shouldn't be an issue for you, but I don't believe you have.\n\nWhat this project offers is the same as Construct Hub but centralized, opinionated from an SRE/PE focus, and with minimal inputs needed.",
              "score": -16,
              "created_utc": "2026-01-20 03:56:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0lxtyl",
                  "author": "lost12487",
                  "text": "I'm not referring to your blog site, I'm referring to your obviously AI-generated source code.",
                  "score": 22,
                  "created_utc": "2026-01-20 04:13:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0pft5h",
              "author": "o5mfiHTNsH748KVq",
              "text": "> but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.\n\nwhy? you could always just read the code and make sure it does what you think it does. seems like unnecessary effort.",
              "score": -2,
              "created_utc": "2026-01-20 18:02:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pkdi1",
                  "author": "lost12487",
                  "text": "Because if you don't even put in the effort to remove the completely superfluous comments that the agent adds to functions then I'm not going to put in the effort to find out where else you were lazy.",
                  "score": 9,
                  "created_utc": "2026-01-20 18:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mdcaj",
          "author": "vincentdesmet",
          "text": "this topic would do much better on https://cdk.dev community channels \n\nSpecifically collaboration with OpenConstructs foundation may be interesting for you\n\nIâ€™m still stuck enabling TF teams to adopt L2, moving to L3 afterwards (my project is terraconstructs.dev and I am one of core maintainers for http://cdktn.io - the CDKTF fork)",
          "score": 9,
          "created_utc": "2026-01-20 05:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lsrns",
          "author": "behusbwj",
          "text": "Havenâ€™t looked at the code, but the concept is solid and this is how the big players use CDK internally. The reason you donâ€™t see libraries often is because the observability tends to be not worth abstracting when the whole company does it one or two ways.",
          "score": 3,
          "created_utc": "2026-01-20 03:43:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ifz",
              "author": "whudduptho",
              "text": "Thanks for the feedback. I have a few nice abstractions on the roadmap that really capture the IaS philosophy of building self-healing multi-region infra. Feel free to leave any additional feedback if you get a chance to read/use the constructs.Â ",
              "score": 1,
              "created_utc": "2026-01-20 04:55:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lm2bc",
          "author": "o5mfiHTNsH748KVq",
          "text": "I like that you included skills for the repo!",
          "score": -1,
          "created_utc": "2026-01-20 03:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ujp",
              "author": "whudduptho",
              "text": "Yes, force multiplier for sure. Iâ€™ll likely create a repo for some of these soon across TS/Go/Python and GitOps tooling.Â ",
              "score": -6,
              "created_utc": "2026-01-20 04:57:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qiehod",
      "title": "How are you segregating AWS IAM Identity Center (SSO) permission sets at scale?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "author": "sajed8950",
      "created_utc": "2026-01-20 21:41:12",
      "score": 17,
      "num_comments": 13,
      "upvote_ratio": 0.96,
      "text": "Hello everyone,\n\nI am looking for guidance on how organizations design and manage AWS IAM Identity Center (SSO) permission sets at scale.\n\n**Context**  \nOur AWS permission sets are mapped to AD/Okta groups. Some groups are team-based and have access to multiple AWS accounts. Team membership changes frequently, and we also have users who work across multiple teams.\n\nBecause access is granted at the group level, we often run into situations where access requested for one individual results in broader access for others in the same group who didnâ€™t need or ask for it.\n\nWe also receive a high volume of access change requests. While we try to enforce least privilege, weâ€™re struggling to balance that with operational overhead and permission set sprawl.\n\n**Discussion points**\n\n* How do you structure permission sets and groups to scale without constant rework?\n* Do you use team-based, job-based, or hybrid permission sets?\n* Do you create separate groups per account + team + job role, or use a different model?\n* Do you provide birthright access for engineers? If so:\n   * What does that access look like?\n   * Is it different in sandbox vs non-prod vs prod?\n* How do you determine what access a team actually needs, especially when users donâ€™t know what permissions they require?\n* How do you manage temporary access to a permission set? Do you use cyberark sca?\n* Who approves access to permission set groups (manager, app owner, platform, security, etc.)?\n\nAny real-world patterns, lessons learned, or â€œwhat not to doâ€ stories would be appreciated.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0quz2h",
          "author": "tlf01111",
          "text": "I do Identity Center at very large scale (15,000 team members,  5000+ groups, 400 aws accounts, etc.)\n\nUsing IdC in conjunction with standard fare static RBAC IAM permissions & group assignments will result in permission set sprawl at scale.   It just is what it is.     \n  \nWe use set of enterprise-wide console roles that are used for most daily access needs, but also provide account-specific permission sets which engineering teams can use to fine-grain their access if it is needed over above the standard roles.\n\nWe had to build quite a bit of custom code to automate a lot of this (based on CloudTrail events coming in from identity store), but a few years in it's working pretty well.\n\nWe also use customer managed policy references heavily to build more granularity:  With some planning you can grant differing permissions using the same permission set, depending on the target (useful for environment tiers in our case).  \n\nBut it could be better.   The next big milestone is to slowly move to an ABAC model where feasible, which should (in theory) help cut down the number of permission sets needed. \n\nAnyway if you have any specific questions feel free to ask.  I'll try to answer best I can.",
          "score": 6,
          "created_utc": "2026-01-20 21:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ub54i",
              "author": "Lazy-Bicycle-8504",
              "text": " When you say \"we\" do you talk about a whole team of x people just doing this as their daily work? Given your scale this sound like at least 1-2 seniors/architects and 3-5 juniors, is this correct?",
              "score": 2,
              "created_utc": "2026-01-21 12:08:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0y13ak",
                  "author": "tlf01111",
                  "text": "Team of three architect-level, we me doing most of the lifting, and my peer assisting.\n\n\nI have to stress we have extensive automation which handles nearly 100% of the day to day.Â  Â That automation was a six month build for this team.",
                  "score": 2,
                  "created_utc": "2026-01-21 22:53:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0v7ccb",
                  "author": "AWS_Chaos",
                  "text": "This is what I came to ask. And notice it took the team \"a few years\". Meaning at scale, this isn't a one man job. the move to ABAC must be daunting.",
                  "score": 1,
                  "created_utc": "2026-01-21 15:11:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qvhqr",
          "author": "bailantilles",
          "text": "We tend to use permission sets that are mapped to job role per account. Each job role and account is mapped to an AD group. Each AWS account has an owner, backup owner, and support group. Itâ€™s up to one of those constituencies to tell us what permissions each job role requires and who does each role. When the question arises of â€œthis person needs different access than others in their job roleâ€ we as them the question: Do we need to create a new job role for this person or do all the others in that group get the additional permission. In the end, itâ€™s up to them to keep track of all of that as they need to do user access audits quarterly for their application.",
          "score": 4,
          "created_utc": "2026-01-20 21:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuyca",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1i7lgo",
                  "author": "bailantilles",
                  "text": "About 80 accounts over 3 organizations and around 150 permission sets",
                  "score": 1,
                  "created_utc": "2026-01-24 21:58:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qxw34",
          "author": "Healthy_Gap_5986",
          "text": "It's all about defining an RBAC structure and having the discipline to stick to it. Define roles, determine what they need to do in what environments, create PermissionsSets for them then rolling them out. The roles should be enforcing your operating model. e.g.\n\nExamples.\n\nDeveloperSet\n\n* gets almost FullAccess in Dev environments only.\n* SCP whitelist only grants everyone access to specific services.\n* PermissionsBoundary prevents them from self escalating.\n\nTesterSet\n\n* Can read logs, maybe set some data sources.\n* Applies to Dev and UAT.\n\nDevOpsSet\n\n* Access to Prod. Can read logs, manage Support tickets etc.\n* No write access.\n\nAdminSet\n\n* AD group is empty and only used through an audting temporary elevation process.\n* * Prod.\n\nPlatformAdmins\n\n* Gods. Like domain admins. \n* This is you, and you don't get involved in operations. :)\n\nThe same User can be in one or more of the above roles. e.g. Developers and Testers because they are performing those roles. If someone asks for a permission that's not included in the roles above then they are often asking to circumvent the operating model, either because the model is deficient, in which case it needs fixed, or they are just cowboys. (e.g. I want to get into UAT to clickops something because our testing isn't complete and product owner is all over me).\n\nOn defining privileges. YOu tailor it to allow them to get \"quality\" work done quickly. So developers can do a lot in the dev environment, but after that we want the model encourage the maturity of the CICD. So no clickops after Dev environment. It should all be driven by CICD with testing etc all automated.",
          "score": 3,
          "created_utc": "2026-01-20 22:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuzgo",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0zv5ky",
                  "author": "Healthy_Gap_5986",
                  "text": "Tiny atm. 10 workload accounts + LZA platform accounts. Last place had 100+ accounts, pretty much the same model.",
                  "score": 1,
                  "created_utc": "2026-01-22 05:15:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qmmsj7",
      "title": "Latency numbers inside AWS",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qmmsj7/latency_numbers_inside_aws/",
      "author": "servermeta_net",
      "created_utc": "2026-01-25 15:55:38",
      "score": 16,
      "num_comments": 48,
      "upvote_ratio": 0.79,
      "text": "I consult for (what should be) one of the biggest AWS customer in Europe, and they have a very large distributed system built as a _modular microlith_ mostly with node.js:\n\n- The app is built as a small collection of microservices\n- Each microservice is composed of several distinct business units loaded as modules\n- The workload is very sensitive to latency, so modules are grouped together according to IPC patterns, modules that call each other often exists in the same micro service\n\nTo speak of numbers, atm they are running around 5-6000 fargate instances, and the interservice HTTP latency in the same zone is around 8-15 ms.\n\nIs this normal? What latency numbers do you see across containers? Could there be some easy fixes to lower this number?\n\nUnfortunately it's very hard to drive change in a big organization, for example one could try to use placement groups but the related ticket has now been blocked for 2 years already, so I would like to hear how would you tackle this problem, supposing that it's a problem that could somehow be solved.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qmmsj7/latency_numbers_inside_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o1my4cx",
          "author": "Ok_Study3236",
          "text": "are your metrics averaged across all instances between zones or even regions? 8-15 ms could be a totally reasonable number if half your traffic is intra-AZ and the other half inter-region\n\nmeanwhile since we are talking about nodejs here, how is the latency even being measured? at \"5-6000\" i'm assuming massive traffic scale or garbage implementation. if the latter, and you've linked in a few billion lines of third party JS code, 10 ms might simply be coming from actual CPU usage, or from waiting for a time slice on a heavily contended cpu or single core io loop\n\njust knowing the number you gave isnt enough to know whether the service is in poor shape or not",
          "score": 29,
          "created_utc": "2026-01-25 16:00:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1myd7o",
              "author": "servermeta_net",
              "text": "I'm talking only of latency within the same region.",
              "score": -1,
              "created_utc": "2026-01-25 16:01:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1n02uh",
                  "author": "Ok_Study3236",
                  "text": "so you're talking 10-12 ms of latency beyond what would be typical or expected. i'd probably be looking in your app stack before looking at networking as the cause, it's just too high if it's legitimately all intra-region stuff",
                  "score": 11,
                  "created_utc": "2026-01-25 16:09:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1nccgr",
          "author": "DancingBestDoneDrunk",
          "text": "AWS publish intra-zone latency metrics for each zone in all regions via their Network Manager > Infrastructure Performance page",
          "score": 15,
          "created_utc": "2026-01-25 17:01:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nk90j",
              "author": "Wilbo007",
              "text": "Honestly had no idea about this, thanks",
              "score": 2,
              "created_utc": "2026-01-25 17:35:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1p55ob",
                  "author": "DancingBestDoneDrunk",
                  "text": "It's funny that inter AZ latency actually can differ significantly. But if your in that space your probably using placement groups anywayÂ ",
                  "score": 1,
                  "created_utc": "2026-01-25 21:39:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1pdy8o",
              "author": "servermeta_net",
              "text": "Super cool! Is there a way to see this without AWS console, so I can share it with my manager?",
              "score": 0,
              "created_utc": "2026-01-25 22:18:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1n0zon",
          "author": "sirstan",
          "text": "\\> and the interservice HTTP latency in the same zone is around 8-15 ms.\n\nNeed some more information here.  Are you using TLS?  Plain HTTP will be faster (or HTTP to a local envoy proxy which then maintains TLS connections to the adjacent nodes).  Client side load balancing will be faster instead of load balancers.  Are you making cross-az calls?  I've seen customers deploy cross AZ, merge all the performance data, and chase variable response times.\n\nYou can create two Fargate containers in the same AZ and exposes a HTTP service between them and the response time will be <1ms.",
          "score": 10,
          "created_utc": "2026-01-25 16:13:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1n2r4x",
              "author": "servermeta_net",
              "text": "I think we are using TLS, because service calls have the HTTPS prefix.\n\n> You can create two Fargate containers in the same AZ and exposes a HTTP service between them and the response time will be <1ms.\n\nThis is what I did. I created an HTTP echo services using the company templates, I called it from another service and I can see the latency floating around 8-10 ms. Even worse when I add the echo endpoint to big services that are being used.",
              "score": 1,
              "created_utc": "2026-01-25 16:20:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1nuxdv",
                  "author": "sirstan",
                  "text": "I setup:\n\n1. A VPC.\n\n2. Two fargate tasks\n\n3. One is a poller, one is a HTTP hello world server (in go).\n\n4. The poller polls the endpoint every 5 seconds.\n\n  \nWith Route53 local-zone DNS, I get response times in 3.4ms (100 samples) ranging from 1.427ms to 4.254ms.\n\nWithout Route53 local-zone DNS (hardcoded the IP in the client) I get 2.5ms responses ranging from 2.4ms to 2.6ms.",
                  "score": 6,
                  "created_utc": "2026-01-25 18:20:05",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1p5nvp",
                  "author": "sirstan",
                  "text": "I moved the configuration I had below (fargate) to EC2 instances (just running Docker on c6g.medium's with a user script pulling the *same* server and poller from ECR) and the latency for the non-dns lookup version drops to 0.6ms.\n\nFargate seems to introduce significant (2ms) latency.",
                  "score": 1,
                  "created_utc": "2026-01-25 21:41:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1n2wmz",
          "author": "MmmmmmJava",
          "text": "Latency within AZ can easily be microsecond/sub millisecond. \n\nAre you sure your business logic/service time isnâ€™t the cause of your latency?",
          "score": 7,
          "created_utc": "2026-01-25 16:21:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1nclnq",
              "author": "DancingBestDoneDrunk",
              "text": "Agree on this. Same-AZ latency is more often than not sub milliseconds.Â AWS publish intra-zone latency metrics for each zone in all regions via theirÂ Network Manager > Infrastructure PerformanceÂ page",
              "score": 2,
              "created_utc": "2026-01-25 17:03:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1mxtws",
          "author": "Wilbo007",
          "text": "Well you didnt describe how latency is measured exactly.. is it ICMP latency? Or are you measuring something like http latency?",
          "score": 9,
          "created_utc": "2026-01-25 15:59:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1mxx51",
              "author": "servermeta_net",
              "text": "You are right, HTTP latency",
              "score": 2,
              "created_utc": "2026-01-25 15:59:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1mzkcn",
                  "author": "Wilbo007",
                  "text": "I would start by measuring ICMP latency between availability zones in that region, get thousands of data points then you can see a theoretical minimum latency. Other than that you could optimize the code, perhaps rewrite it in another language or use more performant libraries",
                  "score": 8,
                  "created_utc": "2026-01-25 16:06:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1n3uh6",
                  "author": "wise0wl",
                  "text": "Are you measuring this as time to first byte, averages of packet latency on the connection, or overall HTTP request execution time?\n\nWe use AWS as well, but network latency within an AZ is almost always sub millisecond. Between AZs itâ€™s more but not much more. Â How are you routing traffic between services? Load balancers increase latency, especially if they are L7 (ALB) or add TLS.\n\nIf you donâ€™t, I would recommend adding distributed tracing and per-route latency / throughput metrics would be helpful. OpenTelemetry is great. If you donâ€™t want to pay, the OpenTelemetry collector has auto-instrumentation using ebpf, and yes you can setup the collector along with your service in Fargate.\n\nhttps://opentelemetry.io/docs/zero-code/obi/",
                  "score": 5,
                  "created_utc": "2026-01-25 16:25:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1mzlqn",
                  "author": "do_until_false",
                  "text": "TLS? Are connections and tunnels reused?",
                  "score": 2,
                  "created_utc": "2026-01-25 16:07:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1ncyz6",
          "author": "DancingBestDoneDrunk",
          "text": "Have you verified that the measured latency is measured/logged correctly?\n\n\nHow does the services avoid crossing AZs when calling another service, assuming all services are multi AZ deployed?",
          "score": 2,
          "created_utc": "2026-01-25 17:04:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1onph6",
          "author": "znpy",
          "text": "> Is this normal?\n\nmeasuring http latencies means nothing, it's a dumb measure.\n\nwhen i did the measurements i did measure icmp (ping) latencies in eu-west-1 and they were around 100-200 microseconds in the same az and 300-400 microseconds across az.\n\nthe 8-15 msec are most likely due to the software taking too much to reply and too much stuff done between the skb struct in the kernel and what's running in userspace.",
          "score": 2,
          "created_utc": "2026-01-25 20:24:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1n5tde",
          "author": "Realistic-Zebra-5659",
          "text": "No thatâ€™s obsurdly slow. The network should be sub millisecond.\n\nItâ€™s not really enough information but maybe just bisect their setup. Start with a super simple setup with none of their stuff to see latency under 1ms, add custom stuff they are doing until you see what the problem is?",
          "score": 3,
          "created_utc": "2026-01-25 16:33:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ot4nc",
          "author": "XD__XD",
          "text": "oof node js single threads... that is alot of wasted compute",
          "score": 1,
          "created_utc": "2026-01-25 20:47:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1otdnx",
          "author": "XD__XD",
          "text": "I recommend you draw an architecture diagram and we can go through it.",
          "score": 1,
          "created_utc": "2026-01-25 20:48:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1psxqt",
          "author": "SpecialistMode3131",
          "text": "I'd get out of fargate onto EC2 machines under my direct control, and then size them appropriately, colocating everything that needs better latency.\n\nUsing a managed service means you live with the SLA it provides. This situation calls for direct management.",
          "score": 1,
          "created_utc": "2026-01-25 23:25:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1qpepf",
          "author": "alapha23",
          "text": "Use EC2 and EFA if itâ€™s really latency sensitive. Plus, use newer instance generations, they are physically closer",
          "score": 1,
          "created_utc": "2026-01-26 02:07:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1rwk2p",
          "author": "Ok-Data9207",
          "text": "10ms latency inter AZ is normal",
          "score": 1,
          "created_utc": "2026-01-26 06:32:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1nflyo",
          "author": "oneplane",
          "text": "For nodejs that is expected. The only way to make changes in such orgs is to separate implementation from infrastructure. Ensure service owners can specify placement and traffic considerations but the infrastructure (or platform abstraction) decides how that actually pans out. Also allows you to adapt and evolve without having to involve service owners for most changes. It's not that much different from SOLID principles inside software itself.",
          "score": 1,
          "created_utc": "2026-01-25 17:15:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1n4lk1",
          "author": "Old_Pomegranate_822",
          "text": "Can you experiment with deploying to ECS rather than fargate on a replica and seeing what effect that has? You could force all to be the same AZ, or even just on one single huge machine, to try to work out some theoretical maximums / minimums. Might help you prove whether it is networking or higher in the stackÂ ",
          "score": 0,
          "created_utc": "2026-01-25 16:28:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1pe9yz",
              "author": "servermeta_net",
              "text": "Another user in this thread did this and actually fargate adds quite a bit of latency (sub ms to 2-3 ms)",
              "score": 1,
              "created_utc": "2026-01-25 22:19:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qj132z",
      "title": "I made DynamoLens: FOSS desktop companion for DynamoDB",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "author": "rasjonell",
      "created_utc": "2026-01-21 15:35:32",
      "score": 12,
      "num_comments": 3,
      "upvote_ratio": 0.93,
      "text": "Iâ€™ve been building DynamoLens, a free and open-source desktop app for Amazon DynamoDB. Itâ€™s a non-Electron (Wails) desktop client that makes it easy to explore tables, inspect/mutate items, and juggle multiple environments without living in the console or CLI.\n\nHighlights:\n\n\\- Visual workflows to compose repeatable item/table operationsâ€”save, share, and replay without redoing manual steps\n\n\\- Dynamo-first explorer: list tables, view schema details, scan/query, and create/update/delete items and tables\n\n\\- Multiple auth modes: AWS profiles, static creds, or custom endpoints (DynamoDB Local works great)\n\n\\- Modern UI with command palette, pinning, and theming\n\nIf you want to try it: [https://dynamolens.com/](https://dynamolens.com/)\n\nRepo: [https://github.com/rasjonell/dynamo-lens](https://github.com/rasjonell/dynamo-lens) (free & open source)\n\nWould love feedback from folks who live in DynamoDB day to day, whatâ€™s missing or rough?",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0vcgsw",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16fx3m",
          "author": "OkSadMathematician",
          "text": "nice work. wails is solid choice over electron bloat. add batch operations and you got a winner",
          "score": 2,
          "created_utc": "2026-01-23 04:04:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vcgrk",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -2,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlm5iv",
      "title": "frugal log architecture",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qlm5iv/frugal_log_architecture/",
      "author": "running101",
      "created_utc": "2026-01-24 12:49:24",
      "score": 12,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "What is the most frugal log architecture in AWS? I asked with developing a 'standard' logging pattern / design for our business. I am considering sending the logs to CloudWatch then using firehouse kinesis to send the logs to s3 for long term storage. Or using grafana and s3 logs. \n\nWhat are some good options ?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qlm5iv/frugal_log_architecture/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o1f2d22",
          "author": "kondro",
          "text": "The $0.50/GB ingest with CloudWatch is often the killer. If you can log directly to Firehose, you can save a ton.",
          "score": 16,
          "created_utc": "2026-01-24 12:54:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1f94se",
              "author": "ReturnOfNogginboink",
              "text": "I second this",
              "score": 2,
              "created_utc": "2026-01-24 13:38:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1fdckx",
          "author": "BoostedHemi73",
          "text": "Iâ€™d love to hear some more ideas on this topic too.\n\nWeâ€™re currently exploring otel instrumentation in our applications (including frontend and mobile) to improve troubleshooting in support. Since weâ€™ll have those all centralized, Iâ€™m thinking weâ€™ll roll off archives to S3.\n\nWeâ€™re currently testing self-hosted OpenObserve for this. So far, so good. Itâ€™s written in rust, so the resource usage is extremely low.",
          "score": 10,
          "created_utc": "2026-01-24 14:02:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1hp18v",
              "author": "the_ml_guy",
              "text": "OpenObserve can store the logs directly to s3 and use them from there. So you don't need any other s3 archiving mechanism.",
              "score": 2,
              "created_utc": "2026-01-24 20:30:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1hv0io",
                  "author": "BoostedHemi73",
                  "text": "Very cool - thanks!",
                  "score": 1,
                  "created_utc": "2026-01-24 20:59:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1g7ybm",
          "author": "donkanator",
          "text": "If frugality is your main requirement, then it's hard to beat raw S3 with all of its pricing layers and lifecycle controls. \n\nIf you are ok replacing querying and insights with Athena queries, it's probably going to be the most economical.\n\nAnything in the middle will serve you as a point of convenience and it has to be important enough requirement to exist, like ease of aggregation or querying and insights over smaller dataset. \n\nI think cloud watch costs are primarily puts and queries. Storage is not the hugest concern.",
          "score": 6,
          "created_utc": "2026-01-24 16:36:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hsepu",
          "author": "CAMx264x",
          "text": "We tried someone new(Honeycomb) and are having a decent time with them. Definitely some more work compared to our old Elastic stack, but significantly cheaper and itâ€™s all OpenTelemetry, so we can move to a different tool if we donâ€™t like it in a few years. Awesome support too, dedicated Slack channel to ask questions in for our company.",
          "score": 3,
          "created_utc": "2026-01-24 20:46:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ggx4z",
          "author": "oneplane",
          "text": "Depends on how you need to read/access the logs. We usually do FluentBit to Kinesis and then either to S3 or OpenSearch. S3 for for low volume ad-hoc queries, OpenSearch for operational daily use.",
          "score": 2,
          "created_utc": "2026-01-24 17:16:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1i57x9",
          "author": "my9goofie",
          "text": "The cheapest logs are ones that you donâ€™t keep.  Just because you  can log, should you?",
          "score": 2,
          "created_utc": "2026-01-24 21:47:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1i99wp",
              "author": "running101",
              "text": "I donâ€™t make the rules on retention. Security says to keep everything.",
              "score": 1,
              "created_utc": "2026-01-24 22:06:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1j1uws",
          "author": "SpecialistMode3131",
          "text": "Echo the suggestions to skip cloudwatch - but be smart about it. There will be some applications that don't log crazy hard and benefit from more dashboarding and alerting.  That is, they are more mission critical or less stable generally. So for those, letting them keep some or all of the tools is the right plan, even economically, because incidents cost real money.\n\nI tend to think a standard one size fits all pattern is not wise if you actually want to be reasonably frugal - because time spent on incidents costs a lot, and this can quickly overwhelm your savings on paper.  \n\nAlso important is log retention timeline - even glacier costs more than zero. If you don't need the logs, delete them, don't just automatically downgrade their retention.  Getting the app owners to state plainly and simply what their needs are (and the business why) lets you bucket the log SLA sanely.\n\nIt's better to have a flowchart than a one size fits all rule IMO.",
          "score": 2,
          "created_utc": "2026-01-25 00:32:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1h1ep4",
          "author": "CrackaAssCracka",
          "text": "Depends on your ability and desire to self manage anything",
          "score": 1,
          "created_utc": "2026-01-24 18:44:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hfzu1",
          "author": "carshodev",
          "text": "The most frugal option is never going to be AWS, manually setup an instance (or multiple instances with k8s) and then have backups in object storage, this will be very frugal.  \n  \nYou need to instead look at what your requirements are first and scope according to that. How often will you access these logs, how much redundancy do you need, how many services are you logging for? First answer these questions then work backwards.  \n  \nSome things will be much 100x cheaper long term if you have 1000x the logs but take 10x the time to setup so if you have expensive developers they will cost more initially. Some things will be very simple to setup and if you have a small amount of logs the cost will be so small its irrelevant.  \n  \nFocusing on what costs the least can often cost much more in terms of time or due to incomplete solutions.",
          "score": 1,
          "created_utc": "2026-01-24 19:48:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1lajyu",
          "author": "Ok-Data9207",
          "text": "Just use groundcover it is byoc as well",
          "score": 1,
          "created_utc": "2026-01-25 09:28:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1lfqk2",
          "author": "dataflow_mapper",
          "text": "If frugality is the main goal, CloudWatch should be treated as a short term buffer, not the system of record. It gets expensive fast at scale. A common pattern is minimal retention in CloudWatch for operational debugging, then streaming everything to S3 as cheaply as possible and doing search only when needed.\n\nKinesis Firehose to S3 with compression and partitioning is usually the simplest and cheapest long term option. Athena on top of S3 for ad hoc queries beats keeping logs hot in a metrics system. Grafana is fine as a front end, but the real cost savings come from pushing cold data to S3 quickly and being disciplined about retention and sampling.",
          "score": 1,
          "created_utc": "2026-01-25 10:15:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1mkphn",
          "author": "ToneOpposite9668",
          "text": "You may want to read this -- [https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/](https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/)\n\n  \n[https://aws.amazon.com/blogs/mt/simplifying-log-management-using-amazon-cloudwatch-logs-centralization/](https://aws.amazon.com/blogs/mt/simplifying-log-management-using-amazon-cloudwatch-logs-centralization/)",
          "score": 1,
          "created_utc": "2026-01-25 14:58:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkmpal",
      "title": "Installation using SSM document vs EC2 userdata - which one is better?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qkmpal/installation_using_ssm_document_vs_ec2_userdata/",
      "author": "ashofspades",
      "created_utc": "2026-01-23 09:49:30",
      "score": 10,
      "num_comments": 9,
      "upvote_ratio": 0.82,
      "text": "Hey there,  \n  \nIâ€™m looking at this post about creating Azure DevOps agents running on an EC2 Auto Scaling Group:\n\n[https://aws.amazon.com/blogs/modernizing-with-aws/using-ec2-auto-scaling-to-manage-azure-pipelines-capacity/](https://aws.amazon.com/blogs/modernizing-with-aws/using-ec2-auto-scaling-to-manage-azure-pipelines-capacity/)\n\nOne thing I donâ€™t fully understand is the benefit of using EventBridge and an SSM document to install and start the agent.\n\nIn my opinion, this could have been done using EC2 user data as well.\n\nIs there a specific advantage to using SSM documents instead of user data in this approach?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qkmpal/installation_using_ssm_document_vs_ec2_userdata/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o17o2tj",
          "author": "OkSadMathematician",
          "text": "ssm gives you centralized management, logging, retry logic. userdata runs once at boot, ssm can re-run and update. ssm wins for fleet management",
          "score": 18,
          "created_utc": "2026-01-23 09:59:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1dyum1",
              "author": "itzlu4u",
              "text": "This.",
              "score": 1,
              "created_utc": "2026-01-24 07:07:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1h2w24",
              "author": "ashofspades",
              "text": "Actually i also want the script to run just once. So in that case would using userdata be better?",
              "score": 1,
              "created_utc": "2026-01-24 18:50:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1dn0z4",
          "author": "zenmaster24",
          "text": "you can do it both ways but i have found user data to be executed quicker than the ssm docs due to the reliance on the installation, configuration and registration of the ssm agent. you might want to keep that in mind if speed is a requirement",
          "score": 4,
          "created_utc": "2026-01-24 05:31:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o187ga8",
          "author": "safeinitdotcom",
          "text": "Sure it can be done using EC2 user data as well and, although simpler, it is more fragile. The reason they use EventBridge + SSM is mainly for control and reliability, not because user data canâ€™t do the job. :D",
          "score": 2,
          "created_utc": "2026-01-23 12:35:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1h2gxs",
              "author": "ashofspades",
              "text": "Thanks for the reply. Can you please care to explain how using userdata be fragile? Are there any chances of userdata not running?",
              "score": 1,
              "created_utc": "2026-01-24 18:49:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o18oi6u",
          "author": "menge101",
          "text": "I don't use Azure Devops agents, but I'd assume there is probably a third option where you create a base image that includes the agent rather than installing it at startup, which might be viable/preferrable for some use-cases.",
          "score": 3,
          "created_utc": "2026-01-23 14:12:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1h2pt9",
              "author": "ashofspades",
              "text": "Yeah thats what I also thought. This is just a question which came to my mind after going through the documentation. :)",
              "score": 1,
              "created_utc": "2026-01-24 18:50:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1k424f",
          "author": "RebootAllTheThings",
          "text": "I was just having this question after some discussions at work. \n\nI feel like UserData gives you the ability to fail a build if it doesnâ€™t complete all the steps so that if you have a set of required items, and one doesnâ€™t work for whatever reason, then you donâ€™t get your instance. Thinking things like security tooling, settings, etc. \n\nWish I had AWS Org/Control Tower for all of that management though.",
          "score": 1,
          "created_utc": "2026-01-25 04:05:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkjl43",
      "title": "ECS anywhere cluster strategy for on prem servers",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qkjl43/ecs_anywhere_cluster_strategy_for_on_prem_servers/",
      "author": "Full_Bee_920",
      "created_utc": "2026-01-23 06:36:51",
      "score": 10,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "My company has 200+ remote locations across the country with on-premises servers running our application. These servers basically serve our customers at those locations.\n\nWe intend to containerise these applications so we can have them managed centrally using ECS anywhere.\n\nThere are some strict requirements:\n\n1. The multiple servers on that location is designed to failover to the redundant servers only on that location (not cross location)\n\nIn terms of clustering setup, what is the best approach? Should I create one cluster per location? or group all my locations as one cluster? ",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qkjl43/ecs_anywhere_cluster_strategy_for_on_prem_servers/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o18951j",
          "author": "dataflow_mapper",
          "text": "I would strongly lean toward one cluster per location given those requirements. ECS Anywhere still treats a cluster as a shared scheduling and control boundary, so putting all locations into one cluster makes it much easier for something to accidentally cross a boundary you do not want crossed. Even if you add constraints, you are fighting the model a bit.\n\nOne cluster per site keeps failure domains clean and matches how your redundancy is designed. It also makes it easier to reason about capacity, deployments, and outages when something goes wrong at a single location. The tradeoff is more clusters to manage, but that tends to be an operational problem you can automate, while cross location blast radius is harder to undo later.",
          "score": 7,
          "created_utc": "2026-01-23 12:46:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17gj93",
          "author": "TheLargeCactus",
          "text": "Sounds like distributed scada? Likely for powerplants? In my experience, you significantly reduce your blast radius and points of failure by keeping these locations isolated, so why add a layer that unifies them on purpose?",
          "score": 1,
          "created_utc": "2026-01-23 08:49:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17l0l5",
              "author": "Full_Bee_920",
              "text": "yes pretty much. the thing is we have a central HQ and dev team that handles all the in-house software development and we need a reliable way to deploy these containers to all these locations and monitor their status",
              "score": 1,
              "created_utc": "2026-01-23 09:31:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1722fb",
          "author": "ducki666",
          "text": "Sounds like 200+ clusters.\nNightmare",
          "score": 1,
          "created_utc": "2026-01-23 06:41:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o182op0",
              "author": "owengo1",
              "text": "It seems much better than a single cluster.  \nYou can deploy cluster by cluster, manage failed ones etc.   \nA single cluster is a catastrophe waiting to happen. The wrong container, the wrong service configuration will automatically destroy 200 locations.   \nNote also that IaC ( terraform or other ) will have no issue managing 200 clusters",
              "score": 1,
              "created_utc": "2026-01-23 12:01:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18h4vh",
          "author": "aviboy2006",
          "text": "To decide your strategy, think about it using these two models:\n\n**thought model (how you organise)** imagine each location is a **small shop**.\n\n**- one cluster per location:** it is like having 200 different managers. it is very safe, but hard to talk to all of them at once.\n\n**- one big cluster:** like one manager for 200 shops. it is easy to manage, but if the manager gets sick, every shop stops.\n\n**- the middle path:** group shops into **districts**. maybe 10 clusters of 20 sites each. it is easier to manage, and if one district has a problem, the others stay safe.\n\n**Decision model (how you act local)** to follow your rule of \"local failover only,\" use **labels**. think of it like a **delivery truck**:\n\n\\- even if 10 shops are in one district (cluster), each box has a **home address** (a location tag).\n\n\\- if a shelf breaks in shop a, the box stays in shop a. it does not go to shop b because the address label does not match.\n\n**how to make your choice:**\n\n\\- check your team size: if you have a small team, \"200 managers\" (200 clusters) will break your workflow.\n\n\\- check your risk level: if \"one big cluster\" feels scary because a mistake kills everything, move toward the \"district\" model.\n\n\\- check compliance: sometimes the number of clusters depends on what compliance or security rules you need for each location. if one site needs different rules, it might need its own cluster.\n\nTrust the labels: remember that the cluster is for your management ease, but the label is what enforces your local failover rule.",
          "score": 0,
          "created_utc": "2026-01-23 13:33:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17dyfs",
          "author": "LemmyUserOnReddit",
          "text": "One k8s cluster",
          "score": -1,
          "created_utc": "2026-01-23 08:25:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18yri2",
          "author": "oneplane",
          "text": "I think your orchestration needs are better handled with Kubernetes, EKS Anywhere will work for that. As a bonus, you can also easily run that locally so development can get closer to deployed application semantics for a shorter dev loop.",
          "score": -1,
          "created_utc": "2026-01-23 15:03:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlwmm1",
      "title": "AWS L6 SA Interview Prep â€“ Had a Rough Loop + Layoff, Looking to Nail It This Time",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qlwmm1/aws_l6_sa_interview_prep_had_a_rough_loop_layoff/",
      "author": "MrFreezeToCold",
      "created_utc": "2026-01-24 19:39:48",
      "score": 10,
      "num_comments": 9,
      "upvote_ratio": 0.78,
      "text": "Hi folks,\n\nLocation: Netherlands. I have 12+ years of experience in cloud and enterprise architecture and I am preparing for a Senior Solutions Architect (L6) role at AWS (also considering MSFT).\n\nI previously went through an AWS loop and received feedback that one poorly handled question impacted my overall evaluation. This time, I want to be extremely well-prepared.\n\nMy current prep:\n\n* Building 15â€“20 strong Leadership Principle stories (deep dives, metrics, trade-offs)\n* Heavy focus on AWS-centric system design (and generic SWE design)\n* Reviewing SA-level customer scenarios, trade-offs, and failure stories\n\nI am looking for:\n\n* Mock interview partners (LPs and/or system design)\n* Recommendations for AI-based interview prep tools or platforms that allow repeated practice\n* Any advice from people whoâ€™ve cleared AWS L6 SA loops\n\nHappy to exchange mock interviews or pay for quality sessions. Thanks in advance!",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qlwmm1/aws_l6_sa_interview_prep_had_a_rough_loop_layoff/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o1hhanb",
          "author": "classicrock40",
          "text": "You've gone through it once, so you know what's coming. Answers don't have to be AWS centric and tbh might be better if they aren't.  Whatever your answer, you have no idea of all the expertise of the interviewer so never fake it. You know the answer or not. You can be very sure they know AWS.\n\nWhen answering in STAR, you always, always end with a data driven conclusion (time saved, $ saved, new sales, new revenue) or a cross team process improvement. Estimate or use a little poetic license. \n\nDoing your job is not diving deep nor is it learn and be curious nor is it bias for action, etc. They are looking for times you went above and beyond or outside your area.",
          "score": 17,
          "created_utc": "2026-01-24 19:54:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1kl5oq",
              "author": "MrFreezeToCold",
              "text": "Have all the Lp prepared with all those metrics. thanks for the advice.",
              "score": 1,
              "created_utc": "2026-01-25 05:56:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1iylsg",
          "author": "Aggressive_Optimist",
          "text": "I recently passed the L5 loop for AI based role in Amsterdam , I think the best thing I did was to spread the loop over 2 days instead of going through them in a single day.\nprep wise your plan sounds good, Â I had 2-3 Â stories per LP.Â \nPrepared a 2 page compilation of stories overview and crossed any that were discussed just to be sure not to repeat.\nI had little to no aws experience in particular ( mostly Azure ) so I made sure to atleast remember aws alternatives of azure services and try to showcase aws knowledge even if my answers were based on separate cloud experiences.\nAnd in a few rounds somehow conversation drifted towards aws new releases and I was fortunately prepared and actively contributed towards the discussion and felt that the interviewer was impressed.Â \nI was very bad at following the STAR structure and was even interrupted a few times ( this probably was ok at L5 level but might be a turn off at L6 ).\nOverall I felt that if you have a good number of stories and follow STAR, it's mostly a breeze atleast at L5 level.",
          "score": 2,
          "created_utc": "2026-01-25 00:15:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1klpmd",
              "author": "MrFreezeToCold",
              "text": "thanks. based on the impression/depth on the LP stories we are making, is that how a candidate is parked for l5/l6 ?",
              "score": 1,
              "created_utc": "2026-01-25 06:00:27",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1lcfyu",
                  "author": "Aggressive_Optimist",
                  "text": "In my case, I interviewed for a L5 role and got a L5 inclined. I have heard applicants getting a lower level inclination based on their interview performance. In my opinion L5 is an individual contributor role and L6 is more of a entry level technical leadership, so I assume the stories should reflect the same.",
                  "score": 1,
                  "created_utc": "2026-01-25 09:45:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1mmsm6",
          "author": "Vivid_Strawberry115",
          "text": "If you interviewed at Amazon before and theyâ€™re getting you in for another interview but different role, that typically means that you met the bar but the first role wasnâ€™t the best match. The fact that youâ€™re getting a second interview is very promising! Do what youâ€™re doing. Thatâ€™s excellent prep.",
          "score": 1,
          "created_utc": "2026-01-25 15:08:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1hj47t",
          "author": "Sirwired",
          "text": "I was very happy with the \"Interview Success System\" that I purchased from Day One Careers. (I'm totally not affiliated with them.)  I was inclined for an L5 TAM and L5 SA. (The overall SA interview structure is consistent between levels; they just have higher expectations for the higher level roles in regards to technical skill, scope of work, and scope of influence.)\n\nTo be clear, their prep materials are around the LP's, but there's not much you can do to prep for the tech parts of the loop; either you know the answers or you don't.\n\nI bought their main interview prep course, and also paid for their Job Description review, which provides a list of likely LP's so you aren't prepping for ones you don't need. I did not purchase their 1-on-1 coaching, or bother with AI Story analysis, but those are products they offer.\n\nThey also have a very-informative [YouTube](https://www.youtube.com/@amazoninterviewwhizzdayone503) channel with a ton of good content on it, and have a free live Q&A every Monday. (Their YouTube channel is horribly-named, but it's good stuff.)\n\nFor my LP's, I think I had about 45 pages of typed-up stories. (I didn't actually need to refer to my notes during my interview, but I did have a quick-reference-table that I used several times just to remind me of what was in my list of stories.) And I'm sure you know this, but you want to avoid re-using the same story more than once if you can at-all help it.\n\nThe one question that almost got me rejected during phone screen was \"What would you have done better if you had to do it all over again?\" in reference to the flagship project on my CV. That one kind of startled me, because it was in regards to a project I did that was a complete success; innovative, on-time, on-budget, profitable, and repeatable for other customers.",
          "score": -5,
          "created_utc": "2026-01-24 20:02:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qis9yz",
      "title": "Service recommendation",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "author": "Artistic-Analyst-567",
      "created_utc": "2026-01-21 08:15:57",
      "score": 9,
      "num_comments": 11,
      "upvote_ratio": 0.84,
      "text": "Hello folks,\n\nLooking for recommendations for storing and searching across a large volume of data\n\nWe basically have a flattened table structure that holds around 300 million records, probably close to 50 columns\n\nWe need to provide fuzzy text search on some fields, expecting fairly high queries per second volume, and latency has to be on par with synchronous api style (200ms up to 1s)\n\nWe were initially thinking about loading the data into our RDS Aurora (MySQL, r6g.xlarge) but i never dealt with that kind of data volume and i imagine the indexes will be massive and maintenance will be painful\n\nThen i thought about Dynamodb but the fuzzy search requirement ruled that option out\n\nNow thinking OpenSearch serverless might be a good candidate\n\nAnyone worked on a similar scenario? we don't expect that table to get much updates, maybe once a month at most",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0tkzyh",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 08:15:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tqhx8",
          "author": "proxwell",
          "text": "This is really squarely in OpenSearch's wheelhouse.\n\nYou have a high read/query to write ratio, high QPS, infrequent updates, and need to support fuzzy text search.\n\nWhile you could do this in Aurora, I think your experience would be very unpleasant relative to OpenSearch.  With Aurora, you'd have massive fulltext indexes, slow/unpredictable index rebuilds, and performance is likely to bog down quickly under concurrent fuzzy searches.  Also, the scaling story is pretty painful, as youâ€™ll hit IOPS, buffer pool, or CPU ceilings faster than expected.\n\nI think OpenSearch serverless is the way to go in your scenario.  You'll have a little less low-level control for a couple niche tuning settings, and you'll want to do some proactive cost estimation to make sure you know what you're on the hook for, but I still think serverless is the clear winner here.",
          "score": 12,
          "created_utc": "2026-01-21 09:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ujx36",
          "author": "dataflow_mapper",
          "text": "your instinct is pretty solid. RDS will work on paper but at that scale the index bloat and tuning pain usually outweigh the benefits, especially for fuzzy search. DynamoDB is basically out once you need flexible text matching. OpenSearch is the tool most teams land on for this pattern, especially with mostly read traffic and infrequent bulk updates. The key is modeling the index carefully and being very intentional about analyzers so you do not blow up query latency. If the data really is mostly append or monthly refresh, reindexing is manageable. I have seen similar setups hit your latency targets as long as the queries stay scoped and you resist turning every field into a fuzzy search field.",
          "score": 3,
          "created_utc": "2026-01-21 13:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umk1i",
              "author": "Artistic-Analyst-567",
              "text": "Very insightful, will keep those recommendations in mind\nI just saw that there is a dedicated ingestion service for OS serverless (OSIS), this will come in handy since the data will probably reside in S3",
              "score": 1,
              "created_utc": "2026-01-21 13:22:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uk25w",
          "author": "solo964",
          "text": "You're storing 300m records and need to support sustained high query volumes with predictable performance, so I would say that regular managed OpenSearch could be a better option. Run the numbers but it could be more cost-effective as well as improve query latencies. Downside is the higher operational burden.",
          "score": 3,
          "created_utc": "2026-01-21 13:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umrhk",
              "author": "Artistic-Analyst-567",
              "text": "Makes sense, it's probably worth running a couple of POCs and see what the trade-offs and cost implications are",
              "score": 1,
              "created_utc": "2026-01-21 13:24:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tqeks",
          "author": "Horciodedayo",
          "text": "RemindMe! -1 day",
          "score": 1,
          "created_utc": "2026-01-21 09:07:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqh1c",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-22 09:07:43 UTC**](http://www.wolframalpha.com/input/?i=2026-01-22%2009:07:43%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/o0tqeks/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Faws%2Fcomments%2F1qis9yz%2Fservice_recommendation%2Fo0tqeks%2F%5D%0A%0ARemindMe%21%202026-01-22%2009%3A07%3A43%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qis9yz)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-21 09:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ve5ce",
          "author": "TechDebtSommelier",
          "text": "300 million rows plus fuzzy text search is basically OpenSearchâ€™s whole personality, so your instinct there is right. Aurora will technically work but youâ€™ll hate your life maintaining giant text indexes and still miss your latency targets once QPS ramps up. DynamoDB is a non starter for fuzzy search unless you bolt something else on.\n\nOpenSearch Serverless fits well here since your data is mostly read heavy and rarely updated, but do budget time for index tuning and shard sizing because it is not magic. If you want boring and predictable performance at that scale, search engine plus source of truth in S3 or RDS is the usual pattern, not trying to force a relational database to cosplay as a search engine.",
          "score": 1,
          "created_utc": "2026-01-21 15:43:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wnhal",
          "author": "gwinerreniwg",
          "text": "What about S3 Tables and like Athena on top or maybe OpenSearch?",
          "score": 1,
          "created_utc": "2026-01-21 19:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tkzxv",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -1,
          "created_utc": "2026-01-21 08:15:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qimtwo",
      "title": "The architecture behind my sub-500ms Llama 3.2 on Lambda benchmark (it's mostly about vCPUs)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "author": "NTCTech",
      "created_utc": "2026-01-21 03:26:42",
      "score": 9,
      "num_comments": 8,
      "upvote_ratio": 0.8,
      "text": "A few days ago I posted a benchmark here showing Llama 3.2 (3B, Int4) running on Lambda with sub-500ms cold starts. The reaction was skeptical, with many folks sharing their own 10s+ spin-up times for similar workloads.\n\nI wanted to share the specific architecture and configuration that made that benchmark possible. It wasn't a private feature; it was about exploiting how Lambda allocates resources.\n\nHere is the TL;DR of the setup:\n\n**1. The 10GB Memory \"Hack\" is for vCPUs, not RAM.** This is the most critical part. A 3GB model doesn't need 10GB of RAM, but in Lambda, you can't get CPU without memory. At 1,769 MB, you only get 1 vCPU.\n\n* To get the **6 vCPUs** needed to saturate thread pools for parallel model deserialization (e.g., with PyTorch/ONNX Runtime), you need to provision **\\~10GB of memory**.\n* The higher memory also comes with more memory bandwidth, which helps immensely.\n* **Counter-intuitively, this can be cheaper.** The function runs so much faster that the total cost per invocation is often lower than a 4GB function that runs for 5x longer.\n\n**2. Defeating the \"Import Tax\" with Container Streaming.** Standard Python imports like `import torch` are slow. I used Lambda's **container image streaming**. By structuring the Dockerfile so the model weights are in the lower layers, Lambda starts streaming the data *before* the runtime fully initializes, effectively paralleling the two biggest bottlenecks.\n\n**The Results (from my lab):**\n\n* **Vanilla Python (S3 pull):** \\~8s cold start. Unusable.\n* **Optimized Python (10GB + Streaming):** \\~480ms cold start. This was the Reddit post.\n* **Rust + ONNX Runtime:** \\~380ms cold start. The fastest, but highest engineering effort.\n\nI wrote up a full deep dive with the Terraform code, a more detailed benchmark breakdown, and a decision matrix on when *not* to use this approach (e.g., high, steady QPS).\n\n[**https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/**](https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/)\n\nI'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks. Is the trade-off worth it for your use cases?",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0uj87e",
          "author": "Nater5000",
          "text": ">I'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks.\n\n\nWe ended up doing this for some image processing that was part of a REST API. Since that much memory/vCPU was overkill for the rest of the app, we ended up having to have two Lambdas with different memory configs that effectively ran the same code, with the smaller REST API Lambda calling the bigger image processing Lambda as needed. It generally worked, but was more of a headache than one would think at first glance.\n\n\nStill, interesting you managed to make this work in Lambda so effectively. I've played around with running small LLMs in Lambda with some success, so adding some of the details you mentioned might make a big difference.",
          "score": 2,
          "created_utc": "2026-01-21 13:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0unqzg",
              "author": "NTCTech",
              "text": "That is a perfect real-world example of this dynamic in action. Itâ€™s validating to hear you ran into the same CPU-bound constraints with image processing.\n\nRegarding the \"headache\" of splitting into two Lambdas (small router vs. big processor): I feel your pain on the operational overhead, but architecturally, **you absolutely made the right call.**\n\nThis is the classic serverless trade-off: operational complexity vs. execution efficiency. If you ran your lightweight REST API handler on that 10GB instance, youâ€™d be burning significant budget on idle vCPUs just waiting for network I/O. By decoupling them, you aligned the resource profiles to the actual work being done. It hurts to manage, but it's the correct design pattern for cost and performance.\n\nDefinitely give the container streaming setup a shot for your LLM experiments. The high vCPU count *really* shines when it can parallelize the layer download and the model deserialization simultaneously. Please let us know if you see similar gains.",
              "score": -1,
              "created_utc": "2026-01-21 13:29:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0uvv03",
                  "author": "Nater5000",
                  "text": "lol please, I really don't need the overly affirmative LLM-speak on reddit too",
                  "score": 6,
                  "created_utc": "2026-01-21 14:13:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0wo75z",
          "author": "OkSadMathematician",
          "text": "the vcpu angle is underrated. most people think of lambda memory as ram when its really a proxy for compute allocation. seen this same pattern work for build processes and data transforms where you overprovision memory just to get more cpu and end up paying less because runtime drops by 5x\n\ncontainer streaming is clever but i wonder about cache hit rates in production. if youre getting consistent traffic the warm pool keeps things fast anyway but for true sporadic workloads this makes sense. curious what your p99 looks like over a week vs just the cold start number",
          "score": 1,
          "created_utc": "2026-01-21 19:07:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x0167",
              "author": "NTCTech",
              "text": "Yeah, the memory CPU realization is the unlock. I use that same over-provisioning trick for batch jobs now; it feels wrong to throw 10GB at a 500MB process, but the runtime speedup usually makes the pricing math work out in your favor.\n\nOn the weekly P99 question that's the real reality check.\n\nIn my testing over a week with \"choppy\" traffic (enough gaps to trigger frequent cold starts, but some sustained bursts), my weekly P99 hovered around 550msâ€“600ms.\n\nItâ€™s actually slightly *higher* than the pure cold start benchmark (480ms) because real-world noise drags it up network jitters, DynamoDB latency on the lookups, etc.\n\nIf your traffic is totally sporadic (like one request every 2 hours), your P99 is basically just going to be that cold start number every time. But in a mixed workload, the warm starts (sub-100ms) drag the average down, while the cold starts define the tail.",
              "score": 1,
              "created_utc": "2026-01-21 20:01:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o183u84",
          "author": "SameInspection219",
          "text": "I am wondering why Rust is paired with ONNX instead of llama.cpp. Is there a specific reason for this?\n\nAlso, is the 3B limit for Lambda, or could it potentially support 7B models?",
          "score": 1,
          "created_utc": "2026-01-23 12:10:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh1n3l",
      "title": "SESv2 migration",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "author": "sloveubagukaraliui",
      "created_utc": "2026-01-19 11:23:20",
      "score": 8,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hi, I use terraform to manage aws deployments. \n\nSes is deployed using v1 api and now I want to migrate to v2. \n\nWhat are the steps? \n\nDo I destroy v1 resources first and deploy v2? \n\nwhat happens with dkim dns set up, would I need to configure new entries? \n\nI cant have any downtime, emails are a super critical part of our business. Switching to some other domain is not suitable due to need for warmup that can take up to 2 months. ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0gmwiv",
          "author": "CSYVR",
          "text": "They are the same resources, just with different APIs to configure them.\n\nYou can add the v2 resources and run imports gradually, there's not even a huge problem managing the two resources at the same time, as long as you're not making any changes.\n\nAlternative is just deleting the v1s from the state (terraform state rm <resourceid>) and importing the new ones (e.g.  terraform import aws\\_sesv2\\_email\\_identity.example [example.com](http://example.com) )",
          "score": 5,
          "created_utc": "2026-01-19 11:52:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jvjrr",
              "author": "sloveubagukaraliui",
              "text": "wait what\n\nare you saying that I should be able to create a v2 resource using the same domain alongside to an existing v1 domain identity?",
              "score": 1,
              "created_utc": "2026-01-19 21:34:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0jxdt7",
                  "author": "CSYVR",
                  "text": "Yes, just add and import it:\n\n    #v1 resource\n    resource \"aws_ses_domain_identity\" \"example\" {\n      domain = \"example.com\"\n    }\n    \n    #v2 resource\n    resource \"aws_sesv2_email_identity\" \"example\" {   \n      email_identity = \"example.com\" \n    } \n    \n    #Import statement for v2 resource so no new identity is created\n    import {\n      to = aws_sesv2_email_identity.example\n      id = \"example.com\"\n    }\n\nPretty simple once you get the hang of it :)",
                  "score": 2,
                  "created_utc": "2026-01-19 21:44:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0grhy6",
          "author": "shisologic",
          "text": "You can test the migration from ses v1 to ses v2.\n\nIf you can't create v1 using terraform, you can deploy it via AWS CLI ses (not sesv2).",
          "score": 1,
          "created_utc": "2026-01-19 12:28:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1clcuw",
          "author": "jsonpile",
          "text": "Something else that may help is the ses:ApiVersion condition key: \n\nhttps://docs.aws.amazon.com/ses/latest/dg/control-user-access.html#iam-and-ses-examples",
          "score": 1,
          "created_utc": "2026-01-24 01:34:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh10yo",
      "title": "AWS S3 Batch Replication (operation: replicate). Both buckets are versioned. What happens on object key collision?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "author": "IceAdministrative711",
      "created_utc": "2026-01-19 10:48:50",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "**Context**  \nI configure [S3 Batch Operation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html) (to replicate existing objects). Manifest is generated automatically and includes all objects. Both buckets are versioned. Batch Job is configured based on existing (Live) replication configuration.\n\n**Question**  \nI know that both buckets have one object with the same key but different versions. Which version will become current? Is there any documentation on that matter?\n\n\\---\n\n**PS**  \nI observed 2 behaviours:\n\n1. source object's version becomes current version in the Destination Bucket\n2. The Destination object version remains current while source object version is added to the non-current versions in the Destination Bucket\n\nI can only assume that it depends on \\`last modified\\` date and the newest version (be it source or destination) wins",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0hiji7",
          "author": "SpecialistMode3131",
          "text": "I think you're right about what will happen.\n\nMore importantly, you should change your system so this is never even an issue.  Just get rid of this problem.  There is no way this kind of complexity is benefiting you, and you will be able to eliminate it with some thought.",
          "score": 3,
          "created_utc": "2026-01-19 15:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0huxs1",
          "author": "menge101",
          "text": "Completely agree with /u/specialistmode3131 , this seems like an [XY problem](https://xyproblem.info/) as well.  \n\nWhat is it you are trying to do?",
          "score": 2,
          "created_utc": "2026-01-19 16:03:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj44kp",
      "title": "Does AWS close accounts for lack of use?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qj44kp/does_aws_close_accounts_for_lack_of_use/",
      "author": "mntgoat",
      "created_utc": "2026-01-21 17:24:33",
      "score": 7,
      "num_comments": 14,
      "upvote_ratio": 0.67,
      "text": "I got an email this morning saying my account is closed. This is a personal account that I don't use. I think I created it years ago. I do use my business account but that is a different account. The last email prior to this from AWS was 2022. Could it have been closed because of lack of use? \n\n\n\n>This e-mail confirms that the Amazon Web Services account associated with account ID XXXX is permanently closed and cannot be reopened. Any content remaining in this account is inaccessible and will be erased.\n\n>  \n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qj44kp/does_aws_close_accounts_for_lack_of_use/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0w7s4i",
          "author": "xxwetdogxx",
          "text": "Most likely you had something running, and at some point you got a new credit card- after failing to bill the old card AWS shut down the account for non-payment. AWS doesn't shut down accounts simply due to lack of use.",
          "score": 23,
          "created_utc": "2026-01-21 17:55:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wart0",
              "author": "mntgoat",
              "text": "It could be but I don't have any emails from them.\n\nI do remember I used have a charge of cents per month a while ago but I think I shut that down.",
              "score": 2,
              "created_utc": "2026-01-21 18:08:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w1jz2",
          "author": "DarthKey",
          "text": "No.",
          "score": 8,
          "created_utc": "2026-01-21 17:28:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w5iml",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear about your AWS account being closed. You can fill out the following form to contact our Support team for assistance with this: go.aws/account-support. \n\n\\- Gee J.",
          "score": 2,
          "created_utc": "2026-01-21 17:45:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wahwm",
              "author": "mntgoat",
              "text": "I did but they told me they couldn't help me without logging in but when I log in I just get message that it is closed and when I click on support it asks me to log in again.",
              "score": 6,
              "created_utc": "2026-01-21 18:07:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w2ipq",
          "author": "seanv507",
          "text": "I'm pretty sure the same thing happened to me.",
          "score": 1,
          "created_utc": "2026-01-21 17:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1054g1",
          "author": "Every-Barracuda-320",
          "text": "Billing billing... I have an AWS account I haven't used for 10 years and it's still active. They don't close accounts like that unless you don't pay. It could be just a few cents but if not paid, it can cause them to close the account but they sent many warnings before they do it.",
          "score": 1,
          "created_utc": "2026-01-22 06:33:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15ku8i",
              "author": "gadgetvirtuoso",
              "text": "I use SES personally and my bill is often just $0.01 many months and they never actually charge me. I donâ€™t know what the actual threshold is but Iâ€™d guess more than $1 otherwise they lose money on the CC processing fees.",
              "score": 1,
              "created_utc": "2026-01-23 01:08:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o161w03",
                  "author": "Every-Barracuda-320",
                  "text": "Same here. I had many of these $0.01 monthly bills but they were never charged. \n\nSometimes people miss services in other region. My previous company was getting high bills but they couldn't see many services to justify it. I went on exploring. They had a bunch of EC2 running in Singapore region. They were started months ago and forgot about them as they don't usually use that region./",
                  "score": 1,
                  "created_utc": "2026-01-23 02:43:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o121pb8",
          "author": "wesleyaplix",
          "text": "AWS generally doesnâ€™t close accounts *just* for inactivity. The fact that the email says â€œpermanently closed and cannot be reopenedâ€ makes it sound more like an internal compliance or billing trigger than simple lack of use.",
          "score": 1,
          "created_utc": "2026-01-22 15:00:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wjr8q",
          "author": "AWSSupport",
          "text": "Hi there, \n\nThanks for the quick follow up. Could you chat message us your case ID? We can provide your feedback to our Support team, and let them know about your case. \n\n\\- Gee J.",
          "score": -3,
          "created_utc": "2026-01-21 18:48:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wrfn7",
              "author": "mntgoat",
              "text": "Sure thing. Thanks.",
              "score": 2,
              "created_utc": "2026-01-21 19:22:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0x1yh5",
                  "author": "AWSSupport",
                  "text": "Hi Carlos, \n\nThanks for sending us your case ID. We're unable to discuss account details over social media for security purposes. I recommend working with our Support team on your support case for additional assistance. \n\n\\- Gee J.",
                  "score": -9,
                  "created_utc": "2026-01-21 20:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0w9lux",
          "author": "SoggyGrayDuck",
          "text": "They shut off access to ec2, you just have to change the root password and put a ticket in.\n\nEdit: I didn't read the whole comment, you must have waited longer than I did.",
          "score": -9,
          "created_utc": "2026-01-21 18:03:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi650u",
      "title": "How do you keep system context from rotting over time?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "author": "kennetheops",
      "created_utc": "2026-01-20 16:43:17",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 0.88,
      "text": "Former SRE here, looking for advice.\n\nI know there are a lot of tools focused on root cause analysis after things break. Cool, but thatâ€™s not whatâ€™s wearing me down. What actually hurts is the constant context switching while trying to understand how a system fits together, what depends on what, and what changed recently.\n\nAs systems grow, this feels like it gets exponentially harder. Add logs and now youâ€™ve created a million new events to dig through.. Add another database and suddenly youâ€™re dealing with subnet constraints or a DB choice thatâ€™s expensive as hell, and no one noticed until later. Everyone knows their slice, but the full picture lives nowhere, so bit rot just keeps creeping in.\n\nThis feels even worse now that AI agents are pushing a ton of slop ..i mean code and config changes quickly. Things are moving at lightspeed, I cant be the only one feeling like my understanding is falling behind daily.\n\nIâ€™m honestly stuck on how people handle this well in practice. For folks dealing with real production systems, whatâ€™s actually helped? Diagrams, docs, tribal knowledge, tooling, something else? ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0p00z3",
          "author": "SpecialistMode3131",
          "text": "You need to write real documents (preferably outside the codebase, as in wiki type environments) that pull together the business reasons for the system to exist, alongside the high level code decisions that were made.\n\nThere's a lot of different schools of thought - for example, my claim that putting docs outside the codebase is good will be disputed by some - but end of the day you cannot use a tool to skip taking the time to thoroughly describe your intent in laying out the systems as they exist now.\n\nDocs rot, too, so a dedicated hunk of time every week, month, etc to sweep your core foundational documents to ensure they're up to date is critical to keeping important stuff well understood and running.\n\nOnly you can decide if you have the will to do so - if it's important enough.  Just remember you reap as you sow.\n\nWhen I deliver for clients, I always leave behind a thorough high level documentation base for future maintainers, and when I am given existing legacy systems to deal with, building synthesis is the first order of business.",
          "score": 3,
          "created_utc": "2026-01-20 16:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p0yso",
              "author": "kennetheops",
              "text": "I like the idea of having the docs outside of the code base. \n\nWhat are you doing to capture info said in chat threads? Or do you assume this as a just a losing battle?",
              "score": 1,
              "created_utc": "2026-01-20 16:53:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0p1onv",
                  "author": "SpecialistMode3131",
                  "text": "Human beings are present in chat threads. Hold them accountable to putting the important content they learn down in the docs in a good way.  Make keeping docs in good shape part of their evaluation criteria at review time.\n\nThere is a tendency in tech to try and make everything a tool. When work requires judgment, as in documentation, that's a big mistake and it leads to a completely predictable decaying useless mess. Just refuse to make that mistake, and require human beings to own the documentation fully.  And keep the documentation high level so it doesn't become a burden.",
                  "score": 1,
                  "created_utc": "2026-01-20 16:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0p58ws",
          "author": "oneplane",
          "text": "What's helped is having responsibilities tied together, i.e. a change in some IaC is done for a reason, and depending on the size and complexity that reason (or intent) needs to be in the code, in the docs along side the code, in the global system docs or in business docs, or a mix of all of them.\n\nIn theory with static systems you'd be tracing from a business need to a functional need to a technical need to a requirement to a design to an implementation. In reality that doesn't really work out very often, but what you can do is apply the same rules as you'd do in namespaces/modules/packages/boundaries, things that only matter very close to the technical 'thing' and don't spill over into other areas (outside of its own boundary) would be in your commit message, code comments, or repository docs for example. You'd have to have rules and processes in place to not merge code that doesn't have an intent described and attached to it.",
          "score": 1,
          "created_utc": "2026-01-20 17:13:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pezrs",
              "author": "kennetheops",
              "text": "Is this a process or do you use a tool for this?",
              "score": 1,
              "created_utc": "2026-01-20 17:58:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pzasq",
                  "author": "oneplane",
                  "text": "We use Atlantis, OPA and a custom coverage tool to only allow a Terraform apply if coverage on the PR is over 90%, we're experimenting with doing more in a workflow pipeline but it's mostly an optimisation rather than a change in features.\n\nSimilar results can be achieved with pre-commit.",
                  "score": 1,
                  "created_utc": "2026-01-20 19:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0panru",
          "author": "dr_barnowl",
          "text": "Descriptive code.\n\nThe slopcode is a problem for this approach.\n\nWrite abstractions that help you comprehend things. That's basically what all code is once you stop writing raw machine code as byte values into memory.\n\nOnce I get a project started, I don't write a VPC by writing all the little ins and outs. I have a module. I say \"this is VPC #23, it's for this\". The code works out the CIDR blocks from the VPC number, and the module has a standard structured output that application modules expect to see, that describes the available subnets, etc. I just pass this output to the application module which is written to use it.\n\nLook at the top and you can see a VPC, an application, a link of the VPC to the transit gateway. Dig down and you can see the detail, which you make as consistent as possible so it's understandable.\n\n(NB CloudFormation sucks at this, Terraform is much better).",
          "score": 1,
          "created_utc": "2026-01-20 17:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0peupd",
              "author": "kennetheops",
              "text": "we are doing this for infra, but how are you tracking code dependencies  to infra resources? For example say we have 2 dbs but 1 db is dev and the other is prod, and 10 vms. Obviously the prod vms have a higher risk for changes than the dev vms.",
              "score": 1,
              "created_utc": "2026-01-20 17:58:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0qf9db",
                  "author": "dr_barnowl",
                  "text": "Prod vs dev my choice would always be account separation ; setting up cross-account deployment involves some extra work, but in an ideal world, no dev has access to production resources. The clearest way to ensure this is to ensure they have no access to entire accounts.",
                  "score": 1,
                  "created_utc": "2026-01-20 20:44:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qllr1d",
      "title": "Has anyone successfully run IPv6-only EC2 instances hosting a service?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qllr1d/has_anyone_successfully_run_ipv6only_ec2/",
      "author": "damiano81",
      "created_utc": "2026-01-24 12:28:32",
      "score": 6,
      "num_comments": 6,
      "upvote_ratio": 0.88,
      "text": "I spent the last few days trying to set up an IPv6-only instance to avoid NAT Gateway costs... It didn't go well.\n\nIssues I hit:\n\n* Boot times jumped to 5+ minutes (cloud-init timeouts on IPv4 metadata endpoints)\n* SSM Agent doesn't work\n* S3 gateway endpoints default to IPv4 (easy to miss that checkbox)\n* GitHub doesn't support IPv6, so can't pull container images or clone repo\n*  Most third-party APIs and services are IPv4-only\n\nI ended up switching back to IPv4 after realizing I'd need proxy infrastructure for half the services I use.\n\nIs anyone actually running IPv6-only successfully? What's your setup? Am I missing something obvious, or is the ecosystem just not there yet?\n\nCurious if this is a \"me problem\" o",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qllr1d/has_anyone_successfully_run_ipv6only_ec2/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o1fb5db",
          "author": "shinjuku1730",
          "text": "GitHub still doesn't support IPv6. Yes, it's embarrassing.",
          "score": 5,
          "created_utc": "2026-01-24 13:50:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1fws0i",
              "author": "PreciselyWrong",
              "text": "They can't afford the 5 minute time investment of adding AAAA dns records",
              "score": 2,
              "created_utc": "2026-01-24 15:45:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1g0x9o",
          "author": "justin-8",
          "text": "Add the `export AWS_USE_DUALSTACK_ENDPOINT=true` environment variable at the top of your metadata/cloud init/whatever and then most things will just work with no extra work. Also add it to your /etc/environment so it'll apply to everything.\n\nSSM just doesn't work though, and that sucks.",
          "score": 3,
          "created_utc": "2026-01-24 16:04:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1g0bw6",
          "author": "Mishoniko",
          "text": "Good reference information for AWS services on IPv6 (but double-check, some info might be dated):\n\n[https://tty.neveragain.de/2024/05/20/aws-ipv6-egress.html](https://tty.neveragain.de/2024/05/20/aws-ipv6-egress.html)",
          "score": 2,
          "created_utc": "2026-01-24 16:01:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fatlw",
          "author": "kei_ichi",
          "text": "1. EC2 metadata endpoints do support IPv6 so can you tell me why you get the timeout error?\n\n2. My EC2 in IPv6  only subnets working perfectly with SSM so I have no idea why you said that!\n\n3. Iâ€™m not sure about this because Iâ€™m using interfaces endpoint but I remember the docs did mention they will work even with IPv6\n\n4. You should check this first, or any service you have or will to communicate with! 100% your fault\n\n5. Yes! Same as No.4",
          "score": 3,
          "created_utc": "2026-01-24 13:48:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1g7c3h",
          "author": "aataulla",
          "text": "Support for v6 is PITA for any reasonably complex non monolithic system. supply and demand issue at heart and you can forget about IPv6 for the near future. \n\nThe only way you're going to get adoption and reasonable support is if a v4 addree\nss suddenly cost a lot more - a heck of a lot more. Or the large players force adoption (similar to SSL). \n\nAt 5 bucks a month its an annoyance that most will tolerate. At 50 bucks a month per ip customers will scream and demand better v6 support. \n\nIt'll happen when it happens but till then the value conscious clients will have to be the beta testers for everyone else.",
          "score": 0,
          "created_utc": "2026-01-24 16:33:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qhx8d0",
      "title": "Looking for feedback for my CDK approach",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhx8d0/looking_for_feedback_for_my_cdk_approach/",
      "author": "thexavikon",
      "created_utc": "2026-01-20 10:07:03",
      "score": 6,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "I usually work on small projects that share the same AWS stack (dynamodb, lambda, cognito, sqs, s3).\n\nI made a starter template for myself to standardize that.\n\nLooking for feedback if this is a good approach, or if there are better way to do this.   \nI have read people criticizing CodePipeline. Should I move to Github actions instead for the CI/CD pipeline?\n\nHere's the repo: [https://github.com/rohankshah/cdk-starter-template](https://github.com/rohankshah/cdk-starter-template)",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qhx8d0/looking_for_feedback_for_my_cdk_approach/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0n6nms",
          "author": "TurboPigCartRacer",
          "text": "if you plan on sharing it as a starter template i would focus on the structure and configuration of the tools that make a starter worth using instead of supplying it with random constructs (maybe one construct to show as example would be fine). codepipeline for ci/cd is really niche, if you plan on hosting the repo in github it might make more sense to utilize what github has to offer with actions.",
          "score": 1,
          "created_utc": "2026-01-20 10:22:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0naddl",
              "author": "thexavikon",
              "text": "Thank you for your feedback! I guess it's time to move away from code pipeline. I have noticed more people are using Github Actions.",
              "score": 1,
              "created_utc": "2026-01-20 10:55:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0nosm1",
                  "author": "cachemonet0x0cf6619",
                  "text": "this would be my preference. if you need to run your pipeline in your account you can use codebuild as a github actions runner.",
                  "score": 1,
                  "created_utc": "2026-01-20 12:46:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0npz1x",
          "author": "cachemonet0x0cf6619",
          "text": "This is a good start. my only two points of feedback is that you might want to consider separating stacks by volatility. think about separating into stateful and stateless. stateful is things like your db table and your queue. stateless would be your lambdas. \n\nyou have two choices with that. nested stacks or using string parameter names and import existing resources. \n\ntwo, your constructs arenâ€™t composable at all. your queue construct doesnâ€™t allow me to configure it. allow a user to pass some things into the construct like the visibility timeout or something. \n\noh, and finally donâ€™t name anything. you force a name into your queue. names are for pets. use tags for that stuff and let cdk create dynamic names for you. this makes replacement easier in the future.",
          "score": 1,
          "created_utc": "2026-01-20 12:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nzuuv",
              "author": "thexavikon",
              "text": "Thank you so much! This is very useful for me. \n\n>you have two choices with that. nested stacks or using string parameter names and import existing resources.\n\nI'm not really sure how to go about this.\n\nBut point 2 and 3 are something I will definitely implement.",
              "score": 1,
              "created_utc": "2026-01-20 13:51:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0odd17",
                  "author": "cachemonet0x0cf6619",
                  "text": "look it up. whatâ€™s the tradeoffs of using cdk nested stacks and using string parameters to share resources. youâ€™ll want an educated answer to this question",
                  "score": 1,
                  "created_utc": "2026-01-20 15:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1f5fsl",
              "author": "thexavikon",
              "text": "I had one more question. Just so I can get it right.  \nLet's say I split the stacks into stateless and stateful. Now when I redeploy with cdk after changing a lambda (stateless), then do I `cdk deploy statelessStack` or do I `cdk deploy --all`?\n\nThe stateful stuff is set to retain. So is it good practice to redeploy everything or just the thing that has changed?",
              "score": 1,
              "created_utc": "2026-01-24 13:15:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1fjgm8",
                  "author": "cachemonet0x0cf6619",
                  "text": "thatâ€™s a good question. cdk will go though the deployment but only deploy things that have changed so you can safely deploy all of them and aws will know how to build the resources",
                  "score": 1,
                  "created_utc": "2026-01-24 14:37:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}