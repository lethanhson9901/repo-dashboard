{
  "metadata": {
    "last_updated": "2026-02-13 03:16:08",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 159,
    "file_size_bytes": 174154
  },
  "items": [
    {
      "id": "1r0ufs2",
      "title": "Localstack killing community edition - what do we do?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "author": "xenographer",
      "created_utc": "2026-02-10 07:31:10",
      "score": 68,
      "num_comments": 54,
      "upvote_ratio": 0.93,
      "text": "[https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change](https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change)\n\nLocalstack are killing their community edition and making everyone register for a free plan (ugh), so I guess that'll mean they'll slowly nerf the free plant to the point where it's unuseable/put horrible limits on it so you have to pay.\n\nIs there any realistic alternative to localstack out there? Anyone?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4lan0b",
          "author": "alvsanand",
          "text": "Itâ€™s ironic to read them calling it as an 'open-source experiment' rather than a full project, especially since their entire reputation was built on being open-source. They have the right to do it, but they shouldnâ€™t insult our intelligence by pretending otherwise",
          "score": 43,
          "created_utc": "2026-02-10 10:14:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lowhl",
          "author": "tuple32",
          "text": "aws should buy localstack and make it available to their customers for free.",
          "score": 37,
          "created_utc": "2026-02-10 12:14:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nb4lp",
              "author": "HanzJWermhat",
              "text": "This was pitched internally as an idea. I donâ€™t think it was ever taken seriously (I canâ€™t be more specific because my part of the business wasnâ€™t well suited to own it anyway)\n\nThe problem is expectations. If AWS does it, it needs to support everything out of the box. Every API call of which there are 14000+",
              "score": 14,
              "created_utc": "2026-02-10 17:20:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4okuvi",
                  "author": "seanamos-1",
                  "text": "I don't know how seriously they thought about this, but I can't overstate what a significant competitive advantage localstack has been for AWS, and they are losing it.",
                  "score": 10,
                  "created_utc": "2026-02-10 20:51:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4rh613",
                  "author": "ippem",
                  "text": "Ultimately yes, but not from the start; look at CloudFormation support how it grows still slowly after all of these years ðŸ˜",
                  "score": 4,
                  "created_utc": "2026-02-11 07:39:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kw57x",
          "author": "DevWithImagination",
          "text": "Depending on the services you need moto is a great alternative (in fact, localstack uses moto under the hood for some things). We moved quite a bit over to it for speed of testing while using some of the simpler base services (S3, DynamoDb etc)",
          "score": 24,
          "created_utc": "2026-02-10 07:53:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kw94x",
              "author": "xenographer",
              "text": "Nice! [https://github.com/getmoto/moto](https://github.com/getmoto/moto) for reference",
              "score": 13,
              "created_utc": "2026-02-10 07:54:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ombcp",
          "author": "ruibranco",
          "text": "the \"free plan\" to \"slowly nerf it\" pipeline is so predictable at this point. moto covers a surprising number of services if you haven't tried it â€” not as polished but no registration, no usage tracking, and it actually runs offline. for anything more complex, a dedicated AWS dev account with tight billing alerts is honestly more reliable than hoping a third-party tool stays free.",
          "score": 6,
          "created_utc": "2026-02-10 20:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l6c3m",
          "author": "omenking",
          "text": "https://github.com/project-vera/vera-aws\n\nThis project has popped up very recently. It's a research project that is open source.",
          "score": 8,
          "created_utc": "2026-02-10 09:33:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lgpsu",
          "author": "PlanB2019",
          "text": "I would totally pay like 10$ as a hobbyist/individual dev but the currrent entry for premium is just too much to justify for my projects. I wish they had a better entry package, that wasnâ€™t more than my current aws costs haha",
          "score": 7,
          "created_utc": "2026-02-10 11:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kuzx9",
          "author": "HatchedLake721",
          "text": "Whyâ€™s not just pay for it? Itâ€™s a valuable service and people behind it deserve to be paid for it. Anyone not paying for AWS with their own credit card should just put this through their work.\n\nOtherwise, you can just fork and carry on using it as it is today.",
          "score": 19,
          "created_utc": "2026-02-10 07:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lx07v",
              "author": "ippem",
              "text": "Looking from my current company's perspective, we happily pay for things we need, but in our case, the price model (no monthly option plus would need to buy lots of these \"CI credits\" probably) has always killed the idea (for both app developers/CI runs plus for our Terraform development + CI runs).  \nI wish they would have a monthly payment - and have it through e.g. AWS Marketplace would make the adoption way easier.\n\nThat was a hint above how to grow your business, probably exponentially. ðŸ™‚ Companies do not like to commit on things that they don't know the actual usage patterns.",
              "score": 9,
              "created_utc": "2026-02-10 13:08:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4n72d7",
              "author": "GoofAckYoorsElf",
              "text": "A goes from Open Source to freemium - why not pay for it? \n\nB goes from Open Source to freemium - why not pay for it?\n\nC goes from Open Source to freemium - why not pay for it?\n\nBecause I already fucking pay for A and B! What am I Croesus? \n\nOpen Source projects grow on contribution by the community. Shitting on the community and telling them to suddenly pay for the stuff they actually contributed themselves is a fucking dick move, that's what it is!",
              "score": 10,
              "created_utc": "2026-02-10 17:01:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50t458",
                  "author": "HatchedLake721",
                  "text": "Oh please, I can bet my savings less than 1% of localstack users ever contributed to it.\n\nIf you did contribute, I'm sure localstack can sort you out, or feel free to fork it and carry on using and contributing to it, they're not taking away what you already have.\n\nWe have multi-billion companies built on sweat of people writing open source for free. I never have issue with open-source projects going commercial and asking companies to pay for it. Especially in a space like AWS, which is an iPaaS for businesses, not a $9.99 p/m B2C host my hairsalon website pls.",
                  "score": 1,
                  "created_utc": "2026-02-12 18:14:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kxg57",
          "author": "seany1212",
          "text": "Genuine question, why would anyone pay for this? If youâ€™re at a company that takes AWS seriously then they should create you a test environment/account so you donâ€™t need to â€œsimulateâ€ an AWS environment. Â \n\nIf youâ€™re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nThis just seems to add another abstraction layer that will potentially introduce unseen differences when you actually try to port that to AWS.",
          "score": 14,
          "created_utc": "2026-02-10 08:05:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kzo4f",
              "author": "flooberoo",
              "text": "Because with _N_ features being developed simultaneously you ideally have at least _N_ environments. And that can get expensive and slow quite fast.",
              "score": 24,
              "created_utc": "2026-02-10 08:27:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4l4lwm",
                  "author": "lost12487",
                  "text": "I'm not sure why you'd need an account per feature? Why not just give each team a prod and a non-prod account and deploy feature branches within the non-prod account, cleaning up the resources when the feature branch is merged?",
                  "score": -5,
                  "created_utc": "2026-02-10 09:16:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4l6y8d",
              "author": "xenographer",
              "text": "LOL, every time someone starts a sentence with \"Genuine question\" or \"I'm genuinely curious why\" you know that it's bullshit and they're just setting themselves up so they can argue the case against. So intellectually dishonest.\n\n\\> If youâ€™re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nthe whole point is that it's LOCAL and you don't have to set up AWS credentials or resources. Same with integration tests in CI.  \n  \nI'm not sure where \"another abstraction layer\" comes into it.",
              "score": 18,
              "created_utc": "2026-02-10 09:39:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ldrcx",
                  "author": "seany1212",
                  "text": "If itâ€™s local then why bother simulating AWS at all? Just build your app/platform with services/VMs/Docker/Kubernetes\n\nThe logic doesnâ€™t even make sense, Iâ€™m going to simulate a cloud platform that provides an abundance of products and services with potentially infinite compute, locally with none of that.\n\nAgain, why would anyone PAY for that, when it was your initial complaint in the OP",
                  "score": -10,
                  "created_utc": "2026-02-10 10:43:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mqy7w",
              "author": "DZello",
              "text": "Creating ressources in AWS can take forever, databases are a good exemple.",
              "score": 3,
              "created_utc": "2026-02-10 15:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4rx4z6",
          "author": "realqmaster",
          "text": "This fucking sucks. I get that devs ought to be paid, but a credits system for CI builds is unreasonable. I could get behind a one time purchase or a yearly subscription, but tying the costs to the number of builds is flat out wrong. Some projects are built frequently and would burn through their plans (and I think's that's exactly why they target CI for the monetization). Imagine using a Jetbrains IDE and having to pay for each project you create. I hope alternatives emerge in the future, especially if integrated in TestContainers as LocalStack is. For now I'll resort to pinning the version, and move away for future projects.",
          "score": 2,
          "created_utc": "2026-02-11 10:09:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u3vch",
              "author": "remotesynth",
              "text": "I understand your concerns around CI. I wish I could give more detail right now but what I can share is that we are revising the CI credit system for our plans that may help address your concerns. We should have more details soon.\n\n(NOTE: Probably obvious but I work for LocalStack)",
              "score": 2,
              "created_utc": "2026-02-11 17:47:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yrg57",
                  "author": "ippem",
                  "text": "Thanks for the sympathy u/remotesynth ðŸ™‚\n\nA pretty please: have a look also on selling the product through the marketplaces; it really shows that companies are waay happier to contract through them. It probably is more effort for you (plus they for sure have their fees) to establish these, but it might really pay off and help you sell more.\n\nYou have a good product: you need to be able to sell it the easiest ways possible. Going monthly + going marketplaces solves that problem.",
                  "score": 1,
                  "created_utc": "2026-02-12 11:41:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4npdyv",
          "author": "mountainlifa",
          "text": "This is why building for cloud is a regression. Developers are forced into using these third party tools to mock services to build and test features. This should either be native or not required. We are moving our of serverless lambda, dynamo etc to bare bones fast API, docker, postgres that I can run on a single workstation and build, test end to end. No more mocking dozens of services and patching all of my tests.",
          "score": 3,
          "created_utc": "2026-02-10 18:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kw9x3",
          "author": "smutje187",
          "text": "Do you make money with the software you build on LocalStack? Buy a license, just like you buy IDE licenses, rent an office, buy a computer.\n\nOtherwise, AWS credits and use ephemeral environments, most AWS Services that run in LS cost next to nothing for private use.",
          "score": 3,
          "created_utc": "2026-02-10 07:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4olp5o",
          "author": "ruibranco",
          "text": "the realistic answer for most teams is you don't actually need to mock all of AWS locally. SAM CLI + DynamoDB local covers 80% of what people actually use localstack for. the rest you test against a real dev account with short-lived resources. it's less elegant but it's also not going to rug-pull you in 6 months.",
          "score": 1,
          "created_utc": "2026-02-10 20:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50fiue",
          "author": "rad15h",
          "text": "There is an alternative - build it yourself. Hear me out.\n\nAI agents open up options that never would have been sensible or economical before. And this is one of those cases.\n\nI work on a service that runs in AWS and depends on a fair number of AWS services - S3, DDB, EventBridge, Fargate, Lambda, SQS, and probably others I've forgotten about. Testing the full service and running end-to-end tests is painful, and requires deploying a lot of CFN stacks to a dev account.\n\nWe have started using agents to write our code (Kiro CLI + Claude 4.5 Opus) and are producing _far_ more code than we can realistically test. So we needed a new way to test it that the agents could use without human intervention.\n\nI watched a video where someone talked about exactly this problem, and he suggested faking your dependencies and testing locally; that is a lot of work, but it is the kind of work that AI can do extremely easily. It's not complicated or subtle, it just requires knowledge of all the AWS APIs.\n\nIn a few days of running an agent as a background task while I did my day job I had the entire service running on my laptop without using a single real AWS service. The agent built local HTTP servers that fake the AWS service APIs so my service code SDK calls still work. I just have to set `AWS_ENDPOINT_URL_<SERVICE>` to override the service URL to be `localhost:<port>`.\n\nI never would have thought is was possible until I tried it, but I believe it now. I think this is one of the challenges of adopting AI - opening your eyes to the things that you never would have considered before, but which are possible now.\n\nEdit: To clarify, my fake AWS services only implement the small subset of the AWS API that my service code uses. Faking the _entire_ API for all of those services would be a big job, but it's one you don't have to do if you are faking services just for your use case.",
          "score": 1,
          "created_utc": "2026-02-12 17:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1yky",
          "author": "cachemonet0x0cf6619",
          "text": "and this is why i will never recommend local testing of services. mock unit test and architect your application such that it can be tested in isolation.\n\neta: only people downvoting me are local stack employees that thought it was a good idea to charge for this and the the people using local stack that bought the lies",
          "score": -4,
          "created_utc": "2026-02-10 13:37:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4m5eu2",
              "author": "yesman_85",
              "text": "You don't do e2e test then?Â ",
              "score": 1,
              "created_utc": "2026-02-10 13:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4m5t18",
                  "author": "cachemonet0x0cf6619",
                  "text": "i do e2e in the cloud against actual resources",
                  "score": 8,
                  "created_utc": "2026-02-10 13:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1e6pa",
      "title": "Global cloudfront issues",
      "subreddit": "aws",
      "url": "https://health.aws.amazon.com/health/status",
      "author": "dennusb",
      "created_utc": "2026-02-10 21:43:13",
      "score": 61,
      "num_comments": 8,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1e6pa/global_cloudfront_issues/",
      "domain": "health.aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4oyd3u",
          "author": "Difficult-Ad-3938",
          "text": "DNS =)",
          "score": 36,
          "created_utc": "2026-02-10 21:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owf8z",
          "author": "MidgardDragon",
          "text": "Yep RingCentral Contact Center was hard down for about an hour for us. Traced it back to CloudFront.",
          "score": 9,
          "created_utc": "2026-02-10 21:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pe35c",
          "author": "return_of_valensky",
          "text": "my company is having issues with docusign.. i figure this is as good of a reason as any why that might be.. errors logging in, sending documents etc",
          "score": 3,
          "created_utc": "2026-02-10 23:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sn7pn",
          "author": "AntDracula",
          "text": "Neat. Better lay off another few thousand!",
          "score": 4,
          "created_utc": "2026-02-11 13:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owvm2",
          "author": "rhaksw",
          "text": "AppSync is having issues for us",
          "score": 2,
          "created_utc": "2026-02-10 21:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pmphj",
          "author": "UpgradingLight",
          "text": "Jira was affected today for us, not sure if itâ€™s this yet",
          "score": 1,
          "created_utc": "2026-02-11 00:03:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p0nse",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -6,
          "created_utc": "2026-02-10 22:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p7xed",
              "author": "brile_86",
              "text": "global outages exist since way before vibe coding, not sure when you have started in IT",
              "score": 20,
              "created_utc": "2026-02-10 22:41:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8hkc",
                  "author": "AntDracula",
                  "text": "Jarvis, google what \"frequency\" means.",
                  "score": 1,
                  "created_utc": "2026-02-12 13:37:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0hm2o",
      "title": "Support cases unassigned. Anyone still alive at AWS?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "author": "symgenix",
      "created_utc": "2026-02-09 21:44:20",
      "score": 57,
      "num_comments": 72,
      "upvote_ratio": 0.71,
      "text": "Have any of you experienced the same situation? I've got 3 tickets, none of them being actually addressed, the oldest one being created 11d ago.\n\nI am wondering if I should send a registered letter or send a pigeon with my case file, as those would probably arrive quicker than someone actually responding to my online cases. We seem to revert to stone age soon, at least at AWS. AWS would then become ASS right? Amazon Stone Services.\n\nEdit: Basic Support level. Low priority is automatically assigned everywhere.\n\nhttps://preview.redd.it/rbk5wd3hgjig1.png?width=666&format=png&auto=webp&s=6b6b7784a742e28f3d6ed3fda06bb60a2b8357e0",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4i9jbq",
          "author": "anoeuf31",
          "text": "What support level are you on and what severity level were these cases opened at ?",
          "score": 40,
          "created_utc": "2026-02-09 21:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i9rvg",
              "author": "symgenix",
              "text": "Basic -> Low\n\nSo, one could no longer receive any support unless one pays for a support subscription? :D That must be a compelling business decision.",
              "score": -74,
              "created_utc": "2026-02-09 21:50:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ihda4",
                  "author": "nemec",
                  "text": "> That must be a compelling business decision.\n\nMoney can be exchanged for goods and (support) services",
                  "score": 80,
                  "created_utc": "2026-02-09 22:28:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iam0c",
                  "author": "anoeuf31",
                  "text": "Unironically yes - do you think support engineers work out of the goodness of their hearts ? Business support starts at 29 bucks a month . \n\nIf you think whatever you are running on AWS isnâ€™t worth the 29 bucks a month, donâ€™t be surprised when support treats your cases with the same level of importance",
                  "score": 85,
                  "created_utc": "2026-02-09 21:54:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ixz5b",
                  "author": "planedrop",
                  "text": "Dude, pretending that support should just be included doesn't really make sense.\n\n  \nThe point of a lot of cloud services is to be *as cheap as possible* which means cutting support unless you want to pay for that on your own as well. ",
                  "score": 6,
                  "created_utc": "2026-02-09 23:57:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4id9v5",
          "author": "mistuh_fier",
          "text": "Unfortunately if youâ€™re not paying for support then thereâ€™s not much differentiating you vs. mass registrations by AI agents to abuse the Free Tier. \n\nFree tier support tickets to a specific service are essentially aggregated and treated as a canary for widespread issues.",
          "score": 44,
          "created_utc": "2026-02-09 22:07:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4idiwe",
          "author": "PracticalTwo2035",
          "text": "Dude, setup bedrock playground? Wtf, there is no setup, just usage. Please try to search in the internet and maybe read the docs.",
          "score": 31,
          "created_utc": "2026-02-09 22:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j9mat",
          "author": "d70",
          "text": "Basic support = you are free to read documentation on your own. From [the FAQ](https://aws.amazon.com/premiumsupport/faqs/):\n\n>How are the enhanced AWS Support tiers different from Basic Support?\n\n>AWS Basic Support offers all AWS customers access to our Resource Center, Service Health Dashboard, Product FAQs, and Discussion Forums â€“ at no additional charge. Customers who desire a deeper level of support can subscribe to AWS Support at the Business Support+, Enterprise, or Unified Operations level.",
          "score": 5,
          "created_utc": "2026-02-10 01:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i9h47",
          "author": "Outrageous_Lab_6228",
          "text": "What is your support tier?",
          "score": 14,
          "created_utc": "2026-02-09 21:48:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iaarh",
              "author": "symgenix",
              "text": "Basic. I'd rather switch to a different provider than pay for support subscriptions lol.. especially since nothing seems to be properly working without a PHD in AWS apparently. ",
              "score": -48,
              "created_utc": "2026-02-09 21:52:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iciao",
                  "author": "caughtinthought",
                  "text": "FYI the providers that are a layer above AWS (i.e., hand hold more) typically charge much more too. The further from the foundation you go, the more shit costs. ",
                  "score": 21,
                  "created_utc": "2026-02-09 22:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iaufs",
                  "author": "anoeuf31",
                  "text": "When you find this magical cloud provider thatâ€™ll respond to your cases on priority without a support fee , please let us all know !!",
                  "score": 37,
                  "created_utc": "2026-02-09 21:55:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iolp9",
                  "author": "Dave4lexKing",
                  "text": "If whatever youâ€™re building isnâ€™t worth $29/mo for support, then it canâ€™t be very good?",
                  "score": 5,
                  "created_utc": "2026-02-09 23:06:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ikssi",
                  "author": "Nemphiz",
                  "text": "That kinda sounds like a skill issue tbh.",
                  "score": 8,
                  "created_utc": "2026-02-09 22:46:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ih6sp",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear that your support cases have not been responded to yet. I've passed along your feedback to our Support team. Any updates about your support cases will be sent to your inbox. \n\n\\- Gee J.",
          "score": 11,
          "created_utc": "2026-02-09 22:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kp4wa",
          "author": "MavZA",
          "text": "Reading how youâ€™ve responded to comments then maybe you should either consider switching as youâ€™ve threatened you would. Doesnâ€™t seem like youâ€™ve put any effort into learning AWS and how to use the services or how the services fundamentally work. You say you need a PHD, but clearly youâ€™ve come in without any fundamentals and are frustrated because it doesnâ€™t work the way you think it should.",
          "score": 5,
          "created_utc": "2026-02-10 06:49:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4icdhs",
          "author": "Horror_Response_1991",
          "text": "If you arenâ€™t giving them money for support or giving them a lot of money for regular use, they do not care. Â They only have so much support staff and theyâ€™re all busy helping the money.",
          "score": 5,
          "created_utc": "2026-02-09 22:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jqlu3",
          "author": "stephenin916",
          "text": "NOPE everything is going into AI and they have reduced the front line personnel ...if you pay the big money then you get more attention but the days of customer obsession are GONE and the shareholder days have arrived. ",
          "score": 3,
          "created_utc": "2026-02-10 02:43:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kb4hu",
          "author": "teambob",
          "text": "They layed off thousands of people",
          "score": 2,
          "created_utc": "2026-02-10 04:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k6g1b",
          "author": "RuinEnvironmental394",
          "text": "Did you try sending a telegram? And no I'm not talking about the app. ðŸ˜­",
          "score": 1,
          "created_utc": "2026-02-10 04:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iab9q",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-02-09 21:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j5exp",
              "author": "gbonfiglio",
              "text": "Itâ€™s important to debunk this one: there is no mechanism in AWS Support which causes â€˜simpleâ€™ cases to be ignored.\n\nCases are routed to engineers based on a range of parameters like service, complexity, time since open, support tier etc - so there canâ€™t be any structural decision to ignore these cases.",
              "score": 5,
              "created_utc": "2026-02-10 00:39:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iamdq",
              "author": "symgenix",
              "text": "Yes, I did try multiple times via their amazing AI, which, in my experience, was only able to circle around non-related stuff and point me to nonsensical locations. They probably outsource their baisc support AI model to the first model of gpt.",
              "score": -15,
              "created_utc": "2026-02-09 21:54:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iedap",
                  "author": "InterestedBalboa",
                  "text": "Basic support is no support, just how it works",
                  "score": 8,
                  "created_utc": "2026-02-09 22:13:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qxub7w",
      "title": "Bedrock - Requests for Future",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qxub7w/bedrock_requests_for_future/",
      "author": "Live_Bus7425",
      "created_utc": "2026-02-06 21:21:14",
      "score": 40,
      "num_comments": 15,
      "upvote_ratio": 0.95,
      "text": "Hello, my team has been using Bedrock since its infancy and we're a platinum tier Amazon partner. Here are my suggestions for Bedrock:\n\n\\* Add a new **embedding model**. Titan v2 is ok, but its 2 years old. Qwen/Qwen3-Embedding-0.6B is much better at 1024 dimensions. There are many open source models that excel at 512 dimensions also. We're using EC2 (or really ECS with EC2) to host them locally, but having them in Bedrock at a reasonable price would make things easier to maintain.\n\n\\* Add some inexpensive and easy to use **reranker** models that are open source. Cohere is just too expensive... we've been hosting some models on EC2, but we'd rather use Bedrock for jina-reranker-v3 / mxbai-rerank-large-v1 / bge-reranker-v2-m3 / qwen3-reranker-0.6B. \n\n\\* You're fast to add Anthropic models, which we really appreciate. But can you add other open source LLMs that you started investing into already? Where is **DeepSeek v3.2**? Where is **Kimi K2.5**? **MiniMax 2.1**? It feels like a lot of models you host are slightly outdated.\n\n\\* I don't know if anyone is using your **Nova models**. We've benchmarked them, and for the price/performance they always fall short. Sorry... If they were 2x cheaper, we would probably use them in some places.\n\nThis is my team's feedback on AWS Bedrock. I'm curious what other people think about Bedrock and where its lacking.",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1qxub7w/bedrock_requests_for_future/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o40596d",
          "author": "ruibranco",
          "text": "The embedding model situation is spot on. Titan v2 was fine when it launched but the open source space has moved so far ahead that hosting your own on ECS starts making more sense, which kind of defeats the purpose of a managed service. Same story with rerankers, Cohere pricing just doesn't work if you're doing any serious volume of reranking. Would love to see them add jina-reranker-v3 or even the smaller qwen models as first-class Bedrock options.",
          "score": 12,
          "created_utc": "2026-02-07 01:03:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z3k9a",
          "author": "alex_aws_solutions",
          "text": "I can't get into detail because I just started with Bedrock. Our main object and an advantage is to host the llm's locally. But yes, they are definitely behind with some models.",
          "score": 5,
          "created_utc": "2026-02-06 21:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3z561b",
              "author": "Live_Bus7425",
              "text": "Yeah. I agree that local is usually better, but our use case requires data privacy and our usage is very spiky. At night we are almost idle, at peak times we're hitting bedrock limits. Bedrock is nice, because you don't have to maintain any infrastructure. ",
              "score": 3,
              "created_utc": "2026-02-06 21:43:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o406mo4",
          "author": "SoftwarePP",
          "text": "The nova models are incredible for their price offset. There are no models they can do as an example summarization cheaper.",
          "score": 3,
          "created_utc": "2026-02-07 01:11:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o409ezg",
              "author": "Live_Bus7425",
              "text": "Really? Our benchmarks show Haiku 4.5 and even gpt-oss-120B better and cheaper than Nova 2 Pro. Public benchmarks seem to agree. The other thing we didn't like is the speed of Nova models. I'd expect them to be insanely fast, but that was not the case.",
              "score": 1,
              "created_utc": "2026-02-07 01:28:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o42dn57",
                  "author": "SoftwarePP",
                  "text": "Nova lite and micro are pretty much free.",
                  "score": 3,
                  "created_utc": "2026-02-07 11:44:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3z8uzx",
          "author": "d70",
          "text": "Re: embedding - Tried amazon.nova-2-multimodal-embeddings-v1:0? Released at last re:Invent",
          "score": 3,
          "created_utc": "2026-02-06 22:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zgup2",
              "author": "Live_Bus7425",
              "text": "Really nice embedding model. We've used it for Audio and its kinda cool. I was talking about text embeddings, which is probably 99% of use cases for embedding models... at least in my little bubble =)",
              "score": 3,
              "created_utc": "2026-02-06 22:43:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o43d1on",
                  "author": "Opening-Concert826",
                  "text": "Have you looked at the docs? It supports text: https://docs.aws.amazon.com/nova/latest/nova2-userguide/embeddings.html",
                  "score": 2,
                  "created_utc": "2026-02-07 15:29:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o41wa01",
          "author": "Nepgyaaa",
          "text": "DeepSeek v3.2, Kimi K2.5, MiniMax 2.1 are all available now on Bedrock.",
          "score": 3,
          "created_utc": "2026-02-07 08:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41z47c",
          "author": "ChlorrOfTheMask",
          "text": "Yes, please new embedding and reranking models!",
          "score": 1,
          "created_utc": "2026-02-07 09:24:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4zj681",
          "author": "AWSSupport",
          "text": "Hi there, \n\nThanks for this! We've forwarded your feedback to our Bedrock team for review.\n\n\\- Reece W.",
          "score": 1,
          "created_utc": "2026-02-12 14:35:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyukj6",
      "title": "ECS is supposed to be simple?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qyukj6/ecs_is_supposed_to_be_simple/",
      "author": "ReturnOfNogginboink",
      "created_utc": "2026-02-08 00:42:51",
      "score": 35,
      "num_comments": 30,
      "upvote_ratio": 0.87,
      "text": "I've spent the day banging my head against the wall here. I have a container definition in a task definition in a service definition. I have an ECS cluster and a VPC and I have three subnets in three AZs and I have a private endpoint to ECR. I have a security group that should allow these pieces to talk to each other. I have a task execution role that has permissions on ECR and CloudWatch Logs.\n\nECS can't pull the task from ECR and I don't know why.\n\nThe SSM runbook \"**TroubleshootECSTaskFailedToStart**\" runs four out of the twelve steps and says 'success' without giving me any output.\n\nDoes anyone have a sample Terraform stack that shows creating a soup-to-nuts ECS service?\n\nCan anyone opine what might be causing ECS to fail to pull from RDS?\n\nThis is one of my more frustrating days with AWS.\n\nEDIT: The error I finally get is:  \nTask stopped at:Â 2026-02-08T00:42:44.811Z\n\n`ResourceInitializationError: unable to pull secrets or registry auth: The task cannot pull registry auth from Amazon ECR: There is a connection issue between the task and Amazon ECR. Check your task network configuration. operation error ECR: GetAuthorizationToken, exceeded maximum number of attempts, 3, https response error StatusCode: 0, RequestID: , request send failed, Post \"https://api.ecr.us-west-2.amazonaws.com/\": dial tcp 34.223.24.13:443: i/o timeout`\n\nHm... my ECR interface endpoint is for com.amazonaws.us-west-2.ecr.dkr and is in 10.0.x.y... Did I create an interface endpoint for the wrong service??",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qyukj6/ecs_is_supposed_to_be_simple/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o469zum",
          "author": "Traditional_Donut908",
          "text": "Does the fact that you have a private endpoint to ECR mean this is in a private subnet with no NAT gateway? If so you actually need 3 different endpoints.",
          "score": 53,
          "created_utc": "2026-02-08 00:46:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47dedi",
              "author": "cabblinlmao",
              "text": "to answer OP's question, no. ECS is not Lambda. it will be more complicated lol",
              "score": 3,
              "created_utc": "2026-02-08 05:05:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46amxg",
              "author": "water_bottle_goggles",
              "text": "nice",
              "score": 5,
              "created_utc": "2026-02-08 00:50:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46hxy0",
              "author": "ReturnOfNogginboink",
              "text": "One endpoint with three subnet attachments is how it shows up in the GUI.",
              "score": -6,
              "created_utc": "2026-02-08 01:36:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o46ly0f",
                  "author": "clintkev251",
                  "text": "Nope, that's not the same thing. That's one single endpoint. You're missing at least 1 (I see elsewhere you say you have S3)",
                  "score": 19,
                  "created_utc": "2026-02-08 02:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46d687",
          "author": "low_freq",
          "text": "4 key things I found to get ECS up and running in a private subnet (no internet gateway or NAT).\n\n1. VPC Gateway endpoint for s3 (service_name= com.amazonaws.region.s3) (this tripped me up the most, but ECR actually has some backing in S3 apparently)\n2. VPC interface endpoint for ecr api (service_name=com.amazonaws.region.ecr.api)\n3. VPC interface endpoint for ecr for (servicename=com.amazonaws.region.ecr.dkr)\n4. Appropriate perms. Deployer should have â€œecr:GetAuthorizationTokenâ€, amongst all the other ecr actions needed, and look at managed policy â€œAmazonECSTaskExecutionRolePolicyâ€ for a starting point for the role to assign to the task definition. \n\nApologies for formatting, on mobile.",
          "score": 29,
          "created_utc": "2026-02-08 01:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46ekb2",
          "author": "Important_Winner_477",
          "text": "your interface endpoint is only half the battle. you likely missed the `com.amazonaws.us-west-2.ecr.api` endpoint or forgot the s3 gateway endpoint required for the actual layer downloads. without the api endpoint, your task times out trying to hit the public ecr auth range (34.223.x.x) from a private subnet with no nat gateway. check if your security group allows inbound 443 from the task's cidr on *all* required endpoints. are you also allowing egress to s3 in your task security group, or is the missing s3 gateway endpoint what's actually hanging the pull?",
          "score": 15,
          "created_utc": "2026-02-08 01:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46i1ow",
              "author": "ReturnOfNogginboink",
              "text": "I do have an S3 gateway interface. But you're right; I have to check the security group(s) on that.",
              "score": 2,
              "created_utc": "2026-02-08 01:36:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o46ngvp",
                  "author": "Important_Winner_477",
                  "text": "Glad the S3 tip helped. Since you're still hitting timeouts, I'd bet it's the missing ECR API endpoint or a SG rule. I'm a certified cloud pen tester looking for more hands-on cases if you want, I can help you audit your Security Groups and IAM roles for free just to get the practice in?",
                  "score": -3,
                  "created_utc": "2026-02-08 02:11:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46cdk9",
          "author": "clintkev251",
          "text": ">I have a private endpoint to ECR\n\nI have some doubts in your configuration there. The error clearly shows that the request is going out to a public IP. If you had a correctly configured interface endpoint for ECR, this request would be going to a private IP. Take another look at your configuration there. Remember there are multiple endpoints required for a successful image pull\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html",
          "score": 10,
          "created_utc": "2026-02-08 01:01:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bwff4",
              "author": "ReturnOfNogginboink",
              "text": "I had the interface endpoint I had it associated with the right subnets and route table, but hadn't turned on private DNS resolution on it.",
              "score": 1,
              "created_utc": "2026-02-08 22:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46g63a",
          "author": "bryantbiggs",
          "text": "https://github.com/aws-ia/ecs-blueprints",
          "score": 5,
          "created_utc": "2026-02-08 01:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46czci",
          "author": "JEHonYakuSha",
          "text": "Thereâ€™s a few permissions required for ECS to retrieve from ECR. Did you provide them all?\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/ECR_on_ECS.html",
          "score": 3,
          "created_utc": "2026-02-08 01:04:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46i6sp",
              "author": "ReturnOfNogginboink",
              "text": "Yes, those are in the policies on the task execution role. Thank you.",
              "score": 2,
              "created_utc": "2026-02-08 01:37:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46a9hj",
          "author": "Nearby-Middle-8991",
          "text": "It has been a while, but if it's running on top of an ec2 ASG, the role in the ec2s also need tweaking ",
          "score": 2,
          "created_utc": "2026-02-08 00:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48j50v",
          "author": "guareber",
          "text": "Amazon Q is surprisingly not-terrible at finding out issues with existing resources and errors when they are AWS related. Try walking it through the scenario and allowing it to look up your resources.",
          "score": 2,
          "created_utc": "2026-02-08 11:25:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4863eq",
          "author": "forsgren123",
          "text": "Hook up Claude Code to your Terraform codebase and AWS MCP server (or AWS CLI), and it will tell you what's wrong in two minutes.",
          "score": 3,
          "created_utc": "2026-02-08 09:22:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46a51i",
          "author": "SnoopJohn",
          "text": "Can you share you terraform might make it easier to see the problemÂ ",
          "score": 1,
          "created_utc": "2026-02-08 00:47:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ln5n",
          "author": "SoggyGrayDuck",
          "text": "Personally i feel like it's one of the more complicated pieces, that and ec2 BUT I've never really dealt with on prem. I think it's the opposite for experienced onprem moving to the cloud",
          "score": 1,
          "created_utc": "2026-02-08 11:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bdxif",
          "author": "2BucChuck",
          "text": "I guess I get why people bash Claude but build an IAM role with display only access to the landscape resources you need and just ask Claude code to help troubleshoot- it will use the CLI and boto to find the issue. Guaranteed.  There is some learning value to banging your head on the wall but AWS is a steep learning curve at first and if Q doesnâ€™t help you solve it Claude code will for sure",
          "score": 1,
          "created_utc": "2026-02-08 20:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c520s",
              "author": "MealVan",
              "text": "Best answer. Claudeâ€™s ability to diagnose infra issues with just AWS CLI read only commands and some Python scripts is unmatched.",
              "score": 3,
              "created_utc": "2026-02-08 23:10:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f0ca9",
          "author": "KayeYess",
          "text": "I presume you are not using an Internet NAT Gateway or forward proxy or some other solution like natting to a Public VIF. If so, you would need VPC End-points for all AWS services you use\n\n\nYou would need both ECR VPC end-points ... one for Docker and one for the core API itself:\n\ncom.amazonaws.region.ecr.dkr\ncom.amazonaws.region.ecr.api\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html\n\nECS itself has a few\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/vpc-endpoints.html\n\nFor a list of all AWS Services that supports VPC end-points, check this document: https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.html",
          "score": 1,
          "created_utc": "2026-02-09 11:27:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46i8gn",
          "author": "angcritic",
          "text": "Try using Kiro. As a non-cloud engineer who seems to get trapped in cloud issues, it has changed my life and probably added a couple of years to my late career. (Kiro is Amazon's AI and if you logged in or credentialed, it will answer and analyze a lot of these nightmares.)",
          "score": 2,
          "created_utc": "2026-02-08 01:38:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47l5yd",
              "author": "japanthrowaway",
              "text": "Kiro is terrible imo.Â  Claude code with boto or AWS CLI is leap years ahead.Â ",
              "score": 3,
              "created_utc": "2026-02-08 06:09:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47ncob",
              "author": "CamilorozoCADC",
              "text": "start rant\n\nI'm a Kiro power user and all in for it. but one thing that I need to overcorrect repeatedly is the poor thing noticing that I deploy on ECS within a Private Subnet which causes a desire for adding a NAT Gateway. And asking the thing for troubleshooting in OP's situation doesn't help at all because it always resorts to the NAT Gateway solution. I know its dumb but it happens so often its irritating\n\nEnd rant",
              "score": 2,
              "created_utc": "2026-02-08 06:28:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46g263",
          "author": "FunkyDoktor",
          "text": "Claude, analyze why this doesnâ€™t work. Give me a detailed analysis document with current issues and what can be improved. Make sure the deployment is secure. I will check back once Iâ€™ve had my coffee. Off you go.",
          "score": 0,
          "created_utc": "2026-02-08 01:24:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o472w22",
          "author": "yarenSC",
          "text": "Not now, but general advise:\n\nIf possible, adding an IGW (and route to it) is a simple way to debug a problem in a dev environment.  That'll help narrow down if it's a connectivity issue or not.\n\nReachability Analyzer is also quite useful for debugging",
          "score": 0,
          "created_utc": "2026-02-08 03:50:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47j7bw",
              "author": "yourparadigm",
              "text": "That only works if you give your containers public IPs, which you should never do.",
              "score": 3,
              "created_utc": "2026-02-08 05:52:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46aud7",
          "author": "Old_Cry1308",
          "text": "aws is always a headache, try checking your security group settings.",
          "score": -6,
          "created_utc": "2026-02-08 00:51:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0ldl9",
      "title": "Structured outputs now available in Amazon Bedrock",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/structured-outputs-available-amazon-bedrock/",
      "author": "ckilborn",
      "created_utc": "2026-02-10 00:12:23",
      "score": 27,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1r0ldl9/structured_outputs_now_available_in_amazon_bedrock/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4jzhfn",
          "author": "omenking",
          "text": "Hmmm. Structured outputs is always a gotcha with multiple models and so I'd be wary to believe it works across all available models.",
          "score": 0,
          "created_utc": "2026-02-10 03:37:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kkgdu",
              "author": "Seref15",
              "text": "It lists which models it works with at the bottom of the article.",
              "score": 5,
              "created_utc": "2026-02-10 06:08:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qza7v3",
      "title": "Silent behavioral change in NLB DNS publishing for empty AZs? (Breaking change for DR/Failover)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "author": "atawii",
      "created_utc": "2026-02-08 14:24:46",
      "score": 19,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nIâ€™m noticing a significant discrepancy in behavior between legacy Network Load Balancers and newly created ones regarding how they handle DNS for Availability Zones with 0 registered targets.\n\n**The Setup:**\n\n* **Architecture:** Internet-facing NLB -> Target Group (Instance Type) -> K8s Nodes (NodePort).\n* **Cross-Zone Load Balancing:** **Disabled** (intentionally, for cost/latency reasons in a specific multi-AZ setup).\n* **Scenario:** 3 AZs with one specific AZ (e.g., `ca-central-1d`) has no healthy targets (0 nodes).\n\n**The Discrepancy:**\n\n1. **Old NLB (Created \\~2024):**\n   * **Behavior:** The NLB automatically removes the IP address of the empty AZ from the DNS record.\n   * **Result:** `dig comand` returns only 2 IPs (for the healthy AZs). Traffic is never routed to the empty AZ. Everything works.\n   * If we terminate all instances from the first AZ (1a) with AWS FIS, the DNS assigned from this AZ was also removed, so we have only one DNS remaining.\n2. **New NLB (Created Feb 2026):**\n   * **Configuration:** Identical to the old one (Terraform/OpenTofu code is the same).\n   * **Behavior:** The NLB **continues to publish the IP** of the empty AZ in the DNS record.\n   * **Result:** `dig` returns 3 IPs. Client traffic is round-robined to the empty AZ (\\~33% of requests). Since Cross-Zone is disabled and there are no local targets, these packets are blackholed, causing immediate connection timeouts/failures.\n\n**Support's Response:** I opened a ticket, and AWS Support claims *\"*After reviewing your case and consulting with our internal resources, I can confirm that \\*\\*this is the expected behavior for Network Load Balancers\\*\\*, and there has been no recent change to how NLBs handle DNS resolution for AZs with no registered targets*.\"*\n\nHowever, the empirical evidence (side-by-side `dig` results on same-region, same-config LBs) suggests otherwise.\n\n**The Impact:** This feels like a silent breaking change. Previously, we relied on the NLB's ability to \"drain\" an AZ from DNS if the backend was dead (fail-open style). Now, it seems new NLBs are \"sticky\" to their AZs regardless of backend health, which breaks standard DR/Failover patterns where you might spin down an AZ to save costs or during an outage.\n\n**Questions:**\n\n* Has anyone else noticed this shift in \"Fail Open\" behavior on recent NLBs?\n* Is there a new attribute (hidden or documented) that controls this \"DNS draining\" behavior?\n* Is the only solution now to force Cross-Zone Load Balancing (and pay the transfer costs) or manually manipulate Subnet mappings during an incident?\n\nThanks for any insights.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o499urc",
          "author": "ggbcdvnj",
          "text": "The amount of times support has told me â€œthereâ€™s been no changeâ€ when you eventually pull it out of the service team after enough escalation that there actually was a change kills me\n\nDealing with L1 AWS support drains my will to live\n\n</rant>\n\nSorry, all I can say is I wish you the best",
          "score": 15,
          "created_utc": "2026-02-08 14:34:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49brec",
              "author": "atawii",
              "text": "It's incorrect, but honestly, it's the best support response I've had in the last year. At least I got it in under 24 hours.",
              "score": 4,
              "created_utc": "2026-02-08 14:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49s8fv",
                  "author": "MateusKingston",
                  "text": "\"At least I got told the incorrect information fast\".\n\nLol.\n\nThey also even lied, if it was under 24h they didn't even check anything with anyone",
                  "score": 1,
                  "created_utc": "2026-02-08 16:10:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4cu6wz",
              "author": "Ok-Helicopter525",
              "text": "Ok the flip side, customers are very quick to say â€œthe service must have changed or broken somethingâ€ only to find out, oops, itâ€™s their environment that has the issue.",
              "score": 3,
              "created_utc": "2026-02-09 01:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o499f7m",
          "author": "notathr0waway1",
          "text": "This sounds super weird and interesting.  I feel like you documented it well and I hope someone competent actually addresses it.",
          "score": 11,
          "created_utc": "2026-02-08 14:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49cplf",
              "author": "atawii",
              "text": "I'm able to reproduce with old NLB  the behavior. I have report with AWS FIS (for example testing to disrupt an AZ), that is impossible with the new behavior. I'm pretty sure to be not alone.\n\nThe next think I want to test, if I reproduce in another AWS region.",
              "score": 2,
              "created_utc": "2026-02-08 14:50:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4akqy2",
          "author": "ruibranco",
          "text": "Check the target group attributes with \\`aws elbv2 describe-target-group-attributes\\` on both old and new. Specifically look at \\`target\\_group\\_health.dns\\_failover.minimum\\_healthy\\_targets.count\\` and the unhealthy state routing settings. AWS changed some defaults on newer TGs and it's not always reflected in the Terraform state if you're importing or if the provider version changed between the two deploys.",
          "score": 6,
          "created_utc": "2026-02-08 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c0ldy",
              "author": "atawii",
              "text": "Yes, I already check with the UI (and now with the CLI) the minimum\\_healthy\\_targets value is 1 on tjhe old and the new target group. That same to be the default and minimal settings.",
              "score": 1,
              "created_utc": "2026-02-08 22:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ca8le",
                  "author": "ruibranco",
                  "text": "Interesting, if TG attributes match then it's probably at the NLB level. Check if cross-zone load balancing is configured the same on both, and also compare the \\`dns\\_record.client\\_routing\\_policy\\` attribute on the NLB itself. AWS quietly introduced zonal affinity settings that can affect DNS behavior when an AZ has no healthy targets.",
                  "score": 1,
                  "created_utc": "2026-02-08 23:40:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49ae1u",
          "author": "yarenSC",
          "text": "Definitely push back on the support case to explain what's different between the 2.  It's either a bug (since the public docs explicitly say DNS fail over should happen), or something is different \n\nAre you sure there isn't a second target group on the new NLB?  And are all targets healthy?\nWhat you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS",
          "score": 3,
          "created_utc": "2026-02-08 14:37:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49c677",
              "author": "atawii",
              "text": ">since the public docs explicitly say DNS fail over should happen\n\nDo you have a link to the documentation that explain that? I don't find it.\n\n>Are you sure there isn't a second target group on the new NLB? And are all targets healthy? What you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS\n\nYes, I'm sure all instances are healthy on the target group.",
              "score": 2,
              "created_utc": "2026-02-08 14:47:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49drfz",
                  "author": "yarenSC",
                  "text": "[https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health)\n\n  \nThis also has a list of things for you to check to see why it might be failing open.  Note there's a new setting that could be impacting this where you can change the minimum healthy hosts required for an AZ to be considered healthy.  Although if your terraform is identical, then presumably it isn't being used on your new NLB\n\n[https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/](https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/)",
                  "score": 3,
                  "created_utc": "2026-02-08 14:56:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ao28f",
          "author": "x86brandon",
          "text": "Couple of things:\n\nAre you doing the dig against your CNAME or the AWS NLB hostname?  What are you running the dig against? AWS auth or your local DNS?  There are quite a few cases where DNS providers do not honor the low TTL and I have seen places like Comcast take 5-10 minutes to expire the record regardless of the 60 second TTL.  That could be at play here.   I would be curious to see if you still see that after a minute or two from AWS auth servers.  \n  \nDepending on your SLA/SLO, you shouldn't rely on failover this way anyways, you will always have several minutes of black hole potential with an NLB.  In my most critical of apps, before zonal shift existed, I used to do NLB per AZ and orchestrate my traffic failover myself.   It also triples my capacity capability.  However, if you want to purposefully shut down an AZ, I would suggest using zonal shift to get traffic it off it before you remove the AZ.",
          "score": 2,
          "created_utc": "2026-02-08 18:42:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bzwzn",
              "author": "atawii",
              "text": "We use CloudFront in front of the ELB, so it relies solely on AWS's internal DNS resolver, bypassing client-side DNS issues. We have tested this multiple times, and the downtime during an AZ disruption is only 10 seconds. Zonal Shift is still interesting, but we view it as complementary.\n\nIn our case, we have the exact same result after 1m or 60minutes from AWS DNS resolver or internet resolver.",
              "score": 2,
              "created_utc": "2026-02-08 22:40:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4asmwb",
          "author": "x86brandon",
          "text": "Interestingly, Terraform changed the way subnets are handled because of a new API function added.   And folks are complaining about stale IP's being left in target groups creating a similar behavior too.   Something to look at that might explain the differences between the 2 NLB's, especially if your old one was created one way and the new one created another.   As the underlying API interaction in Terraform changed last year.\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41418](https://github.com/hashicorp/terraform-provider-aws/issues/41418)\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41880](https://github.com/hashicorp/terraform-provider-aws/issues/41880)",
          "score": 2,
          "created_utc": "2026-02-08 19:03:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r10ppv",
      "title": "Is Google Drive really cheaper than S3 storage?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "author": "nucleustt",
      "created_utc": "2026-02-10 13:27:49",
      "score": 19,
      "num_comments": 57,
      "upvote_ratio": 0.69,
      "text": "I was in the process of building a cloud backup solution for my company to store files in S3 buckets on our AWS account (US-EAST-1).\n\nNaturally, I did some research on the estimated costs and compared them with other Cloud Storage solutions, like Google Drive.\n\nThat's when I discovered that using Google Drive was actually cheaper.\n\nThis also makes it difficult to compete against Google Drive if you're building your own cloud storage solution.\n\nAre there any Cloud Storage solutions or AWS tiers that are cheaper than Google Drive?\n\nGoogle Drive ($1.99/month for 100GB, further savings on yearly plans)\n\nAWS S3 ($2.30/month for 100GB, not including request fees)",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4m1auu",
          "author": "ReturnOfNogginboink",
          "text": "AWS Glacier Deep Archive is about $1/TB/mo.\n\nThe costs hit when you need to retrieve data. For backups, that happens rarely.",
          "score": 88,
          "created_utc": "2026-02-10 13:34:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mpwdj",
              "author": "ohad1282",
              "text": "And it is slow retrieval, unless you use Glacier IR which is a good potential combination for both low cost storage and quick retrieval",
              "score": 10,
              "created_utc": "2026-02-10 15:42:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nhszu",
                  "author": "enjoytheshow",
                  "text": "Retrieval costs are way more though IIRC",
                  "score": 2,
                  "created_utc": "2026-02-10 17:51:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mux3r",
              "author": "Vista_Lake",
              "text": "Yes, this is exactly right. I've been using Deep Archive for years, have never had to retrieve a file, and probably never will, since I also keep a local backup.",
              "score": 7,
              "created_utc": "2026-02-10 16:05:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4qm7aw",
                  "author": "madwolfa",
                  "text": "Same, I've been using it as an off-site backup for my NAS for many years too.Â ",
                  "score": 1,
                  "created_utc": "2026-02-11 03:35:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m2gm7",
          "author": "No-Rip-9573",
          "text": "Correct me if Iâ€™m wrong but I believe Google drive does not do snapshots or WORM protection, which you would want for backup solution. If youâ€™re just looking for a place to dump some files cheaply thatâ€™s ok, but donâ€™t call it backup if any random malware can just encrypt/overwrite/delete it for you.",
          "score": 35,
          "created_utc": "2026-02-10 13:40:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m3aik",
          "author": "solo964",
          "text": "Did you mean Google Drive or Google Cloud Storage?  \n  \nAmazon S3 and Google Drive both store files but they are very different storage systems and were designed for fundamentally different purposes. S3's primary audience is developers and applications while Google Drive's audience is end users. They have different access mechanisms, different service tiering, different pricing models, different integration with other services, etc. Aside from storing files, they are totally different.",
          "score": 45,
          "created_utc": "2026-02-10 13:45:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfsqf",
              "author": "PlanB2019",
              "text": "Yet the product targeted for developers to ideally serve an end product is more expensive than Google Drive. Thatâ€™s the parallel op is trying to point out. Itâ€™s how the offerings are so expensive.",
              "score": 6,
              "created_utc": "2026-02-10 14:52:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pi78z",
                  "author": "nucleustt",
                  "text": "you are correct",
                  "score": 1,
                  "created_utc": "2026-02-10 23:37:48",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m1dlz",
          "author": "DominusGod",
          "text": "I would look at Backblaze B2 for backups. They are way cheaper than AWS. Also Google Drive does have limits",
          "score": 20,
          "created_utc": "2026-02-10 13:34:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oqe9a",
              "author": "magnetik79",
              "text": "Backblaze B2 for sure if you're looking for object storage on cost. \n\nThey also have a compatible S3 API as well, so it can work with AWS S3 based tooling as well.",
              "score": 3,
              "created_utc": "2026-02-10 21:17:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m24v1",
          "author": "the_birds_and_bees",
          "text": "$0.023 / GB is for standard tier access, which is probably overkill for backups. Pricing here [https://aws.amazon.com/s3/pricing/](https://aws.amazon.com/s3/pricing/) but assuming you are happy with slower retrieval times you can go much cheaper.\n\nBroadly, cheaper => slower access times and higher cost per request. You'd need to pick a tier which works for your business (think \"will I feel comfortable waiting {x time} while prod db is down and the boss is breathing down my neck while I wait for the backup to download\").",
          "score": 7,
          "created_utc": "2026-02-10 13:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pipzf",
              "author": "nucleustt",
              "text": "I wanted frequent access and quick retrieval. So that's why I didn't choose Glacier or deep archive",
              "score": -1,
              "created_utc": "2026-02-10 23:40:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ppco5",
                  "author": "mikebailey",
                  "text": "At scale you may also have issues on Google Drive if that was your pattern: https://developers.google.com/workspace/drive/api/guides/limits",
                  "score": 3,
                  "created_utc": "2026-02-11 00:18:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7tzl",
          "author": "Sirwired",
          "text": "Google Drive and S3 are *very* different use-cases; they aren't really comparable.  Google Drive is an end-user file collaboration tool, S3 is an entire enterprise-grade object storage system.",
          "score": 16,
          "created_utc": "2026-02-10 14:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pik43",
              "author": "nucleustt",
              "text": "This is true. \n\nI wanted to create my own Google Drive-type app, but using S3 since we already have the infrastructure.\n\nAlso, if I wanted to make a competitor to Google Drive, I obviously can't compete on costs.",
              "score": 0,
              "created_utc": "2026-02-10 23:39:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pjg40",
                  "author": "Sirwired",
                  "text": "Frankly, because of all the other costs involved with end-user services (development, marketing, support, billing, etc.), you'd have a tough time competing with Google Drive if your back-end storage was free.\n\nGoogle can provide the per-GB costs they do because most users only use a fraction of their quota, vs. S3, which is purely a consumption-based service.",
                  "score": 4,
                  "created_utc": "2026-02-10 23:45:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7sc5",
          "author": "powersline",
          "text": "Check out backblaze B2 and/or Wasabi.   Both are s3 compatible at a fraction of the price",
          "score": 4,
          "created_utc": "2026-02-10 14:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pis8q",
              "author": "nucleustt",
              "text": "Will do, thanks",
              "score": 1,
              "created_utc": "2026-02-10 23:41:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mb225",
          "author": "johndburger",
          "text": "S3â€™s data durability is 99.999999999% (eleven nines). Does Google even advertise a figure for Drive?\n\nI can set up auto-delete (e.g. 30 days) for S3, no such option for Drive, as far as I can tell.\n\nI can configure S3 buckets to automatically move files to cheaper storage under various circumstances. Again, no such option in Google Drive as far as I can tell.\n\nTheyâ€™re just fundamentally different products, designed for very different use cases.",
          "score": 7,
          "created_utc": "2026-02-10 14:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nuk0n",
              "author": "AnomalyNexus",
              "text": ">Does Google even advertise a figure for Drive?\n\nNot directly, but it is backed by same tech as their cloud storage so 11 9s too. All google's consumer facing product stuff is redundancy'd to high heavens.\n\nSuspect the challenge here isn't reliability but rather variability of throughput. All these sync based drive things are all over the place on what performance you get when",
              "score": 2,
              "created_utc": "2026-02-10 18:49:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pp3tx",
                  "author": "mikebailey",
                  "text": "This isnâ€™t how SLAs actually trickle, since adding those layers of abstraction can impede it. Source: our company sells something that sits on top of BQ, yet our SLA is like 99% or something way lower.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:16:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mfarm",
              "author": "PlanB2019",
              "text": "The complaint which is completely valid is the cost storage and egress fees are more than Google Drive. File storage is a pretty common feature set in applications, itâ€™s odd that a file storage service is multiple times more expensive than Google Drive. Listing features on top the core service doesnâ€™t really change it for me, as Iâ€™m sure it doesnâ€™t for others.",
              "score": -6,
              "created_utc": "2026-02-10 14:49:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mr8zy",
                  "author": "justin-8",
                  "text": "I don't know if I'd call the 15% difference the OP pointed out is \"multiple times more expensive\"",
                  "score": 4,
                  "created_utc": "2026-02-10 15:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mygcy",
          "author": "ioannisthemistocles",
          "text": "Years ago I used Google Drive to store shell scripts, before I started using github. \n\nI found that Google inserted hidden characters in the scripts that broke them. I don't know if that is still the case,\n\nNevertheless, a backup isn't a backup unless you do a test restore and validation.",
          "score": 2,
          "created_utc": "2026-02-10 16:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pjox0",
              "author": "nucleustt",
              "text": ">Years ago I used Google Drive to store shell scripts, before I started using github.\n\nYou sound like an OG hacker.\n\nGoogle messing with the EOL char is crazy. Auto \\\\r\\\\n to \\\\n or vice versa",
              "score": 0,
              "created_utc": "2026-02-10 23:46:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mhcds",
          "author": "benpakal",
          "text": "Standard access rate is for live access from apps to files. not backup. Check glacier rates.",
          "score": 1,
          "created_utc": "2026-02-10 15:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mjtlq",
          "author": "OhMyTechticlesHurts",
          "text": "You mean Google Cloud Storage which Google Drive is built on top of. Cloud Storage is an IaaS service while Google Drive is a SaaS product technically speaking.",
          "score": 1,
          "created_utc": "2026-02-10 15:12:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mswdl",
          "author": "ohad1282",
          "text": "1. Dumping the data to Google Drive may be cheap on storage cost, but think about egress/networking cost if taking the data out of your s3 as well.\n2. Google Drive will indeed provide you a copy, but this is not immutable, no proper retention policy, etc - which you probably need for your back solution and compliance needs. Think about ransomware.\n3. You have backup solutions for that - AWS backup, Rubrik, Commvault, etc. Not cheap but real backup solutions.Â \n4. Goofle drive and most backup solutions/vendors - those do not provide INCREMENTAL changes so if you change a small portion of a file/object, you need to save the whole copy.\n4. Eon.io is another backup solution which stores the data deduped, compressed and most importantly for object storage - incrementally. So honestly, I truly belive this is exactly what you need. It will save you a lot of money and protect you properly. Disclaimer - I work for Eon.",
          "score": 1,
          "created_utc": "2026-02-10 15:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n3o8n",
          "author": "Bourne069",
          "text": "I dont see how. I get 1TB of S3 storage from Wasabi for $5 per month per TB...",
          "score": 1,
          "created_utc": "2026-02-10 16:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pl30v",
              "author": "nucleustt",
              "text": "I just learned about Wasabi",
              "score": 1,
              "created_utc": "2026-02-10 23:54:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nd98w",
          "author": "siddharthnibjiya",
          "text": "Backblaze is $7/month for NO data limit. I found that to be quite a compelling option when evaluating",
          "score": 1,
          "created_utc": "2026-02-10 17:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nrzcc",
          "author": "MavZA",
          "text": "Google Drive is not comparable to Amazon S3 in the way youâ€™re intending to use it. Maybe take a look at S3 compatible object storage solutions and compare from there. S3 is extremely resilient object storage whereas Google Drive is file storage that youâ€™d use for day to day files.",
          "score": 1,
          "created_utc": "2026-02-10 18:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plgt0",
              "author": "nucleustt",
              "text": "Yes, with an additional app, I hoped to make S3 behave like Google Drive. But then I saw the costs and noticed it didnt make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:56:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pphf1",
                  "author": "mikebailey",
                  "text": "In the other direction, Drive has more limits than S3 at the filesystem/API level.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:18:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4o8bcg",
          "author": "AdPhysical9992",
          "text": "Does google drive provides programmatic APIs to get the file content and other things , like event triggers that we have in s3?",
          "score": 1,
          "created_utc": "2026-02-10 19:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plw0k",
              "author": "nucleustt",
              "text": "I'm not sure. \n\nIn that sense, there's no comparison. But for simple cloud sync (with a custom S3 app), the cost didn't make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:58:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ppkdw",
              "author": "mikebailey",
              "text": "Yes, thereâ€™s a huge drive SDK\n\nEvent triggers though I donâ€™t think so",
              "score": 1,
              "created_utc": "2026-02-11 00:19:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ppq4q",
          "author": "dubidub_no",
          "text": "[rsync.net](http://rsync.net) is $0.012 per GB per month single region, no ingress/egress. They have a warrant canary.",
          "score": 1,
          "created_utc": "2026-02-11 00:20:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qtvc1",
          "author": "basedcooking",
          "text": "Thereâ€™s also Wasabi, itâ€™s about 5.99/TB - with no egress fees and instant access. But minimum 90 day retention.",
          "score": 1,
          "created_utc": "2026-02-11 04:27:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4siyl8",
          "author": "joeyx22lm",
          "text": "Iâ€™ve done both. I gave up on Google Drive once I got hit with rolling 24hr rate limit for exceeding 750gb data transfer.",
          "score": 1,
          "created_utc": "2026-02-11 13:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1llz",
          "author": "indigomm",
          "text": "S3 has many options depending on what service you need. Look at S3 Infrequent Access, Glacier Flexible or Instant Access, or even Glacier Deep Archive. They are all much cheaper. But be aware of transfer and retrieval costs on some products.",
          "score": 1,
          "created_utc": "2026-02-10 13:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk2wb",
              "author": "nucleustt",
              "text": "I actually needed frequent access.\n\n>But be aware of transfer and retrieval costs on some products.\n\nI'm not a fan of the transfer fees. IMO, the storage fees should be lower to compensate.",
              "score": 1,
              "created_utc": "2026-02-10 23:48:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mgfvc",
          "author": "mojo21136",
          "text": "Building your own backup solution (or any other solved problems) is not a good use of time. Other providers have solved cheaper than you can do and if something goes wrong when restore is necessary it will be a resume generating event.",
          "score": 1,
          "created_utc": "2026-02-10 14:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk942",
              "author": "nucleustt",
              "text": ">Building your own backup solution (or any other solved problems) is not a good use of time. \n\nThat's what I figured out after investigating the costs. I thought it would have been cheaper to host on S3 TBH.",
              "score": 1,
              "created_utc": "2026-02-10 23:49:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mzjnh",
          "author": "blenderman73",
          "text": "Yeah S3 ingress and egress really adds up haha - it turns into a cost monster over time",
          "score": 1,
          "created_utc": "2026-02-10 16:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nixmp",
              "author": "Sirwired",
              "text": "Errr... what ingress charges?  And what do you imagine the egress charges will be for a remote backup?  It's not like these files will be read often, if ever.",
              "score": 3,
              "created_utc": "2026-02-10 17:56:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ow3i6",
                  "author": "blenderman73",
                  "text": "Then drive is fine. When I worked with s3 based raw layers for EMR we were getting extremely heavy unplanned read loads at the prefix level when teams used the backup product which added up surprisingly. Primary due to how we partitioned.\n\nI.E. LIST operations are priced as writes ($0.005/1K) out of aws \n\nOr a glacier + s3 solution works",
                  "score": 1,
                  "created_utc": "2026-02-10 21:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m4fpj",
          "author": "Old_Cry1308",
          "text": "yeah, google drive cheaper. s3 has hidden fees. good luck competing with that.",
          "score": -8,
          "created_utc": "2026-02-10 13:51:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r209uo",
      "title": "Amazon Textract vs GPT",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "author": "nucleustt",
      "created_utc": "2026-02-11 15:24:44",
      "score": 17,
      "num_comments": 18,
      "upvote_ratio": 0.78,
      "text": "I just had a look at Amazon Textract's pricing, and I'm certain that token usage on a multi-modal GPT model can extract the text from an image into a structured JSON document for much less.\n\nWhat are the advantages of using Amazon Textract vs GPT?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tcrbo",
          "author": "kapowza681",
          "text": "Textract is deterministic, so youâ€™ll typically get the same result every time. Itâ€™s much better at recognizing hand written characters. It gives you the precise location of the characters, which may or may not be useful depending on what youâ€™re hoping to accomplish. \n\nYou can also use both. I sometimes pass along the Textract extracted text to the model along with the document/image as a kind of â€œhelperâ€ text.",
          "score": 44,
          "created_utc": "2026-02-11 15:40:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tj7k7",
              "author": "RecordingForward2690",
              "text": "The precise location stuff is really handy. We were building an application that had to deal with copies of ID documents. Once the document was uploaded, we had to obfuscate the Dutch equivalent of the SSN due to privacy regulations. Textract and ImageMagick made that easy.\n\nMind the (relatively low) throughput quota though.",
              "score": 15,
              "created_utc": "2026-02-11 16:11:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w4xat",
                  "author": "trashtiernoreally",
                  "text": "Quotas can be increased both in terms of async submissions per second and simultaneous running requests.Â ",
                  "score": 2,
                  "created_utc": "2026-02-11 23:44:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4tg83s",
              "author": "nucleustt",
              "text": "Those are solid advantages. \n\nAnd you're right, it may be best to use them in combination to increase reliability when reading critical documents.",
              "score": 5,
              "created_utc": "2026-02-11 15:57:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tinpb",
          "author": "kievmozg",
          "text": "I have to slightly disagree on the handwriting part. While Textract is decent, it lacks semantic context. If a handwritten '5' looks like an 'S', Textract often guesses wrong based on pixel shape alone. A Vision LLM (like GPT-4o or Claude) looks at the surrounding text, understands it's a 'Quantity' field, and correctly identifies it as '5'.\n\nâ€‹Textract is definitely superior for bounding boxes (coordinates) and pure speed on massive datasets. But if your goal is extracting structured JSON from complex/messy documents where field logic matters more than pixel-perfect coordinates, Vision models are usually cheaper and more accurate in practice. We actually benchmarked this extensively for ParserData and found Vision models reduced 'logic errors' by nearly 40% compared to raw Textract output.",
          "score": 11,
          "created_utc": "2026-02-11 16:08:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w9nxj",
              "author": "enjoytheshow",
              "text": "We feed our handwritten output from textract into Bedrock with a prompt explaining it to clean it up. We tried all combinations and that was most successful for us",
              "score": 3,
              "created_utc": "2026-02-12 00:11:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4weqhg",
                  "author": "kievmozg",
                  "text": "That stack is definitely robust. We used it too for a while.\n\n\nâ€‹The only reason we switched to direct Vision models was to kill the 'double tax'. Paying for Textract pages plus Bedrock tokens adds up fast at scale. Going direct to Vision cut our latency and bill by about 40% since we skip the OCR step entirely.",
                  "score": 3,
                  "created_utc": "2026-02-12 00:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tvk45",
          "author": "Ok-Data9207",
          "text": "Make an evaluation set and test both. \n\nIf Image is like some ID or bill, textract works really well because it is trained on really large set of such documents and they have different API calls for them.",
          "score": 3,
          "created_utc": "2026-02-11 17:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wkssy",
          "author": "Hydroshock",
          "text": "[This is not my blog](https://hidekazu-konishi.com/entry/amazon_bedrock_for_titling_commenting_ocr_with_claude3_haiku.html), but this guy did some testing using Claude Haiku. There are other blogs where people did similar.\n\nI've done some pretty extensive testing myself with using LLM (mainly Claude 3.7 generation) vs. Textract on scanned paper documents. The main problem I've had is essentially the LLM \"count to 100\" or \"how many r's are in strawberry\" problem.\n\nLLM would often give a slower and incomplete response, hitting token limits, hallucinating details or re-interpret some lines. I tried again more recently and the models flat out do a tool call to Tesseract.\n\nIt really depends what your use case is though and how accurate you need the OCR. If you have a good quality source image with high DPI and text is well aligned, you get a long way. Textract does give a confidence value on the interpreted text and at the end of the day, Textract is using AI/ML for it's engine, it's just not LLM.",
          "score": 2,
          "created_utc": "2026-02-12 01:17:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ttzgx",
          "author": "SpecialistMode3131",
          "text": "1. Integration - part of a huge platform with obvious integration advantages.\n\n2. Stabilized - GPT constantly changes.  Nobody (but you) is QC'ing result quality.  At any point model changes may blow up your entire approach and what then?\n\n3. Focused - its whole job is to extract text.  It'll get better at its one job over time.",
          "score": 1,
          "created_utc": "2026-02-11 17:01:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4w78e0",
          "author": "2BucChuck",
          "text": "The only thing keeping me there is handwriting on forms - claude4.5 was the first model I saw that could get tables and forms as well",
          "score": 1,
          "created_utc": "2026-02-11 23:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wozui",
          "author": "hcsteve",
          "text": "We have a workflow that needs to extract text from unstructured documents and then do some processing and summarization. Weâ€™ve seen better accuracy by extracting with Textract first and then running through a multimodal model for processing, rather than just running raw docs through the model, especially for complex tabular data. It can be more expensive but the improved accuracy is worth it for us in this case.",
          "score": 1,
          "created_utc": "2026-02-12 01:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xgmrc",
          "author": "koinos_bios",
          "text": "Maybe checkout Bedrock Data Automation",
          "score": 1,
          "created_utc": "2026-02-12 04:38:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xv1k3",
          "author": "Sadboy2403",
          "text": "textract is an ML model and GPT is generative AI, if you need to have accurate results go for tetract.",
          "score": 1,
          "created_utc": "2026-02-12 06:36:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ulcu8",
          "author": "Lendari",
          "text": "Textract existed before GPT models.",
          "score": 0,
          "created_utc": "2026-02-11 19:08:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzzckx",
      "title": "(New here) Is each EC2 instance a part of a VPC?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "author": "itspiris",
      "created_utc": "2026-02-09 09:00:41",
      "score": 16,
      "num_comments": 22,
      "upvote_ratio": 0.9,
      "text": "hey guys. as the title shows, im new here. im taking a course from coursera on AWS to diversify my career as a software developer into the cloud and devops maybe.\n\nnot the point, i am reading about the route tables and VPCs and how to secure them. I just wanted to check if all EC2 instances are part of a VPC or not.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4emovt",
          "author": "Wide_Commission_1595",
          "text": "You can think of a VPC as a container for a network, and all of the things attached to that network!\n\nA VPC alone doesn't do anything, but you can create subnets, which require route tables.  You can create an Internet gateway to route to/from the internet, or endpoints (think network port) to give access to other services.\n\nInside the vpc you could put an EC2 instance, or RDS database etc.  if it has an IP address it's got an interface connected to your VPC.\n\nA thing in your VPC can also have a security group which is like a simple firewall which defines what traffic is allowed in or out.  This can reference an IP range, or another security group.\n\nBeyond that there are DHCP options, acls etc but honestly, they're way less important.  When you need them you'll know why and Google will be your friend ðŸ™‚\n\nOne slightly odd definition that is confusing to start with is public/private subnets.\n\nIn a public subnet you route 0.0.0.0/0 to the Internet gateway.  In a private subnet you don't!  That way resources in the private subnet cannot access or be accessed from the internet.  You can add a NAT gateway if you need outbound internet.  Ironically, because the NAT gateway needs Internet access it lives in the public subnet, but your private route tables have a default route to it.\n\nI hope that's helpful.  AWS networking is weirdly simple once you get used to it, but it can be very confusing initially ðŸ‘",
          "score": 21,
          "created_utc": "2026-02-09 09:17:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eolnm",
              "author": "itspiris",
              "text": "thank you bro. it makes sense to have it as a rule, i just wanted to make sure i understood their infrastructure correctly.\ni am now a little confused between the \"network ACLs\" and \"security groups\", but im sure I'll get the hang of it ðŸ™‚. to me they feel like they're exactly the opposite, but it seems that acls have everything open, while security groups have everything closed until you open. don't they have conflicts with each other? we shall know soon enough",
              "score": 2,
              "created_utc": "2026-02-09 09:36:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4f3es1",
                  "author": "Get-ADUser",
                  "text": "> i am now a little confused between the \"network ACLs\" and \"security groups\"\n\nFrom my 3 and a half years as an AWS Support engineer, you're now a member of a large club ðŸ¤£. Think of Network ACLs as \"dumb\" rules that just work on IP address and port numbers, akin to `iptables` and they're applied on the subnet level.  Security Groups are smarter - instead of just IP ranges as sources/targets you can use rules like \"members of this security group\", \"members of another security group\", etc. and they're applied on the security group level (which can span several subnets).\n\nI'd strongly advise you use one or the other, never both if you can help it.  Using both together is just a recipe for confusion when traffic isn't working that you think should be because of interactions between the two.  The one you use should (nearly) always be security groups.  Only use network ACLs if you really know what you're doing and have a specific need.  They usually only come into play when you're doing fancier stuff like VPC peering or connecting your VPC back to your datacenter with a VPN.",
                  "score": 5,
                  "created_utc": "2026-02-09 11:53:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ny662",
                  "author": "Wide_Commission_1595",
                  "text": "In over a decade I've very rarely use ACLs tbh.  Security groups let you define traffic in one direction and the return traffic is automatically allowed, e.g you connect out to something and the return packets can come back in.\nACLs on the other hand are one way.\nIn the distant past you could use them a bit like a waf IP blocker, so your web server is allowing https from 0.0.0.0/0 but 1.2.3.4 is DoS'ing your site.  Block 1.2.3.4 inbound on the VPC and you're good!  It's free, but tbh I'd rather pay for WAF and it's more friendly API and automation ðŸ¤£",
                  "score": 2,
                  "created_utc": "2026-02-10 19:05:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4enm67",
          "author": "ohmer123",
          "text": "Nowadays, yes. There used to be something called classic link in the early days but it was retired.",
          "score": 7,
          "created_utc": "2026-02-09 09:26:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jlaxe",
              "author": "metarx",
              "text": "You call it classic link, but it originally was the only way it worked.  It became classic link, after vpcs were a thing.",
              "score": 1,
              "created_utc": "2026-02-10 02:12:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4elv5w",
          "author": "SnoopJohn",
          "text": "They are as much as any computer(ec2) connected to a network(vpc) is.\nYou can't launch an ec2 without or outside a vpc.",
          "score": 3,
          "created_utc": "2026-02-09 09:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4f3n0w",
          "author": "omerhaim",
          "text": "EC2 launched only in VPC\n\nIn the past there was classic that were not a part of a VPC, but itâ€™s not an option anymore",
          "score": 3,
          "created_utc": "2026-02-09 11:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4elobg",
          "author": "conairee",
          "text": "EC2 instances run *inside* a VPC, they get an IP address from the VPC CIDR block.\n\nImagine if you and your friends are gaming on a LAN, the VPC is like the LAN and your computers are the EC2 instances.",
          "score": 2,
          "created_utc": "2026-02-09 09:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4els1m",
          "author": "swiebertjee",
          "text": "I believe that by default, EC2 instances are part of the default VPC in each region. You can or course create a new/custom VPC and connect them to it.\n\nGood luck on your cloud adventure!",
          "score": 1,
          "created_utc": "2026-02-09 09:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4emta3",
          "author": "Old_Cry1308",
          "text": "yep, every ec2 instance is in a vpc. it's how aws does networking, whether you like it or not.",
          "score": 1,
          "created_utc": "2026-02-09 09:18:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4en23t",
          "author": "undernocircumstance",
          "text": "Yes, this is required now.",
          "score": 1,
          "created_utc": "2026-02-09 09:21:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4enysl",
          "author": "cloudnavig8r",
          "text": "U/Wide_Commission_1595 made the distinction!  EC2 instances need a network address.  That address is part of a subnet, which is part of a VPC.  So indirectly, *yes*\n\nThe truth is, the Subnet is a range of addresses within the VPC.  And, a subnet is associated with a physical Availability Zone.  (The VPC is an address range across the whole region).\n\nSo, an EC2 instance is on a physical server that is inside an Availability Zone.  It will have an address associated to that AZ (subnet).  \n\nEach subnet can have its own route table as well.  By default the VPC level traffic is â€œlocalâ€ between all subnets.",
          "score": 1,
          "created_utc": "2026-02-09 09:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4har35",
          "author": "Important_Winner_477",
          "text": "Essentially, yes if you started your AWS journey anytime in the last decade, every EC2 instance you launch is sitting inside a VPC. There used to be an \"EC2-Classic\" mode where instances sat on a shared flat network, but AWS killed that off years ago. I run a cloud + AI pentesting firm and I have learn to find ancient \"ghost\" instances in legacy accounts, but for a new developer, the VPC is your non-negotiable boundary",
          "score": 1,
          "created_utc": "2026-02-09 18:57:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1y6ri",
      "title": "I built a Python DynamoDB ORM with real async - Rust + Tokio under the hood, GIL released",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "author": "leandro_damascena",
      "created_utc": "2026-02-11 14:02:22",
      "score": 12,
      "num_comments": 14,
      "upvote_ratio": 0.67,
      "text": "Hey r/aws,\n\nI've been working on an open source DynamoDB library called **pydynox**. It's a Python ORM but the heavy lifting happens in Rust via PyO3.\n\nWanted to share how I handle async because I think it's interesting.\n\n## The problem with most Python DynamoDB libraries\n\nThey either do sync-only, or they wrap sync calls with `asyncio.to_thread()`. That's not real async. You're still blocking a thread somewhere.\n\n## What I do instead\n\nThe Rust core uses Tokio (Rust's async runtime) to talk to DynamoDB. When you call an async method from Python, it goes like this:\n\n1. Python `await`s the call\n2. PyO3 hands it to Tokio on the Rust side\n3. Tokio makes the HTTP request without holding the GIL\n4. Result comes back to Python\n\nThe GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\n## Why this matters\n\nThis helps in any Python app â€” Lambda, ECS, FastAPI, Django, scripts, whatever.\n\n- Serialization/deserialization happens in Rust â€” type conversion is fast\n- Compression (zstd) and encryption (AES-GCM) also run in Rust with the GIL released\n- Zero Python runtime dependencies, so installs are small and there are no conflicts\n- On Lambda specifically, cold starts stay lean and warm invocations hit the Rust fast path\n\n## Quick example\n\n```python\nimport asyncio\nfrom pydynox import Model, ModelConfig, DynamoDBClient\n\nclient = DynamoDBClient()\n\nclass User(Model):\n    model_config = ModelConfig(table=\"users\")\n    pk: str\n    name: str\n    email: str\n\nasync def main():\n    user = User(pk=\"USER#1\", name=\"John\", email=\"john@example.com\")\n    await user.save()\n\n    found = await User.get(pk=\"USER#1\")\n    print(found.name)\n\nasyncio.run(main())\n```\n\nSync works too â€” same API, just drop the `await`.\n\n## Performance\n\nSerialization alone is faster because Rust handles the Python-to-DynamoDB type conversion directly instead of going through multiple dict transformations.\n\nThe library is Apache 2.0 and on GitHub.\n\nDocs: [https://ferrumio.github.io/pydynox/](https://ferrumio.github.io/pydynox/)\n\nIf you've tried mixing Rust and Python for AWS stuff, I'd love to hear how it went. Questions are welcome too.\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tabjj",
          "author": "ElectricSpice",
          "text": "> The GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\nPython doesnâ€™t lock up waiting for the network, that would be ridiculous. Other threads will happily run while waiting on the HTTP response.\n\nThe other reasons are more compelling:  boto3 is a humongous dependency and its serde is quite slow.",
          "score": 23,
          "created_utc": "2026-02-11 15:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sxa6c",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 3,
          "created_utc": "2026-02-11 14:22:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t04kx",
              "author": "Turbulent-Log5758",
              "text": "This comment looks more of an AI slop than the library.",
              "score": 12,
              "created_utc": "2026-02-11 14:37:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sxnzw",
          "author": "Spoonyyy",
          "text": "Ayo this sounds awesome. Will check it out.",
          "score": 2,
          "created_utc": "2026-02-11 14:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tdtlf",
          "author": "AdPhysical9992",
          "text": "There is one module called pynamodb , that does the same thing i guess",
          "score": 2,
          "created_utc": "2026-02-11 15:45:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vjn14",
              "author": "KainMassadin",
              "text": "comparing this to pynamo isnt fair for pynamo, lol",
              "score": 6,
              "created_utc": "2026-02-11 21:53:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tfu9n",
          "author": "mylasttry96",
          "text": "Can this be installed in lambda environments ?",
          "score": 2,
          "created_utc": "2026-02-11 15:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ulcyq",
          "author": "idkbm10",
          "text": "Is there something like this for nodejs?",
          "score": 1,
          "created_utc": "2026-02-11 19:08:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52gubg",
          "author": "AttentionIsAllINeed",
          "text": "So much glue to keep a crappy language alive",
          "score": 0,
          "created_utc": "2026-02-12 23:02:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2rc0s",
      "title": "AWS (AI) Support - unassigned case for 24h with Business Support+",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "author": "alex_aws_solutions",
      "created_utc": "2026-02-12 11:47:23",
      "score": 12,
      "num_comments": 15,
      "upvote_ratio": 0.73,
      "text": "I thought the Business Support+ Plan is something different.... but not. Very unsatisfied!",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4zbjg4",
          "author": "kei_ichi",
          "text": "Isnâ€™t â€œbusiness support+ â€œ plan is just â€œdeveloper supportâ€ plan? But they renamed it to look like an â€œupgradeâ€ but in reality that is just a fancy name and you will â€œmostlyâ€ get answers from AI slop because they fired almost all of their support staff and still continue to do do that! To be honest, even enterprise support plan account are getting answers from bot instead of human so with your 29$ per month support planâ€¦good luck to get your support case handled by human!",
          "score": 14,
          "created_utc": "2026-02-12 13:54:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5271t5",
              "author": "PsychologicalAd6389",
              "text": "You do realize that if you click the option to get a human youâ€™ll get a human",
              "score": 2,
              "created_utc": "2026-02-12 22:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o529ixc",
                  "author": "kei_ichi",
                  "text": "Ya, but in â€œtheoryâ€ only. Again, good luck to get support from human with that support plan. You â€œwillâ€ but with the cost of â€œlong longâ€ waiting queue because another people demand the same (because AI slop just respond with nonsense answers) but how many support staff â€œleftâ€ in that company????",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yu21k",
          "author": "Burekitas",
          "text": "Click reply and pick the Chat option, which would expedite the case.",
          "score": 19,
          "created_utc": "2026-02-12 12:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z8b01",
          "author": "AntDracula",
          "text": "Oops sorry about that. Better layoff another 10,000!",
          "score": 15,
          "created_utc": "2026-02-12 13:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ywsdw",
          "author": "ManBearHybrid",
          "text": "They fired all their support staff in favour of AI and customer service is suffering because of it. I wonder if they consider this a bad thing or if it's just worth it to save from paying all those salaries. ",
          "score": 7,
          "created_utc": "2026-02-12 12:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yzagw",
              "author": "CircularCircumstance",
              "text": "People complaining on Reddit comes at no added costs for AWS.  They'll only respond if it begins to affect the bottom line, IE enterprise customers taking their business elsewwhere.\n\nUnfortunately for so many of us, we are so deeply locked into AWS that the costs for us to move to another provider is massive.",
              "score": 6,
              "created_utc": "2026-02-12 12:40:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8l2j",
                  "author": "AntDracula",
                  "text": "Enshittification hits AWS",
                  "score": 2,
                  "created_utc": "2026-02-12 13:37:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4zgt3y",
                  "author": "CubsFan1060",
                  "text": "This is a great argument for shying away from provider specific tools.  If you build heavily on DynamoDB and Lambda, you're going to struggle to ever be able to actually think about moving.\n\nEveryone likes to talk about the complexity of Kubernetes (which is fair), but if your stack is EKS + postgres + S3, it still isn't _easy_ to move, but it's much much more possible to move.",
                  "score": 1,
                  "created_utc": "2026-02-12 14:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yzb3f",
              "author": "Sirwired",
              "text": "No, they did *not* fire \"all\" the support staff.  Silly exaggeration like this does nobody any favors.",
              "score": -7,
              "created_utc": "2026-02-12 12:40:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8m9r",
                  "author": "AntDracula",
                  "text": "Hi Andy",
                  "score": 0,
                  "created_utc": "2026-02-12 13:38:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o501vfx",
          "author": "mediocretes",
          "text": "Yeah, this is par for the course. Thereâ€™s no point to paying for Amazon support. Iâ€™ve never once had them meet SLAs when anything significant was happening.",
          "score": 2,
          "created_utc": "2026-02-12 16:07:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yvxwj",
          "author": "AWSSupport",
          "text": "Hello, \n\nThanks for providing your case ID. \n\nI can confirm that your case is in the correct queue. I've reached out internally to have this looked into. \n\nBe sure to keep an eye open for further correspondence from our Support team.\n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-12 12:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ywqvv",
              "author": "alex_aws_solutions",
              "text": "Thank you Craig.",
              "score": 1,
              "created_utc": "2026-02-12 12:22:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ythgl",
          "author": "AWSSupport",
          "text": "Hello,\n\nI'm sorry for the frustration this has caused. Please DM us your case ID, so we can take a closer look. \n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-12 11:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r37abo",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "author": "magnetik79",
      "created_utc": "2026-02-12 22:16:45",
      "score": 12,
      "num_comments": 12,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1r37abo/aws_backup_adds_crossregion_database_snapshot/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5282yb",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o529jr4",
          "author": "freeriderblack",
          "text": "... and RDS still behind. I have never understood why they don't keep consistency between Aurora and RDS when it comes to AWS Backups features.",
          "score": 4,
          "created_utc": "2026-02-12 22:24:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52mmu0",
              "author": "naggyman",
              "text": "Aurora and RDS have very different tech stacks under the hood - so Iâ€™m guessing itâ€™d be like developing two entirely separate features. \n\nSo the question then becomes - do you have to hold off releasing support for one because you havenâ€™t completed development on support for the other.",
              "score": 3,
              "created_utc": "2026-02-12 23:34:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o52jq4v",
          "author": "The_Tree_Branch",
          "text": "> Now do cross-region and cross-account in a single backup task.\n\nUnless I'm misunderstanding you, this already exists as of October 2025: https://aws.amazon.com/about-aws/whats-new/2025/10/aws-backup-single-action-database-snapshot-copy-regions/",
          "score": 4,
          "created_utc": "2026-02-12 23:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52lkv4",
              "author": "magnetik79",
              "text": "ðŸ¤¦â€â™‚ï¸ oh geez, I totally missed this announcement. Thanks for the heads up - you're indeed correct!\n\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/backup-feature-availability.html#features-by-resource\n\n> Amazon RDS, Aurora, DocumentDB, and Neptune now support cross-Region and cross-account snapshot copying in a single action. \n\nNice! Just need to add KMS keys to existing clusters and.... _recreate them_. Still this makes the process much nicer.",
              "score": 1,
              "created_utc": "2026-02-12 23:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52l92m",
          "author": "Mutjny",
          "text": "\"Logically\" air-gapped throw some big air quotes around that one.",
          "score": 2,
          "created_utc": "2026-02-12 23:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530b5p",
          "author": "kopi-luwak123",
          "text": "It still does not work with AMK encrypted stuff, right ?",
          "score": 1,
          "created_utc": "2026-02-13 00:53:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o533ji1",
              "author": "magnetik79",
              "text": "No I would assume not - anytime you need to move a backup across regions or accounts you need to be using KMS keys - as Amazon managed keys are unique to each AWS account and region and can't used beyond those bounds.",
              "score": 1,
              "created_utc": "2026-02-13 01:13:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ctrs",
                  "author": "kopi-luwak123",
                  "text": "Yeah, so the intermediate vault is still required.",
                  "score": 1,
                  "created_utc": "2026-02-13 02:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5282x0",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -3,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1f458",
      "title": "Securing OrganizationAccountAccessRole role",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1f458/securing_organizationaccountaccessrole_role/",
      "author": "davestyle",
      "created_utc": "2026-02-10 22:18:32",
      "score": 8,
      "num_comments": 17,
      "upvote_ratio": 0.83,
      "text": "Morning,\n\nThe droids in security are unhappy with my OrganizationAccountAccessRole role's having Administrator managed policy attached.\nI want to keep the role for access in case I ever brake Identity Center but I need to give it less permissions.\n\nAnyone have advice on a suitable policy?",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1r1f458/securing_organizationaccountaccessrole_role/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4p4ztn",
          "author": "sirstan",
          "text": "\"Dear Security;\n\nThis role is used for cross-account administrative tasks in an AWS Organization structure and can only be assumed from our central organizational account that requires multi-factor auth, two-person approval, and all access is logged and alerts the security team.  Without this we lose the ability to provide administrative controls and rollout rulesets.\"\n\nIs roughly the email I've written a half dozen times.\n\nGrab your TAM for a call (and have them bring a security resource) and bring the Droids in to talk.",
          "score": 12,
          "created_utc": "2026-02-10 22:26:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4phixs",
              "author": "Freedomsaver",
              "text": "This. Educate your security team and don't let them dictate non-AWS-best-practice architectures just so they can covery their asses and feel like they did their job.\n\nIf you have not done so already, use SCPs to protect the OrgAccess role from modification, especially it's trust policy.\n\nShow the security team, that this approach is exactly how AWS Control Tower sets things up and show them the AWS Security Reference Architecture: https://docs.aws.amazon.com/prescriptive-guidance/latest/security-reference-architecture/introduction.html",
              "score": 5,
              "created_utc": "2026-02-10 23:33:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4p5oo1",
              "author": "davestyle",
              "text": "That has been the response in the past but they've evolved a bit and learned to chatgpt things and the blibbering thing told them its a great idea and best practice and they're so smart and handsome.",
              "score": 2,
              "created_utc": "2026-02-10 22:29:50",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4p7fvj",
                  "author": "[deleted]",
                  "text": "I would bring them into a meeting and have them try elaborate themselves on why it isn't but don't let them know ahead of time so they can't have GPT on the side already set up with stuff. \n\nI've had to do that where I set up a meeting to go over some security stuff and brought up that role and why are they're complaining about it and then pointed to AWS doc's best practice and repeated the fact that it's centrally managed and it's only accessible by people that have access to the payer account and you have to have SSO ability to even use it and we only use it via oidc mechanisms that are reviewed and approved by people that know and use code daily versus them who don't even know how to code or read AWS's documentation.\n\nYou just need to make them try to tell you that AWS doesn't know best practice when it comes to a multi account access mechanism and if they know so much more why don't they come up with the actual permissions needed for it since they're complaining about it",
                  "score": 4,
                  "created_utc": "2026-02-10 22:38:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4p6se9",
              "author": "[deleted]",
              "text": "This is basically the same response that I have had to have multiple times",
              "score": 1,
              "created_utc": "2026-02-10 22:35:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4p6coz",
          "author": "BacardiDesire",
          "text": "Brooo sounds so familiar haha now with the LLMâ€™s whispering witchcraft in their ears haha.\n\nThe other day someone asked me what the contact details for an AWS account were because they wanted to mail AWS and ask them to delete a dns record they thought was fishy ðŸ¤ªðŸ˜‚ðŸ˜‚",
          "score": 4,
          "created_utc": "2026-02-10 22:33:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p8umh",
          "author": "SuperOsWALD89",
          "text": "I would argue against it, and suggest looking into an org wide scp preventing changes to the assumerolepolicy and policies of the role in the member accounts.\n\nThat would be my main concern if any, assuming best practices in general is followed regarding what is in the master account vs everything else. \n\nIf you are managing a highly regulated organization, I would consider to try to limit the accounts in scope, and remove the role from those in scope to just have it under the billing umbrella.",
          "score": 3,
          "created_utc": "2026-02-10 22:46:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p9kkc",
              "author": "tlf01111",
              "text": "This was our approach.  SCPs are great for this.",
              "score": 3,
              "created_utc": "2026-02-10 22:50:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4papj2",
              "author": "davestyle",
              "text": "Removing that role feels dangerous though seeing how I've already disabled the root account.  \nReally have to hope IdC never breaks.",
              "score": 1,
              "created_utc": "2026-02-10 22:56:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4q4cq1",
          "author": "SammichAffectionate",
          "text": "If you need something in case identity breaks, their language is a break glass account. A break glass account is never used, but tested once in a while. It also has alerts if it is ever used. \n\nhttps://github.com/aws-samples/aws-cross-account-break-glass-example",
          "score": 2,
          "created_utc": "2026-02-11 01:46:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5218to",
          "author": "CSYVR",
          "text": "Create a stackset that deploys a \"Breaktheglassinemergencyrolethatsonlyassumablebythese3peoplefromthemanagementaccount-role\" to all member accounts with exactly the same policy, remove the other and call it a day. Not worth the brainpower.",
          "score": 1,
          "created_utc": "2026-02-12 21:43:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p6ljh",
          "author": "alex_aws_solutions",
          "text": "Try an AccountAccessLimitedRole with ReadOnly or ViewOnly and extend it with iam:PassRole and sts:AssumeRole. If you need to restrict it a little bit more you can add a Condition like PrincipleAccoutID.",
          "score": 0,
          "created_utc": "2026-02-10 22:34:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p7fs3",
              "author": "davestyle",
              "text": "You mean create a new role (AccountAccessLimitedRole) and let it assume another higher privilege role?",
              "score": 1,
              "created_utc": "2026-02-10 22:38:54",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4peinp",
                  "author": "alex_aws_solutions",
                  "text": "Not exactly. Keep the existing one (but unattached) as backup so you can activate it manually if needed. Create a new one as I mentioned. The goal is to restrict the privileges.",
                  "score": 2,
                  "created_utc": "2026-02-10 23:17:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1d9ra",
      "title": "AWS Marketplace KYC",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1d9ra/aws_marketplace_kyc/",
      "author": "olearyboy",
      "created_utc": "2026-02-10 21:09:06",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Filled out all the forms, got preliminary approval then started the KYC. \n\nUploaded back statements, certificate of validity, passport, internet bill for address verification. \n\nAnd then got rejected\n\n\\- Passport not signed (ehhh yeah biometric passports aren't signed, haven't been since \\~2008) \n\n\\- Something about valid business docs, it requested a certificate of validity - i provided a cert of validity, had to go pay for the damn thing. \n\n  \nThe help pages go to 404's \n\nThere's not enough places to upload more supporting doc, replaced passport with drivers license front & back.\n\n  \nI can already tell they're still not requesting the correct documents like those required for say I-9 (even though I'm not getting work, it's the fastest validation for the US) \n\nFor some unknown reason they're processing all of the details in the EU?? I've verified that I'm on the US portal, and that's it's recognized I'm registering a US business  \n\n\nSupport doesn't seem to be available, and I am at a loss as to what to do next",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r1d9ra/aws_marketplace_kyc/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4spva1",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear about the trouble you're having with registering for AWS Marketplace. You can contact our Support team by filling out the following form: \n\nhttp://go.aws/contact-us-marketplace.\n\nIf you already have a case open with them, you can chat message us the case ID, and we'll assist you further.\n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-11 13:41:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4voj8a",
              "author": "olearyboy",
              "text": "Contact form filled out thanks for the outreach ",
              "score": 1,
              "created_utc": "2026-02-11 22:16:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vpx1r",
                  "author": "AWSSupport",
                  "text": "Hi there, \n\nWe're glad we could help with this!\n\n\\- Gee J.",
                  "score": 1,
                  "created_utc": "2026-02-11 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1u1hx",
      "title": "Insert my cert to Traefik in ECS via Terraform/Secrets Manager",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "author": "Budget-Industry-3125",
      "created_utc": "2026-02-11 10:39:43",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 0.82,
      "text": "Hi,\n\nI need to create a configuration where I implement a NLB for a TLS passthrough towards my Traefik container within the cluster.\n\nThe traefik container needs to serve my own certificate, and i don't know how to import it. \n\nI tried to use secrets manager, but I don't know how to implement it. is there any other way? ",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4sclg0",
          "author": "Living_off_coffee",
          "text": "Have you tried AWS Certificate Manager (ACM)? It's designed for things like this.\n\nBut is there a specific reason you want to have TLS pass through with the NLB? You can terminate it at the load balancer instead which might be easier.",
          "score": 6,
          "created_utc": "2026-02-11 12:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4siyfo",
          "author": "KayeYess",
          "text": "What was the challenge with pulling the certificate keys from Secrets Manager? It's just like pulling any other secret.\n\n\nYou could also pull your certs from S3, SSM or ACM (which now allows private keys to be exported).",
          "score": 2,
          "created_utc": "2026-02-11 13:01:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t7avu",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.  \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tbmbm",
                  "author": "KayeYess",
                  "text": "OK. The certs are in secrets manager.\n\n\ntraefik itself is not capable of accessing aws secrets but a separate script (like cert-manager) can be used to sync them to kube secrets, which trafiek can refer to.",
                  "score": 2,
                  "created_utc": "2026-02-11 15:35:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4skir6",
          "author": "safeinitdotcom",
          "text": "Hi,\n\nWhat exactly failed for you in implementing secrets manager for this? Typically you should've been able to inject the secrets to ecs and then write them to files during startup :D ",
          "score": 2,
          "created_utc": "2026-02-11 13:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t79ds",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.   \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r06jkd",
      "title": "Verification loop - \"documents not required\" then reverify 2 days later",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "author": "teasingcupcakeLuv",
      "created_utc": "2026-02-09 15:04:52",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.68,
      "text": "Went through AWS verification. Submitted docs multiple times because support kept asking for the same stuff repeatedly.\n\nFeb 7 - Two emails same day. One says hold removed. Another says \"we no longer require verification documents, disregard the request.\"\n\nFeb 9 - New email. Account on hold for verification again. Need to submit docs by Feb 14 or suspension.\n\nThey just told me documents weren't required 48 hours ago. Now I'm back at square one with a deadline.\n\nSupport has been completely useless. Generic responses, no actual help. Given the recent layoffs and AI support rollout, I'm guessing this is just automated systems conflicting with each other while there's nobody left to actually fix it.\n\nAnyone successfully escaped one of these verification loops? Or is this just the new normal with AWS running everything through automation now?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4g8sx6",
          "author": "AWS_Chaos",
          "text": "If recent posts have taught us anything, back all your stuff up OUTSIDE of this account if it is production! :)",
          "score": 7,
          "created_utc": "2026-02-09 15:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g0c6y",
          "author": "AWSSupport",
          "text": "Hi there, \n\nSorry to hear about your account verification issue. \n\nWe're unable to discuss account-specific info here, but you can send us a private chat with your case ID and we'll check from our end that the case has been routed correctly. \n\n\\- Reece W.",
          "score": -1,
          "created_utc": "2026-02-09 15:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g8xwv",
          "author": "AWSSupport",
          "text": "Thanks for the info. \n\nAs explained, we're unable to discuss account-specific info here, but I reviewed your Support case and I see that our team have provided the final decision. We're unable to influence the outcome or discuss the matter further here as well.  \n\nApologies if the outcome was unfavorable.\n\n\\- Reece W.",
          "score": -3,
          "created_utc": "2026-02-09 15:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4glqsl",
              "author": "teasingcupcakeLuv",
              "text": "Reece, you need to actually look at what happened.\n\nMy account was REINSTATED on February 7, 2026. I have the emails from AWS confirming the hold was removed and verification documents were no longer required.\n\nOn February 9, 2026, my account was suspended AGAIN with a new verification request.\n\nThe \"final decision\" you're referring to was reinstatement. This is a different suspension that happened 48 hours after AWS told me my account was verified and clear.\n\nYour response shows you didn't even review what actually happened before responding. Please look at the facts instead of giving boilerplate responses about final decisions.",
              "score": 5,
              "created_utc": "2026-02-09 16:59:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxkw7y",
      "title": "Quickly register phone number for SNS",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qxkw7y/quickly_register_phone_number_for_sns/",
      "author": "healthiestsalad",
      "created_utc": "2026-02-06 15:37:39",
      "score": 6,
      "num_comments": 10,
      "upvote_ratio": 0.88,
      "text": "Hello, I am trying to spin up an SNS system. I created a topic and when I try to add a phone number to the subscription, i get this error:\n\nAn error occurred while attempting to add a phone number to the SMS sandbox. The phone number was not added.\n\nError code: UserError - Error message: No origination entities available to send\n\n  \nI figured out that this was due to me not setting up an origination number, which I need to resgister for in AWS. However, it says after registering it can take up to two weeks to be verified. \n\nCan I register a phone number to send out the texts quickly? This is just for a sandbox environment. \n\nThank you! ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qxkw7y/quickly_register_phone_number_for_sns/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3x22ia",
          "author": "sryan2k1",
          "text": "\"How quickly can I send spam?\"\n\n  \nThe protections are there for a reason. ",
          "score": 14,
          "created_utc": "2026-02-06 15:41:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x81om",
              "author": "healthiestsalad",
              "text": "I agree, however since sandbox mode can only send to verified numbers this shouldnt be a concern",
              "score": 3,
              "created_utc": "2026-02-06 16:09:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x2r4e",
          "author": "Old-Astronomer3995",
          "text": "Sending SMS with AWS is not easy if you want to use this kind of features outside Sanbox because they donâ€™t want to spam people and break Telco laws. \n\nYou can send SMS in sandbox without a problem. For test purposes it shouldnâ€™t matter which numer sends this sms.",
          "score": 3,
          "created_utc": "2026-02-06 15:44:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x7xxo",
              "author": "healthiestsalad",
              "text": "How do I do this? Is there a resource you can point me to? Thank you",
              "score": 2,
              "created_utc": "2026-02-06 16:08:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3xaw4f",
                  "author": "Old-Astronomer3995",
                  "text": "AWS SNS --> Mobile --> Text messaging (SMS) --> \"Sandbox destination phone numbersÂ (1)\". You will get SMS on this phone number and you have to accept it.\n\nThen you can use this number in Subscriptions as Endpoint when you choose SMS as protocol.\n\nYou can have maximum 10 numbers as destination in sandbox.  \n[https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox.html](https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox.html)\n\nIf you want to leave sandbox you need to create ticket to AWS and have valid reason, your account has to be trusted etc.\n\n[https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox-moving-to-production.html](https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox-moving-to-production.html)\n\nMany things like delegated number, sender id depend on your country and country to which you want to send sms [https://docs.aws.amazon.com/sms-voice/latest/userguide/sender-id-request.html](https://docs.aws.amazon.com/sms-voice/latest/userguide/sender-id-request.html)",
                  "score": 7,
                  "created_utc": "2026-02-06 16:22:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xeygj",
          "author": "ronkinkade",
          "text": "In my experience, 10DLC registration through developer-heavy platforms like AWS can feel like shouting into a void. It is incredibly frustrating to wait weeks just to get a \"rejected\" notice with no clear explanation why.  \n  \nUsually, these rejections happen because of tiny details in your opt-in language or missing disclaimers on your web forms. Carriers are very picky about seeing exactly how people sign up.  \n  \nTo be honest, it shouldn't be this hard. We handle the 10DLC mess for business customers (pre-built vs build-your-own). Our team manually reviews your registration to ensure it passes the first time. Most registrations are complete within 1-2 business days.  \n  \nFull disclosure: I'm with the team at Text-Em-All. We focus on doing SMS marketing and mass messaging the right way so your messages actually deliver without the technical headaches.",
          "score": 2,
          "created_utc": "2026-02-06 16:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yu5in",
          "author": "omeganon",
          "text": "This is not an AWS specific delay. This registration and approval is done with and by a third party entity for any business/commercial use of SMS messaging (e.g. not from your personal phone). That entity is The Campaign Registry (TCR), which is made up of those mobile network operators that control the destination phone networks. They must review and approve SMS applications from \\_all\\_  providers, not just AWS. They review the application and example campaigns that you have provided, and make a determination as to whether that is acceptable on the networks. Only once they approve your campaigns will a 10DLC number be issued that Amazon can then use to send your content.\n\nThe timelines are based on the estimated processing times of TCR.",
          "score": 1,
          "created_utc": "2026-02-06 20:48:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0e1ar",
      "title": "Opinion: LEX bots are a poor fit for connect integrations.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0e1ar/opinion_lex_bots_are_a_poor_fit_for_connect/",
      "author": "DrollAntic",
      "created_utc": "2026-02-09 19:34:34",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 0.69,
      "text": "Lex bots use a legacy keyword-based utterance matching approach for intent selection. For all but the simplest contact center solutions, this isnâ€™t a great fit.\n\nConversational promptâ€“based intent selection is more accurate, provides a better CX experience, and eliminates the need for questions designed to constrain CX replies to specific keywords. It also removes the painful maintenance work of managing long keyword lists to keep intent matching accurate.\n\nTo put it more bluntly, I see Lex bots as technical debt. I continually have to engineer around them to create dynamic interactions that feel like real conversations, rather than a â€œbot with slotsâ€ experience.\n\nI believe a new type of â€œGet Customer Inputâ€ block is needed â€” one that can interact directly with my prompts and Bedrock. This would allow seamless data exchange between Connect and the conversational AI layer, enabling path and route selections based on GenAI responses rather than basic keyword matching.\n\nIâ€™m aware that Lex now supports â€œgenerative assessmentâ€ for keyword intents. However, in my testing, enabling this made intent selection worse, not better. The reality is that keyword-based selection simply doesnâ€™t work for advanced conversational interactions â€” especially when customers may not know the exact keyword that corresponds to their reason for calling.\n\nIâ€™m a huge fan of Connect and have used it for years, but lately, working with Lex has become frustrating. It creates more barriers than bridges, and I believe thatâ€™s a serious issue.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r0e1ar/opinion_lex_bots_are_a_poor_fit_for_connect/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4l08tw",
          "author": "AWSSupport",
          "text": "Hello,\n\nYour feedback is appreciated.\n\nI've shared this internally for further review.  \n\n\\- Adri N.",
          "score": 2,
          "created_utc": "2026-02-10 08:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4maggn",
              "author": "DrollAntic",
              "text": "Thanks Adri!  I appreciate you passing this along.\n\n",
              "score": 1,
              "created_utc": "2026-02-10 14:24:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50k021",
          "author": "dmaciasdotorg",
          "text": "Lex has been and continues to be one of the weakest point of the whole Connect ecosystem. AWS tries to bolt on Bedrock on it, but in my opinion there needs to be a complete different service that AWS needs to create here. Some sort of understanding action service that has conversation, outcomes, and guardrails all in one place. I doubt this would every happen though.",
          "score": 2,
          "created_utc": "2026-02-12 17:31:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50xau1",
              "author": "DrollAntic",
              "text": "I agree with you. I told an AWS support tech last week that LEX is technical debt for connect, they need something better. Let's hope the feedback to the team results in a better integration. The number of times I've been in a design meeting engineering around LEX limits, is a problem. :) ",
              "score": 1,
              "created_utc": "2026-02-12 18:33:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r324m8",
      "title": "AWS Cognito Experience",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "author": "True_Context_6852",
      "created_utc": "2026-02-12 18:59:57",
      "score": 6,
      "num_comments": 17,
      "upvote_ratio": 0.8,
      "text": "Hello  Good People ,\n\nOur org are planning to  migrate the our legacy app sign up process to  AWS Cognito . So  plan is First start the JIT with lambda for new sign up  and later  second step to  migrate all  user to  Cognito and forced reset password . final steps  when all looks fine than enable MFA to all  users . My question is AWS Cognito  right step or should we look other options  like okta or OAuth ? What you people have experienced during migration  ? What other area we need to look so existing user not lost the credentials?  \n\n ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o516zjd",
          "author": "Whend6796",
          "text": "Look elsewhere. \n\n- The documentation is notoriously confusing and poorly organized\n- The service has layers of abstraction that make simple tasks complicated\nAPI Design Issues\n- Inconsistent and unintuitive naming conventions\n- Methods that donâ€™t follow AWS naming patterns used elsewhere\n- Confusing parameter requirements and error messages\n- The SDK can be clunky to work with\nLimited Flexibility\n- User migration from existing systems is painful\n- Customization options for authentication flows are restrictive\n- The hosted UI is difficult to customize and looks dated\n- Hard to implement certain common auth patterns\nToken Management Problems\n- Token refresh flows can be confusing\n- Limited control over token lifetimes and claims\n- Issues with token validation in certain scenarios\nDeveloper Experience\n- Simple tasks often require digging through documentation and Stack Overflow\n- Error messages that donâ€™t clearly explain what went wrong\n- Testing authentication flows locally is cumbersome",
          "score": 22,
          "created_utc": "2026-02-12 19:19:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o518j8p",
          "author": "MuffinMan_Jr",
          "text": "Im using cognito right now for my app, and the developer experience is terrible lol\n\nThat being said, you'd get lots of free MAU so I guess that's cool",
          "score": 24,
          "created_utc": "2026-02-12 19:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o517lty",
          "author": "Wide_Commission_1595",
          "text": "I am usually in the \"AWS all the things\" camp, but Cognito is a tricky one.\n\nCognito _can_ be great for simple sign up flows.  It can even be pretty good with complex federations.  It's also damned cheap compared with other IdPs, but....\n\nThere's a ton of wiring Lambda functions into hooks to make it work the way most people want it to.  If you don't need those things, go with Cognito every day of the week.\n\nIf you want something a little more \"managed\" that just works, I have found external identity providers to be a lot simpler to use.\n\nWe use Okta, but basically any OIDC or SAML IdP (that's all of them!) works well.\n\nYou can even assume roles with web identity etc to do external-IdP-to-AWS role assumption.\n\nGenerally speaking, an external IdP will be simpler, but more expensive, especially as user numbers grow.  Cognito requires more plumbing, but is AWS-native.",
          "score": 11,
          "created_utc": "2026-02-12 19:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530s9s",
          "author": "MrStu56",
          "text": "It's horrible to work with, but when it's up and running it's cheap and reliable. If I had one 2026 AWS wish it would be for AWS to give this service the once over, take a look how people are using it now vs what was envisioned and then re-document it like their other services. This has to be the most opaque service I've ever worked with on AWS. ",
          "score": 3,
          "created_utc": "2026-02-13 00:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o518nbb",
          "author": "BadDescriptions",
          "text": "If you have good engineers then use Cognito. If you have bad engineers and loads of money then use okta/auth0",
          "score": 4,
          "created_utc": "2026-02-12 19:27:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53c1ll",
              "author": "BoostedHemi73",
              "text": "This is the most concise advice Iâ€™ve seen on this topic.\n\nCognito is full of footguns. Test carefully and completely. If you are using CloudFormation, pay very careful attention to the defaults that are applied (like case sensitive email).\n\nBut the price is great for low/moderate MAU.",
              "score": 3,
              "created_utc": "2026-02-13 02:05:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o513pvk",
          "author": "SoggyGrayDuck",
          "text": "Maybe you can clear something up for me. We had a handful of our data engineers converted to BI engineers but they work with cognito? That's confusing to me",
          "score": 1,
          "created_utc": "2026-02-12 19:03:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o519g3k",
          "author": "Alternative-Expert-7",
          "text": "Cognito is cheaper comparing to AuthO or Okta. Or the cheapest if you have big number of users.",
          "score": 1,
          "created_utc": "2026-02-12 19:30:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51a8mz",
          "author": "finitepie",
          "text": "i'm currently building a fully multi tenant rbac platform based on cognito, using the new managed login and no amplify lib whatsoever (best decision ever). and i like it a lot. ",
          "score": 1,
          "created_utc": "2026-02-12 19:34:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o51qwzb",
          "author": "macgoober",
          "text": "Cognito is dirt cheap if your MAU is less than 50k. The dev experience without something like sst.dev is a total nightmare tho.",
          "score": 1,
          "created_utc": "2026-02-12 20:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5234rn",
          "author": "Prestigious_Pace2782",
          "text": "The dev experience is pretty poor, but itâ€™s nice to have it all in CDK and itâ€™s cheap and mostly just works once itâ€™s set up. \n\nI normally start a new project with cognito and use it until it becomes painful or doesnâ€™t support something I need. Sometimes that doesnâ€™t happen and itâ€™s fine.\n\nHave used it at work in some pretty big stuff and had to get pretty in the weeds with apig caching and stuff.\n\nTLDR; Itâ€™s cheap and works well but is feature poor and a bit painful to learn.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52vbqj",
          "author": "mouthbuster",
          "text": "Cognito is pain\nOkta/Auth0/Clerky will all get the job done the easiest at the highest cost\n\nCheck out Keycloak if you have the engineering bandwidth - it can do anything youâ€™d ever want for the sweet cost of hosting it. Can meet any regulatory compliance need Iâ€™ve ever ran into, and you can host this thing anywhere.",
          "score": 1,
          "created_utc": "2026-02-13 00:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535f4b",
          "author": "texxelate",
          "text": "Donâ€™t use Cognito if you have any choice whatsoever. Youâ€™ll have another legacy app sign up process from day 1.",
          "score": 1,
          "created_utc": "2026-02-13 01:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53fgwe",
          "author": "cuddle-bubbles",
          "text": "horrible but great for your resume. if ur the engineering manager and dont have to do it yourself. may be a good idea to let your developers suffer while you add a great bullet point to your resume at the end of it",
          "score": 1,
          "created_utc": "2026-02-13 02:26:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}