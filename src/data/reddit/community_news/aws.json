{
  "metadata": {
    "last_updated": "2026-01-19 16:49:57",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 112,
    "file_size_bytes": 183007
  },
  "items": [
    {
      "id": "1qds6k2",
      "title": "AWS flips switch on Euro cloud as sovereignty fears mount",
      "subreddit": "aws",
      "url": "https://www.theregister.com/2026/01/15/aws_european_sovereign_cloud/?td=rt-3a",
      "author": "NISMO1968",
      "created_utc": "2026-01-15 18:51:57",
      "score": 401,
      "num_comments": 192,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qds6k2/aws_flips_switch_on_euro_cloud_as_sovereignty/",
      "domain": "theregister.com",
      "is_self": false,
      "comments": [
        {
          "id": "nztiz50",
          "author": "teo-tsirpanis",
          "text": "My ‚ÄòThe AWS European Sovereign Cloud is operated exclusively by EU citizens located in the EU‚Äô t-shirt is raising many questions already answered by the t-shirt",
          "score": 18,
          "created_utc": "2026-01-15 23:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o006nun",
              "author": "SoldadoAruanda",
              "text": "I feel like it's suspicious,  as if I move to a new town, and my neighbor introduced himself by saying,  \"Hi, my names Jeff, and don't worry,  I don't murder people in my basement.\"",
              "score": 4,
              "created_utc": "2026-01-16 22:19:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsbh4j",
          "author": "arwinda",
          "text": "Has the USA, using the Cloud Act, still access to the data? Yes or no.",
          "score": 81,
          "created_utc": "2026-01-15 19:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzse14r",
              "author": "ShakataGaNai",
              "text": "Clearly AWS's goal is \"No\", because if it can still be CLOUD'd then it's effectively useless. But that's going to be in a court of law to try and untangle that. It's a cloud infra in Europe, run by Europeans, run by a new European company,  independent of anything American.",
              "score": 48,
              "created_utc": "2026-01-15 19:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzser32",
                  "author": "arwinda",
                  "text": "The Cloud Act allow access as long as the European company is a subsidiary. For AWS this requires a fully independent company. Which also pays all taxes in Europe, as example. No more money extraction to the US.",
                  "score": 34,
                  "created_utc": "2026-01-15 19:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvttyk",
                  "author": "afroisalreadyinu",
                  "text": "\\> independent of anything American\n\nnamed AWS, same hardware, software and API, funded by the American entity, so I doubt this.",
                  "score": 5,
                  "created_utc": "2026-01-16 07:49:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz4tha",
                  "author": "Hopeful-Programmer25",
                  "text": "I simply don‚Äôt believe there is no link to the parent US AWS company, otherwise it‚Äôs not a subsidiary, it‚Äôs a competitor to US AWS. if no money is flowing to the US parent then AWS has effectively withdrawn from the EU market.\n\nObviously, it hasn‚Äôt so the fact it‚Äôs a subsidiary means that the US can easily apply pressure to the parent. Legality means nothing if the US parent can just replace the CEO and board of an ‚Äúindependent‚Äù subsidiary as they own all the shares with people who are compliant.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0fgxf2",
                  "author": "ProfessorNoPuede",
                  "text": "Ah, yes, law. The American republican administration really cares about law. \n\n/s, in case it wasn't obvious.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:40:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsol0n",
              "author": "HanzJWermhat",
              "text": "If it‚Äôs anything like GovCloud no. You need citizenship to access the region, all customer data is stored in the region.\n\nOperational logs probably get exported and centralized however",
              "score": 11,
              "created_utc": "2026-01-15 20:45:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuel3w",
                  "author": "wlonkly",
                  "text": "> You need citizenship to access the region\n\nThat's not correct -- you need to be a US person to open an account, but what happens after that is up to you (and your sponsoring agency).  \n\nI'm Canadian and have access to my company's GovCloud accounts.",
                  "score": 6,
                  "created_utc": "2026-01-16 02:03:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuklkc",
                  "author": "Skytram_",
                  "text": "Logs don‚Äôt get (automatically) exported.",
                  "score": 6,
                  "created_utc": "2026-01-16 02:37:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvtklh",
                  "author": "NaCl-more",
                  "text": "Logs stay in partition",
                  "score": 3,
                  "created_utc": "2026-01-16 07:46:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx5ofi",
                  "author": "KarlHungas",
                  "text": "Operation logs, billing, everything is separate from the US AWS.  I sat in an interesting session about this at AWS reinvent",
                  "score": 3,
                  "created_utc": "2026-01-16 13:57:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxdgz9",
                  "author": "ghillisuit95",
                  "text": "> Operational logs probably get exported and centralized however\n\nNo, AWS mostly uses the in-region CloudWatch for logging. Older services may still use something called timber, but its also regional. \n\nusage data and metrics may be visible to non-eu employees, but I don't think that's very concerning",
                  "score": 2,
                  "created_utc": "2026-01-16 14:37:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsqteu",
                  "author": "arwinda",
                  "text": "> If it‚Äôs anything like GovCloud\n\nI do not see a clear confirmation in the article, nor in other articles about this announcement.\n\nAnd I also don't see any clarification that US personnel definitely won't have access. Until this is confirmed one has to assume that the US, including the government, can still access the data.",
                  "score": -12,
                  "created_utc": "2026-01-15 20:55:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrauu",
              "author": "DecisionOk474",
              "text": "They have a separate auth stack. No US citizens can physically or logically access it.",
              "score": 7,
              "created_utc": "2026-01-15 23:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuio6x",
                  "author": "Sea-Us-RTO",
                  "text": "what about psychologically? üòÑ",
                  "score": 3,
                  "created_utc": "2026-01-16 02:26:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwlsio",
              "author": "coldoil",
              "text": "No.",
              "score": 2,
              "created_utc": "2026-01-16 11:55:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0e665n",
              "author": "JackSpyder",
              "text": "Presumably the US branch can request the EU branch to comply. As theyre legally obligated to do so.\n\nThe EU branch can refuse on legal grounds.\n\nPunishing them or firing them is illegal under EU regs so... jump.",
              "score": 1,
              "created_utc": "2026-01-19 00:59:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00601y",
              "author": "conspicuousxcapybara",
              "text": "Yes. More specifically, AWS wrote in their [blog 'Five facts about how the CLOUD Act actually works'](https://aws.amazon.com/blogs/security/five-facts-about-how-the-cloud-act-actually-works/):\n\n>\"Fact 1: The CLOUD Act does not give the U.S. government **unfettered or automatic access** to data stored in the cloud.   \n  \n\\[..\\]    \n  \nTo compel a provider to disclose content data, law enforcement must convince an independent federal judge that probable cause exists related to a particular crime, and that evidence of the crime will be found in the place to be searched\"",
              "score": 1,
              "created_utc": "2026-01-16 22:16:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0hejrd",
                  "author": "MatthiasWM",
                  "text": "So there *is* access without any EU process. Thanks for confirming that.",
                  "score": 1,
                  "created_utc": "2026-01-19 14:45:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099oe8",
              "author": "National_Way_3344",
              "text": "No they don't.\n\nThey've essentially spun off a whole Euro cloud staffed by Europeans only.\n\nIt's pretty fucking wild because it means Amazon could just walk out of the US given their economy is fucked.",
              "score": 0,
              "created_utc": "2026-01-18 07:55:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzseee6",
          "author": "cloudrkt",
          "text": "As long as it is a US owned company it will never be sovereign.",
          "score": 208,
          "created_utc": "2026-01-15 19:57:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsgtrt",
              "author": "landon912",
              "text": "The region is technically owned by a subsidiary HQ‚Äôd in Europe",
              "score": 70,
              "created_utc": "2026-01-15 20:08:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztccml",
                  "author": "FalseRegister",
                  "text": "Subsidiaries are also subject to US law",
                  "score": 53,
                  "created_utc": "2026-01-15 22:36:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03bknf",
                  "author": "Flaksim",
                  "text": "The CLOUD Act (Clarifying Lawful Overseas Use of Data Act). Makes any promises made by a U.S. company or it's subsidiaries regarding data sovereignity meaningless.\n\nAWS argues its new EU entity is legally separate. However, U.S. courts have historically interpreted \"control\" broadly. If Amazon U.S. has the corporate power to force its subsidiary to act (e.g., by threatening to fire the board of directors), a U.S. judge can rule that Amazon U.S. has \"control\" over the data and order them to produce it or face contempt of court.\n\nAdd in Executive order 12333 and FISA section 702 and you have the trifecta of legal bs the US uses to justify collecting data abroad and at home with impunity, regardless of who is the owner.",
                  "score": 1,
                  "created_utc": "2026-01-17 11:58:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzzot5p",
                  "author": "No-Theory6270",
                  "text": "And lead by one guy called Isra√´l",
                  "score": 1,
                  "created_utc": "2026-01-16 20:54:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsoahs",
                  "author": "HanzJWermhat",
                  "text": "But the operational management and software development is all centrally managed in the US",
                  "score": -23,
                  "created_utc": "2026-01-15 20:43:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o027ztf",
                  "author": "plinkoplonka",
                  "text": "Doesn't matter. \n\nEveryone knows who pulls the strings. \n\nSame as tax breaks that are afforded by splitting global companies across regions, it's the same bullshit.",
                  "score": -1,
                  "created_utc": "2026-01-17 05:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrd7m",
              "author": "Rolandersec",
              "text": "Yeah it‚Äôs too late for this. The other nations are building this stuff out already and it‚Äôs going to be the great commoditization and democratization of the cloud. \n\nWill probably work out great for netapp though.",
              "score": 3,
              "created_utc": "2026-01-15 23:55:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvtmh2",
              "author": "Express-One-1096",
              "text": "It can be if it‚Äôs standalone but pays royalty fees for the brand.",
              "score": 1,
              "created_utc": "2026-01-16 07:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzti94y",
          "author": "Burekitas",
          "text": "The interesting stuff:\n\n10ms latency to eu-central-1.\n\npricing on the website is not fully available yet, use the calculator (https://pricing.calculator.aws.eu/) instead.\n\nS3 is seperated from the \"regular\" S3, therefor, you can register bucket names that already exists in S3 and havn't taken yet, I created the following buckets: 1234, mobile etc. (I really want to registrer \"french-goverment\" but I think it's too much).\n\nRoute53 domains are EU tld (nl/eu/fr/de).\n\nIdentity Center is not yet available (appears in IAM but leads to 404). You can configure external SSO like Okta, OneLogin etc.\n\n  \nIn general, it sounds like AWS are still working on many features, but it's a great starting point.",
          "score": 33,
          "created_utc": "2026-01-15 23:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztod6f",
              "author": "pwnedbilly",
              "text": "It will almost certainly be a separate partition as with GovCloud and AWS China so your ARNs will still be globally unique.",
              "score": 7,
              "created_utc": "2026-01-15 23:39:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuvg3d",
              "author": "sh1boleth",
              "text": "It won‚Äôt have full feature parity with regular aws partition ever due to the nature of operations.\n\nSome niche feature or service will be missing",
              "score": 3,
              "created_utc": "2026-01-16 03:38:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs2ccg",
          "author": "Goon_be_gone",
          "text": "The AWS sovereignty policies are good enough for China I‚Äôm sure they‚Äôll be good enough for the EU.",
          "score": 54,
          "created_utc": "2026-01-15 19:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa76l",
              "author": "kestrel808",
              "text": "AWS China is distinctly different than AWS in the rest of the world.  They have their own API, you can't do things like connect vpc's globally and they're run by local partners.  China is way more than \"just another region\".",
              "score": 35,
              "created_utc": "2026-01-15 19:38:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsb8za",
                  "author": "Kaynard",
                  "text": "Same thing for Europe, it's a new AWS partition (Like China, GovCloud, commercial AWS etc) and with one region in it for now.",
                  "score": 82,
                  "created_utc": "2026-01-15 19:43:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsaxo2",
                  "author": "likeavirgil",
                  "text": "How is that different from the sovereign cloud offering in the EU?",
                  "score": 8,
                  "created_utc": "2026-01-15 19:41:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztrh7j",
                  "author": "DecisionOk474",
                  "text": "Just like every other AWS partition. That isn‚Äôt china specific‚Ä¶..",
                  "score": 3,
                  "created_utc": "2026-01-15 23:55:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsjpgd",
              "author": "hkgwwong",
              "text": "China has other very strong alternatives, unlike Europe. As far as I know nobody consider AWS their first choice , might be way more popular among foreign companies need a cloud in China.",
              "score": 1,
              "created_utc": "2026-01-15 20:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0e7wlz",
                  "author": "Busy-Explanation4339",
                  "text": "Yes, Alibaba is very big in China.",
                  "score": 1,
                  "created_utc": "2026-01-19 01:09:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzsofrd",
          "author": "humbuckler404",
          "text": "So that means they will never be impacted by us-east-1 issues? :skeptical-face:",
          "score": 29,
          "created_utc": "2026-01-15 20:44:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztjo4e",
              "author": "xxwetdogxx",
              "text": "Correct. All the source code was copied into the region, the USA could sink to the bottom of the ocean and the ESC region would still run, there's no dependency.",
              "score": 20,
              "created_utc": "2026-01-15 23:13:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztp7tz",
                  "author": "humbuckler404",
                  "text": "That‚Äôs great news. It‚Äôs been a few years since I worked in AWS, so I know ‚Äúno dependencies‚Äù were something we always pursued. Of course, the challenges in implementing that is what made the Wednesday morning Ops Reviews so entertaining üòè",
                  "score": 7,
                  "created_utc": "2026-01-15 23:43:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvadl2",
                  "author": "ares623",
                  "text": "Don‚Äôt some critical services still rely on us-east-1 though?",
                  "score": -2,
                  "created_utc": "2026-01-16 05:14:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsze5u",
              "author": "nemec",
              "text": "correct, that's the difference between a region and a partition\n\nhttps://www.reddit.com/r/aws/comments/1oe99zi/did_mondays_outage_impact_govcloud_users_at_all/",
              "score": 15,
              "created_utc": "2026-01-15 21:34:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzz5ig5",
              "author": "KayeYess",
              "text": "A few popular services like IAM, R53 and Cloudfront have their control planes operating only in US East 1.\n\n\nR53 announced a HA control plane (opt in required) in US West 2 (still US) for Public Hosted Zones.\n\n\nIAM is also preparing a similar solution, most likely in US West 2\n\n\nUnless they create a totally independent and sovereign region (like China) in EU, AWS EU will have some dependency on AWS US.",
              "score": 1,
              "created_utc": "2026-01-16 19:24:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09joon",
                  "author": "Living_off_coffee",
                  "text": "Can confirm that the EU sovereign cloud is a separate partition, so R53, IAM etc is all in the EU with no dependencies on the US.",
                  "score": 1,
                  "created_utc": "2026-01-18 09:28:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0cysqw",
              "author": "shadycuz",
              "text": "I think alot of people replying to you, has never tried to use CloudFront in a region outside of us-east-1.",
              "score": 1,
              "created_utc": "2026-01-18 21:18:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzst91a",
              "author": "ImCaffeinated_Chris",
              "text": "This is the real question.",
              "score": 1,
              "created_utc": "2026-01-15 21:06:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsjfix",
          "author": "Bloodsucker_",
          "text": "EU should make sure to only use regional providers. Plenty of companies and banks have stopped expanding in the cloud owned by the USA. It's not safe or aligned with European sovereignty. They, aws, know this, that's why they're panicking. It's not sufficient to use a regional subsidiary.",
          "score": 12,
          "created_utc": "2026-01-15 20:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztjqhe",
          "author": "KayeYess",
          "text": "Don't trust anyone. Protect what you need to, yourself. Whether it is a US based cloud company or a Europe based data center doesn't matter.",
          "score": 3,
          "created_utc": "2026-01-15 23:14:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztryj3",
              "author": "BigBagaroo",
              "text": "The US intelligence services would be incompetent if they did not have access to all data.\n\nNow that the US is no longer an ally of EU, EU should move their data away from their platforms.",
              "score": -2,
              "created_utc": "2026-01-15 23:58:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu6uyr",
                  "author": "KayeYess",
                  "text": "Maybe put the data in Greenland üòÇ",
                  "score": 3,
                  "created_utc": "2026-01-16 01:20:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztgobg",
          "author": "yourfriendlyreminder",
          "text": "What is the feature parity with regular AWS? \n\nAnd what is the support model?\n\nThe thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either",
          "score": 2,
          "created_utc": "2026-01-15 22:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00vlp7",
              "author": "MateusKingston",
              "text": ">What is the feature parity with regular AWS?\n\nImpossible to tell so early on but Govt Cloud is heavily behind, but it has all the mainstream products afaik, it's just the new shiny toys and obscure products that never get there or take some time.\n\n>The thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either\n\nI don't think this truly matters, you're not getting supported by AWS Engineers anyway, you're getting support from a support team that was trained and know how their specialized services work, etc. They will simply have those people in the new EU subsidiary that should take over those duties.",
              "score": 2,
              "created_utc": "2026-01-17 00:36:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuud9v",
          "author": "maxip89",
          "text": "It only need one u.s. shadow trial gets public, and the whole aws europe story is done.",
          "score": 2,
          "created_utc": "2026-01-16 03:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy1w3s",
          "author": "Dzefo_",
          "text": "I already see myself migrating all the infra again‚Ä¶",
          "score": 2,
          "created_utc": "2026-01-16 16:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz36cc",
          "author": "granviaje",
          "text": "If trump tells Amazon to shut it down how long do you think it will take for this to happen?¬†\n\nAs long as Trump is on the helm there is no way to trust any US company.¬†",
          "score": 2,
          "created_utc": "2026-01-16 19:13:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e87ly",
              "author": "Busy-Explanation4339",
              "text": "The convicted felon con man has poisoned the well.  There will not be any trust in the America well after he is gone.",
              "score": 1,
              "created_utc": "2026-01-19 01:11:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzuok5",
          "author": "BigBagaroo",
          "text": "The AWS/US brigade is in full force on this topic.\n\nI would advice any non-US citizen to read this article and think for themselves:\n\nhttps://en.wikipedia.org/wiki/Crypto_AG\n\n¬´Crypto AG was a Swiss company specialising in communications and information security founded by Boris Hagelin in 1952. \n\nThe company was secretly purchased in 1970 by the US Central Intelligence Agency (CIA) and West German Federal Intelligence Service (BND) for US $5.75 million (equivalent to $47 million in 2024)[1] and jointly owned until about 1993, with the CIA continuing as sole owner until about 2018¬ª\n\n¬´The mission of breaking encrypted communication using a secretly owned company was known as Operation Rubicon. \n\nWith headquarters in Steinhausen, the company was a long-established manufacturer of encryption machines and a wide variety of cipher devices.¬ª",
          "score": 3,
          "created_utc": "2026-01-16 21:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt5tf8",
          "author": "twin-hoodlum3",
          "text": "Funny seeing all the comments from the AWS fanboys, thinking it matters if the AWS Sovereign Cloud is run by European AWS subsidiaries located in the EU.\n\nGuys: it . doesn‚Äòt. matter. As long as the mother company who fully owns the European subsidiary is US based, then the CLOUD Act still applies. Period.",
          "score": 3,
          "created_utc": "2026-01-15 22:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwx7y3",
              "author": "HomoAndAlsoSapiens",
              "text": "That's why they specifically designed these daughter companies to have to deny requests by US courts. There is not a single American working there that would therefore have to comply with US courts and any request that the parent company in the US would put through because they have to would then be denied because it would be illegal to do so in Europe. It's not as easy as you'd like to think it is.\n\nDid you know that the US also wants to tax you on shares of US-companies even if you have nothing to do with the country? Foreign banks, of course, just ignore that and don't report to them. Their intention was to build a similar system here.",
              "score": 4,
              "created_utc": "2026-01-16 13:11:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o033vg4",
                  "author": "xiwenc",
                  "text": "The scope is not just who operates the datacenters or in this subsidiary. The core supplier of the source code etc can be tampered or loaded with backdoors. US AWS is still the leading entity. They are subject to CLOUD ACT and other US policies.\n\nUnless they do a complete hard fork, and employ europeans, audited independently to be 100% safe and zero relation with US, i could trust it to be sovereign.",
                  "score": 1,
                  "created_utc": "2026-01-17 10:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx0cuj",
                  "author": "twin-hoodlum3",
                  "text": "Basically it's easier than you might think. Under US law, authorities can compel a provider subject to US jurisdiction to disclose data that is within the provider‚Äôs ‚Äúpossession, custody, or control,‚Äù even if the data is stored in Europe. Whether this reaches data ‚Äúhandled by an EU subsidiary‚Äù often turns on whether the US parent (or another US-jurisdiction entity) has sufficient legal/technical control over that data, and it can create a direct conflict with GDPR rules on responding to foreign orders.\n\nThe key message here is \"possession and control\". What do you think will happen to AWS US if some susidiary manager says \"no\" to their bosses? The only way to circumvent such things at least in parts is to use infrastructure like SAP Delos or Bleu. But event this is questionable. \n\nSource: \n\n* 18 U.S. Code ¬ß 2713 (https://www.law.cornell.edu/uscode/text/18/2713)\n* CLOUD act Q&A (https://www.justice.gov/criminal/media/999616/dl?inline)",
                  "score": -1,
                  "created_utc": "2026-01-16 13:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzubez4",
              "author": "alienangel2",
              "text": "I mean, if the US govt wants to get at data hosted in some other cloud provider, even one 100% built from scratch in Europe, they are still going to get it whether they do it legally or not. \n\nCLOUD act will make it vaguely defensible in US courts but no one in the US admin cares about courts anymore, and no one in any intelligence agency has ever cared about courts. It's probably easier for them to steal from some homegrown local cloud provider than from AWS.",
              "score": 3,
              "created_utc": "2026-01-16 01:45:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvq24k",
                  "author": "Interesting_Shine_38",
                  "text": "This is precisely what I believe people fail to understand. Like those guys blew up air gapped uranium enrichment facility. You think your vulnerable outdated OpenStack deployment will be a problem for them?",
                  "score": 2,
                  "created_utc": "2026-01-16 07:16:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00wm34",
                  "author": "MateusKingston",
                  "text": "This is far different from \"they will just demand the data and it will be handed over\".\n\nCyberwarfare and Cybercrime are very different from courts demanding access and being handed over.\n\nBut I wouldn't be so sure about this, the US has only shown their Cyberwarfare capabilities against subpar opponents.",
                  "score": 1,
                  "created_utc": "2026-01-17 00:41:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztbdgd",
              "author": "sutongorin",
              "text": "Even if it didn't apply it's doubtful customers would care. It still has AWS in its name. Anything US-related is tainted.",
              "score": -2,
              "created_utc": "2026-01-15 22:31:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09nzug",
          "author": "Automatic_Gas_113",
          "text": "So this is some kind of EU-washing.",
          "score": 1,
          "created_utc": "2026-01-18 10:08:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gr394",
          "author": "mountcifs",
          "text": "You can‚Äôt apparently trust US. This solves nothing.",
          "score": 1,
          "created_utc": "2026-01-19 12:25:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h2ei2",
          "author": "National-Percentage4",
          "text": "Its bezos. And american. Get off AWS asap.¬†",
          "score": 1,
          "created_utc": "2026-01-19 13:39:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzthe5r",
          "author": "thirstybatman",
          "text": "I truly wonder which public bodies will use this. Two years ago, yes. But not anymore, that train has left the station. Sovereign in the name only.",
          "score": 1,
          "created_utc": "2026-01-15 23:01:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01nn01",
          "author": "Unable-Goat7551",
          "text": "Lots of wildly naive people in this thread",
          "score": 1,
          "created_utc": "2026-01-17 03:32:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt9tuy",
          "author": "egorf",
          "text": "I can see two problems with this.\n\n1) It's hard to imagine AWS \"EU\" not complying with requests from the US administration. Even if we exclude clandestine requests based on the fact that the US doesn't respect sovereignty, imagine they ban, say, the export of cloud orchestration technologies just like they restricted GPU exports, including to the EU.\n\n2) It's easy to imagine AWS \"EU\" trying to comply with all local EU laws and regulations which either brings the cloud to a halt or makes the usage of it impractical. Say, no AI models deployed until seven-years mandatory Environmental Impact Study has been performed. Or something along these lines.",
          "score": -1,
          "created_utc": "2026-01-15 22:23:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwyhjj",
              "author": "HomoAndAlsoSapiens",
              "text": "You have no understanding of this, no offense.\n\n1. Complying with these requests is illegal. There also are no US citizens that could be compelled to comply. In fact, the entire new company structure is based on this principle.\n\n2. They have to comply with laws because laws are not optional. AWS with their normal regions equally has to comply with laws because laws are not optional. In Europe, AWS exclusively operates via its Luxembourgish daughter Amazon Web Services EMEA SARL.",
              "score": 4,
              "created_utc": "2026-01-16 13:18:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzz44n9",
                  "author": "granviaje",
                  "text": ">¬†They have to comply with laws\n\nSince when does the trump admin care about laws?",
                  "score": 2,
                  "created_utc": "2026-01-16 19:18:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz6z4m",
                  "author": "Hopeful-Programmer25",
                  "text": "I may be going overboard but you are assuming laws still matter to the US government‚Ä¶. They don‚Äôt. They can, and will, pressure the parent US company to fulfil what they need and, it‚Äôs clear, that the US parent will fold. The US parent still owns the EU subsidiary, still decides who runs it, who will then find a way to comply or be fired.\n\nThis is going beyond data sovereignty, it‚Äôs that the US is a hostile actor to European interests, and could easily shut down European infrastructure in the worse case scenario.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:31:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyftfn",
                  "author": "egorf",
                  "text": "1. Of course. No EU personnel will be involved in data exfiltration process at all as the AWS software contains all required backdoors for the US staff to download whatever the US needs. Notice: I did not write \"could contain a backdoor\". I deliberately wrote that it DOES contain a backdoor. The opposite is simply inconceivable.\n\n2. Great! I love that AWS complies with the laws as it should be! Meanwhile as a EU citizen I will continue using the US AWS exclusively because I want the most recent AI models available with no committee to decide which text transformation engine I am allowed to use. And I don't want to slap my recent utility bill with every API request to AWS.\n\nSo Godspeed to AWS EU but I have negative trust at all levels.",
                  "score": 0,
                  "created_utc": "2026-01-16 17:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu9ntw",
              "author": "ByronScottJones",
              "text": "Literally none of the people working in the EU partition are allowed to be US citizens. They are all REQUIRED to be EU citizens. There's nobody in the US that will have legal leverage to require such requests to be complied with.",
              "score": 6,
              "created_utc": "2026-01-16 01:36:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyeghf",
                  "author": "egorf",
                  "text": "Exfiltration of data on US request is not going to be done via engagement with EU staff. It will be done in the US by using the corresponding backdoor in the AWS code with no EU involvement and knowledge whatsoever.",
                  "score": -2,
                  "created_utc": "2026-01-16 17:24:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwr2fg",
          "author": "elchupacabrone",
          "text": "They are still American company. This doesn't change anything and it's definitely not \"sovereign\" because when NSA wants to get access to their resources they have to obey.",
          "score": 0,
          "created_utc": "2026-01-16 12:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwyvcw",
              "author": "HomoAndAlsoSapiens",
              "text": "You are so sure? Then explain how a request for the data would be handled and I can explain why you're wrong and have actually not sufficiently thought about it.",
              "score": 1,
              "created_utc": "2026-01-16 13:21:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxrqg6",
                  "author": "elchupacabrone",
                  "text": "Yes I'm sure - CLOUD act 2018.",
                  "score": -1,
                  "created_utc": "2026-01-16 15:44:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt2fhy",
          "author": "BigBagaroo",
          "text": "There is absolutely no reason to believe AWS on this.",
          "score": -6,
          "created_utc": "2026-01-15 21:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztc9a9",
              "author": "bastion_xx",
              "text": "Why not? You, and customers that will use this, can read the docs. From the FAQ:\n> The AWS European Sovereign Cloud will maintain key certifications such as ISO/IEC 27001:2013, SOC 1/2/3 reports, and BSI C5 attestation, all validated regularly by independent auditors to assure our controls are designed appropriately, operate effectively and help customers satisfy their compliance obligations.",
              "score": 4,
              "created_utc": "2026-01-15 22:35:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztti59",
                  "author": "twin-hoodlum3",
                  "text": "Have you ever been to an ISO 27k1 audit and know the controls? These regulations are (surprisingly) just for the sake of compliance (aka: we‚Äòre at least not amateurs), not at all proof of anything in terms of security or sovereignity.",
                  "score": 1,
                  "created_utc": "2026-01-16 00:06:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztq0jl",
                  "author": "BigBagaroo",
                  "text": "Oh my, it says so in the FAQ? Well, that changes everything!",
                  "score": -4,
                  "created_utc": "2026-01-15 23:48:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6i9n",
          "author": "codechris",
          "text": "Complete shite. If you're European use an EU cloud,¬† it this fake wank from Amazon¬†",
          "score": -6,
          "created_utc": "2026-01-15 22:07:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyi6tw",
              "author": "jrolette",
              "text": "What EU cloud would you suggest they use that isn't much more than a VPS and storage provider? There are no options that are even vaguely comparable to AWS, Azure, and GCP.",
              "score": 1,
              "created_utc": "2026-01-16 17:41:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyrmts",
                  "author": "codechris",
                  "text": "Depends what you need. A lot of stuff is just a container and a DB (I'm being simplistic but it makes the point) plenty of companies running on EU clouds¬†",
                  "score": 1,
                  "created_utc": "2026-01-16 18:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs1sjp",
          "author": "BenchOk2878",
          "text": "If Trump can get Greenland,¬† that \"pinky promise\" does not mean shit.\n\n\nBezos will give away any data requested by USA government.¬†\n\n\nGet real.",
          "score": -8,
          "created_utc": "2026-01-15 18:59:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzudnk0",
              "author": "madwolfa",
              "text": "That's not how storage in cloud works, especially if you use your own encryption keys (as you should if you care about this sort of thing).¬†",
              "score": 4,
              "created_utc": "2026-01-16 01:58:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o02kfv4",
          "author": "morefakefakeshit",
          "text": "All of this work just because men in dark glasses can show up at any US data center and take whatever they want",
          "score": 0,
          "created_utc": "2026-01-17 07:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsr2zu",
          "author": "Maang_go",
          "text": "All Trump has to do is ask AWS to revoke encryption keys used by all AWS services in the background, of anything European hosted in AWS. \n\nThen all hardware will still be in Europe, all software will be operating from here, All data will be stored in Europe but unusable. Cloud is designed for control not capex opex.",
          "score": -7,
          "created_utc": "2026-01-15 20:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsyyjo",
              "author": "nemec",
              "text": "Why do you think Americans have control over the EU Cloud encryption keys?",
              "score": 17,
              "created_utc": "2026-01-15 21:32:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztsz0w",
                  "author": "baronas15",
                  "text": "Cloud act",
                  "score": 0,
                  "created_utc": "2026-01-16 00:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztssb2",
                  "author": "twin-hoodlum3",
                  "text": "As long as the customers don‚Äòt use their own KMS encrypting data *before* they get into AWS, AWS and ‚Äûothers‚Äú (by request) have the encryption keys.",
                  "score": 0,
                  "created_utc": "2026-01-16 00:03:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt6rgi",
                  "author": "Maang_go",
                  "text": "‚ÄúNoted.‚Äù",
                  "score": -1,
                  "created_utc": "2026-01-15 22:09:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qe956h",
      "title": "CodeBreach: Infiltrating the AWS Console Supply Chain and Hijacking AWS GitHub Repositories via CodeBuild",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "author": "Kralizek82",
      "created_utc": "2026-01-16 07:02:16",
      "score": 58,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzx03uh",
          "author": "pint",
          "text": "tl;dr\n\nthe core of this attack is a misconfigured github setup, which accepted pull requests from user ids that *contain* a string, instead of *matching* the string. with some difficulty, they managed to register a new id that passed.\n\nthere are many more steps in this attack, but this was the main vulnerability.",
          "score": 47,
          "created_utc": "2026-01-16 13:28:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxe5d1",
              "author": "menge101",
              "text": "ty",
              "score": 6,
              "created_utc": "2026-01-16 14:41:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qbvyk7",
      "title": "Another Big Update",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbvyk7/another_big_update/",
      "author": "DrSkyle",
      "created_utc": "2026-01-13 16:30:32",
      "score": 43,
      "num_comments": 4,
      "upvote_ratio": 0.81,
      "text": "Hey ,\n\nA month ago, I posted **CloudSlash**, a tool to identify \"zombie\" infrastructure (unused NAT Gateways, detached EBS, Ghost EKS clusters) and i have been updating here on r/aws ever since. This time the entire core engine was rewritten to prioritize Safety. Here is what is new in V2\n\n**1. The Lazarus Protocol (Undo Button)**\n\nIf you choose to delete a resource (like a Security Group), CloudSlash now snapshots the configuration *\\_before\\_* generating the delete command.\n\nIt creates a \"restore.tf\" file containing the exact **Terraform Import blocks** needed to resurrect that resource in its original state. This removes the \"what if I break prod\" anxiety.\n\n**2. Mock Mode**\n\nA lot of you didn't want to give a random GitHub tool read access to your account just to test it. Fair point.\n\nYou can now run \"cloudslash scan --mock\".\n\nIt simulates a messy AWS environment locally so you can see exactly how the detection logic works and what the TUI looks like without touching your real keys or credentials.\n\n**3. Complete TUI Overhaul**\n\n\\- **Topology View:** Visualize dependencies (e.g., Load Balancer -> Listener -> Target Group).\n\n\\- **Interactive Region Picker:** No more hardcoded regions. It fetches enabled regions dynamically.\n\n\\- **Deep Inspection:** Press \"Enter\" on any resource to see the exact cost velocity and provenance (who created it).\n\n**4. Open Sourced Heuristics**\n\nI removed the \"black box\" nature of the detection. The README now contains a full **Heuristics Catalog** detailing the exact math used to flag a resource (e.g., \"RDS is Idle if CPU < 5% for 7 days AND ConnectionCount == 0\"). You can audit the logic before running it.\n\n**5. Graph Engine**\n\n3x faster graph traversal for large accounts ( > 500 resources ) . I refactored the engine to use flat slices instead of maps and implemented string interning for resource types, reducing RAM usage by \\~40% on large graphs.\n\n**Other Improvements since v1.3:**\n\n\\- **Headless Mode:** \"cloudslash scan --headless\" is now fully stable for CI/CD usage.\n\n\\- **Graph Engine:** 3x faster graph traversal for large accounts (>500 resources).\n\n\\- **Completion Scripts:** Native bash/zsh/fish auto-completion.\n\n\\- Validation: Strict tag-based overrides (\"cloudslash:ignore\") are now respected deeper in the graph.\n\n**andd manyyy moreee**\n\n**License:** Still AGPLv3 (Open Source). No paywalls.\n\n\n\n**Repo:** [https://github.com/DrSkyle/CloudSlash](https://github.com/DrSkyle/CloudSlash)\n\nbtw parsing AWS graphs is complex, so if you hit any weird edge cases or bugs , please let me know , i plan to fix them immediately\n\nStars are always appreciated :)\n\n:)  DrSkyle",
      "is_original_content": false,
      "link_flair_text": "monitoring",
      "permalink": "https://reddit.com/r/aws/comments/1qbvyk7/another_big_update/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzom976",
          "author": "sfboots",
          "text": "I need to do a scan just for unused ebs volumes and Ami unused and older than 3 months. Nothing very complicated but quite tedious \n\nIs this tool easy enough to use on such a small configuration?",
          "score": 1,
          "created_utc": "2026-01-15 06:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpgy71",
              "author": "AlpacaPi3",
              "text": "Sorry to interrupt to the author‚Äôs post but for the specific case it sounds like an overkill to me.\nI can suggest steampipe, an open source tool which you can SQL query your cloud infrastructure.",
              "score": 5,
              "created_utc": "2026-01-15 10:47:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyrd03",
              "author": "AWS_Chaos",
              "text": "I hate what I'm about to type, but its the world we live in right now. Your question sounded perfect for a powershell and AWS CLI solution. So out of curiosity I simply asked ChatGBT:\n\n\"write me a powershell script that uses the AWS CLI to run through 3 aws accounts and find all the unattached EBS volumes\"\n\nIt pretty much nailed it. It even handled the regions properly and I didn't ask that. I then asked :\n\n\"now write another powershell script but this time if looks for AMI that are older than 3 months\"\n\nand yup, it got it. I leave this exercise up to you.",
              "score": 1,
              "created_utc": "2026-01-16 18:21:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qdvngk",
      "title": "DynamoDB Search functionality?",
      "subreddit": "aws",
      "url": "https://i.redd.it/qwv3xma4ukdg1.png",
      "author": "Antique_Sample_7934",
      "created_utc": "2026-01-15 21:00:20",
      "score": 21,
      "num_comments": 4,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qdvngk/dynamodb_search_functionality/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzt6kqm",
          "author": "geomagnetics",
          "text": "I think it's for PartiSQL searching. it's only enabled if you have the right indexes enabled.",
          "score": 7,
          "created_utc": "2026-01-15 22:08:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztbtcr",
              "author": "Antique_Sample_7934",
              "text": "Do you mean GSI's? I have tons of them. I haven't used PartiSQL though",
              "score": 1,
              "created_utc": "2026-01-15 22:33:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwdx62",
                  "author": "geomagnetics",
                  "text": "I'm not sure what it takes to enable it. but try the PartiSQL editor from the sidebar. that might give you a clue as to what's going on",
                  "score": 1,
                  "created_utc": "2026-01-16 10:52:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6if4",
          "author": "Vprprudhvi",
          "text": "That's true. I just noticed it now",
          "score": 2,
          "created_utc": "2026-01-15 22:07:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdr4tv",
      "title": "TIFU by causing an incident",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "author": "belcheri",
      "created_utc": "2026-01-15 18:14:11",
      "score": 16,
      "num_comments": 14,
      "upvote_ratio": 0.79,
      "text": "I really messed up today and caused an incident. I was supposed to enroll an external production account into our prod OU through Control Tower,  which has compliance stacksets and some SCPs that get enforced. I thought I had done my homework - went through all the account resources to make sure nothing would get auto-remediated. But somehow I still managed to screw it up because of a silly reason, there were a few resources sitting in regions we don't govern, and they started throwing forbidden errors everywhere after the enrollment. I fixed it by reverting and unenrolling the account, but the whole thing made me disappointed that how I missed this.\n\nThe thing that really gets me is there's no safety net. When I was a software engineer, I always had QA testing my code before anything touched production. Now every infrastructure change feels like I'm walking a tightrope with no net underneath.\n\nI made the switch from software engineering to cloud operations about two years ago, and honestly, incidents like this make me question whether I made the right call. How do you all handle this? Thank you. ",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzrt5jx",
          "author": "RFC2516",
          "text": "You found a sharpe edge to your organizations Engineering Safety process. Not your fault. Does your organization have a staving environment that truely mirrors prod that the same change could have been rehearsed in?",
          "score": 14,
          "created_utc": "2026-01-15 18:21:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrta00",
          "author": "cddotdotslash",
          "text": "Yes, you could have a better testing environment or a QA OU to use, but the reality is that it‚Äôs very difficult to completely mirror the setup of one account via another. Even if you‚Äôre religious about defining everything as code, there are still traffic patterns or use cases that might only appear in production.\n\nI think AWS deserves some blame. They have no dry run or audit modes for these kinds of things (including SCPs, account moves, etc.) It‚Äôs been a community request for ages and they‚Äôve pretty much ignored it.",
          "score": 16,
          "created_utc": "2026-01-15 18:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvysdr",
              "author": "TurboPigCartRacer",
              "text": "Indeed running in a QA OU is really difficult to reproduce since the way its being used it completely different compared to accounts running under production OU. It would be great if there's a simulator of some sorts that can use your cloudtrail logs from the past 90 days or so and validate if the new scp applies the right restrictions or not similar to the iam policy simulator.",
              "score": 1,
              "created_utc": "2026-01-16 08:33:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrtdum",
          "author": "Vast_Manufacturer_78",
          "text": "Welcome to infrastructure, you get not credit when it goes right and you get hell when it goes wrong. Just take it as a learning opportunity, early on I once put multiple KMS keys into deletion status and created new ones because I was moving to fast and didn‚Äôt fully read a terraform plan.\n\nI realized rather quickly what happened and made the changes to undo the delete and then import them to the code again, but there were issues with some of the deployments because the alias were removed and had to get recreated.\n\nYou just learn and make notes on things like triple checking your tf plans. For your issue it doesn‚Äôt sound like it was broken for too long, but now you will double check all regions where resources are deployed and confirm it‚Äôs in an approved region for the organization.",
          "score": 6,
          "created_utc": "2026-01-15 18:22:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0itx",
          "author": "stikko",
          "text": "In this case analyzing say 90 days of CloudTrail data and testing against all the SCP statements would have caught it. \n\nNever underestimate peoples‚Äô capacity for doing shit you think they shouldn‚Äôt be doing. \n\nWhat I‚Äôve noticed is that a lot of this comes with experience and having made these sorts of mistakes and learned appropriate lessons from them. Being able to mostly completely/accurately answer:\n\n- what could go wrong?\n- what‚Äôs the impact of that thing going wrong?\n- what‚Äôs the likelihood of it going wrong?\n- how can I mitigate that likelihood?\n\nSo what‚Äôs the appropriate lesson to take away here?",
          "score": 4,
          "created_utc": "2026-01-16 00:44:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrzzq3",
          "author": "uuneter1",
          "text": "I‚Äôm not familiar with what you were doing, but step one is documentation. ‚ÄúSteps to follow for enrolling new account into OU‚Äù. Add whatever caveats you need.",
          "score": 1,
          "created_utc": "2026-01-15 18:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx2r6c",
          "author": "DaWizz_NL",
          "text": "I actually think that Control Tower is the biggest issue here. You can hardly test operations beforehand and it orchestrates a lot of things like a black box.",
          "score": 1,
          "created_utc": "2026-01-16 13:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy6up1",
          "author": "TechDebtSommelier",
          "text": "Honestly, this is a very normal cloud ops rite of passage, even if it feels awful in the moment. Control Tower enrollments plus SCPs plus regional drift is one of those setups where everyone learns the hard way that ‚ÄúI checked everything‚Äù never really means everything.",
          "score": 1,
          "created_utc": "2026-01-16 16:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gpll3",
          "author": "gokulsiva",
          "text": "I sometimes wonder whether the inferior infra in QA is because of cost ? We tend to do a lot of shortcuts in QA is that one of the reasons?",
          "score": 1,
          "created_utc": "2026-01-19 12:13:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrz64b",
          "author": "mikes3ds",
          "text": "To combat issues like that I use terraform. You can see what changes would happen, before applying. Also easier to roll back changes and know what changes cant be rolled back. \n\nOne of the newer advantages of using a Infrastructure as Code (IAC), is when you have a codebase you can use codex or github copilot to search your IAC for potential problems, ask questions. \n\nHaving no Dev/QA sucks however, I always create a smaller env to test my IAC stack.",
          "score": 1,
          "created_utc": "2026-01-15 18:48:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrzjq1",
              "author": "mikes3ds",
              "text": "Also it becomes more like software development when you start using IAC for anything added to your cloud envs.",
              "score": 2,
              "created_utc": "2026-01-15 18:50:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxca8t",
              "author": "AWS_Chaos",
              "text": "This is a serious question: How would Terraform have helped in this particular situation of moving an account into another OU with unforeseen SCP issues?",
              "score": 1,
              "created_utc": "2026-01-16 14:31:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyefsz",
                  "author": "mikes3ds",
                  "text": "Terraform plans can surface drift such as unexpected SCP attachments or policy changes, but the larger benefit is that your organizational structure and guardrails are expressed as code. This makes it far easier to systematically analyze changes for risk‚Äîwhether through automated checks, policy validation, or even using an LLM to review the Terraform code and plan output to flag potentially impactful SCP conditions you may not have anticipated.\n\nThis approach won‚Äôt eliminate every risk, but it provides far more visibility and proactive safeguards than ad-hoc or manual changes.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:24:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qbljlm",
      "title": "Drift-aware change sets were a great idea, but why does it want to update anything using !ImportValue?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbljlm/driftaware_change_sets_were_a_great_idea_but_why/",
      "author": "jemenake",
      "created_utc": "2026-01-13 07:57:11",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "I was experimenting with AWS' new-ish drift-aware change-sets for CloudFormation to see how they work. I started with an existing stack that had a handful of resources, and *one* I had purposely drifted and *another* one, \"PermissionsBoundary\", I made a change to in the template.\n\nWithout drift-awareness (i.e. the \"old\" way we're all used to), it wanted to modify the one PermissionsBoundary resource that I had modified in the template. *With* drift-awareness, it wanted to modify the changed resource in the template *and* the resource that I had drifted (yay!) but it *also* wanted to modify several other resources. What's even more strange is that drift-aware change sets show you which resources have drifted, and it indicated that these had *not* (see the images). When I examined the changes it was going to make, I saw a bunch of \"changeset:KNOWN\\_AFTER\\_APPLY\" values where the template was using !ImportValue.\n\nWhat baffles me is I thought that values exported from other stacks *cannot be changed* if they're being imported by other stacks. So, if this stack already is importing a value and the new template *continues* to import it, the value cannot change.\n\nI was really hoping that drift-awareness was going to give us something more like 'terraform plan', but, with it flagging anything using !importValue like this, it makes it almost not worth using.\n\nDoes anybody know of a way to disable that behavior? Or maybe shed some light on why they made it work like this?\n\nhttps://preview.redd.it/4llmrwnno2dg1.png?width=1375&format=png&auto=webp&s=94c8f1e8dd7c71da5ec7f3b7b23c7ba3cc8c1a69\n\nhttps://preview.redd.it/g1bsp28oo2dg1.png?width=1455&format=png&auto=webp&s=b3e0f3f47f0352f2f3db7de99325ed32e0619184\n\n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qbljlm/driftaware_change_sets_were_a_great_idea_but_why/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzbn3u1",
          "author": "dr_barnowl",
          "text": "`terraform plan` fetches any inputs that depend on `data` blocks - `!ImportValue` is the equivalent of a `terraform_remote_state` data source ; so perhaps this is an apples / oranges comparison, because CF isn't fetching the exported values until you actually apply the changeset, versus Terraform which does all this at the `plan` stage (and allows you to export the entire plan and apply it later without further reference to data sources).\n\n> I thought that values exported from other stacks cannot be changed if they're being imported by other stacks\n\nIs this the case, or is it only that you can't change their names or remove them from the stack? (I confess, I don't have any handy CF stacksets to play with).",
          "score": 1,
          "created_utc": "2026-01-13 09:01:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc2nuo",
          "author": "risae",
          "text": "I also noticed that this feature cannot work with false-positive drifts. For example, if a false-positive drift thinks a resource is deleted, it will try to recreate the resource even if it still exists. I personally don't recommend using it until AWS decides to fix drift detection.",
          "score": 1,
          "created_utc": "2026-01-13 11:25:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcav0s",
          "author": "dataflow_mapper",
          "text": "This bit me too. From what I can tell, drift aware change sets treat !ImportValue as opaque at plan time, so they cannot prove the value is unchanged even if the export is effectively immutable while in use. That‚Äôs why you see KNOWN\\_AFTER\\_APPLY and a proposed update even though nothing will really change. It feels less like a real diff and more like CloudFormation being conservative because it cannot resolve the dependency graph across stacks. I do not think there is a way to disable that behavior today. The only workaround I have seen is minimizing ImportValue usage for things that should never trigger updates, or just mentally filtering those changes out and trusting no-op updates, which is not very satisfying.",
          "score": 1,
          "created_utc": "2026-01-13 12:29:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd8kby",
      "title": "Need Help",
      "subreddit": "aws",
      "url": "https://www.reddit.com/gallery/1qd8kby",
      "author": "BodybuilderCandid672",
      "created_utc": "2026-01-15 03:27:21",
      "score": 12,
      "num_comments": 24,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "billing",
      "permalink": "https://reddit.com/r/aws/comments/1qd8kby/need_help/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nznzrmv",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'billing'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+billing).\n\nLooking for more information regarding billing, securing your account or anything related? [Check it out here!](https://www.reddit.com/r/aws/comments/vn4ebe/check_it_first_operating_within_amazon_web/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-15 03:27:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo26w5",
          "author": "Formal_Alps_2187",
          "text": "You‚Äôre comparing savings plan (a year‚Äôs worth of commitment paid up front) to hourly cost for a month. These are two different things.",
          "score": 14,
          "created_utc": "2026-01-15 03:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo34xe",
              "author": "Soloeye",
              "text": "Looking at it, the monthly prices are correct.  This isn‚Äôt a savings plan problem.  The savings plan was just calculated for 24/7 x 365 @11.5k annually breaking down to $965/month.  \n\nThe thing is the $111 is only calculated at 30ish hours, so ~1 hour per day x 30 days.",
              "score": 5,
              "created_utc": "2026-01-15 03:48:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo424b",
                  "author": "BodybuilderCandid672",
                  "text": "thanks, but i wont run the shared instance for 24/7 will i get bill for 24/7 or only for number of hours i use?",
                  "score": 1,
                  "created_utc": "2026-01-15 03:54:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo3dgc",
              "author": "BodybuilderCandid672",
              "text": "thanks one doubt if i use less hours in shared instance will it cost less? only cost number of hours i use per month?",
              "score": 1,
              "created_utc": "2026-01-15 03:49:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzo3sv7",
                  "author": "Harsha_7697",
                  "text": "Yes.",
                  "score": 1,
                  "created_utc": "2026-01-15 03:52:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzolvce",
                  "author": "Formal_Alps_2187",
                  "text": "The other person's reply is actually incorrect. Your effective costs are lower but again with savings plans you are paying for commitment. You are saying you will spend this amount. If you pay for savings plans for a year's worth and you use only a day's or a month's worth, you are still liable to pay the remaining amount. Just because it's lower in the total cost, assuming you're running it 24/7 but you use it only for one hour, you are still liable to pay for the remaining 23 hours of commitment. Yes it won't be lower",
                  "score": 1,
                  "created_utc": "2026-01-15 06:01:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo3orj",
              "author": "BodybuilderCandid672",
              "text": "but is mention per mouth right? total cost per month 965.9 USD",
              "score": 1,
              "created_utc": "2026-01-15 03:51:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzo9ga1",
          "author": "SnooObjections7601",
          "text": "You can also get better pricing comparison here.\n\nhttps://instances.vantage.sh/aws/ec2/g6.2xlarge?currency=USD&duration=monthly&region=us-east-1\n\nJust remember that the spot pricing here is just the average and not 100% accurate.",
          "score": 2,
          "created_utc": "2026-01-15 04:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo1pvq",
          "author": "DecisionOk474",
          "text": "You expect us to confirm all this math by hand on two screenshots we need to zoom in on? Come on‚Ä¶.\n\nYou aren‚Äôt charged for stopped instances.\n\nYou shouldn‚Äôt compare a price plan to on demand pricing.",
          "score": -1,
          "created_utc": "2026-01-15 03:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoudk2",
          "author": "RecordingForward2690",
          "text": "\"Doing research\" is not the same as \"Asking ChatGPT and then asking Reddit to correct ChatGPT\". If you want to do proper research, start here, read through the various purchase options and take it from there: [https://aws.amazon.com/ec2/pricing/](https://aws.amazon.com/ec2/pricing/)\n\nAlso don't forget to include your EBS cost.",
          "score": -2,
          "created_utc": "2026-01-15 07:13:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdacvr",
      "title": "For a small to medium business, is there an AWS equivalent of M365 for Business or Google Workspace",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdacvr/for_a_small_to_medium_business_is_there_an_aws/",
      "author": "mzthickneck",
      "created_utc": "2026-01-15 04:54:37",
      "score": 12,
      "num_comments": 24,
      "upvote_ratio": 1.0,
      "text": "From what I understand, there isn't, and AWS would provide mostly IaaS services and have the business host their Windows devices and productivity suites.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qdacvr/for_a_small_to_medium_business_is_there_an_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzoeuuz",
          "author": "Burekitas",
          "text": "AWS has [WorkMail](https://aws.amazon.com/workmail/), but it's very rare to see someone using it. \n\nAmazon itself has its own fleet of Exchange servers, which is likely the largest Exchange setup in the world.",
          "score": 20,
          "created_utc": "2026-01-15 05:08:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzotu2n",
              "author": "justin-8",
              "text": "They've been migrating to 365 for a few years",
              "score": 6,
              "created_utc": "2026-01-15 07:08:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp0ei5",
                  "author": "rudigern",
                  "text": "Year singular",
                  "score": 3,
                  "created_utc": "2026-01-15 08:08:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzohrb2",
              "author": "PelosiCapitalMgmnt",
              "text": "The DoD is probably larger",
              "score": 1,
              "created_utc": "2026-01-15 05:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzolu0h",
          "author": "return_of_valensky",
          "text": "Have a look at Zoho mail.\n\nI am admin on many workspace accounts and many of them are looking for alternatives since google keeps jacking the prices up.  Zoho actually is more feature rich than I was aware.  It's a decent service with many of the higher tier offerings like custom domain, file storage, native apps etc for low price.\n\nA basic custom domain email is like $15/year with extra storage compared to $22/month for google.\n\nI have started provisioning some for clients with success.",
          "score": 11,
          "created_utc": "2026-01-15 06:01:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp3ful",
              "author": "CloudandCodewithTori",
              "text": "Came here to say this ^",
              "score": 2,
              "created_utc": "2026-01-15 08:37:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoduk5",
          "author": "x86brandon",
          "text": "WorkDocs/WorkMail... but they got rid of it.  :(",
          "score": 21,
          "created_utc": "2026-01-15 05:01:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoocs8",
              "author": "kei_ichi",
              "text": "And I‚Äôm really happy with that decision. Those service are very hard to use, have tons of issue, and especially the pricing is somewhat I can‚Äôt understand based on the features those services can provide‚Ä¶\n\nI‚Äôm AWS fan boy for IaaS but I prefer Google Workspace for any business (offices) workload.",
              "score": 17,
              "created_utc": "2026-01-15 06:21:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00ijji",
                  "author": "mezbot",
                  "text": "Im proud of AWS for accepting defeat on those, and Chime as they were inferior products.  End user products have always been inferior, I‚Äôm happy they have shifted back to their core competencies.",
                  "score": 4,
                  "created_utc": "2026-01-16 23:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzq5mrt",
              "author": "deskamess",
              "text": "WorkMail is getting deprecated? They just released a new UI for WorkMail.",
              "score": 4,
              "created_utc": "2026-01-15 13:42:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzokz8q",
          "author": "mjreyes",
          "text": "WordDocs and WorkMail are basically ‚Äúme too‚Äù products that are not usable in the real world",
          "score": 7,
          "created_utc": "2026-01-15 05:54:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzpz127",
          "author": "Prestigious_Pace2782",
          "text": "I kinda feel like that‚Äôs like asking ‚Äúwhat‚Äôs the best mobile to use for my phone that‚Äôs not android or iOS‚Äù \n\nSure there are alternatives. But why not use the thing people already know in a business situation? \n\nIf it‚Äôs around values, or dislike of particular companies. Totally understand though.",
          "score": 4,
          "created_utc": "2026-01-15 13:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00ho7j",
              "author": "mezbot",
              "text": "Same with Slack/Teams/Gchat as a runner up.  There are alternatives but if you need to collaborate on stuff with clients, customers, etc. it‚Äôs those or Gsuite/o365/Confluence for the most part.  The ability to collaborate with tools outside of an org is a huge factor these days above and beyond internal docs/spreadsheets/presentations.",
              "score": 2,
              "created_utc": "2026-01-16 23:16:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoi3pq",
          "author": "PelosiCapitalMgmnt",
          "text": "Just use M365 or GSuite, people are familiar with Microsoft or Google tools and expecting non-technical users to use something else just isn‚Äôt worth the hassle. There isn‚Äôt much benefit to using an esoteric tool or office suite that has small adoption if it means your helpdesk will be filled with people who need to be re-taught where everything is to become productive",
          "score": 8,
          "created_utc": "2026-01-15 05:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoe78h",
          "author": "jimmyfivetimes",
          "text": "Not the full suite - WorkDocs and WorkMail were their entry level offerings.  I don‚Äôt recall what‚Äôs still available - one or both services may have been sunset during to lack of adoption.\n\nAnd then there‚Äôs Chime.",
          "score": 2,
          "created_utc": "2026-01-15 05:03:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzosmc5",
              "author": "criminalsunrise",
              "text": "Chimes getting shutdown. Even our AWS account management team are moving away from it for our meetings.",
              "score": 2,
              "created_utc": "2026-01-15 06:58:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrj1y0",
                  "author": "mrbiggbrain",
                  "text": "Just to be clear the specific \"Chime\" offering is being shut down, but not the underlying service (Chime SDK) that powers it. So if your using the Chime SDK for your own solutions those should not be effected.",
                  "score": 3,
                  "created_utc": "2026-01-15 17:36:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpfbjt",
          "author": "devandreacarratta",
          "text": "I used WorkMail for some days. I wasn‚Äôt able to attach the mail to my gmail account to download the email.",
          "score": 1,
          "created_utc": "2026-01-15 10:32:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzq5edu",
              "author": "deskamess",
              "text": "Right... its almost intentional. On my pixel, I can pull it via the Exchange option. On gmail-browser, I cannot since it does not seem to have the right options.  \n  \nIs the new UI better than the old one? I am waiting to see some reviews on it but it is a sparsely used product.",
              "score": 1,
              "created_utc": "2026-01-15 13:41:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqtp6z",
          "author": "mountainlifa",
          "text": "No because Word has been under development since 1980 so why bother reinventing the toothbrush¬†",
          "score": 1,
          "created_utc": "2026-01-15 15:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrcmfh",
          "author": "ryanrem",
          "text": "As people have already stated, I personally wouldn't recommend Workdocs/WorkMail since AWS is moving away from those services.\n\nMicrosoft is such a tyrant in that service it isn't really worth trying to reinvent the wheel. But if you mostly use AWS services outside of that, I'd suggest going with M365 since Amazon themselves picked Microsoft over Google and it's working rather well for them.",
          "score": 1,
          "created_utc": "2026-01-15 17:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvklbh",
          "author": "DrollAntic",
          "text": "Protonmail has a work offering, if you like privacy. Doc and drive tools are not great yet, but under active development.\n\nThere is no reason to combine servers and email / user infrastructure, the most important thing is security and protonmail does that well.\n\nI use it for personal on a paid account, have for years, and it's getting really good. Check it out, see if it meets your needs. \n\nIf you need something to manage workstations and a central domain, that changes things a bit. I'd use Linux personally, with some MDM tools, but not all have that option open.",
          "score": 1,
          "created_utc": "2026-01-16 06:30:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzod2uu",
          "author": "qwer1627",
          "text": "Q for Business, caveat emptor",
          "score": -5,
          "created_utc": "2026-01-15 04:55:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbiay1",
      "title": "Landing Zone Accelerator vs CfCT vs AFT",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/",
      "author": "Iconically_Lost",
      "created_utc": "2026-01-13 04:52:44",
      "score": 11,
      "num_comments": 23,
      "upvote_ratio": 1.0,
      "text": "Looking at LZA and for the life of me struggling to figure out A) What it does, and B) What are the actual benefits compared to doing AF Customisation or using AF with Terraform?\n\nGoing through the Design and the use for it, it seems to just deploy a standard reference Account settings/networks from AWS's own CDK that you cannot change/modify (yes i know you could prob point InstallerStack.template at your own git).\n\nThe layout and settings all seem to be chosen by AWS, where you have no say it what/config actually is deployed to the Workload accounts.\n\nI know that you are supposed to be able to do some customisation via the cofig files, but per the diagram it seems indicate that these are stored in AWS's git. Not yours.\n\n    Landing Zone Accelerator on AWS aims to abstract away most aspects of managing its underlying infrastructure as code (IaC) templates from the user. This is facilitated through the use of its¬†configuration files¬†to define your landing zone environment. However, it is important to keep some common IaC best practices in mind when modifying your configuration to avoid pipeline failure scenarios.\n\nFor those that spun this up, how customizable is this solution/ how easy is it to live with? I know Control Tower is generally a pain, but leadership is dead set on it, so trying to choose the lesser evil.\n\n  \nThe architecture diagram  \n[https://imgur.com/1PLQctv](https://imgur.com/1PLQctv)",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzbws9c",
          "author": "bailantilles",
          "text": "I generally don‚Äôt understand the (current) hate for Control Tower.",
          "score": 9,
          "created_utc": "2026-01-13 10:34:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzelsm7",
              "author": "Yoliocaust93",
              "text": "It does nothing special, and it is an opinionated wrapper that doesn't like you messing around with what it does even the slightest (or you get the \"reset landing zone\" error message on your Friday afternoon)",
              "score": 3,
              "created_utc": "2026-01-13 19:29:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbz5wz",
              "author": "Iconically_Lost",
              "text": "ok, then please explain what it does LZA do, and what are the actual benefits compared to doing AF Customisation or using AF with Terraform?",
              "score": 1,
              "created_utc": "2026-01-13 10:55:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcsr36",
          "author": "mallu0987",
          "text": "We use AFT and very happy with it.",
          "score": 3,
          "created_utc": "2026-01-13 14:15:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbgc4s",
          "author": "Yoliocaust93",
          "text": "If you absolutely need to use CT, use AFT.  Using CloudFormation for anything that is not a StackSet is willingly shooting yourself in the foot. I'd also consider Control Tower itself in the same bullshit tier: you can easily replicate the few things it does (except the useless \"Enrolled\" green-friendly UI) with just a few stacksets. If you have some margin, I'd suggest to enable CT, copy the stacksets it creates (or find them online if available), remove CT, redeploy the stacksets for almost the same result without that horrible service",
          "score": 5,
          "created_utc": "2026-01-13 07:56:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze5zv6",
              "author": "TurboPigCartRacer",
              "text": "yeah AFT is the way to go from the 3 options that are listed by OP, but only if he's willing to go with terraform. However all 3 options are dependent on CT and it all feels like you're trying to manage a block box via IaC where you only have the ability to change some configurations instead of architecting your multi-account setup the way you want it.   \n  \noutside of CT there are some other options, one of them is for example orgformation, however i'm more a cdk person myself so i build my own solution that's build on top of organizations and stacksets. Stackset are really underestimated, but are really powerfull and give you a lot of control and flexibility. I wrote more about Control tower alternatives in [this post](https://towardsthecloud.com/blog/aws-control-tower-alternatives).",
              "score": 0,
              "created_utc": "2026-01-13 18:19:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb3uoj",
          "author": "Ok-Lavishness5190",
          "text": "Please don't go for LZA if you are going to manage a lot of network or IAM resources. It will easily hit 500 resources per CloudFormation stack. Then you will have to look for another option.",
          "score": 4,
          "created_utc": "2026-01-13 06:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb4q19",
              "author": "Iconically_Lost",
              "text": "What do you mean and that resource count is just the LZA stack itself or the actual object I need?\n\nHow does the actual deployment work? ie I need a new account, with specific roles (Azure as SSO source), custom VPC sizing/layout (or from standard ingress patterns ie TGW and or GWLB) but routes are per VPC. \n\nHow does it handle the managing/monitoring of the actual objects that devs deploy via TF/other means?",
              "score": 1,
              "created_utc": "2026-01-13 06:14:33",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzd8p20",
              "author": "Kaynard",
              "text": "They could still use LZA but manage Networking resources outside of it, many customers do, especially when the Networking team isn't the one managing LZA",
              "score": 1,
              "created_utc": "2026-01-13 15:35:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzf3pjv",
                  "author": "Iconically_Lost",
                  "text": "So are you able to explain how one would go about not managing the network portion via LZA?",
                  "score": 1,
                  "created_utc": "2026-01-13 20:52:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfmdkb",
              "author": "Healthy_Gap_5986",
              "text": "This constraint has been rectified (or improved) in the latest major version. Network resources are now split into several smaller stacks.",
              "score": 1,
              "created_utc": "2026-01-13 22:19:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfoizs",
          "author": "Healthy_Gap_5986",
          "text": "The LZA sample config is what you're looking at and is chosen by AWS. You are free to write you're own config and deploy the individual resources any way that LZA allows. It does a lot of stuff just straight of the box (e.g. centralised logging, AWS Backup) and honestly, the standard patterns it deploys are pretty much best practise and how you would deploy things like that yourself anyway.\n\nThere's a few things it's missing. Customization support is poor (it can deploy CFN stacks and thats about it), Some Route53 features are lagging behind and some other things but overall the manpower/value ratio is great. Upgrades can sometimes be a bit finicky but the Issues tracker is active and I've only pinged AWS Support for it once in the early days.\n\nConfig can live in S3 or Github or anything CodeConnections supports. You basically never need to touch Control Tower. \n\nI'm surprised at the negative opinion here. I'm a one man band driving our platform and I send maybe 1 day a month on LZA and the rest getting sh1t done.",
          "score": 2,
          "created_utc": "2026-01-13 22:30:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfsrir",
              "author": "Iconically_Lost",
              "text": "I think the hate maybe because the doco does a terrible job at explaining what it does or more aptly, how.\n\nSo i've figured out the initial push kinda setups the LZA management stack, but the question i cant seem to find is how do we actually deploy workload accounts, and with custom settings (VPCs/subnets/role/etc).\n\nI keep seeing reference to the confg yaml files in the s3. Are these what I customise per account/per job or is it more of a running log of all the config life terraform (all vpc in all accounts, and i just add to the list).\n\nHow do i even trigger the creation of a new account creation? How do i version control what LZA deploys/setings/atrributes because I can see the LZA looks at AWS's git for the actual setup (my diag pic circled).",
              "score": 1,
              "created_utc": "2026-01-13 22:51:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0de7lo",
                  "author": "Healthy_Gap_5986",
                  "text": "The installer stack sets up two Codepipelines \"Installer\" and \"Pipeline\". All config is done with the yamls. The docco for that is here.\nhttps://awslabs.github.io/landing-zone-accelerator-on-aws/latest/user-guide/config/\n\nWhile the config is split over a few yamls, unfortunately the docco is just one big page, you get used to it though.\n\nWhen you run the \"Pipeline\" Codepipeline it reads the yamls and does its thing. The standard config is a good starting point and we haven't deviated from much.\nhttps://awslabs.github.io/landing-zone-accelerator-on-aws/latest/sample-configurations/standard/\n\nThe config validator is very useful. Lets you save time to catch errors before commiting changes.\nhttps://awslabs.github.io/landing-zone-accelerator-on-aws/latest/developer-guide/scripts/#configuration-validator\n\n\nWe also run a separate billing account and Org for testing LZA upgrades and various configs. It's stripped back to keep costs down.",
                  "score": 1,
                  "created_utc": "2026-01-18 22:35:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzauwjj",
          "author": "zenmaster24",
          "text": "!Remind me 1 week",
          "score": 1,
          "created_utc": "2026-01-13 05:00:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzauzhd",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-01-20 05:00:57 UTC**](http://www.wolframalpha.com/input/?i=2026-01-20%2005:00:57%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/nzauwjj/?context=3)\n\n[**3 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Faws%2Fcomments%2F1qbiay1%2Flanding_zone_accelerator_vs_cfct_vs_aft%2Fnzauwjj%2F%5D%0A%0ARemindMe%21%202026-01-20%2005%3A00%3A57%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qbiay1)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-13 05:01:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcjvbg",
          "author": "kapowza681",
          "text": "I would say the benefit is that it‚Äôs opinionated. It does help having everything contained within six config files when handing off to a client, particularly one who is not overly familiar with AWS. It also does a nice job of setting up aggregated logging to a centralized account.",
          "score": 1,
          "created_utc": "2026-01-13 13:26:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcqbhk",
          "author": "Appropriate_Text_529",
          "text": "If I had the time I would rip out LZA completely and use a combination of AFT, CT, & Cfn.\n\nLZA is a huge PiTA to manage, understand, and puts you in heavy reliance of AWS support. I have mine trimmed down to an account vending machine + default logging & tf iam bootstrapping and it‚Äôs still terrible to deal with. It ran fine in Nov but now there was an update and it blows up trying to provision new accounts.\n\nRun",
          "score": 0,
          "created_utc": "2026-01-13 14:02:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qco4xm",
      "title": "What is a cluster trying to abstract exactly?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qco4xm/what_is_a_cluster_trying_to_abstract_exactly/",
      "author": "Whatever4M",
      "created_utc": "2026-01-14 14:06:11",
      "score": 10,
      "num_comments": 30,
      "upvote_ratio": 0.73,
      "text": "I feel like there's a ton of redundant abstraction in clusters/ecs and there doesn't seem to be a lot of guidance on this.\n\nWhere I work, we used to have a single cluster, we define multiple services, each service has it's own capacity provider which is backed by it's own ASG. Since you can define as many services as you want and you can share the same capacity providers, you can have any combination of services/capacity providers you want, so what's the point of a cluster exactly? When I ask myself if we should split our services into different clusters, I can't really think of a really strong reason for it, a single cluster already allows me the freedom to do what I want.\n\nAny thoughts on this?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qco4xm/what_is_a_cluster_trying_to_abstract_exactly/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzjmi5y",
          "author": "jbeckha2",
          "text": "Minimizing blast radius and segregating data. Having a dev cluster vs a prod cluster let's you practice and test a change, especially a change to the underlying infrastructure without risk of breaking production.\n\n\nIf you don't have critical uptime needs or customer data to protect, having multiple clusters is probably overkill.¬†",
          "score": 14,
          "created_utc": "2026-01-14 14:35:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjp4p6",
              "author": "Whatever4M",
              "text": "Hmm, the blast radius stuff makes sense but not sure about data segregation, as long as the vpc is shared, the data can be shared as well, right?",
              "score": 0,
              "created_utc": "2026-01-14 14:49:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjvio1",
                  "author": "Sensi1093",
                  "text": "That‚Äôs why you should have a separate VPC as well.\nIdeally even a separate AWS Account",
                  "score": 14,
                  "created_utc": "2026-01-14 15:20:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzm7yn6",
                  "author": "jbeckha2",
                  "text": "Even with a shared vpc, it can potentially be easier to reason about your network access rules minimizing the chance of making a mistake that exposes customers data. If you do SOC 2 or similar or have customers that require data in certain regions, having separate clusters can make demonstrating that you're compliant much simpler.\n\nBack to your original question about what a cluster abstracts. I think for me it's a way to create a group of things that I can reason about as a group instead of as individuals hopefully simplifying overall configuration and the chance of making mistakes.\n\nI don't know how the services are being split out into different clusters in your environment, so it may not be giving you much benefit. In ours, where we have all of our production services in one cluster and the dev version in another, it makes securing things so much simpler. There's no change I can make in dev that will accidentally expose production customer data.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:42:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjnxn0",
          "author": "menge101",
          "text": "A cluster is abstracting a collection of compute resources as one big clump.\n\nIf you use ECS on EC2, yeah there are separate boxes, but you don't have to think about them, they just provide capacity to the cluster.\n\nHow you use that clump is up to you.",
          "score": 8,
          "created_utc": "2026-01-14 14:43:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjp8d1",
              "author": "Whatever4M",
              "text": "Isn't a capacity provider backed asg doing that same abstraction?",
              "score": 0,
              "created_utc": "2026-01-14 14:49:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjrk8e",
                  "author": "menge101",
                  "text": "I don't want to claim an authoritative stance here, I'd have to go back to docs to confirm it, and I'm not going to right now. (I have time to comment, not time to research; while working)\n\nBut I believe it is the cluster that has the capacity provider, not the ASG.  The ASG works for the capacity provider in the cluster.\n\nCapacity Providers are properly named as ECS Capacity Providers.",
                  "score": 6,
                  "created_utc": "2026-01-14 15:01:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkkvwc",
                  "author": "asdrunkasdrunkcanbe",
                  "text": "Yes...but you don't have specify the capacity provider when starting tasks in the cluster. You can just say, \"Use whatever is the cluster default\".\n\nSo then you don't need to worry about making sure your tasks are running in the right place. It's a prod cluster, configured to provide capacity within your prod VPC, so when you run your tasks, you know they're in prod and not somewhere else.\n\nIf you were to provide one big cluster with capacity providers per-environment, then there's always the risk that you might start a task intended for staging, using the prod capacity provider.\n\nThe logical separation provided by the cluster prevents that from happening.",
                  "score": 2,
                  "created_utc": "2026-01-14 17:16:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkcder",
          "author": "SpecialistMode3131",
          "text": "As your infrastructure grows, having everything in one big clump becomes unmanageable. So, there are lots of ways to subdivide, including in infrastructure patterns.  Naming each individual business function sanely is pretty smart, won't cost you extra, and futureproofs tons of things you will want to do later, like measuring usage more finely, scaling up or down specific business functions without affecting others, etc.",
          "score": 4,
          "created_utc": "2026-01-14 16:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjwn1p",
          "author": "jeff_barr_fanclub",
          "text": "According to [this old presentation](https://d1.awsstatic.com/events/reinvent/2019/CON423-R1_REPEAT%201%20AWS%20Fargate%20under%20the%20hood_No%20Notes.pdf) ECS has a cellular service to manage clusters and tasks, supposedly for both availability and scalability (which makes sense since most many ECS limits are set per cluster). If that's true you'll want to use a new cluster whenever you can rather than sharing one cluster for all your services so that you limit your blast radius during an outage and give yourself higher effective limits. But at the end of the day it seems more like cluster is a failure to abstract away internal backend architecture on their part, rather than an abstraction for our sake.",
          "score": 3,
          "created_utc": "2026-01-14 15:26:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk0pu9",
              "author": "Whatever4M",
              "text": "I see. Thanks for this.\n\nEdit: The presentation says that cluster managers are designed cellularly but it doesn't really say that each cluster is it's cell, so not sure about this.",
              "score": 1,
              "created_utc": "2026-01-14 15:45:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkls28",
                  "author": "jrolette",
                  "text": "I can assure you that each cluster is NOT a cell. The service's cells will contain multiple/many clusters.",
                  "score": 3,
                  "created_utc": "2026-01-14 17:20:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkuk5n",
                  "author": "jeff_barr_fanclub",
                  "text": "Yeah cluster manager cells are almost certainly multitenant, but if all your services are on one cluster and the cluster manager cell that your cluster is on goes down you're SOL, but if you use multiple clusters they'll probably be on multiple cells your blast radius will be smaller.",
                  "score": 1,
                  "created_utc": "2026-01-14 18:00:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzk8nh6",
          "author": "HostisHumaniGeneris",
          "text": "Here's an alternate perspective. Assume you're using Infrastructure as Code to configure your AWS accounts. You discover that for some reason you need to change your cluster settings. If you're using a single cluster for everything, that means you have to deploy your changes to production without testing them first. If you have a separate dev cluster, you can deploy your updated settings to dev first, verify the changes, and then deploy to prod.\n\nNow, it's probably unlikely that you'll need to change cluster settings very often, but it's a good standard practice to keep completely isolated resources for each environment as it avoids guesswork when making updates.\n\nAs a sorta of related anecdote, I was in an environment where we had separate dev and prod resources, but we ran our \"staging\" workloads in the dev environment for acceptance tests. Nonprod is nonprod, right? Turns out, no. A load test against staging knocked our networking offline because we overloaded a NAT server, which then halted all of our dev work because the dev resources were offline. After that, we made sure we had three entirely separate environments, but we would spin down staging when it wasn't in use.",
          "score": 3,
          "created_utc": "2026-01-14 16:21:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk9vzu",
              "author": "Whatever4M",
              "text": "We have a completely separate AWS account for staging, it makes a lot of sense to separate your envs by cluster if you don't. I am mostly asking about splitting services per cluster on a single environment.",
              "score": 1,
              "created_utc": "2026-01-14 16:26:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkoulv",
                  "author": "HostisHumaniGeneris",
                  "text": "Ah, if you're already split by environment then the separation matters less. If you're talking about workloads in a single environment, then an ECS cluster is simply an organizational unit. It gives you an abstraction that then target with other resources like IAM policies and capacity providers. In and of itself it doesn't provide any specific isolation.\n\nSo yes, you could run everything in a single cluster and do your isolation via your IAM and capacity provider config. However, clusters are free, so why not keep that logical separation between projects? In my mind it makes it easier to write your configs.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:34:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkcjhk",
          "author": "justin-8",
          "text": "They matter a lot more for ECS on EC2 - different clusters mean you're on separate physical machines for your containers. So noisy neighbours from a dev workload won't affect your prod containers. I'm not sure if fargate is using separate instances or binpacking within a cluster or account - but you're right that the abstraction doesn't do much when you're talking about fargate",
          "score": 2,
          "created_utc": "2026-01-14 16:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkfh5x",
              "author": "Whatever4M",
              "text": "Since each of our services uses a separate capacity provider/asg, they would be in different instances anyway, no?",
              "score": 1,
              "created_utc": "2026-01-14 16:51:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkusjo",
                  "author": "nekokattt",
                  "text": "generally you don't want separate capacity providers though. The whole point of both EKS and ECS is that you have a pool of compute and a group of things you want to use that compute, and you avoid having to roll an instance per component by allowing the cluster to work out how best to allocate those resources.",
                  "score": 1,
                  "created_utc": "2026-01-14 18:01:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkmlsm",
          "author": "aviboy2006",
          "text": "Lets take step back and ask what a ECS cluster is actually abstracting ?\n\nThe cluster abstracts administrative scope. Specifically, it serves as a boundary for three things like :\n\n1. Security and Permissions (IAM)\n\nA cluster is the easiest place to draw a hard line. It is much simpler to say like junior devs can only see or edit things in cluster B than it is to write complex IAM policies that filter specific services or capacity providers inside a single cluster.\n\n2. Namespace and Service Discovery\n\nServices inside a cluster can easily find each other via Service Connect or Cloud Map. If you put your prod and stage environments in the same cluster, they share the same namespace and separating them into clusters prevents stage app from accidentally talking to a prod database due to a naming collision.\n\n3. Monitoring and Cost Allocation\n\nWhile you can tag individual services, it is much easier to look at a CloudWatch dashboard or a billing report broken down by cluster name. It gives you a clear view of a specific environment without the noise of 50 other unrelated services.\n\nNow lets see when should you actually split into different clusters?\n\nSince you mentioned a single cluster allows you the freedom to do what you want, you are technically correct. You don't have to split them. However, you should consider a split if you hit these scenarios:\n\n\\- If someone accidentally deletes the cluster or misconfigures a cluster-wide setting, does the entire company go dark, or just one department?\n\n\\- If most teams have at least two clusters like prod and non prod. This ensures that testing a new capacity provider setting in staging can't accidentally starve your Production services of resources.\n\n\\- If your healthcare related service needs to be GDPR or HIPPA compliant, it's much easier to put it in its own cluster with its own dedicated ASG and restricted access than to try to prove to an auditor that it‚Äôs virtually separated from your other services like data ingestion or some other operational in the same cluster.\n\nI have three cluster running for prod, qa and dev. currently only one API service is running once its scale or add more services then will think to categories them better as per compliance or security need etc.\n\nSimple terms like analogy then think of ECS cluster as shopping mall. ECS services are individual store like Apple store, Nike or Starbucks store. Cluster become mall management office. You could have one big mall that holds every store in the city, or you could have five smaller malls. Both setups get the job done, but the management experience changes, handle compliances and each area demand.",
          "score": 2,
          "created_utc": "2026-01-14 17:24:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qduom5",
      "title": "Open source tool to generate human-readable Terraform from AWS IAM Identity Center",
      "subreddit": "aws",
      "url": "https://cuenot.io/projects/aws-identity-management/",
      "author": "cuenot_io",
      "created_utc": "2026-01-15 20:23:32",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qduom5/open_source_tool_to_generate_humanreadable/",
      "domain": "cuenot.io",
      "is_self": false,
      "comments": [
        {
          "id": "nzub3gl",
          "author": "Straight_Studio960",
          "text": "Do you have also some sample of naming convention, to go with these repositories, for accounts and OUs and what would the account structure look like for a newly created organization ?¬†\nLike starting from the management account where would you delegate the administrator account to for specific service integrations( Identity center, Cloudtrail logging, Guard duty, Config, security hub).\nSome practices that you learnt along the way of managing them.",
          "score": 1,
          "created_utc": "2026-01-16 01:44:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvnb2c",
          "author": "Ok-Eye-9664",
          "text": "Opus 4.5 + AWS CLI => Human Readable Terraform",
          "score": 1,
          "created_utc": "2026-01-16 06:52:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwskmy",
              "author": "Jazzlike_Object_9464",
              "text": "I‚Äôm interested. Can you describe the idea, please?",
              "score": 1,
              "created_utc": "2026-01-16 12:42:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyhjw0",
              "author": "cuenot_io",
              "text": "This format is easier for AI to read too. Greatly condensed codebase, allows for more context to fit in the window",
              "score": 1,
              "created_utc": "2026-01-16 17:38:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qg8ebs",
      "title": "Principals, tags, SCPs, and ABAC",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "author": "bobaduk",
      "created_utc": "2026-01-18 13:20:11",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 0.88,
      "text": "Hello friends.\n\nI have a reasonably complex AWS account structure with a bunch of workloads and sandboxes in an AWS Organization. I'm thinking about applying ABAC to simplify IAM setup in certain cases. For example, imagine that we have an account sandbox-bobaduk, where I have broad access for playing around. We also have an account secret-data where we store some dataset in an S3 bucket.\n\nWe use Google Workspace as our IDP, and I can apply tags to my role session based on attributes. For example, I authenticate as arn:aws:sts::$sandbox-bobaduk:assumed-role/AWSReservedSSO_MyRole_08759cec7ee3fdc9/bobaduk@org.org. Because I used sso to authenticate, I have the tag `team=data-guy` on my role session.\n\nI can write a resource policy for my s3 bucket that allows GetObject if the OrgId=myorg, and the team tag has the value \"data-guy\".\n\nSo far so good.\n\nMy question, which I'm struggling a little to answer is \"can I trust the provenance of that tag?\".\n\nMy thinking is that I can use an SCP that denies tagging a session with the \"team\" tag, unless the user is adopting a role matching \"AWSReservedSSO_*\". \n\nI should also have an SCP that prevents a user from creating a new role or user with that tag.\n\nthe AWSReservedSSO_* roles can only be created by identity centre, and the trust policy restricts their use to identity centre, so with those SCPs in place, am I missing anything? \n\nI don't need transitive tagging for role chaining, because these tags are _only_ used for this kind of cross-account access based on a resource policy. if I assume another role, I should only have the permissions granted explicitly to that role.",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0aklds",
          "author": "Iliketrucks2",
          "text": "Had a long chat about just this the other day, same set of problems.  We are moving trust from fairly easy to control IAM policy to tag management.  And we want our CD system and users to set both our required tags, but any tags they want, so we need to find a way to namespace tags so we can control how those tags get modified which looks doable but a lot of work.  \n\nAWS does not make this easy, as always.",
          "score": 2,
          "created_utc": "2026-01-18 14:18:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amoy5",
              "author": "bobaduk",
              "text": "Namespacing I have *down*, I have two sets of tags, `myorg:sso:attrib` that gets used for humans, and `myorg:cap:attrib` that gets applied to roles used in automation etc.\n\nsoo attributes are used to say \"this person is in this team, this department whatever, so they can do these things\", capability tags are used to say \"this role can do this particular set of operations\". Given the namespacing, it's easy to say things like  \n\n* \"you may never tag a session as myorg:cap:...\" \n* or \"you may never tag a role myorg:sso:...\"  \n* and \"you may only tag a session as myorg:sso:... if you're assuming an SSO role\",\n\nbut I feel ... unsafe :D",
              "score": 1,
              "created_utc": "2026-01-18 14:29:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0b0vhq",
                  "author": "Iliketrucks2",
                  "text": "Clever. We were going to do similar with corp::{secuirty|cost|access|governance|misc}::{tags} and limit with scps which role(s) can manage which tags, but we still have the omnipotent deployer role that we want to protect against while allowing to create the tags we need in each namespace.  Our concern is around a malicious user rather than an ignorant one - someone who wanted to get access to data could plan a deploy to change tags on things and circumvent our controls.  We have a human review on PR but are concerned about asking devops teams to know enough about tagging to enforce policy - we want technical controls\n\nI think for our most sensitive data we may end up using tagging but adding auditing or a hard scp with specific resources and tag values so only our security team can set/change those tags, then loosen the control and guardrails as data becomes less sensitive so we minimize impact to developers",
                  "score": 1,
                  "created_utc": "2026-01-18 15:42:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qc1tcb",
      "title": "AWS Marketplace traction question ‚Äî what actually moves the needle?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qc1tcb/aws_marketplace_traction_question_what_actually/",
      "author": "Cyber-Pal-4444",
      "created_utc": "2026-01-13 20:08:02",
      "score": 6,
      "num_comments": 6,
      "upvote_ratio": 0.75,
      "text": "We‚Äôve been listed on AWS Marketplace for a while now but traction has been limited.\n\nFor those who‚Äôve had success (or decided to deprioritize it):\n\n* Did AWS Marketplace generate net-new leads, or mostly help close deals already in flight?\n* What specific actions improved results (private offers, sales alignment, AWS co-sell, marketing spend)?\n* How long did it take before you saw meaningful impact?\n\nLooking to learn from real-world experience to decide how much focus this channel deserves.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qc1tcb/aws_marketplace_traction_question_what_actually/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nziw90q",
          "author": "dataflow_mapper",
          "text": "From what I have seen, Marketplace rarely creates true net new demand on its own. It tends to work best as a deal acceleration or procurement unblocker once a buyer already wants what you offer. A lot of teams overestimate the discovery aspect and underestimate how much sales motion still matters.\n\nThe setups that seemed to help were tight alignment with the field team and using private offers as a way to simplify security and billing conversations. When it worked, it was because Marketplace reduced friction, not because someone randomly found the listing and bought.\n\nIf traction is low, I would treat it as a support channel rather than a growth engine. Useful to have, but probably not worth heavy focus unless you already have deals where buyers specifically want to transact that way.",
          "score": 3,
          "created_utc": "2026-01-14 11:56:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyni5i",
              "author": "AWS_Chaos",
              "text": "Anything I've purchased thru marketplace was because I was already dealing with the vendor and they said \"btw, you can get this off Marketplace...\" or \"We can give you a private offer thru Marketplace.\" I do not go looking on marketplace for much. Maybe for Virtual Firewalls?",
              "score": 1,
              "created_utc": "2026-01-16 18:04:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzmo1ge",
          "author": "coyotefarmer",
          "text": "Just being on the marketplace won‚Äôt generate leads.  You have to do all the marketing. It can be helpful to customers who are heavy in AWS but has never been a true selling point for me. It can smooth procurement since it takes payment out of the process. This has been consistent for me with GC and Azure marketplaces as well. Also, the co-sell stuff is next to worthless, for me anyway.",
          "score": 1,
          "created_utc": "2026-01-14 22:58:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzigt53",
          "author": "slidedrooler",
          "text": "First they deny every attempt to list products under your own brand name, forcing you to list them as generic, after nonsensical and stupid catch22 madness where reps play dumb and refuse to acknowledge their own actions. Then they take six full weeks to put your products up for sale after you mail them to fulfillment by amazon. Then they charge you storage fees the entire time. Then you cut your losses, order your products destroyed, and bin this worthless service, cursing amazon for their trechery.",
          "score": -3,
          "created_utc": "2026-01-14 09:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzevvg7",
          "author": "x86brandon",
          "text": "It's complex, especially when you get into multi-cloud.   Best thing we did was engage a multi-cloud marketplace vendor like Tackle.  Their teams moved the needle more than anything with guidance and time to market.\n\nAlmost everything of substance came from co-selling and Tackle teed up the co-sell.  95% of our offers were bespoke private offers and 30% of that was from AWS reps introducing us into verticals and co-selling the deal.   Our co-sell team was introduced by Tackle.",
          "score": -8,
          "created_utc": "2026-01-13 20:15:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qeaqy0",
      "title": "Development environment monitoring?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qeaqy0/development_environment_monitoring/",
      "author": "alangibson",
      "created_utc": "2026-01-16 08:39:00",
      "score": 5,
      "num_comments": 12,
      "upvote_ratio": 0.7,
      "text": "We keep having problems where development, testing, and acceptance environments are left running long after they're needed. We also loose track of what, and what version, is deployed to each environment. Some times its not even clear what team owns what.\n\nDoes anyone know of a tool that can keep track such a mess?\n\nAt a minimum I'd like a dashboard that shows me:\n\n* Basic environment stats like: age, average utilization (ie is anyone using this?)\n* Deployed commits, application versions, etc\n* Team that owns it\n\nI'd really prefer a standalone solution since managers, marketing and sales people are also interested in this information. They're easily alarmed by the complexity of the AWS interface.\n\n\"Deployed commits, application versions,\" is there mainly for marketing and management so they can look for themselves where the features they requested have progressed to. \n\nEdit: clarity.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qeaqy0/development_environment_monitoring/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzw0hrm",
          "author": "bqw74",
          "text": "This question suggests you have more fundamental problems. Why have a dashboard to keep track of a mess? Better to not have the mess at all!\n\nA question:\n- do you use IaC (terraform, cloudformation, etc) - if not, start doing that.\n\n\nThe way we do it:\n- every dev has their own AWS account and _they_ are responsible for what runs in it (and need to account for costs)\n- _everything_ is deployed via CI/CD (infra, app code, the lot)\n- We *force* every dev account to be fully wiped every month by scheduled job. Dev's know this and, if their IaC is good, it takes 10 mins to rebuild their account from code. If something's wrong after this, they know there's a problem with the IaC, and they fix it.\n\n\"Cattle, not pets\" -- Google it.\n\nAs to \"who owns it\" or \"what teams\" -- tags can help with this -- set up a tagging regime/schema and enforce it (there are many ways to do this) including using native AWS tools or a \"compliance-as-code\" type tool.",
          "score": 7,
          "created_utc": "2026-01-16 08:49:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw4hfr",
              "author": "wunderspud7575",
              "text": ">- every dev has their own AWS account and _they_ are responsible for what runs in it (and need to account for costs)\n\nWow, you are living the dream. I've pushed for this in multiple jobs, but never managed to get buy in from architects and cyber folks. Their brain seems to have an allergic reaction to the idea of so many accounts.",
              "score": 1,
              "created_utc": "2026-01-16 09:26:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwn62x",
                  "author": "Davidhessler",
                  "text": "Usually the push back here is because of one of three reasons. They are all indicate either a lack of technical skill OR cultural problems.\n1. Having an account for every dev will cost more ‚Äî this is blatantly untrue. A lot of studies have shown that in general it costs the same or less.  This is because with shared dev accounts there always ends up with orphaned resources that no seems to be able to say who it belongs to. I cannot tell you how many times I‚Äôve seen an RDS resource left on all the time because ‚Äúsomeone might use it‚Äù or ‚Äúthe team can‚Äôt remember who provisioned it.‚Äù\n2. We don‚Äôt have enough people to safely vend these accounts ‚Äî this is a skill problem. You can create AWS accounts via CloudFormation or Terraform today. There‚Äôs tons of AWS services and 3P products that provide automated governance at scale AND meet whatever compliance requirements you need. Any lag in the vending process means you have a manual driven culture somewhere that you need to fix.  There‚Äôs a lot of studies I‚Äôve seen over the years that shows a correlation between the time it takes to vend and the success someone has in the clouds. If it takes you two weeks to vend an account, you are probably overpaying for the cloud and not taking full advantage of it.\n3. Our developers will be able to spin up whatever they like ‚Äî this indicate either you don‚Äôt have proper governance in place of your cloud environment or you don‚Äôt have the proper tools for safe development. Again this is a solved problem by AWS, the OSS community and 3P. You just need to use the tools available.",
                  "score": 1,
                  "created_utc": "2026-01-16 12:05:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzw7a7h",
              "author": "alangibson",
              "text": "I agree this is a process and culture problem. But for all the usual reasons that's not getting fixed anytime soon. So I'm trying to do what any right thinking person would: paper over the problem with yet another app.",
              "score": 1,
              "created_utc": "2026-01-16 09:53:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw5sj4",
          "author": "safeinitdotcom",
          "text": "You could use some AWS specific services:\n\n*  AWS Resource Groups or Service Catalog AppRegistry to group resources. Enforce tags on creation for owner, environment to eliminate ambiguity around ownership.\n* CloudWatch Dashboard filtered by those tags. This gives you a single view of resource utilization (to spot who is actually using what).\n\nSome links that might help:\n\n* [https://docs.aws.amazon.com/servicecatalog/latest/arguide/overview-appreg.html](https://docs.aws.amazon.com/servicecatalog/latest/arguide/overview-appreg.html)\n* [https://docs.aws.amazon.com/ARG/latest/userguide/resource-groups.html](https://docs.aws.amazon.com/ARG/latest/userguide/resource-groups.html)",
          "score": 2,
          "created_utc": "2026-01-16 09:39:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw7qaw",
              "author": "alangibson",
              "text": "Thanks for the info. Tags are really too low-level of a solution for this though. We've got managers, marketing and sales people that want this information at a glance.",
              "score": 1,
              "created_utc": "2026-01-16 09:57:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwe114",
          "author": "dataflow_mapper",
          "text": "This is less a tooling gap and more a hygiene problem that tooling can surface if the basics are there. The biggest unlock is strict ownership and lifecycle metadata, like every environment having an owner, purpose, and expiry baked in at creation time. If environments are created from code and stamped with version info automatically, you can infer what is deployed without anyone manually updating a spreadsheet. Utilization and age are easy once everything is consistently labeled, and you can build a simple read only dashboard on top of that data for non technical folks. The hard part is enforcing cleanup when the expiry hits and making teams feel the cost of leaving things around. I would start by fixing creation standards first, then look for something to visualize it rather than hoping a tool will magically untangle it.",
          "score": 1,
          "created_utc": "2026-01-16 10:53:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03rvei",
          "author": "Sirwired",
          "text": "Tags, tags, tags.  Have a set of mandatory tags for every resource, and tell devs you will start deleting everything that doesn't have them.\n\nOnce you have that, you can do whatever automated operations you want on the information you can now surface.",
          "score": 1,
          "created_utc": "2026-01-17 13:51:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066csm",
              "author": "IridescentKoala",
              "text": "Great now you have angry devs with deleted resources, or the same mess but with tags!",
              "score": 1,
              "created_utc": "2026-01-17 20:53:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06qy2w",
                  "author": "Sirwired",
                  "text": "Plenty of places have a \"untagged resources get deleted\" policy; it's not unusual, and they'll adjust soon enough.  Cost and resource control simply isn't possible without them.\n\nAnd for the kind of analyses OP wants, tags are step 1.",
                  "score": 1,
                  "created_utc": "2026-01-17 22:37:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qg1udo",
      "title": "Centralized CI/CD security scanning for 30+ repos. Best practices?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "author": "_1noob_",
      "created_utc": "2026-01-18 07:06:54",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.78,
      "text": "Hi everyone,\n\nWe are currently working on integrating CI/CD security tools across our platform and wanted to sanity-check our approach with the community.\n\nWe have 30+ repositories in bitbucket and are using AWS for CI/CD. \n\nWhat we are trying to achieve:\n\n* A centralized or shared pipeline for security scanning (SAST, SCA, Container Scanning, DAST).\n* Reuse the same scanning logic for all the repos \n* Keep pipelines scalable and maintainable as the number of repos grows.\n\nThe main challenge we are facing:\n\n* Each repository has different variables for SAST (eg sonarqube) \n\nQuestions:\n\n* Is it a good practice to have one shared security pipeline/template used by all repos for scanning?\n* How do teams typically manage repo-specific variables and Sonar tokens when using shared pipelines?\n* Any real-world patterns or pitfalls to watch out for at this scale (30+ pipelines)?\n\n\n\nAgain, goal is to keep security enforcement consistent without over-coupling pipelines as possible. \n\nWould really appreciate hearing how others have solved this in production.\n\nThanks in advance.",
      "is_original_content": false,
      "link_flair_text": "ci/cd",
      "permalink": "https://reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o09995s",
          "author": "no1bullshitguy",
          "text": "My first question would be: Why do you want it separate? Things like SAST / DAST should ideally be part of the individual application pipeline. Then only you can fail the pipeline when the code does not hit a particular baseline you set, let it be Code Quality (Sonarqube), SAST / DAST etc.\n\nNow, having said that,  I have implemented the other way also, like a Central Pipeline. The way I did is, all the fields are parametrized with fields for example Application ID for that particular application in our scan tool, Packaged Artifact URL for doing Opensource Library Scan, GIT Repo URL for downloading source for SAST ,  Branch to name a few (it has been 5 years so I dont remember most)\n\nThen the application build pipeline will trigger the scanning Job by calling REST API of CI/CD tool with above parameters filled in. Things like Artifact URL, GIT Repo URL etc would be already available as environment variables. But application ID for Scanning tool, i had to set it manually as a parameter for each pipeline (Devs will fill it, and I just had to give the template)\n\nAPI key for your Scanning tool would be most probably global key. This key can be stored as a variable in the central pipeline itself\n\nI have scaled both the above models for 1000+ pipelines. Works well, but I strongly suggest you to keep these scans and Quality gates as part of the actual build pipeline itself. It can go in parallel with rest of the stages not affecting deployment times. Because at some point, you would want to break the pipelines when code quality goes south.",
          "score": 1,
          "created_utc": "2026-01-18 07:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7ylt",
          "author": "XohleT",
          "text": "I am working on the same problem but for github. In our company we have 2000+ repositories and a lot of variation in pipelines due to not standardising from the start. \n\nThis makes it hard to enforce a single pipeline for everyone. If we do create one it is up to us to make sure it works for everyone which is a burden we rather not take on. \n\nSo we decided to decouple enforcement from scanning. In github we can create rulesets that require certain scanning tools to have checked the repository before a PR can be merged. We use this for enforcement while providing pipeline templates and private github actions to help implementation of scanning tools. \n\nThis makes it easier to start enforcement while not being a burden because teams can do their own implementation if ours don‚Äôt work. \n\nFor scanning tools that dont integrate with github rulesets checks we have created our own tool to check if the scanning is sufficient.",
          "score": 1,
          "created_utc": "2026-01-18 12:58:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bfrty",
          "author": "jefoso",
          "text": "I don't know if it's an approach that I'd follow. IMHO it's too late to fail.\n\nMost of these security/quality checks should happen at the left(the beginning) of the development so the earlier it fails the faster and cheaper it is to fix.\n\nI believe that: \n- developers shoulduse linters, pre-commit hooks, things that are cheaper to run and get possible issues locally \n- feature branches should also do some part of the job and execute more complex tools/scans\n \nCentralized tools should be part of the process, the company would have a release process where everyone agrees that if these integration tests or security scans fails, that feature would be removed from the release or the entire release would be blocked.\nI think this is not just about tools and how to implement them, but also how the company and teams works.",
          "score": 1,
          "created_utc": "2026-01-18 16:53:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fbjet",
              "author": "_1noob_",
              "text": "we are also using pre-commit hooks with a decent configuration.",
              "score": 1,
              "created_utc": "2026-01-19 05:01:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i396l",
          "author": "CodacyKPC",
          "text": "Hello, I'm Kendrick, VP of Technology at Codacy. I would say: use Codacy!\n\nWe connect to your Bitbucket directly and use webhooks to listen for changes and then scan the diff when you submit a PR. We do the scanning on our side in our cloud engine so there's no CI/CD configuration for you to have to handle. You can create multiple overlapping \"coding standards\" that can apply to whichever repositories you want, so can create e.g. a \"baseline security\" standard and a \"javascript standard\" and a \"frontend team standard\". \n\nThen you can gate merging of code into your main branch based on whether the Codacy checks passed in the PR.\n\nExtra plus: we have an IDE extension that will run the same checks locally so that by the time your devs get to the PR they should have already resolved all of the issues.\n\nExtra extra plus: the IDE extension \\_forces\\_ AI coding agents to resolve issues in their workflow, before they hand back control to the dev, so issues can get fixed without developers even knowing about them.\n\nYes, this was an advert. It still seemed relevant. Do DM me and we'll set you up with a free trial.",
          "score": 1,
          "created_utc": "2026-01-19 16:40:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qea3vh",
      "title": "Best way to install awscli, boto3, and botocore on Debian 13 EC2 instances",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qea3vh/best_way_to_install_awscli_boto3_and_botocore_on/",
      "author": "-kinappy",
      "created_utc": "2026-01-16 07:59:40",
      "score": 4,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm looking for advice on the best way to install awscli, boto3, and botocore on Debian 13 EC2 instances.\n\nPreviously, awscli was installed via an EC2 launch template using:\n\n/usr/bin/apt-get install awscli --assume-yes\n\nboto3 and botocore were installed via an Ansible playbook using pip. (versions were not pinned)\n\nA breaking change in the pip versions of boto3 and botocore caused compatibility issues with the awscli version from Debian 11‚Äôs apt. To resolve this, I updated the launch template to install awscli from the official zip:\n\n[https://awscli.amazonaws.com/awscli-exe-linux-x86\\_64.zip](https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip)\n\nNow, testing upgrading to Debian 13, global pip installs are blocked (error: externally-managed-environment), and venv is recommended.\n\nQuestion:\n\nWould it be best to move boto3 and botocore installation to the EC2 launch template, using apt:\n\n/usr/bin/apt-get install awscli python3-boto3 python3-botocore --assume-yes\n\nThis should ensure compatibility between all three packages. Any downsides or better approaches?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qea3vh/best_way_to_install_awscli_boto3_and_botocore_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzxejfc",
          "author": "kei_ichi",
          "text": "Launch new EC2 with that OS, install AWS CLI and whatever packages required for that CLI. Take a new AMI using that instance. Then use that AMI in launch template instead of using user-data in launch template which require time and connection to install that CLI every single time a new instance was created using that template!",
          "score": 10,
          "created_utc": "2026-01-16 14:43:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxrjp3",
              "author": "ziroux",
              "text": "And if you already use Ansible, you can use Packer to automate image provisioning",
              "score": 3,
              "created_utc": "2026-01-16 15:43:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00zgrk",
                  "author": "Vast_Manufacturer_78",
                  "text": "These are the answers",
                  "score": 2,
                  "created_utc": "2026-01-17 00:58:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o02ndjo",
                  "author": "witty82",
                  "text": "In general, I'd say packer nicely simplifies this process (even if you just run a shell script)",
                  "score": 2,
                  "created_utc": "2026-01-17 08:15:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzxiq5p",
          "author": "engineerfoodie",
          "text": "If you have a large install base and these are long running instances I would highly recommend looking into Ansible. It allows you to specify all sorts of criteria for install such as if certain things are installed, versions, files, etc. Another option, which can use Ansible under the hood is SSM documents. I believe SSM allows you to have the same criteria",
          "score": 3,
          "created_utc": "2026-01-16 15:03:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz62re",
          "author": "KayeYess",
          "text": "For essential packages, create a base AMI of your own. For everything else, use user data or SSM or something else.",
          "score": 1,
          "created_utc": "2026-01-16 19:27:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzxrquf",
          "author": "pint",
          "text": "i don't know what is the best, but you can use venv just as easily. venv creates a venv-aware python and pip, which you can invoke normally, you don't need to activate.\n\ne.g.\n\n    python3 -m venv /usr/local/python-venv\n    /usr/local/python-venv/bin/pip install boto3\n    /usr/local/python-venv/bin/python myfile.py",
          "score": 0,
          "created_utc": "2026-01-16 15:44:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qefo3w",
      "title": "Account suspended during active DDoS billing review ‚Äî seeking guidance on escalation paths",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qefo3w/account_suspended_during_active_ddos_billing/",
      "author": "Plane-Management-176",
      "created_utc": "2026-01-16 13:16:31",
      "score": 4,
      "num_comments": 7,
      "upvote_ratio": 0.75,
      "text": "Looking for guidance from others who have dealt with AWS account suspensions during active billing or security reviews.\n\nOur production workload was hit by a large DDoS attack, which caused a sudden spike in AWS WAF, CloudFront, and CloudWatch usage and a very large, unexpected bill. We opened support cases immediately, shared ARNs, detailed timelines, WAF analytics, request counts in the millions per day, and attacker IP samples. AWS acknowledged the issue and escalated it for service-team review and possible billing adjustment.\n\nWhile this review was still ongoing, and despite requesting temporary billing hold during the investigation, the account was suspended for non-payment. We‚Äôre now unable to log in to the console, which has taken production applications offline and blocked access to CloudWatch and infrastructure management.\n\nAt this point, we‚Äôre trying to understand the correct escalation path. For those who‚Äôve experienced something similar:  \nIs there a recommended way to get an account reinstated while a billing dispute is under review?  \nAre there escalation channels beyond the standard account support form once console access is blocked?\n\nAppreciate any guidance or experiences from the community.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qefo3w/account_suspended_during_active_ddos_billing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzz8crh",
          "author": "AWSSupport",
          "text": "Hello,\n\nSorry to hear about the issue with your account. Feel free to share your case ID with us via chat and I can take a look.\n\n\\- Doug S.",
          "score": 3,
          "created_utc": "2026-01-16 19:37:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzby1d",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-16 19:54:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzh9vr",
                  "author": "AWSSupport",
                  "text": "Hi there,\n\nThank you for providing your case ID. I've shared your concerns internally with our Support team on your behalf.\n\nI'd encourage you to continue to communicate via email with our Support team as they're equipped with the tools to best assist.\n\n\\- Doug S.",
                  "score": 1,
                  "created_utc": "2026-01-16 20:19:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02fehd",
          "author": "Burekitas",
          "text": "Do you have a Shield Advanced subscription? Or do you work with AWS Partner? \n\n  \nIf not, it might be a major cash flow issue, but the invoice must be paid until this issue is resolved.\n\nI've dealt with DDoS cases in the past and 15K customer received a $413K and it took 4 months to resolve it. Not an easy situation but invoices must be paid :/ \n\nGood luck getting your account back.",
          "score": 3,
          "created_utc": "2026-01-17 07:02:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz5tq1",
          "author": "The_Tree_Branch",
          "text": "Do you have an AWS account manager/account team? I'd be leaning on them heavily if so.",
          "score": 4,
          "created_utc": "2026-01-16 19:26:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzc8hz",
              "author": "Plane-Management-176",
              "text": "No i dont have any AWS account manager",
              "score": 2,
              "created_utc": "2026-01-16 19:55:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09ihai",
          "author": "dataflow_mapper",
          "text": "That sounds brutal, and sadly I have seen variations of this before. Once an account is fully suspended, normal support cases tend to stall because billing enforcement is automated and not tightly coupled to ongoing reviews. What helped in one case was getting the account manager or TAM involved, even if they were only loosely attached before. If you do not have one, pushing hard through the billing escalation form and explicitly stating production impact sometimes triggers a different internal queue. It is also worth asking for temporary read-only console access so you can at least validate state and exports. The big lesson I took from this is that billing disputes and security incidents often move on totally different tracks internally, and they do not always talk to each other fast enough.",
          "score": 1,
          "created_utc": "2026-01-18 09:17:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdjpx7",
      "title": "How to use AWS GPU instances optimally?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdjpx7/how_to_use_aws_gpu_instances_optimally/",
      "author": "blissfully_undefined",
      "created_utc": "2026-01-15 13:37:36",
      "score": 4,
      "num_comments": 10,
      "upvote_ratio": 0.7,
      "text": "I am wanting to use AWS GPUs for some of our custom models training and inference but unable to find suitable instance type for the workload. \n\nI have been trying to find the flexible configuration that I can find in runpod - where I can find multiple different gpus with full choice of how many gpus I want (between 1-10) as well flexible choice of cpus/storage/ram as well.\n\nBut at AWS, everything seems bundled up, I wanted to run a 8 T4 GPU instance and I am stuck with using only gp4dn.metal - which is forcing me to use a machine with 96vcpu - which I frankly don't need - I just want my gpus and their vram. Now I have hit my service quota - while I have raised the request to raise it, I find it really difficult to digest the lack of configuration option even for smaller gpus. \n\nI am willing to pay AWS a little extra than runpod - as long as I get similar configuration flexibility but for some reason AWS (and even GCP) lacks them? \n\nIs there a reason? And what are my options to get optimal usage of GPUs on AWS.\n\nCurrently I would be needing somewhere between 1-5 GPUs in parallel with Vram between 15 to 80GB. Higher numbers are extreme case scenarios.",
      "is_original_content": false,
      "link_flair_text": "compute",
      "permalink": "https://reddit.com/r/aws/comments/1qdjpx7/how_to_use_aws_gpu_instances_optimally/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzq4q45",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'compute'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+compute).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-15 13:37:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzqcxtf",
          "author": "dataflow_mapper",
          "text": "This is mostly a consequence of how AWS designs instance families. They optimize for predictable performance, network bandwidth, and failure domains rather than Lego-style flexibility. The CPU to GPU ratio is intentional because a lot of their customers push data hard through the GPUs, not just VRAM-bound inference. It feels wasteful if your workload is light on CPU, but it simplifies capacity planning and isolation on their side.\n\nYour realistic options are limited. You can look at g5 instances for smaller GPU counts, or split workloads across multiple smaller instances instead of one big box. For training, people sometimes decouple preprocessing onto separate CPU instances and keep GPU nodes as dumb as possible. If you truly want runpod-style flexibility, AWS is the wrong mental model. They sell reliability and integration first, efficiency second.",
          "score": 5,
          "created_utc": "2026-01-15 14:21:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzr1mau",
              "author": "blissfully_undefined",
              "text": "\"a lot of their customers push data hard through the GPUs\" -> can you please elaborate on this, I don't think I fully understand.\n\nWith realistic options, I am happy to workaround with multiple smaller gpu instances as a cluster. What truly holds back is there is hardly any option with gpus with varying VRam available as a single gpu machine like A40, A100, RTX 5090 etc. \n\nI can relate to AWS' decision making process but absolute lack of single gpu machines with portfolio of VRam just surprises me a lot.\n\nOn the off topic, what other platform apart from runpod would you recommend as a good alternative?",
              "score": 2,
              "created_utc": "2026-01-15 16:18:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqfip7",
          "author": "safeinitdotcom",
          "text": "On AWS, GPU instances are offered as fixed SKUs with predefined GPU/CPU ratios. You can‚Äôt rent GPUs independently of CPUs.\n\nInstead of one large multi-GPU node, spin up multiple smaller instances (5 separate g5.xlarge instances (1 GPU each). This reduces wasted CPU while fully utilizing GPUs. You can look over [**AWS ParallelCluster**](https://docs.aws.amazon.com/parallelcluster/latest/ug/what-is-aws-parallelcluster.html).\n\nHope it helps :)",
          "score": 1,
          "created_utc": "2026-01-15 14:34:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztyz1s",
              "author": "blissfully_undefined",
              "text": "Thank you, it does seem like a good suggestion - but the gpu available in g5 instance is also quite limited. Is there a way to get portfolio of different gpus on single machine such as A40, A100, RTX 5090 etc?",
              "score": 1,
              "created_utc": "2026-01-16 00:36:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzv0042",
                  "author": "Flakmaster92",
                  "text": "No, you pick the GPU by picking the instance family. All G6‚Äôs get L4s, all G6e‚Äôs get L40s (IIRC) and so on,",
                  "score": 1,
                  "created_utc": "2026-01-16 04:05:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qeh9wh",
      "title": "CodeBreach: Supply Chain Vuln & AWS CodeBuild Misconfig",
      "subreddit": "aws",
      "url": "https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild",
      "author": "shadowsyntax",
      "created_utc": "2026-01-16 14:23:11",
      "score": 4,
      "num_comments": 3,
      "upvote_ratio": 0.7,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1qeh9wh/codebreach_supply_chain_vuln_aws_codebuild/",
      "domain": "wiz.io",
      "is_self": false,
      "comments": [
        {
          "id": "nzxdzgz",
          "author": "cachemonet0x0cf6619",
          "text": "TLDR; misconfiguration in codebuild leads to aws github access. double check your configurations, people.",
          "score": 3,
          "created_utc": "2026-01-16 14:40:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzhch4",
          "author": "hashkent",
          "text": "It feels like it‚Äôs getting harder to keep your source code secure. Getting scary out there.",
          "score": 1,
          "created_utc": "2026-01-16 20:19:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o02x3bo",
              "author": "oalfonso",
              "text": "We had a big discussion in the last 2 weeks with the data scientists because corp devops and ciso teams blocked external access to pip and they can only access the internal codeartifact. \n\nThey don‚Äôt understand how risky is for a team managing customer sensible data, to download any library they find on the internet without any vulnerability checking.",
              "score": 2,
              "created_utc": "2026-01-17 09:46:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qg7a1g",
      "title": "Moving to CloudFormation with Terraform/Terragrunt background, having difficulties",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "author": "hardvochtig",
      "created_utc": "2026-01-18 12:24:11",
      "score": 4,
      "num_comments": 21,
      "upvote_ratio": 0.63,
      "text": "Hi all, I'm used to Terraform/Terragrunt when setting up infra and got used to its DRY principles and all. However my new company requires me to use CloudFormation for setting up a whole infra from scratch due to audit/compliance reasons. Any tips? Because upon research it seems like everybody hates it and no one actually uses it in this great year of 2026. I've encountered it before, but that's when I was playing around AWS, not production.\n\nI've heard of CDK, might lean into this compared to SAM.\n\n[](https://www.reddit.com/submit/?source_id=t3_1qg79f4)",
      "is_original_content": false,
      "link_flair_text": "CloudFormation/CDK/IaC",
      "permalink": "https://reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0a40s3",
          "author": "Sirwired",
          "text": "CDK generates CFn underneath, but it's still very different from TF. (CDK is a way to use Python, Java, TypeScript, JavaScript, C# and Go to generate CFn.)\n\nI have to wonder what audit reasons require them to use CFn directly.",
          "score": 21,
          "created_utc": "2026-01-18 12:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a4r2p",
              "author": "kei_ichi",
              "text": "All I can think is ‚Äúno external tools other than AWS native tools‚Äù bull sh*t",
              "score": 9,
              "created_utc": "2026-01-18 12:34:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a71m7",
                  "author": "hardvochtig",
                  "text": "Well, yes!",
                  "score": 3,
                  "created_utc": "2026-01-18 12:52:18",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a70cm",
              "author": "hardvochtig",
              "text": "For easy drift detection and everything is managed by AWS including the state.",
              "score": 4,
              "created_utc": "2026-01-18 12:52:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cyi21",
                  "author": "dr_barnowl",
                  "text": "The fact that you're forced to use the AWS backend of CloudFormation is likely the reasoning for this ; but there's no real reason why you can't set up a Terraform based IaC backend with the same constraints.\n\nIf you want full auditablility, the solution is the same ; log all the cloudtrail traffic and use that as the basis for any audit. The result is the same - the console, CF, and terraform, all use the same APIs.\n\nIf you want control, you have to do just as much work to do to prevent console meddling.\n\nDrift detection? TF can do that. State? You can put the state in an S3 bucket with strong controls on it.\n\nAll the attitudes preferring CloudFormation to Terraform I've seen ... seem to be rooted in dislike for the idea of programming. The only advantages CF has over TF in my book are that you have a prebuilt IaC setup, and lots of code samples. The rest ... CF is hard to grow, hard to refactor, and a PITA to modularize. And slow, because dependency graphs in CF treat stacks as an entire atomic unit, you can't update anything with an input that depends on an output until the whole stack is done.",
                  "score": 0,
                  "created_utc": "2026-01-18 21:17:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0coxcb",
              "author": "Davidhessler",
              "text": "Possibly CloudFormation Hooks / Guard. There are a lot of teams implementing controls these days using those techniques.",
              "score": 2,
              "created_utc": "2026-01-18 20:27:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a43ra",
          "author": "mrsmiley32",
          "text": "I'd go CDK and then synth the cloudformation from that for the audit purposes. CDK is much nicer to work with than cloudformation.",
          "score": 12,
          "created_utc": "2026-01-18 12:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a73zn",
              "author": "hardvochtig",
              "text": "So I‚Äôve heard! Definitely the top option, aside from asking them if CF is really necessary",
              "score": 3,
              "created_utc": "2026-01-18 12:52:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aogh8",
                  "author": "AntDracula",
                  "text": "CDK generates CF",
                  "score": 3,
                  "created_utc": "2026-01-18 14:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0akqjl",
          "author": "TheCamerlengo",
          "text": "I used cloud formation and code pipeline for years. I became rather proficient at it. Took a while. It‚Äôs awkward and difficult to debug when things go wrong. It taught me a lot about how AWS IAC provisioning really works. \n\nNew job uses terraform and after 1 day I never looked back. Terraform is light years easier to use but it is an abstraction. Understanding how cloud formation works helped me fill some gaps when using terraform. \n\nBasically you are going to hate cloud formation coming from terraform, but may learn something about how AWS and terraform work under the hood.",
          "score": 2,
          "created_utc": "2026-01-18 14:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ba0dr",
          "author": "ycarel",
          "text": "What are you struggling with?\nSince I don‚Äôt know what your pain points are it is hard to give helpful tips.\nThe only high level thing I have for you is to find the tools provided by your IDE for cloud formation. It will provide auto complete, etc. \nUse cfn-nag to help catch errors. \nThink of cloud formation as a low level language where you have to be super detailed.\nWhen deploying use change sets to help you know exactly what is changing.\nAs many have recommended consider CDK as it is a higher level construct that compiles into CFN.",
          "score": 2,
          "created_utc": "2026-01-18 16:26:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e9wwg",
          "author": "dafim",
          "text": "I'm going to get asked to leave over this opinion but here goes.\n\nTf sucks. Every new company or even department you go to has wildly different ways to do tf. You can \"learn\" tf, then move to another company and have no idea what TF is going on. There are more escape hatches in tf that it can be baffling how it even got a name for itself as iac. There is some real shit out there. It's like the little tikes learning kit for iac. In some ways it's the new perl vs python argument of \"there's more than one way to do it\" in perl vs \"there's only one way to do it\" in Python. Which I guess means in some ways it's a derivation of the (big|little) endiness argument.\n\nThe nicer thing about cf is that it's a bit more predictable (outside of using custom resources, etc) and as long as you're not naming things you can pick it up and deploy it in a similar account for dev or stage, etc. it's concept of \"state\" is the not defined by some file you need to keep track of, it's state is it and it's resources existence. It's also not as clever or fearureful as tf, which when you manage huge amounts of resources in huge amounts of stacks across huge amounts of accounts across modest amounts of departments can be a very very nice thing because you can still fit the concept in your head. And by cf I mean cdk and cf.",
          "score": 2,
          "created_utc": "2026-01-19 01:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7o8t",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-18 12:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cnrff",
              "author": "TheP1000",
              "text": "Cdktf is dead last I saw.",
              "score": 1,
              "created_utc": "2026-01-18 20:21:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aat83",
          "author": "pipesed",
          "text": "As others have pointed out, cdk is the programmatic way to compose cloud infrastructure. It does synth cfn templates, and it's code so it is as controllable and auditable as any other code. \n\nTerraform is still the most popular one we see, followed by cdk typescript.",
          "score": 1,
          "created_utc": "2026-01-18 13:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cj098",
          "author": "oneplane",
          "text": "\\> due to audit/compliance reasons\n\nI highly doubt that is really going to 'require' CloudFormation.\n\n\\> Any tips?\n\nSadly, no. While they are both IaC tools, they are rather different in how they work and view implementation choices. Besides informing about the tech stack next time you interview at a company, there isn't much you can do as even  TFCDK (TF-to-Cfn) is dead at this point. If you are a software engineer, you can use the Cfn CDK, but unless it's some sort of useless checkbox compliance (well, most are) that might not fly.",
          "score": 1,
          "created_utc": "2026-01-18 19:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f99bs",
          "author": "Dry_Raspberry4514",
          "text": "I don't understand the hate for CF. It helped us to solve the biggest problem in DevOps space -Stateless IaC.\n\nTerraform has two providers for AWS - aws and awscc. awscc uses cloud control api under the hood which in turn leverages most the stuff from CF excluding stack.\n\nIf you want support for new or updated aws resource types on day 1, you will need awscc which has dependency on CF indirectly as explained above. There have been cases in the past (and it will continue in future as well) where new aws features (e.g. regional NAT gateways) were added to aws provider after weeks when it was available in awscc provider on day 1 through AWS CC API. Unlike terraform, we use only CC API and have not seen any issue with it so far.",
          "score": 1,
          "created_utc": "2026-01-19 04:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7wdv",
          "author": "Kitchen-Location-373",
          "text": "tbh terragrunt is way way way less DRY for me than sceptre for cloudformation. I get it's a bigger community but terragrunt always turns into spaghetti code meanwhile for cloudformation I usually have like a three line yaml config file per environment",
          "score": 1,
          "created_utc": "2026-01-18 12:58:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a86vc",
              "author": "hardvochtig",
              "text": "For some reason this is the first time I‚Äôve heard of Sceptre despite researching for the past 3 hours. All I keep seeing is CDK. I‚Äôll read more on this, thanks!",
              "score": 1,
              "created_utc": "2026-01-18 13:00:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ajgiq",
                  "author": "wunderspud7575",
                  "text": "Sceptre is a poor man's Stacker. Stacker really should have been more successful. Sceptre is junk.",
                  "score": 1,
                  "created_utc": "2026-01-18 14:11:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0dnpfx",
              "author": "SnoopJohn",
              "text": "If you do terragrunt well it can end up very clean and make it really simple to ensure all environments are the same as the use the same module with just differences in the env vars",
              "score": 1,
              "created_utc": "2026-01-18 23:22:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}