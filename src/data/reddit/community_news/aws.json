{
  "metadata": {
    "last_updated": "2026-01-17 02:19:58",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 50,
    "total_comments": 423,
    "file_size_bytes": 534572
  },
  "items": [
    {
      "id": "1qds6k2",
      "title": "AWS flips switch on Euro cloud as sovereignty fears mount",
      "subreddit": "aws",
      "url": "https://www.theregister.com/2026/01/15/aws_european_sovereign_cloud/?td=rt-3a",
      "author": "NISMO1968",
      "created_utc": "2026-01-15 18:51:57",
      "score": 268,
      "num_comments": 148,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qds6k2/aws_flips_switch_on_euro_cloud_as_sovereignty/",
      "domain": "theregister.com",
      "is_self": false,
      "comments": [
        {
          "id": "nzti94y",
          "author": "Burekitas",
          "text": "The interesting stuff:\n\n10ms latency to eu-central-1.\n\npricing on the website is not fully available yet, use the calculator (https://pricing.calculator.aws.eu/) instead.\n\nS3 is seperated from the \"regular\" S3, therefor, you can register bucket names that already exists in S3 and havn't taken yet, I created the following buckets: 1234, mobile etc. (I really want to registrer \"french-goverment\" but I think it's too much).\n\nRoute53 domains are EU tld (nl/eu/fr/de).\n\nIdentity Center is not yet available (appears in IAM but leads to 404). You can configure external SSO like Okta, OneLogin etc.\n\n  \nIn general, it sounds like AWS are still working on many features, but it's a great starting point.",
          "score": 26,
          "created_utc": "2026-01-15 23:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztod6f",
              "author": "pwnedbilly",
              "text": "It will almost certainly be a separate partition as with GovCloud and AWS China so your ARNs will still be globally unique.",
              "score": 6,
              "created_utc": "2026-01-15 23:39:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuvg3d",
              "author": "sh1boleth",
              "text": "It wonâ€™t have full feature parity with regular aws partition ever due to the nature of operations.\n\nSome niche feature or service will be missing",
              "score": 3,
              "created_utc": "2026-01-16 03:38:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsbh4j",
          "author": "arwinda",
          "text": "Has the USA, using the Cloud Act, still access to the data? Yes or no.",
          "score": 70,
          "created_utc": "2026-01-15 19:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzse14r",
              "author": "ShakataGaNai",
              "text": "Clearly AWS's goal is \"No\", because if it can still be CLOUD'd then it's effectively useless. But that's going to be in a court of law to try and untangle that. It's a cloud infra in Europe, run by Europeans, run by a new European company,  independent of anything American.",
              "score": 46,
              "created_utc": "2026-01-15 19:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzser32",
                  "author": "arwinda",
                  "text": "The Cloud Act allow access as long as the European company is a subsidiary. For AWS this requires a fully independent company. Which also pays all taxes in Europe, as example. No more money extraction to the US.",
                  "score": 32,
                  "created_utc": "2026-01-15 19:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz4tha",
                  "author": "Hopeful-Programmer25",
                  "text": "I simply donâ€™t believe there is no link to the parent US AWS company, otherwise itâ€™s not a subsidiary, itâ€™s a competitor to US AWS. if no money is flowing to the US parent then AWS has effectively withdrawn from the EU market.\n\nObviously, it hasnâ€™t so the fact itâ€™s a subsidiary means that the US can easily apply pressure to the parent. Legality means nothing if the US parent can just replace the CEO and board of an â€œindependentâ€ subsidiary as they own all the shares with people who are compliant.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvttyk",
                  "author": "afroisalreadyinu",
                  "text": "\\> independent of anything American\n\nnamed AWS, same hardware, software and API, funded by the American entity, so I doubt this.",
                  "score": 4,
                  "created_utc": "2026-01-16 07:49:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsol0n",
              "author": "HanzJWermhat",
              "text": "If itâ€™s anything like GovCloud no. You need citizenship to access the region, all customer data is stored in the region.\n\nOperational logs probably get exported and centralized however",
              "score": 12,
              "created_utc": "2026-01-15 20:45:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuel3w",
                  "author": "wlonkly",
                  "text": "> You need citizenship to access the region\n\nThat's not correct -- you need to be a US person to open an account, but what happens after that is up to you (and your sponsoring agency).  \n\nI'm Canadian and have access to my company's GovCloud accounts.",
                  "score": 6,
                  "created_utc": "2026-01-16 02:03:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuklkc",
                  "author": "Skytram_",
                  "text": "Logs donâ€™t get exported.",
                  "score": 4,
                  "created_utc": "2026-01-16 02:37:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvtklh",
                  "author": "NaCl-more",
                  "text": "Logs stay in partition",
                  "score": 3,
                  "created_utc": "2026-01-16 07:46:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx5ofi",
                  "author": "KarlHungas",
                  "text": "Operation logs, billing, everything is separate from the US AWS.  I sat in an interesting session about this at AWS reinvent",
                  "score": 2,
                  "created_utc": "2026-01-16 13:57:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxdgz9",
                  "author": "ghillisuit95",
                  "text": "> Operational logs probably get exported and centralized however\n\nNo, AWS mostly uses the in-region CloudWatch for logging. Older services may still use something called timber, but its also regional. \n\nusage data and metrics may be visible to non-eu employees, but I don't think that's very concerning",
                  "score": 1,
                  "created_utc": "2026-01-16 14:37:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsqteu",
                  "author": "arwinda",
                  "text": "> If itâ€™s anything like GovCloud\n\nI do not see a clear confirmation in the article, nor in other articles about this announcement.\n\nAnd I also don't see any clarification that US personnel definitely won't have access. Until this is confirmed one has to assume that the US, including the government, can still access the data.",
                  "score": -13,
                  "created_utc": "2026-01-15 20:55:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrauu",
              "author": "DecisionOk474",
              "text": "They have a separate auth stack. No US citizens can physically or logically access it.",
              "score": 5,
              "created_utc": "2026-01-15 23:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuio6x",
                  "author": "Sea-Us-RTO",
                  "text": "what about psychologically? ðŸ˜„",
                  "score": 3,
                  "created_utc": "2026-01-16 02:26:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o00601y",
              "author": "conspicuousxcapybara",
              "text": "Yes. More specifically, AWS wrote in their [blog 'Five facts about how the CLOUD Act actually works'](https://aws.amazon.com/blogs/security/five-facts-about-how-the-cloud-act-actually-works/):\n\n>\"Fact 1: The CLOUD Act does not give the U.S. government **unfettered or automatic access** to data stored in the cloud.   \n  \n\\[..\\]    \n  \nTo compel a provider to disclose content data, law enforcement must convince an independent federal judge that probable cause exists related to a particular crime, and that evidence of the crime will be found in the place to be searched\"",
              "score": 1,
              "created_utc": "2026-01-16 22:16:41",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzwlsio",
              "author": "coldoil",
              "text": "No.",
              "score": 1,
              "created_utc": "2026-01-16 11:55:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzseee6",
          "author": "cloudrkt",
          "text": "As long as it is a US owned company it will never be sovereign.",
          "score": 195,
          "created_utc": "2026-01-15 19:57:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsgtrt",
              "author": "landon912",
              "text": "The region is technically owned by a subsidiary HQâ€™d in Europe",
              "score": 68,
              "created_utc": "2026-01-15 20:08:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztccml",
                  "author": "FalseRegister",
                  "text": "Subsidiaries are also subject to US law",
                  "score": 49,
                  "created_utc": "2026-01-15 22:36:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsoahs",
                  "author": "HanzJWermhat",
                  "text": "But the operational management and software development is all centrally managed in the US",
                  "score": -20,
                  "created_utc": "2026-01-15 20:43:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzzot5p",
                  "author": "No-Theory6270",
                  "text": "And lead by one guy called IsraÃ«l",
                  "score": 0,
                  "created_utc": "2026-01-16 20:54:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrd7m",
              "author": "Rolandersec",
              "text": "Yeah itâ€™s too late for this. The other nations are building this stuff out already and itâ€™s going to be the great commoditization and democratization of the cloud. \n\nWill probably work out great for netapp though.",
              "score": 3,
              "created_utc": "2026-01-15 23:55:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvtmh2",
              "author": "Express-One-1096",
              "text": "It can be if itâ€™s standalone but pays royalty fees for the brand.",
              "score": 1,
              "created_utc": "2026-01-16 07:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nztiz50",
          "author": "teo-tsirpanis",
          "text": "My â€˜The AWS European Sovereign Cloud is operated exclusively by EU citizens located in the EUâ€™ t-shirt is raising many questions already answered by the t-shirt",
          "score": 12,
          "created_utc": "2026-01-15 23:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o006nun",
              "author": "SoldadoAruanda",
              "text": "I feel like it's suspicious,  as if I move to a new town, and my neighbor introduced himself by saying,  \"Hi, my names Jeff, and don't worry,  I don't murder people in my basement.\"",
              "score": 2,
              "created_utc": "2026-01-16 22:19:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs2ccg",
          "author": "Goon_be_gone",
          "text": "The AWS sovereignty policies are good enough for China Iâ€™m sure theyâ€™ll be good enough for the EU.",
          "score": 55,
          "created_utc": "2026-01-15 19:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa76l",
              "author": "kestrel808",
              "text": "AWS China is distinctly different than AWS in the rest of the world.  They have their own API, you can't do things like connect vpc's globally and they're run by local partners.  China is way more than \"just another region\".",
              "score": 34,
              "created_utc": "2026-01-15 19:38:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsb8za",
                  "author": "Kaynard",
                  "text": "Same thing for Europe, it's a new AWS partition (Like China, GovCloud, commercial AWS etc) and with one region in it for now.",
                  "score": 80,
                  "created_utc": "2026-01-15 19:43:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsaxo2",
                  "author": "likeavirgil",
                  "text": "How is that different from the sovereign cloud offering in the EU?",
                  "score": 8,
                  "created_utc": "2026-01-15 19:41:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztrh7j",
                  "author": "DecisionOk474",
                  "text": "Just like every other AWS partition. That isnâ€™t china specificâ€¦..",
                  "score": 3,
                  "created_utc": "2026-01-15 23:55:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsjpgd",
              "author": "hkgwwong",
              "text": "China has other very strong alternatives, unlike Europe. As far as I know nobody consider AWS their first choice , might be way more popular among foreign companies need a cloud in China.",
              "score": 1,
              "created_utc": "2026-01-15 20:22:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsofrd",
          "author": "humbuckler404",
          "text": "So that means they will never be impacted by us-east-1 issues? :skeptical-face:",
          "score": 27,
          "created_utc": "2026-01-15 20:44:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztjo4e",
              "author": "xxwetdogxx",
              "text": "Correct. All the source code was copied into the region, the USA could sink to the bottom of the ocean and the ESC region would still run, there's no dependency.",
              "score": 18,
              "created_utc": "2026-01-15 23:13:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztp7tz",
                  "author": "humbuckler404",
                  "text": "Thatâ€™s great news. Itâ€™s been a few years since I worked in AWS, so I know â€œno dependenciesâ€ were something we always pursued. Of course, the challenges in implementing that is what made the Wednesday morning Ops Reviews so entertaining ðŸ˜",
                  "score": 6,
                  "created_utc": "2026-01-15 23:43:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvadl2",
                  "author": "ares623",
                  "text": "Donâ€™t some critical services still rely on us-east-1 though?",
                  "score": -2,
                  "created_utc": "2026-01-16 05:14:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsze5u",
              "author": "nemec",
              "text": "correct, that's the difference between a region and a partition\n\nhttps://www.reddit.com/r/aws/comments/1oe99zi/did_mondays_outage_impact_govcloud_users_at_all/",
              "score": 14,
              "created_utc": "2026-01-15 21:34:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzz5ig5",
              "author": "KayeYess",
              "text": "A few popular services like IAM, R53 and Cloudfront have their control planes operating only in US East 1.\n\n\nR53 announced a HA control plane (opt in required) in US West 2 (still US) for Public Hosted Zones.\n\n\nIAM is also preparing a similar solution, most likely in US West 2\n\n\nUnless they create a totally independent and sovereign region (like China) in EU, AWS EU will have some dependency on AWS US.",
              "score": 1,
              "created_utc": "2026-01-16 19:24:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzst91a",
              "author": "ImCaffeinated_Chris",
              "text": "This is the real question.",
              "score": 1,
              "created_utc": "2026-01-15 21:06:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsjfix",
          "author": "Bloodsucker_",
          "text": "EU should make sure to only use regional providers. Plenty of companies and banks have stopped expanding in the cloud owned by the USA. It's not safe or aligned with European sovereignty. They, aws, know this, that's why they're panicking. It's not sufficient to use a regional subsidiary.",
          "score": 12,
          "created_utc": "2026-01-15 20:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztjqhe",
          "author": "KayeYess",
          "text": "Don't trust anyone. Protect what you need to, yourself. Whether it is a US based cloud company or a Europe based data center doesn't matter.",
          "score": 3,
          "created_utc": "2026-01-15 23:14:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztryj3",
              "author": "BigBagaroo",
              "text": "The US intelligence services would be incompetent if they did not have access to all data.\n\nNow that the US is no longer an ally of EU, EU should move their data away from their platforms.",
              "score": -1,
              "created_utc": "2026-01-15 23:58:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu6uyr",
                  "author": "KayeYess",
                  "text": "Maybe put the data in Greenland ðŸ˜‚",
                  "score": 2,
                  "created_utc": "2026-01-16 01:20:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztgobg",
          "author": "yourfriendlyreminder",
          "text": "What is the feature parity with regular AWS? \n\nAnd what is the support model?\n\nThe thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either",
          "score": 2,
          "created_utc": "2026-01-15 22:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00vlp7",
              "author": "MateusKingston",
              "text": ">What is the feature parity with regular AWS?\n\nImpossible to tell so early on but Govt Cloud is heavily behind, but it has all the mainstream products afaik, it's just the new shiny toys and obscure products that never get there or take some time.\n\n>The thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either\n\nI don't think this truly matters, you're not getting supported by AWS Engineers anyway, you're getting support from a support team that was trained and know how their specialized services work, etc. They will simply have those people in the new EU subsidiary that should take over those duties.",
              "score": 1,
              "created_utc": "2026-01-17 00:36:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuud9v",
          "author": "maxip89",
          "text": "It only need one u.s. shadow trial gets public, and the whole aws europe story is done.",
          "score": 2,
          "created_utc": "2026-01-16 03:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy1w3s",
          "author": "Dzefo_",
          "text": "I already see myself migrating all the infra againâ€¦",
          "score": 2,
          "created_utc": "2026-01-16 16:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt5tf8",
          "author": "twin-hoodlum3",
          "text": "Funny seeing all the comments from the AWS fanboys, thinking it matters if the AWS Sovereign Cloud is run by European AWS subsidiaries located in the EU.\n\nGuys: it . doesnâ€˜t. matter. As long as the mother company who fully owns the European subsidiary is US based, then the CLOUD Act still applies. Period.",
          "score": 4,
          "created_utc": "2026-01-15 22:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwx7y3",
              "author": "HomoAndAlsoSapiens",
              "text": "That's why they specifically designed these daughter companies to have to deny requests by US courts. There is not a single American working there that would therefore have to comply with US courts and any request that the parent company in the US would put through because they have to would then be denied because it would be illegal to do so in Europe. It's not as easy as you'd like to think it is.\n\nDid you know that the US also wants to tax you on shares of US-companies even if you have nothing to do with the country? Foreign banks, of course, just ignore that and don't report to them. Their intention was to build a similar system here.",
              "score": 3,
              "created_utc": "2026-01-16 13:11:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzx0cuj",
                  "author": "twin-hoodlum3",
                  "text": "Basically it's easier than you might think. Under US law, authorities can compel a provider subject to US jurisdiction to disclose data that is within the providerâ€™s â€œpossession, custody, or control,â€ even if the data is stored in Europe. Whether this reaches data â€œhandled by an EU subsidiaryâ€ often turns on whether the US parent (or another US-jurisdiction entity) has sufficient legal/technical control over that data, and it can create a direct conflict with GDPR rules on responding to foreign orders.\n\nThe key message here is \"possession and control\". What do you think will happen to AWS US if some susidiary manager says \"no\" to their bosses? The only way to circumvent such things at least in parts is to use infrastructure like SAP Delos or Bleu. But event this is questionable. \n\nSource: \n\n* 18 U.S. Code Â§ 2713 (https://www.law.cornell.edu/uscode/text/18/2713)\n* CLOUD act Q&A (https://www.justice.gov/criminal/media/999616/dl?inline)",
                  "score": -1,
                  "created_utc": "2026-01-16 13:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzubez4",
              "author": "alienangel2",
              "text": "I mean, if the US govt wants to get at data hosted in some other cloud provider, even one 100% built from scratch in Europe, they are still going to get it whether they do it legally or not. \n\nCLOUD act will make it vaguely defensible in US courts but no one in the US admin cares about courts anymore, and no one in any intelligence agency has ever cared about courts. It's probably easier for them to steal from some homegrown local cloud provider than from AWS.",
              "score": 4,
              "created_utc": "2026-01-16 01:45:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvq24k",
                  "author": "Interesting_Shine_38",
                  "text": "This is precisely what I believe people fail to understand. Like those guys blew up air gapped uranium enrichment facility. You think your vulnerable outdated OpenStack deployment will be a problem for them?",
                  "score": 2,
                  "created_utc": "2026-01-16 07:16:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00wm34",
                  "author": "MateusKingston",
                  "text": "This is far different from \"they will just demand the data and it will be handed over\".\n\nCyberwarfare and Cybercrime are very different from courts demanding access and being handed over.\n\nBut I wouldn't be so sure about this, the US has only shown their Cyberwarfare capabilities against subpar opponents.",
                  "score": 1,
                  "created_utc": "2026-01-17 00:41:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztbdgd",
              "author": "sutongorin",
              "text": "Even if it didn't apply it's doubtful customers would care. It still has AWS in its name. Anything US-related is tainted.",
              "score": 0,
              "created_utc": "2026-01-15 22:31:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzz36cc",
          "author": "granviaje",
          "text": "If trump tells Amazon to shut it down how long do you think it will take for this to happen?Â \n\nAs long as Trump is on the helm there is no way to trust any US company.Â ",
          "score": 1,
          "created_utc": "2026-01-16 19:13:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzzuok5",
          "author": "BigBagaroo",
          "text": "The AWS/US brigade is in full force on this topic.\n\nI would advice any non-US citizen to read this article and think for themselves:\n\nhttps://en.wikipedia.org/wiki/Crypto_AG\n\nÂ«Crypto AG was a Swiss company specialising in communications and information security founded by Boris Hagelin in 1952. \n\nThe company was secretly purchased in 1970 by the US Central Intelligence Agency (CIA) and West German Federal Intelligence Service (BND) for US $5.75 million (equivalent to $47 million in 2024)[1] and jointly owned until about 1993, with the CIA continuing as sole owner until about 2018Â»\n\nÂ«The mission of breaking encrypted communication using a secretly owned company was known as Operation Rubicon. \n\nWith headquarters in Steinhausen, the company was a long-established manufacturer of encryption machines and a wide variety of cipher devices.Â»",
          "score": 1,
          "created_utc": "2026-01-16 21:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzthe5r",
          "author": "thirstybatman",
          "text": "I truly wonder which public bodies will use this. Two years ago, yes. But not anymore, that train has left the station. Sovereign in the name only.",
          "score": 1,
          "created_utc": "2026-01-15 23:01:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt9tuy",
          "author": "egorf",
          "text": "I can see two problems with this.\n\n1) It's hard to imagine AWS \"EU\" not complying with requests from the US administration. Even if we exclude clandestine requests based on the fact that the US doesn't respect sovereignty, imagine they ban, say, the export of cloud orchestration technologies just like they restricted GPU exports, including to the EU.\n\n2) It's easy to imagine AWS \"EU\" trying to comply with all local EU laws and regulations which either brings the cloud to a halt or makes the usage of it impractical. Say, no AI models deployed until seven-years mandatory Environmental Impact Study has been performed. Or something along these lines.",
          "score": -2,
          "created_utc": "2026-01-15 22:23:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu9ntw",
              "author": "ByronScottJones",
              "text": "Literally none of the people working in the EU partition are allowed to be US citizens. They are all REQUIRED to be EU citizens. There's nobody in the US that will have legal leverage to require such requests to be complied with.",
              "score": 7,
              "created_utc": "2026-01-16 01:36:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyeghf",
                  "author": "egorf",
                  "text": "Exfiltration of data on US request is not going to be done via engagement with EU staff. It will be done in the US by using the corresponding backdoor in the AWS code with no EU involvement and knowledge whatsoever.",
                  "score": 0,
                  "created_utc": "2026-01-16 17:24:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwyhjj",
              "author": "HomoAndAlsoSapiens",
              "text": "You have no understanding of this, no offense.\n\n1. Complying with these requests is illegal. There also are no US citizens that could be compelled to comply. In fact, the entire new company structure is based on this principle.\n\n2. They have to comply with laws because laws are not optional. AWS with their normal regions equally has to comply with laws because laws are not optional. In Europe, AWS exclusively operates via its Luxembourgish daughter Amazon Web Services EMEA SARL.",
              "score": 2,
              "created_utc": "2026-01-16 13:18:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzz44n9",
                  "author": "granviaje",
                  "text": ">Â They have to comply with laws\n\nSince when does the trump admin care about laws?",
                  "score": 2,
                  "created_utc": "2026-01-16 19:18:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz6z4m",
                  "author": "Hopeful-Programmer25",
                  "text": "I may be going overboard but you are assuming laws still matter to the US governmentâ€¦. They donâ€™t. They can, and will, pressure the parent US company to fulfil what they need and, itâ€™s clear, that the US parent will fold. The US parent still owns the EU subsidiary, still decides who runs it, who will then find a way to comply or be fired.\n\nThis is going beyond data sovereignty, itâ€™s that the US is a hostile actor to European interests, and could easily shut down European infrastructure in the worse case scenario.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:31:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyftfn",
                  "author": "egorf",
                  "text": "1. Of course. No EU personnel will be involved in data exfiltration process at all as the AWS software contains all required backdoors for the US staff to download whatever the US needs. Notice: I did not write \"could contain a backdoor\". I deliberately wrote that it DOES contain a backdoor. The opposite is simply inconceivable.\n\n2. Great! I love that AWS complies with the laws as it should be! Meanwhile as a EU citizen I will continue using the US AWS exclusively because I want the most recent AI models available with no committee to decide which text transformation engine I am allowed to use. And I don't want to slap my recent utility bill with every API request to AWS.\n\nSo Godspeed to AWS EU but I have negative trust at all levels.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwr2fg",
          "author": "elchupacabrone",
          "text": "They are still American company. This doesn't change anything and it's definitely not \"sovereign\" because when NSA wants to get access to their resources they have to obey.",
          "score": 0,
          "created_utc": "2026-01-16 12:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwyvcw",
              "author": "HomoAndAlsoSapiens",
              "text": "You are so sure? Then explain how a request for the data would be handled and I can explain why you're wrong and have actually not sufficiently thought about it.",
              "score": 1,
              "created_utc": "2026-01-16 13:21:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxrqg6",
                  "author": "elchupacabrone",
                  "text": "Yes I'm sure - CLOUD act 2018.",
                  "score": -1,
                  "created_utc": "2026-01-16 15:44:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt2fhy",
          "author": "BigBagaroo",
          "text": "There is absolutely no reason to believe AWS on this.",
          "score": -5,
          "created_utc": "2026-01-15 21:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztc9a9",
              "author": "bastion_xx",
              "text": "Why not? You, and customers that will use this, can read the docs. From the FAQ:\n> The AWS European Sovereign Cloud will maintain key certifications such as ISO/IEC 27001:2013, SOC 1/2/3 reports, and BSI C5 attestation, all validated regularly by independent auditors to assure our controls are designed appropriately, operate effectively and help customers satisfy their compliance obligations.",
              "score": 2,
              "created_utc": "2026-01-15 22:35:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztti59",
                  "author": "twin-hoodlum3",
                  "text": "Have you ever been to an ISO 27k1 audit and know the controls? These regulations are (surprisingly) just for the sake of compliance (aka: weâ€˜re at least not amateurs), not at all proof of anything in terms of security or sovereignity.",
                  "score": 1,
                  "created_utc": "2026-01-16 00:06:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztq0jl",
                  "author": "BigBagaroo",
                  "text": "Oh my, it says so in the FAQ? Well, that changes everything!",
                  "score": -4,
                  "created_utc": "2026-01-15 23:48:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6i9n",
          "author": "codechris",
          "text": "Complete shite. If you're European use an EU cloud,Â  it this fake wank from AmazonÂ ",
          "score": -5,
          "created_utc": "2026-01-15 22:07:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyi6tw",
              "author": "jrolette",
              "text": "What EU cloud would you suggest they use that isn't much more than a VPS and storage provider? There are no options that are even vaguely comparable to AWS, Azure, and GCP.",
              "score": 1,
              "created_utc": "2026-01-16 17:41:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyrmts",
                  "author": "codechris",
                  "text": "Depends what you need. A lot of stuff is just a container and a DB (I'm being simplistic but it makes the point) plenty of companies running on EU cloudsÂ ",
                  "score": 1,
                  "created_utc": "2026-01-16 18:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs1sjp",
          "author": "BenchOk2878",
          "text": "If Trump can get Greenland,Â  that \"pinky promise\" does not mean shit.\n\n\nBezos will give away any data requested by USA government.Â \n\n\nGet real.",
          "score": -8,
          "created_utc": "2026-01-15 18:59:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzudnk0",
              "author": "madwolfa",
              "text": "That's not how storage in cloud works, especially if you use your own encryption keys (as you should if you care about this sort of thing).Â ",
              "score": 3,
              "created_utc": "2026-01-16 01:58:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsr2zu",
          "author": "Maang_go",
          "text": "All Trump has to do is ask AWS to revoke encryption keys used by all AWS services in the background, of anything European hosted in AWS. \n\nThen all hardware will still be in Europe, all software will be operating from here, All data will be stored in Europe but unusable. Cloud is designed for control not capex opex.",
          "score": -7,
          "created_utc": "2026-01-15 20:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsyyjo",
              "author": "nemec",
              "text": "Why do you think Americans have control over the EU Cloud encryption keys?",
              "score": 15,
              "created_utc": "2026-01-15 21:32:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztsz0w",
                  "author": "baronas15",
                  "text": "Cloud act",
                  "score": 0,
                  "created_utc": "2026-01-16 00:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztssb2",
                  "author": "twin-hoodlum3",
                  "text": "As long as the customers donâ€˜t use their own KMS encrypting data *before* they get into AWS, AWS and â€žothersâ€œ (by request) have the encryption keys.",
                  "score": 0,
                  "created_utc": "2026-01-16 00:03:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt6rgi",
                  "author": "Maang_go",
                  "text": "â€œNoted.â€",
                  "score": -1,
                  "created_utc": "2026-01-15 22:09:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q4apop",
      "title": "I managed to run Llama 3.2 on Lambda with sub-500ms cold starts. Here is the architecture.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q4apop/i_managed_to_run_llama_32_on_lambda_with_sub500ms/",
      "author": "NTCTech",
      "created_utc": "2026-01-05 03:28:54",
      "score": 93,
      "num_comments": 32,
      "upvote_ratio": 0.96,
      "text": "I refused to pay for a dedicated SageMaker endpoint (or even a reserved EC2) for an internal chatbot that gets hit maybe 40â€“60 times a day. It felt like lighting money on fire.\n\nEveryone told me not to bother with Lambda because of cold starts â€” and honestly, they were right at first. Out of the box, loading a \\~4GB model took \\~40 seconds. Completely unusable for anything chat-like. I wasted a few hours proving that point.\n\nBut I went down a rabbit hole over the weekend and ended up with something thatâ€™s actually usable. Iâ€™m seeing cold starts consistently under \\~500ms now.\n\nTwo things that mattered way more than I expected:\n\n**1)** You have to â€œwasteâ€ RAM to get CPU  \nI initially ran it at 4GB since the model fit, but inference was crawling at \\~3â€“4 tokens/sec. Lambda throttles CPU pretty hard unless you provision more memory.\n\nI cranked it up (mostly to unlock the 6 vCPUs), and inference jumped to \\~18â€“22 tokens/sec. Same code, same model â€” just more memory.\n\n**2**) Bypassing disk entirely to fix cold starts  \nSnapStart helps, but it currently doesnâ€™t work with Python container images and caps `/tmp` at 512MB, which is too small for the model.\n\nSo I did something a bit ugly.\n\nDuring the init phase, I stream the model bytes straight from S3 into RAM using `memfd_create` (anonymous memory-backed files). I hand that file descriptor to `llama.cpp`, which thinks itâ€™s reading a file â€” but it never touches disk.\n\nWhen SnapStart snapshots the function, it captures that in-memory model. On restore, the model is already â€œloaded,â€ which kills the cold start.\n\nThis definitely isnâ€™t something Iâ€™d ship blindly. Debugging is painful, memory visibility is opaque, and I wouldnâ€™t be shocked if AWS breaks this in a future runtime. But for this use case, itâ€™s been stable so far.\n\nI wrote up the full architecture and code snippets separately because it didnâ€™t really fit in a Reddit post. If anyone wants the full breakdown, I can drop the link in the comments.\n\nSide question: has anyone replaced Step Functions with Durable Functions for this kind of orchestration? Iâ€™m tempted to simplify state management, but Iâ€™m worried the state history storage costs might sneak up later.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q4apop/i_managed_to_run_llama_32_on_lambda_with_sub500ms/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxtj0mm",
          "author": "d70",
          "text": ">gets hit maybe 40â€“60 times a day\n\nWhy not Bedrock? Tons more options than just Llama if you want cheap and fast models.",
          "score": 50,
          "created_utc": "2026-01-05 14:15:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtlca4",
              "author": "NTCTech",
              "text": "Bedrock was on the shortlist to be honest, fair question though....\n\nFor this case, the main reasons I didnâ€™t go that route were cost predictability and control. Even at low volume, per-token pricing added up faster than I expected once I factored in experimentation and prompt retries, and I wanted tighter control over the runtime behavior.\n\nThis was also partly an exercise in seeing how far Lambda could be pushed for inference under very low utilization. If this were customer-facing or spikier traffic, Bedrock would probably be the more boring (and safer) choice.",
              "score": 5,
              "created_utc": "2026-01-05 14:28:09",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxxa18p",
                  "author": "BaxterPad",
                  "text": "40-60  requests a day and \"costs add up fast\" are hard to fathom. What are we talking... $5 bucks on a horrible day?",
                  "score": 7,
                  "created_utc": "2026-01-06 01:04:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxtvn2g",
          "author": "ExplanationHot4568",
          "text": "Bedrock \"Am I a joke to you?\"",
          "score": 31,
          "created_utc": "2026-01-05 15:21:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtxkhk",
              "author": "NTCTech",
              "text": "Bedrock was definitely considered.\n\nThis was mostly about cost predictability at very low usage and seeing how far Lambda could be pushed. For anything customer-facing or higher volume, Bedrock is probably the sane choice.",
              "score": 11,
              "created_utc": "2026-01-05 15:30:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxv9485",
                  "author": "goguppy",
                  "text": "love the experimentation mindset!",
                  "score": 2,
                  "created_utc": "2026-01-05 19:09:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxtdvus",
          "author": "Old_Pomegranate_822",
          "text": "This does sound interesting, would like to see moreÂ ",
          "score": 8,
          "created_utc": "2026-01-05 13:45:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtmw2q",
              "author": "Mohamed____",
              "text": "Interested as well",
              "score": 3,
              "created_utc": "2026-01-05 14:36:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxttkra",
          "author": "solo964",
          "text": "Note that as well as CPU being proportional to the function's configured RAM, so is the duration cost per ms. But the invocation should complete much more quickly so the net cost may still be comparable.",
          "score": 4,
          "created_utc": "2026-01-05 15:11:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtxw1s",
              "author": "NTCTech",
              "text": "Yep, exactly. The per-ms cost definitely goes up with memory, but the shorter execution time offsets most of it in this case.\n\nAt this traffic level, the cold start penalty mattered more than squeezing out per-ms cost, and the total monthly spend ended up roughly in the same ballpark. If usage creeps up, this tradeoff would probably flip pretty quickly.",
              "score": 1,
              "created_utc": "2026-01-05 15:32:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxthgmp",
          "author": "gwinerreniwg",
          "text": "Please do share the samples - I might have time to play with this today.  Thanks!",
          "score": 5,
          "created_utc": "2026-01-05 14:06:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu1aqu",
          "author": "gcavalcante8808",
          "text": "you can also load the model using @lru_cache so the first execution is slow and the next ones are quick.\n\nYou can also use their warm lambda solution to keep it ready as well.",
          "score": 2,
          "created_utc": "2026-01-05 15:48:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxu33x0",
              "author": "NTCTech",
              "text": "Those are the go-to moves for standard APIs....\n\nIâ€™m a huge fan of  lru\\_cacheÂ for keeping local lookups snappy.\n\nThe headache with Llama 3.2 (or any 1B+ model), though, is the 'Model Gravity.' On a true cold start, that cache is totally empty. The 500ms hit Iâ€™m talking about is that brutal first request where the user is usually stuck waiting for the weights to page into RAM from scratch.\n\nPinging them to keep them warm definitely helps, but it gets tricky with concurrency. If you get a sudden burst, Lambda spins up new containers that haven't been 'pinged,' and those users hit the wall again. The goal here was to make the actual initialization logic so lean that even a fresh, un-warmed container feels fast.\n\nAre you seeing the memory overhead stay stable with lru\\_cache? Iâ€™ve run into some weirdness where the model state eventually eats the available RAM after a few recycles.",
              "score": 2,
              "created_utc": "2026-01-05 15:57:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxuk1fj",
                  "author": "gcavalcante8808",
                  "text": "It's a matter of receiving requests continuously so the lambda get reused.\n\nThinking on entire topic, if the s3 to memory is quicker than loading the model and keep it in the key cache, then its more than valid",
                  "score": 0,
                  "created_utc": "2026-01-05 17:15:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxu50eo",
          "author": "kel-kenny",
          "text": "Noice ðŸ‘. A link to the implementation such as a GitHub repo would really help this hit home. Doesn't need to be clean (no judgment).",
          "score": 2,
          "created_utc": "2026-01-05 16:06:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwfm0k",
          "author": "shibapac",
          "text": "Have you consider using agentcore runtime for this? I have done some cost comparison and where your mem usage goes higher than 3GB, AC runtime is almost always cheaper than lambda. At the end of the day, both lambda and AC runtime are just serverless compute offerings with slightly diff requirement.",
          "score": 1,
          "created_utc": "2026-01-05 22:27:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxfdq4",
              "author": "NTCTech",
              "text": "Iâ€™ve definitely seen AC win out once you start hitting those higher memory tiers.\n\nThe reason I stuck with Lambda for this specific PoC is that the 'Surgical Scraper' approach lets me keep the memory footprint tiny, we're actually only using 512MB. Since we're offloading the heavy weight-paging to the Bedrock managed plane, we don't need the 3GB+ overhead usually required to load a model locally.\n\nI am trying to see how much power I can squeeze out of the smallest possible serverless footprint. But for a more complex agentic workflow that needs sustained compute, AC is definitely on my radar. \n\nAppreciate the insight though.",
              "score": 1,
              "created_utc": "2026-01-06 01:33:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxxs3y8",
          "author": "idkbm10",
          "text": "Hey\n\nIm building an app for city tours, will this work for a chatbot or for image recognition? Is it cheaper than bedrock?",
          "score": 1,
          "created_utc": "2026-01-06 02:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxt7pl",
              "author": "NTCTech",
              "text": "This specific project is a bit different than what you're looking for.\n\nJust to clarify. this utility actually uses Amazon Bedrock to run the models. Itâ€™s a specialized 'Surgical Scraper' designed to help DevOps engineers diagnose server errors (like Nutanix or Kubernetes logs) in under 500ms.\n\nFor a city tour chatbot, you would still want to use Bedrock, but you'd likely use a larger model like Claude 3.5 Sonnet or Nova for better conversation flow. This particular project uses Llama 3.2 1B, which is great for fast technical analysis but might be too 'small' for a detailed tour guide bot.\n\nAs for image recognition, you may want to look at Amazon Rekognition or the multi-modal models in Bedrock. \n\nHope that helps point you in the right direction. \n\nGood Luck!",
              "score": 1,
              "created_utc": "2026-01-06 02:48:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7teqs",
          "author": "sniper_cze",
          "text": "What about price? And what about price compared to other ways in AWS and llama onprem?",
          "score": 1,
          "created_utc": "2026-01-07 15:46:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyakfvd",
              "author": "NTCTech",
              "text": "Itâ€™s not â€œcheapâ€ in absolute terms, itâ€™s *cheap enough* for this specific usage pattern.\n\nWith max memory provisioned, the per-ms Lambda cost is obviously higher. But because inference completes much faster and the traffic is low (40â€“60 calls/day), the total monthly spend stayed in the low double-digits. Cold starts mattered more here than squeezing every cent per ms.\n\nCompared to alternatives:  \nâ€¢ SageMaker / always-on EC2: much higher baseline cost for this level of usage  \nâ€¢ Bedrock: simpler and safer, but per-token costs + retries during experimentation added up faster than I wanted  \nâ€¢ On-prem: cheapest at scale, but overkill operationally for something this small\n\nIf usage went up or latency SLAs got stricter, this tradeoff would flip pretty quickly and Iâ€™d move to something more boring. This was mostly about matching the architecture to very low, bursty demand.\n\nCurious if anyone else has found a 'sweet spot' for low-volume LLM apps without paying the 'idling tax'?",
              "score": 1,
              "created_utc": "2026-01-07 23:04:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyklfo3",
          "author": "AcrobaticLime6103",
          "text": "Assumption: average 30-second invocations\n\n10GB Lambda with Snapstart\n($0.0000166667 x 10GB x 30secs) Invocation + ($0.0001397998 x 10GB) Snapstart restore = $0.006398008\nNote: Ignoring Snapstart caching cost\n30secs x 22 tokens/sec = 660 output tokens\n\n384MB Lambda with Snapstart\n($0.0000166667 x 0.375GB x 30secs) Invocation + ($0.0001397998 x 0.375GB) Snapstart restore = $0.0002399253\n\nCost difference to afford Bedrock API = $0.006398008 - $0.0002399253 = $0.0061580827\n\nAssumption: 50% input tokens, 50% output tokens (adjust accordingly to suit your narrative), so $0.00307904135 to afford output tokens\n\nNova 2 Lite = 1,231 output tokens\nLlama 4 Scout = 4,665 output tokens\nQwen3 Coder = 5,131 output tokens\ngpt-oss-20b = 10,263 output tokens\n\nEdit: I did like your wild idea. Thanks for sharing!",
          "score": 1,
          "created_utc": "2026-01-09 10:14:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyp6ve8",
              "author": "NTCTech",
              "text": "I seriously appreciate you breaking out the calculator and doing the hard math on this. That is a fantastic breakdown.\n\nWhen you look at the raw economics of the cost delta between a 10GB Lambda and a tiny orchestration Lambda, that difference buys a *lot* of tokens on those newer managed models.\n\nMy original project was definitely driven by a bit of stubborn engineering curiosity.....I just wanted to see if it was possible to beat the cold start monster while self-hosting. It was more about the hack than the perfect economic model.\n\nBut looking at numbers like yours, itâ€™s hard to justify self-hosting long-term. Honestly, the v2 Iâ€™m working on right now is shifting toward exactly what you described: using Lambda just for lightweight orchestration over Bedrock APIs. The operational simplicity plus those token economics you highlighted are just too good to ignore.  \n  \nI sincerely thank you for the effort on this comment and for enjoying the \"wild idea\"!",
              "score": 1,
              "created_utc": "2026-01-10 00:26:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5dkvz",
      "title": "Why doesnâ€™t AWS need a â€œrouter networkâ€ between two subnets / VPCs?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q5dkvz/why_doesnt_aws_need_a_router_network_between_two/",
      "author": "Last-Pie-607",
      "created_utc": "2026-01-06 08:57:42",
      "score": 76,
      "num_comments": 35,
      "upvote_ratio": 0.92,
      "text": "Iâ€™ve been a bit confused about AWS networking, and Iâ€™m trying to reconcile it with what I learned in college.\n\nBack then, if we had two networks/subnets that needed to talk to each other, weâ€™d always create a router (or a separate network in between). The router would have one IP in each subnet, and both sides would use it as the gateway. That mental model made sense to me.\n\nNow in AWS:\n\n* Two subnets in the same VPC can talk without any visible router\n* Two VPCs can talk using VPC peering, but peering itself isnâ€™t a â€œnetworkâ€ and doesnâ€™t have IPs\n* Thereâ€™s no device with two interfaces that I configure\n\nConceptually I get that AWS is abstracting things, but mentally it still feels weird because *something* must be routing the traffic.\n\nHow do experienced AWS folks think about this?  \nIs the right way to think of it as a distributed, managed router built into the VPC / AWS backbone rather than an actual network or device?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q5dkvz/why_doesnt_aws_need_a_router_network_between_two/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxz7p0v",
          "author": "theonlywaye",
          "text": "Why do you think there isnâ€™t a router? Itâ€™s all virtual networking at the end of the day. The details are just abstracted away from the end user. Each subnet you create you lose IPs because AWS reserves them to assign to stuff like the router and that is in the documentation, have a read over \n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/subnet-sizing.html",
          "score": 116,
          "created_utc": "2026-01-06 09:04:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzbt1x",
              "author": "morimando",
              "text": "This, same way any VPC has a default resolver. The routing table configures what is going where, and for there to be a routing table, there has to be something interpreting and enforcing that same routing table. \n\nItâ€™s just more complicated under the surface because of the fact that you have a vast amount of customer networks and donâ€™t have physical routers for each customer network.",
              "score": 23,
              "created_utc": "2026-01-06 09:44:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny34bjs",
              "author": "Zenin",
              "text": "Yes and no.  VPC is an internal, software-defined network that is *not* IP based and does *not* use traditional IP routing.  Customer's IP packets are encapsulated and there are no IP \"hops\" while in VPC that the user will ever see.  That .1 \"VPC router\" address on subnets?  Yah, you'll never see a route to or from that address, I'm not even sure it's internally used by anything and isn't just legacy at this point.\n\nThis btw is why tools like traceroute don't work in VPC: There's no visible routing hop for traceroute to expose, even when crossing VPC to VPC.  The only hops are at the edges of VPC (Internet, VPN, etc).  \n  \nRelated, this is indirectly why traceroute isn't \"needed\" because a packet can't get blocked partway through VPC routing.  That's because VPC evaluates the path before the packet even leaves the device and nothing that can't route will be sent at all, it dies at the source.  So even if you've got layers of NACLs and Security Groups and going across multiple VPCs etc, if there's a block in any of those policies the packet won't even leave the ENI.",
              "score": 11,
              "created_utc": "2026-01-06 21:53:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3brmx",
                  "author": "brophylicious",
                  "text": "Neat! Love learning how the magic is implemented",
                  "score": 2,
                  "created_utc": "2026-01-06 22:29:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzj2zz",
          "author": "blissadmin",
          "text": "The short answer is: VPC didn't exist for the first few years of AWS, all customers were on one giant private network. AWS built VPC as a packet encapsulation service in order to enable inter-VPC routing of potentially overlapping customer address spaces and quasi-unlimited scaling which was simply not possible with the original networking approach.\n\nThe long answer is in this re:Invent 2013 session where you can hear the entire thought process throughout the building and launching of VPC: https://youtu.be/Zd5hsL-JNY4\n\nIf you can find the 45 minutes to watch this you will know more about VPC than most customers.\n\nSource: ex-AWS",
          "score": 61,
          "created_utc": "2026-01-06 10:50:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny0avmn",
              "author": "llima1987",
              "text": "Any other resources you'd recommend for deeper understanding of AWS? I personally love to learn what's inside the box.",
              "score": 3,
              "created_utc": "2026-01-06 14:02:02",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny18zsj",
                  "author": "ImmortalMurder",
                  "text": "Search through re:invent YouTube channel to see some recorded sessions. I was there a few years back and sat on a session that explained how AWS builds custom networking gear to handle their redundancy and insane throughput requirements. Everything is software defined over there so they do some really cool hardware/software stuff to achieve all this",
                  "score": 7,
                  "created_utc": "2026-01-06 16:48:04",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3ki6g",
                  "author": "blissadmin",
                  "text": "There's an updated/expanded version of the same talk from a couple years later: https://www.youtube.com/watch?v=3qln2u1Vr2E\n\nAlso in the same \"series\", one focused on authenticating requests at scale: https://www.youtube.com/watch?v=tPr1AgGkvc4\n\nReally you could just search YT for anything Eric Brandwine has delivered, his talks are very much targeted at the deepest possible understanding of what AWS does: https://www.youtube.com/results?search_query=eric+brandwine+aws+reinvent",
                  "score": 2,
                  "created_utc": "2026-01-06 23:12:19",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxz856t",
          "author": "au_ru_xx",
          "text": "Whatever the subned CIDR you choose, your x.x.x.1 is a router, x.x.x.2 is a DNS, x.x.x.3 is reserved for whatever AWS will decide to use it for in the future, x.x.x.255 is locked off as it's usually broadcast and AWS does not support broadcasts.",
          "score": 11,
          "created_utc": "2026-01-06 09:09:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz96rx",
          "author": "runitzerotimes",
          "text": "AWS is an abstraction above the networking layer.\n\nEverything you see is fake. Most of the time it looks like what you learnt, because thatâ€™s the cleanest way to map it, and itâ€™s good for users too.\n\nBut itâ€™s all one step up. Essentially everything is hidden from you and AWS exposes certain ways to control it.\n\nItâ€™s like playing those Steam Cloud games. Youâ€™re not actually playing the game on your hardware directly, the game is being played elsewhere then streamed to you. Thereâ€™s a middle layer.\n\nAWS is a middle layer between networking layer and you. AWS is not the networking layer itself.",
          "score": 26,
          "created_utc": "2026-01-06 09:19:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzbzu7",
              "author": "morimando",
              "text": "That captures the essence Iâ€˜d say. You as a user write documents like a routing table and subnet definition etc and AWS is translating that to actual network rules.",
              "score": 9,
              "created_utc": "2026-01-06 09:46:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny5m0ib",
              "author": "IridescentKoala",
              "text": "This is just not true. It's all virtualization and apis.",
              "score": 1,
              "created_utc": "2026-01-07 06:20:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzpyrg",
          "author": "The_Packeteer",
          "text": "I think of it like â€œthank god I donâ€™t have to fuss with router interferences just to configure a subnetâ€\n\nYouâ€™re seeing a good example of cloud abstracting away complexity to reduce friction and simplify \n\nBut under the hood, thereâ€™s virtual and physical routers. U can see this by checking the â€œdefault gatewayâ€ for your ec2 nodes. Thatâ€™s a virtual router interface within the VPC.",
          "score": 6,
          "created_utc": "2026-01-06 11:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz8g92",
          "author": "MavZA",
          "text": "I approached it the same way, with fundamentals in mind, and I did take some time to adjust. But your mental model is essentially correct. Thinking of it as a distributed, managed router built into the AWS backbone is the right way to frame it. The route tables you configure are the equivalent of what you would put on a physical router, they are just applied across the underlying infrastructure rather than on a single device. This is because AWS handles routing at the hypervisor and software defined networking level. Once I got comfortable with that, I stopped worrying about it. It requires less configuration, less maintenance, and very rarely needs to be tweaked. I must say having used other clouds, this abstraction model is much more approachable than they are, especially versus Azure. At least for me.",
          "score": 5,
          "created_utc": "2026-01-06 09:12:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxzzrv0",
          "author": "RecordingForward2690",
          "text": "Coming from a physical networking background and trying to wrap my head around AWS networking, this video helped me a lot:\n\n[https://www.youtube.com/watch?v=Zd5hsL-JNY4](https://www.youtube.com/watch?v=Zd5hsL-JNY4)\n\nMost important takeways:\n\nAWS VPC is IP-over-IP. Not VLANs and such.\n\nBecause the network has its own compute, the network itself has become intelligent. So we can have dumb hosts and we don't need to define/add intelligent devices to the network.\n\n\\*A lot\\* of the traditional networking stuff that used to be solved either in the hosts or by adding devices to a network, are now handled by the Nitro system.",
          "score": 4,
          "created_utc": "2026-01-06 12:57:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxz7xnd",
          "author": "Living_off_coffee",
          "text": "Remember that everything in AWS is software defined networking - there are ultimately physical switches and firewalls and things, but that bears no resemblance to what you see in the AWS console.\n\nYou generally don't need to think too much about it, but yeah, you can think of a VPC as having a router. Each subnet has a route table that you can configure from the VPC dashboard.",
          "score": 6,
          "created_utc": "2026-01-06 09:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0jchf",
          "author": "x86brandon",
          "text": "There is a â€œrouterâ€.  Itâ€™s why there is a route table and route table associations with subnets. \n\nNo AWS networking is not fake.  Itâ€™s a real software defined network thatâ€™s run like a VLAN in a VLAN.",
          "score": 3,
          "created_utc": "2026-01-06 14:47:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny1sr1k",
              "author": "Get-ADUser",
              "text": "VPCs don't use VLANs at all",
              "score": 1,
              "created_utc": "2026-01-06 18:16:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxz7nkk",
          "author": "ElderCantPvm",
          "text": "All the networking objects and concepts are virtualized/abstracted in the first place. You don't need a router because you're not actually routing traffic between physical devices, you're just updating your rules for what is allowed to talk to what on the virtual network.",
          "score": 6,
          "created_utc": "2026-01-06 09:04:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz7zrh",
              "author": "goatanuss",
              "text": "I mean you canâ€¦  Iâ€™ve configured routes in AWS before and subnets and interfaces\n\nIf OP provides an example solution we might be able to give better feedback on why you donâ€™t have to configure it",
              "score": -1,
              "created_utc": "2026-01-06 09:07:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzmiml",
          "author": "Maang_go",
          "text": "Look for reserved IPs in any private range you use in AWS.",
          "score": 1,
          "created_utc": "2026-01-06 11:20:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3rpe2",
          "author": "blaaackbear",
          "text": "rtfm",
          "score": 1,
          "created_utc": "2026-01-06 23:49:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygp4fd",
          "author": "Fantastic_Context645",
          "text": "So, in AWS there are definitely things that are abstracted away, but you still have all the basics that are there. You have VPCs which contain subnets, route tables, transit gateways, etc...\n\nTo answer your questions specifically:  \n\n\n\\- Two subnets in the same VPC can talk without any visible router:  \nIf you go and look at your route tables in your VPC, anytime you see a route that says \"local\" in the \"Target\" field, that basically means \"use the VPCs internal routing mechanisms because it knows what's attached to itself\". If you create a VPC with CIDR range of 10.0.0.0/24, and then create 2 subnets (10.0.0.0/25 and 10.0.0.128/25), each of those has some reserved IP addresses, one of which is the \"router\" for that subnet. So, 10.0.0.0/25 and 10.0.0.128/25 can talk to each other because they are \"local\" to each other. Think of it as a Layer 3 switch that has 2 SVIs with the same subnets. They can both route to each other because they are aware of each other on the same switch. i.e. \"LOCAL\". It's a little more complicated than that under the hood of AWS, but in a nutshell that's how it's working\n\n\\- Two VPCs can talk using VPC peering, but peering itself isn't a \"network\" and doesn't have IPs  \nTrue. There is no \"transit\" network with VPC peering. However, remember those hidden and reserved IPs? Under the hood, conceptually, what is happening is think of it as connecting a Layer 3 switch with a Router. Just because they are connected doesn't mean they can talk to each other. However, go into their routing tables and define the next hop IPs, and they can. In AWS, you're pretty much doing the same thing by having the following: 2 VPCs with 10.0.0.0/24 and 10.0.1.0/24 peered. Now, in a routing table, you'll be able to select the Peering Connection as the \"Target\". So, in VPC1, you'd have a route that would look something like this: 10.0.1.0/24 with Target of \"pcx-GobbeldyGook\", so anything that uses that routing table knows \"use the peering connection\". It's the same thing as defining the next hop, you just don't have implicit access to those IP addresses under the hood.\n\n\\- There's no device with 2 interfaces that I can configure  \nThat's kinda the whole point. When you're automating this (i.e. CLI or CloudFormation), you don't want to end user to have to define and be aware of every single little thing. If they can make it to where I use 1 line or 1 command to configure something, they have a customer. It also helps prevent someone from fat-fingering a route. How many times have you heard someone say \"oh, I typed in the wrong route\". It still happens (i.e. you referenced the wrong peering connection), but the result isn't \"I locked myself out of the device or AWS out of the device\", it's \"traffic stops flowing, let me go make a change to my config, ok now it's back up\".\n\nEveryone I know that came from a networking background, when talking about cloud, either loves it or hates it. Something *IS* routing the traffic, it's the abstracted thing that you don't have to manage. The \"correct\" way to think about networking in the cloud, in my opinion, is that it's someone else managing the complexity of routing protocols, device configuration VLAN/VXLAN configuration. Really you end up moving more into \"AWS does this better/worse than Azure/GCP\", and less about the underlying technology. You really just need to know how AWS implements the stuff and how the configurations ensure the traffic flows as intended/expected.\n\nJust my $0.02",
          "score": 1,
          "created_utc": "2026-01-08 20:16:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz903sp",
          "author": "GlumPlayings",
          "text": "Think of a VPC as already having a managed, distributed router baked in. Every subnetâ€™s route table programs that fabric, not a box you own. ENIs send packets, the VPC control plane handles routing over AWSâ€™s backbone. Peering just stitches two of those fabrics together. No hop IPs because the router isnâ€™t a thing you manage",
          "score": 1,
          "created_utc": "2026-01-12 22:52:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0b0e3",
          "author": "jdptechnc",
          "text": "If you want to really oversimplify things... the VPC service IS the router (along with other functions).  You have control over the routing if you want by creating your own route tables and associating them with subnets.  But the router is there.",
          "score": 0,
          "created_utc": "2026-01-06 14:02:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny20r27",
          "author": "KayeYess",
          "text": "There are routers (AWS prefers to call them gateways) everywhere, even between subnets in the same VPC. As a customer, you don't see some of these \"routers\" but you have access to create/update route tables at the subnet level, and at all other network boundaries (peering, tgw, igw, natgw, gwlb, dxgw, etc). If a solution like CloudWAN is used, even the routes can be abstracted.",
          "score": 0,
          "created_utc": "2026-01-06 18:52:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny36qll",
              "author": "Zenin",
              "text": "There aren't routers in the traditional sense with VPC.  From the user space a packet leaving ENI XYZ headed for ENI ABC simply teleports from XYZ to ABC; there's no \"route\" between them.\n\nCertainly in the internals of the software defined network stack that is the VPC service there's \"routing\", but none of that cares or even knows about your IP configuration.  When your IP packet is leaving XYZ headed for ABC, after evaluating if your policies allow this to happen at all, your IP packet is encapsulated with a VPC wrapper and shuttled through the VPC service by its own methods to ABC where only then is it unpacked and handed to ABC.  To be clear, what happens as that packet travels through the VPC service itself doesn't use or even know about your \"subnets\" or \"routers\" or anything else.  *ALL* VPC knows about once it's in its care is the ENI source/destination IDs (not the IPs on those ENIs; the *ENI ID*).\n\nThis is why tools like traceroute don't work in VPC.  There's no user-visible \"hop\" for traceroute to ping, there's no \"route\" to discover, and if anything like a NACL blocks the connection it's blocked *before the packet even leaves the ENI at all.* \\-Packets only get sent if they *can* be delivered, a determination VPC makes before it even accepts the packet at all.",
              "score": 2,
              "created_utc": "2026-01-06 22:05:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny39243",
                  "author": "KayeYess",
                  "text": "Long story short, thats exactly what I meant by \"not visible to customer\", or trace route, or access analyzer.Â The term \"router\" is used loosely here. It's all SDN.",
                  "score": -1,
                  "created_utc": "2026-01-06 22:16:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q4iqjw",
      "title": "AWS Console is now unusable with Firefox",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q4iqjw/aws_console_is_now_unusable_with_firefox/",
      "author": "ManuelKiessling",
      "created_utc": "2026-01-05 10:57:18",
      "score": 67,
      "num_comments": 47,
      "upvote_ratio": 0.85,
      "text": "Anyone else experiencing this, or am I holding it wrong?\n\nFor several months by now, accessing the AWS Console (i.e., the AWS web-based user interface) via Firefox (latest version, on a M1 MacBook Pro) has become an exercise in futility.\n\nAfter a couple of minutes that a UI like EC2 or S3 etc. is open in a tab, that tab just \"stops\" or \"freezes\", that is, I can no longer interact with the UI elements of the opened AWS Console page, and Firefox shows a warning about how that tab stopped working.\n\nNot even reload works anymore â€”Â I need to close the tab and open the page in a new tab, which will then also reliably run into the same issue in 100% of all cases after a couple of minutes.\n\nBottom line is, I had to switch to Google Chrome for all things AWS Console.\n\nFeels like the bad ol' days of the 90s browser wars to be honest...",
      "is_original_content": false,
      "link_flair_text": "console",
      "permalink": "https://reddit.com/r/aws/comments/1q4iqjw/aws_console_is_now_unusable_with_firefox/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxsrvfy",
          "author": "MartijnKooij",
          "text": "Also Firefox on macOS all latest versions running many tabs with different aws accounts all day every day without issues. Try running in troubleshooting mode to rule out addons and other settings https://support.mozilla.org/en-US/kb/diagnose-firefox-issues-using-troubleshoot-mode",
          "score": 52,
          "created_utc": "2026-01-05 11:09:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxuz7ee",
              "author": "Vakz",
              "text": "How are you using different AWS in different accounts? Something like https://granted.dev with https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/, or are you using another solution?",
              "score": 4,
              "created_utc": "2026-01-05 18:24:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxv5zzc",
                  "author": "MartijnKooij",
                  "text": "Aws introduced multi console session support last year allowing this. Before that I used the Firefox containers add-on. https://docs.aws.amazon.com/awsconsolehelpdocs/latest/gsg/multisession.html",
                  "score": 8,
                  "created_utc": "2026-01-05 18:55:01",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxvtarr",
                  "author": "Scream_Tech7661",
                  "text": "I use the multi-account containers. One container per AWS account. Works well enough for me, mostly. The annoying part is having a session expire when I haven't used that container in awhile.\n\nThe multi-console session support hasn't worked for me. I think because we use SSO roles. Not really sure.",
                  "score": 3,
                  "created_utc": "2026-01-05 20:42:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxvjz3v",
                  "author": "towelrod",
                  "text": "That's what I use on MacOS and Firefox, and I also haven't noticed any particular problems. Nothing like what OP said",
                  "score": 2,
                  "created_utc": "2026-01-05 19:58:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxvfijs",
                  "author": "BinaryRockStar",
                  "text": "I haven't moved over to the properly supported multi-session functionality and still use Firefox with Multi Account Containers then a second plugin called Containerize which lets you map URL regex's to container names. \n\nSet up doesn't take long (I only have about ten accounts though) then each account loads in a separate Firefox container and has it's own colour and icon in the address bar so you can clearly see which account you're in at a glance.\n\nAWS Console now has custom header colours too I think so my setup is getting less and less useful compared to default Console. Maybe I don't need it at all any more?",
                  "score": 1,
                  "created_utc": "2026-01-05 19:38:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxsvw2y",
          "author": "Nahape",
          "text": "Can confirm this too, itâ€™s freezing after a period of time in FF. It only seems to occur on certain pages for me. Certainly the main Console Home, and also sometimes on Cloudwatch dashboard pages.",
          "score": 12,
          "created_utc": "2026-01-05 11:42:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxh768",
              "author": "baever",
              "text": "I mainly see it on cloudwatch dashboard pages as well.",
              "score": 1,
              "created_utc": "2026-01-06 01:43:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxsvuz7",
          "author": "pixeladdie",
          "text": "I use Firefox to access the AWS web console every day for the past few years. No issues here. \n\nOn Windows 11.",
          "score": 24,
          "created_utc": "2026-01-05 11:42:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsqrvf",
          "author": "4sokol",
          "text": "AWS web ui under Firefox 146.0 (64-bit) \\[Fedora Linux\\] works as usual, JFYI",
          "score": 13,
          "created_utc": "2026-01-05 11:00:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsrati",
              "author": "ManuelKiessling",
              "text": "Thanks for the data point. I really wonder what's behind this. And I can't imagine I'm the only one â€”Â I always drive my systems in a very \"vanilla\" way: no fancy setups, no crazy add-ons or extensions, no little snitch or VPN or stuff like this, really just a run-of-the-mill M1 MacBook Pro with a default macOS install, and the mainstream Firefox installation on top.",
              "score": 4,
              "created_utc": "2026-01-05 11:04:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxuwzd2",
                  "author": "kestrel808",
                  "text": "Do you have something like Cisco umbrella on your work network that might be intercepting or fucking with certain kinds of traffic (like dns?)",
                  "score": 1,
                  "created_utc": "2026-01-05 18:14:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxszfxp",
          "author": "BreakingPitt",
          "text": "Same weird behavior with Chrome, but my work laptop is so full of shit installed by my employer so I canâ€™t tell you if is this due to chrome only or due to chrome + some shitty needless security tool installed",
          "score": 4,
          "created_utc": "2026-01-05 12:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxstk5z",
          "author": "AWSSupport",
          "text": "Hello,\n\nSorry to hear about this issue.\n\nWe appreciate your detailed feedback & have shared this internally for review.\n\n\\- Adri N.",
          "score": 7,
          "created_utc": "2026-01-05 11:23:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsvwtl",
              "author": "ManuelKiessling",
              "text": "As suggested by u/MartijnKooij I am now running multiple AWS Console tabs in Firefox Troubleshoot mode, and the first one already ran into the issues:\n\n[https://imgur.com/a/QWVcfYJ](https://imgur.com/a/QWVcfYJ)",
              "score": 10,
              "created_utc": "2026-01-05 11:43:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxt8rf5",
                  "author": "ostern13",
                  "text": "Im experiencing the same issue",
                  "score": 7,
                  "created_utc": "2026-01-05 13:15:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxt0jyl",
          "author": "Humble-Bus-1964",
          "text": "Same issue but only on Edge and Brave.\nEdge has Ublock (but disabled for AWS), Brave the built in Adblocker.\nThere might be some bad side effects from just having it installed from the looks. Chrome without anything, no issues. Firefox no issues.",
          "score": 5,
          "created_utc": "2026-01-05 12:18:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtolaa",
          "author": "baever",
          "text": "I'm seeing it on my 2021 MBP M1 Pro with Firefox 146.01/Tahoe 26.1 and ublock origin with multi account turned on. It's typically happening when returning to a tab after a period of inactivity.",
          "score": 4,
          "created_utc": "2026-01-05 14:45:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxszxm1",
          "author": "Nemergal",
          "text": "Hello,\n\nExactly same problem since 1 month with Firefox.",
          "score": 7,
          "created_utc": "2026-01-05 12:14:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxt8rde",
          "author": "andreal",
          "text": "Yes, I have the same issue with Firefox on Linux Mint, DynamoDB console ALWAYS ends up freezing after a while.",
          "score": 3,
          "created_utc": "2026-01-05 13:15:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtd2eh",
          "author": "anotherNarom",
          "text": "Same issue in Firefox, Chrome and Edge. On MacOs and Windows. \n\nEspecially prevalent in CodePipeline",
          "score": 3,
          "created_utc": "2026-01-05 13:41:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtykup",
          "author": "f50c13t1",
          "text": "I had the same issue, did you accept the storing of \"functional\" cookies? My cookies blocker was too agressive. Their recent version now relies on functional cookies.",
          "score": 3,
          "created_utc": "2026-01-05 15:35:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsvyt2",
          "author": "PashaPostaaja",
          "text": "I have the same problem.",
          "score": 6,
          "created_utc": "2026-01-05 11:43:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxt122r",
          "author": "KeyPerformance2810",
          "text": "Me and a few colleagues have had same issue on MacOS & latest Firefox for the past month or so, M1 Macbook Pro as well.",
          "score": 5,
          "created_utc": "2026-01-05 12:22:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsyr1w",
          "author": "BrownCarter",
          "text": "Mine is not freezing but blank white screen I switched to Chrome and everything works",
          "score": 2,
          "created_utc": "2026-01-05 12:05:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxt99y3",
          "author": "TheOrion666ps",
          "text": "Same issue but on chrome. Macbook m4",
          "score": 2,
          "created_utc": "2026-01-05 13:18:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu1uow",
          "author": "kroakfrog",
          "text": "I started getting a similar issue about a month ago. Duckduckgo seems to work fine.",
          "score": 2,
          "created_utc": "2026-01-05 15:51:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxuhlol",
          "author": "CyrilDevOps",
          "text": "Same problem here,  \nI get a top window 'alert' with   \nThis page is slowing down Firefox. To speed up your browser, stop this page, and a 'stop' button.  \nAnd all the buttons/automation of the aws console are stuck until I click on the 'stop' buton and force a full reload of the page.",
          "score": 2,
          "created_utc": "2026-01-05 17:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxw5k1i",
              "author": "extra_specticles",
              "text": "Yeah I saw this yesterday - I've not used the AWS console for a few weeks, and I'm assuming it's some combo of Firefox and console changes. Before Christmas it was working fine for me.",
              "score": 1,
              "created_utc": "2026-01-05 21:39:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxv3soj",
          "author": "CSYVR",
          "text": "Same issues here, both on Win11 and MacOS. Doesnt happen often but i use granted w/ multi account containers, so perhaps this reduces the occurrences?\n\nFound few related topics here:\n\n[https://connect.mozilla.org/t5/discussions/is-anyone-experiencing-slowness-with-aws-web-console-and-the/td-p/109480](https://connect.mozilla.org/t5/discussions/is-anyone-experiencing-slowness-with-aws-web-console-and-the/td-p/109480)  \n[https://www.reddit.com/r/aws/comments/1pag62b/aws\\_console\\_issue/](https://www.reddit.com/r/aws/comments/1pag62b/aws_console_issue/)",
          "score": 2,
          "created_utc": "2026-01-05 18:45:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxxb85y",
          "author": "tamale",
          "text": "Same issue here for me with Amazon.com as well",
          "score": 2,
          "created_utc": "2026-01-06 01:11:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2wujo",
          "author": "Competitive_Term399",
          "text": "Exactly the same issue. I thought it was my setup!",
          "score": 2,
          "created_utc": "2026-01-06 21:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsxm3p",
          "author": "PaintDrinkingPete",
          "text": "I don't have this issue, access on FF quite regularly... have you tried disabling any extensions you may have installed to see if that fixes it?",
          "score": 1,
          "created_utc": "2026-01-05 11:56:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtcfcz",
          "author": "ProudEggYolk",
          "text": "I have the same (painful) problem with both Firefox and Chrome (zero extensions) on Linux Mint.",
          "score": 1,
          "created_utc": "2026-01-05 13:37:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtdvf0",
          "author": "d70",
          "text": "Works fine for me. I recommend creating a new profile is Firefox to see if your default profile is problematic. You could also download a Nightly build so you have two separate versions to test.",
          "score": 1,
          "created_utc": "2026-01-05 13:45:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu1kgp",
          "author": "FlinchMaster",
          "text": "I noticed the same issue in Chrome this past month. Turning on multi-session support in the console fixed it for me though.",
          "score": 1,
          "created_utc": "2026-01-05 15:49:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxv2vdm",
          "author": "pjastrza",
          "text": "Same in chrome",
          "score": 1,
          "created_utc": "2026-01-05 18:41:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6hkxo",
          "author": "gravityReset",
          "text": "Same issue here with a Mac m1 pro also",
          "score": 1,
          "created_utc": "2026-01-07 11:02:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyc1s8h",
          "author": "ciciban072",
          "text": "I reverted to firefox version 143 for the same reason. The newer versions are way to error/security aggressive and gave me lots of issues accessing AWS.",
          "score": 1,
          "created_utc": "2026-01-08 03:41:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydkqbz",
              "author": "ManuelKiessling",
              "text": "I had to disable Enhanced Tracking Protection on the AWS Site for quite a while now in order to use the Console at all. However, my issue is unrelated I think, das this is about the Console freezing my browser tab.\n\nAlso, I would be extremely wary of using an outdated Firefox version that is not an ESR version, you are putting yourself at enormous risk if you surf anywhere outside of \"safe\" sites like AWS!\n\nProbably better to go back to 140 then, as this is an ESR version that receives regular security fixes.",
              "score": 1,
              "created_utc": "2026-01-08 10:49:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyht83u",
                  "author": "ciciban072",
                  "text": "I'm on Linux, I still have the latest version installed via snaps and 143 under /opt/ I use for AWS (with disabled auto upgrade).",
                  "score": 1,
                  "created_utc": "2026-01-08 23:18:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxu13oq",
          "author": "JerkyChew",
          "text": "Clear your cache.",
          "score": 1,
          "created_utc": "2026-01-05 15:47:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxvd278",
              "author": "ziroux",
              "text": "Just curious, did it fix this issue for you, or are we talking generic troubleshooting?",
              "score": 1,
              "created_utc": "2026-01-05 19:26:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxu4cf5",
          "author": "sur_surly",
          "text": "I work for AWS and use FF internally just for the console, no issues.",
          "score": 0,
          "created_utc": "2026-01-05 16:02:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3b4yu",
      "title": "What services do Amazon engineers use the most on non-AWS product teams?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q3b4yu/what_services_do_amazon_engineers_use_the_most_on/",
      "author": "theyeeha",
      "created_utc": "2026-01-04 00:31:20",
      "score": 47,
      "num_comments": 72,
      "upvote_ratio": 0.86,
      "text": "Primarily interested in full stack application teams\n\nEC2 vs App Runner vs Elastic Beanstalk for backend/compute (with RDS/DynamoDB)\n\nApp Runner vs CloudFront + S3 for frontend",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q3b4yu/what_services_do_amazon_engineers_use_the_most_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxjl7iq",
          "author": "Severe_Marketing651",
          "text": "Most new services use either lambda or fargate for compute with ddb",
          "score": 84,
          "created_utc": "2026-01-04 01:11:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjuisn",
              "author": "Unlucky_Major4434",
              "text": "Basically everything uses APIG + lambda + DDB unless thereâ€™s a verrrry good reason not to lol.",
              "score": 39,
              "created_utc": "2026-01-04 02:02:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxlef56",
                  "author": "SanJJ_1",
                  "text": "Golden path is more commonly ECS instead of lambda, no?",
                  "score": 5,
                  "created_utc": "2026-01-04 08:30:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxny8z2",
              "author": "terrabl",
              "text": "What lambda runtime? Python or node?",
              "score": 1,
              "created_utc": "2026-01-04 18:10:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxk9uq1",
          "author": "chemosh_tz",
          "text": "S3 is probably the most used in any team",
          "score": 31,
          "created_utc": "2026-01-04 03:28:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjrahd",
          "author": "MmmmmmJava",
          "text": "Everything is frequently used with the exception of RDS. Use of relational DBs require senior approval.",
          "score": 36,
          "created_utc": "2026-01-04 01:44:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjw41u",
              "author": "Infamous_Art1174",
              "text": "Interesting. Whyâ€™s this?",
              "score": 11,
              "created_utc": "2026-01-04 02:11:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkctmk",
                  "author": "MmmmmmJava",
                  "text": "Amazonâ€™s preference for DynamoDB over RDS for internal services stems from hard-learned lessons about building systems at massive scale. The core issue is that traditional relational databases with table joins fundamentally donâ€™t scale for low-latency, high-throughput services. At Amazonâ€™s scale, this becomes a critical architectural constraint.\n\nWhen you perform joins across tables in a relational database, the complexity grows with your data size. What works fine for millions of rows becomes problematic at billions. More importantly, joins require the database to do significant computational work at query time, which introduces unpredictable latency. For services handling 1K - 10M requests per second where every millisecond matters, this variability is unacceptable. You canâ€™t maintain tight p99 latency guarantees when your database might suddenly need to scan and correlate large datasets.\n\nDynamoDBâ€™s design philosophy is different: push the complexity to application logic at write time rather than database logic at read time. By denormalizing data and organizing it around access patterns, you get predictable single-digit millisecond reads regardless of your total data size. This trades developer convenience for operational reliability which is exactly what Amazon needs for services like retail, fulfillment, advertising, and AWS itself.\n\nThe licensing situation with Oracle added another dimension to this shift. As Amazon grew, Oracle licensing costs became astronomical and the vendor relationship grew contentious. This created financial pressure and strategic risk around depending on a competitorâ€™s database technology. The move away from Oracle-based RDS toward purpose-built databases like DynamoDB was partly about cost, but more-so about control and architectural fit.\n\nAlso the requirement for senior leadership approval to use RDS isnâ€™t about RDS being bad per se, but itâ€™s about making engineers seriously consider whether they actually need relational features. Most services donâ€™t need joins if theyâ€™re designed with the right data model. The approval process forces teams to justify why they canâ€™t use DynamoDBâ€™s access patterns, ensuring that services are built with scalability and operational excellence in mind from the start rather than hitting scaling walls later.\n\nFor the uninitiated, [hereâ€™s a ~7 year old YT video about DDB](https://youtu.be/HaEPXoXVf2k) which contains a fantastic â€œhistoryâ€ section at the beginning. The whole thing is worth watching.",
                  "score": 100,
                  "created_utc": "2026-01-04 03:45:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxk5nbw",
                  "author": "andersanity",
                  "text": "Scaling concerns mostly. \n\nhttps://aws.amazon.com/solutions/case-studies/amazon-database-migration/",
                  "score": 12,
                  "created_utc": "2026-01-04 03:04:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxk8qcf",
                  "author": "maretard",
                  "text": "Any application developer can generally figure out (or be easily taught) high availability and operations for most AWS technologies. On the other hand relational datastores are so complex they have their own job description (DBA) with specializations per platform. An underprepared team getting thrown into a relational datastore with no senior/principal level DBA expertise is a recipe for disaster, but even worse, you wonâ€™t realize the extent of your fucked-ness until years later when itâ€™s too late to go back easily.",
                  "score": 8,
                  "created_utc": "2026-01-04 03:22:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxmmpwv",
              "author": "Yeunger",
              "text": "Iâ€™ve heard this and I always think about how my intern project back in 2022 used Aurora. It was just made for one scientist, cause he wanted to use SQL (lol). I didnâ€™t know any better and nobody said anything. The database is still up and running to this day (Iâ€™m on that team now as FTE) and still nobody has said anything. I think we are now down to 0 users now that the person has left",
              "score": 2,
              "created_utc": "2026-01-04 14:20:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxjwyp7",
              "author": "kopi-luwak123",
              "text": "Probably the reason why search sucks in a lot of services console.",
              "score": -4,
              "created_utc": "2026-01-04 02:16:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxljivh",
          "author": "mrlikrsh",
          "text": "CloudFormation using CDK, ECS (very rare to no EKS), no Control Tower, EC2 instances via ASG, DDB, Lambda. Never saw someone using beanstalk or app runner.",
          "score": 9,
          "created_utc": "2026-01-04 09:16:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpmw55",
              "author": "Mobile_Plate8081",
              "text": "Didnâ€™t even know they existed lol.",
              "score": 2,
              "created_utc": "2026-01-04 22:46:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxn3sn8",
          "author": "Horror-Tower2571",
          "text": "Lambda for literally anything that works with it, never used EC2 or ECS/EKS unless we absolutely have to",
          "score": 7,
          "created_utc": "2026-01-04 15:50:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxjjn6g",
          "author": "Hopeful-Trainer-5479",
          "text": "Ecs is the most common. Also everything we do is via cloud formation. Other than that, I've seen: ddb, kinesis, redis, lambda, etc",
          "score": 16,
          "created_utc": "2026-01-04 01:02:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxljkcn",
              "author": "Nakrule18",
              "text": "Why not CDK?",
              "score": 2,
              "created_utc": "2026-01-04 09:17:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxlkad3",
                  "author": "Hopeful-Trainer-5479",
                  "text": "everything we do is via cdk. i meant cloud formation to provision the cdk stuff",
                  "score": 6,
                  "created_utc": "2026-01-04 09:23:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxlkm7s",
                  "author": "KarelKat",
                  "text": "Most of the new stuff is CDK. And guess you could argue that CDK is just Clouformation anyways heh",
                  "score": 3,
                  "created_utc": "2026-01-04 09:26:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxjxdyj",
          "author": "Quinnypig",
          "text": "Isengard, to my chagrin.",
          "score": 26,
          "created_utc": "2026-01-04 02:18:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxmtomb",
              "author": "ghillisuit95",
              "text": "Thatâ€™s only for AWS teams isnâ€™t it? Cdo uses conduit.\n\nUnless that changed after I left",
              "score": 7,
              "created_utc": "2026-01-04 14:59:47",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxlczk2",
              "author": "NaCl-more",
              "text": "I love Isengard. Though conduitâ€™s temp accounts are cool",
              "score": 5,
              "created_utc": "2026-01-04 08:17:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxpmpr9",
                  "author": "Mobile_Plate8081",
                  "text": "No one uses them anymore. I thought they deprecated lol",
                  "score": 1,
                  "created_utc": "2026-01-04 22:45:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxm6hcd",
              "author": "baever",
              "text": "Externally, [Identity Center](https://aws.amazon.com/iam/identity-center/) is the closest thing to Isengard. It provides group based access to temporary credentials in roles. If you need just in time access to your roles use [TEAM](https://aws.amazon.com/blogs/security/temporary-elevated-access-management-with-iam-identity-center/). If you want the easier console deeplink functionality and to quickly pivot between accounts and roles use [Speedrun](https://speedrun.cc).",
              "score": 5,
              "created_utc": "2026-01-04 12:36:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxkk7ue",
              "author": "bizzygreenthumb",
              "text": "What is Isengard",
              "score": 4,
              "created_utc": "2026-01-04 04:32:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkpo9a",
                  "author": "tybit",
                  "text": "Itâ€™s an internal tool for managing AWS accounts, and itâ€™s great. \n\nHereâ€™s @Quinnypigâ€™s blog post on it https://www.lastweekinaws.com/blog/the-aws-service-i-hate-the-most/\n\nIâ€™m impressed heâ€™s still holding the grudge all these years later.",
                  "score": 17,
                  "created_utc": "2026-01-04 05:08:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxkl0ge",
                  "author": "zanathan33",
                  "text": "Essentially an identity provider and account provisioning tool.",
                  "score": 4,
                  "created_utc": "2026-01-04 04:37:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxn5uiz",
          "author": "EssenceOfLlama81",
          "text": "We use Kinesis, Apache Flink, SNS, S3, Glue, and RDS for collecting, processing, and storing data.\n\nWe then use CloudFront, API Gateway, Lambda@Edge, Lambda, S3, and DynamoDB for the frontend.\n\nFor data use-cases we use Athena/Glue to fetch high latency backend data, RDS for lower latency backend data, and use Dynamo mostly for storing data just used for frontend support (like user preferences and saved pages). We aslo ocassionally use ddb kind of like a cache for high latency queries.",
          "score": 3,
          "created_utc": "2026-01-04 16:00:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxn8sze",
              "author": "True-Ad-2269",
              "text": "it's great to usse these tools when you dont have to consider about building early in a region",
              "score": 1,
              "created_utc": "2026-01-04 16:14:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxl1lad",
          "author": "sergiu230",
          "text": "I'm surprised nobody mentioned cloudfront yet. Everyone said S3, cloudfront paired with S3 is the GOAT.",
          "score": 5,
          "created_utc": "2026-01-04 06:38:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxpn3lx",
              "author": "Mobile_Plate8081",
              "text": "Yeah but most teams donâ€™t own this infrastructure directly",
              "score": 1,
              "created_utc": "2026-01-04 22:47:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjf9rd",
          "author": "blinkyretard",
          "text": "If App Runner provides the persistent storage (i.e efs), damn it will become the #1 choice for me for a POC environment",
          "score": 1,
          "created_utc": "2026-01-04 00:39:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxne6hy",
              "author": "Advanced_Bag_5995",
              "text": "have you tried ECS Express Mode? you can configure your task definition to use EFS with Express Mode",
              "score": 2,
              "created_utc": "2026-01-04 16:39:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxnfrx7",
                  "author": "blinkyretard",
                  "text": "I was trying to have cost effective solution for POC environment and app runner looked dirt cheap. But unfortunately my app needed persistent volume. So i went with docker on t4g.small ec2. Whereas cheapest fargate had $57/month. No?",
                  "score": 1,
                  "created_utc": "2026-01-04 16:46:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxjf2q4",
          "author": "lobbo80s",
          "text": "CodeDeploy",
          "score": -11,
          "created_utc": "2026-01-04 00:38:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjtigj",
              "author": "goatanuss",
              "text": "Internal Amazon engineers usually donâ€™t use CodeDeploy and prefer internal build tools",
              "score": 11,
              "created_utc": "2026-01-04 01:57:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxlkgli",
                  "author": "KarelKat",
                  "text": "Except that those internal build tools use codedeploy when deploying to lambda and certain other targets. Using cdk and targeting lambda with blue/green or canary deployment? Code deploy under the hood. Sure the internal stuff builds the assets and gets them to the AWS account  but the last stage is codedeploy with Lambda. This is mostly hidden though so you don't really \"use\" it but it is an important part under the hood.",
                  "score": 2,
                  "created_utc": "2026-01-04 09:25:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxkrq0s",
                  "author": "Fluid-Tone-9680",
                  "text": "I have not seen any Amazon engineer who \"prefers\" internal builder tools.",
                  "score": 1,
                  "created_utc": "2026-01-04 05:22:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxlwgqb",
                  "author": "lobbo80s",
                  "text": "They all have to use CodeDeploy so itâ€™s technically most used.",
                  "score": 0,
                  "created_utc": "2026-01-04 11:12:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxjp6ly",
          "author": "mountainlifa",
          "text": "The big irony at Amazon is that service teams use relatively few platform services and mainly use ec2. Meanwhile the AWS marketing folks are shoving AI and lambda onto customers to secure lock-in.",
          "score": -29,
          "created_utc": "2026-01-04 01:33:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxjppf8",
              "author": "No_Divide5125",
              "text": "Mm not true. Lambda is literally recommended internally. What you on about?",
              "score": 23,
              "created_utc": "2026-01-04 01:36:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxjptoy",
              "author": "rhit_engineer",
              "text": "Ideally you want services to have as few independent dependencies as possible if you are trying for maximum reliability, so not really a surprise, especially for new region builds.",
              "score": 3,
              "created_utc": "2026-01-04 01:36:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxjtut8",
              "author": "goatanuss",
              "text": "This may have been true a few years ago but this isnâ€™t the case now",
              "score": 2,
              "created_utc": "2026-01-04 01:58:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxnudqu",
              "author": "_murb",
              "text": "builderhub says otherwise",
              "score": 1,
              "created_utc": "2026-01-04 17:53:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjhcyh",
          "author": "Physics_Prop",
          "text": "EBS is virtually unused, ECS is far more popular with more flexibility.",
          "score": -20,
          "created_utc": "2026-01-04 00:50:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxkhvm8",
              "author": "Ok-Switch9308",
              "text": "You serious? Or you are just SDE 1?",
              "score": 4,
              "created_utc": "2026-01-04 04:16:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxl5qpa",
                  "author": "Physics_Prop",
                  "text": "I mean elastic beanstalk, poor choice of acronym lol.",
                  "score": 4,
                  "created_utc": "2026-01-04 07:12:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxld2lk",
              "author": "NaCl-more",
              "text": "EBS is unused? The fuck?",
              "score": 2,
              "created_utc": "2026-01-04 08:17:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q61eyt",
      "title": "Amazon ECS now supports tmpfs mounts on AWS Fargate and ECS Managed Instances - AWS",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ecs-tmpfs-mounts-aws-fargate-managed-instances/",
      "author": "sleeps_lit",
      "created_utc": "2026-01-07 01:16:07",
      "score": 45,
      "num_comments": 2,
      "upvote_ratio": 0.96,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1q61eyt/amazon_ecs_now_supports_tmpfs_mounts_on_aws/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "ny5479s",
          "author": "risae",
          "text": "Oh wow, this is awesome. I really needed that feature.Â ",
          "score": 1,
          "created_utc": "2026-01-07 04:14:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4smpy",
          "author": "LetterNo941",
          "text": "thank for information",
          "score": 0,
          "created_utc": "2026-01-07 03:06:53",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6gki2",
      "title": "Python 3.12 Lambda functions slower than 3.9",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q6gki2/python_312_lambda_functions_slower_than_39/",
      "author": "henk1122",
      "created_utc": "2026-01-07 14:20:02",
      "score": 43,
      "num_comments": 16,
      "upvote_ratio": 0.9,
      "text": "Due to deprecation, we have to update our python version from 3.9 to 3.14. We run it on ARM.\n\nHowever, after upgrade, we see a 4 times performance drop on execution time. This lambda is fairly simply, just checking a sns message and forwarding this as destination.\n\nhttps://preview.redd.it/mdi5es9vrxbg1.png?width=540&format=png&auto=webp&s=a8ac2d906fbba8669296b3676e1dd6f9d8fecea0\n\nDoes other people also experience this?\n\n\\-- edit  \nI can't edit the post title, but I mean updated to 3.14",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q6gki2/python_312_lambda_functions_slower_than_39/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "ny7g4yi",
          "author": "yusufmayet",
          "text": "AWS Lambda Python 3.12 Blog Post Reference:\n\n\n\nFrom the official AWS blog post - [https://aws.amazon.com/blogs/compute/python-3-12-runtime-now-available-in-aws-lambda](https://aws.amazon.com/blogs/compute/python-3-12-runtime-now-available-in-aws-lambda)\n\n \"At launch, new Lambda runtimes receive less usage than existing, established runtimes. This can \n\nresult in longer cold start times due to reduced cache residency within internal Lambda sub-systems.\n\nCold start times typically improve in the weeks following launch as usage increases.\"\n\n \"As a result, AWS recommends not drawing conclusions from side-by-side performance comparisons \n\nwith other Lambda runtimes until the performance has stabilized.\"\n\n\n\nThis may explain your slowdown with Python 3.14 - it's a brand new runtime with minimal cache \n\nresidency in AWS's internal systems.",
          "score": 70,
          "created_utc": "2026-01-07 14:42:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7gldc",
              "author": "henk1122",
              "text": "Yes, it seems something about that. With 3.13 it's only twice the execution time",
              "score": 10,
              "created_utc": "2026-01-07 14:44:29",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny8mzjr",
              "author": "randomusername0582",
              "text": "But they say 99.9% of lambda invocations are \"warm\"\n\nThis should have effectively no impact on average duration for any \"real\" scale",
              "score": 5,
              "created_utc": "2026-01-07 17:59:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nybeyfe",
                  "author": "minirova",
                  "text": "Yeah, and at least 99.9% of lambda invocations are running on the older versions of python.",
                  "score": 2,
                  "created_utc": "2026-01-08 01:39:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyc50q8",
              "author": "Zenin",
              "text": "That's absolutely ridiculous.  It's not like they have 10,000 different runtime options: Why not simply pin the base runtimes in the cache so they're never cold no matter the popularity?  User-code going cold I totally get, but the *base runtime layers* what the hell?  This seems like a no-brainer?\n\nThis literally means anyone cost and/or performance sensitive needs to be running simulations constantly across all acceptable runtime combinations and dynamically changing their configurations to match the moving target.  What a crock!",
              "score": 8,
              "created_utc": "2026-01-08 03:59:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7vmbm",
          "author": "henk1122",
          "text": "Update:\n\nAfter some more tests:\n\nARM - python 3.14 - execution time increases 4 times  \nARM - python 3.13 - execution time increases 2 times\n\nChanging the function back to x86 and the execution time is the same as python 3.9 on ARM\n\nTLDR;\n\nARM is slower with newer python versions which eliminates the cost advantage of running the lambda on ARM.",
          "score": 34,
          "created_utc": "2026-01-07 15:56:24",
          "is_submitter": true,
          "replies": [
            {
              "id": "ny82dpa",
              "author": "Pavrr",
              "text": "Interesting. i would reach out to aws support and ask them.",
              "score": 9,
              "created_utc": "2026-01-07 16:27:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7chye",
          "author": "edthesmokebeard",
          "text": "Check memory usage.   I found this a while back and it gave some interesting insights: [https://github.com/alexcasalboni/aws-lambda-power-tuning](https://github.com/alexcasalboni/aws-lambda-power-tuning)",
          "score": 9,
          "created_utc": "2026-01-07 14:23:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7cx0g",
              "author": "henk1122",
              "text": "That's very interesting! However, nothing has been changed in the configuration, just the python version.   \nIt might be because it's running on their newer OS: [https://docs.aws.amazon.com/lambda/latest/dg/lambda-python.html#python-sdk-included](https://docs.aws.amazon.com/lambda/latest/dg/lambda-python.html#python-sdk-included)",
              "score": 5,
              "created_utc": "2026-01-07 14:25:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny7e1im",
                  "author": "edthesmokebeard",
                  "text": "Thats kind of what I was thinking - perhaps python3.12 has fatter memory requirements.  In the tests I ran on a lot of our little infrastructure 'utility' lambdas, they almost always ran faster if you gave them more than the minimal memory.   The trick is since its memoryXtime, you might double memory but save 10% time, so its not worth it, etc.  Gotta profile.\n\nIf its NOT that, then that sucks that some python3.12 library isn't optimized for what you need.",
                  "score": 4,
                  "created_utc": "2026-01-07 14:31:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny8gyz4",
          "author": "choseusernamemyself",
          "text": "Can you try updating your dependencies to newer glibc versions with the right Python version? It might be about the nativity from the OS change to AL2023.",
          "score": 2,
          "created_utc": "2026-01-07 17:32:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8k5gw",
              "author": "henk1122",
              "text": "This is a very basic lambda with no dependency",
              "score": 3,
              "created_utc": "2026-01-07 17:47:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nycgta6",
                  "author": "Sea-Us-RTO",
                  "text": "all functions have dependencies. a plain print(\"hello world\") function has a dependency on python's print function, which in turn needs stdout libraries.\n\nsince all lambdas make network calls, check your client library for network config changes that occurred between 3.9 -> 3.13.  might be a new setting you can enable in 3.14, for example, or an extra security setting that you could disable.  maybe a default timeout or retry backoff minimum delay was increased.\n\n\nand definitely try doubling the functions memory.  if the 3.9 function was close to the cap, the updayed libraries in 3.14 might have tipped you over the brink.\n\n\ntry using provisioned concurrency to determine if the increase is coming from init, or from your handler.",
                  "score": 3,
                  "created_utc": "2026-01-08 05:14:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qbvyk7",
      "title": "Another Big Update",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbvyk7/another_big_update/",
      "author": "DrSkyle",
      "created_utc": "2026-01-13 16:30:32",
      "score": 42,
      "num_comments": 4,
      "upvote_ratio": 0.81,
      "text": "Hey ,\n\nA month ago, I posted **CloudSlash**, a tool to identify \"zombie\" infrastructure (unused NAT Gateways, detached EBS, Ghost EKS clusters) and i have been updating here on r/aws ever since. This time the entire core engine was rewritten to prioritize Safety. Here is what is new in V2\n\n**1. The Lazarus Protocol (Undo Button)**\n\nIf you choose to delete a resource (like a Security Group), CloudSlash now snapshots the configuration *\\_before\\_* generating the delete command.\n\nIt creates a \"restore.tf\" file containing the exact **Terraform Import blocks** needed to resurrect that resource in its original state. This removes the \"what if I break prod\" anxiety.\n\n**2. Mock Mode**\n\nA lot of you didn't want to give a random GitHub tool read access to your account just to test it. Fair point.\n\nYou can now run \"cloudslash scan --mock\".\n\nIt simulates a messy AWS environment locally so you can see exactly how the detection logic works and what the TUI looks like without touching your real keys or credentials.\n\n**3. Complete TUI Overhaul**\n\n\\- **Topology View:** Visualize dependencies (e.g., Load Balancer -> Listener -> Target Group).\n\n\\- **Interactive Region Picker:** No more hardcoded regions. It fetches enabled regions dynamically.\n\n\\- **Deep Inspection:** Press \"Enter\" on any resource to see the exact cost velocity and provenance (who created it).\n\n**4. Open Sourced Heuristics**\n\nI removed the \"black box\" nature of the detection. The README now contains a full **Heuristics Catalog** detailing the exact math used to flag a resource (e.g., \"RDS is Idle if CPU < 5% for 7 days AND ConnectionCount == 0\"). You can audit the logic before running it.\n\n**5. Graph Engine**\n\n3x faster graph traversal for large accounts ( > 500 resources ) . I refactored the engine to use flat slices instead of maps and implemented string interning for resource types, reducing RAM usage by \\~40% on large graphs.\n\n**Other Improvements since v1.3:**\n\n\\- **Headless Mode:** \"cloudslash scan --headless\" is now fully stable for CI/CD usage.\n\n\\- **Graph Engine:** 3x faster graph traversal for large accounts (>500 resources).\n\n\\- **Completion Scripts:** Native bash/zsh/fish auto-completion.\n\n\\- Validation: Strict tag-based overrides (\"cloudslash:ignore\") are now respected deeper in the graph.\n\n**andd manyyy moreee**\n\n**License:** Still AGPLv3 (Open Source). No paywalls.\n\n\n\n**Repo:** [https://github.com/DrSkyle/CloudSlash](https://github.com/DrSkyle/CloudSlash)\n\nbtw parsing AWS graphs is complex, so if you hit any weird edge cases or bugs , please let me know , i plan to fix them immediately\n\nStars are always appreciated :)\n\n:)  DrSkyle",
      "is_original_content": false,
      "link_flair_text": "monitoring",
      "permalink": "https://reddit.com/r/aws/comments/1qbvyk7/another_big_update/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzom976",
          "author": "sfboots",
          "text": "I need to do a scan just for unused ebs volumes and Ami unused and older than 3 months. Nothing very complicated but quite tedious \n\nIs this tool easy enough to use on such a small configuration?",
          "score": 1,
          "created_utc": "2026-01-15 06:04:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzpgy71",
              "author": "AlpacaPi3",
              "text": "Sorry to interrupt to the authorâ€™s post but for the specific case it sounds like an overkill to me.\nI can suggest steampipe, an open source tool which you can SQL query your cloud infrastructure.",
              "score": 4,
              "created_utc": "2026-01-15 10:47:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyrd03",
              "author": "AWS_Chaos",
              "text": "I hate what I'm about to type, but its the world we live in right now. Your question sounded perfect for a powershell and AWS CLI solution. So out of curiosity I simply asked ChatGBT:\n\n\"write me a powershell script that uses the AWS CLI to run through 3 aws accounts and find all the unattached EBS volumes\"\n\nIt pretty much nailed it. It even handled the regions properly and I didn't ask that. I then asked :\n\n\"now write another powershell script but this time if looks for AMI that are older than 3 months\"\n\nand yup, it got it. I leave this exercise up to you.",
              "score": 1,
              "created_utc": "2026-01-16 18:21:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe956h",
      "title": "CodeBreach: Infiltrating the AWS Console Supply Chain and Hijacking AWS GitHub Repositories via CodeBuild",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "author": "Kralizek82",
      "created_utc": "2026-01-16 07:02:16",
      "score": 41,
      "num_comments": 3,
      "upvote_ratio": 0.92,
      "text": "https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzx03uh",
          "author": "pint",
          "text": "tl;dr\n\nthe core of this attack is a misconfigured github setup, which accepted pull requests from user ids that *contain* a string, instead of *matching* the string. with some difficulty, they managed to register a new id that passed.\n\nthere are many more steps in this attack, but this was the main vulnerability.",
          "score": 34,
          "created_utc": "2026-01-16 13:28:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxe5d1",
              "author": "menge101",
              "text": "ty",
              "score": 4,
              "created_utc": "2026-01-16 14:41:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4h6h9",
      "title": "GitHub - huseyinbabal/taws: Terminal UI for AWS (taws) - A terminal-based AWS resource viewer and manager",
      "subreddit": "aws",
      "url": "https://github.com/huseyinbabal/taws",
      "author": "huseyinbabal",
      "created_utc": "2026-01-05 09:23:26",
      "score": 40,
      "num_comments": 16,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1q4h6h9/github_huseyinbabaltaws_terminal_ui_for_aws_taws/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nxsq886",
          "author": "DiTochat",
          "text": "Need to get this listed on scoop for Windows",
          "score": 2,
          "created_utc": "2026-01-05 10:55:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsqlqs",
              "author": "huseyinbabal",
              "text": "Will be available soon :pray: [https://github.com/huseyinbabal/taws/issues/19](https://github.com/huseyinbabal/taws/issues/19)",
              "score": 2,
              "created_utc": "2026-01-05 10:58:50",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxt6sua",
              "author": "huseyinbabal",
              "text": "Now it is supported\n\nscoop bucket add huseyinbabal [https://github.com/huseyinbabal/scoop-bucket](https://github.com/huseyinbabal/scoop-bucket)\n\nscoop install taws",
              "score": 2,
              "created_utc": "2026-01-05 13:02:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxsv7wa",
          "author": "WoodpeckerNational29",
          "text": "2 gÃ¼nde 800 star iyiymiÅŸ.",
          "score": 2,
          "created_utc": "2026-01-05 11:37:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxt0zaa",
              "author": "huseyinbabal",
              "text": "12 saatte ðŸ˜",
              "score": 1,
              "created_utc": "2026-01-05 12:21:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxu4ji6",
                  "author": "WoodpeckerNational29",
                  "text": "abi bot degil biliyorum da bu nedir yav, 1000 olmus. benim anlamadÄ±ÄŸÄ±m Ã§ok Ã¶zel bir ÅŸey mi Ã§Ã¶zÃ¼yor? bu kadar insan ne ara bundan haberdar oldu, valla helal olsun",
                  "score": 1,
                  "created_utc": "2026-01-05 16:03:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxu8mlj",
          "author": "synackk",
          "text": "This is freaking cool",
          "score": 1,
          "created_utc": "2026-01-05 16:22:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxu8vw7",
              "author": "huseyinbabal",
              "text": "Thanks â˜ºï¸",
              "score": 1,
              "created_utc": "2026-01-05 16:24:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny1ama2",
          "author": "pivovarit",
          "text": "Just tried it and it looks great :) great job!",
          "score": 1,
          "created_utc": "2026-01-06 16:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6n4ex",
              "author": "huseyinbabal",
              "text": "Thanks :)",
              "score": 1,
              "created_utc": "2026-01-07 11:47:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny3tyv0",
          "author": "foomanjee",
          "text": "This is cool, but danger danger!\n\nYour readme lists control+d as pagedown, but that's the hotkey for deleting resources!\n\nI'd much rather you support proper page up and page down",
          "score": 1,
          "created_utc": "2026-01-07 00:01:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny6n1re",
              "author": "huseyinbabal",
              "text": "Thanks for informing about this. Actually, we don't support page up/down since we already have filter, up and down. It was a confusion in README but fixed now. Btw, 1.1.2 released with new features, you are welcome to test it :) [https://github.com/huseyinbabal/taws](https://github.com/huseyinbabal/taws)",
              "score": 1,
              "created_utc": "2026-01-07 11:46:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6n9j8",
          "author": "huseyinbabal",
          "text": "Cool features like SSO support are released in 1.1.0, if you want to check it out: [https://github.com/huseyinbabal/taws/releases/tag/v1.1.0](https://github.com/huseyinbabal/taws/releases/tag/v1.1.0)",
          "score": 1,
          "created_utc": "2026-01-07 11:48:06",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nxsloay",
          "author": "foamz13",
          "text": "Nice! Gonna try it out, I have guys in my team that donâ€™t like using the web console",
          "score": 0,
          "created_utc": "2026-01-05 10:15:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsm0ce",
              "author": "huseyinbabal",
              "text": "Thanks ðŸ™ New features are coming, Ä± really would like to see the feedbacks",
              "score": 1,
              "created_utc": "2026-01-05 10:18:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q94wcq",
      "title": "PSA: If you're heavily using ECS with EC2, check that your capacity provider hasn't given you ghost instances that aren't actually running tasks",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q94wcq/psa_if_youre_heavily_using_ecs_with_ec2_check/",
      "author": "pribnow",
      "created_utc": "2026-01-10 14:05:40",
      "score": 39,
      "num_comments": 10,
      "upvote_ratio": 0.9,
      "text": "Sharing this here because I posted about [having more EC2 instances than ECS tasks running](https://www.reddit.com/r/aws/comments/1pqlprw/i_always_have_way_more_ec2_instances_than_i_do/)\n\nAWS Support did confirm this is a real issue (and indicated they had already received tickets about this issue from other users) where our configuration should NOT result in a bunch of unused nodes sitting around (this was seriously costing us an extra like $10k to $15k a month as we heavily use ECS)\n\nIf you're using ECS with a capacity provider and EC2 then I highly recommend you go check that your node count and your task count match or are at least close",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q94wcq/psa_if_youre_heavily_using_ecs_with_ec2_check/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nyshaks",
          "author": "Vakz",
          "text": "We too had this issue. Can't say how many hours we spent trying to resolve it, but in the end we just gave up ans moved all workloads to Fargate. While EC2 should be cheaper in theory it ended up being more expensive due to shoddy autoscaling, and in particular when taking into account time spent by engineers trying to find workarounds.",
          "score": 19,
          "created_utc": "2026-01-10 14:30:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nysm1g1",
              "author": "burlyginger",
              "text": "IMO Fargate is cheaper when you look at the whole cost of infra and management because you eventually end up spending 0 time maintaining fargate.",
              "score": 7,
              "created_utc": "2026-01-10 14:56:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nysm5tz",
              "author": "pribnow",
              "text": "It's wild because if you would have asked me this last year I'd have told you it was Fargate that was going to cost us more money but I agree, something seems.....wrong....in their capacity provider impl\n\n\nBut I have to give our account reps and the support team big props for handling this and making it right",
              "score": 4,
              "created_utc": "2026-01-10 14:57:28",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyu0bhx",
              "author": "coinclink",
              "text": "I agree, fargate is great and takes so much of the pain points away. With savings plans added, it also significantly closes the pricing gap between EC2 as well. To me, it's a no brainer for majority of projects.",
              "score": 2,
              "created_utc": "2026-01-10 18:58:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyuf740",
              "author": "hatchetation",
              "text": "Last time I checked, Fargate spot was still a great deal too. Really like that pricing model.",
              "score": 1,
              "created_utc": "2026-01-10 20:11:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nystvkr",
          "author": "Diablo-x-",
          "text": "Try binpack strategy + if you can allow downtime then set the rollout deployments to have 0% min running and 100% max running tasks.\n\nThis will guarantee to not over provision ec2 instances and use them to their full potential before spawning new ones while cutting down costs by a huge amount ( at the price of downtime and less HA).",
          "score": 4,
          "created_utc": "2026-01-10 15:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7dlxs",
              "author": "Trick_Brain7050",
              "text": "Nah the bug is that the ec2 instance becomes stuck, alive but not able have anything provisioned on it. Sometimes even running ghost containers! Been around for years",
              "score": 1,
              "created_utc": "2026-01-12 18:19:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7koin",
                  "author": "AWSSupport",
                  "text": "Hi there, \n\nThank you for this EC2 feedback. I have forwarded this to our internal team for further review. \n\n\\- Gee J.",
                  "score": 1,
                  "created_utc": "2026-01-12 18:51:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz1paef",
          "author": "alex_bilbie",
          "text": "We wasted a lot of time about 18 months ago trying to move from Fargate to EC2. The problem then was that the ECS orchestrator did not factor in VPC trunking into its scheduling algorithm. Support + service team confirmed it was an issue but there was no timeline for resolution so we ditched the plan and stuck with Fargate",
          "score": 1,
          "created_utc": "2026-01-11 21:41:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz36uhr",
          "author": "Advanced_Bag_5995",
          "text": "alternatively if you do have a need for specific instances then ECS Managed Instances is the way to go",
          "score": 1,
          "created_utc": "2026-01-12 02:11:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2mf1g",
      "title": "Scaling 'Mark All as Read' in DynamoDB: Avoiding the 1MB limit without 100k background writes.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q2mf1g/scaling_mark_all_as_read_in_dynamodb_avoiding_the/",
      "author": "guts1866",
      "created_utc": "2026-01-03 05:39:26",
      "score": 39,
      "num_comments": 14,
      "upvote_ratio": 0.88,
      "text": "Building a notification system (Missed calls, alerts, etc.) and I've run into the classic DynamoDB 1MB response limit.\n\nBasically, my users can have thousands of notifications. I need to be able to \"Mark All as Read\" instantly.\n\n Currently, my \"unread\" query is returning way too much data because I can't effectively update every single row in the DB without the cost being insane.\n\nI tried using a timestamp in Redis to filter the results in my backend, but Iâ€™m still paying for the \"Read\" units in Dynamo for items that are technically already read. It feels like I'm fighting the database.\n\nIf youâ€™ve built a notification feed,  how did you handle the \"Mark All\" feature? Did you use a \"watermark\" timestamp, or did you find a clever way to batch update?\n\nAppreciate any tips or war stories!",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q2mf1g/scaling_mark_all_as_read_in_dynamodb_avoiding_the/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxg1rbw",
          "author": "Mishoniko",
          "text": ">I tried using a timestamp in Redis to filter the results in my backend, but Iâ€™m still paying for the \"Read\" units in Dynamo for items that are technically already read. It feels like I'm fighting the database.\n\nYou are because your schema design is faulty. Putting a read marker in the message when you can expect users to generate millions of notifications was never going to scale.\n\nIndex notifications by Sargable value (timestamp, etc.). Put a watermark in the user record. One row update to mark read all. \n\nIf that's not doable then build a SQS/Lambda pipeline to run the marking async and batch queries by the size limit.",
          "score": 70,
          "created_utc": "2026-01-03 14:46:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxhinz6",
              "author": "IntermediateSwimmer",
              "text": "I was a solutions architect for 6 years at AWS OP, u/Mishoniko is exactly correct here",
              "score": 13,
              "created_utc": "2026-01-03 18:56:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxg76xp",
          "author": "Limp-Maximum9662",
          "text": "Add a version field. When all marked as read inc by 1 in one global user config. When reading the notifications, read only latest version",
          "score": 17,
          "created_utc": "2026-01-03 15:15:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxg6q4u",
          "author": "darvink",
          "text": "Move the read/unread marker to the user record rather than having a property of read/unread in the notification record.",
          "score": 12,
          "created_utc": "2026-01-03 15:12:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgjtrd",
              "author": "Robodude",
              "text": "What do you track in the user record? NotificationId and timestamp?",
              "score": 3,
              "created_utc": "2026-01-03 16:16:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxgrsif",
                  "author": "darvink",
                  "text": "Depending on its access pattern, but if it is just a simple read/unread marker, you can maybe add a set of unread notification ids.\n\nEmpty this set to indicate that everything is in read status.\n\nEdit: note that you need to know exactly what your access pattern is. If you do it this way and you have a lot of notifications you might hit the max entry size limit.\n\nWe always make decisions based on trade off, and doing it this way is probably one of the simplest way, if your access pattern allows it.",
                  "score": 1,
                  "created_utc": "2026-01-03 16:54:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxh6kdh",
          "author": "alex_bilbie",
          "text": "Store a lastReadTimestamp property on the user record.\n\nWhen the user marks all as read, update that property, then you can easily determine if notifications added after that time are new.",
          "score": 9,
          "created_utc": "2026-01-03 18:02:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhewwu",
          "author": "bittrance",
          "text": "As others have said. you put the read markers in the user record. However, that is only half the answer, since simply putting a list of ids there will not scale forever. What you want to do is encode the read marks as a list of ranges. For simplicity, if we assume the ids are ints, you will have `[(1,5),(7,15),(17,17)]` meaning messages 1-5,7-15 and 17 have been marked as read. (If we assume that all messages will eventually be marked read, it can be easier to view the list as unread message ranges instead.) In practice, such a list is unlikely to ever grow large. Typically, you cache these ranges in memory and use them to inform queries as needed.\n\nI have not done this in DynamoDB, but I imagine that if you use timebased UUIDv6/7 ids, it should work just fine.",
          "score": 2,
          "created_utc": "2026-01-03 18:40:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxg6v9q",
          "author": "ReturnOfNogginboink",
          "text": "Create a secondary index with just the users ID and the 'hasbeenread' flag. Use the secondary index to query and mark items read.",
          "score": 3,
          "created_utc": "2026-01-03 15:13:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxi3j2w",
          "author": "RecordingForward2690",
          "text": "I've had a somewhat similar problem, where I was doing a multi-user (shared) whiteboard. All draw operations went into one DDB table (with the session ID as the partition key, and the timestamp as the sort key), and users that were attaching to an existing session did a query for all operations within a particular session ID to get the latest whiteboard status. But... What if somebody pressed the \"clear whiteboard\" button? There was no way to do a query for all operations since a particular operation happened, within a single table setup.\n\nSo in the end I implemented a second table with just the timestamp of the last clear operation of a session (partition key session ID, no sort key). So users would first query that second table with their session ID, get the timestamp of the last clear operation, and then query the operations table, but only for operations with that session ID and since that timestamp. Works like a charm. You don't even need a secondary index or something, since the timestamp was used as the sort key anyway, which gives an implicit index.\n\nA background query/scan operation is then used to purge the first table of stale entries every now and then.\n\nYou can do the same, by setting up an additional table where you store the timestamp of the \"Mark all Unread\" operations, with your user ID as the partition key. Your code should query that first, and then use that timestamp to only request data for that user, that is newer than that timestamp. If the timestamp is your sort key, then things are very easy. But if your timestamp is a non-indexed field, it may help to put a local secondary index on it. (It doesn't have to be a global secondary index in this case, as you won't be querying by specific timestamps.)\n\nThis also means that you don't have to update all your notifications when a user clicks on \"Mark all Read\". The only thing you need to think about - maybe - is the situation where a user clicks on \"Mark all Read\" and then wants to flag certain notifications as Unread anyway.",
          "score": 1,
          "created_utc": "2026-01-03 20:36:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxg2hjl",
          "author": "elchicodeallado",
          "text": "https://dev.to/epilot/scaling-notification-systems-how-a-single-timestamp-improved-our-dynamodb-performance-5c84\n\nhad the same issue and found a very smart solution. DM me if you need more help.",
          "score": 1,
          "created_utc": "2026-01-03 14:50:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxh1eod",
          "author": "alienangel2",
          "text": "Are you ok with some duplication and storage costs scaling with number of unreads? if so the approach is pretty simple: \n\n- for each user track message ids (or if the size is comparable, the whole message) that is unread. Depending on size this could be a per-user record, a per-user ddb table or (probably best) an s3 blob. You could use SQS if you were willing to let notificatuons expire within ~4 days\n- each time a new notification comes, update this per-user structure. Make sure it has metadata for a counter so you can efficiently display the notification count without parsing the whole thing \n- if the user hits \"mark all as read\", delete their user-specific record/table/s3 blob or purge their sqs \n\nThe duplication means you can do the delete in one operation without losing the original notifications (otherwise you could considering having a similar per-user structure for \"read notifications\" but at that point you've abandoned you (poorly thought out) original ddb schema for notifications) \n\nPushing it to s3 keeps it scalable. Even if a user legitimately has thousands of unread notifications they can't humanly read all of them at once anyway, so persisting them individually isn't really required. If they want to read a particular past notification (read or unread) that you let them addtess, they can just go directly to your original ddb table and read it by id.",
          "score": 0,
          "created_utc": "2026-01-03 17:39:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxh78sj",
          "author": "DaScoobyShuffle",
          "text": "Each message can have a boolean for read/unread.  Make sure they're fetched by timestamp.  When a user marks it as read, you make the boolean true.  Make sure this record can be indexed by timestamp.\n\nYou also store (immutable) \"master\" records.  These records have a timestamp and a flag for read/unread.  When a user marks everything as read, you create one of these.\n\nWhen reading individual messages later, you also query for the latest \"master\" record.  If the message is older than the master record, then you ignore the read/unread from the message record and use the master's.  Otherwise you use the message's value.\n\nThis way, it doesn't matter how many messages there are.",
          "score": -1,
          "created_utc": "2026-01-03 18:05:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9s4uv",
      "title": "New to AWS (and the cloud), should I learn CloudFormation or Terraform for IaC?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q9s4uv/new_to_aws_and_the_cloud_should_i_learn/",
      "author": "CIA11",
      "created_utc": "2026-01-11 06:28:13",
      "score": 37,
      "num_comments": 103,
      "upvote_ratio": 0.77,
      "text": "I eventually want to learn how to do IaC but not sure which to use. I heard Terraform is a bit better than CloudFormation. ",
      "is_original_content": false,
      "link_flair_text": "CloudFormation/CDK/IaC",
      "permalink": "https://reddit.com/r/aws/comments/1q9s4uv/new_to_aws_and_the_cloud_should_i_learn/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nyxo9e8",
          "author": "Zenin",
          "text": "Terraform.\n\nIt's not just that it's portable, it's simply better in every way and that's something the industry has picked up on which makes it more marketable of a skill.\n\nIf you're in AWS a lot you'll almost certainly need to deal with CloudFormation anyway as some of it isn't avoidable even in otherwise pure-Terraform shops, but it should be considered an unfortunate tool requirement for some tasks rather than a goto.  CloudFormation StackSets for example, at least service managed ones, don't have a native parallel in Terraform so if you're doing a lot of Organization wide work you're almost certainly going to deal with the horrors of CloudFormation to some degree.  This is the space I spend a lot of my own time...but you know what I wrap my StackSets in?  Terraform. ;)",
          "score": 98,
          "created_utc": "2026-01-11 07:18:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxs3yi",
              "author": "aqyno",
              "text": "Whenever someone says terraform is â€œportableâ€ you immediately know they have never written anything \"portable\"",
              "score": 67,
              "created_utc": "2026-01-11 07:52:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyzlo46",
                  "author": "yesman_85",
                  "text": "It's as portable as just switching your db from mssql to postgres, sounds good on paper, but not just flip a switch.\n\n\nBut it's more portable than CF, you can have both resources together in the same repo, you can fairly simple replace modules as you go etc.Â ",
                  "score": 14,
                  "created_utc": "2026-01-11 15:53:39",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyxu9mb",
                  "author": "courage_the_dog",
                  "text": "Everybody knows you just change the provider and voila you port it!",
                  "score": 34,
                  "created_utc": "2026-01-11 08:12:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyzamsh",
                  "author": "Liloxtc",
                  "text": "The knowledge is portable though which is useful,",
                  "score": 9,
                  "created_utc": "2026-01-11 14:58:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyxz04h",
                  "author": "Zenin",
                  "text": "Yep, it's much more that the provider interface is portable allowing IaC across other services including SaaS providers like Github, Okta, etc.  It can be very, very handy to put all the components of a stack together even as they cross vendors.  For example, Cognito integration with Okta, VPN setups between Azure and AWS, etc.",
                  "score": 12,
                  "created_utc": "2026-01-11 08:55:56",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyzuevr",
                  "author": "oneplane",
                  "text": "It's not portable in the sense that programming languages can compile for multiple targets, it's portable in the sense that abstractions and compositions you reason about are portable. You still won't be making a magic module that creates the 'correct' resources depending on what cloud you aim for, even if you could, that would be a bad idea (similar to 'moving a datacenter to the cloud' being a bad idea in general, since clouds when used as a virtual datacenter are a great way to burn all your money).\n\nIf you stack something like Cloudflare, GitHub, AWS and Kubernetes, they will all have platform-specific things that you might not want to IaC, but for the things where you do, Terraform is one of the very few things that can do them all. You'd still also use Wrangler (CF) and code (i.e in a Lambda), Git (because you are't going to make commits using IaC) and something like Argo and Helm (because besides initialisation and data sharing, terraform really has no business in Kubernetes).",
                  "score": 3,
                  "created_utc": "2026-01-11 16:35:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz2vhmp",
                  "author": "JerkyChew",
                  "text": "The CEO of Atlassian came to my work circa 2019 to tell us all about how Terraform was a \"code once run anywhere\" solution. Multicloud, data center, on prem, didn't matter!!! I had just been hired a couple days earlier and told my new manager that the guy was full of shit. It didn't go well.\n\nThat being said, TF is still the best out there. If IBM wrecks it, hopefully something like OpenTofu can pick up where it left off.",
                  "score": 2,
                  "created_utc": "2026-01-12 01:11:18",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz4kn35",
                  "author": "craigthackerx",
                  "text": "The idea of the syntax being familiar is portable though, but the same is true with real programming languages rather than DSL. \n\nI don't write AWS terraform, I'm mostly Azure these days, but compared to someone who doesn't use terraform at all, and without blowing my own horn too much - \"I'm better drunk than they are sober\". \n\nI understand the ecosystem, dynamic blocks, the type system and how I can go from A to B, the resources are the easy part.  I do appreciate however, since I don't use AWS much anymore, understanding the complexities of what resources I need vs what I'd need in Azure is the real gap. \n\nMy own recommendation is basically just that, have good enough portable knowledge between the 2 clouds.  The DSLs are easy if you're already decent at a programming language like Python/Go/JavaScript, you'll pick any of them up easy enough, you won't pick up the knowledge of what every service does, what considerations and drawbacks each design pattern has.  Learning the native IaC tool for your main platform is obviously always going to be helpful anyway.  Well... Azure ARM templates suck so bad, so maybe skip that and go to Azure  Bicep + Terraform these days for that specific platform...",
                  "score": 1,
                  "created_utc": "2026-01-12 07:46:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyyvue2",
              "author": "Extra-Moose4828",
              "text": "There are comments complaining about the definition of \"portable\". Yes, the Terraform code for AWS resources will be different from code for GCP resources.\n\n\nHOWEVER, what is really nice about Terraform is that you can have BOTH your AWS and GCP resources in the SAME repo and codebase, and be able to reference them/link them together! You really cannot do that with CDK, at least not without some hacks.\n\n\nSo maybe it's not quite \"portable\", but it is \"universal\" and I'd rather learn one tool.",
              "score": 10,
              "created_utc": "2026-01-11 13:33:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzd89ys",
                  "author": "mrbiggbrain",
                  "text": "What is even nicer is that you can decouple the implementation details from the desires. By wrapping things in properly built modules you can focus on what the configuration should do, not how or where it is built. For example you create code not to deploy EC2 instances but simply ask for a deployment point, and that deployment point could be an auto-scaling group, K8s, containers, elastic beanstalk. It could be hosted on AWS, on GCP, on Azure. You don't care, you ask for something and you get something that fills that role with a consistent interface. \n\nYou ask for something to be running code and got something that is running code. The team could redeploy tomorrow on a different platform, or add a dozen new security features and you are none the wiser because you still have the exact same interface. \n\nIs most IaC written this way? No, but being able to abstract away those implementation details is one of the benefits that can enable more portable code. Even if your module ONLY supports a single style of deployment in a single provider, the fact that you have a module can enable you to more easily shift to somewhere else.",
                  "score": 1,
                  "created_utc": "2026-01-13 15:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyz9or1",
              "author": "oriondracowolf",
              "text": "This applies to Azure too, skip Bicep, use Terraform.",
              "score": 1,
              "created_utc": "2026-01-11 14:53:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyy25ow",
          "author": "Physical-Sign-2237",
          "text": "Terraform, CF is garbage.\n\n~10 year user of CloudFormation",
          "score": 31,
          "created_utc": "2026-01-11 09:25:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyhzk1",
              "author": "aromaticfoxsquirrel",
              "text": "I used CF to 6 years and recently switched jobs and have been using TF for a week.\n\nUse TF.",
              "score": 12,
              "created_utc": "2026-01-11 11:50:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzj2egz",
              "author": "aqyno",
              "text": "With nine years of experience deploying over a thousand resources across more than twenty providers using Terraform, CloudFormation, and the CDK, I can state definitively: those who claim one of them is garbage are typically producing garbage code themselves.",
              "score": 1,
              "created_utc": "2026-01-14 12:40:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzj5rk7",
                  "author": "Physical-Sign-2237",
                  "text": "> its jus skill issue bro",
                  "score": 1,
                  "created_utc": "2026-01-14 13:02:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyxteoq",
          "author": "ryancoplen",
          "text": "Iâ€™ll go against the grain and say that if you know you will be 100% targeting AWS, then you should be learning CDK, which will be generating your cloud formation files for you.\n\nIn 2026, there is no reason to study CF, unless you have a legacy code base that you have to work with. All new development of IaC on AWS should be using CDK.\n\nI think terraform has probably lost a big chunk of its use case as LLMs can do such a good job of building out IaC for various clouds, if you need that. If you donâ€™t need the â€œportabilityâ€ (scare quotes because you will never be able to directly reuse TF code for anything that isnâ€™t totally trivial between different clouds), then going with the direct â€œlanguageâ€ suited to your environment is going to be more productive anyways.",
          "score": 63,
          "created_utc": "2026-01-11 08:04:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyyhkky",
              "author": "Rtktts",
              "text": "But you never just target AWS. There are tons of other tools which you can manage with terraform and your company definitely uses them. Be it GitHub, Keycloak, Vault, Grafana, some database vendor etc. Besides being able to directly reference resources between different providers, terraform (or opentofu) also provides a module systems to share common functionality. This means that even if your team is only doing AWS (which they probably donâ€™t), it would be a bad decision to lock yourself out of your companies ecosystem of modules.",
              "score": 11,
              "created_utc": "2026-01-11 11:46:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyynmd8",
                  "author": "magnetik79",
                  "text": "Exactly. I'll add Datadog, PagerDuty, Rollbar, JIRA service management.",
                  "score": 2,
                  "created_utc": "2026-01-11 12:36:21",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5aqqy",
                  "author": "owengo1",
                  "text": "And with EKS when you need to manage IRSA, helm etc, with terraform you can in same IaC create aws resources ( IAM, ASGS etc ), k8s resources, helm resources. Good look with cloudformation.",
                  "score": 1,
                  "created_utc": "2026-01-12 11:46:54",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nz5bfu5",
                  "author": "qwer1627",
                  "text": "I dont know much about terraform, but Iâ€™ve seen my fair share of L2 CDK templates to know that thereâ€™s no way TF will work as yet another abstraction layer over the ever changing organism that is CDK\\AWS, wherein parts of itself actively try to make each other obsolete\\overabstract important features, forcing you to return back to cFns and basic L1 abstractions (if they exist, otherwise you make your own). \n\nExtending the organic metaphor: youâ€™ve got to understand that AWS has cancer all over itself, and it constantly battles it via new forms of cancer, which sometimes develop into new limbs\\joints and suddenly become a core part of the organism, and you must learn them or the new limb may cause you to stab yourself directly into a 1M+ AWS bill\\utter mess of a production environment that may have to be at some point completely torn down while crashing out live, for all your users to experience; also - every product\\service eventually ends up with IaC that is fairly bespoke and case by case when mature - portability is a nice concept for MVP\\medium stage, then you start measuring traffic in TPS and everything starts to become quite cloud-specific.\n\nAnyway. CDK if you want to learn AWS would be my vote, Terraform is probably not even wrong.\n\nOn a holy war note: why would you ever use anything other than AWS, which is both literally and accursedly, Turing complete?\n\nEdit: Iâ€™ve had Opus 4.5 steel-man a position contrary to mine and have been educated on Big Query and also feel the need to concede that EKS is kinda cursed (â€¦ECS tho). Running away before other opinions get here, or someone shows up who is using TF to manage HPC clusters (or something else I am too CDK pilled to have been aware of till now wrt TFs capabilities)",
                  "score": 1,
                  "created_utc": "2026-01-12 11:52:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxzse4",
              "author": "yeaman17",
              "text": "Absolutely this. If you're on AWS, then CDK makes maintenance a breeze, and allows for lots of conditional and complex infrastructure use cases across different environments. I started out using terraform in 2016 and after using CDK never went back",
              "score": 9,
              "created_utc": "2026-01-11 09:03:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz1wsb0",
              "author": "Zenin",
              "text": "CDK is problematic and limited in use case.  There's a number of unfixable issues with it, some of which you won't \"see\" in particular situations (if you're purely a dev, for example), some of which you can't avoid forever.\n\nCDK as it's currently implemented is sugar over CloudFormation.  As a result it brings forward the large set of intractable baggage that CloudFormation has.\n\nAs a syntactic sugar layer over CF it *does* address some of CF's larger warts such as requiring the complexities of Lambda backed custom resources for things so mundane as a random name generator for resource IDs or a lookup of an existing subnet to deploy to by tag filter.  Arguably the #1 killer feature of CDK is that it effectively wraps that whole insanity away in a construct.  But...it's still ultimately a custom lambda and everything that comes with it that must live for the life of your stack despite doing nothing after deployment.  And the real kicker is this model that CF uses is incredibly fragile.  CDK goes to great pains to try and bullet proof the code here, but it can only do so much as the architecture of CloudFormation is intrinsically fragile and when (not if) it fails it can often result in extremely difficult if not completely impossible to fix problems.  Problems that can require tearing the entire stack down, manually finding what it couldn't destroy and cleaning that out, and only after hours of waiting for CF to timeout its failures all while your prod sits dead in the water while you scream at AWS support to kick it over on the back end.\n\nTerraform's data resources make most of CDK/CF web of custom lambda hack resources a non-event.  What can't be handled by data resources is handled by utility providers like \"random\".  But the biggest win here is that you can *always* fix a broken terraform stack / state / etc and you never have to fight with the trainwreck of a service that CloudFormation is to do so.  TF stacks have far less issues in general because the model is far cleaner, but when they do have issues they're far easier and faster to identify and fix because you aren't dealing with the blackbox of CloudFormation that stuck in some operation you can't force quit or force fail.\n\nAnd then there's inter-department needs.  CDK is ok for developers that are deeply familiar with the advanced features of their target programming language, but try collaborating with the Networking, Security, Auditing, Admin teams in larger orgs about resource configurations and you'll quickly find that almost no one else can read your skibidi toilet code much less grok how the resources are actually being configured.  The cop out from developers is always, \"Oh just synthesize to CF\" as if autogenerated CF is much better; it might as well be minified javascript.  TF's plan output is both incredibly clean, it's also very complete, and doesn't require any assumptions or masters in software engineering to grok.\n\nCDK being glorified CloudFormation also means you're stuck with CF's pathetic duct tape solution for dealing with drift.  I know, you'll say drift can't happen if you're \"doing things the right way\", but some of us actually work in reality.\n\nCF is slow.  It's slow when things work correctly, but it's horrifically slow when things to bad.  If you're keeping the default of trying to rollback the entire stack on any failure, you get to not only wait for that entire failure to finish rolling back before you can try to apply the syntax error fix you quickly made, but if you don't really know what went wrong so sorry CF has already started nuking the evidence you need to actually diagnose WTF happened.  Or you can chose to not roll back so you can investigate the failed resources for clues, but it's not like you can sanely fix the code and just roll forward.  Maybe to fix the issue you need to force resources X and Y to be destroyed and rebuilt, but you'd prefer not to rollback the 300 other resources that are fine.  TF that's trivial (just taint the two resources and apply), but in CF you're basically forced to roll the entire thing back and then try again from whole cloth.  What PITA.\n\nAnd then there's the fact that increasingly applications are deploying with a variety of integrations.  Hooking into SaaS observability, hooking into ticketing alert systems, hooking in to 3rd party IdPs like Okta, hooking into CICD to auto-configure GitHub actions, etc.  With CDK you're basically at a dead end: The only option you have is to write your own incredibly hacky, incredibly fragile lambda backed custom resources...including all the insanity of trying to auth all them securely.  \n  \nI've already written a novel and I've only scratched the surface.  There's a reason that you almost never see CDK used for anything more than the most trivial of stack architectures.  Even with a simple \"hey, I'm an api service!\" application stacks it's easy to blow through CF resource count limits on things like API Gateway configurations and force yourself into a bunch of nested CF stacks, massively complicating an already messy system and easily locking yourself into dependency hell between the nested stacks because again, CF has no data resources and imports/exports are a sick joke in practice.\n\nTerraform for infra.  Helm for k8s.  Ansible for OS.  Don't cross the beams.",
              "score": 2,
              "created_utc": "2026-01-11 22:16:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz4fscg",
              "author": "vincentdesmet",
              "text": "i think if youâ€™re new to cloud, this is the best answer.. start with high level patterns and understand how to build value.. then dive deeper and apply what you learned by doing the same in TF (it has the biggest market share.. it will be frustrating but you will have a much better understanding of the end goal)",
              "score": 1,
              "created_utc": "2026-01-12 07:02:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz59r3i",
              "author": "qwer1627",
              "text": "This guy synthesizes stacks ^",
              "score": 1,
              "created_utc": "2026-01-12 11:39:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz00eni",
          "author": "Expensive-Charity-69",
          "text": "Terraform or CDK, we are mainly using CDK and quite happy with it.",
          "score": 5,
          "created_utc": "2026-01-11 17:03:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzswms",
          "author": "gingerfettacheese",
          "text": "I love my template.yml and my template.yml loves me.",
          "score": 5,
          "created_utc": "2026-01-11 16:28:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyz1l8a",
          "author": "tholmes4005",
          "text": "I have not used Terraform in a production environment,  but have used CDK. I would concentrate a code based IaC like Terraform, CDK, or Pulumi but I would at least be able to read a CFN template and how AWS uses them.",
          "score": 3,
          "created_utc": "2026-01-11 14:08:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0l8r3",
          "author": "menge101",
          "text": "For AWS use CDK.\n\nLeaps and bounds better than Cloudformation, and IMO, better than Terraform.",
          "score": 7,
          "created_utc": "2026-01-11 18:39:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1circ",
          "author": "moltar",
          "text": "Learn CDK",
          "score": 3,
          "created_utc": "2026-01-11 20:42:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2b6i4",
          "author": "Itsjugu",
          "text": "If you're making your entire application in AWS, use CDK which uses CloudFormation templates. Rollbacks are very easy and it makes deploying very easy.",
          "score": 3,
          "created_utc": "2026-01-11 23:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy95ev",
          "author": "SonOfSofaman",
          "text": "Consider becoming familiar with both. Create a small project or two with each one just to get a taste of each. They are very different and they have very different strengths and weaknesses. Using them both gives you insight into those differences and helps you develop an intuition about them. Then, review the comments here and decide for yourself which option is right for you. The very fact that you have already decided to use IaC shows you have good instincts. I think you should leverage your instincts and the information shared here, then make an informed choice.\n\nThe people here are very smart with lots of experience, but, they probably don't know your background or specific requirements. Their opinions are well intentioned, and they are providing well informed opinions. You're probably seeing valid arguments for both options because there ARE valid arguments for both options, so choosing from among the options without having your own experience might be little more than a coin flip.",
          "score": 2,
          "created_utc": "2026-01-11 10:30:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2f02h",
          "author": "ghostmastergeneral",
          "text": "Having gone from CFN to CDK to Terraform to Pulumi: just go with Pulumi.",
          "score": 2,
          "created_utc": "2026-01-11 23:48:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxufch",
          "author": "arrogantambassador9",
          "text": "I would suggest to take a look at Pulumi. It does everything that TF does but you can write the code in TypeScript or Python so the other devs on your team can also contribute to the infra code, and have a better understanding of it.",
          "score": 6,
          "created_utc": "2026-01-11 08:13:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz07w7z",
              "author": "idiocracy_ixii",
              "text": "Ius Pulumi over Terraform since it is better at complex control logic (if this, then do that). \n\nIf you don't need that, then a declarative TF approach is probably better.",
              "score": 1,
              "created_utc": "2026-01-11 17:39:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz1h0eb",
                  "author": "return_of_valensky",
                  "text": "You can be declarative with code. Declarative just means it matches the state of the document.",
                  "score": 1,
                  "created_utc": "2026-01-11 21:03:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz3h6ih",
              "author": "magnetik79",
              "text": "It's a shame Terraform hasn't added this as a feature over the years, being able to call out to other languages for data transforms/etc.\n\nRight now I'm using the Terraform external provider for this - which works, but is a tad clunky to work with. Shelling out to Python, accepting input via STDIN (as JSON) and returning JSON back into Terraform for use.",
              "score": 1,
              "created_utc": "2026-01-12 03:07:06",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyz19fs",
              "author": "onan",
              "text": "And I would counter-suggest that OP should explicitly _not_ look at Pulumi. Quite possibly ever, but certainly not as a first foray into the space.\n\nThe ability to write imperative code directly into your config is an anti-feature, breaking the fundamental model of declarative configuration. It is the express train to ending up with config that is buggy, opaque, unmaintainable, and non-deterministic.",
              "score": 0,
              "created_utc": "2026-01-11 14:06:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz1gkp1",
                  "author": "return_of_valensky",
                  "text": "â€‹â€‹ I never understand how this argument keeps coming up to learn an older tool because it can do less and somehow that's a feature.\n\nYou can write YAML with pulumi if you want, not psychotic HCL. Pulumi is fully open source and has many advanced features over TF (e.g. automation API, language native tooling like csv, yaml and json processing, api lookups) while remaining compatible with any TF providers and many pulumi native providers better than TF.\n\nCode is also declarative, BTW. That word just means your interpreter brings it to the desired state of the document.â€‹â€‹",
                  "score": 3,
                  "created_utc": "2026-01-11 21:01:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyzh9n9",
              "author": "x86brandon",
              "text": "It's too bad Terraform is deprecating CDKTF because you could also use those languages with Terraform.\n\n[https://developer.hashicorp.com/terraform/cdktf](https://developer.hashicorp.com/terraform/cdktf)",
              "score": 0,
              "created_utc": "2026-01-11 15:32:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyxiqys",
          "author": "informity",
          "text": "https://aws.amazon.com/cdk/",
          "score": 9,
          "created_utc": "2026-01-11 06:31:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxvdfo",
              "author": "Blue-Command",
              "text": "CDK isnâ€™t really what the OP was asking about. The only real connection is that CDK ultimately compiles down to CloudFormation under the hood.",
              "score": -10,
              "created_utc": "2026-01-11 08:22:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxyt6e",
                  "author": "teroa",
                  "text": "Still OP should take a look on CDK. It will make dealing with IaC so much easier than plain CloudFormation.",
                  "score": 6,
                  "created_utc": "2026-01-11 08:54:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz0dahk",
          "author": "BloodAndTsundere",
          "text": "Putting aside Terraform, as others have said if you are going the Cloudformation route spend your time on CDK (Cloud Development Kit) not Cloudformation itself. CDK has a library in many programming languages (I use Typescript and that seems to be the first class one) that lets you write imperative code which compiles to Cloudformation. The big gain isn't using imperative code however, but that there are many higher-level abstractions that do a lot of the nitty gritty work for you, especially in the realm of IAM permissions.",
          "score": 2,
          "created_utc": "2026-01-11 18:04:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0ua1h",
          "author": "Healthy-Voice-7993",
          "text": "CloudFormation is easier and perfectly fine for 99% of use cases. I have never seen anyone actually port anything from AWS to another platform. So the portability advantage is overrated. Keep it simple and stay with CloudFormation.",
          "score": 2,
          "created_utc": "2026-01-11 19:19:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxv3tr",
          "author": "Blue-Command",
          "text": "Terraform is great to start with, but youâ€™ll eventually want at least a basic handle on CloudFormation too. CF is AWSâ€™s native IaC tool, so it pops up sooner or later. Iâ€™d say start with Terraform, get comfortable, and when you run into a situation where CF makes more sense, just pick it up as you go.",
          "score": 3,
          "created_utc": "2026-01-11 08:20:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyy4xzb",
          "author": "rad15h",
          "text": "If you only care about AWS then I'd recommend learning the CDK. I would never write CloudFormation files by hand any more. You write code in CDK using a real programming language and CDK generates the CloudFormation for you.\n\nCDK supports loads of languages, but if you don't have a strong preference I'd recommend learning it in TypeScript, that seems to be the most used, and it's what CDK is written in.",
          "score": 2,
          "created_utc": "2026-01-11 09:51:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzf17k",
          "author": "Due_Ad_2994",
          "text": "Cloudformation. Terraform is definitely not portable and just adds moving parts and licensing ambiguity.",
          "score": 2,
          "created_utc": "2026-01-11 15:21:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxj7dz",
          "author": "Intelligent-Put4528",
          "text": "I think Terraform is a good choice.  \nTerraform is often considered more flexible and beginner-friendly, especially if you want multi-cloud support. CloudFormation is great if youâ€™re fully committed to AWS.",
          "score": 1,
          "created_utc": "2026-01-11 06:35:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyhxzh",
          "author": "LargeSale8354",
          "text": "I started with CF and fell out of it very quickly.  I can't remember what it was I was trying to do but the company I was with had full AWS support and AWS produced a solution to an issue I was having.\nMost solutions you can work through and learn enough from to use in other situations. This thing had CF calling a Python script to generate a CF template. \nI remember thinking Terraform was so much simpler. And that was in the early days of Terraform. \nI've had to revisit CF recently and was shocked to find there are different flavours of it. It looked like 2 teams had forked each others code base due to irreconcilable differences",
          "score": 1,
          "created_utc": "2026-01-11 11:49:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzxg65",
          "author": "quitedumb00",
          "text": "Terraform, at the enterprise level it is easier to manage IaC in Terraform or CDK than native Cloudformation.\n\nAlso note that at the enterprise level, there can be a whole another job to maintain Terraform for the org as administrator or developer.",
          "score": 1,
          "created_utc": "2026-01-11 16:49:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0jhks",
          "author": "MateTheNate",
          "text": "CloudFormation is fine if you want to hand non-tech people a single file that they can deploy for things like a demo. If you need to do anything complex you can quickly end up with 3000+ line files and lots of lambda custom resources though.      \n\nCDK works well if you need to do some things with the JavaScript/Python language itself like string manipulation/validation, expanding file paths, triggering a build step.      \n\nTerraform is really ergonomic and nice to use and has a huge community. It works across multiple cloud providers and partner services. I find it is the easiest to use for cross-region or cross-account deployment since you can use multiple providers. It has data objects that you can use to look up existing resources within your account too. I find its conditional logic and validation/formatting capabilities a bit lacking, and you have to drop down to writing custom resources though Go or CLI which is not as clean as how CDK/CloudFormation do it with lambdas. Terraform state is also a little bit less consistent than CDK/CloudFormation which seem to roll back cleaner.",
          "score": 1,
          "created_utc": "2026-01-11 18:31:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz1fzbh",
          "author": "return_of_valensky",
          "text": "pulumi. terraform is last gen.\n\njust talked to the guys at polymarket, they're using pulumi + Typescript, so is apple. don't learn old tech. â€‹",
          "score": 1,
          "created_utc": "2026-01-11 20:58:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz3a87h",
          "author": "MateusKingston",
          "text": "Pure CF is chaos, it's either CDK or TF (or any other IaC solution).\n\nI heavily dislike the lock in to AWS with CDK and I think TF is easier for Ops folks so that's my preference but they're all good.",
          "score": 1,
          "created_utc": "2026-01-12 02:29:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4fonx",
          "author": "k-lcc",
          "text": "Why not both? \nI'm using both for different kinds of deployments.",
          "score": 1,
          "created_utc": "2026-01-12 07:01:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz59nu2",
          "author": "qwer1627",
          "text": "CDK - Terraform folks will say otherwise, but it just depends on whether you want to learn â€˜cloud opsâ€™ or painfully and truly learn AWS one broken deployment at a time (its S3 and EC2s all the way down, and then thereâ€™s Lambdas)",
          "score": 1,
          "created_utc": "2026-01-12 11:38:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz93n01",
          "author": "onefivesix156",
          "text": "Cloudformation/SAM.",
          "score": 1,
          "created_utc": "2026-01-12 23:10:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzebkpk",
          "author": "UnluckyTiger5675",
          "text": "Both. Know what both are good at and bad at.",
          "score": 1,
          "created_utc": "2026-01-13 18:43:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxkpwt",
          "author": "mrlikrsh",
          "text": "I'd suggest getting a grasp of both. They make the same API calls using AWS SDK to create resources, terraform state management is different compared to CloudFormation (where you don't need to manage state). \n\nBut if you are new to the cloud, start with console. Create, update and delete things directly see what API calls are made in CloudTrail, try doing this with CLI (which makes the same API calls using boto3) then take a dip into CloudFormation (maybe CDK too), then terraform. So you'll get an idea of how things work in AWS. And you'll also feel terraform is faster. \n\nGood luck navigating the docs and breaking things!",
          "score": 1,
          "created_utc": "2026-01-11 06:47:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxvogr",
          "author": "StoleYaBiscuit",
          "text": "So, I have worked with both Cloudformation and Terraform and I can say both are great to work with once you get the base concepts of how to construct the scripts.\n\nLike everybody else here stated, Terraform is better if you find yourself building resources across different clouds, as you save yourself the time to manage the initial configuration, but if you are sure you are staying in the AWS ecosystem you might find it useful that in Cloudformation you may use special functions(like cfn-signal for example, to improve the way your resources are built, that does not exist in Terraform, at least that was the case several years ago, others might correct me if Iâ€™m wrong)\n\nAnd just as a personal rant, I would say the only thing I absolutely hate about Terraform is the way the terraform apply command works in a specific situation - if there are multiple resources in your script that you are creating/updating and the operation fails you are left with partially created/updated infrastructure up to the point the failure happened. \n\nI understand why they did it this way, so you are not wasting time on long lasting resource recreation, but in my opinion this is a bad design(I cannot stop drawing parallels with imagining SQL transaction doing thisâ€¦ just catastrophic) The problem with this for me is not on the development environment, where you can play around with resource config and usually resource downtime is not vital, but sometimes it happens on staging or prod(as http errors of TF calling the API still happen, very rarely a bad config would pass the dev env to cause this situation on higher env) but when it does it is undesirable, as you either want to be left with either the initial working version or the final when all the resource changes are applied, not something in between. And here comes the praise for Cloudformation - it always brings back the latest version if an error occurs during script application.\n\nApart from that, I have absolutely no other complaint from Terraform, itâ€™s a great tool. And please donâ€™t put too much weight on that in your final decision, as this happens extremely rarely and as I said itâ€™s more of a personal rant than anything else.",
          "score": 1,
          "created_utc": "2026-01-11 08:25:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyygmdc",
          "author": "dr_barnowl",
          "text": "Here are my comments on the matter.\n\nhttps://www.reddit.com/r/aws/comments/puqf4t/terraform_vs_cdk_vs_cloudformation_vs/he7hdgp/",
          "score": 1,
          "created_utc": "2026-01-11 11:38:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyyqmgs",
          "author": "gr33n8ananas",
          "text": "Terraform is a more transferable skillset, works across clouds, and generally has a better UX. If youâ€™re 100% invested in AWS, CDK would be the best AWS-native option.",
          "score": 1,
          "created_utc": "2026-01-11 12:58:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyzjawa",
          "author": "Imaginary_Belt4976",
          "text": "Terraform. Have tried cf, cdk and tf and will never do anything but tf now.",
          "score": 1,
          "created_utc": "2026-01-11 15:42:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz0skvc",
          "author": "omerhaim",
          "text": "TF.",
          "score": 1,
          "created_utc": "2026-01-11 19:11:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz2cg27",
          "author": "Paradox5353",
          "text": "I'll throw my .02 in here...was recently made redundant and started looking for a new position around a week ago. I've spent 8 years working with AWS infrastructure, mostly CloudFormation and CDK, and a small amount of Terraform. Based on what I've seen so far, If I had to go back I'd prioritise Terraform, and get some Azure experience under my belt.",
          "score": 1,
          "created_utc": "2026-01-11 23:35:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxisd1",
          "author": "noelmathewdl",
          "text": "I'd suggest going terraform route. It's portable when compared to cloudformation since you can manage other clouds as well with it.  \n~~Terraform gets converted to CloudFormation afaik when you apply the changes.~~\n\nEdit: Turns out i was wrong about terraform getting converted to cloudformation. It makes use of apis calls instead.",
          "score": -4,
          "created_utc": "2026-01-11 06:31:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxjk3o",
              "author": "zenmaster24",
              "text": "Terraform does not get converted to cloudformation - it talks to the resources api directly, it has no need for cloudformation",
              "score": 17,
              "created_utc": "2026-01-11 06:37:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxk4r3",
                  "author": "noelmathewdl",
                  "text": "oops.   \nGotta read up then.   \nI was in the assumption it does.",
                  "score": 2,
                  "created_utc": "2026-01-11 06:42:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxjo90",
              "author": "wtcext",
              "text": "> Terraform gets converted to CloudFormation afaik when you apply the changes.\n\nNo, terraform directly calls AWS APIs and have the state at the storage of choice. CloudFormation is not involved.",
              "score": 5,
              "created_utc": "2026-01-11 06:38:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxkg9h",
                  "author": "noelmathewdl",
                  "text": "oops.   \nDidn't know this.   \nI thought it did.",
                  "score": 1,
                  "created_utc": "2026-01-11 06:45:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxju2q",
              "author": "lost12487",
              "text": "Terraform specifically does not get converted into CloudFormation when you apply. It uses the AWS API, similar to what the AWS CLI uses. IMO this is an advantage, rather than a disadvantage.",
              "score": 3,
              "created_utc": "2026-01-11 06:40:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxm8ex",
                  "author": "noelmathewdl",
                  "text": "Yes.   \nMy bad.   \nWrong mental model. It doesn't used Cloudformation at all.",
                  "score": 1,
                  "created_utc": "2026-01-11 07:00:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyxjpg7",
              "author": "sorawee",
              "text": ">Terraform gets converted to CloudFormation afaik when you apply the changes\n\nNo? Terraform makes direct API calls IIUC. It doesn't involve CFN.",
              "score": 2,
              "created_utc": "2026-01-11 06:39:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyxlxxz",
                  "author": "noelmathewdl",
                  "text": "Yup.   \nThats right.  \nIt doesn't involve CFN.",
                  "score": 1,
                  "created_utc": "2026-01-11 06:58:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyylog6",
          "author": "AleksHop",
          "text": "terraform, dont lockin in tech that is not used anywhere",
          "score": 0,
          "created_utc": "2026-01-11 12:20:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxko4i",
          "author": "Euphoric_Barracuda_7",
          "text": "I learned both. Terraform knowledge is transferrable if you're working with multi cloud setups. If it's solely AWS you're better off with cloudformation, but of course you can still use Terraform. I started with Cloudformation because back in the day there was no Terraform.",
          "score": -1,
          "created_utc": "2026-01-11 06:47:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxrv8o",
          "author": "aqyno",
          "text": "Learn both.",
          "score": 0,
          "created_utc": "2026-01-11 07:50:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxo47a",
          "author": "devandreacarratta",
          "text": "In my experience, Terraform is the best way to learn IaC.\n\nNow you are working on AWS and you can learn CloudFormation, but if you change cloud provider with TF you donâ€™t learn a new language.\n\nAnother solution could be Pulumi, but I donâ€™t have a lot of experience so you can evaluate before study",
          "score": -1,
          "created_utc": "2026-01-11 07:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyxqyf9",
          "author": "codegefluester",
          "text": "I swear on SST (https://sst.dev) over Terraform. It is high-level enough to make it easy to understand but also allows you to drop lower-level if you need more freedom. Provides an excellent DevX in my opinion.\n\nIt uses Pulumi under the hood IIRC, which you can of course also use directly if you want.",
          "score": -1,
          "created_utc": "2026-01-11 07:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz14kbv",
          "author": "SharkFilmsNepal",
          "text": "First learn AWS native Cloudformation then learn terraform. Both are needed .",
          "score": 0,
          "created_utc": "2026-01-11 20:05:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q05hib",
      "title": "Why do I need 5 different services just to run a function on HTTP trigger?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q05hib/why_do_i_need_5_different_services_just_to_run_a/",
      "author": "Sadhvik1998",
      "created_utc": "2025-12-31 05:56:29",
      "score": 37,
      "num_comments": 48,
      "upvote_ratio": 0.71,
      "text": "Genuine questionâ€”am I missing something, or is this just how the cloud works?\n\nWhat I'm trying to do:\n\n\\- Simple thing - HTTP request comes in, runs some code async and pushes a message to broker.\n\nWhat am I using to do this (AWS example):\n\n1. API Gateway for the HTTP endpoint\n2. Lambda for running code\n3. EventBridge for routing the event\n4. SQS for queue and retries\n5. CloudWatch for logs\n6. I am to connect everything\n\nSame story on Azure/GCP, just different service names.\n\nTwo problems I'm facing:\n\n1. Cost is crazy: Each service bills separately. One request = 5 billing charges (API Gateway + Lambda + EventBridge + SQS + CloudWatch). When traffic grows, I'm paying more for connecting services than actual compute.\n2. Too many moving parts: 6 different dashboards to check. Retries are configured in 3 places. Debugging needs checking multiple services. Each service has its own limits.\n\n\n\nFor one simple \"run code on HTTP request,\" I'm managing half a dozen services.\n\nMy question:\n\nIs this normal? Do you just accept this complexity? Or is there a simpler way that I'm missing?\n\nI see people either deal with it or go back to old-style EC2 apps. Is there any middle path?\n\nWhat do you guys do?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q05hib/why_do_i_need_5_different_services_just_to_run_a/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwvduf9",
          "author": "The-Wizard-of-AWS",
          "text": "Sounds like youâ€™re making things way too complicated. API Gateway -> Lambda is all you need if you just need to trigger a function. If you need something long running or need to have it handle scale with SQS then itâ€™s API Gateway-> SQS -> Lambda. If this wasnâ€™t in the cloud it wouldnâ€™t be much different if you wanted the same scale and resiliency. Youâ€™d have something like Load Balancer-> compute -> queue/stream (e.g., RabbitMQ, Kafka) -> compute. In the cloud you donâ€™t have to manage most of those things.",
          "score": 108,
          "created_utc": "2025-12-31 06:07:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwxeimj",
              "author": "aboothe726",
              "text": "You can also use a lambda function URL (without API gateway) if you just need to be able to access/trigger the function publicly and donâ€™t care about the URL.",
              "score": 20,
              "created_utc": "2025-12-31 15:31:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxeymp",
                  "author": "SodaAnt",
                  "text": "Lambda function URLs support IAM auth.",
                  "score": 12,
                  "created_utc": "2025-12-31 15:34:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww7sxs",
              "author": "Crossroads86",
              "text": "IAM and Cloudwatch is still needed.",
              "score": 6,
              "created_utc": "2025-12-31 10:41:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx01kpi",
                  "author": "The-Wizard-of-AWS",
                  "text": "Technically CloudWatch is optional. If you donâ€™t grant permissions and donâ€™t create a log group it will still work. And, like the other things, this isnâ€™t really different than if you run on prem. You log it somewhere and have to have a way to view the logs. \n\nYouâ€™re right about IAM, which is needed for everything.  Itâ€™s the one difference from on prem for most things (unless youâ€™ve done zero trust). That said, it often is in place of networking requirements youâ€™d have. You may need to have firewall rules in the cloud, but in its simplest form you donâ€™t have to think about networking at all. Itâ€™s been a while since Iâ€™ve even used a security group.",
                  "score": 2,
                  "created_utc": "2025-12-31 23:56:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nww93bx",
              "author": "BredFromAbove",
              "text": "Always have a sqs in between, no? Best for retries in case of error / timeout?",
              "score": 0,
              "created_utc": "2025-12-31 10:53:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwx6cm8",
                  "author": "landon912",
                  "text": "For event handlers? Yes. For an API? No. \n\nThe caller is responsible for handling the queueing / retries of required.",
                  "score": 19,
                  "created_utc": "2025-12-31 14:48:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwx5ynp",
                  "author": "Veuxdo",
                  "text": "No? Without a very specific reason, adding another thing between APIG and Lambda would create more problems than it solves.",
                  "score": 5,
                  "created_utc": "2025-12-31 14:46:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nww99td",
                  "author": "tr666tr",
                  "text": "Depends if you need a synchronous response from the Lambda",
                  "score": 1,
                  "created_utc": "2025-12-31 10:55:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwzbvgs",
                  "author": "chalbersma",
                  "text": "Depends on the use case. If failure is acceptable then no.Â ",
                  "score": 1,
                  "created_utc": "2025-12-31 21:26:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwvfpll",
          "author": "MmmmmmJava",
          "text": "I understand where youâ€™re coming from but Iâ€™ll nitpick your example. Technically you donâ€™t need SQS, Event Bridge, or event CW logs (but youâ€™ll want logs) or possibly event API GW for a minimal serverless HTTP endpoint (if you use lambda function URLs). \n\nThe event bridge, API GW, and SQS layers are managed services acting as functional add-ons based on your specific use case. Each of these services are powerful building blocks that you can pick and choose to use. \n\nAlso, what type of routing are you doing with event bridge? Can that Event Bridge routing component be eliminated by adding a little extra code/routing logic in your Lambda?",
          "score": 24,
          "created_utc": "2025-12-31 06:22:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvgkkk",
          "author": "lulu1993cooly",
          "text": "Aws is really meant to be an ecosystem of interconnected services, not a one-click solution. \n\nYou seem to want SaaS not PaaS mate",
          "score": 50,
          "created_utc": "2025-12-31 06:29:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy9lfo",
              "author": "Mysterious_Rub_224",
              "text": "This.",
              "score": 0,
              "created_utc": "2025-12-31 18:05:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvenmo",
          "author": "Beginning-Swim-1249",
          "text": "You could just invoke the lambda directly if itâ€™s not business critical or production. However, if you want the extra stuffâ€¦ well you need the extra stuff. Youâ€™re not going to get a gateway without a gateway, logs with logs etc. \n\nThere probably is a cloud formation stack that has all this ready for you so thereâ€™s not really much in the way of manual configuration you need to repeat. Or you could use some IaC that has a template for it.\n\nAlso as you scale up in complexity you wonâ€™t necessarily need to have another of everything, youâ€™ll probably share some of the service, especially the more expensive ones.\n\nIâ€™m pretty sure AWS allows you to make custom dashboards as well so you can aggregate all your metrics in one â€œplaceâ€. Itâ€™s been a while since Iâ€™ve used it",
          "score": 13,
          "created_utc": "2025-12-31 06:14:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvdypx",
          "author": "dunkah",
          "text": "Your simple thing has all of those components. Either do them yourself or use a managed service. Sometimes it is for sure cheaper and simpler.",
          "score": 10,
          "created_utc": "2025-12-31 06:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvdxc6",
          "author": "magnetik79",
          "text": "Steps 1& 2 can be combined, using Lambda functions URLs.",
          "score": 14,
          "created_utc": "2025-12-31 06:08:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvkbl2",
              "author": "itdoesntmatteranyway",
              "text": "As long as youâ€™re okay without the allow/denylist and throttling API gateway provides.",
              "score": 15,
              "created_utc": "2025-12-31 07:01:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwvt159",
              "author": "behusbwj",
              "text": "Function urlâ€™s are an anti-pattern",
              "score": -9,
              "created_utc": "2025-12-31 08:21:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwveyuv",
          "author": "kobumaister",
          "text": "You don't NEED all that, you need it if you want to implement it using aws services. You could use knative with a rabbitmq and a kafka server, for example.\n\nA lot of context is missing in your post. Why do you want to implement using solely aws services? It's a requirement? Why not use a simple python service in an ec2 instance with celery?\n\nIf you have the expertise, building that is quite straightforward and generalizing it to build future services too.\n\nAbout the billing part, those services are quite cheap, if you can't monetize your service to cover that cost, you need to review what you're offering (or your infra).\n\nAnd about the monitoring, you don't need monitoring dashboards for each step, you monitor the part that you can act on, in this case, the lambda. Other services are monitored by aws. Maybe you'll build a dashboard with business metrics about how many requests are going through, but you don't monitor the uptime of event bridge. The approach that worked better for me is an up-bottom monitoring.",
          "score": 4,
          "created_utc": "2025-12-31 06:16:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwznns",
              "author": "marx2k",
              "text": ">Why not use a simple python service in an ec2 instance with celery?\n\nTell me more about celery",
              "score": 0,
              "created_utc": "2025-12-31 14:10:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwxd0l4",
                  "author": "kobumaister",
                  "text": "https://letmegooglethat.com/?q=Celery+python+",
                  "score": 1,
                  "created_utc": "2025-12-31 15:24:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwwezyb",
          "author": "pint",
          "text": "i don't understand eventbridge in your architecture, but for the other elements: those are not what you have to use, but what you want to use, right? you yourself added rationale for them. you can easily skip sqs, but then you risk losing messages. you don't need logs, but you want for auditing/debugging. it is not aws that is complex, but your requirements.\n\nthis is pretty typical. i often end up having 10-15 objects in my cloudformation templates even for the simplest applications.\n\nabout costs: if you look at your bill, or do any calculations, you often see a very lopsided picture. one or two services will dominate, while most of them will be single digit percents. however it is, this is the price. take it or leave it.",
          "score": 2,
          "created_utc": "2025-12-31 11:46:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwx8wa7",
              "author": "germoo0",
              "text": "usually the main compute and the main storage. f.e. EC2 and RDS",
              "score": 1,
              "created_utc": "2025-12-31 15:02:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwwhaw4",
          "author": "RecordingForward2690",
          "text": "One more thing to add - you don't need six CW Dashboards. Just grab all the metrics from all the components you need, and add them to a custom dashboard. Everything in one view.\n\nOther than that - you forgot three essential services in your list. Make sure you throw in a WAF at your public endpoint (CloudFront, API GW or ALB) for DDoS/XSS and other protections. And you'll want to use ACM and Route53 to get a proper X.509 cert so you can do https:// instead of http://.\n\nAWS is all about building blocks, that each do one thing and do one thing well, and can be combined in a lot of different ways. And that's a good thing, IMHO. Consider the opposite. Suppose that AWS would have a ready-to-go solution that would allow you to make an https:// API call (using a custom domain name), that would invoke code. Now you're managing code in that solution. Then there would be another complete solution that would accept events from some sort of queue and run code in response, with retries upon failure. Now you need to manage code in that solution as well, with slightly different configuration parameters and capabilities. Before you know it, AWS would have to manage 100s of environments where users can run code. Better to have one all-singing-all-dancing solution for running code that can be integrated everywhere: Lambda.\n\n(In reality, AWS already has half a dozen solutions to run code in a serverless fashion. It's not just Lambda, but also Lambda@Edge, CloudFront Functions, SSM Documents and a few others. When for instance a new Python runtime is launched, we always find that support for that runtime in these solutions is added on a different schedule. So we could go to Python 3.13 in Lambda, but not yet in our SSM documents. Grrr.)",
          "score": 2,
          "created_utc": "2025-12-31 12:05:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwx5vwv",
          "author": "oneplane",
          "text": "\\> Why do I need 5 different services just to run a function on HTTP trigger?\n\nBecause 'run a function on http trigger' is 5 different things. It can even be 50 different things depending on how granular you want to get.\n\nYou can pay someone to make the 5 different things seem like 1 thing, or you could us a service that doesn't have 5 things but only has 1 thing that just happens to be the thing you need.\n\nDoing this yourself on EC2 is also 5 things (if you just pick 5 random things). But EC2 itself is also more than 5 things (Instance, ENI, IP, AMI, EBS, Subnet, VPC, SG, AWS Account) so it's never really 'just the few things you wanted' if you don't specify your scope.\n\nIt can be 'one thing' if you scope it to a single Git repo, but that repo would need all the config to make that 1 thing happen (by doing 5 things in its configuration).\n\nPerhaps the issue here is how you perceive 'things' or 'complexity'; depending on your perspective merely including a standard library for a function that needs a runtime to open a socket and read and write on it is already too complex, but there isn't going to be a solution that doesn't do those things. But is that a problem? Not really, you're probably not even taking those into account because they are just there.\n\nThe same goes for the services and granularity of the components you consume. The complexity doesn't go away, it's just packaged and abstracted differently. Keep in mind that complex â‰  hard (or difficult), it merely means that a thing is composed out of multiple other things.",
          "score": 2,
          "created_utc": "2025-12-31 14:46:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvdv7a",
          "author": "cmills2000",
          "text": "Start small using a monolith deployed to an ec2 instance or an app service (Elastic Beanstalk, ECS).  The AWS way of doing things is often overkill.  Start with as little as you need at first, and if you find in the future that you need to do it the AWS way due to scale, you cross that bridge when you get there.",
          "score": 3,
          "created_utc": "2025-12-31 06:07:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvnsde",
              "author": "HydrA-",
              "text": "Eh, not sure I agree. With IaaC and AI its never been easier to set things up correctly from the start. I wouldnâ€™t risk the double work and then have something that isnâ€™t scalable or can scale-to-zero, or needs patching and firewall rules/nat gateway, etc. etc. Going the VM route will not necessarily simplify things. Before you know it youâ€™re relatively locked in to Beanstalk or what have you",
              "score": 3,
              "created_utc": "2025-12-31 07:32:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwvgfp9",
          "author": "PhilipJayFry1077",
          "text": "Those services (minus cloud watch) are super cheap. Like millions of invocations and it's dirt cheap. What kind of traffic are you expecting?",
          "score": 2,
          "created_utc": "2025-12-31 06:28:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxc426",
          "author": "TechDebtSommelier",
          "text": "This is normal for cloud-native serverless architectures, but many teams avoid the complexity and cost by switching to a small EC2-based service: a single always-on application handles the HTTP request, runs the async logic, and publishes to a broker in one place, giving you fewer moving parts, simpler debugging, and more predictable costs at the expense of some managed scaling and infrastructure responsibility.",
          "score": 1,
          "created_utc": "2025-12-31 15:19:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxk03g",
          "author": "KayeYess",
          "text": "All you need is API Gateway (listener) and compute (Lambda). SQS is good for async/retries. EventBridge is another way of invoking Lambda. Not sure why you are using it if you only need to support web based triggers. Unless you are doing something special, Cloudwatch for most services is more or less out of the box. Also, you are managing nothing here. These are all \"managed\" services. You are essentially configuring them as per your requirements. If you were to build and manage similar services on your own, it would be far more complicated.and expensiveÂ \n\nIf you find your existing setup expensive and complicated, you (or a qualified architect) should revisit the Architecture/Design.",
          "score": 1,
          "created_utc": "2025-12-31 15:59:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0q59u",
          "author": "_smartin",
          "text": "You could simplify architecture based on requirements. Why have an event broker AND a distributed queue? Also, if all lambda is doing is mapping and invoking another AWS service, cut it out. You can use an API Gateway AWS Integration type and use VTL to map requests and responses directly to and from the underlying AWS service you *ACTUALLY* need. Most people donâ€™t know this because AWS and partners propagate a message of â€œuse lambdaâ€ through all the examples.",
          "score": 1,
          "created_utc": "2026-01-01 02:32:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1kmth",
          "author": "poptimus_rhyme",
          "text": "Wouldn't something like n8n make this workflow easier?",
          "score": 1,
          "created_utc": "2026-01-01 06:23:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1lsmv",
          "author": "jagster247",
          "text": "I recommend SST",
          "score": 1,
          "created_utc": "2026-01-01 06:34:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx41mel",
          "author": "austerul",
          "text": "I think you may be doing something wrong.\n1. If your use case is \"run lambda on http trigger\" then all you need is lambda and some http gateway  (api gateway is expensive unless you really need all the stuff it brings for running a rest api)\n2. I don't see why you need eventbridge for the stuff you listed. Eventbridge is largely useful to have your code react to events or for scheduled jobs. It's not mandatory for http triggers or to process sqs messages. Some people use it to schedule jobs to ensure the lambda is warmed up which you may or may not care about. Have you measured your cold start penalty? Is it worth the cost?\n3. If you need retries then yes, you need sqs. You can do some limited retries inside your lambda function with the risk of prolonging the running time when the retry would not work.\n\nBut realistically, nothing you mention here is really particular to cloud except the concept of lambda.\n\nInstead of lambda with event bridge warmup you'd need a permanent service up.\n\nInstead of sqs/sns you would need some queueing system for retries (rabbitmq, redis) - another server to manage\n\nInstead of api gateway you'd need some reverse proxy (maybe depending on your platform, if using Go or Rust I wouldn't have a problem exposing directly).\n\nIf you care about logs or metrics, you'd need your own log collector/metrics backend and instrument your service to use that + ensure that your infrastructure is monitored (server, app, queue, reverse proxy)",
          "score": 1,
          "created_utc": "2026-01-01 17:57:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvgdhv",
          "author": "NoMoreVillains",
          "text": "You really only need APIGW and lambda. If you don't want logs nothing is making you use CloudWatch. I'm not sure what the message and broker you're using are but if that's not needed then cut out SQS. Also you only pay for the traffic/duration/messages sent so why does it matter?",
          "score": 1,
          "created_utc": "2025-12-31 06:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvri5a",
          "author": "soundman32",
          "text": "Costs are crazy?  How much traffic are you expecting?\n\nAws first year is probably free, even for the services you mention.\n\nAlternatively, host your app yourself on your own server. Traffic will be minimal, you wont need a load balancer and multiple instances.  All you need is a domain name, a static ip address, and a server.\n\nWhen you NEED to scale, then start looking at cloud.",
          "score": 1,
          "created_utc": "2025-12-31 08:07:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvu3uf",
          "author": "r2yxe",
          "text": "You can get rid of the Eventbridge layer and maybe use lambda function urls or directly invoke lambda depending on the auth scenario. \n\nBut without some additional context its hard to say.",
          "score": 1,
          "created_utc": "2025-12-31 08:31:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwi73r",
          "author": "owengo1",
          "text": "For the complexity side, you can just  ask your favorite llm to generate a terraform for your project. You will have a full working PoC in one go, IaC, and you can maintain it with an llm. It will connect all the services and you will have a small bunch of file to manage your infra.\n\nFor the cost side it's another issue: clearly your costs will grow linearly with your traffic, so it will be very cheap as long you have very low traffic, and quickly something completely unaffordable with high traffic. Once again, you can ask an LLM to modelize the costs of your architecture and estimate the threshold at which you have to find something else.\n\n\"Something else\" could be cloudflare workers, or ALB + ECS instead of Gateway + Lambda, or a cheap graviton instance, ... Clearly you will have other constraints to manage but it's very likely you can save a significant amout of money with a less \"fully-managed\" solution.",
          "score": 1,
          "created_utc": "2025-12-31 12:13:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxd8kh",
          "author": "flyontimeapp",
          "text": "Because AWS is 15% of Amazon's revenue but 60% of its profit. More complexity is better for them because it locks you in.",
          "score": -1,
          "created_utc": "2025-12-31 15:25:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvm97q",
          "author": "Human-Possession135",
          "text": "I use AWS lightsail containers. One instance is $7 per month and offers up to 10 containers. I have a fastapi + redis + worker node. \n\nCovers the same usecase: a quick endpoint + task queue + retry logic + message broker\n\nFew months ago we got 25k signups in < 1 hour and it held up aside from the queue filling up",
          "score": 0,
          "created_utc": "2025-12-31 07:18:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwvdtrr",
          "author": "serpix",
          "text": "Use terraform or cdk to set this up at least.\nI'd like to correct that you'll be getting the largest bill from Cloudwatch alone ðŸ‘",
          "score": -2,
          "created_utc": "2025-12-31 06:07:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwwe4x8",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -2,
          "created_utc": "2025-12-31 11:39:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwwzj0w",
              "author": "marx2k",
              "text": "ALB to Cloudfront you say?",
              "score": 1,
              "created_utc": "2025-12-31 14:10:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx2pr9a",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -4,
          "created_utc": "2026-01-01 13:15:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx9z5rc",
              "author": "LilRagnarLothbrok",
              "text": "Yeedu is scam and the support sucks, they billed me additional charges and they have a lot of downtime issues",
              "score": 2,
              "created_utc": "2026-01-02 16:32:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxmx0q",
      "title": "Memory spikes killing my workersðŸ’€  need scaling advice",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1pxmx0q/memory_spikes_killing_my_workers_need_scaling/",
      "author": "tiln7",
      "created_utc": "2025-12-28 09:03:41",
      "score": 34,
      "num_comments": 29,
      "upvote_ratio": 0.73,
      "text": "So I've got this Node.js SaaS that's processing way more data than I originally planned for and my infrastructure is starting to crack...\n\n**Current setup (hosted on 1 EC2):**\n\n* Main API container (duplicated, behind load balancer)\n* Separate worker container handling background tasks\n\n**The problem:** Critical tasks are not executed fast enough + memory spikes making my worker container being restarted 6-7x per day.\n\n**What the workers handle:**\n\n* API calls to external services (some slow/unpredictable)\n* Heavy data processing and parsing\n* Document generation\n* Analysis tasks that crunch through datasets\n\n\n\nSome jobs are time-critical (like onboardings) and others can take hours.\n\n\n\n**What I'm considering:**\n\n1. Managed Redis (AWS ElastiCache) \n2. Switching to SQS \n\n  \nWhat approach should I take and why? How should I scale my workers based on the workload?   \n\n\nThanks ðŸ™",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1pxmx0q/memory_spikes_killing_my_workers_need_scaling/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwclk3e",
          "author": "Dave3of5",
          "text": "Try to figure out the memory spikes / crashing first before doing anything arch / design related. There could be a problem there and then you are just shifting your problem around.",
          "score": 13,
          "created_utc": "2025-12-28 11:40:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwcmchg",
              "author": "tiln7",
              "text": "will try!",
              "score": 2,
              "created_utc": "2025-12-28 11:47:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwca7im",
          "author": "MortTheLemur23",
          "text": "For a starter I would recommend separating your API from your workers by placing them on separate instances. And for more resilience dockerize both and use an AWS managed service like ECS or Elastic Beanstalk (simple setup). That way a single api/worker failure won't tear down your entire app.\n\nAnd for the workers, I would (like you said) look into SQS or Bullmq to queue your worker jobs. That enables you to better manage your jobs and see what causes your memory spikes.",
          "score": 25,
          "created_utc": "2025-12-28 09:53:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwie5zm",
              "author": "UltimateLmon",
              "text": "Honestly though for OP's particular problem, Op should really investigate the memory spikes.\n\n\nThough everything you've said should still be implemented because it's just generally good to have more resilient architecture - costs pending.\n\n\nOP might even consider moving analysis tasks to AWS Batch while at it. Can't tell about doc processing and data processing without further details.",
              "score": 5,
              "created_utc": "2025-12-29 07:46:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwc87zt",
          "author": "seanv507",
          "text": "Its unclear what your question is. \n\nAre you saying you need more compute resources (bigger instance/ aws batch serverless ,...) so handle memory spikes\n\nor a better multiprocessing (so important quick tasks are performed in a timely way) eg a separate queue\n\n...",
          "score": 9,
          "created_utc": "2025-12-28 09:33:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcno6e",
          "author": "hornetmadness79",
          "text": "You underestimated the necessary resources required to run your apps. Not uncommon really, but your reaction is. If an app is crashing 7 times a day, you can either fix the code, provision a larger node, or build better infra to handle the capacity problem. Throwing more cloudy solutions to fix a problem of your own making is what AWS is betting on.",
          "score": 7,
          "created_utc": "2025-12-28 11:59:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwc6rg3",
          "author": "xzaramurd",
          "text": "For background tasks it sounds like you could use AWS Batch with Fargate or EC2 Spot instances. For your API, if sounds like you already have an ELB? Do you not have an AutoScalingGroup with it so it can spin up more instances if needed?",
          "score": 10,
          "created_utc": "2025-12-28 09:19:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwc8q4g",
          "author": "mr_q_ukcs",
          "text": "What was the decision behind hosting it on a single ec2 ?\n\nThe memory spikes could be a number of application level  issues, do they happen at a set timeframe or are they random?\n\nAre your api calls asynchronous ? Do you have timeouts on them? Do you have back offs? All these things can cause a constraint on cpu resource.\n\nI would look at moving your service to ECS Fargate if itâ€™s handling tasks that are critical, a single ec2 isnâ€™t going to give you the resilience you need.",
          "score": 4,
          "created_utc": "2025-12-28 09:38:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcu9i5",
          "author": "FlamboyantKoala",
          "text": "Are you generating files in memory? Â 90% of the time Iâ€™ve had to fix issues with memory itâ€™s caused by that.Â ",
          "score": 2,
          "created_utc": "2025-12-28 12:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwd32a8",
          "author": "cachemonet0x0cf6619",
          "text": "i donâ€™t think using another cloud service is going to fix your underlying issue of a poorly designed application. if you dm me we can talk about the shift aspect of lift and shift but iâ€™d need to see the details",
          "score": 1,
          "created_utc": "2025-12-28 13:54:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj070q",
          "author": "dataflow_mapper",
          "text": "This smells like a workload separation problem more than just a queue choice. Mixing time critical jobs and long running memory heavy tasks in the same worker almost guarantees spikes and restarts. I would split workers by job class first, even if they still share infra, so the heavy batch stuff cannot starve or crash onboarding jobs.\n\nSQS plus autoscaled workers is usually a good baseline because it forces you to think in smaller, bounded jobs and gives you backpressure for free. Redis can work, but it is easier to accidentally turn it into a memory footgun. Also worth looking at streaming large payloads instead of loading everything into memory at once. Most Node memory issues I see come from buffering way more than expected.",
          "score": 1,
          "created_utc": "2025-12-29 11:11:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcugwz",
          "author": "Wide_Commission_1595",
          "text": "So generally it seems like you've got a lot right! Separate API and workers is going to make scaling this an awful lot easier! \n\nFirst of consider moving over to Fargate.  If have the API auto scale based on CPU/memory to make sure it stays responsive.  I would go with the SQS option for queueing jobs, because you can auto scale your workers based on queue length, and that way you keep background job processing responsive.\n\nIt's not clear exactly how the background jobs work, i.e. is it always one type of job, or are there multiple different jobs?  Basically I would go with one queue per job type, and have dedicated workers assigned to their own queue, but if that creates extra work, a single queue/worker combo will do fine\n\nLonger term, depending on how the whole system works I might be tempted to convert the API to API gateway.  You can use it to validate requests without code and place items direct into SQS.  Other endpoints can use lambda functions.  For the reports, save them S3 and then in the API return a redirect to a pre-signed S3 url so user can download easily without exposing the bucket itself.  These are future suggestions though, for now just moving away from EC2 and into Fargate with SQS buffering should take you an awfully long way",
          "score": 1,
          "created_utc": "2025-12-28 12:55:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwd3xsu",
              "author": "nekokattt",
              "text": "Fargate is going to be more expensive and you still have to configure it to scale. While it removes the overhead of managing EC2, it does not remove the issue for OP.",
              "score": 3,
              "created_utc": "2025-12-28 14:00:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwi9xpr",
                  "author": "Wide_Commission_1595",
                  "text": "The OP is already running containers, do why use EC2 when ECS is specifically for scaling. \n\nYour right, you do have to configure scaling, I mean, that's kind of how AWS works.  You configure services to work the way you want them to?\n\nAnd yes, it's going to cost more.  Scaling up kinda does that.  Again, it's how AWS works.\n\nThe OP could attempt to fix memory leaks, which could take months, may never fix the issue, and all the while of customers off, or just scale using services designed for the task and keep customers happy and paying.....",
                  "score": 0,
                  "created_utc": "2025-12-29 07:09:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwdjncf",
          "author": "AnomalyNexus",
          "text": "node.js is a poor choice for time-critical heavy data processing\n\nYou can try to patch over that by throwing more hardware at it to buy time but if the SaaS keeps growing you'll hit a wall eventually forcing a rewrite of at least the core logic in something more suitable",
          "score": 1,
          "created_utc": "2025-12-28 15:32:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwh8agd",
              "author": "ducki666",
              "text": "Lol",
              "score": 1,
              "created_utc": "2025-12-29 02:49:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwe5ckk",
          "author": "mlhpdx",
          "text": "Use Lambda. You already know Node.js and can keep your web server since it probably wonâ€™t need scaling for a bit if you put the workers elsewhere.Â \n\nIdeally, have the web sever put messages for workers in a queue (or multiple queues if you have different priority levels) and use Lambda to work it/them. This isnâ€™t an ideal setup, but itâ€™s an easy step from where you are and allows workers to scale from zero to whatever you need when spikes happen.",
          "score": 0,
          "created_utc": "2025-12-28 17:21:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwennm6",
              "author": "tiln7",
              "text": "Noted! Migrating everything to lambdas would require serious refactoring and probably I would need to open DB?",
              "score": 1,
              "created_utc": "2025-12-28 18:49:05",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nweubk7",
                  "author": "mlhpdx",
                  "text": "Yeah, donâ€™t migrate everything â€” just the worker code that runs in the background. The Lambda can connect to the same VPC that contains the DB, so it doesnâ€™t need to be â€œopenâ€ in that sense.",
                  "score": 0,
                  "created_utc": "2025-12-28 19:19:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwfkeyq",
          "author": "TechDebtSommelier",
          "text": "Put the heavy work behind SQS and let your API just enqueue jobs, because Redis queues fall over easily when memory spikes or workers crash. Split workers by job type so fast, time sensitive tasks are not stuck behind long running jobs, and autoscale workers based on SQS queue depth. Keep EC2 or ECS for predictable heavy jobs and consider Lambda only for short bursty tasks. This setup absorbs spikes cleanly and stops one bad job from taking everything down.",
          "score": 0,
          "created_utc": "2025-12-28 21:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwibgyw",
          "author": "could_be_any_person",
          "text": "I also have an app hosted on AWS with an API container and long running tasks. You need to split your tasks between different workers. Have a dedicated worker container for long running tasks and one for short tasks. Create an auto scaling group and policy for each worker. I have mine set to scale based on the size of my task queues, but you can also set it to scale based on memory, cpu, etc. For example, you can create an auto scaling policy for your short tasks to create more worker containers whenever tasks are backed up. That way, there's always a worker container available to process short tasks in case there's a spike in user activity (or migrate short tasks to a lambda function).  You can also set up predictive scaling policies so that your cluster scales automatically ahead of predicted demand patterns. \n\nEither use redis + a lambda function + the EventBridge scheduler, AWS SQS, or a managed solution like Temporal to handle delegation of queued tasks to your worker containers.\n\nFigure out the memory problem first. Your program shouldn't be crashing regardless of spike in user activity. It should be queuing any jobs your container can't handle. I recommend SQS for that. Also make sure you're not saving large files to memory. Use a temp folder to save any large files that you need to return.",
          "score": 0,
          "created_utc": "2025-12-29 07:22:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwc7vjc",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -17,
          "created_utc": "2025-12-28 09:30:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwd0ns8",
              "author": "Dangerous-Sale3243",
              "text": "OP is unclear, but it doesnâ€™t sound like thereâ€™s a memory leak, thereâ€™s just either â€œbadâ€ programming (holding entire documents in memory perhaps too long) or just lack of scaling in the design.\n\nOP could spend a lot of time rewriting to Rust but it wouldnâ€™t solve the underlying mathematical problem that requests/sec * avg request time * avg document size is close to the memory limit.\n\nI do think rewriting to Rust could be helpful though, but itâ€™s further down the list of priorities. To me, #1 is stopping the bleeding, give everything more RAM to stop dropping requests. #2 is to switch to passing documents as s3 URIs and then migrate the background workers to Lambda.",
              "score": 2,
              "created_utc": "2025-12-28 13:39:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nweqd7r",
              "author": "bot403",
              "text": "As a software engineer I'd rather spin up a second instance in minutes to hours than a week or weeks doing a risky language rewrite of my core application.",
              "score": 1,
              "created_utc": "2025-12-28 19:01:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q20o8j",
      "title": "AWS CloudFormation Diagrams",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q20o8j/aws_cloudformation_diagrams/",
      "author": "Philippe_Merle",
      "created_utc": "2026-01-02 14:56:22",
      "score": 28,
      "num_comments": 6,
      "upvote_ratio": 0.85,
      "text": "[AWS CloudFormation Diagrams](https://github.com/philippemerle/AWS-CloudFormation-Diagrams) is a simple CLI script to generate AWS architecture diagrams from AWS CloudFormation templates. It parses both YAML and JSON AWS CloudFormation templates, supports 140 AWS resource types and any custom resource types, generates DOT, GIF, JPEG, PDF, PNG, SVG, and TIFF diagrams, and provides 126 generated diagram examples. Following illustrates a generated diagram example\n\nhttps://preview.redd.it/nzbkvn4q9yag1.png?width=4899&format=png&auto=webp&s=99771623c2d4e43240950e7f7d398ac0ef0104bc\n\n",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1q20o8j/aws_cloudformation_diagrams/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxa33d2",
          "author": "Veuxdo",
          "text": "Nice work. Some ideas for improvement after just looking at the sample:\n\n- The sample diagram appears to be combining *run-time* relations and *permission* relations. An example a of *run-time* relation is APIG -> Lambda -> Dynamo Table, while *permission* relations include the IAM roles and permissions. It would probably be best to split these concerns up into two separate diagrams (and possibly a third: static Cloudfront configuration). [\"Master\" diagrams are generally bad](https://www.ilograph.com/blog/posts/breaking-up-the-master-diagram/).\n\n- The arrows really need labels to tell the viewer what the relations are.",
          "score": 11,
          "created_utc": "2026-01-02 16:50:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxf9ajk",
              "author": "Philippe_Merle",
              "text": "Thank for these improvement ideas.",
              "score": 1,
              "created_utc": "2026-01-03 11:39:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxn43na",
          "author": "mrlikrsh",
          "text": "Good stuff, there is an MCP server that can do this on top of the existing diagram as code packages out there (mentioning this to help you not duplicate efforts). This takes some heavy lifting away. Thank you.\n\n[https://aws.amazon.com/blogs/machine-learning/build-aws-architecture-diagrams-using-amazon-q-cli-and-mcp/](https://aws.amazon.com/blogs/machine-learning/build-aws-architecture-diagrams-using-amazon-q-cli-and-mcp/)",
          "score": 3,
          "created_utc": "2026-01-04 15:52:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxanayz",
          "author": "bruderj15",
          "text": "This looks great! I will give it a try!",
          "score": 2,
          "created_utc": "2026-01-02 18:24:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxc1n5w",
          "author": "imbecominginsane",
          "text": "Thanks for sharing! Will give it a try",
          "score": 2,
          "created_utc": "2026-01-02 22:27:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxehs0f",
          "author": "ThigleBeagleMingle",
          "text": "Andâ€¦â€¦? \n\nProblem \n\nChallenge/Opportunity\n\nApproach/capabilities\n\nImplementation\n\nResults/scope/impact statement",
          "score": -2,
          "created_utc": "2026-01-03 07:43:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7eu81",
      "title": "Can I host my website on AWS as a beginner?",
      "subreddit": "aws",
      "url": "/r/cheapesthosting/comments/1q7espl/can_i_host_my_website_on_aws_as_a_beginner/",
      "author": "calebkiirya",
      "created_utc": "2026-01-08 15:33:02",
      "score": 28,
      "num_comments": 33,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q7eu81/can_i_host_my_website_on_aws_as_a_beginner/",
      "domain": "",
      "is_self": false,
      "comments": [
        {
          "id": "nyey428",
          "author": "Ok-Equivalent-5131",
          "text": "Yes you can. Should you, unless your specifically trying to get experience with aws, no probably not. If itâ€™s just hosting a simple website Iâ€™d suggest using heroku or something.",
          "score": 15,
          "created_utc": "2026-01-08 15:41:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf3r5j",
              "author": "calebkiirya",
              "text": "I am not specifically trying to learn AWS right now, just want something simple and predictable for hosting. Sounds like a managed platform might be a better fit for now. Thanks for the suggestion.",
              "score": 1,
              "created_utc": "2026-01-08 16:06:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyg6u0k",
                  "author": "Docs_For_Developers",
                  "text": "I started on AWS, switched to Render because it's much more intuitive and has a good mcp",
                  "score": 2,
                  "created_utc": "2026-01-08 18:56:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyx17vi",
                  "author": "Librarian-Rare",
                  "text": "Fly.io has hard budget limits and is super simple. Iâ€™m sure there are other providers with similar offerings. You want simple + budget caps..",
                  "score": 1,
                  "created_utc": "2026-01-11 04:29:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyfvmn5",
          "author": "TheMagicTorch",
          "text": "AWS Lightsail might be what you're looking for",
          "score": 4,
          "created_utc": "2026-01-08 18:08:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfz18z",
              "author": "calebkiirya",
              "text": "I had not looked into Lightsail yet. A simpler, more predictable AWS option might be a good middle ground. I will check it out, thanks for pointing it out.",
              "score": 2,
              "created_utc": "2026-01-08 18:22:52",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyj2zzs",
              "author": "x86brandon",
              "text": "Yes, Lightsail is a great starting point!",
              "score": 1,
              "created_utc": "2026-01-09 03:19:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyqsemd",
                  "author": "calebkiirya",
                  "text": "ok, thanks",
                  "score": 1,
                  "created_utc": "2026-01-10 06:17:07",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nygm9vs",
          "author": "devandreacarratta",
          "text": "Yes, you can but â€¦\n\nThe main point is to understand the technology of your website.\n\nIn any case, I suggest two services \n\n- aws amplify\n- aws lightsail \n\nI used both in the past and probably I come back to this services in the next month",
          "score": 4,
          "created_utc": "2026-01-08 20:03:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjnchz",
              "author": "calebkiirya",
              "text": "That makes sense. Understanding what the site actually needs seems more important than the platform itself. Amplify and Lightsail both sound like more beginner friendly entry points into AWS. I will look into both and see which fits my use case better. Thanks for sharing your experience.",
              "score": 1,
              "created_utc": "2026-01-09 05:23:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyjvpbe",
                  "author": "devandreacarratta",
                  "text": "Last but not least, if you have a static website you can evaluate also S3 + CloudFront as free tired/ serverless solution.\n\nI have a GitHub repository with this case study if you want to see",
                  "score": 1,
                  "created_utc": "2026-01-09 06:26:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyhd7n1",
          "author": "KayeYess",
          "text": "You sure could. AWS now even has some free and flatrate options https://www.reddit.com/r/aws/comments/1p0pa4p/aws_offers_flatrate_including_free_web_hosting/",
          "score": 2,
          "created_utc": "2026-01-08 22:02:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjm3f5",
              "author": "calebkiirya",
              "text": "That is good to know, I was not aware of the flat rate options. I will read through that thread, having predictable pricing definitely makes AWS more approachable. Thanks for sharing the link.",
              "score": 1,
              "created_utc": "2026-01-09 05:14:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhf8lw",
          "author": "petrefax",
          "text": "You can but I probably wouldn't recommend it if you're just interested in hosting a website. It's a little too easy to get yourself into trouble if you don't know what you're doing. But if you want a challenge and are interested in learning more about AWS, it's definitely doable.",
          "score": 2,
          "created_utc": "2026-01-08 22:11:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjl2zu",
              "author": "calebkiirya",
              "text": "That sounds reasonable. For now I am more focused on getting something online without surprises, but I do like the idea of learning AWS later as a challenge once I have more experience. Thanks for the balanced take.",
              "score": 1,
              "created_utc": "2026-01-09 05:07:30",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nyryarj",
              "author": "Maximus_Modulus",
              "text": "Specifically surprise bills. Lots of moving parts in AWS. Just have to be aware of costs and keeping an eye on it or setting up alerts etc.",
              "score": 1,
              "created_utc": "2026-01-10 12:29:41",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg7khr",
          "author": "OchirDarmaev",
          "text": "Consider use sst to easy deploy your site https://sst.dev/docs/component/aws/static-site/",
          "score": 1,
          "created_utc": "2026-01-08 18:59:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjosmo",
              "author": "calebkiirya",
              "text": "That looks interesting, especially if it simplifies deployment while still letting me learn AWS concepts. I will take a look at SST and see if it fits a small, low risk setup.",
              "score": 1,
              "created_utc": "2026-01-09 05:33:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nygexmj",
          "author": "cloudfox1",
          "text": "No you are not allowed , sorry.",
          "score": 1,
          "created_utc": "2026-01-08 19:31:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjnzng",
              "author": "calebkiirya",
              "text": "From all the replies here it sounds like â€œallowedâ€ is not the issue, but whether it is the right tool for the job. I will probably start with something simpler and revisit AWS later for learning.",
              "score": 1,
              "created_utc": "2026-01-09 05:27:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyx9uu1",
          "author": "RobotDeathSquad",
          "text": "Itâ€™s funny how uninformed so many of the answers are.Â \n\nYes, you can host websites on AWS. Yes, it can be free or very cheap (static assets in S3, small amounts of dynamic execution in lambda, storage in dynamodb).Â ",
          "score": 1,
          "created_utc": "2026-01-11 05:23:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxk1u7",
              "author": "calebkiirya",
              "text": "It does seem like a lot of the risk comes from *how* AWS is used rather than AWS itself. A setup with S3 for static assets and minimal serverless components sounds very different from spinning up full servers and forgetting about them. I think the caution is still useful for beginners, but I agree that with the right architecture it can be very cheap. Thanks for adding that perspective.",
              "score": 1,
              "created_utc": "2026-01-11 06:42:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyez0jd",
          "author": "solo964",
          "text": "It would help to provide more details on what \"simple website or small project\" means to you specifically, but here is a [related post](https://www.reddit.com/r/webdev/comments/t1dt37/cheapest_place_to_host_a_static_website/).",
          "score": 1,
          "created_utc": "2026-01-08 15:45:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyezqiv",
              "author": "calebkiirya",
              "text": "Thanks, that is fair. By simple, I mean a low traffic site, mostly static pages with maybe a small backend later. I am mainly trying to avoid unexpected costs while learning. I will check out the post you shared.",
              "score": 0,
              "created_utc": "2026-01-08 15:48:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf0qs6",
          "author": "ururururu",
          "text": "AWS is one of or the biggest cloud provider.  Learning how the cloud functions, publishing to it, iterating & maintaining are key skills that can be very beneficial for your resume and future projects.  I would say it could be worth it just for that.\n\n\nDepending on how small and static your website is you might just be able to publish to a bucket (S3) and have it serve static web pages.   E.g. => https://www.google.com/search?q=s3+server+web+content",
          "score": 1,
          "created_utc": "2026-01-08 15:53:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf7sb8",
              "author": "calebkiirya",
              "text": "That is a good point. The resume and learning value is definitely appealing. Starting with something like a small static site on S3 sounds like a safer way to get hands on experience without much risk. I will look into that approach and keep cost alerts in place. Thanks for the suggestion.",
              "score": 1,
              "created_utc": "2026-01-08 16:24:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf5by3",
          "author": "pint",
          "text": "aws is the polar opposite of beginner friendly",
          "score": 0,
          "created_utc": "2026-01-08 16:13:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyfb222",
              "author": "calebkiirya",
              "text": "That is fair. From everything people have shared here, it definitely seems powerful but not very forgiving for beginners. Probably better to start with something simpler and approach AWS later with more experience.",
              "score": 1,
              "created_utc": "2026-01-08 16:38:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyf30x4",
          "author": "Sad-Tear5712",
          "text": "I am building cloudagent.io for this very purpose and would love to help for free in exchange of honest feedback.\n\nDM if interested",
          "score": -2,
          "created_utc": "2026-01-08 16:03:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf9c8c",
              "author": "calebkiirya",
              "text": "Thanks for the offer, I appreciate it. I am still in the learning and evaluation phase right now, but I will take a look at cloudagent and keep this in mind. Happy to share feedback once I have a clearer setup.",
              "score": 2,
              "created_utc": "2026-01-08 16:31:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q511r9",
      "title": "Rate Increase: EC2 Capacity Blocks",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q511r9/rate_increase_ec2_capacity_blocks/",
      "author": "cloudnavig8r",
      "created_utc": "2026-01-05 22:57:36",
      "score": 25,
      "num_comments": 18,
      "upvote_ratio": 0.86,
      "text": "Iâ€™ve been with AWS for over 8 1/2 years, and it has been very rare to see _rate increases_.  \n\nI saw this Register article [https://www.theregister.com/2026/01/05/aws_price_increase/] today.  \n\nA 15% decrease would be something u/jeffbarr would be happy to share the news about.  But a 15% increase will attract u/quinnypig to interject his $0.02, I mean $0.023 (must factor in the 15% increase)\n\nWhen I would teach Cloud Finance courses. I often challenged learners to identify when AWS has increased rates.  Usually the only thing they can come up with is the EIP fees (and that is debatable if going from free to charged is a price increase or the ending of a free inclusion).  \n\nWhen are other times that AWS has **raised** prices?\n\nWhat impact does this have for you and your workloads?\n\n_Note:_ this is a specialised workload that not too many â€œaverageâ€ users are consuming.\n\nHow would you identify if AWS increases the rates of your workloads. And do you have a proactive mitigation plan in place?",
      "is_original_content": false,
      "link_flair_text": "billing",
      "permalink": "https://reddit.com/r/aws/comments/1q511r9/rate_increase_ec2_capacity_blocks/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxwlqkw",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'billing'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+billing).\n\nLooking for more information regarding billing, securing your account or anything related? [Check it out here!](https://www.reddit.com/r/aws/comments/vn4ebe/check_it_first_operating_within_amazon_web/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-05 22:57:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwnvra",
          "author": "Sirwired",
          "text": "Errr... the article was written by QuinnyPig, so you don't have to wait at all for his take!",
          "score": 18,
          "created_utc": "2026-01-05 23:08:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxwsuvt",
              "author": "cloudnavig8r",
              "text": "I didnâ€™t see that!\n\nIt wasnâ€™t in his sarcastic toneâ€¦ it was filtered!",
              "score": 8,
              "created_utc": "2026-01-05 23:34:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxyxdsw",
          "author": "Ahrimaan",
          "text": "Capacity Blocks have ALWAYS been Dynamic pricing, i don't know why he is whining about \"spot\" price fluctuation",
          "score": 5,
          "created_utc": "2026-01-06 07:27:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxz2sbw",
              "author": "cloudnavig8r",
              "text": "This is a fair point.  \n\nThe price will be updated again in April.  But it is a significant change that may not have been well communicated to customers.\n\nAnd the price will change at some point in time, not clearly identified.  From a FinOps perspective it is an increase- and cannot be planned for.\n\nWith Spot instances, they will never exceed the published On-demand rate.  These have no cap.",
              "score": 1,
              "created_utc": "2026-01-06 08:17:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxwmvlw",
          "author": "coinclink",
          "text": "It's interesting, because Capacity Blocks are really the only way you can even use these instance types. It's extremely rare that you can ever just spin one of these up on-demand. So in effect, it's a way for them to advertise one price (on-demand) while actually charging more. It's not surprising that GPU prices are increasing in a general sense though.",
          "score": 3,
          "created_utc": "2026-01-05 23:03:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxycby8",
              "author": "Burekitas",
              "text": "Not really; many companies spin on-demand instances or bombard the capacity reservation API until they get enough instances. \n\nIt much more efficient to run with capacity block, unless you purchase savings plans for 3 years (which most of these companies are doing).",
              "score": 2,
              "created_utc": "2026-01-06 04:42:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxxvawl",
          "author": "zerotoherotrader",
          "text": "Yes.  Only the big organizations will be using these instances regularly.. but they are covered by enterprise discounts and other savings plans.",
          "score": 1,
          "created_utc": "2026-01-06 03:00:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyio8g",
              "author": "cloudnavig8r",
              "text": "But a discount plan is like a percentage off.  An increase is still an increase.  \n\nIf you have a 10% blanket discount plan (private pricing agreement, esp, whatever).  And the price goes up 15%â€¦ your effective price still goes up 15%.  \n\nIf it was $100, your discount is $10.  You pay $90.  \nThen the price goes up to $115.  Your discount is now $11.50.  You are paying $103.50.\n\nAn increase in public pricing of 15% (at $100) results in an increase of $13.50 (which is still 15% from your discounted $90).\n\n_Note, numbers are for illustration purposes_. As u/Quinnypig stated in the post, it will open up interesting conversations with account teams that have already negotiated their private pricing agreements.",
              "score": 2,
              "created_utc": "2026-01-06 05:26:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxxxjqm",
          "author": "yarenSC",
          "text": "I think the most famous price increase was when S3 added per-API fees.\n\nI remember early on when price cuts were common, there was a marketing phase commonly tossed around with something like \"AWS has only ever raised prices 4 times in its history  but has cut prices <> times!\"",
          "score": 1,
          "created_utc": "2026-01-06 03:12:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyix8l",
              "author": "cloudnavig8r",
              "text": "I know we used to have material that would tout the number of price reductions.  \nNever saw the raised 4x messaging.",
              "score": 2,
              "created_utc": "2026-01-06 05:28:31",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny02di6",
                  "author": "yarenSC",
                  "text": "I don't remember if it was exactly 4, but somewhere around there.  And I feel like it stopped being talked about much ~6-7 years ago",
                  "score": 1,
                  "created_utc": "2026-01-06 13:13:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxy52h0",
          "author": "LordWitness",
          "text": "I think my case fits the same category as the EIP debate, but whenever pricing changes come up, I canâ€™t forget the SageMaker Canvas incident.\n\nFor those whoâ€™ve used SageMaker, this will sound familiar.\n\nCanvas is the no-code UI where you can ingest data, train models, and analyze results without writing a single line of code.\n\nThe fun part is the pricing: Canvas charges per active session. Until you explicitly click Log out in the Canvas UI, AWS charges you over $1 per hour.\n\nAnd hereâ€™s the absurd part: you can close the browser tab, log out of AWS entirely, delete SageMaker resources and Jeff Bezos will still happily keep the session alive and keep charging you.\n\n\nThis behavior started in April 2022. Before that, Canvas was free. I had used it on my personal account in January 2022 for study. I even saw the pricing notice, but thought, â€œNo problem, I wonâ€™t use it after April,â€ and ignored it.\n\nWhat I didnâ€™t expect was that AWS would keep sessions created months earlier permanently logged in.\n\nFast-forward to mid-July. I came back from vacation, opened my account, and found $600 in charges. I was about to lose my $500 credit and still owe money.\n\nAfter pleading my case with support, they eventually granted me credits to cover the SageMaker Canvas charges.",
          "score": 1,
          "created_utc": "2026-01-06 03:56:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxy0ann",
          "author": "xrothgarx",
          "text": "In 2024 they started charging $43 for each IPv4 address https://aws.amazon.com/blogs/aws/new-aws-public-ipv4-address-charge-public-ip-insights/",
          "score": 0,
          "created_utc": "2026-01-06 03:28:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxyhxlz",
              "author": "cloudnavig8r",
              "text": "That is the point of arguably it isnâ€™t a price increase, but removal from free-tier.  Which also arguably an effective increase from zero.\n\nThe other thing is that it was communicated very clearly for 3-6 months in advance of going into effect.",
              "score": 1,
              "created_utc": "2026-01-06 05:21:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxycefr",
          "author": "Burekitas",
          "text": "I consider this to be similar to spot pricing, the day AWS will increase the on demand prices that would be a game changer.",
          "score": -1,
          "created_utc": "2026-01-06 04:43:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwn4ep",
          "author": "abofh",
          "text": "In an indirect way, forcing everyone to VPC's baked in NAT gateway pricing for (almost) every workload",
          "score": -9,
          "created_utc": "2026-01-05 23:04:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxwta5s",
              "author": "cloudnavig8r",
              "text": "I was referring to direct pricing increases.  Not effective more expensive workloads.\n\nThere are ways to engineer around most of these add-on costs.",
              "score": 1,
              "created_utc": "2026-01-05 23:36:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4xkf7",
      "title": "pydynox: DynamoDB ORM with Rust core",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q4xkf7/pydynox_dynamodb_orm_with_rust_core/",
      "author": "leandro_damascena",
      "created_utc": "2026-01-05 20:47:01",
      "score": 24,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "I built a DynamoDB ORM called pydynox. The core is written in Rust for speed.\n\nI work with DynamoDB + Lambda a lot and got tired of slow serialization in Python, so I moved that part to Rust.\n\n`class User(Model):`  \n`model_config = ModelConfig(table=\"users\")`  \n`pk = String(hash_key=True)`  \n`name = String()`\n\n`user = User(pk=\"USER#123\", name=\"John\")`  \n`user.save()`\n\n`user = await User.get(pk=\"USER#123\")`\n\nHas the usual stuff: batch ops, transactions, GSI, Pydantic, TTL, encryption, compression, async. Also added S3Attribute for large files (DynamoDB has a 400KB limit, so you store the file in S3 and metadata in DynamoDB).\n\nBeen using it in production for a few months now. Works well for my use cases but I'm sure there are edge cases I haven't hit yet.\n\nStill pre-release (0.12.0). Would love to hear what's missing or broken. If you use DynamoDB and want to try it, let me know how it goes.\n\n[https://github.com/leandrodamascena/pydynox](https://github.com/leandrodamascena/pydynox)\n\n**What my project does**\n\nIt's an ORM for DynamoDB. You define models as Python classes and it handles serialization, queries, batch operations, transactions, etc. The heavy work (serialization, compression, encryption) runs in Rust via PyO3.\n\n**Target audience**\n\nPeople who use DynamoDB in Python, especially in AWS Lambda where performance matters. It's in pre-release but I'm using it in production.\n\n**Comparison**\n\nThe main alternative is PynamoDB. pydynox has a similar API but uses Rust for the hot path. Also has some extras like S3Attribute for large files, field-level encryption with KMS, and compression built-in.",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1q4xkf7/pydynox_dynamodb_orm_with_rust_core/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxx645w",
          "author": "nemec",
          "text": "neat. I only briefly looked at the code, so apologies if I missed something but you should consider using KMS:GenerateDataKey and handling encryption and decryption client side rather than via KMS:Encrypt/Decrypt. Beyond just running into the [max plaintext size](https://docs.aws.amazon.com/kms/latest/APIReference/API_Encrypt.html) of 4KB per operation (where a DDB record/field can be up to 400KB), if you do a batch Put with 30 records and each record has 3 encrypted fields, it looks like your library will make 90 calls to KMS:Encrypt. With data keys, you make one KMS call and then encrypt locally 90 times which should be significantly faster.\n\nYou could even just wrap the Rust AWS database encryption SDK if you're willing to live with the extra metadata fields it requires - the ItemEncryptor will let you client-side encrypt and decrypt DDB records without touching DDB, so you can continue to use the DDB client code you wrote. I've never used the Rust one, but I assume it has much the same features as the Java client.\n\nhttps://docs.aws.amazon.com/database-encryption-sdk/latest/devguide/ddb-rust-using.html#ddb-rust-item-encryptors",
          "score": 3,
          "created_utc": "2026-01-06 00:43:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxzeazi",
              "author": "leandro_damascena",
              "text": "Damn, you're right. I totally missed this.\n\nCalling KMS:Encrypt for each field is dumb - 90 KMS calls for a batch write? And the 4KB limit would break on larger fields anyway.\n\nGoing to switch to envelope encryption:\n\n\\- GenerateDataKey once  \n\\- AES locally in Rust  \n\\- Store the encrypted DEK with the data\n\nWill check out the Database Encryption SDK too. Might be worth the metadata overhead.\n\nThanks for this SUPER important catch!",
              "score": 1,
              "created_utc": "2026-01-06 10:08:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nydlto1",
          "author": "FarkCookies",
          "text": "Would love to see some benchmarking against PynamoDB. When working with a DB CPU is rarely the bottleneck.",
          "score": 1,
          "created_utc": "2026-01-08 10:59:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nydmqwa",
              "author": "leandro_damascena",
              "text": "Hey u/FarkCookies thanks for replying. I do have some benchmarks.\n\nYou can check the source code here: [https://github.com/leandrodamascena/pydynox/tree/main/benchmarks](https://github.com/leandrodamascena/pydynox/tree/main/benchmarks)\n\nAnd the docs here: [https://leandrodamascena.github.io/pydynox/guides/benchmarks/](https://leandrodamascena.github.io/pydynox/guides/benchmarks/)\n\nI can't attach images here in this post, but I have a CloudWatch dashboard with those metrics and will make it public soon.\n\nI'm using AWS Lambda for my tests because it is a good use case where memory/cpu are limited in a very specific environment, but I'm open to ideas on how to improve this benchmark to other computer environments and what make sense or not.\n\nRegarding your comment about CPU, yeah, I agree that some of the heavy work is done by the DB engine, but DynamoDB is a special case that we need to deal with serialization and a lot of other stuff.",
              "score": 1,
              "created_utc": "2026-01-08 11:06:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nydqhrd",
                  "author": "FarkCookies",
                  "text": "I am just a big fan of PynamoDB and I need a lot of convincing to switch. Indeed (de)serialisation is super slow so maybe the biggest bang for the buck would be to rewrite that part in Rust in some drop in replacement?",
                  "score": 1,
                  "created_utc": "2026-01-08 11:37:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdvngk",
      "title": "DynamoDB Search functionality?",
      "subreddit": "aws",
      "url": "https://i.redd.it/qwv3xma4ukdg1.png",
      "author": "Antique_Sample_7934",
      "created_utc": "2026-01-15 21:00:20",
      "score": 20,
      "num_comments": 4,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qdvngk/dynamodb_search_functionality/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzt6kqm",
          "author": "geomagnetics",
          "text": "I think it's for PartiSQL searching. it's only enabled if you have the right indexes enabled.",
          "score": 6,
          "created_utc": "2026-01-15 22:08:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztbtcr",
              "author": "Antique_Sample_7934",
              "text": "Do you mean GSI's? I have tons of them. I haven't used PartiSQL though",
              "score": 2,
              "created_utc": "2026-01-15 22:33:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwdx62",
                  "author": "geomagnetics",
                  "text": "I'm not sure what it takes to enable it. but try the PartiSQL editor from the sidebar. that might give you a clue as to what's going on",
                  "score": 1,
                  "created_utc": "2026-01-16 10:52:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6if4",
          "author": "Vprprudhvi",
          "text": "That's true. I just noticed it now",
          "score": 2,
          "created_utc": "2026-01-15 22:07:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7fmbk",
      "title": "AWS Community Builders Applications Are Now Open",
      "subreddit": "aws",
      "url": "https://builder.aws.com/community/community-builders",
      "author": "No_Secretary2862",
      "created_utc": "2026-01-08 16:02:29",
      "score": 19,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1q7fmbk/aws_community_builders_applications_are_now_open/",
      "domain": "builder.aws.com",
      "is_self": false,
      "comments": [
        {
          "id": "nyh7bci",
          "author": "goguppy",
          "text": "Thanks for sharing!",
          "score": 1,
          "created_utc": "2026-01-08 21:37:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3ejxx",
      "title": "Looking for Best Practices/ Tooling approach for managing 100's -> 1000's of acounts",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q3ejxx/looking_for_best_practices_tooling_approach_for/",
      "author": "Iconically_Lost",
      "created_utc": "2026-01-04 03:03:23",
      "score": 17,
      "num_comments": 13,
      "upvote_ratio": 0.87,
      "text": "Looking for advice and pointers' to KB/Whitepapers/YT on how do people manage 100's -> 1000s of AWS accounts.\n\n* What is your tooling and approval pipeline. For both core infra (Accounts, Ingress/egress Networking, Permissions/roles, Auditing, Policy enforcement) and workloads (devs) ie EKS/ECS + task/k8s, LBs, ect.\n* Do you mandate the same tooling/ approval pipeline for both the core infra and dev teams (workload spins ups) or do you let the dev teams pick their own tooling/approval for the workloads?\n* Do you let you devs just execute TF/tooling from their laptops or do you use a GitOps/Devops tools like Spacelift/Firefly/TF Cloud\n* How do you split structure your gits? Is it per account/environment? How do you insure that the code that was used to build the preprod is the same that is being used for prd. \n\n  \nI know its a very large, open ended question, but looking for personal hands on experience answers. What do you do in your environment, how did you scale it up?\n\n",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q3ejxx/looking_for_best_practices_tooling_approach_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxl0yaf",
          "author": "wreckuiem48",
          "text": "If you have thousands of accounts it sounds like it might be worth also considering enterprise support where you will get a dedicated AWS team to help guide you in this process. ES does have a cost though...",
          "score": 6,
          "created_utc": "2026-01-04 06:32:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxk8kj2",
          "author": "Akimotoh",
          "text": "Tags, control tower, and organization policies. Are all root account passwords baselined?",
          "score": 11,
          "created_utc": "2026-01-04 03:21:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxkgatt",
              "author": "moofox",
              "text": "Disagree. Colocating unrelated workloads in the same account is a greater security risk.",
              "score": 9,
              "created_utc": "2026-01-04 04:06:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nxkxxxa",
              "author": "PeteTinNY",
              "text": "As a former AWS SA who was very involved with the beginnings of multi account architecture, I really disagree.    Yes multi account can build complexity if you donâ€™t automate not building protective guardrails that can only be done via multiple accounts is the only way to control the blast radius of risk.   Even the simple risk of very large platform limits. \n\nLook at ControlTower, look at the old multi account frameworks and solutions.   Those a good starts.    But looking at some of the work J&J, Thompson Ruters, Disney, and Comcast did as mega enterprise orgs â€¦.  It would be crazy unsafe to run as one mega account.   \n\nEven just for the account limits.",
              "score": 6,
              "created_utc": "2026-01-04 06:09:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxkz8io",
                  "author": "Iconically_Lost",
                  "text": "So what would you recommend/ point at? Would you go click ops via controlTower + CF or Terraform->Control Tower.  Individual git repos for the TF per account? or on giant?\n\nHow would the approval flow work? Would be a manual approval process and then manual execution? \n\nGot any good links?",
                  "score": 1,
                  "created_utc": "2026-01-04 06:19:08",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nxkascx",
              "author": "Iconically_Lost",
              "text": "I get the purpose of consolidation and tagging but are you saying you would be looking at doing this all via the Conroll Tower gui? No TF, all accounts have identical networks/sizing, not storing CloudFormations in Git. Approval/PR outside and clips-ops once the approval comes through?",
              "score": 0,
              "created_utc": "2026-01-04 03:34:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxkkgdw",
          "author": "trash-packer1983",
          "text": "Seems like a good use case to control via Landing Zone Accelerator \n\nhttps://aws.amazon.com/solutions/implementations/landing-zone-accelerator-on-aws/",
          "score": 3,
          "created_utc": "2026-01-04 04:33:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxl5yr2",
          "author": "Fit-Honeydew-9928",
          "text": "Well we had the same issue and did engage a call with AWS Enterprise Support Architect, they wanted to push thru the control tower , but control tower requires your first AWS account as Mgmt account and ideally nothing being deployed there ( which will not be true for many of us.) . Lastly we went ahead with using creating a global terraform repo for our root account AWS with SSO Mgmt. Created a terraform super user role (Administrative permission) in each account ( one time manual setup). Used a atlantis super user from the main account to assume those admin role in each account to run terraform manifest in each account. Each account had a different terraform directory in our source control repo but all managed by a single atlantis with atlantis.yaml.   \nterraform/  \n  global/ - contains sso config and tf which needs to be deployed to all the accounts ( like global s3 bucket deny policy, default root account disabling)  \n  account1/ ->  aws\\_ec1 , aws\\_an1 and so on so forth  \n  account2/ ->  aws\\_ec1 , aws\\_an1 and so on so forth  \nPs: Please go through the limitations of AWS Control Tower before pushing for it.",
          "score": 2,
          "created_utc": "2026-01-04 07:14:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxodm5v",
          "author": "KayeYess",
          "text": "Everything starts with good strategy, architecture and design. I recommend investing in these areas before taking the plunge.\n\n\nAt a high level, Organizations (account structure), workload network types and placement (shared services, inspection, ingress/egress, regular apps, regions, connectivity, etc), naming standards for tags (very important), security (includes a whole gamut), backupÂ  resiliency, governance and compliance, observability, standard deployment patterns (so each workload type does not have to reinvent everything), CMDB, Change /Operations management, Support structure, FinOPs, CICD/automation (native, terra or some combination) and so on.",
          "score": 2,
          "created_utc": "2026-01-04 19:17:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxodmfd",
          "author": "Wide_Commission_1595",
          "text": "LZA etc from AWS is good, but I tend find intend up butting up against limitations.\n\nI have a TF repo for the master account which manages SSO, OU structure, and service delegations etc.  it's not huge, but we run it nightly to ensure no drift.  This also deploys a CFN stack set that sets a few bits an pieces up in every account automatically.\n\nWe have an SCP repo that sets up the main guardrails\n\nThe OU structure has 2 parent OUs, core and workload.  Core accounts are for things like Deployment, Security, Network etc.  there aren't many accounts here, but they're each extremely specific.  For example the Deployment account has the OIDC integration with GitHub, security has security hub, inspector, guard duty etc.\n\nUnder workloads we then have business units.  Below that are environment OUs.  This lets us set a few SCPs depending on unit or env so for example we limit EC2 instance sizes in lower environments to keep costs down a bit\n\nOne of our core accounts is called Vending, and has a custom built account vending machine.  It's not hugely complicated but you select your business unit and give it a name and select an owner from a directory, and it creates one a count per env in your business unit. \n\nBending also let's you request an account deletion, but has some approval steps.  It also has a nightly job so that when a user leaves but owns an account it is delegated up to their manager, who can then assign ownership.\n\nBasically, the aim is that each core area doesn't change a lot, accounts can be created/destroyed on demand, and for the most part, AWS takes care of itself and doesn't need teams.to manage it.  Accounts are owned by the teams that use them, one account(across envs) per app\n\nIt sounds complicated, butjin reality it's pretty simple, easily extensible and generally ticks along in the background!\n\nIf you go the TF route, we have a single bucket in the deployment account that all state lives in and is accessible to the whole org via a bucket policy.  State files are read only except for the account you're accessing (e.g. if you are writing state from ac/c 123 you can write to the /123/....key, any other is read only to allow for remote state.\n\nEverything is deployed via cicd, no laptop deploys allowed.  SCP blocks the root user in all accounts with a (usually empty) exception list for emergencies.\n\nWe don't allow r/w access to humans, only the deployment account OIDC roles.  We do have a break-glass option to get admin access, but it's overly complex so won't go into detail.  We use an Okta workflow for it, and it's not ideal but it's rarely used.\n\nOh, and never allow IAM users without a security exception, and that gets reconfirmed every 3 months and has to be signed of by an architect",
          "score": 2,
          "created_utc": "2026-01-04 19:17:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmlx80",
          "author": "jinxiao2010",
          "text": "We're currently using ADF, all accounts are bootstrapped by ADF. We also developed a lot of core infra pipelines.",
          "score": 1,
          "created_utc": "2026-01-04 14:16:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2epx1",
      "title": "How do you monitor async (lambda -> sqs -> lambda..) workflows when correlation Ids fall apart?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q2epx1/how_do_you_monitor_async_lambda_sqs_lambda/",
      "author": "bl4ckmagik",
      "created_utc": "2026-01-02 23:49:49",
      "score": 17,
      "num_comments": 23,
      "upvote_ratio": 0.9,
      "text": "Hi guys,   \n\nI have experienced issues related to async workflows such as the flow not completing, or not even being triggered when there are multiple hops involved (API gateway -> lambda -> sqs -> lambda...) and things breaking silently.   \n\nI was wondering if you guys have faced similar issues such as not knowing if a flow completed as expected. Especially, at scale when there are 1000s of flows being run in parallel.   \n\nOne example being, I have an EOD workflow that had failed because of a bug in a calculation which decides next steps, and it never sent the message to the queue because of the bug miscalcuting. Therefore it never even threw an error or alert. I only got to know about this a few days later.   \n\nYou can always retrospectively look at logs and try to figure out what went wrong but that would require you knowing that a workflow failed or never got triggered in the first place.   \n\nAre there any tools you use to monitor async workflows and surface these issues? Like track the expected and actual flow? ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q2epx1/how_do_you_monitor_async_lambda_sqs_lambda/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxd4qfz",
          "author": "TampaStartupGuy",
          "text": "Not sure this will solve your issue, but hereâ€™s a solution that I use. \n\nTrack the workflow state directly in DynamoDB instead of relying on logs. The core issue is youâ€™re depending on error logs to flag failures, but in this case the bug prevented the message from being sent at all, so there was nothing to log.\n\nInstead, make the expected workflow state something you can query. Set up a job tracking table in Ddb where each step is recorded with a job ID, step name, status like pending, in progress, completed, or failed with a timestamp. Then you query for steps that never completed, not just the ones that failed. \n\nYou can invoke the lambda whenever the task is done.  It queries for jobs where the status isnâ€™t marked as completed and sends an alert if anythingâ€™s missing.\n\nThe key idea is to track what should have happened and alert when something doesnâ€™t show up, rather than waiting for an error to tell you something broke. DLQs help if your handler crashes. State tracking catches the silent failures where no message was sent at all.",
          "score": 15,
          "created_utc": "2026-01-03 02:03:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxeurw0",
              "author": "Willkuer__",
              "text": "I currently have to deal with this setup and I hate it tbh. I still have to find the correct logs to debug the issue. Instead of writing your own process manager in ddb I find stepfunction executions much easier to use and they give me all the information needed: input, output, error for each individual step.\n\nWe also have the issue that we have some relatively long running jobs that can fail within ninutes but also run succesfully for days. The jobs health is just so hard to debug with a ddb record and loads of cloudwatch logs.",
              "score": 4,
              "created_utc": "2026-01-03 09:37:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxckrk6",
          "author": "smutje187",
          "text": "You should never consciously let a process fail silently - issues with AWS itself can always happen but your Lambda code should never ignore errors or exceptions (depending on your programming language) and instead raise CloudWatch alarms or other kind of events that trigger someone to take a look.",
          "score": 10,
          "created_utc": "2026-01-03 00:10:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxctw4e",
              "author": "bl4ckmagik",
              "text": "Agreed. I'm very much in the fail loud camp as well. Maybe I should have phrased my post better. Sorry, English isn't my first language.   \nThe tricky cases I've experienced are not really exceptions or errors inside lambdas but situations where they don't run at all causing workflow to finish halfway. Like an event ridge rule not matching, sns filters dropping messages... Etc.    \n\nIn those scenarios there's no event to trigger an alarm. You only notice it because a downstream effect never happens.   \n\nAny thoughts on catching non-events like that early?",
              "score": 3,
              "created_utc": "2026-01-03 01:01:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxeu37j",
          "author": "Willkuer__",
          "text": "I am currently rebuilding a POC based on sqs+lambda flows using stepfunctions because of such issues. I've worked with both in the past and find stepfunctions much easier on the observability side if the workflow gets more complex/has more steps.\n\nStepfunctions comes with a significant overhead in engineering I'd say but it is worth the hassle.\n\nThis obviously makes only sense of you have a job-like structure: a trigger, start/end of a job. If you are more interested in kind of real-time streaming it's maybe too rigid depending on your usecase.",
          "score": 4,
          "created_utc": "2026-01-03 09:31:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxchc86",
          "author": "Iliketrucks2",
          "text": "Can you add cray tracing easily?",
          "score": 1,
          "created_utc": "2026-01-02 23:51:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxchha2",
              "author": "bl4ckmagik",
              "text": "Sorry, do you mean X-ray tracing?",
              "score": 1,
              "created_utc": "2026-01-02 23:52:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxci13g",
                  "author": "Iliketrucks2",
                  "text": "Lol yeah sorry. Autocorrect got me.  I think you can fairly quickly and easily instrument your code to get better insights into whatâ€™s going on",
                  "score": 1,
                  "created_utc": "2026-01-02 23:55:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxe5pmg",
          "author": "commentShark",
          "text": "I currently have every error thrown raise an alarm which emails me, then I investigate that issue by pasting the email to Claude to debug it (which has a doc of Instructions on how to query etc). It can fix the issue quite fast. \n\nWorks for my low traffic site, Iâ€™ve plugged lots of holes and edge cases this way. Could work with higher error thresholds or sampling.",
          "score": 1,
          "created_utc": "2026-01-03 06:03:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxqw93q",
          "author": "Physical-Sign-2237",
          "text": "step functions",
          "score": 1,
          "created_utc": "2026-01-05 02:38:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxwjiwj",
          "author": "HosseinKakavand",
          "text": "This is a very real problem with multi-hop async flows. At a certain point, choreography starts to break down, especially for long-lived or multi-step workflows (mega workflows), because thereâ€™s no single place that knows what *should* have happened versus what *actually* did. Correlation IDs and logs help after the fact, but they donâ€™t surface silent failures like a missing branch or an un-emitted event at runtime. For higher-stakes workflows, teams often move to an explicit orchestration layer with durable state, step tracking, timeouts, retries, and compensating actions, so you can alert on â€œexpected step not reachedâ€ rather than discovering issues days later. Thatâ€™s exactly the class of IT operations workflows Luther is designed to handle, including SQS-based flows, with built-in visibility and auditability. More details are on the Luther Enterprise subreddit:  \n[https://www.reddit.com/r/luthersystems/](https://www.reddit.com/r/luthersystems/)",
          "score": 1,
          "created_utc": "2026-01-05 22:46:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5quh0",
      "title": "AWS CLI - am I the only one who is terrified of being in the wrong account when I do something?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q5quh0/aws_cli_am_i_the_only_one_who_is_terrified_of/",
      "author": "WeirdWebDev",
      "created_utc": "2026-01-06 18:36:22",
      "score": 16,
      "num_comments": 66,
      "upvote_ratio": 0.77,
      "text": "AWS CLI - am I the only one who is terrified of being in the wrong account when I do something?\n\nI know the answer to \"am I the only one\" is always no, but the purpose of my question is more of a \"how do I mitigate this fear or possibility of what I fear coming true\"\n\nI've even toyed with the idea of a separate machine for updating prod, which I'm not ruling out.\n\nUPDATE: Thanks for all the responses, I am reading them all even if I don't respond to them all. I was half expecting to get reamed for posing the question lol.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q5quh0/aws_cli_am_i_the_only_one_who_is_terrified_of/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "ny1yplh",
          "author": "Extreme-Accident-968",
          "text": "i never have a default account. i have my credentials configured and use --profile <name of the account> for everything",
          "score": 81,
          "created_utc": "2026-01-06 18:43:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny20gsb",
              "author": "onbiver9871",
              "text": "This, for sure. I never have a default set, so whether interactively or in any scripting, I am forced to specify a profile.",
              "score": 11,
              "created_utc": "2026-01-06 18:51:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny27pqg",
              "author": "jdptechnc",
              "text": "This is the appropriately paranoid answer.  Always be explicit.",
              "score": 10,
              "created_utc": "2026-01-06 19:24:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2jndr",
                  "author": "Extreme-Accident-968",
                  "text": "my reddit user name is no coincidence /s",
                  "score": 3,
                  "created_utc": "2026-01-06 20:19:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2295t",
              "author": "abofh",
              "text": "This, my default either points at one of my personal accounts (on my contracting laptop) or at nothing at all (on work provided machines) - if I don't specify --profile/AWS\\_PROFILE, it should fail, not do the wrong thing.",
              "score": 2,
              "created_utc": "2026-01-06 18:59:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny28r8h",
              "author": "Sirwired",
              "text": "This Is The Way...  no default account means no uncertainty on where your command went.",
              "score": 2,
              "created_utc": "2026-01-06 19:28:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2lahb",
              "author": "WeirdWebDev",
              "text": "OK, cool. I do have my default set to my \"sandbox,\" but I'll remove it to force me to get in the habit of being explicit every time.",
              "score": 1,
              "created_utc": "2026-01-06 20:26:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny20824",
          "author": "dghah",
          "text": "    $ aws sts get-caller-identity\n\n ... is your friend along with no default credentials, only SSO profiles along with terminal extensions that graphically display the value of the current sso role name",
          "score": 36,
          "created_utc": "2026-01-06 18:50:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3fyo5",
              "author": "Iliketrucks2",
              "text": "hmmmm i should add that to my prompt ...",
              "score": 1,
              "created_utc": "2026-01-06 22:49:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyb3n2f",
              "author": "b3542",
              "text": "Came here to say this.",
              "score": 1,
              "created_utc": "2026-01-08 00:40:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "ny2ls31",
              "author": "No-Rip-9573",
              "text": "I have it aliased to â€œstsâ€ :)",
              "score": 1,
              "created_utc": "2026-01-06 20:28:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny50q5d",
                  "author": "iamaperson3133",
                  "text": "`whoamz`",
                  "score": 7,
                  "created_utc": "2026-01-07 03:53:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny3phj3",
                  "author": "maikindofthai",
                  "text": "Thatâ€™s crazy",
                  "score": 2,
                  "created_utc": "2026-01-06 23:38:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1zszx",
          "author": "Akimotoh",
          "text": "You should modify your terminalâ€™s ps1 variable to dynamically show the account number that is in use. It can show up behind or after your folder display",
          "score": 29,
          "created_utc": "2026-01-06 18:48:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny23rqq",
              "author": "GrandJunctionMarmots",
              "text": "This is the answer!\n\nIf you use ohmyzsh then it's baked in.",
              "score": 11,
              "created_utc": "2026-01-06 19:06:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyc6a9v",
                  "author": "wetpaste",
                  "text": "Starship is my favorite prompt manager. Good alternative to something like Omz if you want a prompt that looks nice",
                  "score": 2,
                  "created_utc": "2026-01-08 04:07:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny2subm",
                  "author": "otterley",
                  "text": "Is it? Iâ€™ve been using ohmyzsh for a while and havenâ€™t seen it. Whatâ€™s your customization?",
                  "score": 1,
                  "created_utc": "2026-01-06 21:01:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny21i6e",
          "author": "notospez",
          "text": "I know there's not too many fans of it, but for this specific fear CloudShell is actually a very good solution. You're always running it from a browser screen where you can see the logged-in account name and role at the top. And there's also \\`aws sts get-caller-identity\\`.",
          "score": 8,
          "created_utc": "2026-01-06 18:55:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2n64g",
              "author": "Zenin",
              "text": "The more skilled you are at a Bash prompt, the more you lothe CloudShell.\n\nFor example, you'll build up muscle memory for hotkeys like CTRL-W and not even think about when you're in CloudShell.  Well, shit.\n\nDitto common hotkeys in various terminal editors, etc.  You're always just one muscle memory command away from screwing over your entire day.\n\nThere's also the whole issue of not having your personal toolkit with you that you've built up over years and decades, tuned exactly to your needs.  Sure, as a highly experienced Linux user / admin you can do everything \"manually\" on a bare system, but it's neither efficient nor enjoyable to be using a rock as a hammer when you've got a cordless nail gun in your toolkit you can't use.\n\nCloudShell is ok for break glass situations and for inexperienced CLI users, but it absolutely should *never* be the primary terminal for anyone because you'll never improve your terminal skills beyond mediocre while forced to work within its limited, ephemeral little sandbox.",
              "score": 3,
              "created_utc": "2026-01-06 20:35:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2qisg",
                  "author": "notospez",
                  "text": "Oh absolutely, you can pry my trusty terminal from my cold dead hands. But if OP were using a real terminal they'd presumably use something like [https://github.com/juhofriman/aws-profile-bash-prompt](https://github.com/juhofriman/aws-profile-bash-prompt) already.\n\n\\[Edit\\]: for zsh users [https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/aws](https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/aws) is extremely powerful.",
                  "score": 4,
                  "created_utc": "2026-01-06 20:50:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny27elx",
              "author": "jdptechnc",
              "text": "CloudShell is good in a pinch.",
              "score": 3,
              "created_utc": "2026-01-06 19:22:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny24pb9",
          "author": "Quinnypig",
          "text": "I use [Granted](https://granted.dev) for this. Shows the profile in the CLI, shows the profile in the Firefox browser bar in the web console. Haven't screwed it up since then.",
          "score": 8,
          "created_utc": "2026-01-06 19:10:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2sod2",
              "author": "garfunkle21",
              "text": "Shame CommonFate went the way it did. Any idea of another JIT solution (other than [TEAM](https://aws.amazon.com/blogs/security/temporary-elevated-access-management-with-iam-identity-center/))?",
              "score": 1,
              "created_utc": "2026-01-06 21:00:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3vl9a",
                  "author": "Quinnypig",
                  "text": "Granted was given to the fwd:CloudSec folks and is still actively maintained.",
                  "score": 1,
                  "created_utc": "2026-01-07 00:09:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny26hp7",
          "author": "FarkCookies",
          "text": "I always use profiles (and export AWS\\_PROFILE=), and I have $AWS\\_PROFILE in my shell prompt.",
          "score": 5,
          "created_utc": "2026-01-06 19:18:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2l5ns",
              "author": "nemec",
              "text": "this is the way. I even have a zsh completion script so I can tab-complete profile names (`use <name>` to set the env var, `use -` to unset)",
              "score": 2,
              "created_utc": "2026-01-06 20:26:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2t0om",
                  "author": "otterley",
                  "text": "Can you share it?",
                  "score": 1,
                  "created_utc": "2026-01-06 21:02:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny1xcoo",
          "author": "2fast2nick",
          "text": "We have a process to get elevated access for prod, so even if you try to do a modification, you would get denied.",
          "score": 3,
          "created_utc": "2026-01-06 18:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny21u1n",
          "author": "Least-Woodpecker-569",
          "text": "You are 100% right to be terrified. I am very concerned about such scenarios as well, and I have made a few costly mistakes because of that. \n\nMy solution to that was scripting. I have â€œaws-devâ€ and â€œaws-prodâ€ scripts that set up correct env variables and then run aws cli passing remaining arguments to it. I do not have a default account, and I never let myself set long living keys through env variables. Not foolproof, as you can still call a wrong script, but better than nothing. \n\nIt also helps to type the command in a text editor and then copy/paste it into the command line - gives you more time to think. \n\nFinally, it also helps to have someone else run the command in prod. Or have another person to watch you doing that. I despise peer programming, but I am more than OK with someone watching and approving my steps when working in prod.",
          "score": 3,
          "created_utc": "2026-01-06 18:57:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1ydg8",
          "author": "o5mfiHTNsH748KVq",
          "text": "I got into championing DevOps practices because of this fear (among other fears)\n\nBasically anything I do with the CLI is scripted and the script includes making sure itâ€™s acting against the correct environment.\n\nIf youâ€™re nervous about something, that probably means you can script yourself a guard rail.\n\nIn the age of AI, itâ€™s very low effort to generate a script instead of manually running something with the CLI.",
          "score": 2,
          "created_utc": "2026-01-06 18:42:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1ylqy",
          "author": "AWSSupport",
          "text": "Hi there,\n\nWe're always looking for ways to improve our products. If interested, you can share your feedback with us the following ways: http://go.aws/feedback.\n\n\\- Aimee K.",
          "score": 2,
          "created_utc": "2026-01-06 18:43:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1z3tv",
          "author": "mr_mgs11",
          "text": "We use identity center and SSO. I have my .config file with different profiles for each account, and I have set the profile manually before I do anything. I also ALWAYS do an \"aws s3 ls\" before I do anything because I am paranoid as well. The bucket names will have environment and account name in there somewhere.",
          "score": 2,
          "created_utc": "2026-01-06 18:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny20pec",
          "author": "pipesed",
          "text": "There's a couple different approaches. For the cli, you can use a prompt decorator like ohmyzsh's so you see which role/account you're currently assuming. You can also use things like iterm2 badges to alert you of which account you are in.",
          "score": 2,
          "created_utc": "2026-01-06 18:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny21k9y",
          "author": "marcoslop16",
          "text": "I use OhMyZsh it has a plug it that in console shows me at all times which profile and region Iâ€™m working on",
          "score": 2,
          "created_utc": "2026-01-06 18:56:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2m0ua",
          "author": "cloud_coder",
          "text": "setup an ENV var and update your prompt so it says where you point. Like others said, avoid assumptions and defaults. A little clever shell scripting can add some indicators and guard rails.",
          "score": 2,
          "created_utc": "2026-01-06 20:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3ls9s",
          "author": "FlinchMaster",
          "text": "I have my shell prompt set to print out my current `AWS_PROFILE` value. \n\n[https://imgur.com/a/BOVcJc4](https://imgur.com/a/BOVcJc4)\n\nI also make use of fzf to get fuzzy search selection of all my profiles. And aws-sso-utils populates all the possible profile for me. \n\n    # Command to set the AWS_PROFILE env var with a fuzzy selector\n    alias aws-profile='export AWS_PROFILE=$(sed -n \"s/\\[profile \\(.*\\)\\]/\\1/gp\" ~/.aws/config | fzf)'\n    \n    # And a shorthand alias for this\n    alias ap=\"aws-profile\"",
          "score": 2,
          "created_utc": "2026-01-06 23:18:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny4qsss",
          "author": "danstermeister",
          "text": "if every command has **--profile** stipulated, then it's impossible to realize your fear.",
          "score": 2,
          "created_utc": "2026-01-07 02:56:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny58j3m",
          "author": "nicarras",
          "text": "I use aliases so that they are tied to specific accounts.",
          "score": 2,
          "created_utc": "2026-01-07 04:42:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1zbp9",
          "author": "ExpertIAmNot",
          "text": "The \"correct answer\" is to only use CI to deploy to prod, but we all know that the reality is that doesn't always happen.  \n  \nI usually handle this by removing the default config from my local AWS config file and creating a bash script in my repo that writes unique profiles that include a bunch of things that tell me wether I'm using a dangerous profile name or not. Any dev can run this script on their machine and be ready to use the roles with minimal effort.\n\nI then use the \\`--profile\\` flag when doing command line operations. A little more typing, but great clarity on what environment you are about to hit.   \n  \nSome profile names are sometimes baked into other deploy scripts too. CI doesn't use them though, that's a whole other category.\n\n    echo 'Writing poweruseraccess-dev-000000000000-us-east-1...'\n    aws configure set sso_start_url https://orgname.awsapps.com/start --profile poweruseraccess-dev-000000000000-us-east-1\n    aws configure set sso_region us-east-1 --profile poweruseraccess-dev-000000000000-us-east-1\n    aws configure set sso_account_id 000000000000 --profile poweruseraccess-dev-000000000000-us-east-1\n    aws configure set sso_role_name PowerUserAccess --profile poweruseraccess-dev-000000000000-us-east-1\n    aws configure set region us-east-1 --profile poweruseraccess-dev-000000000000-us-east-1\n    \n    \n    echo 'Writing readonlyaccess-prod-111111111111-us-east-1...'\n    aws configure set sso_start_url https://orgname.awsapps.com/start --profile readonlyaccess-prod-111111111111-us-east-1\n    aws configure set sso_region us-east-1 --profile readonlyaccess-prod-111111111111-us-east-1\n    aws configure set sso_account_id 111111111111 --profile readonlyaccess-prod-111111111111-us-east-1\n    aws configure set sso_role_name ReadOnlyAccess --profile readonlyaccess-prod-111111111111-us-east-1\n    aws configure set region us-east-1 --profile readonlyaccess-prod-111111111111-us-east-1",
          "score": 2,
          "created_utc": "2026-01-06 18:46:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny298a7",
              "author": "ReturnOfNogginboink",
              "text": "Only using CI can happen, actually. \n\nI didn't have write access to my accounts (at least, not my prod accounts). My CI pipeline does.",
              "score": 2,
              "created_utc": "2026-01-06 19:31:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny2dmja",
                  "author": "ExpertIAmNot",
                  "text": "It definitely can happen!!! Iâ€™ve seen it too! But itâ€™s not as common as local deploys, in my experience.",
                  "score": 1,
                  "created_utc": "2026-01-06 19:51:12",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "ny4dt9x",
                  "author": "mr_jim_lahey",
                  "text": "I've been doing strictly-IaaC-only (including for local development) for so long that it gives me anxiety thinking about modifying things manually via CLI or console. For me it feels like the equivalent of doing `mkdir -p /tmp/backup-1 && cp -r ./* /tmp/backup-1` instead of using git. Like sure, there are some rare, limited circumstances where it makes sense once in a blue moon, but you're just setting yourself up for pain and failure if that's your default.",
                  "score": 1,
                  "created_utc": "2026-01-07 01:46:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "ny2p4y5",
              "author": "Zenin",
              "text": "You're using SSO, which is great.  But do yourself a huge favor and upgrade your configs to use SSO \"session\" configurations (sso-session instead of profile) so you can set your start URL, etc SSO specific information once in an sso-session and simply reference that sso-session in all your specific profiles.\n\n`[sso-session orgname]`  \n`sso_start_url =` `https://orgname.awsapps.com/start`  \n`sso_region = us-east-1`  \n`sso_registration_scopes = sso:account:access`  \n  \n`[profile readonlyaccess-prod-111111111111-us-east-1]`  \n`sso_session = orgname`  \n`sso_account_id = 111111111111`  \n`sso_role_name = ReadOnlyAccess`  \n`region = us-east-1`\n\nAlso, not for nothing, but ReadOnlyAccess should *NEVER* be considered a \"safe\" default policy.  Strongly consider switching to a custom policy with **SecurityAudit** as your base instead of ReadOnlyAccess.  The issue is that ReadOnlyAccess includes full access to *data* not just configuration.  All S3 bucket data, all DynamoDB data, etc.  At least around here, the company is much more concerned about data getting exfiltrated than accidentally deleted.",
              "score": 2,
              "created_utc": "2026-01-06 20:44:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny230ty",
          "author": "jmreicha",
          "text": "aws-vault",
          "score": 1,
          "created_utc": "2026-01-06 19:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny23yla",
          "author": "jspreddy",
          "text": "aws-vault + ohmyzsh config to always show current profile name on cli prompt.",
          "score": 1,
          "created_utc": "2026-01-06 19:06:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny24ewi",
          "author": "zMynxx",
          "text": "I have an alias for aws that read my profiles file and feeds it to fzf, then sets the cmd as â€˜aws â€”profile <selected-profile> â€¦â€™ so I always interactively select the correct account.\nFor kubernetes clusters I use â€˜kubieâ€™",
          "score": 1,
          "created_utc": "2026-01-06 19:09:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny26msf",
          "author": "escape_deez_nuts",
          "text": "Terrified?  No..  Cautious?  yes",
          "score": 1,
          "created_utc": "2026-01-06 19:19:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny26ywv",
          "author": "Dull_Caterpillar_642",
          "text": "Gonna chime in with the usual \"you should be managing changes via infrastructure as code (like a CDK stack which gets run by your build server on merge to main), not shoot from the hip manual CLI commands where you hope for the best\"",
          "score": 1,
          "created_utc": "2026-01-06 19:20:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2h8yd",
          "author": "Seref15",
          "text": "I added $AWS_PROFILE to my shell prompt and change profiles using that.",
          "score": 1,
          "created_utc": "2026-01-06 20:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2jveo",
          "author": "FlyingFalafelMonster",
          "text": "Unless you're creating resources from scratch (that you shouldn't do via AWS CLI anyway) wrong account will result in access denied.\n...Unless you specify cross account access to S3 bucket, upload a file, and it will be inaccessible to the bucket owner account, hahaha.Â ",
          "score": 1,
          "created_utc": "2026-01-06 20:20:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2uoa6",
          "author": "Invspam",
          "text": "the more terrifying thing is that you can actually do stuff with aws cli aside from assuming roles. the default should be no access. first you assume role (you would know which role to what account you are using), then u do stuff. esp to prod. just think of it like sudo.",
          "score": 1,
          "created_utc": "2026-01-06 21:09:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny2v3dl",
          "author": "depeupleur",
          "text": "You can add colors to the top",
          "score": 1,
          "created_utc": "2026-01-06 21:11:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5fyfn",
          "author": "KayeYess",
          "text": "I always use profile-name (and region). I recommend you make it a habit.",
          "score": 1,
          "created_utc": "2026-01-07 05:33:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5pyus",
          "author": "Decent-Economics-693",
          "text": "AWS Vault to rule them all.",
          "score": 1,
          "created_utc": "2026-01-07 06:52:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7dmgp",
          "author": "r0b074p0c4lyp53",
          "text": "I have a custom zsh prompt that shows me the currently \"active\" AWS profile on the right. It also shows me the git status and often of my CWD. Life saver",
          "score": 1,
          "created_utc": "2026-01-07 14:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8shvw",
          "author": "StPatsLCA",
          "text": "I script out everything I'm going to do more than once. Because I'm using temporary credentials I get the account ID from the API and compare it inside of scripts. You do it however you want but I mostly have a bash file with non secret env vars including the ID that gets included in my repos and sourced by scripts.",
          "score": 1,
          "created_utc": "2026-01-07 18:23:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny9s8pf",
          "author": "prolixalias",
          "text": "Just make it part of your prompt, if thatâ€™s possible in your shell. If youâ€™re not using a shell - Iâ€™m not sure.",
          "score": 1,
          "created_utc": "2026-01-07 20:58:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyctcel",
          "author": "Mobile_Plate8081",
          "text": "So first, nothing in default. Second, credentials should be temporary. So I need to authenticate every hour.",
          "score": 1,
          "created_utc": "2026-01-08 06:46:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1xgbf",
          "author": "Suspicious-Kiwi-6105",
          "text": "Don't worry, use [leapp](https://www.leapp.cloud/download/desktop-app)",
          "score": -4,
          "created_utc": "2026-01-06 18:38:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxtlwv",
      "title": "AWS Support Nightmare",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1pxtlwv/aws_support_nightmare/",
      "author": "theHephestus",
      "created_utc": "2025-12-28 15:12:11",
      "score": 15,
      "num_comments": 15,
      "upvote_ratio": 0.69,
      "text": "I am a long time lurker, I always read about AWS support horror stories here and I did not think it was that bad until a few days ago its still ongoing.  TLDR AWS support sucks ass.\n\nI have AWS Business Support +. AWS restricted my account after a security alert. I complied with all the remediation needed, even had to explain that CI/CD activity from GitHub Actions IP != human sign-in location.\n\nNow support is repeatedly insisting I delete EKS node group IAM roles that are actively in use, required for node groups to operate, and properly scoped standard EKS worker/ECR/CNI policies.\n\nThey havenâ€™t provided any concrete justification beyond generic shared responsibility text and a link to how to delete a role. \n\nAnyone been through this? How did you escalate to get an actual security rationale or get restrictions lifted? Any success getting service credits for the delay?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1pxtlwv/aws_support_nightmare/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwdpitm",
          "author": "clintkev251",
          "text": "If the roles were created or modified around the time of the compromise, they probably have these flagged as suspicious. You need to explain to them a few things, 1. The roles were created by you and have been validated as not suspicious, 2. They are currently in use for an active production workload and you will not be deleting them. If they don't listen, reiterate, request they escalate, remind them you consider this to be a false positive.",
          "score": 19,
          "created_utc": "2025-12-28 16:02:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwds2eb",
          "author": "cachemonet0x0cf6619",
          "text": "whatâ€™s stopping you from creating a new role with the same policies and swapping to that?",
          "score": 27,
          "created_utc": "2025-12-28 16:15:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdru7o",
          "author": "pipesed",
          "text": "What are the trust policies for these roles, and can you determine in cloudtrail what assumed these roles in the past?",
          "score": 8,
          "created_utc": "2025-12-28 16:14:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwdoutw",
          "author": "AWSSupport",
          "text": "Hello,\n\nApologies for any frustrations you've encountered.\n\nYou can share your case ID via chat message, so we can pass along your concerns.\n\n\\- Elle G.",
          "score": 13,
          "created_utc": "2025-12-28 15:59:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwe0oj7",
          "author": "Nearby-Middle-8991",
          "text": "Support is always a crapshoot, and AWS isn't the only one. It's a large pool of people, some are experienced, some are not. Some turn off their brains and follow the script blindly.\n\nFor AWS specifically, what worked for me was to check the working hours of whomever had the ticket, and then raise a chat *outside* of those, so I'd get someone new.  Alternatively, depending on your level of support, go light a fire under the TAM. But TAM experience was about as much as crapshoot for me, so idk...\n\nThe script being followed there probably assumes you roles were compromised. That's easy to check on cloudtrail, but can't really be sure without the details. Swapping roles shouldn't be that much trouble...",
          "score": 6,
          "created_utc": "2025-12-28 16:58:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfp8qf",
          "author": "pausethelogic",
          "text": "â€œAWS support sucks ass because I donâ€™t understand what theyâ€™re telling me to doâ€ lol\n\nAWS takes security seriously, so theyâ€™re not going to be super flexible about you continuing to use a role that theyâ€™ve marked as compromised\n\nAre you claiming that theyâ€™re wrong and the role wasnâ€™t compromised or part of a security incident?",
          "score": 6,
          "created_utc": "2025-12-28 21:50:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8nes2",
              "author": "owengo1",
              "text": "Ok but what's the value of a support which can't explain why the action must done, and how to do it so that production workloads are not impacted?  \nI mean, if support is just: \"reset to factory defauts\" ( or whatever scripted instructions list ), you're better off with chatgpt \\[ which will probably ask to see the potentially compromised role and explain why it has to be replaced and how to replace it as safely as possible and how to monitor the replacement went ok or not>.  \n The real question is the value of the support, not if the request they make could be pertinent. Any dumbass can say \"wipe out\", \"block all traffic\", \"revoke all privileges\" etc.",
              "score": 0,
              "created_utc": "2026-01-02 11:53:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwg56yu",
          "author": "coinclink",
          "text": "I understand from your perspective that this seems like they are being dumb, but they are actually doing exactly what they are supposed to do. They haven't been assured that these roles weren't modified to allow the attacker to assume them during your compromise. All they see on their end is timestamps showing that the roles WERE created or modified during your compromise.\n\nDon't be upset with AWS because of your perceived superiority of knowledge. You should have a little humility instead. YOU (or your team) fat fingered and leaked a key and you shouldn't be upset with AWS taking drastic measures to ensure infrastructure security. (it's ok, we've all done it once or twice, I'm not trying to shame you, BUT YOU SHOULD BE ASHAMED, that's what stops you from doing it again!)",
          "score": 4,
          "created_utc": "2025-12-28 23:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8o6l2",
              "author": "owengo1",
              "text": "If support was really \"support\", and not just a scripted todo list, they would explain why there is a problem, the likely cause, and how to remedy it safely. It's very clear OP does not fully understand what happened and it's also very clear support made 0 effort to explain anything, they just had an automated security alert, sent an automated email with hard coded instructions, and they just say \"this must be done\". Even if yes, the action must be done, they prove they have 0 value versus a fully automated script.",
              "score": 1,
              "created_utc": "2026-01-02 11:59:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxal674",
                  "author": "coinclink",
                  "text": "I guarantee they did explain it. Every org has had this happen and they offer very clear and comprehensive explanations in their shared responsibility documentation pages that they link to.",
                  "score": 1,
                  "created_utc": "2026-01-02 18:14:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwib6qq",
          "author": "IridescentKoala",
          "text": "Why won't you remove the roles?",
          "score": 1,
          "created_utc": "2025-12-29 07:20:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwivkls",
          "author": "devguyrun",
          "text": "products/services aside, AWS support is best in class in my opinion, most if not all in the support org are highly technical folks and know what they are talking about, when they don't , they always check in with others that do.\n\none should be smart enough to know when they are not being so....",
          "score": 1,
          "created_utc": "2025-12-29 10:29:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8mk6v",
          "author": "owengo1",
          "text": "This is \"nova\" support I guess",
          "score": 1,
          "created_utc": "2026-01-02 11:46:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwg3e72",
          "author": "isoAntti",
          "text": "They never mention these cases when they say go cloud/aws",
          "score": -2,
          "created_utc": "2025-12-28 23:03:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbljlm",
      "title": "Drift-aware change sets were a great idea, but why does it want to update anything using !ImportValue?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbljlm/driftaware_change_sets_were_a_great_idea_but_why/",
      "author": "jemenake",
      "created_utc": "2026-01-13 07:57:11",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "I was experimenting with AWS' new-ish drift-aware change-sets for CloudFormation to see how they work. I started with an existing stack that had a handful of resources, and *one* I had purposely drifted and *another* one, \"PermissionsBoundary\", I made a change to in the template.\n\nWithout drift-awareness (i.e. the \"old\" way we're all used to), it wanted to modify the one PermissionsBoundary resource that I had modified in the template. *With* drift-awareness, it wanted to modify the changed resource in the template *and* the resource that I had drifted (yay!) but it *also* wanted to modify several other resources. What's even more strange is that drift-aware change sets show you which resources have drifted, and it indicated that these had *not* (see the images). When I examined the changes it was going to make, I saw a bunch of \"changeset:KNOWN\\_AFTER\\_APPLY\" values where the template was using !ImportValue.\n\nWhat baffles me is I thought that values exported from other stacks *cannot be changed* if they're being imported by other stacks. So, if this stack already is importing a value and the new template *continues* to import it, the value cannot change.\n\nI was really hoping that drift-awareness was going to give us something more like 'terraform plan', but, with it flagging anything using !importValue like this, it makes it almost not worth using.\n\nDoes anybody know of a way to disable that behavior? Or maybe shed some light on why they made it work like this?\n\nhttps://preview.redd.it/4llmrwnno2dg1.png?width=1375&format=png&auto=webp&s=94c8f1e8dd7c71da5ec7f3b7b23c7ba3cc8c1a69\n\nhttps://preview.redd.it/g1bsp28oo2dg1.png?width=1455&format=png&auto=webp&s=b3e0f3f47f0352f2f3db7de99325ed32e0619184\n\n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qbljlm/driftaware_change_sets_were_a_great_idea_but_why/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzbn3u1",
          "author": "dr_barnowl",
          "text": "`terraform plan` fetches any inputs that depend on `data` blocks - `!ImportValue` is the equivalent of a `terraform_remote_state` data source ; so perhaps this is an apples / oranges comparison, because CF isn't fetching the exported values until you actually apply the changeset, versus Terraform which does all this at the `plan` stage (and allows you to export the entire plan and apply it later without further reference to data sources).\n\n> I thought that values exported from other stacks cannot be changed if they're being imported by other stacks\n\nIs this the case, or is it only that you can't change their names or remove them from the stack? (I confess, I don't have any handy CF stacksets to play with).",
          "score": 1,
          "created_utc": "2026-01-13 09:01:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzc2nuo",
          "author": "risae",
          "text": "I also noticed that this feature cannot work with false-positive drifts. For example, if a false-positive drift thinks a resource is deleted, it will try to recreate the resource even if it still exists. I personally don't recommend using it until AWS decides to fix drift detection.",
          "score": 1,
          "created_utc": "2026-01-13 11:25:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcav0s",
          "author": "dataflow_mapper",
          "text": "This bit me too. From what I can tell, drift aware change sets treat !ImportValue as opaque at plan time, so they cannot prove the value is unchanged even if the export is effectively immutable while in use. Thatâ€™s why you see KNOWN\\_AFTER\\_APPLY and a proposed update even though nothing will really change. It feels less like a real diff and more like CloudFormation being conservative because it cannot resolve the dependency graph across stacks. I do not think there is a way to disable that behavior today. The only workaround I have seen is minimizing ImportValue usage for things that should never trigger updates, or just mentally filtering those changes out and trusting no-op updates, which is not very satisfying.",
          "score": 1,
          "created_utc": "2026-01-13 12:29:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdr4tv",
      "title": "TIFU by causing an incident",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "author": "belcheri",
      "created_utc": "2026-01-15 18:14:11",
      "score": 13,
      "num_comments": 13,
      "upvote_ratio": 0.78,
      "text": "I really messed up today and caused an incident. I was supposed to enroll an external production account into our prod OU through Control Tower,  which has compliance stacksets and some SCPs that get enforced. I thought I had done my homework - went through all the account resources to make sure nothing would get auto-remediated. But somehow I still managed to screw it up because of a silly reason, there were a few resources sitting in regions we don't govern, and they started throwing forbidden errors everywhere after the enrollment. I fixed it by reverting and unenrolling the account, but the whole thing made me disappointed that how I missed this.\n\nThe thing that really gets me is there's no safety net. When I was a software engineer, I always had QA testing my code before anything touched production. Now every infrastructure change feels like I'm walking a tightrope with no net underneath.\n\nI made the switch from software engineering to cloud operations about two years ago, and honestly, incidents like this make me question whether I made the right call. How do you all handle this? Thank you. ",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzrt5jx",
          "author": "RFC2516",
          "text": "You found a sharpe edge to your organizations Engineering Safety process. Not your fault. Does your organization have a staving environment that truely mirrors prod that the same change could have been rehearsed in?",
          "score": 14,
          "created_utc": "2026-01-15 18:21:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrta00",
          "author": "cddotdotslash",
          "text": "Yes, you could have a better testing environment or a QA OU to use, but the reality is that itâ€™s very difficult to completely mirror the setup of one account via another. Even if youâ€™re religious about defining everything as code, there are still traffic patterns or use cases that might only appear in production.\n\nI think AWS deserves some blame. They have no dry run or audit modes for these kinds of things (including SCPs, account moves, etc.) Itâ€™s been a community request for ages and theyâ€™ve pretty much ignored it.",
          "score": 15,
          "created_utc": "2026-01-15 18:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvysdr",
              "author": "TurboPigCartRacer",
              "text": "Indeed running in a QA OU is really difficult to reproduce since the way its being used it completely different compared to accounts running under production OU. It would be great if there's a simulator of some sorts that can use your cloudtrail logs from the past 90 days or so and validate if the new scp applies the right restrictions or not similar to the iam policy simulator.",
              "score": 1,
              "created_utc": "2026-01-16 08:33:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrtdum",
          "author": "Vast_Manufacturer_78",
          "text": "Welcome to infrastructure, you get not credit when it goes right and you get hell when it goes wrong. Just take it as a learning opportunity, early on I once put multiple KMS keys into deletion status and created new ones because I was moving to fast and didnâ€™t fully read a terraform plan.\n\nI realized rather quickly what happened and made the changes to undo the delete and then import them to the code again, but there were issues with some of the deployments because the alias were removed and had to get recreated.\n\nYou just learn and make notes on things like triple checking your tf plans. For your issue it doesnâ€™t sound like it was broken for too long, but now you will double check all regions where resources are deployed and confirm itâ€™s in an approved region for the organization.",
          "score": 6,
          "created_utc": "2026-01-15 18:22:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0itx",
          "author": "stikko",
          "text": "In this case analyzing say 90 days of CloudTrail data and testing against all the SCP statements would have caught it. \n\nNever underestimate peoplesâ€™ capacity for doing shit you think they shouldnâ€™t be doing. \n\nWhat Iâ€™ve noticed is that a lot of this comes with experience and having made these sorts of mistakes and learned appropriate lessons from them. Being able to mostly completely/accurately answer:\n\n- what could go wrong?\n- whatâ€™s the impact of that thing going wrong?\n- whatâ€™s the likelihood of it going wrong?\n- how can I mitigate that likelihood?\n\nSo whatâ€™s the appropriate lesson to take away here?",
          "score": 5,
          "created_utc": "2026-01-16 00:44:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrzzq3",
          "author": "uuneter1",
          "text": "Iâ€™m not familiar with what you were doing, but step one is documentation. â€œSteps to follow for enrolling new account into OUâ€. Add whatever caveats you need.",
          "score": 1,
          "created_utc": "2026-01-15 18:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx2r6c",
          "author": "DaWizz_NL",
          "text": "I actually think that Control Tower is the biggest issue here. You can hardly test operations beforehand and it orchestrates a lot of things like a black box.",
          "score": 1,
          "created_utc": "2026-01-16 13:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy6up1",
          "author": "TechDebtSommelier",
          "text": "Honestly, this is a very normal cloud ops rite of passage, even if it feels awful in the moment. Control Tower enrollments plus SCPs plus regional drift is one of those setups where everyone learns the hard way that â€œI checked everythingâ€ never really means everything.",
          "score": 1,
          "created_utc": "2026-01-16 16:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrz64b",
          "author": "mikes3ds",
          "text": "To combat issues like that I use terraform. You can see what changes would happen, before applying. Also easier to roll back changes and know what changes cant be rolled back. \n\nOne of the newer advantages of using a Infrastructure as Code (IAC), is when you have a codebase you can use codex or github copilot to search your IAC for potential problems, ask questions. \n\nHaving no Dev/QA sucks however, I always create a smaller env to test my IAC stack.",
          "score": 1,
          "created_utc": "2026-01-15 18:48:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrzjq1",
              "author": "mikes3ds",
              "text": "Also it becomes more like software development when you start using IAC for anything added to your cloud envs.",
              "score": 2,
              "created_utc": "2026-01-15 18:50:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxca8t",
              "author": "AWS_Chaos",
              "text": "This is a serious question: How would Terraform have helped in this particular situation of moving an account into another OU with unforeseen SCP issues?",
              "score": 1,
              "created_utc": "2026-01-16 14:31:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyefsz",
                  "author": "mikes3ds",
                  "text": "Terraform plans can surface drift such as unexpected SCP attachments or policy changes, but the larger benefit is that your organizational structure and guardrails are expressed as code. This makes it far easier to systematically analyze changes for riskâ€”whether through automated checks, policy validation, or even using an LLM to review the Terraform code and plan output to flag potentially impactful SCP conditions you may not have anticipated.\n\nThis approach wonâ€™t eliminate every risk, but it provides far more visibility and proactive safeguards than ad-hoc or manual changes.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:24:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q09vkg",
      "title": "Dynamodb local support for multi-attribute GSI",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q09vkg/dynamodb_local_support_for_multiattribute_gsi/",
      "author": "quantumfy",
      "created_utc": "2025-12-31 10:25:57",
      "score": 12,
      "num_comments": 7,
      "upvote_ratio": 0.94,
      "text": "Dear u/aws ,  \nWhen will support for multi-attribute GSI be available in Dynamodb-local?",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1q09vkg/dynamodb_local_support_for_multiattribute_gsi/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwyh2kh",
          "author": "soundman32",
          "text": "For testing purposes?",
          "score": 1,
          "created_utc": "2025-12-31 18:43:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyja5g",
              "author": "quantumfy",
              "text": "Both testing and development, I have been using it on my local environment for a while, and it was working fine. Now that this new feature has been used, it no longer functions on local",
              "score": 2,
              "created_utc": "2025-12-31 18:54:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyl99w",
          "author": "AWSSupport",
          "text": "Hi there,\n\nI found the following docs regarding multi-attribute GSI in Dynamodb-local: https://go.aws/4q2zaav & https://go.aws/3N8uwJc.\n\nIf this isn't quite it, send us a chat message with further details, so we can pass it along to our team.\n\n\\- Elle G.",
          "score": -1,
          "created_utc": "2025-12-31 19:04:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwyy5jh",
              "author": "Jolly-Phone8982",
              "text": "Hello, \n\nI believe what OP is referring to is the fact that the dynamo-db local docker image hasnâ€™t been updated to support the new multi-attribute GSI feature. \n\nThe resources you sent are correct, however, the dynamo db image on docker hub was last updated 4 months ago and fails to create a table using the new gsi system. \n\nLooks like the dynamo team need to push the latest image to docker so we can start testing and migrating our dbs",
              "score": 6,
              "created_utc": "2025-12-31 20:12:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx0pssl",
                  "author": "kei_ichi",
                  "text": "Unfortunately, I think we will get new â€œAIâ€ features before we get that image updatedâ€¦",
                  "score": 1,
                  "created_utc": "2026-01-01 02:30:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2keo7",
              "author": "redditor_tx",
              "text": "u/AWSSupport Elle, can you please ping the team? It's worrying that the Docker image hasn't been updated in 4 months. I also found [https://github.com/aws/aws-sdk-net/issues/4179](https://github.com/aws/aws-sdk-net/issues/4179)",
              "score": 1,
              "created_utc": "2026-01-01 12:30:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx2nz4q",
                  "author": "AWSSupport",
                  "text": "Hi there,\n\nI've passed along feedback to our devs team for review. \n\n\\- Kay B.",
                  "score": 2,
                  "created_utc": "2026-01-01 13:01:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q17obr",
      "title": "Learning path for AWS Certified Solutions Architect",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q17obr/learning_path_for_aws_certified_solutions/",
      "author": "Oredreim",
      "created_utc": "2026-01-01 16:08:45",
      "score": 12,
      "num_comments": 9,
      "upvote_ratio": 0.93,
      "text": "Hi! I'm a cybersecurity Engineer (more for red team) that wants to be certified with AWS Certified Solutions Architect, and I'm here to ask for videos or documentations or anything that could help me learn to approve this Certification.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q17obr/learning_path_for_aws_certified_solutions/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nx4r07d",
          "author": "Tiny_Durian_5650",
          "text": "I passed my SA Pro exam on the first try mostly by watching video tutorials, I think they were from Linux Academy. The teacher's name was Adrian Cantrill, he sells them on his own site now: https://learn.cantrill.io/",
          "score": 8,
          "created_utc": "2026-01-01 20:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3i406",
          "author": "abofh",
          "text": "Take the sample tests, if you clear them easy, you'll do fine, if you struggle, read the docs more.\n\n\nAlso: red team, not read team",
          "score": 6,
          "created_utc": "2026-01-01 16:15:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3qvml",
              "author": "Oredreim",
              "text": "The autocorrect Xd",
              "score": 1,
              "created_utc": "2026-01-01 17:01:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx3iggy",
          "author": "AWSSupport",
          "text": "Hi there,\n\nThese materials can help you study for our AWS Certified Solutions Architect exam: https://go.aws/3YkgyGI & https://go.aws/3Lm0YaB.\n\n\\- Elle G.",
          "score": 11,
          "created_utc": "2026-01-01 16:17:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3j1ni",
          "author": "sad-whale",
          "text": "r/awscertifications FAQ",
          "score": 3,
          "created_utc": "2026-01-01 16:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3lcjm",
          "author": "xxwetdogxx",
          "text": "Practice tests are a must, I'm a tutorialsdojo guy myself",
          "score": 5,
          "created_utc": "2026-01-01 16:32:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx3n7jz",
              "author": "t90090",
              "text": "TJ is a must for practice exams and their cheat sheets.",
              "score": 3,
              "created_utc": "2026-01-01 16:42:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nx8esr2",
          "author": "skillbubble",
          "text": "If youâ€™re coming from a red team / security background, the biggest shift is thinking in terms of **architecture and trade-offs**, not just services.\n\nIâ€™d recommend starting with:\n\n* **AWS Skill Builder**Â (official, mapped directly to the exam)\n* **AWS Well-Architected Framework**Â â€” especially the Security and Reliability pillars\n* Adrian Cantrillâ€™s Solutions Architect course (very architecture-focused)\n\nWhen studying, try to map each service toÂ *why*Â youâ€™d choose it, not justÂ *how*Â it works. That mindset helps a lot on the exam.",
          "score": 1,
          "created_utc": "2026-01-02 10:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxj5pmx",
          "author": "garathk",
          "text": "Udemy Stephan Maarek course. I used that plus some practice tests and passed by a pretty solid margin. The udemy courses go on sale very frequently. I'm pretty sure I've never paid more than 10 bucks for one. Good platform.",
          "score": 1,
          "created_utc": "2026-01-03 23:48:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qd8kby",
      "title": "Need Help",
      "subreddit": "aws",
      "url": "https://www.reddit.com/gallery/1qd8kby",
      "author": "BodybuilderCandid672",
      "created_utc": "2026-01-15 03:27:21",
      "score": 12,
      "num_comments": 24,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "billing",
      "permalink": "https://reddit.com/r/aws/comments/1qd8kby/need_help/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nznzrmv",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'billing'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+billing).\n\nLooking for more information regarding billing, securing your account or anything related? [Check it out here!](https://www.reddit.com/r/aws/comments/vn4ebe/check_it_first_operating_within_amazon_web/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-15 03:27:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo26w5",
          "author": "Formal_Alps_2187",
          "text": "Youâ€™re comparing savings plan (a yearâ€™s worth of commitment paid up front) to hourly cost for a month. These are two different things.",
          "score": 11,
          "created_utc": "2026-01-15 03:42:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo34xe",
              "author": "Soloeye",
              "text": "Looking at it, the monthly prices are correct.  This isnâ€™t a savings plan problem.  The savings plan was just calculated for 24/7 x 365 @11.5k annually breaking down to $965/month.  \n\nThe thing is the $111 is only calculated at 30ish hours, so ~1 hour per day x 30 days.",
              "score": 3,
              "created_utc": "2026-01-15 03:48:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzo424b",
                  "author": "BodybuilderCandid672",
                  "text": "thanks, but i wont run the shared instance for 24/7 will i get bill for 24/7 or only for number of hours i use?",
                  "score": 1,
                  "created_utc": "2026-01-15 03:54:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo3dgc",
              "author": "BodybuilderCandid672",
              "text": "thanks one doubt if i use less hours in shared instance will it cost less? only cost number of hours i use per month?",
              "score": 1,
              "created_utc": "2026-01-15 03:49:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzo3sv7",
                  "author": "Harsha_7697",
                  "text": "Yes.",
                  "score": 1,
                  "created_utc": "2026-01-15 03:52:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzolvce",
                  "author": "Formal_Alps_2187",
                  "text": "The other person's reply is actually incorrect. Your effective costs are lower but again with savings plans you are paying for commitment. You are saying you will spend this amount. If you pay for savings plans for a year's worth and you use only a day's or a month's worth, you are still liable to pay the remaining amount. Just because it's lower in the total cost, assuming you're running it 24/7 but you use it only for one hour, you are still liable to pay for the remaining 23 hours of commitment. Yes it won't be lower",
                  "score": 1,
                  "created_utc": "2026-01-15 06:01:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzo3orj",
              "author": "BodybuilderCandid672",
              "text": "but is mention per mouth right? total cost per month 965.9 USD",
              "score": 1,
              "created_utc": "2026-01-15 03:51:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzo9ga1",
          "author": "SnooObjections7601",
          "text": "You can also get better pricing comparison here.\n\nhttps://instances.vantage.sh/aws/ec2/g6.2xlarge?currency=USD&duration=monthly&region=us-east-1\n\nJust remember that the spot pricing here is just the average and not 100% accurate.",
          "score": 1,
          "created_utc": "2026-01-15 04:30:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzo1pvq",
          "author": "DecisionOk474",
          "text": "You expect us to confirm all this math by hand on two screenshots we need to zoom in on? Come onâ€¦.\n\nYou arenâ€™t charged for stopped instances.\n\nYou shouldnâ€™t compare a price plan to on demand pricing.",
          "score": -1,
          "created_utc": "2026-01-15 03:39:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoudk2",
          "author": "RecordingForward2690",
          "text": "\"Doing research\" is not the same as \"Asking ChatGPT and then asking Reddit to correct ChatGPT\". If you want to do proper research, start here, read through the various purchase options and take it from there: [https://aws.amazon.com/ec2/pricing/](https://aws.amazon.com/ec2/pricing/)\n\nAlso don't forget to include your EBS cost.",
          "score": -2,
          "created_utc": "2026-01-15 07:13:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q86udm",
      "title": "Using AWS Lambda for image processing while main app runs on EC2 â€” good idea?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q86udm/using_aws_lambda_for_image_processing_while_main/",
      "author": "Longjumping_Jury_455",
      "created_utc": "2026-01-09 12:20:43",
      "score": 11,
      "num_comments": 30,
      "upvote_ratio": 0.92,
      "text": "Iâ€™m building a Node.js marketplace app buy sell (classifieds / second-hand or new style).\n\nThe main backend runs on EC2 . For images, I need to handle resizing, watermarking, and NSFW checks. Image processing is fully async and users can wait before their ad is published.\n\nIâ€™m currently planning to use BullMQ workers on EC2, but Iâ€™m considering offloading only the image processing to AWS Lambda (triggered via S3 or SQS), while keeping the main API on EC2.\n\nIs this a sane / common approach, or does it introduce unnecessary complexity compared to just using EC2 workers? Cost matters more than speed at this stage.\n\nIâ€™d also appreciate any general advice or recommendations around this kind of setup or better alternatives I should consider.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q86udm/using_aws_lambda_for_image_processing_while_main/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nyowbma",
          "author": "sad-whale",
          "text": "Image processing is a classic Lambda use case. Good idea\n\nA quick online search and youâ€™ll find multiple resources that will walk you through setting it up.",
          "score": 17,
          "created_utc": "2026-01-09 23:30:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrplcc",
          "author": "pint",
          "text": "depends on the usage pattern, right? if you have enough spare capacity in the server instances, doing computation there makes sense. if you can seriously downsize the server instance by offloading computation elsewhere, then that makes sense. whether it is lambda or ecs or a different instance, depends on task size and frequency. lambda also have limitations to abide.",
          "score": 5,
          "created_utc": "2026-01-10 11:16:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypf4fx",
          "author": "Hey-buuuddy",
          "text": "I would segment each check to its own lambda, then orchestrate with a step function. Cost explorer will have cost for each segmented by default, easy to see anomalies or delta from benchmark-based expectations.",
          "score": 2,
          "created_utc": "2026-01-10 01:11:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyoy4sz",
          "author": "darc_ghetzir",
          "text": "Microservices for the win! Whatever is easiest for your setup and iteration in the future. I mix and match resources as my heart desires. Build the best system for your needs",
          "score": 1,
          "created_utc": "2026-01-09 23:40:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypmjdd",
          "author": "Prestigious_Pace2782",
          "text": "Iâ€™d move it all to lambda",
          "score": 1,
          "created_utc": "2026-01-10 01:52:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypvtne",
          "author": "LordWitness",
          "text": "> Image processing is fully async and users can wait before their ad is published.\n\nI'm currently planning to use BullMQ workers on EC2, but I'm considering offloading only the image processing to AWS Lambda (triggered via S3 or SQS), while keeping the main API on EC2.\n\n> Is this a sane / common approach, or does it introduce unnecessary complexity compared to just using EC2 workers? \n\n> Cost matters more than speed at this stage.\n\nNo, it's even considered good practice to use lambda for background jobs. It integrates seamlessly with S3; if you work on different file steps across S3 or different prefixes, you don't even need to use SQS. \n\nBesides being faster, it will also be cheaper. With much less configuration \n\nAfter you set up an async Job with lambda for first time, you won't want to go back anymore lol.\n\n> In what cases would lambda not work for your situation?\n\n* Large files: If your code needs to use more than 10GB of memory per file, lambda would not be ideal due to its 10GB memory limit per invocation.\n\n* vendor lock-in: very specific, but some clients tend to switch cloud providers all the time. If you think your company will switch cloud providers, It's best not to use lambda because of the difficulty in applying an \"as-is\" migration to other providers.",
          "score": 1,
          "created_utc": "2026-01-10 02:43:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyr5hyk",
          "author": "SameInspection219",
          "text": "Not a good practice. The best practice is to run everything on AWS Lambda.",
          "score": 1,
          "created_utc": "2026-01-10 08:11:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nytdlvk",
          "author": "Shinroo",
          "text": "We started with lambdas in a step function for our media pipeline and as traffic scaled we eventually moved these workflows into kubernetes. Lambda served us well while we used it!",
          "score": 1,
          "created_utc": "2026-01-10 17:12:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyz50jh",
          "author": "KayeYess",
          "text": "Since you already have an EC2, check usage and see if you can do image processing there as well. If not, using Lambdas is appropriate for this type of usecase. It is not necessarily much more complicated but Lambdas, as short-lived serverless computes, do have some well known caveats that you need to be aware of.",
          "score": 1,
          "created_utc": "2026-01-11 14:27:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyowf07",
          "author": "Kyxstrez",
          "text": "Why not simply use [Cloudflare Images](https://www.cloudflare.com/developer-platform/products/cloudflare-images/)? It supports all things you mentioned and it has a generous free plan. It's not worth running sharp on Lambda, even though I saw companies doing that in the past.",
          "score": 1,
          "created_utc": "2026-01-09 23:30:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyp6eee",
              "author": "pestkranker",
              "text": "Sharp is great, itâ€™s powering our image processing infrastructure. Why do you think itâ€™s not worth?",
              "score": 1,
              "created_utc": "2026-01-10 00:24:09",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyp8sle",
                  "author": "Kyxstrez",
                  "text": "Cloudflare Images handling all things for you as a managed service, and with a generous free plan since last year. All images served from CDN so it's super fast. Alternatively, Bunny Optimizer for just $9.5/month has unlimited usage.",
                  "score": 3,
                  "created_utc": "2026-01-10 00:36:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyp1k17",
          "author": "Akimotoh",
          "text": "I think lambda will end up costing a lot more than if you used small reserved instances or docker containers on ec2 or fargate",
          "score": -1,
          "created_utc": "2026-01-09 23:58:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nypd3w4",
              "author": "coinclink",
              "text": "quick bursts of compute only when you need it is literally what lambda is for, how could something running 24/7 possibly end up being cheaper?",
              "score": 1,
              "created_utc": "2026-01-10 01:00:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nysrnfn",
                  "author": "RecordingForward2690",
                  "text": "Lambda is about 8 times more expensive, on a per-CPU-cycle basis, than a comparable EC2. So if you have a workload that is able to keep an EC2 CPU busy for at least about 12.5% on average, that EC2 may work out cheaper than Lambda. (And to be honest, that's probably the most important incentive to look at that new feature that allows you to run Lambda on your own EC2s.)\n\nIn this particular scenario, the EC2 is already there to handle the API workload. If you add a queueing system so that the work can be queued and handled within the spare cycles that the EC2 will probably have anyway, it won't cost anything extra.\n\nAnd depending on how many images need to be converted and how much CPU that's going to cost, you could even consider spinning up additional EC2 instances once there are sufficient images in the queue for an hours work or so. Running an EC2 at full tilt for an hour to clear the queue will definitely be cheaper than using Lambdas in that case.\n\nAnd that means that the OP now needs to trade a simple Lambda based solution against the engineering effort of developing the other solutions. How much is your time worth, vs. what is the cost difference between the different solutions. Are we talking about dozens of pictures per day or are we talking about millions of pictures per day? In the first case you can have a Lambda-based solution up and running with a few hours of engineering time, but in the latter case it may be worth it spending a few days on engineering the cheapest EC2-based solution.\n\nHeck, you could even think of a hybrid approach. Dump all the work in an SQS queue and let this SQS trigger a Lambda. But the Lambda should have a low concurrency value. You then also add an EC2 Auto Scaling group with a min capacity of zero, and a scale-out policy that's dependent on the amount of messages in the queue. If there's more than, say, 15 minutes worth of work in the SQS queue, you add an EC2. If there's more than, say, 60 minutes worth of work in the SQS queue, you add a few more. Scale-in, all the way back to zero, when the queue depth is consistently below the threshold where a Lambda is cheaper. This could well be the cheapest solution overall, but it also allows you to develop and deploy your solution in stages: Start with the Lambda, add the EC2 functionality later or the other way around.",
                  "score": 2,
                  "created_utc": "2026-01-10 15:26:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nypv7co",
                  "author": "MateusKingston",
                  "text": ">how could something running 24/7 possibly end up being cheaper?\n\n Because you pay premium for that burst capacity. Not saying this would end up being more expensive, probably not as lambda is one of the most cost effective ways to do serverless and serverless is cheaper for people with very bursty workloads, which seems to be his case.\n\nThat being said, serverless can be more expensive, and this \"how could something running 24/7 end up being cheaper?\" is not a valid argument",
                  "score": 3,
                  "created_utc": "2026-01-10 02:39:52",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyq47bc",
                  "author": "256BitChris",
                  "text": "T4.smalls cost like $5/month if you use the 3 year prepaid compute savings plan.\n\nI haven't done the math but the math but I'd wager that's significantly less than a single lambda running for 730 hours per month.\n\nIn addition the ec2 instances can handle multiple requests at a time, whereas your cost scales linearly per each simultaneous invocation.\n\nEc2 tends to save you money as your load increases.  The new interesting thing out of reinvent this year is you can now use ec2 to run your lambdas which feels like the best of both worlds.",
                  "score": 0,
                  "created_utc": "2026-01-10 03:32:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdacvr",
      "title": "For a small to medium business, is there an AWS equivalent of M365 for Business or Google Workspace",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdacvr/for_a_small_to_medium_business_is_there_an_aws/",
      "author": "mzthickneck",
      "created_utc": "2026-01-15 04:54:37",
      "score": 11,
      "num_comments": 24,
      "upvote_ratio": 0.93,
      "text": "From what I understand, there isn't, and AWS would provide mostly IaaS services and have the business host their Windows devices and productivity suites.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qdacvr/for_a_small_to_medium_business_is_there_an_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzoeuuz",
          "author": "Burekitas",
          "text": "AWS has [WorkMail](https://aws.amazon.com/workmail/), but it's very rare to see someone using it. \n\nAmazon itself has its own fleet of Exchange servers, which is likely the largest Exchange setup in the world.",
          "score": 19,
          "created_utc": "2026-01-15 05:08:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzotu2n",
              "author": "justin-8",
              "text": "They've been migrating to 365 for a few years",
              "score": 6,
              "created_utc": "2026-01-15 07:08:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp0ei5",
                  "author": "rudigern",
                  "text": "Year singular",
                  "score": 6,
                  "created_utc": "2026-01-15 08:08:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzohrb2",
              "author": "PelosiCapitalMgmnt",
              "text": "The DoD is probably larger",
              "score": 1,
              "created_utc": "2026-01-15 05:29:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzolu0h",
          "author": "return_of_valensky",
          "text": "Have a look at Zoho mail.\n\nI am admin on many workspace accounts and many of them are looking for alternatives since google keeps jacking the prices up.  Zoho actually is more feature rich than I was aware.  It's a decent service with many of the higher tier offerings like custom domain, file storage, native apps etc for low price.\n\nA basic custom domain email is like $15/year with extra storage compared to $22/month for google.\n\nI have started provisioning some for clients with success.",
          "score": 11,
          "created_utc": "2026-01-15 06:01:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzp3ful",
              "author": "CloudandCodewithTori",
              "text": "Came here to say this ^",
              "score": 2,
              "created_utc": "2026-01-15 08:37:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoduk5",
          "author": "x86brandon",
          "text": "WorkDocs/WorkMail... but they got rid of it.  :(",
          "score": 18,
          "created_utc": "2026-01-15 05:01:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoocs8",
              "author": "kei_ichi",
              "text": "And Iâ€™m really happy with that decision. Those service are very hard to use, have tons of issue, and especially the pricing is somewhat I canâ€™t understand based on the features those services can provideâ€¦\n\nIâ€™m AWS fan boy for IaaS but I prefer Google Workspace for any business (offices) workload.",
              "score": 14,
              "created_utc": "2026-01-15 06:21:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o00ijji",
                  "author": "mezbot",
                  "text": "Im proud of AWS for accepting defeat on those, and Chime as they were inferior products.  End user products have always been inferior, Iâ€™m happy they have shifted back to their core competencies.",
                  "score": 1,
                  "created_utc": "2026-01-16 23:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzq5mrt",
              "author": "deskamess",
              "text": "WorkMail is getting deprecated? They just released a new UI for WorkMail.",
              "score": 3,
              "created_utc": "2026-01-15 13:42:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzokz8q",
          "author": "mjreyes",
          "text": "WordDocs and WorkMail are basically â€œme tooâ€ products that are not usable in the real world",
          "score": 6,
          "created_utc": "2026-01-15 05:54:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoi3pq",
          "author": "PelosiCapitalMgmnt",
          "text": "Just use M365 or GSuite, people are familiar with Microsoft or Google tools and expecting non-technical users to use something else just isnâ€™t worth the hassle. There isnâ€™t much benefit to using an esoteric tool or office suite that has small adoption if it means your helpdesk will be filled with people who need to be re-taught where everything is to become productive",
          "score": 8,
          "created_utc": "2026-01-15 05:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoe78h",
          "author": "jimmyfivetimes",
          "text": "Not the full suite - WorkDocs and WorkMail were their entry level offerings.  I donâ€™t recall whatâ€™s still available - one or both services may have been sunset during to lack of adoption.\n\nAnd then thereâ€™s Chime.",
          "score": 2,
          "created_utc": "2026-01-15 05:03:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzosmc5",
              "author": "criminalsunrise",
              "text": "Chimes getting shutdown. Even our AWS account management team are moving away from it for our meetings.",
              "score": 2,
              "created_utc": "2026-01-15 06:58:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzrj1y0",
                  "author": "mrbiggbrain",
                  "text": "Just to be clear the specific \"Chime\" offering is being shut down, but not the underlying service (Chime SDK) that powers it. So if your using the Chime SDK for your own solutions those should not be effected.",
                  "score": 2,
                  "created_utc": "2026-01-15 17:36:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzpz127",
          "author": "Prestigious_Pace2782",
          "text": "I kinda feel like thatâ€™s like asking â€œwhatâ€™s the best mobile to use for my phone thatâ€™s not android or iOSâ€ \n\nSure there are alternatives. But why not use the thing people already know in a business situation? \n\nIf itâ€™s around values, or dislike of particular companies. Totally understand though.",
          "score": 2,
          "created_utc": "2026-01-15 13:04:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00ho7j",
              "author": "mezbot",
              "text": "Same with Slack/Teams/Gchat as a runner up.  There are alternatives but if you need to collaborate on stuff with clients, customers, etc. itâ€™s those or Gsuite/o365/Confluence for the most part.  The ability to collaborate with tools outside of an org is a huge factor these days above and beyond internal docs/spreadsheets/presentations.",
              "score": 2,
              "created_utc": "2026-01-16 23:16:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpfbjt",
          "author": "devandreacarratta",
          "text": "I used WorkMail for some days. I wasnâ€™t able to attach the mail to my gmail account to download the email.",
          "score": 1,
          "created_utc": "2026-01-15 10:32:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzq5edu",
              "author": "deskamess",
              "text": "Right... its almost intentional. On my pixel, I can pull it via the Exchange option. On gmail-browser, I cannot since it does not seem to have the right options.  \n  \nIs the new UI better than the old one? I am waiting to see some reviews on it but it is a sparsely used product.",
              "score": 1,
              "created_utc": "2026-01-15 13:41:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzqtp6z",
          "author": "mountainlifa",
          "text": "No because Word has been under development since 1980 so why bother reinventing the toothbrushÂ ",
          "score": 1,
          "created_utc": "2026-01-15 15:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrcmfh",
          "author": "ryanrem",
          "text": "As people have already stated, I personally wouldn't recommend Workdocs/WorkMail since AWS is moving away from those services.\n\nMicrosoft is such a tyrant in that service it isn't really worth trying to reinvent the wheel. But if you mostly use AWS services outside of that, I'd suggest going with M365 since Amazon themselves picked Microsoft over Google and it's working rather well for them.",
          "score": 1,
          "created_utc": "2026-01-15 17:07:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvklbh",
          "author": "DrollAntic",
          "text": "Protonmail has a work offering, if you like privacy. Doc and drive tools are not great yet, but under active development.\n\nThere is no reason to combine servers and email / user infrastructure, the most important thing is security and protonmail does that well.\n\nI use it for personal on a paid account, have for years, and it's getting really good. Check it out, see if it meets your needs. \n\nIf you need something to manage workstations and a central domain, that changes things a bit. I'd use Linux personally, with some MDM tools, but not all have that option open.",
          "score": 1,
          "created_utc": "2026-01-16 06:30:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzod2uu",
          "author": "qwer1627",
          "text": "Q for Business, caveat emptor",
          "score": -7,
          "created_utc": "2026-01-15 04:55:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q0zatf",
      "title": "How is the SA market in 2025?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q0zatf/how_is_the_sa_market_in_2025/",
      "author": "No_Mood4637",
      "created_utc": "2026-01-01 08:18:12",
      "score": 10,
      "num_comments": 15,
      "upvote_ratio": 0.7,
      "text": "I'm a Senior Dev who has thinking about jumping to a SA role for the past few years. I did the SAA cert in 2023 and have been building with AWS since 10 years. Europe based.\n\nMy job has become more about managing AI agents now, and it's less fulfilling. In fact even our CDK has become mostly AI driven.\n\nHow do you feel about the future of the SA role in terms of job safety and satisfaction? \n\nThanks",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q0zatf/how_is_the_sa_market_in_2025/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nx1zcwr",
          "author": "mathilda-scott",
          "text": "From what Iâ€™m seeing, SA roles in 2025 are still solid in Europe, but the shape of the job has changed. The pure â€œdesign architecturesâ€ part is more commoditized now, especially with AI-assisted IaC.\n\nStrong SAs are the ones who can translate messy business problems into constraints, trade-offs, security, cost, and org impact - not just draw diagrams. If you enjoy customer-facing work, influencing decisions, and guiding teams (vs. hands-on coding all day), SA can still be satisfying and fairly safe. If you want deep build work again, it may feel like a lateral move rather than an escape from AI-driven workflows.",
          "score": 21,
          "created_utc": "2026-01-01 08:52:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3befq",
          "author": "nope_nope_nope_yep_",
          "text": "SA here.\n\nItâ€™s still a growing and important area, AI can help, but it doesnâ€™t really help with all of the actual sales and finding out what the customer really wants, some customers just donâ€™t know what they really want and need a human to make the decision if what they want is really the right fit for their business needs.",
          "score": 3,
          "created_utc": "2026-01-01 15:38:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx1wvfb",
          "author": "Old_Cry1308",
          "text": "sa still exists but way more pre sales and powerpoint than deep aws. fun depends on company. and yeah hiring is rough lately everywhere",
          "score": 8,
          "created_utc": "2026-01-01 08:25:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1xkqu",
              "author": "No_Mood4637",
              "text": "My intuition is that the SA market would be heavily saturated because of AI lowering the skill requirement of doing architecture work, so what do we need highly paid SA. Same with consultancies in general. I think the big4 have all had big layoffs recently... I'm also thinking about the way AWS in heading, building their own AIs specifically designed for architecture planning which are very easy to use. Is the golden age of SA behind us?",
              "score": -5,
              "created_utc": "2026-01-01 08:33:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nx2di4s",
                  "author": "forsgren123",
                  "text": "It's a common mistake to think that the SA role is only about tech, while in reality the role is customer-facing and requires good soft skills, business acumen, decision maker relationship building, navigating customer org, sales pipeline, identifying and developing opportunities, connecting customers to service teams, public speaking, leading meetings and workshops, etc.\n\nIf you're *only* technical, you will end up being a glorified tech support for the customers' developers - which is being commoditized because developers can ask those technical questions directly from the AI instead.\n\nFrom personal experience I see AI tools only boosting SA work, because you can do research and build demos/pocs much faster now. And who's better at commanding AI than the SA who often has 20 years of experience in the industry, understands the business challenge and constraints, and knows the platform inside out.",
                  "score": 12,
                  "created_utc": "2026-01-01 11:22:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx23iwe",
                  "author": "Jin-Bru",
                  "text": "As a senior Enterprise architect with over 30 years of design experience AI might have broad impact at the development coding level but architecture is often quite specific within the organisation. \n\nThe layers may be fairly constant but the deployment of architecture needs to be customised for each organisation\n\n\nI'd say architecture is still a good place to be but employers are digging deeper into experience than output.",
                  "score": 3,
                  "created_utc": "2026-01-01 09:37:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nx32xde",
                  "author": "CoolBoi6Pack",
                  "text": "Not the case for sure. Most architecture work can't be done by AI because it's too difficult to explain all the business constraints and impacts that we're targeting.",
                  "score": 1,
                  "created_utc": "2026-01-01 14:48:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx1za28",
          "author": "TomRiha",
          "text": "SA role has been watered out over the years. Used to be very senior people who had built and accomplished things in their careers, wanting to help customers. \n\nToday itâ€™s kids chasing promotions, period.",
          "score": 5,
          "created_utc": "2026-01-01 08:51:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx2niql",
              "author": "Sirwired",
              "text": "In my SA Launch Group, there was not a single \"kid chasing promotions.\" We had a Sr. RDS dev, a vet coming from 15 yrs in Army IT, myself (25 yrs in IT infrastructure), and a seasoned K8s/EKS admin.\n\nAnd yeah, I use the hell out of AI tools when slapping together CDK proof-of-concepts, but you can be assured that nothing is going in front of a customer until I understand the why and how of every box on that diagram.",
              "score": 8,
              "created_utc": "2026-01-01 12:57:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx388dh",
                  "author": "TomRiha",
                  "text": "Good for the customers in your Geo in that case.\n\nThough, unless your in a greenfield segment 9 out of 10 customers are gonna be deeper in in their competence then IaC PoCs. With those customers the value is Specialist SA engagements. Generalist/Account SAs need to be able to gain trust of the customers senior technical management to move the needle. This is not done by IaC PoCs. \n\nThis is done by deeply understanding customers domain and challenges. This is something todayâ€™s SAs are not equipped to do, because they are too junior. Itâ€™s also hard to make or deepen those relationships. In the past SAs had fewer customers and spent tons of time onsite with customers. Today itâ€™s more accounts, distributed teams and customers working hybrid making it really difficult.\n\nAll of the above is why SAs are turning more into presales. Partially because in presales PoCs you can get away with IaC PoCs and simple things like that. But also because the customers have changed. Either customers are super deep or not in cloud. The not in cloud ones need to be sold to, they are not self served customers. All those are in cloud already.\n\nWith all the above how do associate SAs make an impact? Well they hunt for stories to their promo doc. Their managers cheer them on because they have KPIs on leveling employees. So Day 2.",
                  "score": 5,
                  "created_utc": "2026-01-01 15:20:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxdm0uj",
                  "author": "mountainlifa",
                  "text": "\"SA launch\". The stuff of nightmares.",
                  "score": 1,
                  "created_utc": "2026-01-03 03:47:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nx2sm07",
              "author": "cjrun",
              "text": "And this is why its important that an SA portrays an aura of some technical credibility.",
              "score": 1,
              "created_utc": "2026-01-01 13:37:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxdmdhl",
          "author": "mountainlifa",
          "text": "With the impending layoffs predicted to hit AWS I can't imagine it's a good place to be. I served from 2017-2022 and it was cutthroat then despite no threat from layoffs, I can't imagine now. I would suspect it's highly sales focused, you'd be better off switching to account executive, at least you get commission.",
          "score": 1,
          "created_utc": "2026-01-03 03:49:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1j3c1",
      "title": "Tools for bulk discovery/ diagram AWS and Azure.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q1j3c1/tools_for_bulk_discovery_diagram_aws_and_azure/",
      "author": "Iconically_Lost",
      "created_utc": "2026-01-01 23:51:32",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "Hey are there any decent tools or scripts that can be used to do a bulk discovery of an AWS account/ Azure tenant for all the objects, the relative configurations/ logical connections (ie DNS name->NLB->TG->ECS)/ links and dump it out to a CSV. If it can do a diagram of all of this, would be a plus.\n\n  \nI did look at cloudcraft, but it only does AWS and does not export to CSV/excel, Hava was meh and cloudockit seems to be very $.\n\n  \nThe ultimate goal is to have a total export of all the objects so this could be manually analyzed for relevance in prep for migrations/audit.\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q1j3c1/tools_for_bulk_discovery_diagram_aws_and_azure/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nx60d7y",
          "author": "Old_Cry1308",
          "text": "cloudockit is pricey but works. maybe try lucidchart, no csv though.",
          "score": 1,
          "created_utc": "2026-01-02 00:04:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx62fu7",
              "author": "Iconically_Lost",
              "text": "Lucid doesn't support Azure, no csv/excel and if I am paying for a tool. I would prefer 1 that does both (AWS+Azure and CSV).",
              "score": 1,
              "created_utc": "2026-01-02 00:16:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx66s8t",
          "author": "Veuxdo",
          "text": "[Resource explorer](https://aws.amazon.com/resourceexplorer/) can dump all of your resources in an account to CSV. This can be a *lot* because it includes IAM and default EC2 resources.\n\nWhat it doesn't do is export relations and interactions between the resources. The tools you mentioned can (ostensibly) do this, but as you noted they are either expensive, limited, or both.\n\nThat said, exporting your resources to CSV and then importing those into a diagram tool is at least half the battle. With those imported resources you can use your understanding of the system to create relevant/interesting perspectives of it. [This article](https://www.ilograph.com/blog/posts/generate-aws-diagrams-with-resource-explorer-and-ilograph/) has a few more details on what that might look like.",
          "score": 1,
          "created_utc": "2026-01-02 00:40:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx6sunt",
              "author": "extra_specticles",
              "text": "Throw that CSV into an LLM with the awslabs diagramming MCP, and it will likely do a great job.\n\nI'll have a try with kiro-cli when I get back to work next week.",
              "score": 1,
              "created_utc": "2026-01-02 02:53:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nx6yf7k",
              "author": "Iconically_Lost",
              "text": "Will have another look, but last time i looked it needed some setup and i was hoping for just something more turn key. Give it access, or use my account and get CSV. \n\nI just need the raw content, diagramming is a optional.",
              "score": 1,
              "created_utc": "2026-01-02 03:28:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q4jupm",
      "title": "Friendly nudge: please donâ€™t let containersonaws.com fade away",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q4jupm/friendly_nudge_please_dont_let_containersonawscom/",
      "author": "ScoreApprehensive992",
      "created_utc": "2026-01-05 11:59:32",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.69,
      "text": "Hey r/aws and AWS folks :)\n\nI noticed there has no been more activity onÂ [containersonaws.com](http://containersonaws.com)Â lately. Itâ€™s such a cool DNS name with a lot of potential for the containers community.\n\nIt would feel a bit petty to let it fade and vanishes and I hope it resumes/keeps activity and stays useful for builders. ðŸ™",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q4jupm/friendly_nudge_please_dont_let_containersonawscom/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxu4u23",
          "author": "Quinnypig",
          "text": "Copyright date hasnâ€™t been updated yet, but itâ€™s still early January. \n\nI wonder who was maintaining this?",
          "score": 6,
          "created_utc": "2026-01-05 16:05:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx0em0",
              "author": "asantos6",
              "text": "It basically died when aws shifted the DA to the AI hype ðŸ˜•\nMiss this site, and the containers from the couch show",
              "score": 3,
              "created_utc": "2026-01-06 00:14:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q74mut",
      "title": "Do Lambda Durable Functions support waiting for network calls?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q74mut/do_lambda_durable_functions_support_waiting_for/",
      "author": "yeaman17",
      "created_utc": "2026-01-08 06:37:38",
      "score": 10,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "Let's say I want to make a POST request to some third party API, and because they're from the stone age and don't support callbacks or polling, the API response takes up to 15 minutes and I need to wait for that. Do durable functions support waiting for a response from these long running network calls without getting billed for waiting?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q74mut/do_lambda_durable_functions_support_waiting_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nycsuww",
          "author": "Mobile_Plate8081",
          "text": "Nope. It is a completely different paradigm. The lambda effectively shuts down on waits so the connection terminates. \n\nIt restarts as soon as the callback token is used.",
          "score": 8,
          "created_utc": "2026-01-08 06:43:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyctkff",
              "author": "yeaman17",
              "text": "Ah bummer, was hoping to find a serverless solution for this issue, but looks like I'll need some long running service to handle making the those calls. Thanks for letting me know!",
              "score": 3,
              "created_utc": "2026-01-08 06:48:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyctpwa",
                  "author": "Mobile_Plate8081",
                  "text": "Offer to fix the service downstream for free. Might be cheaper ðŸ˜—",
                  "score": 3,
                  "created_utc": "2026-01-08 06:50:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nycuac1",
                  "author": "witty82",
                  "text": "If u want to stay in the Lambda paradigm then managed instances could be a somewhat reasonable option here  https://aws.amazon.com/blogs/aws/introducing-aws-lambda-managed-instances-serverless-simplicity-with-ec2-flexibility/\n\nBecause the instances can handle multiple requests it becomes more reasonable to hold connections open for long.",
                  "score": 2,
                  "created_utc": "2026-01-08 06:54:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pyc5zb",
      "title": "Denial of Wallet Via Route 53?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1pyc5zb/denial_of_wallet_via_route_53/",
      "author": "Extra-Moose4828",
      "created_utc": "2025-12-29 04:08:43",
      "score": 9,
      "num_comments": 8,
      "upvote_ratio": 0.8,
      "text": "I am wondering if anyone knows if a Denial of Wallet attack via Route 53 is possible??\n\n  \nThe pricing for Route 53 is $0.40 per million queries per month.\n\n  \nI know that this can be avoided by pointing the DNS records to an AWS resource (as described here: [https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/configuring-route53-for-cost-protection-from-nxdomain-attacks.html](https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/configuring-route53-for-cost-protection-from-nxdomain-attacks.html) ).\n\n  \nBut let's say that's not an option. Is it even feasible for an attacker to send enough DNS queries to rack up a substantial (>$100) bill?? O  \nMy napkin math tells me that to get to >$100, they would need to send 250 million requests in a month. Which I think sounds possible?? \n\n  \nHas anyone ever witnessed such an attack?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1pyc5zb/denial_of_wallet_via_route_53/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwj3ww5",
          "author": "Sirwired",
          "text": "If someone wants to rack up your AWS bill, they are definiteily likely to choose other routes besides R53.  (In the big scheme of things, a $100/mo bill isn't considered \"substantial\" at all.)",
          "score": 27,
          "created_utc": "2025-12-29 11:43:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwiymmo",
          "author": "jmkgreen",
          "text": "They could. Question is why. You wouldnâ€™t likely be causing a DoS and itâ€™s probably the case AWS would raise their shields faster than you would notice.\n\nThatâ€™s not to say something nasty has never happened, I just donâ€™t recall this vector being mentioned as an attack likely to inflict damage when hosted on modern infrastructure.",
          "score": 11,
          "created_utc": "2025-12-29 10:57:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwj4dzj",
          "author": "RecordingForward2690",
          "text": "AWS hosts millions of public domains, but all these domains are hosted on a smaller number of DNS servers (still a large number of servers, because there's multiple servers in each of the 250+ POPs, but probably thousands instead of millions).\n\nDespite things like Shuffle Sharding (see the Builders Library for an explanation), there is a risk that a DoS/DoW attack on one domain impacts other domains. That's why AWS  protects its own infrastructure against these types of attacks by default. AWS calls this protection Shield Standard. \n\n>All AWS customers benefit from the automatic protection of Shield Standard, at no additional charge. Shield Standard defends against the most common, frequently occurring network and transport layer DDoS attacks that target your website or applications. While Shield Standard helps protect all AWS customers, you get particular benefit with Amazon RouteÂ 53 hosted zones, Amazon CloudFront distributions, and AWS Global Accelerator standard accelerators. These resources receive comprehensive availability protection against all known network and transport layer attacks.\n\n[https://docs.aws.amazon.com/waf/latest/developerguide/ddos-standard-summary.html](https://docs.aws.amazon.com/waf/latest/developerguide/ddos-standard-summary.html)",
          "score": 8,
          "created_utc": "2025-12-29 11:47:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjb9dw",
          "author": "Big-Minimum6368",
          "text": "In order to even get to $1000 would take 2.5 billion requests per month. Someone check my math.\n\nThis would not be a worthwhile attack vector in my mind. Our AWS bills we wouldn't notice that outside of an audit",
          "score": 6,
          "created_utc": "2025-12-29 12:41:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwizwth",
          "author": "Wilbo007",
          "text": "In a month thats just under 100 queries per second, for a month certainly possible",
          "score": 1,
          "created_utc": "2025-12-29 11:09:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx3wa93",
          "author": "dub_starr",
          "text": "my company was hit with an NXDOMAIN attack a few years ago. Not AWS DNS provider, but it is a possible thing. if the DNS company didnt work with us, we would have been on the hook for over a million dollars (pretty high profile sites and company). one of the problems we had is that we had a very large legacy backlinking posture, which was very helpful for google ranking at the time. We had some wildcard DNS entries for a lot of the older links that would direct them to a landing page of sorts. That wildcard record was the set of sites that were attacked. With a small botnet, its really easy to get the request counts up high",
          "score": 1,
          "created_utc": "2026-01-01 17:30:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwkkant",
          "author": "eggwhiteontoast",
          "text": "Any query to your domain doesnâ€™t always end up in Route53 or wherever your domain is hosted, DNS records are often cached by numerous DNS servers on the way for faster performance. Unless your TTL is very low, query to your domain will most likely be answered by one of the intermediary DNS servers for eg ISPs DNS.",
          "score": 1,
          "created_utc": "2025-12-29 16:47:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwnmbwa",
              "author": "Extra-Moose4828",
              "text": "Correct, however that doesn't stop an attacker from directly querying AWS's authoritative server directly.",
              "score": 3,
              "created_utc": "2025-12-30 01:59:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q3eofu",
      "title": "Update: Added Terraform state mapping to the open-source AWS cleanup CLI (v1.3)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q3eofu/update_added_terraform_state_mapping_to_the/",
      "author": "DrSkyle",
      "created_utc": "2026-01-04 03:09:14",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 0.76,
      "text": "Hey everyone, back with an update on cloudslash that I posted a few weeks ago in this subreddit.\n\nthe feedback last time was super helpful, but the biggest complaint was valid: â€œwe found a zombie NAT Gateway costing $30/mo, but if I delete it in the AWS Console, terraform state is instantly out of sync.\"\n\nfinding the waste is the easy part. Cleaning it up without breaking your state file is the actual headache. So for v1.3, I went down the rabbit hole of parsing .tfstate files to fix this.\n\n\n\nThe New Features\n\nThe Terraform Bridge Instead of just telling you \"Delete nat-0abc123\", the tool now scans your local .tfstate (read-only), maps the physical AWS ID to the Terraform Resource Address (e.g., module.vpc.aws\\_nat\\_gateway.main), and generates the specific terraform state rm command for you.\n\nIt also auto-backups your state file before recommending changes. This lets you decouple the resource from your state before you nuke it.\n\nDeeper Waste Detection (The Graph) I moved beyond simple CloudWatch metrics to find \"Second-Order Waste\".\n\n\"Hollow\" Load Balancers: ELBs that look healthy, but their targets are in a subnet with no active route to the internet.\n\n\"Vampire\" EBS: Finds volumes attached to instances that have been stopped for >30 days. You're paying storage costs for a dead server.\n\nEKS Ghost Clusters: AutoScaling Groups that are burning cash but only running DaemonSets (like kube-proxy) with zero actual app pods.\n\n\n\nNew Safety Logic (Open Source)\n\nDeleting resources based purely on \"0% CPU\" is risky, so I added these checks to verify DNS and config data before recommending a delete.\n\nDNS Safety Lock: Before telling you to release an Elastic IP, it checks your Route53 zones. If an A-Record still points to that IP, it stops you. (Prevents subdomain takeovers).\n\nLambda Pruning: Finds functions with 0 invocations in 90 days + no code updates in 6 months.\n\nLog Rot: Identifies CloudWatch Log Groups set to \"Never Expire\" (the AWS default), which silently accumulate TBs of storage costs over time.\n\nOrphaned Snapshots: Flags old EBS snapshots where the original volume was deleted months ago, but the backup was left behind.\n\n\n\nThe Repo & License\n\nThe core scanner, TUI, and detection engine are AGPL (Open Source) and free forever. i sell a Pro License ($49 lifetime) for the automation layer (the scripts that fix the Terraform state for you). Since it's just me building this, the sales keep the project alive and allow me to support grassroots orphanages and animal sanctuaries (I post the receipts on X).\n\n\n\nRepo: [https://github.com/DrSkyle/CloudSlash](https://github.com/DrSkyle/CloudSlash)\n\n\n\nParsing nested modules in the state file is tricky, so let me know if you hit any edge cases.\n\n:) DrSkyle",
      "is_original_content": false,
      "link_flair_text": "monitoring",
      "permalink": "https://reddit.com/r/aws/comments/1q3eofu/update_added_terraform_state_mapping_to_the/",
      "domain": "self.aws",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q4049t",
      "title": "Decommissioning Directory Service",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q4049t/decommissioning_directory_service/",
      "author": "cryptoconvos",
      "created_utc": "2026-01-04 20:07:56",
      "score": 9,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "I am attempting to decommission AWS Microsoft AD Directory Service and am unable to get it to release it's tentacles from the VPC. I opened a ticket a couple days ago using the free Support, but haven't heard back. My concern is that it's charging daily for things I'm not using. Has anyone else experienced something like this? Any ideas how I can expedite this or get this deleted faster?\n\nHere's the Ticket I opened:\n\nThe service reports authorized applications, but none are visible or removable via console or CLI. The directory has AWS-owned ENIs that cannot be deleted by the customer. This appears to be a stale authorization record in the Directory Service control plane. Please clear the internal authorization binding so the directory can be deleted.Â \n\nThanks for any comments and energy about this... I just need counsel. ðŸ¤“",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q4049t/decommissioning_directory_service/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxppeec",
          "author": "yourparadigm",
          "text": "ENIs and VPC subnets don't cost anything. Usually these ENIs will get cleaned up automatically, but sometimes they get stuck and need manual cleanup from AWS.",
          "score": 3,
          "created_utc": "2026-01-04 22:59:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxsgbb",
              "author": "cryptoconvos",
              "text": "Great! Thank you.",
              "score": 1,
              "created_utc": "2026-01-06 02:44:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxrt3uf",
          "author": "VictorBaird_",
          "text": "Yeah, that sounds like a stuck control plane issue, not something you can fix yourself. If console and CLI show no authorized apps but the directory still has AWS-owned ENIs, only AWS can clear it. Open a second ticket under billing, reference the original case, and say youâ€™re being charged for a resource you literally canâ€™t delete. That usually gets a faster response and often credits if they admit itâ€™s stuck.",
          "score": 2,
          "created_utc": "2026-01-05 05:58:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxsi5w",
              "author": "cryptoconvos",
              "text": "Perfect. Thank you. I will open the second ticket. Thanks!",
              "score": 1,
              "created_utc": "2026-01-06 02:44:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyz9jmm",
          "author": "cryptoconvos",
          "text": "It took a few days, but the advice here is good. The \"basic\" (free) support sent the request to the right team. After that it was two clicks and an 18 year old Directory Service was gone! Thank you for the solid advice, y'all.",
          "score": 1,
          "created_utc": "2026-01-11 14:52:39",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbiay1",
      "title": "Landing Zone Accelerator vs CfCT vs AFT",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/",
      "author": "Iconically_Lost",
      "created_utc": "2026-01-13 04:52:44",
      "score": 8,
      "num_comments": 22,
      "upvote_ratio": 0.91,
      "text": "Looking at LZA and for the life of me struggling to figure out A) What it does, and B) What are the actual benefits compared to doing AF Customisation or using AF with Terraform?\n\nGoing through the Design and the use for it, it seems to just deploy a standard reference Account settings/networks from AWS's own CDK that you cannot change/modify (yes i know you could prob point InstallerStack.template at your own git).\n\nThe layout and settings all seem to be chosen by AWS, where you have no say it what/config actually is deployed to the Workload accounts.\n\nI know that you are supposed to be able to do some customisation via the cofig files, but per the diagram it seems indicate that these are stored in AWS's git. Not yours.\n\n    Landing Zone Accelerator on AWS aims to abstract away most aspects of managing its underlying infrastructure as code (IaC) templates from the user. This is facilitated through the use of itsÂ configuration filesÂ to define your landing zone environment. However, it is important to keep some common IaC best practices in mind when modifying your configuration to avoid pipeline failure scenarios.\n\nFor those that spun this up, how customizable is this solution/ how easy is it to live with? I know Control Tower is generally a pain, but leadership is dead set on it, so trying to choose the lesser evil.\n\n  \nThe architecture diagram  \n[https://imgur.com/1PLQctv](https://imgur.com/1PLQctv)",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzbws9c",
          "author": "bailantilles",
          "text": "I generally donâ€™t understand the (current) hate for Control Tower.",
          "score": 8,
          "created_utc": "2026-01-13 10:34:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzelsm7",
              "author": "Yoliocaust93",
              "text": "It does nothing special, and it is an opinionated wrapper that doesn't like you messing around with what it does even the slightest (or you get the \"reset landing zone\" error message on your Friday afternoon)",
              "score": 3,
              "created_utc": "2026-01-13 19:29:23",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzbz5wz",
              "author": "Iconically_Lost",
              "text": "ok, then please explain what it does LZA do, and what are the actual benefits compared to doing AF Customisation or using AF with Terraform?",
              "score": 1,
              "created_utc": "2026-01-13 10:55:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcsr36",
          "author": "mallu0987",
          "text": "We use AFT and very happy with it.",
          "score": 3,
          "created_utc": "2026-01-13 14:15:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbgc4s",
          "author": "Yoliocaust93",
          "text": "If you absolutely need to use CT, use AFT.  Using CloudFormation for anything that is not a StackSet is willingly shooting yourself in the foot. I'd also consider Control Tower itself in the same bullshit tier: you can easily replicate the few things it does (except the useless \"Enrolled\" green-friendly UI) with just a few stacksets. If you have some margin, I'd suggest to enable CT, copy the stacksets it creates (or find them online if available), remove CT, redeploy the stacksets for almost the same result without that horrible service",
          "score": 5,
          "created_utc": "2026-01-13 07:56:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nze5zv6",
              "author": "TurboPigCartRacer",
              "text": "yeah AFT is the way to go from the 3 options that are listed by OP, but only if he's willing to go with terraform. However all 3 options are dependent on CT and it all feels like you're trying to manage a block box via IaC where you only have the ability to change some configurations instead of architecting your multi-account setup the way you want it.   \n  \noutside of CT there are some other options, one of them is for example orgformation, however i'm more a cdk person myself so i build my own solution that's build on top of organizations and stacksets. Stackset are really underestimated, but are really powerfull and give you a lot of control and flexibility. I wrote more about Control tower alternatives in [this post](https://towardsthecloud.com/blog/aws-control-tower-alternatives).",
              "score": 0,
              "created_utc": "2026-01-13 18:19:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb3uoj",
          "author": "Ok-Lavishness5190",
          "text": "Please don't go for LZA if you are going to manage a lot of network or IAM resources. It will easily hit 500 resources per CloudFormation stack. Then you will have to look for another option.",
          "score": 4,
          "created_utc": "2026-01-13 06:07:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzb4q19",
              "author": "Iconically_Lost",
              "text": "What do you mean and that resource count is just the LZA stack itself or the actual object I need?\n\nHow does the actual deployment work? ie I need a new account, with specific roles (Azure as SSO source), custom VPC sizing/layout (or from standard ingress patterns ie TGW and or GWLB) but routes are per VPC. \n\nHow does it handle the managing/monitoring of the actual objects that devs deploy via TF/other means?",
              "score": 1,
              "created_utc": "2026-01-13 06:14:33",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nzd8p20",
              "author": "Kaynard",
              "text": "They could still use LZA but manage Networking resources outside of it, many customers do, especially when the Networking team isn't the one managing LZA",
              "score": 1,
              "created_utc": "2026-01-13 15:35:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzf3pjv",
                  "author": "Iconically_Lost",
                  "text": "So are you able to explain how one would go about not managing the network portion via LZA?",
                  "score": 1,
                  "created_utc": "2026-01-13 20:52:42",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzfmdkb",
              "author": "Healthy_Gap_5986",
              "text": "This constraint has been rectified (or improved) in the latest major version. Network resources are now split into several smaller stacks.",
              "score": 1,
              "created_utc": "2026-01-13 22:19:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzfoizs",
          "author": "Healthy_Gap_5986",
          "text": "The LZA sample config is what you're looking at and is chosen by AWS. You are free to write you're own config and deploy the individual resources any way that LZA allows. It does a lot of stuff just straight of the box (e.g. centralised logging, AWS Backup) and honestly, the standard patterns it deploys are pretty much best practise and how you would deploy things like that yourself anyway.\n\nThere's a few things it's missing. Customization support is poor (it can deploy CFN stacks and thats about it), Some Route53 features are lagging behind and some other things but overall the manpower/value ratio is great. Upgrades can sometimes be a bit finicky but the Issues tracker is active and I've only pinged AWS Support for it once in the early days.\n\nConfig can live in S3 or Github or anything CodeConnections supports. You basically never need to touch Control Tower. \n\nI'm surprised at the negative opinion here. I'm a one man band driving our platform and I send maybe 1 day a month on LZA and the rest getting sh1t done.",
          "score": 2,
          "created_utc": "2026-01-13 22:30:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzfsrir",
              "author": "Iconically_Lost",
              "text": "I think the hate maybe because the doco does a terrible job at explaining what it does or more aptly, how.\n\nSo i've figured out the initial push kinda setups the LZA management stack, but the question i cant seem to find is how do we actually deploy workload accounts, and with custom settings (VPCs/subnets/role/etc).\n\nI keep seeing reference to the confg yaml files in the s3. Are these what I customise per account/per job or is it more of a running log of all the config life terraform (all vpc in all accounts, and i just add to the list).\n\nHow do i even trigger the creation of a new account creation? How do i version control what LZA deploys/setings/atrributes because I can see the LZA looks at AWS's git for the actual setup (my diag pic circled).",
              "score": 1,
              "created_utc": "2026-01-13 22:51:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzauwjj",
          "author": "zenmaster24",
          "text": "!Remind me 1 week",
          "score": 1,
          "created_utc": "2026-01-13 05:00:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzauzhd",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 7 days on [**2026-01-20 05:00:57 UTC**](http://www.wolframalpha.com/input/?i=2026-01-20%2005:00:57%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/aws/comments/1qbiay1/landing_zone_accelerator_vs_cfct_vs_aft/nzauwjj/?context=3)\n\n[**3 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Faws%2Fcomments%2F1qbiay1%2Flanding_zone_accelerator_vs_cfct_vs_aft%2Fnzauwjj%2F%5D%0A%0ARemindMe%21%202026-01-20%2005%3A00%3A57%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qbiay1)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-13 05:01:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzcjvbg",
          "author": "kapowza681",
          "text": "I would say the benefit is that itâ€™s opinionated. It does help having everything contained within six config files when handing off to a client, particularly one who is not overly familiar with AWS. It also does a nice job of setting up aggregated logging to a centralized account.",
          "score": 1,
          "created_utc": "2026-01-13 13:26:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzcqbhk",
          "author": "Appropriate_Text_529",
          "text": "If I had the time I would rip out LZA completely and use a combination of AFT, CT, & Cfn.\n\nLZA is a huge PiTA to manage, understand, and puts you in heavy reliance of AWS support. I have mine trimmed down to an account vending machine + default logging & tf iam bootstrapping and itâ€™s still terrible to deal with. It ran fine in Nov but now there was an update and it blows up trying to provision new accounts.\n\nRun",
          "score": 0,
          "created_utc": "2026-01-13 14:02:27",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qco4xm",
      "title": "What is a cluster trying to abstract exactly?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qco4xm/what_is_a_cluster_trying_to_abstract_exactly/",
      "author": "Whatever4M",
      "created_utc": "2026-01-14 14:06:11",
      "score": 8,
      "num_comments": 30,
      "upvote_ratio": 0.7,
      "text": "I feel like there's a ton of redundant abstraction in clusters/ecs and there doesn't seem to be a lot of guidance on this.\n\nWhere I work, we used to have a single cluster, we define multiple services, each service has it's own capacity provider which is backed by it's own ASG. Since you can define as many services as you want and you can share the same capacity providers, you can have any combination of services/capacity providers you want, so what's the point of a cluster exactly? When I ask myself if we should split our services into different clusters, I can't really think of a really strong reason for it, a single cluster already allows me the freedom to do what I want.\n\nAny thoughts on this?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qco4xm/what_is_a_cluster_trying_to_abstract_exactly/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzjmi5y",
          "author": "jbeckha2",
          "text": "Minimizing blast radius and segregating data. Having a dev cluster vs a prod cluster let's you practice and test a change, especially a change to the underlying infrastructure without risk of breaking production.\n\n\nIf you don't have critical uptime needs or customer data to protect, having multiple clusters is probably overkill.Â ",
          "score": 13,
          "created_utc": "2026-01-14 14:35:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjp4p6",
              "author": "Whatever4M",
              "text": "Hmm, the blast radius stuff makes sense but not sure about data segregation, as long as the vpc is shared, the data can be shared as well, right?",
              "score": 0,
              "created_utc": "2026-01-14 14:49:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjvio1",
                  "author": "Sensi1093",
                  "text": "Thatâ€™s why you should have a separate VPC as well.\nIdeally even a separate AWS Account",
                  "score": 14,
                  "created_utc": "2026-01-14 15:20:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzm7yn6",
                  "author": "jbeckha2",
                  "text": "Even with a shared vpc, it can potentially be easier to reason about your network access rules minimizing the chance of making a mistake that exposes customers data. If you do SOC 2 or similar or have customers that require data in certain regions, having separate clusters can make demonstrating that you're compliant much simpler.\n\nBack to your original question about what a cluster abstracts. I think for me it's a way to create a group of things that I can reason about as a group instead of as individuals hopefully simplifying overall configuration and the chance of making mistakes.\n\nI don't know how the services are being split out into different clusters in your environment, so it may not be giving you much benefit. In ours, where we have all of our production services in one cluster and the dev version in another, it makes securing things so much simpler. There's no change I can make in dev that will accidentally expose production customer data.",
                  "score": 1,
                  "created_utc": "2026-01-14 21:42:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjnxn0",
          "author": "menge101",
          "text": "A cluster is abstracting a collection of compute resources as one big clump.\n\nIf you use ECS on EC2, yeah there are separate boxes, but you don't have to think about them, they just provide capacity to the cluster.\n\nHow you use that clump is up to you.",
          "score": 8,
          "created_utc": "2026-01-14 14:43:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjp8d1",
              "author": "Whatever4M",
              "text": "Isn't a capacity provider backed asg doing that same abstraction?",
              "score": 0,
              "created_utc": "2026-01-14 14:49:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzjrk8e",
                  "author": "menge101",
                  "text": "I don't want to claim an authoritative stance here, I'd have to go back to docs to confirm it, and I'm not going to right now. (I have time to comment, not time to research; while working)\n\nBut I believe it is the cluster that has the capacity provider, not the ASG.  The ASG works for the capacity provider in the cluster.\n\nCapacity Providers are properly named as ECS Capacity Providers.",
                  "score": 5,
                  "created_utc": "2026-01-14 15:01:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkkvwc",
                  "author": "asdrunkasdrunkcanbe",
                  "text": "Yes...but you don't have specify the capacity provider when starting tasks in the cluster. You can just say, \"Use whatever is the cluster default\".\n\nSo then you don't need to worry about making sure your tasks are running in the right place. It's a prod cluster, configured to provide capacity within your prod VPC, so when you run your tasks, you know they're in prod and not somewhere else.\n\nIf you were to provide one big cluster with capacity providers per-environment, then there's always the risk that you might start a task intended for staging, using the prod capacity provider.\n\nThe logical separation provided by the cluster prevents that from happening.",
                  "score": 2,
                  "created_utc": "2026-01-14 17:16:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkcder",
          "author": "SpecialistMode3131",
          "text": "As your infrastructure grows, having everything in one big clump becomes unmanageable. So, there are lots of ways to subdivide, including in infrastructure patterns.  Naming each individual business function sanely is pretty smart, won't cost you extra, and futureproofs tons of things you will want to do later, like measuring usage more finely, scaling up or down specific business functions without affecting others, etc.",
          "score": 4,
          "created_utc": "2026-01-14 16:38:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjwn1p",
          "author": "jeff_barr_fanclub",
          "text": "According to [this old presentation](https://d1.awsstatic.com/events/reinvent/2019/CON423-R1_REPEAT%201%20AWS%20Fargate%20under%20the%20hood_No%20Notes.pdf) ECS has a cellular service to manage clusters and tasks, supposedly for both availability and scalability (which makes sense since most many ECS limits are set per cluster). If that's true you'll want to use a new cluster whenever you can rather than sharing one cluster for all your services so that you limit your blast radius during an outage and give yourself higher effective limits. But at the end of the day it seems more like cluster is a failure to abstract away internal backend architecture on their part, rather than an abstraction for our sake.",
          "score": 3,
          "created_utc": "2026-01-14 15:26:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk0pu9",
              "author": "Whatever4M",
              "text": "I see. Thanks for this.\n\nEdit: The presentation says that cluster managers are designed cellularly but it doesn't really say that each cluster is it's cell, so not sure about this.",
              "score": 1,
              "created_utc": "2026-01-14 15:45:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkls28",
                  "author": "jrolette",
                  "text": "I can assure you that each cluster is NOT a cell. The service's cells will contain multiple/many clusters.",
                  "score": 3,
                  "created_utc": "2026-01-14 17:20:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzkuk5n",
                  "author": "jeff_barr_fanclub",
                  "text": "Yeah cluster manager cells are almost certainly multitenant, but if all your services are on one cluster and the cluster manager cell that your cluster is on goes down you're SOL, but if you use multiple clusters they'll probably be on multiple cells your blast radius will be smaller.",
                  "score": 1,
                  "created_utc": "2026-01-14 18:00:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzk8nh6",
          "author": "HostisHumaniGeneris",
          "text": "Here's an alternate perspective. Assume you're using Infrastructure as Code to configure your AWS accounts. You discover that for some reason you need to change your cluster settings. If you're using a single cluster for everything, that means you have to deploy your changes to production without testing them first. If you have a separate dev cluster, you can deploy your updated settings to dev first, verify the changes, and then deploy to prod.\n\nNow, it's probably unlikely that you'll need to change cluster settings very often, but it's a good standard practice to keep completely isolated resources for each environment as it avoids guesswork when making updates.\n\nAs a sorta of related anecdote, I was in an environment where we had separate dev and prod resources, but we ran our \"staging\" workloads in the dev environment for acceptance tests. Nonprod is nonprod, right? Turns out, no. A load test against staging knocked our networking offline because we overloaded a NAT server, which then halted all of our dev work because the dev resources were offline. After that, we made sure we had three entirely separate environments, but we would spin down staging when it wasn't in use.",
          "score": 3,
          "created_utc": "2026-01-14 16:21:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzk9vzu",
              "author": "Whatever4M",
              "text": "We have a completely separate AWS account for staging, it makes a lot of sense to separate your envs by cluster if you don't. I am mostly asking about splitting services per cluster on a single environment.",
              "score": 1,
              "created_utc": "2026-01-14 16:26:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkoulv",
                  "author": "HostisHumaniGeneris",
                  "text": "Ah, if you're already split by environment then the separation matters less. If you're talking about workloads in a single environment, then an ECS cluster is simply an organizational unit. It gives you an abstraction that then target with other resources like IAM policies and capacity providers. In and of itself it doesn't provide any specific isolation.\n\nSo yes, you could run everything in a single cluster and do your isolation via your IAM and capacity provider config. However, clusters are free, so why not keep that logical separation between projects? In my mind it makes it easier to write your configs.",
                  "score": 1,
                  "created_utc": "2026-01-14 17:34:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkcjhk",
          "author": "justin-8",
          "text": "They matter a lot more for ECS on EC2 - different clusters mean you're on separate physical machines for your containers. So noisy neighbours from a dev workload won't affect your prod containers. I'm not sure if fargate is using separate instances or binpacking within a cluster or account - but you're right that the abstraction doesn't do much when you're talking about fargate",
          "score": 2,
          "created_utc": "2026-01-14 16:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzkfh5x",
              "author": "Whatever4M",
              "text": "Since each of our services uses a separate capacity provider/asg, they would be in different instances anyway, no?",
              "score": 1,
              "created_utc": "2026-01-14 16:51:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkusjo",
                  "author": "nekokattt",
                  "text": "generally you don't want separate capacity providers though. The whole point of both EKS and ECS is that you have a pool of compute and a group of things you want to use that compute, and you avoid having to roll an instance per component by allowing the cluster to work out how best to allocate those resources.",
                  "score": 1,
                  "created_utc": "2026-01-14 18:01:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzkmlsm",
          "author": "aviboy2006",
          "text": "Lets take step back and ask what a ECS cluster is actually abstracting ?\n\nThe cluster abstracts administrative scope. Specifically, it serves as a boundary for three things like :\n\n1. Security and Permissions (IAM)\n\nA cluster is the easiest place to draw a hard line. It is much simpler to say like junior devs can only see or edit things in cluster B than it is to write complex IAM policies that filter specific services or capacity providers inside a single cluster.\n\n2. Namespace and Service Discovery\n\nServices inside a cluster can easily find each other via Service Connect or Cloud Map. If you put your prod and stage environments in the same cluster, they share the same namespace and separating them into clusters prevents stage app from accidentally talking to a prod database due to a naming collision.\n\n3. Monitoring and Cost Allocation\n\nWhile you can tag individual services, it is much easier to look at a CloudWatch dashboard or a billing report broken down by cluster name. It gives you a clear view of a specific environment without the noise of 50 other unrelated services.\n\nNow lets see when should you actually split into different clusters?\n\nSince you mentioned a single cluster allows you the freedom to do what you want, you are technically correct. You don't have to split them. However, you should consider a split if you hit these scenarios:\n\n\\- If someone accidentally deletes the cluster or misconfigures a cluster-wide setting, does the entire company go dark, or just one department?\n\n\\- If most teams have at least two clusters like prod and non prod. This ensures that testing a new capacity provider setting in staging can't accidentally starve your Production services of resources.\n\n\\- If your healthcare related service needs to be GDPR or HIPPA compliant, it's much easier to put it in its own cluster with its own dedicated ASG and restricted access than to try to prove to an auditor that itâ€™s virtually separated from your other services like data ingestion or some other operational in the same cluster.\n\nI have three cluster running for prod, qa and dev. currently only one API service is running once its scale or add more services then will think to categories them better as per compliance or security need etc.\n\nSimple terms like analogy then think of ECS cluster as shopping mall. ECS services are individual store like Apple store, Nike or Starbucks store. Cluster become mall management office. You could have one big mall that holds every store in the city, or you could have five smaller malls. Both setups get the job done, but the management experience changes, handle compliances and each area demand.",
          "score": 2,
          "created_utc": "2026-01-14 17:24:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5vloe",
      "title": "Aws lambda concurrency",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q5vloe/aws_lambda_concurrency/",
      "author": "spidernello",
      "created_utc": "2026-01-06 21:26:02",
      "score": 8,
      "num_comments": 12,
      "upvote_ratio": 0.91,
      "text": "I will keep this brief. Given that AWS Lambda can execute multiple concurrent instances of the same function, in a scenario where a FastAPI endpoint runs Python code that performs I/O operations, under what circumstances does it make sense to use asynchronous programming or threading within the Lambda itself?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1q5vloe/aws_lambda_concurrency/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "ny34m25",
          "author": "The-Wizard-of-AWS",
          "text": "Just so weâ€™re clear, Lambda may execute many concurrent executions on your function, but each is a completely isolated instance. There is no scenario where the same function instance is processing multiple requests at the same time. \n\nWith that said, where it may make sense is if there is something else your function can be doing while itâ€™s waiting for the I/O operation to complete. If everything in your code has to be done after the previous thing then there isnâ€™t any value in threading when running in Lambda. \n\nItâ€™s also worth noting that you probably only have a single thread available unless you crank up the memory on the function.",
          "score": 19,
          "created_utc": "2026-01-06 21:55:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5ka8f",
              "author": "itsflowzbrah",
              "text": "Adding to this, for fastAPI (all?) frameworks can do both async and threading. So if you have 1 lambda function that makes 2 downstream API requests. You can make those 2 downstream calls asynchronously without needing to bump the memory of the function.",
              "score": 1,
              "created_utc": "2026-01-07 06:06:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny30rxt",
          "author": "RecordingForward2690",
          "text": "If the Lambda is called from the API Gateway, then the event that triggers the Lambda is a single API Gateway request. Usually, but not always, handling such a request is a series of dependent steps that have to be executed in order. It doesn't make sense to use asynchronous/threading in that case.\n\nBut I've written a complex Lambda in the past that was triggered by an API Gateway request, and needed to do a bunch of things, including querying two DynamoDB tables, updating a different DynamoDB table, and making a bunch of API calls back to the API Gateway. (This one was using wss:// so I had to make multiple API calls to the API Gateway to send the wss:// responses to a variety of other channels.) By carefully applying async constructs in the code (using NodeJS Promises and async/await in my case) I was able to run a whole bunch of calls in parallel, significantly reducing latency and cost.\n\nIf your Lambda is triggered from an SQS queue, for instance, then the event that triggers the Lambda holds multiple SQS messages which can usually be handled independently. Writing your code in an async/parallel fashion is pretty much a no-brainer in that case.",
          "score": 6,
          "created_utc": "2026-01-06 21:37:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny388sb",
          "author": "llima1987",
          "text": "Note first that a FastAPI server usually will handle multiple requests concurrently, and that's not gonna happen on lambda. Each FastAPI instance will handle exactly 1 request at a time, so you loose most of the async time usage gains. The second thing is that lambda ties CPU cycles to memory allocation. So unless your end point needs to wait on a lot of IO at the same time, your running time will probably be mostly spent waiting for your turn to use the CPU. Lastly, async stuff comes at a cost, as using FastAPI does. Running FastAPI on lambda means you'll likely gonna spend most of your function running time doing a lot of internal mumbo jumbo of FastAPI that's actually irrelevant in lambda's context.",
          "score": 4,
          "created_utc": "2026-01-06 22:12:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny3w3u9",
              "author": "solo964",
              "text": "Mumbo jumbo.",
              "score": 1,
              "created_utc": "2026-01-07 00:12:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny3weok",
                  "author": "llima1987",
                  "text": "Thanks, I did get in doubt about this.",
                  "score": 1,
                  "created_utc": "2026-01-07 00:14:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny2ze2b",
          "author": "jason120au",
          "text": "If the Lambda itself could be processing hundreds of files in an execution it makes sense  make this threaded as you can process more than one file at a time.",
          "score": 3,
          "created_utc": "2026-01-06 21:31:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny30mgy",
          "author": "InsolentDreams",
          "text": "You definitely can thread on a lambda we do some multi multi concurrency in one of our setups.  We have a sqs to help us fan out and launch sometimes hundreds of lambdas at the same time and in each one of those anywhere between 10-50 threads to do some work collecting and processing data.\n\nYou have to try it and dial it in though because your workload will only scale so much in your lambda with so much concurrency per lambda before it greatly affects your processing time.  It really depends what you are doing.  The fan out and parallelism in our setup is configurable with an env var and in some case is dynamic based on some conditions which change over time.",
          "score": 2,
          "created_utc": "2026-01-06 21:37:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny36g1q",
          "author": "pint",
          "text": "almost negligible difference.\n\nif you use def, fastapi will create a thread, which is unnecessary, and a minor performance inefficiency. probably not noticeable.\n\nasync is beneficial if you have logic that is asynchronous in itself, e.g. you want to use gather.\n\ni always use async in lambdas, even if the internal logic is not async, exactly to avoid thread creation.",
          "score": 2,
          "created_utc": "2026-01-06 22:03:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny39eub",
          "author": "Gasp0de",
          "text": "If your lambda waits for I/O from multiple sources it always makes sense to do that concurrently. It will make your request faster giving your customers lower latency and you will be billed for less execution time.",
          "score": 2,
          "created_utc": "2026-01-06 22:17:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3l6vn",
          "author": "Crossroads86",
          "text": "The circumstances on lambda are not different than on other systems. You can always scale your application horizontally for instance just starting a lot of containers in parallel. But you would usually do this in response to a lot of incoming requests.\n\nIf you application then needs to do a lot of IO while handeling the request and you want them do be habdeled in parallel or you have business logic that can run while you wait for the IO to finish, then you should use async.",
          "score": 2,
          "created_utc": "2026-01-06 23:15:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7ew1d",
          "author": "TechDebtSommelier",
          "text": "It makes sense when a single Lambda invocation needs to wait on multiple I/O bound operations at the same time such as calling several external APIs or databases and you want to overlap that waiting instead of doing it sequentially. Async or limited threading can reduce per invocation latency and cost, but it does not help CPU bound work and does not replace Lambda level concurrency for scaling across requests.",
          "score": 2,
          "created_utc": "2026-01-07 14:35:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3ghv6",
      "title": "Changed MFA device",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q3ghv6/changed_mfa_device/",
      "author": "Valuable-Cap-3357",
      "created_utc": "2026-01-04 04:35:38",
      "score": 8,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "Hi, I have changed the MFA device for my root login and I am unable to login. I have tried the steps provided and it's only generating AI answers with no support.\n\nI raised a case and still the response is to go back to that same page which generated AI response.\n\nThere is an alternative login process where email and contact is used. I get email OTP but no call on the registered contact.\n\nI am stuck, any suggestions.\n\n",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1q3ghv6/changed_mfa_device/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nxt3uwh",
          "author": "dataflow_mapper",
          "text": "This is one of the few cases where AWS support can actually fix it, but it is slow and painful. Root MFA issues usually require identity verification and manual review, and the phone call not coming through is a common blocker. Make sure the contact number is correct with country code and try during business hours for the region. If the case keeps looping, replying clearly that this is a root account MFA lockout sometimes gets it escalated to a human. Unfortunately there is no workaround or bypass, and anyone claiming there is is wrong.",
          "score": 3,
          "created_utc": "2026-01-05 12:42:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxt60gu",
              "author": "Valuable-Cap-3357",
              "text": "Yh I am going round and round for a week. Even here 2 people from aws team posted and gave conflicting information. This is such a pain. I was using Microsoft authenticator and they have no backup codes unlike google authenticator. I think that would have been better.",
              "score": 1,
              "created_utc": "2026-01-05 12:57:18",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nxu25s0",
              "author": "AWS_Chaos",
              "text": "The only work around I know is if it is part of an Organization and you have setup a delegated account. Those users I think could make the change. But this is NOT a common setup and more for Enterprises.",
              "score": 1,
              "created_utc": "2026-01-05 15:52:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxkm46y",
          "author": "AWSSupport",
          "text": "I understand the confusion when updating your MFA.\n\nSince you've already reached out and created a case, send the case ID over chat and we can take a closer look.\n\nIn the meantime, we have a video walkthrough that can provide more guidance: http://go.aws/reset-mfa-device-yt \n\n\\- Randi S.",
          "score": 2,
          "created_utc": "2026-01-04 04:44:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxkv4u9",
              "author": "Valuable-Cap-3357",
              "text": "I have seen this video using IAM, there is no user who has contact access apart from root.",
              "score": 0,
              "created_utc": "2026-01-04 05:47:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxkx9zz",
                  "author": "AWSSupport",
                  "text": "Hi there,\n\nWe've sent you a private chat. \n\n\\- Reece W.",
                  "score": 1,
                  "created_utc": "2026-01-04 06:03:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxtenrm",
          "author": "latent_signalcraft",
          "text": "root MFA lockouts are one of the few cases where automation really does not help. if the alternative contact flow is failing the only real path is continued escalation with AWS support and explicitly stating root access is blocked due to MFA change. in my experience it can take time but a human review is eventually required since there is no self service recovery once root MFA breaks.",
          "score": 1,
          "created_utc": "2026-01-05 13:50:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycq7ts",
          "author": "Valuable-Cap-3357",
          "text": "Got resolved. Got a call back and they removed the old MFA device. Got access back.",
          "score": 1,
          "created_utc": "2026-01-08 06:22:12",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzj2kg",
      "title": "How does RDS use NVMe instance store?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1pzj2kg/how_does_rds_use_nvme_instance_store/",
      "author": "RecordingForward2690",
      "created_utc": "2025-12-30 14:10:20",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.84,
      "text": "I have a transactional MSSQL DB that currently runs on a db.z1d.2xlarge RDS instance. From the metrics we know that this database is overprovisioned, and we are looking at smaller (cheaper) instances, possibly a db.r7i.xlarge.\n\n(Note that there is a discrepancy in the documentation: [This page](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.InstanceClasses.html) claims that MSSQL SE supports a db.r7i.xlarge, while [this page](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.Support.html) claims it doesn't.)\n\nBased on the CW Metrics and DB Insights I can pretty much predict how the DB will behave regarding CPU, memory, network and EBS I/O when switching instance types. However, the z1d.2xlarge also has 300 GB of NVMe SSD instance store, and I have no clue whether this is used, what for, and whether this will impact performance if I switch to an instance type without instance store. It doesn't seem like there are CW Metrics available for starters, and I also can't find any documentation on it. Does anybody know of a way to understand what's going on with this storage?\n\nThe problem is also that this is a production database that runs 24/7. Due to it being Multi-AZ, switching instance types requires quite a bit of downtime that we have to schedule in advance. This severely limits the ability to experiment. I do have a test environment but I don't have a mock load generator that is representative of the workload.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1pzj2kg/how_does_rds_use_nvme_instance_store/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwqjvwg",
          "author": "earl_of_angus",
          "text": "eta: I originally read MSSQL as MySQL - optimized reads doesn't apply.  Instead, with MS SQL you can check where the tmpdb is stored to see if it's on the nvme drive or ebs.\n\nFor uses of nvme, out of the box defaults will enable Optimized Reads: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-optimized-reads.html#rds-optimized-reads-use-cases (TL;DR: temp tables etc)\n\nFor CloudWatch, take a look at the *LocalStorage metrics e.g., ReadThroughputLocalStorage - https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-metrics.html (ctrl-f LocalStorage)",
          "score": 3,
          "created_utc": "2025-12-30 14:45:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwqyi8k",
              "author": "RecordingForward2690",
              "text": "Thanks. Your response however, throws up more questions.\n\nFirst, I don't have any \\*LocalStorage metrics in CloudWatch. At all. Not even the FreeLocalStorage or FreeLocalStoragePercent, which I would expect to be there even if instance store was not used at all. Any idea?\n\nSecond, [this documentation](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.InstanceStore.html) suggests that instance store is automatically used for tempdb usage, but only on db.m5d, db.r5d and db.x2iedn instances. db.z1d instances are not listed. Would that be an error in the documentation, or does that mean that I would actually need to put in extra work (which I didn't do) to start using the instance store? I'm not familiar with MSSQL at all. Is the disk location of the tempdb something that I can view using SQL Studio or something?",
              "score": 1,
              "created_utc": "2025-12-30 15:58:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwr28wn",
                  "author": "earl_of_angus",
                  "text": "> Is the disk location of the tempdb something that I can view using SQL Studio or something?\n\nThe tempdb is an object in SQL Server Management Studio (under system databases) that can be right-clicked & then view properties, or you can run a query like:\n\n\n    SELECT name AS file_name, physical_name AS physical_location\n    FROM sys.master_files\n    WHERE database_id = DB_ID(N'tempdb');",
                  "score": 2,
                  "created_utc": "2025-12-30 16:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwrncnn",
          "author": "Competitive_Two6205",
          "text": "RDS for SQL Server uses instance store to host the TempDB. You should monitor your TempDB usage to assess the impact to move it to off NVMe. For example if your databases are using Read Committed Snapshot Isolation (RCSI) your performances will likely be affected. I'm happy to provide more details",
          "score": 2,
          "created_utc": "2025-12-30 17:54:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwqoky9",
          "author": "InterestedBalboa",
          "text": "Do yourself a favour and put together a plan to get off MSSQL, itâ€™s not cloud native, expensive and has limitations the competition doesnâ€™t have.\n\nIf youâ€™re a â€œMicrosoft shopâ€ then you have bigger problems to worry about and you can disregard said advice.",
          "score": 0,
          "created_utc": "2025-12-30 15:10:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwquxnc",
              "author": "RecordingForward2690",
              "text": "Wish I could. This is a 3rd party product that requires 3 MSSQL databases, and something like 69 Windows EC2 instances (with MS Service Fabric) to run properly in our Prod environment, with our workload. All authentication is done through AD. Ripping out the DB technology and replacing it with something else is not going to happen.\n\nThis is also the first Microsoft-based workload that we're hosting in AWS. All other workloads so far were either developed in-house (serverless) or Linux-based. So we're learning a lot about Microsoft technology as we go along.\n\nThe good news is that all the integrations that we built around this product are all AWS-native, with DynamoDB, SQS/SNS, EventBridge, Lambda, ECS and whatnot.",
              "score": 3,
              "created_utc": "2025-12-30 15:41:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pze3rs",
      "title": "Using a presigned url in 2025 to upload file is a good enough solution to protect from malware files and allowing only images?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1pze3rs/using_a_presigned_url_in_2025_to_upload_file_is_a/",
      "author": "xSypRo",
      "created_utc": "2025-12-30 09:49:02",
      "score": 8,
      "num_comments": 24,
      "upvote_ratio": 0.75,
      "text": "Hi,\n\nI was looking for the answer online and came across this - [https://www.reddit.com/r/aws/comments/zmbw4h/enforce\\_content\\_type\\_during\\_upload\\_with\\_s3\\_signed/](https://www.reddit.com/r/aws/comments/zmbw4h/enforce_content_type_during_upload_with_s3_signed/)\n\n  \nThis post from 3 years ago, and the answer was no. 3 years ago AWS S3 only allowed to enforce content type header, which is a joke for a serious attacker.\n\n3 years later, is there a solution?\n\nI am working on an app of my own that allows users to upload file, verifying the files are legit is a big overhead that I want to take off my mind. Presigned url is an easy solution or should I skip it and do it on my server?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1pze3rs/using_a_presigned_url_in_2025_to_upload_file_is_a/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nwpfvzj",
          "author": "The_Startup_CTO",
          "text": "AWS GuardDuty can scan files for Malware, and you can configure the bucket with a deny policy for any file that doesn't have the tag from GuardDuty that it's clean.",
          "score": 52,
          "created_utc": "2025-12-30 09:56:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwro2cu",
              "author": "thegeniunearticle",
              "text": "But - GD ain't cheap.\n\nS3 bucket scanning adds up.",
              "score": 4,
              "created_utc": "2025-12-30 17:57:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwslvgh",
                  "author": "Zenin",
                  "text": "Have you checked the pricing recently on GD for this?  It dropped 85% last Feb, making it *much* more reasonable.\n\n[https://aws.amazon.com/about-aws/whats-new/2025/02/amazon-guardduty-malware-protection-s3-price-reduction/](https://aws.amazon.com/about-aws/whats-new/2025/02/amazon-guardduty-malware-protection-s3-price-reduction/)",
                  "score": 5,
                  "created_utc": "2025-12-30 20:36:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwrqqte",
                  "author": "The_Startup_CTO",
                  "text": "There are alternatives, though I would recommend to do the math. So far, at none of the companies I've worked with, the cost for the malware scan was anywhere near something that would justify spending the working hours of engineers to find a cheaper solution.",
                  "score": 4,
                  "created_utc": "2025-12-30 18:10:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwroc07",
                  "author": "techypaul",
                  "text": "There are self made options, or one from the marketplace which is pretty cheap (Sophos based).",
                  "score": 1,
                  "created_utc": "2025-12-30 17:59:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpg2xs",
          "author": "steveoderocker",
          "text": "The best way to do it is to use something like event notifications and use lambda to actually verify the file contents. Eg https://devsecopssourav.hashnode.dev/content-type-validation-during-file-uploads-to-an-aws-s3-bucket",
          "score": 17,
          "created_utc": "2025-12-30 09:58:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwphbp7",
              "author": "RecordingForward2690",
              "text": "This was my idea as well. And you can combine it with the tip from u/The_Startup_CTO: After the Lambda has verified that the file contents matches the Content-Type header AND the Content-Type header is allowed, you add a tag that indicates the file is clean. The S3 bucket then has a resource policy with a Deny on any GetObject API call when the tag is not present. Simple, elegant, minimal code changes necessary.",
              "score": 15,
              "created_utc": "2025-12-30 10:09:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nwq4w7r",
              "author": "The_Startup_CTO",
              "text": "I don't think that this would work. You can already limit the presigned url to a specific content-type, so verifying with the lambda afterwards doesn't give you anything extra. The actual danger isn't the content-type, though, that's just metadata that hints to the browser how it should try to open the file. You can still upload any combination of bytes and just give it whatever content-type will be accepted. But the file will still have the same malware in it.\n\nThat's why the check via GuardDuty is so important: It checks the actual content of the file, not just some metadata associated with it.",
              "score": 2,
              "created_utc": "2025-12-30 13:18:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwqjigu",
                  "author": "RecordingForward2690",
                  "text": "Read the blog post to the end. The example uses python-magic to actually determine the type of file from the content. This is then compared to the Content-Type header. So it will even detect the situation where a hacker uploads a file in an allowed content format, but uses a different (but also allowed) Content-Type header.",
                  "score": 1,
                  "created_utc": "2025-12-30 14:43:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwpg57w",
          "author": "nemec",
          "text": "nothing's changed. AWS doesn't validate your content. You can't trust what the client uploads, all you can do is validate after the upload is finished, before the new content is available to others.\n\ne.g. virus scanning: https://docs.aws.amazon.com/guardduty/latest/ug/gdu-malware-protection-s3.html",
          "score": 13,
          "created_utc": "2025-12-30 09:58:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwppxls",
          "author": "texxelate",
          "text": "Presigned URLs are not intended to solve this problem. So,  no. Youâ€™ll need to analyse the file after it has been uploaded.\n\nYou can do this easily by configuring an SQS queue which invokes a Lambda, or something which others have suggested.",
          "score": 5,
          "created_utc": "2025-12-30 11:27:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpudqw",
          "author": "martinbean",
          "text": "A pre-signed URL just lets a user upload a file to your S3 bucket for a short period of time. It does absolutely **zero** checks on the type of file being uploaded.",
          "score": 5,
          "created_utc": "2025-12-30 12:04:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpu857",
          "author": "raja4net",
          "text": "If you donâ€™t want to use GuardDuty, you can use [ClamAV](https://aws.amazon.com/blogs/developer/virus-scan-s3-buckets-with-a-serverless-clamav-based-cdk-construct/) to scan for malware. No built-in solution to restrict upload of images only.",
          "score": 4,
          "created_utc": "2025-12-30 12:02:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx2stqu",
          "author": "TopSwagCode",
          "text": "Presigned urls isnt protection for anything. Its just a easy way to upload files without them touching your server first. If you want to scan items you either need to scan them before upload on server or scan afterwards in bucket. There are tons of options to do so.",
          "score": 2,
          "created_utc": "2026-01-01 13:39:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpok5e",
          "author": "magnetik79",
          "text": "You have to programmatically verify the content of the upload. The presigned S3 URL system is solid, what you do with the content beyond that is your job to implement.",
          "score": 1,
          "created_utc": "2025-12-30 11:15:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwq7qyi",
          "author": "Toastyproduct",
          "text": "No built in solutions. Best method is to build this into the backend. If the files are going to be limited in size and number then uploading to your backend and then placing in the bucket is still best. For images I recommend sanitizing using a reformat with some tool to a common file type and wiping out metadata. \n\nIf the files are more frequent or bigger then a â€œinboxâ€ location and then a lambda might be better than directly through backend. Just depends on your scale and resource sizing.",
          "score": 1,
          "created_utc": "2025-12-30 13:36:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwsn86a",
          "author": "Zenin",
          "text": "You can't trust any data you (or a service you control) has actually seen.  There's no client-side solution to this problem; You *have* to accept the data first and then scan it however you choose.  And you have to scan *all* of it, not just a handful of bytes at the start to workout the file magic number type.\n\nGuardDuty is the obvious choice and after Feb's price cuts is very reasonably priced.  Anything else you do is going to almost certainly cost you more.  More resources, more man hours, more risks, more support issues, more outages.",
          "score": 1,
          "created_utc": "2025-12-30 20:43:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7iexe",
      "title": "Open-source CQRS + Event Sourcing framework for AWS Serverless (Lambda, DynamoDB, Step Functions)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q7iexe/opensource_cqrs_event_sourcing_framework_for_aws/",
      "author": "mbc-net",
      "created_utc": "2026-01-08 17:44:24",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I've been building enterprise SaaS applications on AWS and kept re-implementing the same patterns. So I open-sourced a framework that handles CQRS and Event Sourcing on AWS serverless.\n\n# AWS Architecture\n\n* **Lambda** \\+ API Gateway for compute\n* **DynamoDB** as event store (with Streams for event processing)\n* **Step Functions** for workflow orchestration\n* **RDS/Aurora** for read models (complex queries)\n* **Cognito** for authentication\n* **SNS/SQS** for async messaging\n* **CDK** for infrastructure as code\n\n# Key Features\n\n* CQRS pattern with automatic DynamoDB â†’ RDS synchronization\n* Multi-tenant data isolation out of the box\n* Optimistic locking for concurrent updates\n* Full audit trail via event sourcing\n* Local development with DynamoDB Local + LocalStack (no AWS costs during dev)\n\n# Quick Start\n\n      npm install -g @mbc-cqrs-serverless/cli\n      mbc new my-app\n      cd my-app && npm install\n      npm run build            # Build the project\n      npm run offline:docker   # Start local AWS services\n      npm run migrate          # Run database migrations\n      npm run offline:sls      # Start API server\n      # Running at http://localhost:4000\n\nBuilt on NestJS + TypeScript for type safety and familiar patterns.\n\n# Links\n\n* ðŸ“š Docs: [https://mbc-cqrs-serverless.mbc-net.com/](https://mbc-cqrs-serverless.mbc-net.com/)\n* â­ GitHub: [https://github.com/mbc-net/mbc-cqrs-serverless](https://github.com/mbc-net/mbc-cqrs-serverless)\n* ðŸ“¦ npm: [https://www.npmjs.com/package/@mbc-cqrs-serverless/core](https://www.npmjs.com/package/@mbc-cqrs-serverless/core)\n\nCurrently at v1.0.17, battle-tested in production. Looking for feedback from the AWS community!",
      "is_original_content": false,
      "link_flair_text": "serverless",
      "permalink": "https://reddit.com/r/aws/comments/1q7iexe/opensource_cqrs_event_sourcing_framework_for_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nyoz9fy",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-09 23:46:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nypl3ez",
              "author": "mbc-net",
              "text": "Thank you so much for the kind words and for sharing your approach!\n\nI checked out the Postgres Connector documentationâ€”the event-driven automation using logical decoding/triggers to bridge transactional and analytical workloads is a really elegant approach. The emphasis on enterprise-grade reliability and seamless failover is impressive.\n\nWe took a similar philosophy with MBC CQRS Serverless but optimized for the AWS serverless ecosystemâ€”using DynamoDB Streams to capture write events and sync to RDS for complex queries. This gives startups and mid-sized teams CQRS benefits without managing infrastructure like EKS clusters.\n\nSeeing established platforms validating the CQRS/Event Sourcing pattern for mission-critical enterprise workloads is truly inspiring!\n\nWould love to stay connected and exchange ideas.",
              "score": 1,
              "created_utc": "2026-01-10 01:44:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5m3kx",
      "title": "CloudSlash v1.3.3: We removed the paywall. Terraform Remediation & Headless mode are now free.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q5m3kx/cloudslash_v133_we_removed_the_paywall_terraform/",
      "author": "DrSkyle",
      "created_utc": "2026-01-06 15:46:09",
      "score": 7,
      "num_comments": 0,
      "upvote_ratio": 0.67,
      "text": "Hey r/aws, DrSkyle here again.\n\nA few weeks ago, I posted CloudSlash, a CLI to find â€œzombie\" infrastructure (unused NAT Gateways, detached EBS, etc.) using graph topology rather than just CloudWatch metrics.\n\nThe feedback was pretty clear: you liked the tool, but hated that the Terraform Remediation (the script that fixes your .tfstate) was locked behind a paid license.\n\n**I heard you. andd v1.3.3 is a hard pivot.**\n\nIâ€™ve stripped out all license keys, payment links, and \"Pro\" checks. It's completely free now.\n\n* **Unlocked \"State Doctor\":** The feature that maps AWS IDs back to Terraform resource addresses and generates terraform state rm commands is open to everyone.\n* **Unlocked Headless Mode:** You can now run cloudslash scan --headless in your CI/CD pipelines without a key.\n\nThe graph engine we built is really cool (it builds a DAG of your network to mathematically prove isolation), and I decided I'd rather have the tool used widely than hide the best mechanics behind a paywall.\n\n**For those who missed the last post, it:**\n\n* **Finds Waste:** \"Vampire\" NAT Gateways (<1GB traffic), \"Ghost\" EKS clusters (0 pods), and orphaned snapshots.\n* **Fixes State:** Generates surgical Terraform scripts to delete waste without corrupting your state file.\n* **Local-First:** Runs on your machine. No SaaS. No data leaves your laptop.\n\nThe codebase is fully AGPLv3 now.\n\n**Repo:** [https://github.com/DrSkyle/CloudSlash](https://github.com/DrSkyle/CloudSlash)\n\nIf this saves you money on your bill this month, dropping a Star on the repo would mean a lot.\n\nCheers, DrSkyle",
      "is_original_content": false,
      "link_flair_text": "monitoring",
      "permalink": "https://reddit.com/r/aws/comments/1q5m3kx/cloudslash_v133_we_removed_the_paywall_terraform/",
      "domain": "self.aws",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q7n6rw",
      "title": "Engineers: would you act on cost alerts with infrastructure context vs just dollar amounts?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q7n6rw/engineers_would_you_act_on_cost_alerts_with/",
      "author": "ang-ela",
      "created_utc": "2026-01-08 20:35:26",
      "score": 7,
      "num_comments": 18,
      "upvote_ratio": 0.77,
      "text": "FinOps lead here. Engineers: would you actually act on cost alerts if they showed you the infrastructure metric that caused the spike? Something like your Lambda concurrency jumped 500% instead of just a dollar amount?\n\nI'm pushing for alerts that give actual technical context, not just the generic your bill went up $200. Am thinking of better alerts like your RDS connections spiked 300% or EBS IOPS doubled overnight.\n\nSeems like you'd be more likely to investigate and fix when you know what broke, not just that something costs more.\n\n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1q7n6rw/engineers_would_you_act_on_cost_alerts_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nygzrtw",
          "author": "404_AnswerNotFound",
          "text": "We use Cost Anomaly alerts for this which report which AWS services had a spike. It's helpful as it gives us a quick guide of what to focus upon, even if most of our spikes are benign and caused by expected burst usage. Getting the alert and context automatically sent to the team also provides a good indicator for security related incidents.",
          "score": 10,
          "created_utc": "2026-01-08 21:04:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyh0wcz",
              "author": "Quinnypig",
              "text": "Same. It's a hidden AWS gem.",
              "score": 5,
              "created_utc": "2026-01-08 21:09:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nyhtcik",
              "author": "ang-ela",
              "text": "I get you, but I feel cost anomaly detection stops short of actionable context.",
              "score": 1,
              "created_utc": "2026-01-08 23:19:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nygwbr3",
          "author": "Capable_Dingo_493",
          "text": "it's pretty simple to find out where the cost is coming from once I get the alert for the higher bill - wouldn't make buch difference for me",
          "score": 4,
          "created_utc": "2026-01-08 20:49:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhu84p",
              "author": "ang-ela",
              "text": "Sure, you can dig through cost explorer, but that's reactive troubleshooting when you are already bleeding money.",
              "score": 2,
              "created_utc": "2026-01-08 23:23:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyhs55u",
          "author": "Snaddyxd",
          "text": "Yes, I know engineers will act. I'm a FinOps btw. \n\nLast quarter, we introduced pointfive after a cost incident, and their alerts are basically infra context. Have seen teams take up remediation actions because for once they know where to look.",
          "score": 4,
          "created_utc": "2026-01-08 23:13:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhucfi",
              "author": "ang-ela",
              "text": "Thank you for confirmation",
              "score": 1,
              "created_utc": "2026-01-08 23:24:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nygv4kg",
          "author": "CSYVR",
          "text": "I guess it would be a better and more relevant metric. Generally most engineers (or devs more specifically) are pushed to build features more than be cost conscious. An increase in $200, especially on a 200K MRR is not worth even thinking about in cost terms, but might be a real indicator of a self invoking lambda, which could actually effect performance, availability and other metrics that are more aligned with an engineer's ownership.",
          "score": 3,
          "created_utc": "2026-01-08 20:43:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhtsro",
              "author": "ang-ela",
              "text": "Precisely. That runaway lambda for example is probably hammering the error budget and response times.",
              "score": 2,
              "created_utc": "2026-01-08 23:21:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyh4h3p",
          "author": "SpecialistMode3131",
          "text": "The more rich you can make the alert, the better -- but do not introduce error.  Nothing will get engineers to ignore your rich alert faster than if it is sometimes wrong.\n\nThis is the reason a lot of infra people give very sparse alerts and build those up to dashboards, injecting business context only then, if then. Context tends to rot, and the alert becomes spurious and gets ignored.\n\nSo, just be very sure before you attach business context to an alert that you're right every time and you're going to still be right all the time in 10 years.",
          "score": 2,
          "created_utc": "2026-01-08 21:24:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyh5ysd",
          "author": "cloudnavig8r",
          "text": "Thatâ€™s better, but not good enough.\n\nCost is one metric, but it alone is insufficient.  Context of what contributed to the cost is key.\n\nBut, this is not just what service(s) increased, but identifying the workloads.  \n\nThen, associating the workloads with their value metrics.  \n\nâ€”-\n\nIf you cloud costs go up 10% (for a given workload) and during that same time the workload generated 25% more revenue- I donâ€™t think you should be focused on the 10% increase of cloud costs.",
          "score": 2,
          "created_utc": "2026-01-08 21:31:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym2tnw",
          "author": "aviboy2006",
          "text": "As engineer I will surely look into it. Because of cost spike is shoot not just because wrong architecture but because of something wrong because code or app then itâ€™s worth to look. Is that what you are saying ?",
          "score": 1,
          "created_utc": "2026-01-09 15:41:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrc59q",
          "author": "Blue-Command",
          "text": "Detecting that cost is off is start of it, as you say, point A. Looking into it and finding the cause is on the other end, that is, when you have detected the real cause then you can start thinking how to fix it, this is point B. Fixing it is point C. Your question lies somewhere between A and B points. If you would be able to provide context to engineer with full info in point B (i.e. pile up of large EBS volumes with exact reference to samples, xy lambda executions out of proportion for this and that lambdas, logging cost for xy) then you would not be ignored for sure.\n\nGetting from point A to point B in many cases requires engineer looking into it. What you can help with is go into Cost Explorer and Bills (this is what I do more or less 1st) and check where is it off, so on which specific service and billing point. This is \\~10% from A to B. Then, looking into exact services an detecting the cause, trying to get to point B. As you I am also thinking of how to automated this, and how much AI can help here.",
          "score": 1,
          "created_utc": "2026-01-10 09:13:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nygyc4b",
          "author": "cothomps",
          "text": "It strikes me as a pretty big problem if all infrastructure monitoring is left to a \"FinOps\" function.",
          "score": 1,
          "created_utc": "2026-01-08 20:57:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyhsxei",
              "author": "ang-ela",
              "text": "Precisely, cost should be everyone's problem",
              "score": 1,
              "created_utc": "2026-01-08 23:16:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyhuqbn",
                  "author": "cothomps",
                  "text": "Even if all of this is free, something like RDS connections spiking or IOPS going out of band would indicate a potential problem with the application (or whatever this is doing).\n\nAre teams / engineers doing zero operational monitoring?",
                  "score": 2,
                  "created_utc": "2026-01-08 23:26:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyhpdqi",
          "author": "serverhorror",
          "text": "Anything that is\n\n1. Actionable, and\n2. Worth fixing \n\nshould be an alert and any engineer worth anything will act.\n\nA question that's much harder to answer (if not mandated by policy): Are you even the right person to make that decision?\n\nBecause I'll happily limit that 500 % spike back down to acceptable levels, but I sure hope you have a good explanation if 80 % of requests will suddenly error out and -- because you said so -- that is absolutely fine.\n\nIf that's not fine, the whole thing is not actionable and is, at best, a data point, and at worst introduces even more alert fatigue.",
          "score": 0,
          "created_utc": "2026-01-08 22:59:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7wk7q",
      "title": "RDS2017+ and no CLR Support is a gotcha I did not see coming..",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1q7wk7q/rds2017_and_no_clr_support_is_a_gotcha_i_did_not/",
      "author": "VIDGuide",
      "created_utc": "2026-01-09 02:53:44",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.89,
      "text": "So we've been on SQL2016 for a while, and of course, being 10 years old now, it's coming up to end of life this year. So it's been on the roadmap to do testing and upgrade. Been over the main application itself, and MS's documentation, and nothing really stood out. We had some concerns about a 3rd party application that's out of contract with us that we can no longer update, and had to hope it was still going to be compatible. \n\nSo we spin up a dev env and run into a massive problem right up front. \n\nWhile MSSQL 2017+ supports CLR functions, AWS RDS with SQL2017+ does NOT! \n\nWith the impending timeline, this is a pretty major kicker. This is going to need either a significant re-engineering effort (The CLR functions are too complex for T-SQL and are used in many applications across many functions and in many ways, which is why the CLR-in-the-DB was perfect for us), or we'd have to move to SQL on EC2 and lose \\*all\\* the RDS cloud benefits and licensing management. \n\nI know AWS has to move with the times re: versions, I get deprecating out 2016, that's fine; but removing support for functionality with no proper path forward, that's cloud-nightmare territory. ",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1q7wk7q/rds2017_and_no_clr_support_is_a_gotcha_i_did_not/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nyiyarj",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-09 02:53:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyj0bzl",
          "author": "steveoderocker",
          "text": "A very quick google search would indicate RDS Custom is your only option \n\nhttps://aws.amazon.com/blogs/database/migrate-your-sql-server-workload-with-clr-integration-to-aws/",
          "score": 3,
          "created_utc": "2026-01-09 03:04:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyj8v8i",
              "author": "VIDGuide",
              "text": "yup, but that means moving to SQL2019, which ultimately will be for the best, but brings even MORE gap in compatibility with the legacy application we have to support. It's a bit of a mess. \n\nWe're now kicking off an internal evaluation on re-engineering everything to remove CLR usage, and refactor it out, vs RDS Custom.",
              "score": 1,
              "created_utc": "2026-01-09 03:52:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nyjbl9o",
                  "author": "steveoderocker",
                  "text": "\nWell, the â€œeasyâ€ thing to do in the mean time is run sql server on ec2 and when you are ready, move back to RDS (either standard or custom). But yes, sounds like a bit of a pickle.",
                  "score": 5,
                  "created_utc": "2026-01-09 04:08:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyjsqa6",
                  "author": "Straight_Waltz_9530",
                  "text": "It's likely out of scope considering the amount of work, but RDS Aurora Postgres has Babelfish, providing a bunch of T-SQL and TDS protocol compatibility, allows custom functions in a variety of procedural languages, and even supports Trusted Language Extensions when you need to eke out the highest performance from your custom in-database logic.\n\nIt'd be a big lift and probably not justifiable money and time-wise, but if you're looking at a major pain in the ass either way with an annoying EOL treadmill, it might be worth exploring since Postgres is better at backward compatibility in my experience.\n\nYou'd lose PIVOT and clustered indexes but gain a lot of different features. It'd be a non-trivial lift though, no doubt.",
                  "score": 1,
                  "created_utc": "2026-01-09 06:02:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyiyaq8",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 0,
          "created_utc": "2026-01-09 02:53:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qarlx9",
      "title": "Need advise regarding upgrade and production switching.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qarlx9/need_advise_regarding_upgrade_and_production/",
      "author": "samuel_-002",
      "created_utc": "2026-01-12 10:38:40",
      "score": 7,
      "num_comments": 7,
      "upvote_ratio": 0.89,
      "text": "We have 4 servers in the enviornment hosting a total of 3-4 sites\nwe need to upgrade the mysql first and after rectifiying any errors we plan to\nmove with the php and os upgrades and we plan to set up a separate preprod\nenviornment for te upgrade and test it uot and push it into production what \nwould be the optimal way to do this upgrade?",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qarlx9/need_advise_regarding_upgrade_and_production/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nz5keom",
          "author": "uuneter1",
          "text": "Create a â€œstagingâ€ env exactly like your prod env and test changes there. This has been a common setup for many years.\n\nBtw punctuation would sure make your post more readable.",
          "score": 6,
          "created_utc": "2026-01-12 12:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz560tm",
          "author": "RecordingForward2690",
          "text": "Use the opportunity to go back to the drawing board and plan/execute things properly according to 2026 best practices: Separate accounts for Dev, Test, Accept, Prod, everything deployed through IaC, 12-factor app, AMI Builder for your EC2s, Auto Scaling Groups, Load Balancers, CloudFront, API Gateways, RDS etc.\n\nAt the end of that process redirect your Route53 records to the new environment and decommission the old one.\n\nIt's a lot more work but it'll pay off in the future.",
          "score": 2,
          "created_utc": "2026-01-12 11:07:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz53xfo",
          "author": "Decent-Economics-693",
          "text": "Well, there are several ways to do this, but some info is missing to rule out one over another.\n\n4 servers. Are these servers something like â€œall-inâ€ boxes: the website and the database in the same box? Or, so you have database(s) deployed separately from the webservers?",
          "score": 1,
          "created_utc": "2026-01-12 10:49:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz5h8kl",
          "author": "dataflow_mapper",
          "text": "Setting up a separate preprod environment is the right move. I would make it as close to prod as possible, ideally from snapshots or AMIs, so you are testing real data and config.\n\nDo the upgrades in the same order you mentioned. MySQL first, then app level stuff like PHP, then OS last. Verify each step before moving on so you know what broke. For the prod switch, a blue green style cutover works well even on a small setup. Spin up the upgraded stack, test it, then flip DNS or load balancer targets so rollback is just pointing traffic back.\n\nAlso make sure you have recent backups and a clear rollback plan before touching prod. That matters more than any specific AWS service choice.",
          "score": 1,
          "created_utc": "2026-01-12 12:35:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz6soew",
          "author": "ururururu",
          "text": "If you're really concerned and facing unknown risks.... you can do a \"blue => green\" or \"A => B\" switch where you (1) setup a new iteration of the environment (2) get everything running (3) switch to the new environment (4) decom the old.  This is inefficient and expensive since you have two sets of hardware to pay for.  But it beats downtime.",
          "score": 1,
          "created_utc": "2026-01-12 16:44:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz77yw1",
          "author": "benpakal",
          "text": "Do you have only the prod environment? You should have one or more non-prod environments where you can test changes before pushing to prod.",
          "score": 1,
          "created_utc": "2026-01-12 17:54:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}