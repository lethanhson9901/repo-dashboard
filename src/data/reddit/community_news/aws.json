{
  "metadata": {
    "last_updated": "2026-02-18 03:09:58",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 131,
    "file_size_bytes": 136240
  },
  "items": [
    {
      "id": "1r4yqqp",
      "title": "Small PSA regarding ECR and Docker CLI for pushing images",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "author": "magnetik79",
      "created_utc": "2026-02-14 23:05:45",
      "score": 136,
      "num_comments": 13,
      "upvote_ratio": 0.99,
      "text": "Hey all.\n\n  Quick post of something I noticed over the weekend which might trip up someone else.\n\n\nWas pushing a Docker image into ECR using a GitHub Actions deployment workflow, a workflow that's been same-same for a good six months and suddenly two days prior was failing with the following error:\n\n```\nunknown: unexpected status from HEAD request to https://XXXXX.dkr.ecr.ap-southeast-2.amazonaws.com/v2/XXXX/XXXX/manifests/sha256:XXXX: 403 Forbidden\nmake: *** [Makefile:68: burp] Error 1\nError: Process completed with exit code 2.\n```\n\nAfter a little head scratching, I pulled out a few community threads via Google - all from 1 - 2 years ago, but suspiciously had some very recent comments (two days prior) on them with similar issues:\n\n- https://repost.aws/questions/QUYf5U-mW3SqaYKFEvbr9fzw/suddenly-getting-403-on-pushing-my-containers-to-ecs\n- https://stackoverflow.com/questions/79137398/gitlab-cicd-issue-403-forbidden-while-pushing-docker-image-to-aws-ecr\n\nThe IAM role used in my GitHub workflow was (as it should be) fairly restrictive - with the following IAM actions only:\n\n```\necr:BatchCheckLayerAvailability\necr:CompleteLayerUpload\necr:InitiateLayerUpload\necr:PutImage\necr:UploadLayerPart\n```\n\nThese are all honed against a [specific ECR repository ARN](https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonelasticcontainerregistry.html#amazonelasticcontainerregistry-repository).\n\nTurns out, adding `ecr:BatchGetImage` was the fix - this provides the ability for querying image digests from within ECR, which is exactly where the HTTP HEAD error lies.\n\nSo, it seems a recent release of Docker CLI has changed the behavior of `docker push` to now query image digests during an image push and I can only assume this version recently landed on GitHub managed workflow runners.\n\nAnyway... hopefully this helps someone else out of a bind!\n",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5ffwnp",
          "author": "l0g0ut",
          "text": "Thank you for the in depth investigation report. These kind of post and people like you really made Reddit a treasure",
          "score": 26,
          "created_utc": "2026-02-15 00:20:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fji5o",
              "author": "magnetik79",
              "text": "thanks for the kind words.",
              "score": 4,
              "created_utc": "2026-02-15 00:41:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f5bs0",
          "author": "phaubertin",
          "text": "This is really good to know, thanks for posting.",
          "score": 16,
          "created_utc": "2026-02-14 23:14:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f9egh",
              "author": "magnetik79",
              "text": "cheers.",
              "score": 5,
              "created_utc": "2026-02-14 23:39:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5fsc73",
          "author": "MonkeyArmpit",
          "text": "I wasn‚Äôt aware of docker cli change. I always just set it up as the official documentation suggested \n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push-iam.html",
          "score": 6,
          "created_utc": "2026-02-15 01:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5lu3kg",
              "author": "magnetik79",
              "text": "Good callout.\n\nSmall issue there, `ecr:GetAuthorizationToken` doesn't have an ARN association, so technically that second policy example may not actually work.",
              "score": 1,
              "created_utc": "2026-02-16 01:07:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ltpri",
          "author": "puttak",
          "text": "You are saved my life.",
          "score": 2,
          "created_utc": "2026-02-16 01:05:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rileh",
          "author": "FlowPuzzleheaded4995",
          "text": "Thanks for timely post we were having our CI/CD pipelines failing today this helped alot resolving quickly",
          "score": 2,
          "created_utc": "2026-02-16 22:22:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5riqtg",
              "author": "magnetik79",
              "text": "Not a problem - wasn't sure if my post was gonna just be Internet points farming, but seems I've helped a few people out :)",
              "score": 2,
              "created_utc": "2026-02-16 22:23:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5riv1v",
                  "author": "FlowPuzzleheaded4995",
                  "text": "absolutely!",
                  "score": 1,
                  "created_utc": "2026-02-16 22:24:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hs9uk",
          "author": "thebru",
          "text": "Hit something similar. \n\nWe ended up disabling `provenance` in the build. It was pushing an image index along with the two images we built through. \n\nLambda didn't like this.",
          "score": 1,
          "created_utc": "2026-02-15 11:47:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ffyqc",
          "author": "burnbern",
          "text": "Had the same issue and Opus saved me‚Ä¶lol",
          "score": 1,
          "created_utc": "2026-02-15 00:20:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6snkt",
      "title": "DynamoDB single-table pattern: SaaS Multi-Tenant with 10 access patterns, 1 GSI (full breakdown)",
      "subreddit": "aws",
      "url": "https://singletable.dev/blog/pattern-saas-multi-tenant",
      "author": "tejovanthn",
      "created_utc": "2026-02-17 01:38:12",
      "score": 56,
      "num_comments": 34,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r6snkt/dynamodb_singletable_pattern_saas_multitenant/",
      "domain": "singletable.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o5spqqi",
          "author": "cachemonet0x0cf6619",
          "text": "me likes. i don‚Äôt run single table for multi tenant but  if i ever do this will be the reference. \n\ni really liked the site too. only suggestion is that the tables on mobile are tough to read but not a big deal i look forward to more patterns",
          "score": 4,
          "created_utc": "2026-02-17 02:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t3xfa",
              "author": "tejovanthn",
              "text": "Thank you :) \n\nWhat patterns would you like to see sooner? üòÅ",
              "score": 1,
              "created_utc": "2026-02-17 03:58:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5t400s",
              "author": "tejovanthn",
              "text": "Also, how do you handle multitenant? Separate tables per tenant?",
              "score": 1,
              "created_utc": "2026-02-17 03:58:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5t5j35",
          "author": "finitepie",
          "text": "If i understand you correctly, you are worried, that using an GSI to create a tenant index, could cause a hot partition? But how often do you actually need to make that request? I would just create a {pk TENANT#<tenant-id>, sk:METADATA} for each tenant, that has a property TYPE=TENANT and use a GSI to query for the type, to get a full tenant list or something similiar. But would be more worried, that your general pk/sk design leads to hot partitioning, since your pk is always the tenant id, and the pk determines the partition. What I do is, to break it down into subcategories. like {pk: TENANT#<tenant-id>#USER, sk: <user-id>} or {pk: TENANT#<tenant-id>#PROJECT, sk: <project-id>}. That would be already two distinct paritition, instead of a single one by just using the pattern {pk: TENANT#<tenant-id>, sk: PROJECT#<project-id>}, where¬†all items for that tenant compete for the same¬†1,000 WCU / 3,000 RCU per-partition throughput limit. That works also well for me, since i usually have dedicated api routes for subcategories. What is your security model to enforce tenant isolation?",
          "score": 5,
          "created_utc": "2026-02-17 04:09:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t8673",
              "author": "tejovanthn",
              "text": "Great points ‚Äî here's my thinking:\n\nTenant index isn't really a worry because it's an admin operation with low volume. I've handled this with the TENANT\\_LIST GSI, but your TYPE=TENANT approach seems functionally similar.\n\nSplitting PKs into subcategories is an interesting approach - you spread writes across multiple partitions with the tradeoff that you lose the ability to read across entity types in a single operation. I think this really depends on the access patterns. For the multi-tenant case, being able to query \\`TENANT#<id>\\` and get metadata + subscription + users in one call is something I reach for a lot.  \nFor most SaaS apps, from what I understand, the hot partition concern is overblown - 1,000 WCU per partition is a lot, and since 2018 DynamoDB's adaptive capacity redistributes throughput to handle hot partitions without you needing to intervene. It won't proactively split them, but it handles the imbalance. If you're at a scale where a single tenant is consistently pushing past that, you probably have bigger architectural decisions to make anyway.\n\nThe tenant isolation point is legit and something I should address in the article. In my production apps I handle this at the application layer (tRPC + OpenAuth ‚Äî every query is scoped to the authenticated tenant). I'm aware of IAM fine-grained access control with \\`dynamodb:LeadingKeys\\` condition keys as the DB-level option, but haven't needed it yet. Have you had success with that approach in practice, or is there something else you'd recommend?",
              "score": 1,
              "created_utc": "2026-02-17 04:27:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tb242",
                  "author": "finitepie",
                  "text": "I didn't actually have tRPC on the radar. Looks very interesting. Have to learn more about it. So basically, I make sure that the relevant data (tenant id, role, etc) is part of the signed access token, like you do. I have predefined IAM roles with role tags, using the LeadingKeys pattern, and at the API level, the actual dynamodb requests are being done while assuming those roles. This will enforce tenant isolation. But I also have more RBAC/ABAC style of permissions enforced at the middleware level. For all that I build an universal authentication and authorisation system I deploy once (or as often as I want to get more isolation for other reasons)  and can reuse for any other app. It's just plug and play at this point. But was a lot of work to get there. But at the moment I'm still doing REST APIs. Which works nicely, because I'm running Hono with OpenAPI extension, where I only have to define a zod schema as single source of truth, and can easily generate the correctly typed client code via the OpenAPI specs, it automatically generates from that. But the system would work with GraphQL too. ",
                  "score": 1,
                  "created_utc": "2026-02-17 04:47:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5u8q35",
          "author": "SikhGamer",
          "text": "This is a god awful idea if you have a complicated setup. If your setup is flat and easy to understand _forever_ then _maybe_ this would be a good idea.\n\nOtherwise use an RDBMS _please_.",
          "score": 8,
          "created_utc": "2026-02-17 09:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uftvd",
              "author": "tejovanthn",
              "text": "True. DynamoDB isn't the right choice for every workload, and forcing single-table design onto a domain with unpredictable or constantly evolving access patterns is going to hurt. No argument there.\n\nBut when the access patterns are well-understood upfront - which they are for a lot of SaaS CRUD apps - the operational simplicity and scaling characteristics of DynamoDB are hard to beat. The goal of this pattern library is to make the \"well-understood\" part easier to get to. :)",
              "score": 2,
              "created_utc": "2026-02-17 10:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tou1y",
          "author": "mamaBiskothu",
          "text": "Why not have separate tables for each tenant?",
          "score": 3,
          "created_utc": "2026-02-17 06:36:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tspj0",
              "author": "tejovanthn",
              "text": "It's a valid approach and some teams do this ‚Äî especially when you need hard isolation for compliance (HIPAA, SOC2) or you want to offer dedicated-tenancy as a premium tier.\n\nThe tradeoffs though:\n\n\\- Operational overhead scales linearly - Every new tenant means a new table, new GSIs, new CloudWatch alarms, new backup configs. At 100 tenants that's manageable. At 10,000 it's a nightmare.  \n\\- Cross-tenant queries become expensive - \"List all tenants\" or \"aggregate usage across tenants\" requires scanning every table.  \n\\- AWS account limits - There's a default limit of 2,500 tables per account per region. You can request increases, but it's a signal you're fighting the grain.  \n\\- Cost - Each table with on-demand pricing has its own minimum throughput allocation. One shared table is cheaper than N separate ones.\n\nThe single-table approach gives you logical isolation (tenant-scoped partition keys) with the operational simplicity of one table. If you need stronger isolation, the IAM LeadingKeys approach another commenter mentioned gives you DB-level enforcement without separate tables.\n\nThat said, table-per-tenant is the right call for some use cases ‚Äî particularly when tenants have wildly different scale or strict data residency requirements. It's not wrong, just different tradeoffs.",
              "score": 1,
              "created_utc": "2026-02-17 07:10:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tuox5",
                  "author": "mamaBiskothu",
                  "text": "Fair points. I get it. This was a fascinating post, thanks a million.",
                  "score": 2,
                  "created_utc": "2026-02-17 07:28:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5vwxjn",
              "author": "pablo__c",
              "text": "I'd second this. Have multiple tables, one for each tenant, but then do a single table approach for the rest of the stuff. Btw, ignore the \"just use a relational db\" comments. It's ok to try new/different things, and DynamoDB is great for new simple projects with its scale to zero pay as you go model.",
              "score": 1,
              "created_utc": "2026-02-17 16:09:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5t356u",
          "author": "MmmmmmJava",
          "text": "Edit: you‚Äôve fixed it!\n\n~~Your article‚Äôs phrasing seems to indicate you have 3 GSIs, vs 3 access patterns in 1 GSI.~~",
          "score": 2,
          "created_utc": "2026-02-17 03:53:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t4w4w",
              "author": "tejovanthn",
              "text": "Thanks for the feedback :) could you clarify where I can word it better - the blog article, or the post here?",
              "score": 1,
              "created_utc": "2026-02-17 04:04:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5t657t",
                  "author": "MmmmmmJava",
                  "text": "No problem. I think your post could be rephrased to clarify that you walk through two variations. first multiple GSIs and then an overloaded one.\n\nYour article may also benefit from having an index (no pun intended) at the beginning to show the sections and what‚Äôs coming later in the article.",
                  "score": 1,
                  "created_utc": "2026-02-17 04:13:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5uj1om",
          "author": "teo-tsirpanis",
          "text": "That was the best single-table explainer I've ever seen. üëèüèª üëèüèª",
          "score": 2,
          "created_utc": "2026-02-17 11:15:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5um2mk",
              "author": "tejovanthn",
              "text": "Thanks, appreciate it! üòÑ",
              "score": 1,
              "created_utc": "2026-02-17 11:41:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5td0od",
          "author": "gottcha-",
          "text": "How do you handle schema changes?",
          "score": 1,
          "created_utc": "2026-02-17 05:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tfy7a",
              "author": "tejovanthn",
              "text": "Good question - this is one of the genuine pain points with DynamoDB, and one that kept me sticking to rdbms for a very long time. \n\nFor attribute-level changes (adding a new field, changing a default), it's straightforward - DynamoDB is schemaless per item, so new items get the new attribute and old items don't. I handle backfills lazily at read time or with a one-off migration script depending on whether the field is required.\n\nFor key structure changes (modifying a PK/SK pattern or GSI), it's more involved. You can't alter keys on existing items - you have to write new items with the new key pattern and clean up the old ones. ElectroDB's versioning helps here: you define a new entity version and can read both old and new formats during the transition.\n\nFor GSI changes, adding a new GSI is non-disruptive (DynamoDB backfills it from the existing table). Changing or removing one requires a migration plan.\n\nHonestly, this is probably the strongest argument against overly complex single-table designs - the more entities and overloaded indexes you have, the harder migrations get. It's why I'd rather start with clean, well-separated key prefixes and only overload GSIs when the access patterns are stable.\n\nSchema migration tooling is a big gap in the DynamoDB ecosystem right now. It's something I'm thinking about for singletable.dev down the road.",
              "score": -1,
              "created_utc": "2026-02-17 05:23:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ti5x8",
          "author": "kingslayerer",
          "text": "If you are on rust maybe you will find my lib useful \n\nhttps://github.com/Salman-Sali/dynorow",
          "score": 1,
          "created_utc": "2026-02-17 05:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tr86z",
          "author": "Patient-Swordfish906",
          "text": "Good write up, been using single table design in production apps for a few years now.\n\nMy only nitpick with your article is that access pattern #5 is not really covered by your design. You claim you can get a project by ID by using get item on the full SK, but you have the date as a prefix, so you can‚Äôt query only by project ID.",
          "score": 1,
          "created_utc": "2026-02-17 06:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tse2s",
          "author": "Soccham",
          "text": "People at my work have been doing this and it‚Äôs a fucking disaster. \n\nJust use relational databases.",
          "score": 1,
          "created_utc": "2026-02-17 07:07:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vyl5y",
          "author": "TechDebtSommelier",
          "text": "Scan is a \"we'll fix it later\" that becomes a 3am incident. Write-shard the GSI key (TENANT#<0-N>), scatter-gather on read, done. Yes it's annoying. No there's no cleaner way. Welcome to DynamoDB.",
          "score": 1,
          "created_utc": "2026-02-17 16:17:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yke8x",
          "author": "ShakataGaNai",
          "text": "What is this, a [schema diagram for ants](https://imgur.com/a/gPKV00U)? But seriously, I can't read it and can't make it any larger.",
          "score": 1,
          "created_utc": "2026-02-17 23:54:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t8lgm",
          "author": "the_corporate_slave",
          "text": "Single table pattern is over complicated trash. Unless you are doing an app rewrite where you know exactly what schema you need, this is a mistake",
          "score": -1,
          "created_utc": "2026-02-17 04:30:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tb0tu",
              "author": "tejovanthn",
              "text": "There's a real point here - single-table design has a steep learning curve and if you get your access patterns wrong upfront, refactoring is painful.\n\nBut \"you need to know exactly what schema you need\" is true of DynamoDB in general, not just single-table. Multi-table DynamoDB still requires you to define access patterns before you design. It's not a relational database where you can normalize first and figure out queries later.\n\nWhere I'd push back: single-table isn't all-or-nothing. The modern approach is pragmatic - group entities that are queried together, use a few clean GSIs, don't overload everything into one index just because you can. That's what this pattern does.\n\nThat said, if your app's access patterns are genuinely unknown and/or evolving fast, DynamoDB itself might not be the right choice - and that's a totally valid position.",
              "score": 1,
              "created_utc": "2026-02-17 04:47:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tc35e",
                  "author": "finitepie",
                  "text": "I actually prefer the single table design. Everything boils down to how your data model is defined. But as you said, the problem is often not the single table design, but that you might need access patterns, that you are not aware of, yet. But a profound schema migration is always a pain in the a\\*. :D",
                  "score": 6,
                  "created_utc": "2026-02-17 04:55:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r37abo",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "author": "magnetik79",
      "created_utc": "2026-02-12 22:16:45",
      "score": 36,
      "num_comments": 15,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1r37abo/aws_backup_adds_crossregion_database_snapshot/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5282yb",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52l92m",
          "author": "Mutjny",
          "text": "\"Logically\" air-gapped throw some big air quotes around that one.",
          "score": 13,
          "created_utc": "2026-02-12 23:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52jq4v",
          "author": "The_Tree_Branch",
          "text": "> Now do cross-region and cross-account in a single backup task.\n\nUnless I'm misunderstanding you, this already exists as of October 2025: https://aws.amazon.com/about-aws/whats-new/2025/10/aws-backup-single-action-database-snapshot-copy-regions/",
          "score": 9,
          "created_utc": "2026-02-12 23:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52lkv4",
              "author": "magnetik79",
              "text": "ü§¶‚Äç‚ôÇÔ∏è oh geez, I totally missed this announcement. Thanks for the heads up - you're indeed correct!\n\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/backup-feature-availability.html#features-by-resource\n\n> Amazon RDS, Aurora, DocumentDB, and Neptune now support cross-Region and cross-account snapshot copying in a single action. \n\nNice! Just need to add KMS keys to existing clusters and.... _recreate them_. Still this makes the process much nicer.",
              "score": 1,
              "created_utc": "2026-02-12 23:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o529jr4",
          "author": "freeriderblack",
          "text": "... and RDS still behind. I have never understood why they don't keep consistency between Aurora and RDS when it comes to AWS Backups features.",
          "score": 6,
          "created_utc": "2026-02-12 22:24:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52mmu0",
              "author": "naggyman",
              "text": "Aurora and RDS have very different tech stacks under the hood - so I‚Äôm guessing it‚Äôd be like developing two entirely separate features. \n\nSo the question then becomes - do you have to hold off releasing support for one because you haven‚Äôt completed development on support for the other.",
              "score": 10,
              "created_utc": "2026-02-12 23:34:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o530b5p",
          "author": "kopi-luwak123",
          "text": "It still does not work with AMK encrypted stuff, right ?",
          "score": 1,
          "created_utc": "2026-02-13 00:53:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o533ji1",
              "author": "magnetik79",
              "text": "No I would assume not - anytime you need to move a backup across regions or accounts you need to be using KMS keys - as Amazon managed keys are unique to each AWS account and region and can't used beyond those bounds.",
              "score": 2,
              "created_utc": "2026-02-13 01:13:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ctrs",
                  "author": "kopi-luwak123",
                  "text": "Yeah, so the intermediate vault is still required.",
                  "score": 1,
                  "created_utc": "2026-02-13 02:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56v79q",
          "author": "gex80",
          "text": "What the hell does logically air-gapped mean? The only definition I know of means no network access",
          "score": 1,
          "created_utc": "2026-02-13 16:43:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59bnvp",
          "author": "ruibranco",
          "text": "the term \"logically air-gapped\" is doing more heavy lifting than any vpc peering config i've ever written",
          "score": 1,
          "created_utc": "2026-02-14 00:13:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5282x0",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -5,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6fzf7",
      "title": "Amazon EC2 supports nested virtualization on virtual Amazon EC2 instances",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r6fzf7/amazon_ec2_supports_nested_virtualization_on/",
      "author": "KayeYess",
      "created_utc": "2026-02-16 17:30:58",
      "score": 26,
      "num_comments": 14,
      "upvote_ratio": 0.94,
      "text": "[https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-nested-virtualization-on-virtual/](https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-nested-virtualization-on-virtual/)\n\n\"Posted on:¬†Feb 16, 2026: Starting today, customers can create nested environments within virtualized Amazon EC2 instances. Previously, customers could only create and manage virtual machines inside bare metal EC2 instances. With this launch, customers can create nested virtual machines by running KVM or Hyper-V on virtual EC2 instances. Customers can leverage this capability for use cases such as running emulators for mobile applications, simulating in-vehicle hardware for automobiles, and running Windows Subsystem for Linux on Windows workstations.\n\nThis capability is available in all commercial regions on C8i, M8i, and R8i instances. To learn more about enabling hardware virtualization extensions in your environment, see the Amazon EC2 nested virtualization documentation.\"\n\nLink to documentation: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/amazon-ec2-nested-virtualization.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/amazon-ec2-nested-virtualization.html)",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r6fzf7/amazon_ec2_supports_nested_virtualization_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5q15jf",
          "author": "im-a-smith",
          "text": "I can then run Docker inside and have images running inside VMs inside VMs\n\nSweet.¬†",
          "score": 10,
          "created_utc": "2026-02-16 18:05:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qg9wt",
              "author": "visicalc_is_best",
              "text": "This is a great idea, particularly because RAM is so cheap right now",
              "score": 7,
              "created_utc": "2026-02-16 19:14:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rx567",
                  "author": "phaubertin",
                  "text": "It is when it's not your RAM. üòÄ",
                  "score": 2,
                  "created_utc": "2026-02-16 23:41:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5q1fao",
              "author": "samrwalker",
              "text": "Inception",
              "score": 2,
              "created_utc": "2026-02-16 18:06:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5yq7pr",
              "author": "dudeman209",
              "text": "This was Alan Turing‚Äôs vision!",
              "score": 1,
              "created_utc": "2026-02-18 00:26:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5q5dsq",
          "author": "UnluckyTiger5675",
          "text": "I hope this soon gets propagated to AWS workspaces, so my work mandated Windows 11 workspace can run WSL two instead of just WSL one",
          "score": 9,
          "created_utc": "2026-02-16 18:24:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qax17",
              "author": "bobkiwi",
              "text": "I am in the same boat- WSL2 support would help immensely to avoid the \"but Windows 365 VDIs can do it!\"\n\nIf it's in the m8 series, I wouldn't be surprised if it comes to WorkSpaces by Q3... but which year!",
              "score": 1,
              "created_utc": "2026-02-16 18:49:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ylu6j",
              "author": "SammichAffectionate",
              "text": "We are thinking of migrating away from Workspaces but it keeps getting pushed off. Nested virtualization is just one of the reasons.",
              "score": 1,
              "created_utc": "2026-02-18 00:01:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5q1i7c",
          "author": "Alternative-Expert-7",
          "text": "Lets go deeper.",
          "score": 3,
          "created_utc": "2026-02-16 18:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5q42ia",
          "author": "mezbot",
          "text": "Lol, the comments are exactly what I wanted to say‚Ä¶ needs more layers!",
          "score": 3,
          "created_utc": "2026-02-16 18:18:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q4xli",
              "author": "pixeladdie",
              "text": "Yo dawg! I heard you like abstractions‚Ä¶.",
              "score": 3,
              "created_utc": "2026-02-16 18:22:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5qcubx",
                  "author": "HiCookieJack",
                  "text": "So we've put podman in your docker, so you can download layers to download layers of layers¬†",
                  "score": 1,
                  "created_utc": "2026-02-16 18:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qs9j2",
          "author": "MassPatriot",
          "text": "VMception",
          "score": 3,
          "created_utc": "2026-02-16 20:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yy2mt",
          "author": "VIDGuide",
          "text": "Yo dawg.. we heard you liked vms, so we put vms in your vms, so you can vm while you vm!",
          "score": 1,
          "created_utc": "2026-02-18 01:09:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r209uo",
      "title": "Amazon Textract vs GPT",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "author": "nucleustt",
      "created_utc": "2026-02-11 15:24:44",
      "score": 23,
      "num_comments": 22,
      "upvote_ratio": 0.85,
      "text": "I just had a look at Amazon Textract's pricing, and I'm certain that token usage on a multi-modal GPT model can extract the text from an image into a structured JSON document for much less.\n\nWhat are the advantages of using Amazon Textract vs GPT?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tcrbo",
          "author": "kapowza681",
          "text": "Textract is deterministic, so you‚Äôll typically get the same result every time. It‚Äôs much better at recognizing hand written characters. It gives you the precise location of the characters, which may or may not be useful depending on what you‚Äôre hoping to accomplish. \n\nYou can also use both. I sometimes pass along the Textract extracted text to the model along with the document/image as a kind of ‚Äúhelper‚Äù text.",
          "score": 48,
          "created_utc": "2026-02-11 15:40:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tj7k7",
              "author": "RecordingForward2690",
              "text": "The precise location stuff is really handy. We were building an application that had to deal with copies of ID documents. Once the document was uploaded, we had to obfuscate the Dutch equivalent of the SSN due to privacy regulations. Textract and ImageMagick made that easy.\n\nMind the (relatively low) throughput quota though.",
              "score": 14,
              "created_utc": "2026-02-11 16:11:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w4xat",
                  "author": "trashtiernoreally",
                  "text": "Quotas can be increased both in terms of async submissions per second and simultaneous running requests.¬†",
                  "score": 2,
                  "created_utc": "2026-02-11 23:44:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4tg83s",
              "author": "nucleustt",
              "text": "Those are solid advantages. \n\nAnd you're right, it may be best to use them in combination to increase reliability when reading critical documents.",
              "score": 5,
              "created_utc": "2026-02-11 15:57:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tinpb",
          "author": "kievmozg",
          "text": "I have to slightly disagree on the handwriting part. While Textract is decent, it lacks semantic context. If a handwritten '5' looks like an 'S', Textract often guesses wrong based on pixel shape alone. A Vision LLM (like GPT-4o or Claude) looks at the surrounding text, understands it's a 'Quantity' field, and correctly identifies it as '5'.\n\n‚ÄãTextract is definitely superior for bounding boxes (coordinates) and pure speed on massive datasets. But if your goal is extracting structured JSON from complex/messy documents where field logic matters more than pixel-perfect coordinates, Vision models are usually cheaper and more accurate in practice. We actually benchmarked this extensively for ParserData and found Vision models reduced 'logic errors' by nearly 40% compared to raw Textract output.",
          "score": 13,
          "created_utc": "2026-02-11 16:08:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w9nxj",
              "author": "enjoytheshow",
              "text": "We feed our handwritten output from textract into Bedrock with a prompt explaining it to clean it up. We tried all combinations and that was most successful for us",
              "score": 3,
              "created_utc": "2026-02-12 00:11:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4weqhg",
                  "author": "kievmozg",
                  "text": "That stack is definitely robust. We used it too for a while.\n\n\n‚ÄãThe only reason we switched to direct Vision models was to kill the 'double tax'. Paying for Textract pages plus Bedrock tokens adds up fast at scale. Going direct to Vision cut our latency and bill by about 40% since we skip the OCR step entirely.",
                  "score": 3,
                  "created_utc": "2026-02-12 00:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tvk45",
          "author": "Ok-Data9207",
          "text": "Make an evaluation set and test both. \n\nIf Image is like some ID or bill, textract works really well because it is trained on really large set of such documents and they have different API calls for them.",
          "score": 3,
          "created_utc": "2026-02-11 17:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wkssy",
          "author": "Hydroshock",
          "text": "[This is not my blog](https://hidekazu-konishi.com/entry/amazon_bedrock_for_titling_commenting_ocr_with_claude3_haiku.html), but this guy did some testing using Claude Haiku. There are other blogs where people did similar.\n\nI've done some pretty extensive testing myself with using LLM (mainly Claude 3.7 generation) vs. Textract on scanned paper documents. The main problem I've had is essentially the LLM \"count to 100\" or \"how many r's are in strawberry\" problem.\n\nLLM would often give a slower and incomplete response, hitting token limits, hallucinating details or re-interpret some lines. I tried again more recently and the models flat out do a tool call to Tesseract.\n\nIt really depends what your use case is though and how accurate you need the OCR. If you have a good quality source image with high DPI and text is well aligned, you get a long way. Textract does give a confidence value on the interpreted text and at the end of the day, Textract is using AI/ML for it's engine, it's just not LLM.",
          "score": 2,
          "created_utc": "2026-02-12 01:17:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ttzgx",
          "author": "SpecialistMode3131",
          "text": "1. Integration - part of a huge platform with obvious integration advantages.\n\n2. Stabilized - GPT constantly changes.  Nobody (but you) is QC'ing result quality.  At any point model changes may blow up your entire approach and what then?\n\n3. Focused - its whole job is to extract text.  It'll get better at its one job over time.",
          "score": 2,
          "created_utc": "2026-02-11 17:01:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bw4bf",
              "author": "bot403",
              "text": "As a longtime textract user id say llms are getting better MUCH faster then textract. They've made some improvements over the years but we got better results switching to LLMs. I've only seen textract improve slowly or barely at all.\n\n\nDisclaimer, part of our results with LLMs though are the bit of analysis and business domain interpretation we want on the 100% correct OCR result. We can do it in 1 pass with a LLM vs scan+interpret with textract.",
              "score": 1,
              "created_utc": "2026-02-14 12:29:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dvxex",
                  "author": "SpecialistMode3131",
                  "text": "Seems legit to me.  You've built a bespoke system to solve your business problem.  As long as it has good monitoring and QC, that sounds like exactly the right way to solve it.",
                  "score": 2,
                  "created_utc": "2026-02-14 19:05:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4w78e0",
          "author": "2BucChuck",
          "text": "The only thing keeping me there is handwriting on forms - claude4.5 was the first model I saw that could get tables and forms as well",
          "score": 1,
          "created_utc": "2026-02-11 23:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wozui",
          "author": "hcsteve",
          "text": "We have a workflow that needs to extract text from unstructured documents and then do some processing and summarization. We‚Äôve seen better accuracy by extracting with Textract first and then running through a multimodal model for processing, rather than just running raw docs through the model, especially for complex tabular data. It can be more expensive but the improved accuracy is worth it for us in this case.",
          "score": 1,
          "created_utc": "2026-02-12 01:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xgmrc",
          "author": "koinos_bios",
          "text": "Maybe checkout Bedrock Data Automation",
          "score": 1,
          "created_utc": "2026-02-12 04:38:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xv1k3",
          "author": "Sadboy2403",
          "text": "textract is an ML model and GPT is generative AI, if you need to have accurate results go for tetract.",
          "score": 1,
          "created_utc": "2026-02-12 06:36:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57gg0f",
          "author": "GeekLifer",
          "text": "If you need accurate OCR use textract. We used both and the problem with LLM is their vision is terrible. Lots of hallucinations",
          "score": 1,
          "created_utc": "2026-02-13 18:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57q29a",
              "author": "nucleustt",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-13 19:11:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ulcu8",
          "author": "Lendari",
          "text": "Textract existed before GPT models.",
          "score": 1,
          "created_utc": "2026-02-11 19:08:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r2rc0s",
      "title": "AWS (AI) Support - unassigned case for 24h with Business Support+",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "author": "alex_aws_solutions",
      "created_utc": "2026-02-12 11:47:23",
      "score": 22,
      "num_comments": 15,
      "upvote_ratio": 0.81,
      "text": "I thought the Business Support+ Plan is something different.... but not. Very unsatisfied!",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4zbjg4",
          "author": "kei_ichi",
          "text": "Isn‚Äôt ‚Äúbusiness support+ ‚Äú plan is just ‚Äúdeveloper support‚Äù plan? But they renamed it to look like an ‚Äúupgrade‚Äù but in reality that is just a fancy name and you will ‚Äúmostly‚Äù get answers from AI slop because they fired almost all of their support staff and still continue to do do that! To be honest, even enterprise support plan account are getting answers from bot instead of human so with your 29$ per month support plan‚Ä¶good luck to get your support case handled by human!",
          "score": 17,
          "created_utc": "2026-02-12 13:54:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5271t5",
              "author": "PsychologicalAd6389",
              "text": "You do realize that if you click the option to get a human you‚Äôll get a human",
              "score": 3,
              "created_utc": "2026-02-12 22:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o529ixc",
                  "author": "kei_ichi",
                  "text": "Ya, but in ‚Äútheory‚Äù only. Again, good luck to get support from human with that support plan. You ‚Äúwill‚Äù but with the cost of ‚Äúlong long‚Äù waiting queue because another people demand the same (because AI slop just respond with nonsense answers) but how many support staff ‚Äúleft‚Äù in that company????",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yu21k",
          "author": "Burekitas",
          "text": "Click reply and pick the Chat option, which would expedite the case.",
          "score": 20,
          "created_utc": "2026-02-12 12:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z8b01",
          "author": "AntDracula",
          "text": "Oops sorry about that. Better layoff another 10,000!",
          "score": 22,
          "created_utc": "2026-02-12 13:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ywsdw",
          "author": "ManBearHybrid",
          "text": "They fired all their support staff in favour of AI and customer service is suffering because of it. I wonder if they consider this a bad thing or if it's just worth it to save from paying all those salaries. ",
          "score": 8,
          "created_utc": "2026-02-12 12:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yzagw",
              "author": "CircularCircumstance",
              "text": "People complaining on Reddit comes at no added costs for AWS.  They'll only respond if it begins to affect the bottom line, IE enterprise customers taking their business elsewwhere.\n\nUnfortunately for so many of us, we are so deeply locked into AWS that the costs for us to move to another provider is massive.",
              "score": 6,
              "created_utc": "2026-02-12 12:40:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zgt3y",
                  "author": "CubsFan1060",
                  "text": "This is a great argument for shying away from provider specific tools.  If you build heavily on DynamoDB and Lambda, you're going to struggle to ever be able to actually think about moving.\n\nEveryone likes to talk about the complexity of Kubernetes (which is fair), but if your stack is EKS + postgres + S3, it still isn't _easy_ to move, but it's much much more possible to move.",
                  "score": 2,
                  "created_utc": "2026-02-12 14:22:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4z8l2j",
                  "author": "AntDracula",
                  "text": "Enshittification hits AWS",
                  "score": 2,
                  "created_utc": "2026-02-12 13:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yzb3f",
              "author": "Sirwired",
              "text": "No, they did *not* fire \"all\" the support staff.  Silly exaggeration like this does nobody any favors.",
              "score": -8,
              "created_utc": "2026-02-12 12:40:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8m9r",
                  "author": "AntDracula",
                  "text": "Hi Andy",
                  "score": 0,
                  "created_utc": "2026-02-12 13:38:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o501vfx",
          "author": "mediocretes",
          "text": "Yeah, this is par for the course. There‚Äôs no point to paying for Amazon support. I‚Äôve never once had them meet SLAs when anything significant was happening.",
          "score": 3,
          "created_utc": "2026-02-12 16:07:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yvxwj",
          "author": "AWSSupport",
          "text": "Hello, \n\nThanks for providing your case ID. \n\nI can confirm that your case is in the correct queue. I've reached out internally to have this looked into. \n\nBe sure to keep an eye open for further correspondence from our Support team.\n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-12 12:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ywqvv",
              "author": "alex_aws_solutions",
              "text": "Thank you Craig.",
              "score": 1,
              "created_utc": "2026-02-12 12:22:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ythgl",
          "author": "AWSSupport",
          "text": "Hello,\n\nI'm sorry for the frustration this has caused. Please DM us your case ID, so we can take a closer look. \n\n\\- Craig M.",
          "score": 0,
          "created_utc": "2026-02-12 11:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4k17f",
      "title": "How are you managing Bedrock?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "author": "jmreicha",
      "created_utc": "2026-02-14 12:59:48",
      "score": 19,
      "num_comments": 35,
      "upvote_ratio": 0.91,
      "text": "Looking for perspective on how teams are managing their Bedrock architectures and trying to get a handle on some things. Some questions I have:\n\n\\- How are you managing cost and cost attribution?\n\n\\- Are teams centralizing Bedrock infrastructure and model management? Or deploying models in each account?\n\n\\- How are folks managing security? What kinds of governance and guardrails are being put in place?\n\n\\- What about AgentCore? How is that being managed?\n\n\\- What is everyone using to manage changes? Terraform? Something else? Terraform support seems to be lacking.",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5c7m6h",
          "author": "2BucChuck",
          "text": "Built an API on the front of it in ECS and Lambda  to limit each user based on tokens which can be increased as needed.   In that an Admin can manage users and bots leveraging bedrock and while at it just made it an AWS MCP.  didn‚Äôt want to give bots any direct access to AWS IAM roles so tokens and JWT gateway seemed better to tamp down runaway usage since its early days until we could see how much costs and usage were coming from different places and users and tools",
          "score": 27,
          "created_utc": "2026-02-14 13:49:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dmhnw",
              "author": "aboothe726",
              "text": "I really like that approach. I've done something similar to give internal users access to vendor APIs while controlling for and tracking usage and without having to share the actual credentials for the vendor APIs. Worked really well.",
              "score": 4,
              "created_utc": "2026-02-14 18:18:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cqkr2",
              "author": "2BucChuck",
              "text": "DM me I can share the setup we have but would call is an Alpha release",
              "score": 2,
              "created_utc": "2026-02-14 15:37:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eb4oy",
              "author": "weirdbrags",
              "text": "did you look at litellm?",
              "score": 2,
              "created_utc": "2026-02-14 20:25:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ec3yu",
                  "author": "2BucChuck",
                  "text": "Interesting but no , we have to maintain lots of PII and SOC2 and this whole AI area has too many moving parts for us at the moment.  It‚Äôs the same idea though I see",
                  "score": 3,
                  "created_utc": "2026-02-14 20:31:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5dwsy7",
          "author": "CoopertheFluffy",
          "text": "Everyone always asks \"how are you managing bedrock?\" but nobody ever asks \"how are you managing, bedrock?\"",
          "score": 9,
          "created_utc": "2026-02-14 19:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1h2w",
          "author": "FarkCookies",
          "text": "I could not figure out how to do cost attribution except for having acc per team/env. ",
          "score": 8,
          "created_utc": "2026-02-14 13:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cre3l",
              "author": "pixeladdie",
              "text": "I haven‚Äôt had to test this yet but does [application inference profiles](https://aws.amazon.com/blogs/machine-learning/manage-multi-tenant-amazon-bedrock-costs-using-application-inference-profiles/) do what you need?",
              "score": 5,
              "created_utc": "2026-02-14 15:41:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5czrfp",
                  "author": "iwearhaines",
                  "text": "This is what we use. SCP to deny any model invocation that didn't go through an AIP, with each AIP tagged to the owning team",
                  "score": 4,
                  "created_utc": "2026-02-14 16:24:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5enple",
                  "author": "FarkCookies",
                  "text": "Wow thanks had no idea",
                  "score": 3,
                  "created_utc": "2026-02-14 21:34:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cd9ky",
          "author": "weirdbrags",
          "text": "question of the year.",
          "score": 7,
          "created_utc": "2026-02-14 14:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cos8z",
          "author": "Lba5s",
          "text": "you don‚Äôt",
          "score": 6,
          "created_utc": "2026-02-14 15:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ep3da",
          "author": "jojolejobar",
          "text": "We use litellm \nEach user has a key with a budget\nWorks with Claude, open code, openwebui..",
          "score": 4,
          "created_utc": "2026-02-14 21:41:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1oqv",
          "author": "AWSSupport",
          "text": "Hi there. I've forwarded your feedback to our Bedrock team for further review.\n\n\\- Roman Z.",
          "score": 4,
          "created_utc": "2026-02-14 13:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5crb89",
              "author": "2BucChuck",
              "text": "Ha you might regret posting here but also please fix the pricing on OpenSearch - it‚Äôs outrageous.  We setup one knowledge agent and bill went through the roof.  It‚Äôs not even clear how to undo it since it gets assigned in background.  That said appreciate how fast this was scaled up and the model ecosystem !",
              "score": 6,
              "created_utc": "2026-02-14 15:41:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ficlk",
                  "author": "weirdbrags",
                  "text": "s3 vectors?",
                  "score": 1,
                  "created_utc": "2026-02-15 00:34:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cegjm",
              "author": "japanthrowaway",
              "text": "Hey while you're at it can you tell the team to maintain their bedrock access gateway a bit better? Bedrock doesn't have a native openai api endpoint so we have to use BAG which doesn't even support all the native models on bedrock itself. Insane how AWS preaches being AI forward but they ignore this piece of critical infra.",
              "score": 2,
              "created_utc": "2026-02-14 14:30:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cqpon",
                  "author": "Maxious",
                  "text": "https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-mantle.html\n\n\n¬†is this not an openai API endpoint¬†",
                  "score": 3,
                  "created_utc": "2026-02-14 15:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cy8le",
          "author": "Nearby-Tomato9925",
          "text": "Individual Inference profiles with tags and then those tags enabled for AWS Budgets. Is it amazing? No. But at least it is something.",
          "score": 1,
          "created_utc": "2026-02-14 16:16:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5faimo",
              "author": "jmreicha",
              "text": "How many profiles are you managing? I can get behind doing that part with Terraform if it doesn't become a huge number.",
              "score": 1,
              "created_utc": "2026-02-14 23:46:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d7hs1",
          "author": "VladyPoopin",
          "text": "Application inference profiles for cost attribution to a specific pipeline. Getting more granular can be problematic, but it works.",
          "score": 1,
          "created_utc": "2026-02-14 17:02:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d927u",
          "author": "egoslicer",
          "text": "We use okta, so I built a cost attribution tool by login and token usage. From there, created a leaderboard so we can track usage.",
          "score": 1,
          "created_utc": "2026-02-14 17:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5el0dp",
          "author": "ShakataGaNai",
          "text": "Currently experimenting with [LiteLLM Proxy.](https://docs.litellm.ai/docs/simple_proxy) Conceptually it's perfect for the use case. As it has separate auth, admin API's, cost attribution, etc. However, it doesn't work for things like Claude Code (TBD on OpenCode, haven't tried it yet). \n\nBut, I'd really love something first party from Amazon. Having the ability to track token usage per API key or IAM role would be vastly superior than proxying every request with another tool.",
          "score": 1,
          "created_utc": "2026-02-14 21:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eqiym",
              "author": "Nick4753",
              "text": "LiteLLM is called out specifically in Claude Code's documentation https://code.claude.com/docs/en/llm-gateway#litellm-configuration\n\nLiteLLM is really underselling itself. You can use it as a gateway for just about any purpose, beyond just engineer access for coding.",
              "score": 2,
              "created_utc": "2026-02-14 21:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fzusw",
                  "author": "ShakataGaNai",
                  "text": "It is called out and thats why I tried it, but that doesn't mean it works well. Anthropic is rolling out features that break when running against things like LiteLLM. So it might work for a while, then might break at random. I was having issues with a new beta flag, which you can \"turn off\" in CC....except [it doesn't actually obey the setting](https://github.com/anthropics/claude-code/issues/21676).\n\nAnd the passthrough endpoints on LiteLLM are... meh. There are a bunch of limitations like they don't have good of an idea of the tokens used. They also can't stop usage for a specific key that's over allocation. Also it was, for me, logging hundreds of lines of ... errors(?)... when claude code was working against LiteLLM (and it was in fact working through LiteLLM to Bedrock).\n\nSo yes, it's possible. But if I were someone wanting to use something to control usage for Claude Code for an entire company... I wouldn't rely on that setup. Which is a shame because thats exactly who I am and what I wanted to do.\n\nIf someone has Bedrock/LiteLLM/ClaudeCode setup and working entirely correctly, without kneecapping yourself and losing out on major features, please tell me your config.",
                  "score": 3,
                  "created_utc": "2026-02-15 02:30:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5fdm0r",
              "author": "jmreicha",
              "text": "How does that approach work with inference profiles? Have you found much of the AgentCore tools to have similar functionality to litellm?",
              "score": 1,
              "created_utc": "2026-02-15 00:05:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f3cm1",
          "author": "donkanator",
          "text": "AWS best practices say to segregate workloads into their own accounts. From there, you don't have to worry about teams stepping on each other's toes if they maintain separate applications. If they are fine being under the same account then whoever fits the bill should be fine to pay for them all.\n\nAt the end of the day, any AI application or system is going to have a normal system architecture first and then some API calls. Chances are, containers or storage or support engineers are going to be much more expensive than a few AI calls. \n\nWe use scp and guardrails to ensure that people use only the models we are comfortable with and invokemodel permissions contain a guardrail condition. \n\nAgentcore is still in the pipeline but I'm struggling with the concept of customers being able to call public cloud apis directly (with a role or IDP token). Normally we expect to have some kind of ingress like application load balancer or cloudfront, but agent core pretty much welcomes anyone to call your API which can be a problem with legal and trade. (Honestly, why do we have to go through this all over again)",
          "score": 1,
          "created_utc": "2026-02-14 23:02:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r76u7k",
      "title": "How to build a distributed queue in a single JSON file on object storage (S3)",
      "subreddit": "aws",
      "url": "https://turbopuffer.com/blog/object-storage-queue",
      "author": "itty-bitty-birdy-tb",
      "created_utc": "2026-02-17 14:03:33",
      "score": 17,
      "num_comments": 8,
      "upvote_ratio": 0.83,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r76u7k/how_to_build_a_distributed_queue_in_a_single_json/",
      "domain": "turbopuffer.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5vx5ax",
          "author": "the8bit",
          "text": "Starting this 'seems like this won't really scale'\n\nEnding it 'ah you are basically reimplementing Kafka. Bold choice '",
          "score": 9,
          "created_utc": "2026-02-17 16:10:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yk71d",
              "author": "itty-bitty-birdy-tb",
              "text": "Ha. Well I guess we'll¬†take¬†\"Kafka but¬†it's one¬†JSON¬†file\" as¬†a¬†compliment",
              "score": 1,
              "created_utc": "2026-02-17 23:52:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vt3gm",
          "author": "AdCharacter3666",
          "text": "This is kinda like Iceberg but for queues.",
          "score": 3,
          "created_utc": "2026-02-17 15:50:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yk7cz",
              "author": "itty-bitty-birdy-tb",
              "text": "yeah decent comparison actually, same idea of using object storage as the source of truth with atomic metadata updates. Iceberg uses manifest files, we use CAS. the nice thing about both patterns is that object storage handles durability and availability so the compute layer can stay stateless.",
              "score": 1,
              "created_utc": "2026-02-17 23:53:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yxfp8",
          "author": "ruibranco",
          "text": "The Iceberg comparison is actually really apt ‚Äî both are fundamentally betting that object storage conditional writes are reliable enough to build coordination primitives on top of. The fact that you can get away with a single JSON file instead of a proper consensus protocol says a lot about how far S3's consistency model has come since they went strongly consistent in 2020.",
          "score": 3,
          "created_utc": "2026-02-18 01:06:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yaex3",
          "author": "Hackinet",
          "text": "Wait, why use a single file? Why not just do a group commit to a new file for a worker to pick up? \n\nIt still doesn't solve the issue with two workers picking up duplicate work in your article but I feel it would simplify the architecture and the write race conditions that you might run into.",
          "score": 2,
          "created_utc": "2026-02-17 22:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yjidl",
              "author": "itty-bitty-birdy-tb",
              "text": "the single file with CAS is what gives us strong consistency for free. the full queue state is always in one place, and CAS guarantees that any mutation¬†(push, claim, heartbeat) is¬†atomic with¬†respect to the current¬†state. if¬†you write new¬†files instead, you need¬†a¬†separate¬†coordination¬†mechanism to establish¬†ordering, track¬†which¬†files have been consumed, and¬†garbage¬†collect old¬†ones. you're¬†basically rebuilding the consistency¬†guarantees that¬†CAS on¬†a single file gives¬†you out¬†of¬†the box.",
              "score": 1,
              "created_utc": "2026-02-17 23:49:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6fnfx",
      "title": "m8azn single-thread performance tops EC2 benchmarks",
      "subreddit": "aws",
      "url": "https://go.runs-on.com/instances/ec2/m8azn",
      "author": "crohr",
      "created_utc": "2026-02-16 17:19:08",
      "score": 16,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ci/cd",
      "permalink": "https://reddit.com/r/aws/comments/1r6fnfx/m8azn_singlethread_performance_tops_ec2_benchmarks/",
      "domain": "go.runs-on.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5quolc",
          "author": "SkywardSyntax",
          "text": "Finally something that can run my homelab's nginx-proxy-manager docker container and tailscale exit node at the same time",
          "score": 6,
          "created_utc": "2026-02-16 20:24:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5spe0z",
          "author": "Big-Razzmatazz-2899",
          "text": "‚ÄúIt‚Äôs the A Z N, better recognize!‚Äù",
          "score": 1,
          "created_utc": "2026-02-17 02:27:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6kyza",
      "title": "Nested virtualization now available on EC2 instances",
      "subreddit": "aws",
      "url": "https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e",
      "author": "ckilborn",
      "created_utc": "2026-02-16 20:29:52",
      "score": 15,
      "num_comments": 1,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "compute",
      "permalink": "https://reddit.com/r/aws/comments/1r6kyza/nested_virtualization_now_available_on_ec2/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5qvolp",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'compute'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+compute).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-16 20:29:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4fjvp",
      "title": "GuardDuty found outgoing SSH Bruteforce attack - what now?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "author": "Xtrearer",
      "created_utc": "2026-02-14 08:36:19",
      "score": 14,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "GuardDuty identified outbound traffic that matches SSH brute force attack patterns. \n\nThe traffic originated from one of our Windows Server 2022 instances. The instance is in a private subnet (not visible to the public internet), so no public IP, and has a SG that only allows inbound traffic on ICMP(ping) and RDP,  both of which is restricted to our AWS VPN Client SG. All outbound traffic is currently allowed.\n\nThe outgoing \"attack\" originated from random local ports - 50242 ans 60664 - and targeted what looks like Amazon Public IPs: 15.197.199.235(Washington) and 99.83.130.128(Seattle)  on remote port 22 (SSH)\n\nThe machine was switched off by support, pending investigation. Ive checked the events, services and netstat, but could not find any trace of it. \n\nIve tried Googling this behavior, without any luck. Any ideas?\n\nAt this point I will be rebuilding a new server just to be safe.\n\n[Solved]",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5bh0gs",
          "author": "Xtrearer",
          "text": "Source has been found. Misconfigured internal sftp interface. Occams razor - if no body can get in, it must be your own fault. \n\nThe AWS IPs were linked to a Global Accelerator that fronts our File Transfer Server. This exists in another account which made it difficult to track.\n\nWe were almoat DDOS'd a while back so immediatly assumed bad actors... so yay I guess.",
          "score": 41,
          "created_utc": "2026-02-14 10:11:27",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5c1371",
              "author": "SheriffRoscoe",
              "text": "Thank you, [DenverCoder9](https://xkcd.com/979/).",
              "score": 10,
              "created_utc": "2026-02-14 13:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ck44k",
                  "author": "creamersrealm",
                  "text": "Lol thank you for the reference.",
                  "score": 5,
                  "created_utc": "2026-02-14 15:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5baitc",
          "author": "morimando",
          "text": "Isolate the instance and restore from an known good image. Keep isolation ideally until you‚Äôve verified that clients with access to the server are clean. Review access permissions and user actions. Likely something has laterally moved from your network into the server and potentially has persistence on your network. Ensure endpoint protection is running on all devices and do offline scans of the data layer where possible to find potential root kits.",
          "score": 11,
          "created_utc": "2026-02-14 09:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bh8o6",
              "author": "Xtrearer",
              "text": "Yeah this was exactly my playbook which lead to the \"culprit\".",
              "score": 1,
              "created_utc": "2026-02-14 10:13:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bhmyo",
                  "author": "morimando",
                  "text": "The potentially dangerous bit is if someone had put in a backdoor / remote shell of some sort longer ago that evades detection and made it into backups. \n\nDo you have Guard Duty EC2 Protection on that server? Also in case you happen to be on Enterprise Support, look into enabling Security Incident Response service",
                  "score": 4,
                  "created_utc": "2026-02-14 10:17:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5b8bi3",
          "author": "theculture",
          "text": "I would be considering that whatever is on the other side of that VPN is either compromised or a bad actor.",
          "score": 3,
          "created_utc": "2026-02-14 08:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5be5fo",
          "author": "ChiefOtacon",
          "text": "This one feels like a Security Speciality Certification question :D\n\nMost likely something on the other end of your VPN is compromised and moved on to Your instance",
          "score": 2,
          "created_utc": "2026-02-14 09:43:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b8svk",
          "author": "dghah",
          "text": "Treat as breach and activate your incident response plan. Rebuilding the windows server is correct. Maybe turn on VPC flow logs if not on already.  \n\nFeels like either a RDP user did something dodgy while connected or something installed on windows server got compromised.\n\nSince AWS had to tell you that you got popped consider this a sign that you may not have good visibility elsewhere in your IT landscape ‚Äî maybe your VPN service credentials or a user device that use VPN is compromised or RAT‚Äôed",
          "score": 1,
          "created_utc": "2026-02-14 08:50:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1y6ri",
      "title": "I built a Python DynamoDB ORM with real async - Rust + Tokio under the hood, GIL released",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "author": "leandro_damascena",
      "created_utc": "2026-02-11 14:02:22",
      "score": 13,
      "num_comments": 13,
      "upvote_ratio": 0.68,
      "text": "Hey r/aws,\n\nI've been working on an open source DynamoDB library called **pydynox**. It's a Python ORM but the heavy lifting happens in Rust via PyO3.\n\nWanted to share how I handle async because I think it's interesting.\n\n## The problem with most Python DynamoDB libraries\n\nThey either do sync-only, or they wrap sync calls with `asyncio.to_thread()`. That's not real async. You're still blocking a thread somewhere.\n\n## What I do instead\n\nThe Rust core uses Tokio (Rust's async runtime) to talk to DynamoDB. When you call an async method from Python, it goes like this:\n\n1. Python `await`s the call\n2. PyO3 hands it to Tokio on the Rust side\n3. Tokio makes the HTTP request without holding the GIL\n4. Result comes back to Python\n\nThe GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\n## Why this matters\n\nThis helps in any Python app ‚Äî Lambda, ECS, FastAPI, Django, scripts, whatever.\n\n- Serialization/deserialization happens in Rust ‚Äî type conversion is fast\n- Compression (zstd) and encryption (AES-GCM) also run in Rust with the GIL released\n- Zero Python runtime dependencies, so installs are small and there are no conflicts\n- On Lambda specifically, cold starts stay lean and warm invocations hit the Rust fast path\n\n## Quick example\n\n```python\nimport asyncio\nfrom pydynox import Model, ModelConfig, DynamoDBClient\n\nclient = DynamoDBClient()\n\nclass User(Model):\n    model_config = ModelConfig(table=\"users\")\n    pk: str\n    name: str\n    email: str\n\nasync def main():\n    user = User(pk=\"USER#1\", name=\"John\", email=\"john@example.com\")\n    await user.save()\n\n    found = await User.get(pk=\"USER#1\")\n    print(found.name)\n\nasyncio.run(main())\n```\n\nSync works too ‚Äî same API, just drop the `await`.\n\n## Performance\n\nSerialization alone is faster because Rust handles the Python-to-DynamoDB type conversion directly instead of going through multiple dict transformations.\n\nThe library is Apache 2.0 and on GitHub.\n\nDocs: [https://ferrumio.github.io/pydynox/](https://ferrumio.github.io/pydynox/)\n\nIf you've tried mixing Rust and Python for AWS stuff, I'd love to hear how it went. Questions are welcome too.\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tabjj",
          "author": "ElectricSpice",
          "text": "> The GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\nPython doesn‚Äôt lock up waiting for the network, that would be ridiculous. Other threads will happily run while waiting on the HTTP response.\n\nThe other reasons are more compelling:  boto3 is a humongous dependency and its serde is quite slow.",
          "score": 23,
          "created_utc": "2026-02-11 15:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ulcyq",
          "author": "idkbm10",
          "text": "Is there something like this for nodejs?",
          "score": 2,
          "created_utc": "2026-02-11 19:08:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sxa6c",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-02-11 14:22:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t04kx",
              "author": "Turbulent-Log5758",
              "text": "This comment looks more of an AI slop than the library.",
              "score": 13,
              "created_utc": "2026-02-11 14:37:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sxnzw",
          "author": "Spoonyyy",
          "text": "Ayo this sounds awesome. Will check it out.",
          "score": 2,
          "created_utc": "2026-02-11 14:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tdtlf",
          "author": "AdPhysical9992",
          "text": "There is one module called pynamodb , that does the same thing i guess",
          "score": 2,
          "created_utc": "2026-02-11 15:45:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vjn14",
              "author": "KainMassadin",
              "text": "comparing this to pynamo isnt fair for pynamo, lol",
              "score": 8,
              "created_utc": "2026-02-11 21:53:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tfu9n",
          "author": "mylasttry96",
          "text": "Can this be installed in lambda environments ?",
          "score": 2,
          "created_utc": "2026-02-11 15:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52gubg",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-12 23:02:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r621ua",
      "title": "When can we get certification vouchers?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r621ua/when_can_we_get_certification_vouchers/",
      "author": "HistoricalTear9785",
      "created_utc": "2026-02-16 06:21:51",
      "score": 10,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "I wanted to check if anyone knows about any upcoming AWS events where free certification vouchers might be offered. Last year, they provided 50% discount vouchers are there any similar opportunities coming up this year?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r621ua/when_can_we_get_certification_vouchers/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5nejtq",
          "author": "MavZA",
          "text": "AWS provides them sporadically really. Sometimes they have certification drives, but it‚Äôs up to their internal team planning etc. we simply don‚Äôt have a view on that.",
          "score": 6,
          "created_utc": "2026-02-16 08:08:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o1cy4",
          "author": "alex_aws_solutions",
          "text": "When you take an exam they will provide you with an 50% discount for the next one. ",
          "score": 3,
          "created_utc": "2026-02-16 11:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qrxsu",
          "author": "Thinguist",
          "text": "Just get a job that pays for them. I‚Äôve done 7 now for free.",
          "score": 1,
          "created_utc": "2026-02-16 20:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5splkf",
          "author": "socaltrey",
          "text": "Our account manager always seems to be offering them.  I've never found anyone on the team that wants to take AWS on the offer of free certification.",
          "score": 1,
          "created_utc": "2026-02-17 02:28:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3m2un",
      "title": "Cloud Computing Career Path: SA, DevOps, or ML Engineer?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r3m2un/cloud_computing_career_path_sa_devops_or_ml/",
      "author": "shawnenso",
      "created_utc": "2026-02-13 10:48:35",
      "score": 10,
      "num_comments": 19,
      "upvote_ratio": 0.92,
      "text": "Hey there good people, I'm a computer science grad looking to specialize in cloud computing and I'm stuck between:\n\n1.Solutions Architect\n\n2. DevOps\n\n3. Machine Learning Engineer\n\nI've got 6 months to master one of these. Can anyone share their experience or point me in the right direction? What are the pros and cons of each role? Any roadmaps or resources to get started?\n\nThank you, I really appreciate you in advance.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r3m2un/cloud_computing_career_path_sa_devops_or_ml/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o55yy6g",
          "author": "Dandama",
          "text": "It is important to note that the SA role, especially at AWS, is considered pre-sales. This means you are working as part of a sales team and therefore have a lot of face time with various stakeholders within your customers organization. While it is important to understand the technology to solve business problems, having strong soft skills is just as crtical.",
          "score": 12,
          "created_utc": "2026-02-13 14:04:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o559q64",
          "author": "Sirwired",
          "text": "Well, you won't be \"mastering\" anything in six months...\n\nAn architect needs to be extremely strong in IT infrastructure fundamentals, which is something not commonly taught in college CS classes. You'll need to do a ton of studying on your own.\n\nDevOps is a combination of infrastructure and development; you'll need to understand automated pipeline tools and workload sizing.\n\nML?  If your CS program is math-heavy, then this might be a good choice. ML classes would be best, but barring that ask your professors for advice.",
          "score": 9,
          "created_utc": "2026-02-13 11:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55fuow",
              "author": "enjoytheshow",
              "text": ">An architect needs to be extremely strong in IT infrastructure fundamentals, which is something not commonly taught in college CS classes. You'll need to do a ton of studying on your own.\n\nAlso like 5+ YOE. There aren‚Äôt entry level architect positions. Every good cloud or solution architect has  done it enough times that you have the knowledge and experience of what not to do next time.",
              "score": 2,
              "created_utc": "2026-02-13 12:08:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aqn7b",
                  "author": "shawnenso",
                  "text": "What are you suggesting I should do?",
                  "score": 1,
                  "created_utc": "2026-02-14 06:01:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5aqxvt",
              "author": "shawnenso",
              "text": "I am willing to learn and work without getting paid just to gain the experience.",
              "score": 0,
              "created_utc": "2026-02-14 06:03:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dal0d",
                  "author": "Sirwired",
                  "text": "Doing productive work without pay is not even legal in most countries, unless you can find a charitable organization to volunteer for that could use the (limited) skills of a college student.",
                  "score": 2,
                  "created_utc": "2026-02-14 17:18:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55b3up",
          "author": "courage_the_dog",
          "text": "I mean you're not going to master any of this in 6months lol most of these are senior level roles normally.\nYou'd have to have been building architecture in order to be an SA, you'd have to have dealt with dev and operstions to become a devops.\nChances of landing a junior role in any of these are slim",
          "score": 5,
          "created_utc": "2026-02-13 11:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aqj4c",
              "author": "shawnenso",
              "text": "Where, how,what can I use to start?",
              "score": 1,
              "created_utc": "2026-02-14 06:00:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5anus7",
          "author": "Human-Job2104",
          "text": "Solutions Architect Professional and Gen AI professional, these are probably the hottest and most relevant skills. Both have Associate level you can do on your way up to pro.\n\nDevops is great, but a little too focused on some AWS specific tool sets that most devs might not use.\n\nML is great, but AI is hotter and growing faster imo.",
          "score": 3,
          "created_utc": "2026-02-14 05:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aqd22",
              "author": "shawnenso",
              "text": "Thank you for this. You are the only one so far who didn't tell me it cannot be done.",
              "score": 2,
              "created_utc": "2026-02-14 05:58:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5as4nv",
                  "author": "Human-Job2104",
                  "text": "You got this!\n\nUdemy courses and practice exams by these guys are great: Stephane Maarek, Neal Davis, Abhishek Singh, Frank Kane\n\nThey are on sale almost every day. Only buy them when 80-90% off.\n\nDo the associate exam first. When you pass, you get a 50% off coupon for the next test. You can even start w/ practitioner. It's the cheapest exam and if you took and passed practitioner, then associate, then pro w/ the cupons, it'd cost the same as taking the pro exam once.\n\nDo the labs in the courses for practice. And take the practice exams till you pass consistently. \n\nMix that with real world work and consistency and you'll be an expert in no time! Good luck!",
                  "score": 1,
                  "created_utc": "2026-02-14 06:14:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5fl3ia",
          "author": "o5mfiHTNsH748KVq",
          "text": "Don't think of DevOps as a career path, think of it as something you do to achieve being an effective Solutions Architect or ML Engineer (i'm guessing you mean ML Ops?)\n\nIt can be a career path, but that line of thinking is limiting. Be a well rounded engineer that values a DevOps mindset.",
          "score": 2,
          "created_utc": "2026-02-15 00:51:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o573vre",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-13 17:25:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58yy97",
          "author": "mylasttry96",
          "text": "‚ú®Delusion‚ú®",
          "score": 1,
          "created_utc": "2026-02-13 22:57:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58zfb4",
              "author": "mylasttry96",
              "text": "In all seriousness you‚Äôd be lucky to get hired on as a jr cloud engineer w little to no experience",
              "score": 3,
              "created_utc": "2026-02-13 23:00:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aq4po",
                  "author": "shawnenso",
                  "text": "That's why I asked for a roadmap, those professionals started from somewhere.",
                  "score": 1,
                  "created_utc": "2026-02-14 05:56:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r324m8",
      "title": "AWS Cognito Experience",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "author": "True_Context_6852",
      "created_utc": "2026-02-12 18:59:57",
      "score": 9,
      "num_comments": 25,
      "upvote_ratio": 0.8,
      "text": "Hello  Good People ,\n\nOur org are planning to  migrate the our legacy app sign up process to  AWS Cognito . So  plan is First start the JIT with lambda for new sign up  and later  second step to  migrate all  user to  Cognito and forced reset password . final steps  when all looks fine than enable MFA to all  users . My question is AWS Cognito  right step or should we look other options  like okta or OAuth ? What you people have experienced during migration  ? What other area we need to look so existing user not lost the credentials?  \n\n ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o518j8p",
          "author": "MuffinMan_Jr",
          "text": "Im using cognito right now for my app, and the developer experience is terrible lol\n\nThat being said, you'd get lots of free MAU so I guess that's cool",
          "score": 29,
          "created_utc": "2026-02-12 19:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51xs9v",
              "author": "True_Context_6852",
              "text": "May I know what is terrible please ?",
              "score": 1,
              "created_utc": "2026-02-12 21:27:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o516zjd",
          "author": "Whend6796",
          "text": "Look elsewhere. \n\n- The documentation is notoriously confusing and poorly organized\n- The service has layers of abstraction that make simple tasks complicated\nAPI Design Issues\n- Inconsistent and unintuitive naming conventions\n- Methods that don‚Äôt follow AWS naming patterns used elsewhere\n- Confusing parameter requirements and error messages\n- The SDK can be clunky to work with\nLimited Flexibility\n- User migration from existing systems is painful\n- Customization options for authentication flows are restrictive\n- The hosted UI is difficult to customize and looks dated\n- Hard to implement certain common auth patterns\nToken Management Problems\n- Token refresh flows can be confusing\n- Limited control over token lifetimes and claims\n- Issues with token validation in certain scenarios\nDeveloper Experience\n- Simple tasks often require digging through documentation and Stack Overflow\n- Error messages that don‚Äôt clearly explain what went wrong\n- Testing authentication flows locally is cumbersome",
          "score": 41,
          "created_utc": "2026-02-12 19:19:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o568zic",
              "author": "methods2121",
              "text": "Props to this correct and succinct overview.   This would be valuable across almost every AWS service to separate the 'hype' vs. reality.  I second that Cognito would be very low on my list based on your requirements above and you should definitely look and preferably test others.",
              "score": 2,
              "created_utc": "2026-02-13 14:56:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o517lty",
          "author": "Wide_Commission_1595",
          "text": "I am usually in the \"AWS all the things\" camp, but Cognito is a tricky one.\n\nCognito _can_ be great for simple sign up flows.  It can even be pretty good with complex federations.  It's also damned cheap compared with other IdPs, but....\n\nThere's a ton of wiring Lambda functions into hooks to make it work the way most people want it to.  If you don't need those things, go with Cognito every day of the week.\n\nIf you want something a little more \"managed\" that just works, I have found external identity providers to be a lot simpler to use.\n\nWe use Okta, but basically any OIDC or SAML IdP (that's all of them!) works well.\n\nYou can even assume roles with web identity etc to do external-IdP-to-AWS role assumption.\n\nGenerally speaking, an external IdP will be simpler, but more expensive, especially as user numbers grow.  Cognito requires more plumbing, but is AWS-native.",
          "score": 12,
          "created_utc": "2026-02-12 19:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530s9s",
          "author": "MrStu56",
          "text": "It's horrible to work with, but when it's up and running it's cheap and reliable. If I had one 2026 AWS wish it would be for AWS to give this service the once over, take a look how people are using it now vs what was envisioned and then re-document it like their other services. This has to be the most opaque service I've ever worked with on AWS. ",
          "score": 6,
          "created_utc": "2026-02-13 00:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ioxny",
              "author": "DocterDum",
              "text": "Now now, we all know ‚Äúgive this service the once over‚Äù will end up being just a new interface slapped on with half the features missing, a few new garbage features nobody asked for, and a massive stack of bugs to boot.\n\n\n\n*Speaking from general large company experience, I haven‚Äôt paid a ton of attention to AWS specifically",
              "score": 1,
              "created_utc": "2026-02-15 15:19:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5iqua9",
                  "author": "MrStu56",
                  "text": "Well I've often wondered if Cognito could work internally with a VPC endpoint like loads of other services. I could see that being really handy, but couldn't see why it was seemingly deliberately left out.",
                  "score": 1,
                  "created_utc": "2026-02-15 15:29:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o518nbb",
          "author": "BadDescriptions",
          "text": "If you have good engineers then use Cognito. If you have bad engineers and loads of money then use okta/auth0",
          "score": 9,
          "created_utc": "2026-02-12 19:27:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53c1ll",
              "author": "BoostedHemi73",
              "text": "This is the most concise advice I‚Äôve seen on this topic.\n\nCognito is full of footguns. Test carefully and completely. If you are using CloudFormation, pay very careful attention to the defaults that are applied (like case sensitive email).\n\nBut the price is great for low/moderate MAU.",
              "score": 3,
              "created_utc": "2026-02-13 02:05:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53t8s3",
              "author": "VladyPoopin",
              "text": "This. If you have a solid engineer who ca actually wrap their head around how it works and utilize your own UI over the hosted UI, it‚Äôll work well for you.\n\nThat being said, that‚Äôs a hurdle for sure.",
              "score": 1,
              "created_utc": "2026-02-13 03:53:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51qwzb",
          "author": "macgoober",
          "text": "Cognito is dirt cheap if your MAU is less than 50k. The dev experience without something like sst.dev is a total nightmare tho.",
          "score": 2,
          "created_utc": "2026-02-12 20:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52vbqj",
          "author": "mouthbuster",
          "text": "Cognito is pain\nOkta/Auth0/Clerky will all get the job done the easiest at the highest cost\n\nCheck out Keycloak if you have the engineering bandwidth - it can do anything you‚Äôd ever want for the sweet cost of hosting it. Can meet any regulatory compliance need I‚Äôve ever ran into, and you can host this thing anywhere.",
          "score": 2,
          "created_utc": "2026-02-13 00:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535f4b",
          "author": "texxelate",
          "text": "Don‚Äôt use Cognito if you have any choice whatsoever. You‚Äôll have another legacy app sign up process from day 1.",
          "score": 2,
          "created_utc": "2026-02-13 01:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59i8t6",
          "author": "Howlla_",
          "text": "The good thing about authentication flows is that you shouldn't be changing that code frequently. It should be thoroughly tested and deployed in a production environment and cognito is the cheapest option.\nIf you need simpler stepup or plan on making many complex requirements then other ISV solutions like okta are amazing.",
          "score": 2,
          "created_utc": "2026-02-14 00:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o513pvk",
          "author": "SoggyGrayDuck",
          "text": "Maybe you can clear something up for me. We had a handful of our data engineers converted to BI engineers but they work with cognito? That's confusing to me",
          "score": 1,
          "created_utc": "2026-02-12 19:03:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516srq",
              "author": "True_Context_6852",
              "text": "I am talking about B2C customer migration as current sign up  process involved with SQL DB where user save credential  and later sign in with  same credentials . Now we want to  migrate all  sues to AWS Cognito  .The ask is what  is over all  experience if any body  did it like our org are on retail end .  ",
              "score": 1,
              "created_utc": "2026-02-12 19:18:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o519g3k",
          "author": "Alternative-Expert-7",
          "text": "Cognito is cheaper comparing to AuthO or Okta. Or the cheapest if you have big number of users.",
          "score": 1,
          "created_utc": "2026-02-12 19:30:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5234rn",
          "author": "Prestigious_Pace2782",
          "text": "The dev experience is pretty poor, but it‚Äôs nice to have it all in CDK and it‚Äôs cheap and mostly just works once it‚Äôs set up. \n\nI normally start a new project with cognito and use it until it becomes painful or doesn‚Äôt support something I need. Sometimes that doesn‚Äôt happen and it‚Äôs fine.\n\nHave used it at work in some pretty big stuff and had to get pretty in the weeds with apig caching and stuff.\n\nTLDR; It‚Äôs cheap and works well but is feature poor and a bit painful to learn.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52fy4b",
              "author": "True_Context_6852",
              "text": "Did you face real challenge with real customer during migration",
              "score": 1,
              "created_utc": "2026-02-12 22:57:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o53fgwe",
          "author": "cuddle-bubbles",
          "text": "horrible but great for your resume. if ur the engineering manager and dont have to do it yourself. may be a good idea to let your developers suffer while you add a great bullet point to your resume at the end of it",
          "score": 1,
          "created_utc": "2026-02-13 02:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54fnpk",
          "author": "hungrysandiegan",
          "text": "If you can leverage the Managed Login, Cognito works great and is cheap! Lots of companies can‚Äôt go the managed login route and have to use custom UI where its a pain!",
          "score": 1,
          "created_utc": "2026-02-13 06:43:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58g9mu",
          "author": "Past-Owl-3180",
          "text": "Won't recommend Cognito for even simpler use-cases. AWS has screwed up evolution of this, once great product.",
          "score": 1,
          "created_utc": "2026-02-13 21:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5963yt",
          "author": "GuavaRevolutionary56",
          "text": "Go with Okta or Ping. So much to bolt on for AWS Cognito.",
          "score": 1,
          "created_utc": "2026-02-13 23:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55a1xy",
          "author": "bajcmartinez",
          "text": "Cognito is just one more service into the hundreds of AWS services and doesn't seem like an important one based on its evolution, documentation and overall DX.\n\nI wouldn't recommend building your own auth, but you can choose from services like Auth0 for easy setup, good docs and DX, though depending on the number of users and features required you can go with a free plan or one of the plans. Alternatively, open-source solutions like Keycloak are pretty good, though that's again, more engineering work required for set up and maintenance.",
          "score": 0,
          "created_utc": "2026-02-13 11:22:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3ytpa",
      "title": "Amazon RDS now supports backup configuration when restoring snapshots",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-aurora-backup-configuration-restoring-snapshots/",
      "author": "risae",
      "created_utc": "2026-02-13 19:36:37",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r3ytpa/amazon_rds_now_supports_backup_configuration_when/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5bubfs",
          "author": "bot403",
          "text": "What's the big deal with just setting it up after it's started? I get this is a nice change but OP implies it fixes some larger issue.",
          "score": 1,
          "created_utc": "2026-02-14 12:14:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e4t24",
              "author": "risae",
              "text": "It doesn't make sense that you can specify certain things, but not this¬†",
              "score": 1,
              "created_utc": "2026-02-14 19:51:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r57wqh",
      "title": "any quick method or automation is available to delete iam roles that are unused ?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r57wqh/any_quick_method_or_automation_is_available_to/",
      "author": "Any_Animator4546",
      "created_utc": "2026-02-15 06:52:27",
      "score": 8,
      "num_comments": 18,
      "upvote_ratio": 0.79,
      "text": "For my better understanding I create a new IAM role every time I create a new service in AWS. I am still learning these access control permissions. I want to know if there is a quick automatic way in which I can delete the IAM roles that are no longer been used ?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r57wqh/any_quick_method_or_automation_is_available_to/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5gzo9v",
          "author": "the_programmr",
          "text": "IaC is your friend here. If you use something with CDK/TF, you can delete all resources and associated IAM roles when you delete a stack.  \n\nIf the IAM roles you‚Äôre referring to here were created manually, would have to create a script using the AWS SDK to loop through roles and delete based on last usage time.",
          "score": 16,
          "created_utc": "2026-02-15 07:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h0rbr",
              "author": "Any_Animator4546",
              "text": "thanks",
              "score": 2,
              "created_utc": "2026-02-15 07:23:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jjfhf",
                  "author": "SpecialistMode3131",
                  "text": "Don't forget you can use IAC Generator to create the cloudformation stack, \\*then\\* blow away what you want gone.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:48:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hwjgm",
          "author": "weirdbrags",
          "text": "cloud custodian can help \n\nhttps://cloudcustodian.io/docs/aws/resources/iam.html",
          "score": 3,
          "created_utc": "2026-02-15 12:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ig0w0",
              "author": "pazarr",
              "text": "This is my preferred way too.",
              "score": 1,
              "created_utc": "2026-02-15 14:31:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hog6t",
          "author": "mrlikrsh",
          "text": "There is a last activity on the iam console for the role, not sure if you can get this programmatically",
          "score": 2,
          "created_utc": "2026-02-15 11:12:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hcp2k",
          "author": "pazarr",
          "text": "You can set up a cloud custodian. I quite like the tool.",
          "score": 1,
          "created_utc": "2026-02-15 09:19:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5he01n",
              "author": "Any_Animator4546",
              "text": "hi i am using a boto3 python script",
              "score": -2,
              "created_utc": "2026-02-15 09:32:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ii409",
                  "author": "pazarr",
                  "text": "If you don't want to use anything but boto, you can get last accessed information and than take action. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_last-accessed-view-data.html",
                  "score": 1,
                  "created_utc": "2026-02-15 14:43:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ndux5",
          "author": "ilyas-inthe-cloud",
          "text": "Check the \"Last activity\" column in the IAM console, it shows when each role was last used. For the ones showing 30+ days of inactivity you can safely nuke them. But honestly if you're learning, start using CloudFormation or CDK now. When you delete a stack it cleans up all the roles it created. Saves you from this exact problem going forward.",
          "score": 1,
          "created_utc": "2026-02-16 08:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hdfft",
          "author": "pint",
          "text": "no, because there is no such thing as \"used\" role. nobody knows if you have a script somewhere that uses that role. including you yourself, because what if you reused one of these auto-generated roles somewhere, and the forgot?\n\nroles have last access time. also, roles have a trust policy, which tells you where the role is allowed to be used. if only lambda is allowed for example, you know it is not used anywhere else.\n\nif you are not a programmer, you might get an ai chatbot to develop a script for you to make a list with these fields for review. trusting an ai to develop the deletion script is a little more fishy.\n\nif you are some of a programmer, or willing to take on the task, you can use any sdk (e.g. boto3) to do this programmatically.\n\na middle ground is ai developed listing script, followed by manual review, followed by an excel-generated list of aws cli commands in a cmd file (assuming windows).",
          "score": -2,
          "created_utc": "2026-02-15 09:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ihrbm",
              "author": "pazarr",
              "text": "In fact you can check the last time an IAM role has been accessed. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_last-accessed-view-data.html\n\nThis can be easily accessible via aws api or cli.",
              "score": 2,
              "created_utc": "2026-02-15 14:41:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5je2ub",
                  "author": "pint",
                  "text": "that's what i said",
                  "score": 0,
                  "created_utc": "2026-02-15 17:22:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1u1hx",
      "title": "Insert my cert to Traefik in ECS via Terraform/Secrets Manager",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "author": "Budget-Industry-3125",
      "created_utc": "2026-02-11 10:39:43",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "Hi,\n\nI need to create a configuration where I implement a NLB for a TLS passthrough towards my Traefik container within the cluster.\n\nThe traefik container needs to serve my own certificate, and i don't know how to import it. \n\nI tried to use secrets manager, but I don't know how to implement it. is there any other way? ",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4sclg0",
          "author": "Living_off_coffee",
          "text": "Have you tried AWS Certificate Manager (ACM)? It's designed for things like this.\n\nBut is there a specific reason you want to have TLS pass through with the NLB? You can terminate it at the load balancer instead which might be easier.",
          "score": 5,
          "created_utc": "2026-02-11 12:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4siyfo",
          "author": "KayeYess",
          "text": "What was the challenge with pulling the certificate keys from Secrets Manager? It's just like pulling any other secret.\n\n\nYou could also pull your certs from S3, SSM or ACM (which now allows private keys to be exported).",
          "score": 2,
          "created_utc": "2026-02-11 13:01:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t7avu",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.  \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tbmbm",
                  "author": "KayeYess",
                  "text": "OK. The certs are in secrets manager.\n\n\ntraefik itself is not capable of accessing aws secrets but a separate script (like cert-manager) can be used to sync them to kube secrets, which trafiek can refer to.",
                  "score": 2,
                  "created_utc": "2026-02-11 15:35:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4skir6",
          "author": "safeinitdotcom",
          "text": "Hi,\n\nWhat exactly failed for you in implementing secrets manager for this? Typically you should've been able to inject the secrets to ecs and then write them to files during startup :D ",
          "score": 2,
          "created_utc": "2026-02-11 13:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t79ds",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.   \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r593tt",
      "title": "How are the Nova 2 models for text processing",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r593tt/how_are_the_nova_2_models_for_text_processing/",
      "author": "2B-Pencil",
      "created_utc": "2026-02-15 08:05:50",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.9,
      "text": "I currently have a text processing workload that is using Gemini 3 Flash: summarization, keyword extraction, etc. Nothing fancy. But I do have to process the occasional 500k token document which is why I like Gemini. It does fairly well even with really big text  \n\n\n\nBut all my infra is on AWS and I have Activate credits for my project so I was strongly considering switching to Nova 2 models for cost savings. \n\n  \nwhat‚Äôs everyone‚Äòs experience with Nova 2 model family?",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1r593tt/how_are_the_nova_2_models_for_text_processing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5hdz7k",
          "author": "Sirwired",
          "text": "Every use case is different; while you could do something fancy with a whole system to score responses for comparison ( [https://aws.amazon.com/bedrock/evaluations/](https://aws.amazon.com/bedrock/evaluations/) ), you can just start by taking a couple of your trickier inputs and eyeballing the result.\n\nCertainly Nova 2 is pretty value-priced.",
          "score": 2,
          "created_utc": "2026-02-15 09:32:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r791ot",
      "title": "How to automate aws savings plans without manual quarterly analysis?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r791ot/how_to_automate_aws_savings_plans_without_manual/",
      "author": "My_Rhythm875",
      "created_utc": "2026-02-17 15:30:12",
      "score": 7,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Every quarter there's this ritual where you analyze usage patterns, try to predict future compute needs, calculate optimal savings plan coverage, submit recommendations to leadership, get approval, then finally buy commitments. By the time the whole process finishes usage has already changed and the analysis is outdated.\n\nCommitment recommendations in cost explorer are okay as a starting point but they don't account for upcoming projects, seasonal traffic patterns or planned architecture changes. They just look at historical usage and say \"buy this much\" which is often wrong.\n\nUnder committing means leaving savings on the table, over-committing means paying for capacity you don't use and the optimal middle ground requires constant adjustment. Three year commitments save more but lock you in longer which is risky for startups where everything changes constantly.\n\nCoverage percentage drops randomly when workloads shift and you need to evaluate whether to buy more which savings plan type makes sense (compute vs ec2) and what term length is appropriate. Feels like this should be automated somehow but I haven't found anything that actually works reliably\n\nIs there a good workflow for this or is manual quarterly analysis just the reality?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r791ot/how_to_automate_aws_savings_plans_without_manual/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5w2np5",
          "author": "pausethelogic",
          "text": "There are some companies that will handle this for you. In general though, this is a manual process unless you want to automate it yourself. As you‚Äôve mentioned, there is a lot of real risk associated with the different options available",
          "score": 2,
          "created_utc": "2026-02-17 16:38:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w4qpr",
          "author": "BloodAndTsundere",
          "text": "As far as overcommitting goes, I think there is a secondary market for reserved instances which can mitigate some of that risk.",
          "score": 1,
          "created_utc": "2026-02-17 16:48:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wcfwj",
          "author": "SpecialistMode3131",
          "text": "If you pay for it, you can get another human being to do this for you (We do it).  But at the end of the day, unless someone who really cares is looking hard at your spend versus your business objectives, you cannot know if that money is being wisely spent.\n\nSo the only real decision is whether you're doing that in-house, paying someone for it out of house, or just choosing not to do it at all.  People do all three things, with varying degrees of competence, with the variance in results you'd expect.",
          "score": 1,
          "created_utc": "2026-02-17 17:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5whnw7",
          "author": "CharacterHand511",
          "text": "Three year commitments are scary for startups yeah, one-year terms are safer because who knows what infrastructure will look like in 2027",
          "score": 1,
          "created_utc": "2026-02-17 17:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5whzbt",
          "author": "Sea-Car8041",
          "text": "coverage dropping is annoying bc u have to investigate why, is it a good change (moved to cheaper instances) or bad change (accidentally lost coverage)... requires manual analysis either way",
          "score": 1,
          "created_utc": "2026-02-17 17:53:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wklc1",
          "author": "galiyonkegalib",
          "text": "cost explorer recommendations are too simplistic, they don't understand context like \"migrating to lambda next quarter\" or \"traffic doubles in q4 every year\"",
          "score": 1,
          "created_utc": "2026-02-17 18:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wmmjr",
          "author": "lostsomewhere--",
          "text": "Automation would be nice but trusting a tool to automatically buy commitments feels risky without human review first like what if the algorithm makes a mistake and commits you to $50k of unnecessary capacity. Some tools like prosperops try to do this or there's vantage autopilot feature that handles it but I'd want to really understand the logic before letting it run unsupervised",
          "score": 1,
          "created_utc": "2026-02-17 18:14:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wo86r",
          "author": "Connect_Street_867",
          "text": "Compute savings plans vs ec2 specific is another decision point, compute is more flexible but ec2 specific saves more... depends on whether you value flexibility or max savings",
          "score": 1,
          "created_utc": "2026-02-17 18:21:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5xhihu",
          "author": "TooMuchTaurine",
          "text": "Why quarterly, we just do it once a year, try to maintain about 95% coverage at peak to give us some buffer.",
          "score": 1,
          "created_utc": "2026-02-17 20:39:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}