{
  "metadata": {
    "last_updated": "2026-01-22 08:58:07",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 132,
    "file_size_bytes": 197001
  },
  "items": [
    {
      "id": "1qds6k2",
      "title": "AWS flips switch on Euro cloud as sovereignty fears mount",
      "subreddit": "aws",
      "url": "https://www.theregister.com/2026/01/15/aws_european_sovereign_cloud/?td=rt-3a",
      "author": "NISMO1968",
      "created_utc": "2026-01-15 18:51:57",
      "score": 422,
      "num_comments": 198,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qds6k2/aws_flips_switch_on_euro_cloud_as_sovereignty/",
      "domain": "theregister.com",
      "is_self": false,
      "comments": [
        {
          "id": "nztiz50",
          "author": "teo-tsirpanis",
          "text": "My â€˜The AWS European Sovereign Cloud is operated exclusively by EU citizens located in the EUâ€™ t-shirt is raising many questions already answered by the t-shirt",
          "score": 20,
          "created_utc": "2026-01-15 23:10:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o006nun",
              "author": "SoldadoAruanda",
              "text": "I feel like it's suspicious,  as if I move to a new town, and my neighbor introduced himself by saying,  \"Hi, my names Jeff, and don't worry,  I don't murder people in my basement.\"",
              "score": 3,
              "created_utc": "2026-01-16 22:19:55",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsbh4j",
          "author": "arwinda",
          "text": "Has the USA, using the Cloud Act, still access to the data? Yes or no.",
          "score": 84,
          "created_utc": "2026-01-15 19:44:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzse14r",
              "author": "ShakataGaNai",
              "text": "Clearly AWS's goal is \"No\", because if it can still be CLOUD'd then it's effectively useless. But that's going to be in a court of law to try and untangle that. It's a cloud infra in Europe, run by Europeans, run by a new European company,  independent of anything American.",
              "score": 52,
              "created_utc": "2026-01-15 19:55:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzser32",
                  "author": "arwinda",
                  "text": "The Cloud Act allow access as long as the European company is a subsidiary. For AWS this requires a fully independent company. Which also pays all taxes in Europe, as example. No more money extraction to the US.",
                  "score": 36,
                  "created_utc": "2026-01-15 19:59:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvttyk",
                  "author": "afroisalreadyinu",
                  "text": "\\> independent of anything American\n\nnamed AWS, same hardware, software and API, funded by the American entity, so I doubt this.",
                  "score": 5,
                  "created_utc": "2026-01-16 07:49:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz4tha",
                  "author": "Hopeful-Programmer25",
                  "text": "I simply donâ€™t believe there is no link to the parent US AWS company, otherwise itâ€™s not a subsidiary, itâ€™s a competitor to US AWS. if no money is flowing to the US parent then AWS has effectively withdrawn from the EU market.\n\nObviously, it hasnâ€™t so the fact itâ€™s a subsidiary means that the US can easily apply pressure to the parent. Legality means nothing if the US parent can just replace the CEO and board of an â€œindependentâ€ subsidiary as they own all the shares with people who are compliant.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:21:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0fgxf2",
                  "author": "ProfessorNoPuede",
                  "text": "Ah, yes, law. The American republican administration really cares about law. \n\n/s, in case it wasn't obvious.",
                  "score": 1,
                  "created_utc": "2026-01-19 05:40:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsol0n",
              "author": "HanzJWermhat",
              "text": "If itâ€™s anything like GovCloud no. You need citizenship to access the region, all customer data is stored in the region.\n\nOperational logs probably get exported and centralized however",
              "score": 10,
              "created_utc": "2026-01-15 20:45:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuel3w",
                  "author": "wlonkly",
                  "text": "> You need citizenship to access the region\n\nThat's not correct -- you need to be a US person to open an account, but what happens after that is up to you (and your sponsoring agency).  \n\nI'm Canadian and have access to my company's GovCloud accounts.",
                  "score": 6,
                  "created_utc": "2026-01-16 02:03:37",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzuklkc",
                  "author": "Skytram_",
                  "text": "Logs donâ€™t get (automatically) exported.",
                  "score": 6,
                  "created_utc": "2026-01-16 02:37:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvtklh",
                  "author": "NaCl-more",
                  "text": "Logs stay in partition",
                  "score": 4,
                  "created_utc": "2026-01-16 07:46:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx5ofi",
                  "author": "KarlHungas",
                  "text": "Operation logs, billing, everything is separate from the US AWS.  I sat in an interesting session about this at AWS reinvent",
                  "score": 3,
                  "created_utc": "2026-01-16 13:57:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzxdgz9",
                  "author": "ghillisuit95",
                  "text": "> Operational logs probably get exported and centralized however\n\nNo, AWS mostly uses the in-region CloudWatch for logging. Older services may still use something called timber, but its also regional. \n\nusage data and metrics may be visible to non-eu employees, but I don't think that's very concerning",
                  "score": 2,
                  "created_utc": "2026-01-16 14:37:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsqteu",
                  "author": "arwinda",
                  "text": "> If itâ€™s anything like GovCloud\n\nI do not see a clear confirmation in the article, nor in other articles about this announcement.\n\nAnd I also don't see any clarification that US personnel definitely won't have access. Until this is confirmed one has to assume that the US, including the government, can still access the data.",
                  "score": -13,
                  "created_utc": "2026-01-15 20:55:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrauu",
              "author": "DecisionOk474",
              "text": "They have a separate auth stack. No US citizens can physically or logically access it.",
              "score": 8,
              "created_utc": "2026-01-15 23:55:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzuio6x",
                  "author": "Sea-Us-RTO",
                  "text": "what about psychologically? ðŸ˜„",
                  "score": 4,
                  "created_utc": "2026-01-16 02:26:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzwlsio",
              "author": "coldoil",
              "text": "No.",
              "score": 2,
              "created_utc": "2026-01-16 11:55:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0e665n",
              "author": "JackSpyder",
              "text": "Presumably the US branch can request the EU branch to comply. As theyre legally obligated to do so.\n\nThe EU branch can refuse on legal grounds.\n\nPunishing them or firing them is illegal under EU regs so... jump.",
              "score": 1,
              "created_utc": "2026-01-19 00:59:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o00601y",
              "author": "conspicuousxcapybara",
              "text": "Yes. More specifically, AWS wrote in their [blog 'Five facts about how the CLOUD Act actually works'](https://aws.amazon.com/blogs/security/five-facts-about-how-the-cloud-act-actually-works/):\n\n>\"Fact 1: The CLOUD Act does not give the U.S. government **unfettered or automatic access** to data stored in the cloud.   \n  \n\\[..\\]    \n  \nTo compel a provider to disclose content data, law enforcement must convince an independent federal judge that probable cause exists related to a particular crime, and that evidence of the crime will be found in the place to be searched\"",
              "score": 1,
              "created_utc": "2026-01-16 22:16:41",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0hejrd",
                  "author": "MatthiasWM",
                  "text": "So there *is* access without any EU process. Thanks for confirming that.",
                  "score": 1,
                  "created_utc": "2026-01-19 14:45:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o099oe8",
              "author": "National_Way_3344",
              "text": "No they don't.\n\nThey've essentially spun off a whole Euro cloud staffed by Europeans only.\n\nIt's pretty fucking wild because it means Amazon could just walk out of the US given their economy is fucked.",
              "score": 0,
              "created_utc": "2026-01-18 07:55:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzseee6",
          "author": "cloudrkt",
          "text": "As long as it is a US owned company it will never be sovereign.",
          "score": 208,
          "created_utc": "2026-01-15 19:57:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsgtrt",
              "author": "landon912",
              "text": "The region is technically owned by a subsidiary HQâ€™d in Europe",
              "score": 72,
              "created_utc": "2026-01-15 20:08:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztccml",
                  "author": "FalseRegister",
                  "text": "Subsidiaries are also subject to US law",
                  "score": 50,
                  "created_utc": "2026-01-15 22:36:23",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o03bknf",
                  "author": "Flaksim",
                  "text": "The CLOUD Act (Clarifying Lawful Overseas Use of Data Act). Makes any promises made by a U.S. company or it's subsidiaries regarding data sovereignity meaningless.\n\nAWS argues its new EU entity is legally separate. However, U.S. courts have historically interpreted \"control\" broadly. If Amazon U.S. has the corporate power to force its subsidiary to act (e.g., by threatening to fire the board of directors), a U.S. judge can rule that Amazon U.S. has \"control\" over the data and order them to produce it or face contempt of court.\n\nAdd in Executive order 12333 and FISA section 702 and you have the trifecta of legal bs the US uses to justify collecting data abroad and at home with impunity, regardless of who is the owner.",
                  "score": 1,
                  "created_utc": "2026-01-17 11:58:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzzot5p",
                  "author": "No-Theory6270",
                  "text": "And lead by one guy called IsraÃ«l",
                  "score": 1,
                  "created_utc": "2026-01-16 20:54:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsoahs",
                  "author": "HanzJWermhat",
                  "text": "But the operational management and software development is all centrally managed in the US",
                  "score": -23,
                  "created_utc": "2026-01-15 20:43:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o027ztf",
                  "author": "plinkoplonka",
                  "text": "Doesn't matter. \n\nEveryone knows who pulls the strings. \n\nSame as tax breaks that are afforded by splitting global companies across regions, it's the same bullshit.",
                  "score": -1,
                  "created_utc": "2026-01-17 05:58:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztrd7m",
              "author": "Rolandersec",
              "text": "Yeah itâ€™s too late for this. The other nations are building this stuff out already and itâ€™s going to be the great commoditization and democratization of the cloud. \n\nWill probably work out great for netapp though.",
              "score": 3,
              "created_utc": "2026-01-15 23:55:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzvtmh2",
              "author": "Express-One-1096",
              "text": "It can be if itâ€™s standalone but pays royalty fees for the brand.",
              "score": 1,
              "created_utc": "2026-01-16 07:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzti94y",
          "author": "Burekitas",
          "text": "The interesting stuff:\n\n10ms latency to eu-central-1.\n\npricing on the website is not fully available yet, use the calculator (https://pricing.calculator.aws.eu/) instead.\n\nS3 is seperated from the \"regular\" S3, therefor, you can register bucket names that already exists in S3 and havn't taken yet, I created the following buckets: 1234, mobile etc. (I really want to registrer \"french-goverment\" but I think it's too much).\n\nRoute53 domains are EU tld (nl/eu/fr/de).\n\nIdentity Center is not yet available (appears in IAM but leads to 404). You can configure external SSO like Okta, OneLogin etc.\n\n  \nIn general, it sounds like AWS are still working on many features, but it's a great starting point.",
          "score": 33,
          "created_utc": "2026-01-15 23:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztod6f",
              "author": "pwnedbilly",
              "text": "It will almost certainly be a separate partition as with GovCloud and AWS China so your ARNs will still be globally unique.",
              "score": 10,
              "created_utc": "2026-01-15 23:39:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzuvg3d",
              "author": "sh1boleth",
              "text": "It wonâ€™t have full feature parity with regular aws partition ever due to the nature of operations.\n\nSome niche feature or service will be missing",
              "score": 3,
              "created_utc": "2026-01-16 03:38:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzs2ccg",
          "author": "Goon_be_gone",
          "text": "The AWS sovereignty policies are good enough for China Iâ€™m sure theyâ€™ll be good enough for the EU.",
          "score": 60,
          "created_utc": "2026-01-15 19:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsa76l",
              "author": "kestrel808",
              "text": "AWS China is distinctly different than AWS in the rest of the world.  They have their own API, you can't do things like connect vpc's globally and they're run by local partners.  China is way more than \"just another region\".",
              "score": 35,
              "created_utc": "2026-01-15 19:38:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzsb8za",
                  "author": "Kaynard",
                  "text": "Same thing for Europe, it's a new AWS partition (Like China, GovCloud, commercial AWS etc) and with one region in it for now.",
                  "score": 85,
                  "created_utc": "2026-01-15 19:43:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzsaxo2",
                  "author": "likeavirgil",
                  "text": "How is that different from the sovereign cloud offering in the EU?",
                  "score": 9,
                  "created_utc": "2026-01-15 19:41:44",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztrh7j",
                  "author": "DecisionOk474",
                  "text": "Just like every other AWS partition. That isnâ€™t china specificâ€¦..",
                  "score": 3,
                  "created_utc": "2026-01-15 23:55:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsjpgd",
              "author": "hkgwwong",
              "text": "China has other very strong alternatives, unlike Europe. As far as I know nobody consider AWS their first choice , might be way more popular among foreign companies need a cloud in China.",
              "score": 1,
              "created_utc": "2026-01-15 20:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0e7wlz",
                  "author": "Busy-Explanation4339",
                  "text": "Yes, Alibaba is very big in China.",
                  "score": 1,
                  "created_utc": "2026-01-19 01:09:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzsofrd",
          "author": "humbuckler404",
          "text": "So that means they will never be impacted by us-east-1 issues? :skeptical-face:",
          "score": 28,
          "created_utc": "2026-01-15 20:44:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztjo4e",
              "author": "xxwetdogxx",
              "text": "Correct. All the source code was copied into the region, the USA could sink to the bottom of the ocean and the ESC region would still run, there's no dependency.",
              "score": 19,
              "created_utc": "2026-01-15 23:13:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztp7tz",
                  "author": "humbuckler404",
                  "text": "Thatâ€™s great news. Itâ€™s been a few years since I worked in AWS, so I know â€œno dependenciesâ€ were something we always pursued. Of course, the challenges in implementing that is what made the Wednesday morning Ops Reviews so entertaining ðŸ˜",
                  "score": 7,
                  "created_utc": "2026-01-15 23:43:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzvadl2",
                  "author": "ares623",
                  "text": "Donâ€™t some critical services still rely on us-east-1 though?",
                  "score": -2,
                  "created_utc": "2026-01-16 05:14:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzsze5u",
              "author": "nemec",
              "text": "correct, that's the difference between a region and a partition\n\nhttps://www.reddit.com/r/aws/comments/1oe99zi/did_mondays_outage_impact_govcloud_users_at_all/",
              "score": 14,
              "created_utc": "2026-01-15 21:34:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzz5ig5",
              "author": "KayeYess",
              "text": "A few popular services like IAM, R53 and Cloudfront have their control planes operating only in US East 1.\n\n\nR53 announced a HA control plane (opt in required) in US West 2 (still US) for Public Hosted Zones.\n\n\nIAM is also preparing a similar solution, most likely in US West 2\n\n\nUnless they create a totally independent and sovereign region (like China) in EU, AWS EU will have some dependency on AWS US.",
              "score": 1,
              "created_utc": "2026-01-16 19:24:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o09joon",
                  "author": "Living_off_coffee",
                  "text": "Can confirm that the EU sovereign cloud is a separate partition, so R53, IAM etc is all in the EU with no dependencies on the US.",
                  "score": 2,
                  "created_utc": "2026-01-18 09:28:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0cysqw",
              "author": "shadycuz",
              "text": "I think alot of people replying to you, has never tried to use CloudFront in a region outside of us-east-1.",
              "score": 1,
              "created_utc": "2026-01-18 21:18:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzst91a",
              "author": "ImCaffeinated_Chris",
              "text": "This is the real question.",
              "score": 1,
              "created_utc": "2026-01-15 21:06:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzsjfix",
          "author": "Bloodsucker_",
          "text": "EU should make sure to only use regional providers. Plenty of companies and banks have stopped expanding in the cloud owned by the USA. It's not safe or aligned with European sovereignty. They, aws, know this, that's why they're panicking. It's not sufficient to use a regional subsidiary.",
          "score": 12,
          "created_utc": "2026-01-15 20:20:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztjqhe",
          "author": "KayeYess",
          "text": "Don't trust anyone. Protect what you need to, yourself. Whether it is a US based cloud company or a Europe based data center doesn't matter.",
          "score": 3,
          "created_utc": "2026-01-15 23:14:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztryj3",
              "author": "BigBagaroo",
              "text": "The US intelligence services would be incompetent if they did not have access to all data.\n\nNow that the US is no longer an ally of EU, EU should move their data away from their platforms.",
              "score": -2,
              "created_utc": "2026-01-15 23:58:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzu6uyr",
                  "author": "KayeYess",
                  "text": "Maybe put the data in Greenland ðŸ˜‚",
                  "score": 3,
                  "created_utc": "2026-01-16 01:20:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztgobg",
          "author": "yourfriendlyreminder",
          "text": "What is the feature parity with regular AWS? \n\nAnd what is the support model?\n\nThe thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either",
          "score": 2,
          "created_utc": "2026-01-15 22:58:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o00vlp7",
              "author": "MateusKingston",
              "text": ">What is the feature parity with regular AWS?\n\nImpossible to tell so early on but Govt Cloud is heavily behind, but it has all the mainstream products afaik, it's just the new shiny toys and obscure products that never get there or take some time.\n\n>The thing with these sovereign cloud solutions is that they're technically not first party, so you're not gonna get first party support either\n\nI don't think this truly matters, you're not getting supported by AWS Engineers anyway, you're getting support from a support team that was trained and know how their specialized services work, etc. They will simply have those people in the new EU subsidiary that should take over those duties.",
              "score": 2,
              "created_utc": "2026-01-17 00:36:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzuud9v",
          "author": "maxip89",
          "text": "It only need one u.s. shadow trial gets public, and the whole aws europe story is done.",
          "score": 2,
          "created_utc": "2026-01-16 03:31:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy1w3s",
          "author": "Dzefo_",
          "text": "I already see myself migrating all the infra againâ€¦",
          "score": 2,
          "created_utc": "2026-01-16 16:29:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz36cc",
          "author": "granviaje",
          "text": "If trump tells Amazon to shut it down how long do you think it will take for this to happen?Â \n\nAs long as Trump is on the helm there is no way to trust any US company.Â ",
          "score": 2,
          "created_utc": "2026-01-16 19:13:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0e87ly",
              "author": "Busy-Explanation4339",
              "text": "The convicted felon con man has poisoned the well.  There will not be any trust in the America well after he is gone.",
              "score": 2,
              "created_utc": "2026-01-19 01:11:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzzuok5",
          "author": "BigBagaroo",
          "text": "The AWS/US brigade is in full force on this topic.\n\nI would advice any non-US citizen to read this article and think for themselves:\n\nhttps://en.wikipedia.org/wiki/Crypto_AG\n\nÂ«Crypto AG was a Swiss company specialising in communications and information security founded by Boris Hagelin in 1952. \n\nThe company was secretly purchased in 1970 by the US Central Intelligence Agency (CIA) and West German Federal Intelligence Service (BND) for US $5.75 million (equivalent to $47 million in 2024)[1] and jointly owned until about 1993, with the CIA continuing as sole owner until about 2018Â»\n\nÂ«The mission of breaking encrypted communication using a secretly owned company was known as Operation Rubicon. \n\nWith headquarters in Steinhausen, the company was a long-established manufacturer of encryption machines and a wide variety of cipher devices.Â»",
          "score": 4,
          "created_utc": "2026-01-16 21:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt5tf8",
          "author": "twin-hoodlum3",
          "text": "Funny seeing all the comments from the AWS fanboys, thinking it matters if the AWS Sovereign Cloud is run by European AWS subsidiaries located in the EU.\n\nGuys: it . doesnâ€˜t. matter. As long as the mother company who fully owns the European subsidiary is US based, then the CLOUD Act still applies. Period.",
          "score": 5,
          "created_utc": "2026-01-15 22:04:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwx7y3",
              "author": "HomoAndAlsoSapiens",
              "text": "That's why they specifically designed these daughter companies to have to deny requests by US courts. There is not a single American working there that would therefore have to comply with US courts and any request that the parent company in the US would put through because they have to would then be denied because it would be illegal to do so in Europe. It's not as easy as you'd like to think it is.\n\nDid you know that the US also wants to tax you on shares of US-companies even if you have nothing to do with the country? Foreign banks, of course, just ignore that and don't report to them. Their intention was to build a similar system here.",
              "score": 5,
              "created_utc": "2026-01-16 13:11:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o033vg4",
                  "author": "xiwenc",
                  "text": "The scope is not just who operates the datacenters or in this subsidiary. The core supplier of the source code etc can be tampered or loaded with backdoors. US AWS is still the leading entity. They are subject to CLOUD ACT and other US policies.\n\nUnless they do a complete hard fork, and employ europeans, audited independently to be 100% safe and zero relation with US, i could trust it to be sovereign.",
                  "score": 1,
                  "created_utc": "2026-01-17 10:50:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzx0cuj",
                  "author": "twin-hoodlum3",
                  "text": "Basically it's easier than you might think. Under US law, authorities can compel a provider subject to US jurisdiction to disclose data that is within the providerâ€™s â€œpossession, custody, or control,â€ even if the data is stored in Europe. Whether this reaches data â€œhandled by an EU subsidiaryâ€ often turns on whether the US parent (or another US-jurisdiction entity) has sufficient legal/technical control over that data, and it can create a direct conflict with GDPR rules on responding to foreign orders.\n\nThe key message here is \"possession and control\". What do you think will happen to AWS US if some susidiary manager says \"no\" to their bosses? The only way to circumvent such things at least in parts is to use infrastructure like SAP Delos or Bleu. But event this is questionable. \n\nSource: \n\n* 18 U.S. Code Â§ 2713 (https://www.law.cornell.edu/uscode/text/18/2713)\n* CLOUD act Q&A (https://www.justice.gov/criminal/media/999616/dl?inline)",
                  "score": -1,
                  "created_utc": "2026-01-16 13:29:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzubez4",
              "author": "alienangel2",
              "text": "I mean, if the US govt wants to get at data hosted in some other cloud provider, even one 100% built from scratch in Europe, they are still going to get it whether they do it legally or not. \n\nCLOUD act will make it vaguely defensible in US courts but no one in the US admin cares about courts anymore, and no one in any intelligence agency has ever cared about courts. It's probably easier for them to steal from some homegrown local cloud provider than from AWS.",
              "score": 3,
              "created_utc": "2026-01-16 01:45:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvq24k",
                  "author": "Interesting_Shine_38",
                  "text": "This is precisely what I believe people fail to understand. Like those guys blew up air gapped uranium enrichment facility. You think your vulnerable outdated OpenStack deployment will be a problem for them?",
                  "score": 2,
                  "created_utc": "2026-01-16 07:16:09",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o00wm34",
                  "author": "MateusKingston",
                  "text": "This is far different from \"they will just demand the data and it will be handed over\".\n\nCyberwarfare and Cybercrime are very different from courts demanding access and being handed over.\n\nBut I wouldn't be so sure about this, the US has only shown their Cyberwarfare capabilities against subpar opponents.",
                  "score": 1,
                  "created_utc": "2026-01-17 00:41:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztbdgd",
              "author": "sutongorin",
              "text": "Even if it didn't apply it's doubtful customers would care. It still has AWS in its name. Anything US-related is tainted.",
              "score": 0,
              "created_utc": "2026-01-15 22:31:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o09nzug",
          "author": "Automatic_Gas_113",
          "text": "So this is some kind of EU-washing.",
          "score": 1,
          "created_utc": "2026-01-18 10:08:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gr394",
          "author": "mountcifs",
          "text": "You canâ€™t apparently trust US. This solves nothing.",
          "score": 1,
          "created_utc": "2026-01-19 12:25:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0h2ei2",
          "author": "National-Percentage4",
          "text": "Its bezos. And american. Get off AWS asap.Â ",
          "score": 1,
          "created_utc": "2026-01-19 13:39:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jc4xt",
          "author": "puck_fella",
          "text": "I spent a large part of last year building this. It was hell. Debugging issues after it has been isolated is the next level of hell.",
          "score": 1,
          "created_utc": "2026-01-19 20:02:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0juhok",
          "author": "LivingstoneMcSimmons",
          "text": "If this would make the European cloud immune to US (Trump's) sanctions then they would make that very clear in their communications about this 'sovereign cloud'. The fact that it talks around this topic signals this entity is still under US gov reach via the US AWS HQ.",
          "score": 1,
          "created_utc": "2026-01-19 21:29:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0k4d2t",
          "author": "crytpkeeeper",
          "text": "Th US Govt can pressure Amazon all they want. They wonâ€™t get the data if itâ€™s in the EU Sovereign Cloud. Amazon cut the strings for the US Cloud Act by creating this legal structure. Say and speculate and hate on AWS all you want. The US Govt can try and threaten Amazon. But the ONLY path now is through EU courts.",
          "score": 1,
          "created_utc": "2026-01-19 22:17:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzthe5r",
          "author": "thirstybatman",
          "text": "I truly wonder which public bodies will use this. Two years ago, yes. But not anymore, that train has left the station. Sovereign in the name only.",
          "score": 1,
          "created_utc": "2026-01-15 23:01:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o01nn01",
          "author": "Unable-Goat7551",
          "text": "Lots of wildly naive people in this thread",
          "score": 1,
          "created_utc": "2026-01-17 03:32:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt9tuy",
          "author": "egorf",
          "text": "I can see two problems with this.\n\n1) It's hard to imagine AWS \"EU\" not complying with requests from the US administration. Even if we exclude clandestine requests based on the fact that the US doesn't respect sovereignty, imagine they ban, say, the export of cloud orchestration technologies just like they restricted GPU exports, including to the EU.\n\n2) It's easy to imagine AWS \"EU\" trying to comply with all local EU laws and regulations which either brings the cloud to a halt or makes the usage of it impractical. Say, no AI models deployed until seven-years mandatory Environmental Impact Study has been performed. Or something along these lines.",
          "score": -2,
          "created_utc": "2026-01-15 22:23:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwyhjj",
              "author": "HomoAndAlsoSapiens",
              "text": "You have no understanding of this, no offense.\n\n1. Complying with these requests is illegal. There also are no US citizens that could be compelled to comply. In fact, the entire new company structure is based on this principle.\n\n2. They have to comply with laws because laws are not optional. AWS with their normal regions equally has to comply with laws because laws are not optional. In Europe, AWS exclusively operates via its Luxembourgish daughter Amazon Web Services EMEA SARL.",
              "score": 4,
              "created_utc": "2026-01-16 13:18:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzz44n9",
                  "author": "granviaje",
                  "text": ">Â They have to comply with laws\n\nSince when does the trump admin care about laws?",
                  "score": 2,
                  "created_utc": "2026-01-16 19:18:16",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzz6z4m",
                  "author": "Hopeful-Programmer25",
                  "text": "I may be going overboard but you are assuming laws still matter to the US governmentâ€¦. They donâ€™t. They can, and will, pressure the parent US company to fulfil what they need and, itâ€™s clear, that the US parent will fold. The US parent still owns the EU subsidiary, still decides who runs it, who will then find a way to comply or be fired.\n\nThis is going beyond data sovereignty, itâ€™s that the US is a hostile actor to European interests, and could easily shut down European infrastructure in the worse case scenario.",
                  "score": 2,
                  "created_utc": "2026-01-16 19:31:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzyftfn",
                  "author": "egorf",
                  "text": "1. Of course. No EU personnel will be involved in data exfiltration process at all as the AWS software contains all required backdoors for the US staff to download whatever the US needs. Notice: I did not write \"could contain a backdoor\". I deliberately wrote that it DOES contain a backdoor. The opposite is simply inconceivable.\n\n2. Great! I love that AWS complies with the laws as it should be! Meanwhile as a EU citizen I will continue using the US AWS exclusively because I want the most recent AI models available with no committee to decide which text transformation engine I am allowed to use. And I don't want to slap my recent utility bill with every API request to AWS.\n\nSo Godspeed to AWS EU but I have negative trust at all levels.",
                  "score": 0,
                  "created_utc": "2026-01-16 17:30:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzu9ntw",
              "author": "ByronScottJones",
              "text": "Literally none of the people working in the EU partition are allowed to be US citizens. They are all REQUIRED to be EU citizens. There's nobody in the US that will have legal leverage to require such requests to be complied with.",
              "score": 5,
              "created_utc": "2026-01-16 01:36:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyeghf",
                  "author": "egorf",
                  "text": "Exfiltration of data on US request is not going to be done via engagement with EU staff. It will be done in the US by using the corresponding backdoor in the AWS code with no EU involvement and knowledge whatsoever.",
                  "score": -2,
                  "created_utc": "2026-01-16 17:24:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzwr2fg",
          "author": "elchupacabrone",
          "text": "They are still American company. This doesn't change anything and it's definitely not \"sovereign\" because when NSA wants to get access to their resources they have to obey.",
          "score": 0,
          "created_utc": "2026-01-16 12:32:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwyvcw",
              "author": "HomoAndAlsoSapiens",
              "text": "You are so sure? Then explain how a request for the data would be handled and I can explain why you're wrong and have actually not sufficiently thought about it.",
              "score": 1,
              "created_utc": "2026-01-16 13:21:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzxrqg6",
                  "author": "elchupacabrone",
                  "text": "Yes I'm sure - CLOUD act 2018.",
                  "score": -1,
                  "created_utc": "2026-01-16 15:44:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt2fhy",
          "author": "BigBagaroo",
          "text": "There is absolutely no reason to believe AWS on this.",
          "score": -6,
          "created_utc": "2026-01-15 21:48:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztc9a9",
              "author": "bastion_xx",
              "text": "Why not? You, and customers that will use this, can read the docs. From the FAQ:\n> The AWS European Sovereign Cloud will maintain key certifications such as ISO/IEC 27001:2013, SOC 1/2/3 reports, and BSI C5 attestation, all validated regularly by independent auditors to assure our controls are designed appropriately, operate effectively and help customers satisfy their compliance obligations.",
              "score": 2,
              "created_utc": "2026-01-15 22:35:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztti59",
                  "author": "twin-hoodlum3",
                  "text": "Have you ever been to an ISO 27k1 audit and know the controls? These regulations are (surprisingly) just for the sake of compliance (aka: weâ€˜re at least not amateurs), not at all proof of anything in terms of security or sovereignity.",
                  "score": 1,
                  "created_utc": "2026-01-16 00:06:55",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztq0jl",
                  "author": "BigBagaroo",
                  "text": "Oh my, it says so in the FAQ? Well, that changes everything!",
                  "score": -4,
                  "created_utc": "2026-01-15 23:48:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6i9n",
          "author": "codechris",
          "text": "Complete shite. If you're European use an EU cloud,Â  it this fake wank from AmazonÂ ",
          "score": -4,
          "created_utc": "2026-01-15 22:07:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzyi6tw",
              "author": "jrolette",
              "text": "What EU cloud would you suggest they use that isn't much more than a VPS and storage provider? There are no options that are even vaguely comparable to AWS, Azure, and GCP.",
              "score": 1,
              "created_utc": "2026-01-16 17:41:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyrmts",
                  "author": "codechris",
                  "text": "Depends what you need. A lot of stuff is just a container and a DB (I'm being simplistic but it makes the point) plenty of companies running on EU cloudsÂ ",
                  "score": 1,
                  "created_utc": "2026-01-16 18:23:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzs1sjp",
          "author": "BenchOk2878",
          "text": "If Trump can get Greenland,Â  that \"pinky promise\" does not mean shit.\n\n\nBezos will give away any data requested by USA government.Â \n\n\nGet real.",
          "score": -7,
          "created_utc": "2026-01-15 18:59:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzudnk0",
              "author": "madwolfa",
              "text": "That's not how storage in cloud works, especially if you use your own encryption keys (as you should if you care about this sort of thing).Â ",
              "score": 4,
              "created_utc": "2026-01-16 01:58:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o02kfv4",
          "author": "morefakefakeshit",
          "text": "All of this work just because men in dark glasses can show up at any US data center and take whatever they want",
          "score": 0,
          "created_utc": "2026-01-17 07:48:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzsr2zu",
          "author": "Maang_go",
          "text": "All Trump has to do is ask AWS to revoke encryption keys used by all AWS services in the background, of anything European hosted in AWS. \n\nThen all hardware will still be in Europe, all software will be operating from here, All data will be stored in Europe but unusable. Cloud is designed for control not capex opex.",
          "score": -7,
          "created_utc": "2026-01-15 20:56:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzsyyjo",
              "author": "nemec",
              "text": "Why do you think Americans have control over the EU Cloud encryption keys?",
              "score": 16,
              "created_utc": "2026-01-15 21:32:58",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nztsz0w",
                  "author": "baronas15",
                  "text": "Cloud act",
                  "score": 0,
                  "created_utc": "2026-01-16 00:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nztssb2",
                  "author": "twin-hoodlum3",
                  "text": "As long as the customers donâ€˜t use their own KMS encrypting data *before* they get into AWS, AWS and â€žothersâ€œ (by request) have the encryption keys.",
                  "score": 0,
                  "created_utc": "2026-01-16 00:03:00",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzt6rgi",
                  "author": "Maang_go",
                  "text": "â€œNoted.â€",
                  "score": -1,
                  "created_utc": "2026-01-15 22:09:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qe956h",
      "title": "CodeBreach: Infiltrating the AWS Console Supply Chain and Hijacking AWS GitHub Repositories via CodeBuild",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "author": "Kralizek82",
      "created_utc": "2026-01-16 07:02:16",
      "score": 59,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qe956h/codebreach_infiltrating_the_aws_console_supply/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzx03uh",
          "author": "pint",
          "text": "tl;dr\n\nthe core of this attack is a misconfigured github setup, which accepted pull requests from user ids that *contain* a string, instead of *matching* the string. with some difficulty, they managed to register a new id that passed.\n\nthere are many more steps in this attack, but this was the main vulnerability.",
          "score": 51,
          "created_utc": "2026-01-16 13:28:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzxe5d1",
              "author": "menge101",
              "text": "ty",
              "score": 7,
              "created_utc": "2026-01-16 14:41:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhutpm",
      "title": "If a person spends a billion dollars and buys all the compute on EC2 for today, what happens to the rest of the people requesting it?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "author": "PrestigiousZombie531",
      "created_utc": "2026-01-20 07:40:30",
      "score": 34,
      "num_comments": 69,
      "upvote_ratio": 0.75,
      "text": "- Just an honest question / showerthought, whatever you want to call it",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0mpzwk",
          "author": "Murky-Sector",
          "text": "Amazon would still limit your capacity. They would looove to setup all kinds of dedicated capacity just for you though, which you could use with wild abandon. For a price of course.",
          "score": 109,
          "created_utc": "2026-01-20 07:46:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mscs4",
              "author": "katatondzsentri",
              "text": "This. We actually use \"aws assisted capacity reservations\" which basically means they deployed a few racks with servers in the AZ we needed it.",
              "score": 31,
              "created_utc": "2026-01-20 08:07:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rgst7",
                  "author": "x86brandon",
                  "text": "Those aren't even deploying racks, that's just earmarking things in the scheduler.   Their large customers have earmarked fleet allocations and don't run into the same capacity problems as most.  And when you get big enough, you stop fussing with reservations, etc and just get a fixed EDP discount across all services and you generally will never see an unavailable error.  From experience anyways.",
                  "score": 12,
                  "created_utc": "2026-01-20 23:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0rgcuz",
              "author": "x86brandon",
              "text": "You don't need dedicated capacity.   Amazon simply limits spend in incremental amounts as a credit risk management.  Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.",
              "score": 7,
              "created_utc": "2026-01-20 23:47:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rlypo",
                  "author": "Murky-Sector",
                  "text": ">Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.\n\nI think its hysterical youre taking such great pains to analyze a hypothetical question about spending $1,000,000,000 on EC2. But ok.",
                  "score": -8,
                  "created_utc": "2026-01-21 00:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mpmrf",
          "author": "multidollar",
          "text": "Insufficient Capacity, please try your request again using another availability zone or try your request again shortly.",
          "score": 81,
          "created_utc": "2026-01-20 07:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oikm4",
              "author": "yarenSC",
              "text": "This would only be if somehow the account had gotten infinite quotas approved, which wouldn't be the case",
              "score": 11,
              "created_utc": "2026-01-20 15:28:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rmn5e",
                  "author": "multidollar",
                  "text": "Oh, but it often is :)",
                  "score": 1,
                  "created_utc": "2026-01-21 00:21:29",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0rftzz",
                  "author": "x86brandon",
                  "text": "Depends on the relationship, I have no limits on my accounts, but that's a 10 digit account spend.",
                  "score": -1,
                  "created_utc": "2026-01-20 23:44:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sjhbi",
              "author": "mr_jim_lahey",
              "text": "Kind of moot given account limits/quotas, and that the question is more generally about \"all the compute\", but I think it's possible AWS could provision a billion dollars' worth of on-demand instances in a single (major) region, assuming they were somewhat spread across instance types. Certainly they could accommodate it easily if spread across multiple regions. They have an unfathomable amount of capacity. $1B is like 1% of their ARR.",
              "score": 1,
              "created_utc": "2026-01-21 03:28:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqkhb",
          "author": "casce",
          "text": "It happens occasionally that AWS temporarily runs out of specific instance type in specific regions.\n\nWhat happens is you can't deploy new ones in that case but your running stuff is fine. Just don't stop and start it or you might be unable to start it again.\n\nThe same would happen if someone literally requested all of AWS' instances without AWS stopping them. AWS would most certainly stop them though (wouldn't be worth it to anger ALL other customers).",
          "score": 13,
          "created_utc": "2026-01-20 07:51:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w28xt",
              "author": "look_of_centipede",
              "text": "If you need to stop/start it, a brief capacity reservation can prevent someone from sniping it out from under you.",
              "score": 1,
              "created_utc": "2026-01-21 17:31:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mq6ph",
          "author": "No_Pomegranate7508",
          "text": "Reminds me of another similar question: \"Would you still love me if I were a worm?\"",
          "score": 25,
          "created_utc": "2026-01-20 07:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mpp3u",
          "author": "soundman32",
          "text": "The people who really need have paid for reserved instances for years ahead.",
          "score": 10,
          "created_utc": "2026-01-20 07:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mq8ke",
              "author": "Tall-Reporter7627",
              "text": "Like....if they bought a Dell server and stuffed it in their own rack, but at twice the cost?",
              "score": 5,
              "created_utc": "2026-01-20 07:48:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mqxsu",
                  "author": "Loko8765",
                  "text": "No. AWS allows you to reserve instances in advance. You actually pay a lower price, but of course you commit to the duration. If you know you will use it, it is win-win.",
                  "score": 9,
                  "created_utc": "2026-01-20 07:54:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0u47g2",
                  "author": "SlinkyAvenger",
                  "text": "More like two ISPs, two gateways, four switches, four firewalls, eight servers, two power connections, and two generators",
                  "score": 2,
                  "created_utc": "2026-01-21 11:14:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0msv40",
                  "author": "mba_pmt_throwaway",
                  "text": "2x the cost of a server isnâ€™t bad, actually. Just the ops overhead maintaining the servers + DC costs could cost more than the raw server costs. Ofc at a certain scale the math tips back in favor of self managing, but for most customers 2x would be great value.",
                  "score": 2,
                  "created_utc": "2026-01-20 08:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0nc08x",
              "author": "pint",
              "text": "yes, because, you know, there are no use cases where you need ephemeral instances. none.",
              "score": 1,
              "created_utc": "2026-01-20 11:09:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rh9ji",
              "author": "x86brandon",
              "text": "However, their billion dollar customers just get a flat discount and don't deal with this stuff at least.  EDP ends up being a revenue commitment and a flat discount off list without dealing with the micro managing of instance types, etc.",
              "score": 1,
              "created_utc": "2026-01-20 23:52:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0w31oe",
              "author": "look_of_centipede",
              "text": "Capacity reservations generally don't tie to long term cost, cost reservations generally don't reserve capacity.  There are edge cases but they're rare.",
              "score": 1,
              "created_utc": "2026-01-21 17:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqm02",
          "author": "vacri",
          "text": "System isn't set up for putting on that much compute at once - you'll run into Limits, and you're not going to be able to set them particularly high without satisfying AWS\n\nAssuming that it was all prepped beforehand and they could buy up the compute power and pay double the going rate to make it worth AWS's time, AWS still wouldn't do it because the damage to the brand by taking everyone's servers off them for 1 day would have many substantial customers fleeing to other vendors.",
          "score": 8,
          "created_utc": "2026-01-20 07:51:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rh2g1",
              "author": "x86brandon",
              "text": "System is set up for a lot of load.   Credit limits are not.  :)\n\nI have launched groups of 5,000 p4.24xd's at a time.",
              "score": 2,
              "created_utc": "2026-01-20 23:51:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0sqi2q",
                  "author": "Alborak2",
                  "text": "Ive probably seen the downsteam effects of that launch lol. ML workloads move sooooo much data around.\n\nAnd yeah your other comments about limits are right. If you have the keys to the castle we'll pretty much let you run until the physical capacity is gone. Not many of those around. Our internal test accounts are unlimited and will launch thousands of instances with 20+ EBS volumes on each.",
                  "score": 1,
                  "created_utc": "2026-01-21 04:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mt5c1",
          "author": "FlyingFalafelMonster",
          "text": "Insufficient capacity. Happens already for GPU instances. Unless you buy capacity reservations, then even if you do not use instance it still is reserved for you.Â ",
          "score": 5,
          "created_utc": "2026-01-20 08:14:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rizzh",
              "author": "x86brandon",
              "text": "For what it's worth, east-1 is the only place I see GPU issues...  the other regions I haven't had problems with since 2021.  west-2 I have very high launch rate success.",
              "score": 1,
              "created_utc": "2026-01-21 00:01:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vd1go",
                  "author": "nagyz_",
                  "text": "I haven't been able to reserve the p6 gb200. Does it show as reservable for you as in you get an actual time slot with a price?",
                  "score": 1,
                  "created_utc": "2026-01-21 15:38:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o10gn1t",
                  "author": "CategoryRepulsive699",
                  "text": "Try Australia",
                  "score": 1,
                  "created_utc": "2026-01-22 08:14:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qlnfz",
          "author": "ComplianceAuditor",
          "text": "You can't do that even with a billion dollars, because it would cause a lot more than a billion dollars in \"damage\" to their other customers if they suddenly have no capacity.\n\nIt's also not possible. There is no scenario ever, where AWS takes away an on demand instance from a customer just because another customer wants to use it.\n\nIdk why this is being downvoted though. Guess being curious is off limits for the internet.",
          "score": 6,
          "created_utc": "2026-01-20 21:13:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n1m87",
          "author": "TekintetesUr",
          "text": "Unfortunately nothing, doesn't matter how hard we try. In-use on-demand capacity will not be taken away from current users. Existing reservations won't be cancelled by a higher bid. Etc.",
          "score": 3,
          "created_utc": "2026-01-20 09:34:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rg41y",
          "author": "x86brandon",
          "text": "AWS has an internal allocation mapping.  A single customer and account can't hit the entire fleet.  And also, a billion dollars at retail prices would not actually consume the entire fleet.   Their fleet is probably much larger than you might imagine.",
          "score": 3,
          "created_utc": "2026-01-20 23:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p4pfm",
          "author": "Quinnypig",
          "text": "The more interesting version of this question revolves around spending that billion dollars in S3 storage. There are no known quotas around that.",
          "score": 6,
          "created_utc": "2026-01-20 17:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0muov0",
          "author": "danizumi",
          "text": "In the AWS management console, look at the Service Quotas page, each service has hard and soft limits for each service. You should definitely be looking at these limits before putting a service into a production environment to ensure you donâ€™t hit a limit, or at least be aware of the limits.",
          "score": 2,
          "created_utc": "2026-01-20 08:29:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nkrre",
          "author": "KayeYess",
          "text": "Quotas and other limitations will kick in long before a single customer can purchase and use even a small fraction of all the available resources.",
          "score": 2,
          "created_utc": "2026-01-20 12:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s2own",
          "author": "Sowhataboutthisthing",
          "text": "Nice try, Elon.",
          "score": 2,
          "created_utc": "2026-01-21 01:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s4cjx",
          "author": "Human-Job2104",
          "text": "Service Quotas will stop them.",
          "score": 2,
          "created_utc": "2026-01-21 02:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vsr0s",
          "author": "FinOps_4ever",
          "text": "All of the people who purchased ODCR's to properly cover their EC2 needs will all get substantial bonuses.\n\nBut the proper answer is account limits and usage quotas.",
          "score": 2,
          "created_utc": "2026-01-21 16:48:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thzu2",
          "author": "oscarolim",
          "text": "Billion dollars? Thatâ€™s like 5 instances for a week.",
          "score": 2,
          "created_utc": "2026-01-21 07:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mts6b",
          "author": "Complex86",
          "text": "This is impossible. Each family is not equal and it would be honestly really difficult for 1 person to consume 100% of instances across all zones in all regions",
          "score": 1,
          "created_utc": "2026-01-20 08:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rhg2n",
              "author": "x86brandon",
              "text": "Not to mention, a billion dollars probably wouldn't get you there.   :)",
              "score": 3,
              "created_utc": "2026-01-20 23:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mwzk3",
          "author": "Soccer_Vader",
          "text": "If you are consuming all of the instances that aws has available at any given point, and not reserved for any internal/external use case, you are spending some developing countries gdp in a day. They would love that tho.",
          "score": 1,
          "created_utc": "2026-01-20 08:50:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oinsm",
          "author": "plaaam",
          "text": "What type of question is that :skull:",
          "score": 1,
          "created_utc": "2026-01-20 15:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p0n8q",
          "author": "SpecialistMode3131",
          "text": "You can't buy it all precisely because that would be bad for Amazon's overall business, so they have limits across all services.",
          "score": 1,
          "created_utc": "2026-01-20 16:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ro677",
          "author": "Top-Shopping410",
          "text": "Keep getting out of capacity I guess. I had this issue when I worked for another cloud provider and we just waited for the hardware installed",
          "score": 1,
          "created_utc": "2026-01-21 00:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rpzjg",
          "author": "Storage-Proper",
          "text": "They would continue to sell it",
          "score": 1,
          "created_utc": "2026-01-21 00:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t3yg1",
          "author": "Burekitas",
          "text": "He won't be able to do that, he will need so much accounts and quota increase requests, it will take 20 years to get to that position. \n\n  \nBut if he did, people asking for EC2 will encounter issues, but in a couple of weeks AWS will fill the gap.",
          "score": 1,
          "created_utc": "2026-01-21 05:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tg5t0",
          "author": "suur-siil",
          "text": "They have the official quotas on your account, and all kinds of other hidden limits too.\n\nI used to have a quota of 20k across various instance-types in a fairly small region and ended up having interesting chats with AWS engineers after trying to spin up large jobs.\n\nThere's also reserved capacity for those who think ahead.",
          "score": 1,
          "created_utc": "2026-01-21 07:31:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tme95",
          "author": "alapha23",
          "text": "This happens all the time for c8g in where binance is running. And gpus as well.",
          "score": 1,
          "created_utc": "2026-01-21 08:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yd3yn",
          "author": "Expensive-Virus3594",
          "text": "Rest of the people will get insufficient capacity errors. This will trigger a severity 2 incident of not a sev 1. \n\nIn reality you canâ€™t make a huge allocation due to account level caps etc.  \n\nThis issue happens in AWS time to time  when something internally breaks.",
          "score": 1,
          "created_utc": "2026-01-21 23:57:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0znyge",
          "author": "plinkoplonka",
          "text": "Nothing. It's limited by account quota.",
          "score": 1,
          "created_utc": "2026-01-22 04:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10h936",
          "author": "CategoryRepulsive699",
          "text": "There are various limits including how much you can procure per second. But I do remember moving sliders in the internal UI that caused truckloads of equipment delivered into the datacenters...",
          "score": 1,
          "created_utc": "2026-01-22 08:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mqct9",
          "author": "lasthunter657",
          "text": "You cant buy all of them AWS have limit on how many EC2 you can have at the same time",
          "score": 1,
          "created_utc": "2026-01-20 07:49:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdvngk",
      "title": "DynamoDB Search functionality?",
      "subreddit": "aws",
      "url": "https://i.redd.it/qwv3xma4ukdg1.png",
      "author": "Antique_Sample_7934",
      "created_utc": "2026-01-15 21:00:20",
      "score": 21,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qdvngk/dynamodb_search_functionality/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzt6kqm",
          "author": "geomagnetics",
          "text": "I think it's for PartiSQL searching. it's only enabled if you have the right indexes enabled.",
          "score": 5,
          "created_utc": "2026-01-15 22:08:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nztbtcr",
              "author": "Antique_Sample_7934",
              "text": "Do you mean GSI's? I have tons of them. I haven't used PartiSQL though",
              "score": 1,
              "created_utc": "2026-01-15 22:33:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzwdx62",
                  "author": "geomagnetics",
                  "text": "I'm not sure what it takes to enable it. but try the PartiSQL editor from the sidebar. that might give you a clue as to what's going on",
                  "score": 1,
                  "created_utc": "2026-01-16 10:52:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzt6if4",
          "author": "Vprprudhvi",
          "text": "That's true. I just noticed it now",
          "score": 2,
          "created_utc": "2026-01-15 22:07:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nzzgy",
          "author": "solo964",
          "text": "That Search button does not appear for any of my DynamoDB tables. Are you still seeing it today? Wonder if it was a mistake or an experiment that they've since suppressed.",
          "score": 1,
          "created_utc": "2026-01-20 13:52:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0q6u5n",
              "author": "Antique_Sample_7934",
              "text": "It went away. Probably an experiment they rolled back or a bad deployment releasing something too early.",
              "score": 1,
              "created_utc": "2026-01-20 20:05:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qiehod",
      "title": "How are you segregating AWS IAM Identity Center (SSO) permission sets at scale?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "author": "sajed8950",
      "created_utc": "2026-01-20 21:41:12",
      "score": 18,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "Hello everyone,\n\nI am looking for guidance on how organizations design and manage AWS IAM Identity Center (SSO) permission sets at scale.\n\n**Context**  \nOur AWS permission sets are mapped to AD/Okta groups. Some groups are team-based and have access to multiple AWS accounts. Team membership changes frequently, and we also have users who work across multiple teams.\n\nBecause access is granted at the group level, we often run into situations where access requested for one individual results in broader access for others in the same group who didnâ€™t need or ask for it.\n\nWe also receive a high volume of access change requests. While we try to enforce least privilege, weâ€™re struggling to balance that with operational overhead and permission set sprawl.\n\n**Discussion points**\n\n* How do you structure permission sets and groups to scale without constant rework?\n* Do you use team-based, job-based, or hybrid permission sets?\n* Do you create separate groups per account + team + job role, or use a different model?\n* Do you provide birthright access for engineers? If so:\n   * What does that access look like?\n   * Is it different in sandbox vs non-prod vs prod?\n* How do you determine what access a team actually needs, especially when users donâ€™t know what permissions they require?\n* How do you manage temporary access to a permission set? Do you use cyberark sca?\n* Who approves access to permission set groups (manager, app owner, platform, security, etc.)?\n\nAny real-world patterns, lessons learned, or â€œwhat not to doâ€ stories would be appreciated.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0quz2h",
          "author": "tlf01111",
          "text": "I do Identity Center at very large scale (15,000 team members,  5000+ groups, 400 aws accounts, etc.)\n\nUsing IdC in conjunction with standard fare static RBAC IAM permissions & group assignments will result in permission set sprawl at scale.   It just is what it is.     \n  \nWe use set of enterprise-wide console roles that are used for most daily access needs, but also provide account-specific permission sets which engineering teams can use to fine-grain their access if it is needed over above the standard roles.\n\nWe had to build quite a bit of custom code to automate a lot of this (based on CloudTrail events coming in from identity store), but a few years in it's working pretty well.\n\nWe also use customer managed policy references heavily to build more granularity:  With some planning you can grant differing permissions using the same permission set, depending on the target (useful for environment tiers in our case).  \n\nBut it could be better.   The next big milestone is to slowly move to an ABAC model where feasible, which should (in theory) help cut down the number of permission sets needed. \n\nAnyway if you have any specific questions feel free to ask.  I'll try to answer best I can.",
          "score": 7,
          "created_utc": "2026-01-20 21:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ub54i",
              "author": "Lazy-Bicycle-8504",
              "text": " When you say \"we\" do you talk about a whole team of x people just doing this as their daily work? Given your scale this sound like at least 1-2 seniors/architects and 3-5 juniors, is this correct?",
              "score": 2,
              "created_utc": "2026-01-21 12:08:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0v7ccb",
                  "author": "AWS_Chaos",
                  "text": "This is what I came to ask. And notice it took the team \"a few years\". Meaning at scale, this isn't a one man job. the move to ABAC must be daunting.",
                  "score": 1,
                  "created_utc": "2026-01-21 15:11:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0y13ak",
                  "author": "tlf01111",
                  "text": "Team of three architect-level, we me doing most of the lifting, and my peer assisting.\n\n\nI have to stress we have extensive automation which handles nearly 100% of the day to day.Â  Â That automation was a six month build for this team.",
                  "score": 1,
                  "created_utc": "2026-01-21 22:53:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qvhqr",
          "author": "bailantilles",
          "text": "We tend to use permission sets that are mapped to job role per account. Each job role and account is mapped to an AD group. Each AWS account has an owner, backup owner, and support group. Itâ€™s up to one of those constituencies to tell us what permissions each job role requires and who does each role. When the question arises of â€œthis person needs different access than others in their job roleâ€ we as them the question: Do we need to create a new job role for this person or do all the others in that group get the additional permission. In the end, itâ€™s up to them to keep track of all of that as they need to do user access audits quarterly for their application.",
          "score": 4,
          "created_utc": "2026-01-20 21:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuyca",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qxw34",
          "author": "Healthy_Gap_5986",
          "text": "It's all about defining an RBAC structure and having the discipline to stick to it. Define roles, determine what they need to do in what environments, create PermissionsSets for them then rolling them out. The roles should be enforcing your operating model. e.g.\n\nExamples.\n\nDeveloperSet\n\n* gets almost FullAccess in Dev environments only.\n* SCP whitelist only grants everyone access to specific services.\n* PermissionsBoundary prevents them from self escalating.\n\nTesterSet\n\n* Can read logs, maybe set some data sources.\n* Applies to Dev and UAT.\n\nDevOpsSet\n\n* Access to Prod. Can read logs, manage Support tickets etc.\n* No write access.\n\nAdminSet\n\n* AD group is empty and only used through an audting temporary elevation process.\n* * Prod.\n\nPlatformAdmins\n\n* Gods. Like domain admins. \n* This is you, and you don't get involved in operations. :)\n\nThe same User can be in one or more of the above roles. e.g. Developers and Testers because they are performing those roles. If someone asks for a permission that's not included in the roles above then they are often asking to circumvent the operating model, either because the model is deficient, in which case it needs fixed, or they are just cowboys. (e.g. I want to get into UAT to clickops something because our testing isn't complete and product owner is all over me).\n\nOn defining privileges. YOu tailor it to allow them to get \"quality\" work done quickly. So developers can do a lot in the dev environment, but after that we want the model encourage the maturity of the CICD. So no clickops after Dev environment. It should all be driven by CICD with testing etc all automated.",
          "score": 3,
          "created_utc": "2026-01-20 22:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuzgo",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0zv5ky",
                  "author": "Healthy_Gap_5986",
                  "text": "Tiny atm. 10 workload accounts + LZA platform accounts. Last place had 100+ accounts, pretty much the same model.",
                  "score": 1,
                  "created_utc": "2026-01-22 05:15:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qdr4tv",
      "title": "TIFU by causing an incident",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "author": "belcheri",
      "created_utc": "2026-01-15 18:14:11",
      "score": 17,
      "num_comments": 14,
      "upvote_ratio": 0.81,
      "text": "I really messed up today and caused an incident. I was supposed to enroll an external production account into our prod OU through Control Tower,  which has compliance stacksets and some SCPs that get enforced. I thought I had done my homework - went through all the account resources to make sure nothing would get auto-remediated. But somehow I still managed to screw it up because of a silly reason, there were a few resources sitting in regions we don't govern, and they started throwing forbidden errors everywhere after the enrollment. I fixed it by reverting and unenrolling the account, but the whole thing made me disappointed that how I missed this.\n\nThe thing that really gets me is there's no safety net. When I was a software engineer, I always had QA testing my code before anything touched production. Now every infrastructure change feels like I'm walking a tightrope with no net underneath.\n\nI made the switch from software engineering to cloud operations about two years ago, and honestly, incidents like this make me question whether I made the right call. How do you all handle this? Thank you. ",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qdr4tv/tifu_by_causing_an_incident/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzrt5jx",
          "author": "RFC2516",
          "text": "You found a sharpe edge to your organizations Engineering Safety process. Not your fault. Does your organization have a staving environment that truely mirrors prod that the same change could have been rehearsed in?",
          "score": 14,
          "created_utc": "2026-01-15 18:21:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrta00",
          "author": "cddotdotslash",
          "text": "Yes, you could have a better testing environment or a QA OU to use, but the reality is that itâ€™s very difficult to completely mirror the setup of one account via another. Even if youâ€™re religious about defining everything as code, there are still traffic patterns or use cases that might only appear in production.\n\nI think AWS deserves some blame. They have no dry run or audit modes for these kinds of things (including SCPs, account moves, etc.) Itâ€™s been a community request for ages and theyâ€™ve pretty much ignored it.",
          "score": 16,
          "created_utc": "2026-01-15 18:22:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzvysdr",
              "author": "TurboPigCartRacer",
              "text": "Indeed running in a QA OU is really difficult to reproduce since the way its being used it completely different compared to accounts running under production OU. It would be great if there's a simulator of some sorts that can use your cloudtrail logs from the past 90 days or so and validate if the new scp applies the right restrictions or not similar to the iam policy simulator.",
              "score": 1,
              "created_utc": "2026-01-16 08:33:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzrtdum",
          "author": "Vast_Manufacturer_78",
          "text": "Welcome to infrastructure, you get not credit when it goes right and you get hell when it goes wrong. Just take it as a learning opportunity, early on I once put multiple KMS keys into deletion status and created new ones because I was moving to fast and didnâ€™t fully read a terraform plan.\n\nI realized rather quickly what happened and made the changes to undo the delete and then import them to the code again, but there were issues with some of the deployments because the alias were removed and had to get recreated.\n\nYou just learn and make notes on things like triple checking your tf plans. For your issue it doesnâ€™t sound like it was broken for too long, but now you will double check all regions where resources are deployed and confirm itâ€™s in an approved region for the organization.",
          "score": 6,
          "created_utc": "2026-01-15 18:22:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0itx",
          "author": "stikko",
          "text": "In this case analyzing say 90 days of CloudTrail data and testing against all the SCP statements would have caught it. \n\nNever underestimate peoplesâ€™ capacity for doing shit you think they shouldnâ€™t be doing. \n\nWhat Iâ€™ve noticed is that a lot of this comes with experience and having made these sorts of mistakes and learned appropriate lessons from them. Being able to mostly completely/accurately answer:\n\n- what could go wrong?\n- whatâ€™s the impact of that thing going wrong?\n- whatâ€™s the likelihood of it going wrong?\n- how can I mitigate that likelihood?\n\nSo whatâ€™s the appropriate lesson to take away here?",
          "score": 3,
          "created_utc": "2026-01-16 00:44:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrzzq3",
          "author": "uuneter1",
          "text": "Iâ€™m not familiar with what you were doing, but step one is documentation. â€œSteps to follow for enrolling new account into OUâ€. Add whatever caveats you need.",
          "score": 1,
          "created_utc": "2026-01-15 18:52:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzx2r6c",
          "author": "DaWizz_NL",
          "text": "I actually think that Control Tower is the biggest issue here. You can hardly test operations beforehand and it orchestrates a lot of things like a black box.",
          "score": 1,
          "created_utc": "2026-01-16 13:42:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzy6up1",
          "author": "TechDebtSommelier",
          "text": "Honestly, this is a very normal cloud ops rite of passage, even if it feels awful in the moment. Control Tower enrollments plus SCPs plus regional drift is one of those setups where everyone learns the hard way that â€œI checked everythingâ€ never really means everything.",
          "score": 1,
          "created_utc": "2026-01-16 16:51:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0gpll3",
          "author": "gokulsiva",
          "text": "I sometimes wonder whether the inferior infra in QA is because of cost ? We tend to do a lot of shortcuts in QA is that one of the reasons?",
          "score": 1,
          "created_utc": "2026-01-19 12:13:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzrz64b",
          "author": "mikes3ds",
          "text": "To combat issues like that I use terraform. You can see what changes would happen, before applying. Also easier to roll back changes and know what changes cant be rolled back. \n\nOne of the newer advantages of using a Infrastructure as Code (IAC), is when you have a codebase you can use codex or github copilot to search your IAC for potential problems, ask questions. \n\nHaving no Dev/QA sucks however, I always create a smaller env to test my IAC stack.",
          "score": 1,
          "created_utc": "2026-01-15 18:48:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzrzjq1",
              "author": "mikes3ds",
              "text": "Also it becomes more like software development when you start using IAC for anything added to your cloud envs.",
              "score": 2,
              "created_utc": "2026-01-15 18:50:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzxca8t",
              "author": "AWS_Chaos",
              "text": "This is a serious question: How would Terraform have helped in this particular situation of moving an account into another OU with unforeseen SCP issues?",
              "score": 1,
              "created_utc": "2026-01-16 14:31:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzyefsz",
                  "author": "mikes3ds",
                  "text": "Terraform plans can surface drift such as unexpected SCP attachments or policy changes, but the larger benefit is that your organizational structure and guardrails are expressed as code. This makes it far easier to systematically analyze changes for riskâ€”whether through automated checks, policy validation, or even using an LLM to review the Terraform code and plan output to flag potentially impactful SCP conditions you may not have anticipated.\n\nThis approach wonâ€™t eliminate every risk, but it provides far more visibility and proactive safeguards than ad-hoc or manual changes.",
                  "score": 1,
                  "created_utc": "2026-01-16 17:24:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhotxo",
      "title": "Infrastructure as Software: Beyond Infrastructure as Code",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "author": "whudduptho",
      "created_utc": "2026-01-20 02:36:43",
      "score": 16,
      "num_comments": 16,
      "upvote_ratio": 0.62,
      "text": "I've been working on a topic over the last 4 years: building out infrastructure using AWS CDK through an SRE lens.\n\nBeing in the DevOps, SRE, and Platform Engineering domains, I kept asking myself why aren't all the key NFRs built into the constructs we use as golden paths? Focused on reliability and developer experience, I put together a construct library where services have cost-savings, reliability, security, and scalability baked in from the start.\n\nThis is where I want to introduce a phrase I'm calling Infrastructure as Software. The idea is that these constructs, with minimal input, can be stitched together to build fault-tolerant systems. I built this site as a forcing function to showcase what I've been working on, but more importantly it's how an SRE approaches building self-healing infrastructure.\n\nThere's still more to this project, but for now I want to introduce the philosophy of Infrastructure as Software as I continue to illustrate how these constructs work together to build autonomous systems.\n\nWould love to get the communityâ€™s input. \n\n[https://github.com/crmagz/cdk-constructs-library](https://github.com/crmagz/cdk-constructs-library)\n\n[https://thepractitioner.cloud/blog/infrastructure-as-software](https://thepractitioner.cloud/blog/infrastructure-as-software)\n\n[https://thepractitioner.cloud/guides/infrastructure-as-software/introduction](https://thepractitioner.cloud/guides/infrastructure-as-software/introduction)\n\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0lppjt",
          "author": "lost12487",
          "text": "This looks like a vibe-coded [SST ](https://sst.dev/docs/examples)with your opinion of the \"golden path\" baked in. It sounds like you generally have good ideas about the topic, but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.",
          "score": 38,
          "created_utc": "2026-01-20 03:26:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lv0i0",
              "author": "whudduptho",
              "text": "I believe you are referring to the site [https://thepractitioner.cloud](https://thepractitioner.cloud/blog/infrastructure-as-software). It uses [https://vite.dev/](https://vite.dev/). And no not vibe coded. Some of us actually know how to write software and use AI as the tool it is.\n\nThe project I'm discussing is a culmination of years of multi-region active-active systems building. If you know infra and can read code then taking a look at the constructs [https://github.com/crmagz/cdk-constructs-library/tree/main/packages](https://github.com/crmagz/cdk-constructs-library/tree/main/packages) shouldn't be an issue for you, but I don't believe you have.\n\nWhat this project offers is the same as Construct Hub but centralized, opinionated from an SRE/PE focus, and with minimal inputs needed.",
              "score": -16,
              "created_utc": "2026-01-20 03:56:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0lxtyl",
                  "author": "lost12487",
                  "text": "I'm not referring to your blog site, I'm referring to your obviously AI-generated source code.",
                  "score": 22,
                  "created_utc": "2026-01-20 04:13:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0pft5h",
              "author": "o5mfiHTNsH748KVq",
              "text": "> but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.\n\nwhy? you could always just read the code and make sure it does what you think it does. seems like unnecessary effort.",
              "score": -4,
              "created_utc": "2026-01-20 18:02:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pkdi1",
                  "author": "lost12487",
                  "text": "Because if you don't even put in the effort to remove the completely superfluous comments that the agent adds to functions then I'm not going to put in the effort to find out where else you were lazy.",
                  "score": 8,
                  "created_utc": "2026-01-20 18:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mdcaj",
          "author": "vincentdesmet",
          "text": "this topic would do much better on https://cdk.dev community channels \n\nSpecifically collaboration with OpenConstructs foundation may be interesting for you\n\nIâ€™m still stuck enabling TF teams to adopt L2, moving to L3 afterwards (my project is terraconstructs.dev and I am one of core maintainers for http://cdktn.io - the CDKTF fork)",
          "score": 9,
          "created_utc": "2026-01-20 05:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lsrns",
          "author": "behusbwj",
          "text": "Havenâ€™t looked at the code, but the concept is solid and this is how the big players use CDK internally. The reason you donâ€™t see libraries often is because the observability tends to be not worth abstracting when the whole company does it one or two ways.",
          "score": 1,
          "created_utc": "2026-01-20 03:43:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ifz",
              "author": "whudduptho",
              "text": "Thanks for the feedback. I have a few nice abstractions on the roadmap that really capture the IaS philosophy of building self-healing multi-region infra. Feel free to leave any additional feedback if you get a chance to read/use the constructs.Â ",
              "score": 1,
              "created_utc": "2026-01-20 04:55:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lm2bc",
          "author": "o5mfiHTNsH748KVq",
          "text": "I like that you included skills for the repo!",
          "score": -3,
          "created_utc": "2026-01-20 03:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ujp",
              "author": "whudduptho",
              "text": "Yes, force multiplier for sure. Iâ€™ll likely create a repo for some of these soon across TS/Go/Python and GitOps tooling.Â ",
              "score": -5,
              "created_utc": "2026-01-20 04:57:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgshy7",
      "title": "What is the value proposition of AWS MCP server?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qgshy7/what_is_the_value_proposition_of_aws_mcp_server/",
      "author": "Dry_Raspberry4514",
      "created_utc": "2026-01-19 03:00:43",
      "score": 12,
      "num_comments": 25,
      "upvote_ratio": 0.78,
      "text": "One of the tools (aws\\_\\_\\_call\\_aws) in AWS MCP server (confusing name, should have been called AWS Core MCP Server) simply takes same input as aws cli. Most the people using aws will have cli installed already and so if an MCP client has the cli command matching a prompt then it can simply invoke cli to get the job done. What is the advantage of using this tool over cli?\n\nMatching a prompt to corresponding cli command or input for aws query APIs is the main (and toughest) problem and most LLMs stuggle with it because their training data is old and web search tools used by these LLMs are not that effective.\n\nIdeally this tool should have accepted the prompt as input, use documentation search tool internally to find matching command and then return the result after executing the command.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qgshy7/what_is_the_value_proposition_of_aws_mcp_server/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0f2ghv",
          "author": "[deleted]",
          "text": "Reason: Hype\n\nBoard: \"Large companies are providing access via MCP, we need to do the same.\"",
          "score": 19,
          "created_utc": "2026-01-19 04:00:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0he0fs",
              "author": "Xerxero",
              "text": "What does it add? \nI can feed the AWS documentation to Claude and let it run api calls.",
              "score": 1,
              "created_utc": "2026-01-19 14:42:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0g4fre",
          "author": "Sirwired",
          "text": "There are more uses for MCP servers than AI Coding tools; there are a ton of AI agents that are not going to have bash access.  (And the users might not have AWS permissions at all; you can assume a role with your agent and set permissions that way.)",
          "score": 6,
          "created_utc": "2026-01-19 09:04:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gan5t",
              "author": "HiCookieJack",
              "text": "except you give them a bash MCP :D",
              "score": 3,
              "created_utc": "2026-01-19 10:03:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0gtq6i",
                  "author": "Sirwired",
                  "text": "I know you are kidding, but for those not getting the joke: AI agents that run on the web don't necessarily run in anything that has a shell prompt on it.",
                  "score": 2,
                  "created_utc": "2026-01-19 12:44:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0g4e9y",
          "author": "runitzerotimes",
          "text": "â€œCLI can handle everything, why do we need API?â€\n\nâ€œREST API can handle everything, why do we need SDK?â€\n\nâ€œScripts can handle everything, why do we need IAC?â€\n\nEvery single technology is just a different version of what came before it with QOL changes. Donâ€™t be the wanker who stands there complaining like a dinosaur about new tech â€œwhen the old way works fineâ€.",
          "score": 15,
          "created_utc": "2026-01-19 09:03:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fhsjf",
          "author": "Zenin",
          "text": "One possible reason I could think of is it seems difficult for some systems (such as Q / kiro) to safely trust specific CLI commands.  Meaning if I trust \"aws\" I'm also trusting \"rm\" because the actual tool is \"bash\".  So even if I have my aws profiles configured for safety, I still can't safely trust my agent to use it because AWS isn't actually the tool it's using, bash is.\n\nClaude Code IIRC is better about its tools having more nuance here so you can trust \"curl\" without trusting all possible CLI commands.\n\nIn these environments it may be easier to control trust with an MCP server than can be done with CLI commands.",
          "score": 5,
          "created_utc": "2026-01-19 05:47:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h63ql",
              "author": "ObjectiveAide9552",
              "text": "Redditors: llm suck, you canâ€™t trust them to do anything right. Also Redditors: why donâ€™t you just give llmâ€™s full access to your cli?",
              "score": 5,
              "created_utc": "2026-01-19 14:00:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fpvgy",
          "author": "VIDGuide",
          "text": "Could it be to do with permissions? The CLi needs a IAM key assigned one way or another, effectively, how is authentication to the MCP handled? I havenâ€™t looked into it, itâ€™s probably similar or IAM based anyway, but curious if it could abstract away from the IAM key completely perhaps?",
          "score": 1,
          "created_utc": "2026-01-19 06:52:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gvzha",
              "author": "Sirwired",
              "text": "Bingo.  Assume a role with your agent service, and you don't need to hand out IAM permissions to your users at all.",
              "score": 1,
              "created_utc": "2026-01-19 12:59:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lhjv8",
          "author": "jed_l",
          "text": "Itâ€™s a checkbox tbh. This drives usage, but once the hype train slows down, you will end up with well designed MCP servers that are not just mimics of the API. 95% of the APIs AWS offers are not directly called, a quarter are paginated, and the rest have little documentation on usage. \n\nWell designed MCP servers are not parities of the API.",
          "score": 1,
          "created_utc": "2026-01-20 02:41:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ewrey",
          "author": "Spaceman_Zed",
          "text": "I was curious as well, although I use the MCP daily, and know it works better, I couldn't quite put words to it. So please accept this through AI answer.\n\n1. Reliability & Hallucination Prevention\nLLM + CLI (The Risk): When an LLM generates a CLI command, it is guessing the syntax based on its training data. If a flag has changed, or if the model \"hallucinates\" a parameter (e.g., inventing a --force-delete flag that doesn't exist), the command fails. You then have to paste the error back to the LLM to debug.  \nAWS MCP (The Solution): The MCP server exposes defined tools to the LLM. The LLM doesn't guess the command; it selects a tool from a list of valid options provided by the server. The MCP server then constructs the correct API call or CLI command under the hood, ensuring syntax accuracy.  \n2. Context Window Efficiency\nLLM + CLI: To get an LLM to understand your infrastructure via CLI, you often have to run aws ec2 describe-instances, copy the massive JSON output, and paste it into the chat. This eats up your context window rapidly with irrelevant noise.\nAWS MCP: MCP servers are \"context-aware.\" They can fetch only the relevant resources (resources) or summarize data before sending it to the LLM. This keeps the conversation focused and prevents the model from \"forgetting\" earlier instructions due to context overflow.  \n3. Security & Guardrails\nLLM + CLI: If you give an LLM access to a terminal (e.g., via a \"bash\" tool), it effectively has the permissions of your local user. It could accidentally delete resources or upload credentials if you aren't watching every character it types.\nAWS MCP:\nLeast Privilege: You can run the MCP server with a specific, restricted AWS profile or role, independent of your main local credentials.  \nSandboxing: MCP servers can verify the \"intent\" of a command before executing it.\nRead-Only Modes: Many MCP implementations allow you to set the server to \"read-only,\" meaning the LLM can look at your S3 buckets but physically cannot execute a delete or put command, regardless of what the prompt says.\n4. Structured Data vs. Text Parsing\nLLM + CLI: CLI output is text. The LLM has to parse whitespace, tables, or raw JSON text. Complex outputs (like CloudWatch logs or deeply nested JSON) are difficult for an LLM to read reliably without formatting errors.\nAWS MCP: The protocol allows the server to pass structured objects directly to the LLM. It acts like an API integration, meaning the LLM receives clean data structures (lists, dictionaries) rather than a wall of text it has to OCR/parse.\n5. Discovery & Up-to-Date Knowledge\nLLM + CLI: The LLM's knowledge of AWS CLI commands is cut off at its training date. It won't know about a new AWS service released last month.\nAWS MCP: The MCP server is a piece of software you update. If AWS releases a new feature and you update your MCP server, the LLM immediately has access to that \"tool\" and its documentation via the protocol, even if the model itself hasn't been retrained.",
          "score": -6,
          "created_utc": "2026-01-19 03:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ez4c3",
              "author": "Buttleston",
              "text": "We're so cooled",
              "score": 9,
              "created_utc": "2026-01-19 03:39:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0h5llh",
              "author": "ObjectiveAide9552",
              "text": "This is absolutely correct. Reddit just has a luddite hate boner for anything generated by llm.",
              "score": 1,
              "created_utc": "2026-01-19 13:57:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0et4oy",
          "author": "rlt0w",
          "text": "This? https://awslabs.github.io/mcp/#available-aws-mcp-servers",
          "score": 0,
          "created_utc": "2026-01-19 03:05:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0eufyf",
              "author": "Dry_Raspberry4514",
              "text": "This one - [https://docs.aws.amazon.com/aws-mcp/latest/userguide/what-is-mcp-server.html](https://docs.aws.amazon.com/aws-mcp/latest/userguide/what-is-mcp-server.html)",
              "score": 1,
              "created_utc": "2026-01-19 03:12:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0euqwd",
                  "author": "rlt0w",
                  "text": "I know what MCP is, I guess I have no idea what you're asking. I use them daily and find great utility in them.",
                  "score": 2,
                  "created_utc": "2026-01-19 03:13:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qduom5",
      "title": "Open source tool to generate human-readable Terraform from AWS IAM Identity Center",
      "subreddit": "aws",
      "url": "https://cuenot.io/projects/aws-identity-management/",
      "author": "cuenot_io",
      "created_utc": "2026-01-15 20:23:32",
      "score": 10,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qduom5/open_source_tool_to_generate_humanreadable/",
      "domain": "cuenot.io",
      "is_self": false,
      "comments": [
        {
          "id": "nzub3gl",
          "author": "Straight_Studio960",
          "text": "Do you have also some sample of naming convention, to go with these repositories, for accounts and OUs and what would the account structure look like for a newly created organization ?Â \nLike starting from the management account where would you delegate the administrator account to for specific service integrations( Identity center, Cloudtrail logging, Guard duty, Config, security hub).\nSome practices that you learnt along the way of managing them.",
          "score": 1,
          "created_utc": "2026-01-16 01:44:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvnb2c",
          "author": "Ok-Eye-9664",
          "text": "Opus 4.5 + AWS CLI => Human Readable Terraform",
          "score": 1,
          "created_utc": "2026-01-16 06:52:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzwskmy",
              "author": "Jazzlike_Object_9464",
              "text": "Iâ€™m interested. Can you describe the idea, please?",
              "score": 1,
              "created_utc": "2026-01-16 12:42:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzyhjw0",
              "author": "cuenot_io",
              "text": "This format is easier for AI to read too. Greatly condensed codebase, allows for more context to fit in the window",
              "score": 1,
              "created_utc": "2026-01-16 17:38:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qg8ebs",
      "title": "Principals, tags, SCPs, and ABAC",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "author": "bobaduk",
      "created_utc": "2026-01-18 13:20:11",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Hello friends.\n\nI have a reasonably complex AWS account structure with a bunch of workloads and sandboxes in an AWS Organization. I'm thinking about applying ABAC to simplify IAM setup in certain cases. For example, imagine that we have an account sandbox-bobaduk, where I have broad access for playing around. We also have an account secret-data where we store some dataset in an S3 bucket.\n\nWe use Google Workspace as our IDP, and I can apply tags to my role session based on attributes. For example, I authenticate as arn:aws:sts::$sandbox-bobaduk:assumed-role/AWSReservedSSO_MyRole_08759cec7ee3fdc9/bobaduk@org.org. Because I used sso to authenticate, I have the tag `team=data-guy` on my role session.\n\nI can write a resource policy for my s3 bucket that allows GetObject if the OrgId=myorg, and the team tag has the value \"data-guy\".\n\nSo far so good.\n\nMy question, which I'm struggling a little to answer is \"can I trust the provenance of that tag?\".\n\nMy thinking is that I can use an SCP that denies tagging a session with the \"team\" tag, unless the user is adopting a role matching \"AWSReservedSSO_*\". \n\nI should also have an SCP that prevents a user from creating a new role or user with that tag.\n\nthe AWSReservedSSO_* roles can only be created by identity centre, and the trust policy restricts their use to identity centre, so with those SCPs in place, am I missing anything? \n\nI don't need transitive tagging for role chaining, because these tags are _only_ used for this kind of cross-account access based on a resource policy. if I assume another role, I should only have the permissions granted explicitly to that role.",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0aklds",
          "author": "Iliketrucks2",
          "text": "Had a long chat about just this the other day, same set of problems.  We are moving trust from fairly easy to control IAM policy to tag management.  And we want our CD system and users to set both our required tags, but any tags they want, so we need to find a way to namespace tags so we can control how those tags get modified which looks doable but a lot of work.  \n\nAWS does not make this easy, as always.",
          "score": 3,
          "created_utc": "2026-01-18 14:18:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amoy5",
              "author": "bobaduk",
              "text": "Namespacing I have *down*, I have two sets of tags, `myorg:sso:attrib` that gets used for humans, and `myorg:cap:attrib` that gets applied to roles used in automation etc.\n\nsoo attributes are used to say \"this person is in this team, this department whatever, so they can do these things\", capability tags are used to say \"this role can do this particular set of operations\". Given the namespacing, it's easy to say things like  \n\n* \"you may never tag a session as myorg:cap:...\" \n* or \"you may never tag a role myorg:sso:...\"  \n* and \"you may only tag a session as myorg:sso:... if you're assuming an SSO role\",\n\nbut I feel ... unsafe :D",
              "score": 1,
              "created_utc": "2026-01-18 14:29:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0b0vhq",
                  "author": "Iliketrucks2",
                  "text": "Clever. We were going to do similar with corp::{secuirty|cost|access|governance|misc}::{tags} and limit with scps which role(s) can manage which tags, but we still have the omnipotent deployer role that we want to protect against while allowing to create the tags we need in each namespace.  Our concern is around a malicious user rather than an ignorant one - someone who wanted to get access to data could plan a deploy to change tags on things and circumvent our controls.  We have a human review on PR but are concerned about asking devops teams to know enough about tagging to enforce policy - we want technical controls\n\nI think for our most sensitive data we may end up using tagging but adding auditing or a hard scp with specific resources and tag values so only our security team can set/change those tags, then loosen the control and guardrails as data becomes less sensitive so we minimize impact to developers",
                  "score": 1,
                  "created_utc": "2026-01-18 15:42:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qeaqy0",
      "title": "Development environment monitoring?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qeaqy0/development_environment_monitoring/",
      "author": "alangibson",
      "created_utc": "2026-01-16 08:39:00",
      "score": 8,
      "num_comments": 12,
      "upvote_ratio": 0.79,
      "text": "We keep having problems where development, testing, and acceptance environments are left running long after they're needed. We also loose track of what, and what version, is deployed to each environment. Some times its not even clear what team owns what.\n\nDoes anyone know of a tool that can keep track such a mess?\n\nAt a minimum I'd like a dashboard that shows me:\n\n* Basic environment stats like: age, average utilization (ie is anyone using this?)\n* Deployed commits, application versions, etc\n* Team that owns it\n\nI'd really prefer a standalone solution since managers, marketing and sales people are also interested in this information. They're easily alarmed by the complexity of the AWS interface.\n\n\"Deployed commits, application versions,\" is there mainly for marketing and management so they can look for themselves where the features they requested have progressed to. \n\nEdit: clarity.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qeaqy0/development_environment_monitoring/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzw0hrm",
          "author": "bqw74",
          "text": "This question suggests you have more fundamental problems. Why have a dashboard to keep track of a mess? Better to not have the mess at all!\n\nA question:\n- do you use IaC (terraform, cloudformation, etc) - if not, start doing that.\n\n\nThe way we do it:\n- every dev has their own AWS account and _they_ are responsible for what runs in it (and need to account for costs)\n- _everything_ is deployed via CI/CD (infra, app code, the lot)\n- We *force* every dev account to be fully wiped every month by scheduled job. Dev's know this and, if their IaC is good, it takes 10 mins to rebuild their account from code. If something's wrong after this, they know there's a problem with the IaC, and they fix it.\n\n\"Cattle, not pets\" -- Google it.\n\nAs to \"who owns it\" or \"what teams\" -- tags can help with this -- set up a tagging regime/schema and enforce it (there are many ways to do this) including using native AWS tools or a \"compliance-as-code\" type tool.",
          "score": 6,
          "created_utc": "2026-01-16 08:49:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw4hfr",
              "author": "wunderspud7575",
              "text": ">- every dev has their own AWS account and _they_ are responsible for what runs in it (and need to account for costs)\n\nWow, you are living the dream. I've pushed for this in multiple jobs, but never managed to get buy in from architects and cyber folks. Their brain seems to have an allergic reaction to the idea of so many accounts.",
              "score": 1,
              "created_utc": "2026-01-16 09:26:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzwn62x",
                  "author": "Davidhessler",
                  "text": "Usually the push back here is because of one of three reasons. They are all indicate either a lack of technical skill OR cultural problems.\n1. Having an account for every dev will cost more â€” this is blatantly untrue. A lot of studies have shown that in general it costs the same or less.  This is because with shared dev accounts there always ends up with orphaned resources that no seems to be able to say who it belongs to. I cannot tell you how many times Iâ€™ve seen an RDS resource left on all the time because â€œsomeone might use itâ€ or â€œthe team canâ€™t remember who provisioned it.â€\n2. We donâ€™t have enough people to safely vend these accounts â€” this is a skill problem. You can create AWS accounts via CloudFormation or Terraform today. Thereâ€™s tons of AWS services and 3P products that provide automated governance at scale AND meet whatever compliance requirements you need. Any lag in the vending process means you have a manual driven culture somewhere that you need to fix.  Thereâ€™s a lot of studies Iâ€™ve seen over the years that shows a correlation between the time it takes to vend and the success someone has in the clouds. If it takes you two weeks to vend an account, you are probably overpaying for the cloud and not taking full advantage of it.\n3. Our developers will be able to spin up whatever they like â€” this indicate either you donâ€™t have proper governance in place of your cloud environment or you donâ€™t have the proper tools for safe development. Again this is a solved problem by AWS, the OSS community and 3P. You just need to use the tools available.",
                  "score": 1,
                  "created_utc": "2026-01-16 12:05:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nzw7a7h",
              "author": "alangibson",
              "text": "I agree this is a process and culture problem. But for all the usual reasons that's not getting fixed anytime soon. So I'm trying to do what any right thinking person would: paper over the problem with yet another app.",
              "score": 1,
              "created_utc": "2026-01-16 09:53:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzw5sj4",
          "author": "safeinitdotcom",
          "text": "You could use some AWS specific services:\n\n*  AWS Resource Groups or Service Catalog AppRegistry to group resources. Enforce tags on creation for owner, environment to eliminate ambiguity around ownership.\n* CloudWatch Dashboard filtered by those tags. This gives you a single view of resource utilization (to spot who is actually using what).\n\nSome links that might help:\n\n* [https://docs.aws.amazon.com/servicecatalog/latest/arguide/overview-appreg.html](https://docs.aws.amazon.com/servicecatalog/latest/arguide/overview-appreg.html)\n* [https://docs.aws.amazon.com/ARG/latest/userguide/resource-groups.html](https://docs.aws.amazon.com/ARG/latest/userguide/resource-groups.html)",
          "score": 2,
          "created_utc": "2026-01-16 09:39:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzw7qaw",
              "author": "alangibson",
              "text": "Thanks for the info. Tags are really too low-level of a solution for this though. We've got managers, marketing and sales people that want this information at a glance.",
              "score": 1,
              "created_utc": "2026-01-16 09:57:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzwe114",
          "author": "dataflow_mapper",
          "text": "This is less a tooling gap and more a hygiene problem that tooling can surface if the basics are there. The biggest unlock is strict ownership and lifecycle metadata, like every environment having an owner, purpose, and expiry baked in at creation time. If environments are created from code and stamped with version info automatically, you can infer what is deployed without anyone manually updating a spreadsheet. Utilization and age are easy once everything is consistently labeled, and you can build a simple read only dashboard on top of that data for non technical folks. The hard part is enforcing cleanup when the expiry hits and making teams feel the cost of leaving things around. I would start by fixing creation standards first, then look for something to visualize it rather than hoping a tool will magically untangle it.",
          "score": 1,
          "created_utc": "2026-01-16 10:53:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03rvei",
          "author": "Sirwired",
          "text": "Tags, tags, tags.  Have a set of mandatory tags for every resource, and tell devs you will start deleting everything that doesn't have them.\n\nOnce you have that, you can do whatever automated operations you want on the information you can now surface.",
          "score": 1,
          "created_utc": "2026-01-17 13:51:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o066csm",
              "author": "IridescentKoala",
              "text": "Great now you have angry devs with deleted resources, or the same mess but with tags!",
              "score": 1,
              "created_utc": "2026-01-17 20:53:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o06qy2w",
                  "author": "Sirwired",
                  "text": "Plenty of places have a \"untagged resources get deleted\" policy; it's not unusual, and they'll adjust soon enough.  Cost and resource control simply isn't possible without them.\n\nAnd for the kind of analyses OP wants, tags are step 1.",
                  "score": 1,
                  "created_utc": "2026-01-17 22:37:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qj132z",
      "title": "I made DynamoLens: FOSS desktop companion for DynamoDB",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "author": "rasjonell",
      "created_utc": "2026-01-21 15:35:32",
      "score": 8,
      "num_comments": 2,
      "upvote_ratio": 0.9,
      "text": "Iâ€™ve been building DynamoLens, a free and open-source desktop app for Amazon DynamoDB. Itâ€™s a non-Electron (Wails) desktop client that makes it easy to explore tables, inspect/mutate items, and juggle multiple environments without living in the console or CLI.\n\nHighlights:\n\n\\- Visual workflows to compose repeatable item/table operationsâ€”save, share, and replay without redoing manual steps\n\n\\- Dynamo-first explorer: list tables, view schema details, scan/query, and create/update/delete items and tables\n\n\\- Multiple auth modes: AWS profiles, static creds, or custom endpoints (DynamoDB Local works great)\n\n\\- Modern UI with command palette, pinning, and theming\n\nIf you want to try it: [https://dynamolens.com/](https://dynamolens.com/)\n\nRepo: [https://github.com/rasjonell/dynamo-lens](https://github.com/rasjonell/dynamo-lens) (free & open source)\n\nWould love feedback from folks who live in DynamoDB day to day, whatâ€™s missing or rough?",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0vcgsw",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vcgrk",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -1,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh10yo",
      "title": "AWS S3 Batch Replication (operation: replicate). Both buckets are versioned. What happens on object key collision?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "author": "IceAdministrative711",
      "created_utc": "2026-01-19 10:48:50",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "**Context**  \nI configure [S3 Batch Operation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html) (to replicate existing objects). Manifest is generated automatically and includes all objects. Both buckets are versioned. Batch Job is configured based on existing (Live) replication configuration.\n\n**Question**  \nI know that both buckets have one object with the same key but different versions. Which version will become current? Is there any documentation on that matter?\n\n\\---\n\n**PS**  \nI observed 2 behaviours:\n\n1. source object's version becomes current version in the Destination Bucket\n2. The Destination object version remains current while source object version is added to the non-current versions in the Destination Bucket\n\nI can only assume that it depends on \\`last modified\\` date and the newest version (be it source or destination) wins",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0hiji7",
          "author": "SpecialistMode3131",
          "text": "I think you're right about what will happen.\n\nMore importantly, you should change your system so this is never even an issue.  Just get rid of this problem.  There is no way this kind of complexity is benefiting you, and you will be able to eliminate it with some thought.",
          "score": 3,
          "created_utc": "2026-01-19 15:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0huxs1",
          "author": "menge101",
          "text": "Completely agree with /u/specialistmode3131 , this seems like an [XY problem](https://xyproblem.info/) as well.  \n\nWhat is it you are trying to do?",
          "score": 2,
          "created_utc": "2026-01-19 16:03:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qefo3w",
      "title": "Account suspended during active DDoS billing review â€” seeking guidance on escalation paths",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qefo3w/account_suspended_during_active_ddos_billing/",
      "author": "Plane-Management-176",
      "created_utc": "2026-01-16 13:16:31",
      "score": 7,
      "num_comments": 8,
      "upvote_ratio": 0.82,
      "text": "Looking for guidance from others who have dealt with AWS account suspensions during active billing or security reviews.\n\nOur production workload was hit by a large DDoS attack, which caused a sudden spike in AWS WAF, CloudFront, and CloudWatch usage and a very large, unexpected bill. We opened support cases immediately, shared ARNs, detailed timelines, WAF analytics, request counts in the millions per day, and attacker IP samples. AWS acknowledged the issue and escalated it for service-team review and possible billing adjustment.\n\nWhile this review was still ongoing, and despite requesting temporary billing hold during the investigation, the account was suspended for non-payment. Weâ€™re now unable to log in to the console, which has taken production applications offline and blocked access to CloudWatch and infrastructure management.\n\nAt this point, weâ€™re trying to understand the correct escalation path. For those whoâ€™ve experienced something similar:  \nIs there a recommended way to get an account reinstated while a billing dispute is under review?  \nAre there escalation channels beyond the standard account support form once console access is blocked?\n\nAppreciate any guidance or experiences from the community.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qefo3w/account_suspended_during_active_ddos_billing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "nzz8crh",
          "author": "AWSSupport",
          "text": "Hello,\n\nSorry to hear about the issue with your account. Feel free to share your case ID with us via chat and I can take a look.\n\n\\- Doug S.",
          "score": 3,
          "created_utc": "2026-01-16 19:37:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzby1d",
              "author": "[deleted]",
              "text": "[deleted]",
              "score": 1,
              "created_utc": "2026-01-16 19:54:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzzh9vr",
                  "author": "AWSSupport",
                  "text": "Hi there,\n\nThank you for providing your case ID. I've shared your concerns internally with our Support team on your behalf.\n\nI'd encourage you to continue to communicate via email with our Support team as they're equipped with the tools to best assist.\n\n\\- Doug S.",
                  "score": 1,
                  "created_utc": "2026-01-16 20:19:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o02fehd",
          "author": "Burekitas",
          "text": "Do you have a Shield Advanced subscription? Or do you work with AWS Partner? \n\n  \nIf not, it might be a major cash flow issue, but the invoice must be paid until this issue is resolved.\n\nI've dealt with DDoS cases in the past and 15K customer received a $413K and it took 4 months to resolve it. Not an easy situation but invoices must be paid :/ \n\nGood luck getting your account back.",
          "score": 3,
          "created_utc": "2026-01-17 07:02:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzz5tq1",
          "author": "The_Tree_Branch",
          "text": "Do you have an AWS account manager/account team? I'd be leaning on them heavily if so.",
          "score": 5,
          "created_utc": "2026-01-16 19:26:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzzc8hz",
              "author": "Plane-Management-176",
              "text": "No i dont have any AWS account manager",
              "score": 2,
              "created_utc": "2026-01-16 19:55:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o09ihai",
          "author": "dataflow_mapper",
          "text": "That sounds brutal, and sadly I have seen variations of this before. Once an account is fully suspended, normal support cases tend to stall because billing enforcement is automated and not tightly coupled to ongoing reviews. What helped in one case was getting the account manager or TAM involved, even if they were only loosely attached before. If you do not have one, pushing hard through the billing escalation form and explicitly stating production impact sometimes triggers a different internal queue. It is also worth asking for temporary read-only console access so you can at least validate state and exports. The big lesson I took from this is that billing disputes and security incidents often move on totally different tracks internally, and they do not always talk to each other fast enough.",
          "score": 2,
          "created_utc": "2026-01-18 09:17:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qis9yz",
      "title": "Service recommendation",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "author": "Artistic-Analyst-567",
      "created_utc": "2026-01-21 08:15:57",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 0.77,
      "text": "Hello folks,\n\nLooking for recommendations for storing and searching across a large volume of data\n\nWe basically have a flattened table structure that holds around 300 million records, probably close to 50 columns\n\nWe need to provide fuzzy text search on some fields, expecting fairly high queries per second volume, and latency has to be on par with synchronous api style (200ms up to 1s)\n\nWe were initially thinking about loading the data into our RDS Aurora (MySQL, r6g.xlarge) but i never dealt with that kind of data volume and i imagine the indexes will be massive and maintenance will be painful\n\nThen i thought about Dynamodb but the fuzzy search requirement ruled that option out\n\nNow thinking OpenSearch serverless might be a good candidate\n\nAnyone worked on a similar scenario? we don't expect that table to get much updates, maybe once a month at most",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0tkzyh",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 08:15:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tqhx8",
          "author": "proxwell",
          "text": "This is really squarely in OpenSearch's wheelhouse.\n\nYou have a high read/query to write ratio, high QPS, infrequent updates, and need to support fuzzy text search.\n\nWhile you could do this in Aurora, I think your experience would be very unpleasant relative to OpenSearch.  With Aurora, you'd have massive fulltext indexes, slow/unpredictable index rebuilds, and performance is likely to bog down quickly under concurrent fuzzy searches.  Also, the scaling story is pretty painful, as youâ€™ll hit IOPS, buffer pool, or CPU ceilings faster than expected.\n\nI think OpenSearch serverless is the way to go in your scenario.  You'll have a little less low-level control for a couple niche tuning settings, and you'll want to do some proactive cost estimation to make sure you know what you're on the hook for, but I still think serverless is the clear winner here.",
          "score": 10,
          "created_utc": "2026-01-21 09:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ujx36",
          "author": "dataflow_mapper",
          "text": "your instinct is pretty solid. RDS will work on paper but at that scale the index bloat and tuning pain usually outweigh the benefits, especially for fuzzy search. DynamoDB is basically out once you need flexible text matching. OpenSearch is the tool most teams land on for this pattern, especially with mostly read traffic and infrequent bulk updates. The key is modeling the index carefully and being very intentional about analyzers so you do not blow up query latency. If the data really is mostly append or monthly refresh, reindexing is manageable. I have seen similar setups hit your latency targets as long as the queries stay scoped and you resist turning every field into a fuzzy search field.",
          "score": 4,
          "created_utc": "2026-01-21 13:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umk1i",
              "author": "Artistic-Analyst-567",
              "text": "Very insightful, will keep those recommendations in mind\nI just saw that there is a dedicated ingestion service for OS serverless (OSIS), this will come in handy since the data will probably reside in S3",
              "score": 1,
              "created_utc": "2026-01-21 13:22:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uk25w",
          "author": "solo964",
          "text": "You're storing 300m records and need to support sustained high query volumes with predictable performance, so I would say that regular managed OpenSearch could be a better option. Run the numbers but it could be more cost-effective as well as improve query latencies. Downside is the higher operational burden.",
          "score": 2,
          "created_utc": "2026-01-21 13:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umrhk",
              "author": "Artistic-Analyst-567",
              "text": "Makes sense, it's probably worth running a couple of POCs and see what the trade-offs and cost implications are",
              "score": 1,
              "created_utc": "2026-01-21 13:24:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tqeks",
          "author": "Horciodedayo",
          "text": "RemindMe! -1 day",
          "score": 1,
          "created_utc": "2026-01-21 09:07:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqh1c",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-22 09:07:43 UTC**](http://www.wolframalpha.com/input/?i=2026-01-22%2009:07:43%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/o0tqeks/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Faws%2Fcomments%2F1qis9yz%2Fservice_recommendation%2Fo0tqeks%2F%5D%0A%0ARemindMe%21%202026-01-22%2009%3A07%3A43%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qis9yz)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-21 09:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ve5ce",
          "author": "TechDebtSommelier",
          "text": "300 million rows plus fuzzy text search is basically OpenSearchâ€™s whole personality, so your instinct there is right. Aurora will technically work but youâ€™ll hate your life maintaining giant text indexes and still miss your latency targets once QPS ramps up. DynamoDB is a non starter for fuzzy search unless you bolt something else on.\n\nOpenSearch Serverless fits well here since your data is mostly read heavy and rarely updated, but do budget time for index tuning and shard sizing because it is not magic. If you want boring and predictable performance at that scale, search engine plus source of truth in S3 or RDS is the usual pattern, not trying to force a relational database to cosplay as a search engine.",
          "score": 1,
          "created_utc": "2026-01-21 15:43:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wnhal",
          "author": "gwinerreniwg",
          "text": "What about S3 Tables and like Athena on top or maybe OpenSearch?",
          "score": 1,
          "created_utc": "2026-01-21 19:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tkzxv",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -1,
          "created_utc": "2026-01-21 08:15:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi650u",
      "title": "How do you keep system context from rotting over time?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "author": "kennetheops",
      "created_utc": "2026-01-20 16:43:17",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "Former SRE here, looking for advice.\n\nI know there are a lot of tools focused on root cause analysis after things break. Cool, but thatâ€™s not whatâ€™s wearing me down. What actually hurts is the constant context switching while trying to understand how a system fits together, what depends on what, and what changed recently.\n\nAs systems grow, this feels like it gets exponentially harder. Add logs and now youâ€™ve created a million new events to dig through.. Add another database and suddenly youâ€™re dealing with subnet constraints or a DB choice thatâ€™s expensive as hell, and no one noticed until later. Everyone knows their slice, but the full picture lives nowhere, so bit rot just keeps creeping in.\n\nThis feels even worse now that AI agents are pushing a ton of slop ..i mean code and config changes quickly. Things are moving at lightspeed, I cant be the only one feeling like my understanding is falling behind daily.\n\nIâ€™m honestly stuck on how people handle this well in practice. For folks dealing with real production systems, whatâ€™s actually helped? Diagrams, docs, tribal knowledge, tooling, something else? ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0p00z3",
          "author": "SpecialistMode3131",
          "text": "You need to write real documents (preferably outside the codebase, as in wiki type environments) that pull together the business reasons for the system to exist, alongside the high level code decisions that were made.\n\nThere's a lot of different schools of thought - for example, my claim that putting docs outside the codebase is good will be disputed by some - but end of the day you cannot use a tool to skip taking the time to thoroughly describe your intent in laying out the systems as they exist now.\n\nDocs rot, too, so a dedicated hunk of time every week, month, etc to sweep your core foundational documents to ensure they're up to date is critical to keeping important stuff well understood and running.\n\nOnly you can decide if you have the will to do so - if it's important enough.  Just remember you reap as you sow.\n\nWhen I deliver for clients, I always leave behind a thorough high level documentation base for future maintainers, and when I am given existing legacy systems to deal with, building synthesis is the first order of business.",
          "score": 3,
          "created_utc": "2026-01-20 16:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p0yso",
              "author": "kennetheops",
              "text": "I like the idea of having the docs outside of the code base. \n\nWhat are you doing to capture info said in chat threads? Or do you assume this as a just a losing battle?",
              "score": 1,
              "created_utc": "2026-01-20 16:53:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0p1onv",
                  "author": "SpecialistMode3131",
                  "text": "Human beings are present in chat threads. Hold them accountable to putting the important content they learn down in the docs in a good way.  Make keeping docs in good shape part of their evaluation criteria at review time.\n\nThere is a tendency in tech to try and make everything a tool. When work requires judgment, as in documentation, that's a big mistake and it leads to a completely predictable decaying useless mess. Just refuse to make that mistake, and require human beings to own the documentation fully.  And keep the documentation high level so it doesn't become a burden.",
                  "score": 1,
                  "created_utc": "2026-01-20 16:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0p58ws",
          "author": "oneplane",
          "text": "What's helped is having responsibilities tied together, i.e. a change in some IaC is done for a reason, and depending on the size and complexity that reason (or intent) needs to be in the code, in the docs along side the code, in the global system docs or in business docs, or a mix of all of them.\n\nIn theory with static systems you'd be tracing from a business need to a functional need to a technical need to a requirement to a design to an implementation. In reality that doesn't really work out very often, but what you can do is apply the same rules as you'd do in namespaces/modules/packages/boundaries, things that only matter very close to the technical 'thing' and don't spill over into other areas (outside of its own boundary) would be in your commit message, code comments, or repository docs for example. You'd have to have rules and processes in place to not merge code that doesn't have an intent described and attached to it.",
          "score": 1,
          "created_utc": "2026-01-20 17:13:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pezrs",
              "author": "kennetheops",
              "text": "Is this a process or do you use a tool for this?",
              "score": 1,
              "created_utc": "2026-01-20 17:58:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pzasq",
                  "author": "oneplane",
                  "text": "We use Atlantis, OPA and a custom coverage tool to only allow a Terraform apply if coverage on the PR is over 90%, we're experimenting with doing more in a workflow pipeline but it's mostly an optimisation rather than a change in features.\n\nSimilar results can be achieved with pre-commit.",
                  "score": 1,
                  "created_utc": "2026-01-20 19:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0panru",
          "author": "dr_barnowl",
          "text": "Descriptive code.\n\nThe slopcode is a problem for this approach.\n\nWrite abstractions that help you comprehend things. That's basically what all code is once you stop writing raw machine code as byte values into memory.\n\nOnce I get a project started, I don't write a VPC by writing all the little ins and outs. I have a module. I say \"this is VPC #23, it's for this\". The code works out the CIDR blocks from the VPC number, and the module has a standard structured output that application modules expect to see, that describes the available subnets, etc. I just pass this output to the application module which is written to use it.\n\nLook at the top and you can see a VPC, an application, a link of the VPC to the transit gateway. Dig down and you can see the detail, which you make as consistent as possible so it's understandable.\n\n(NB CloudFormation sucks at this, Terraform is much better).",
          "score": 1,
          "created_utc": "2026-01-20 17:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0peupd",
              "author": "kennetheops",
              "text": "we are doing this for infra, but how are you tracking code dependencies  to infra resources? For example say we have 2 dbs but 1 db is dev and the other is prod, and 10 vms. Obviously the prod vms have a higher risk for changes than the dev vms.",
              "score": 1,
              "created_utc": "2026-01-20 17:58:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0qf9db",
                  "author": "dr_barnowl",
                  "text": "Prod vs dev my choice would always be account separation ; setting up cross-account deployment involves some extra work, but in an ideal world, no dev has access to production resources. The clearest way to ensure this is to ensure they have no access to entire accounts.",
                  "score": 1,
                  "created_utc": "2026-01-20 20:44:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qh1n3l",
      "title": "SESv2 migration",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "author": "sloveubagukaraliui",
      "created_utc": "2026-01-19 11:23:20",
      "score": 6,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Hi, I use terraform to manage aws deployments. \n\nSes is deployed using v1 api and now I want to migrate to v2. \n\nWhat are the steps? \n\nDo I destroy v1 resources first and deploy v2? \n\nwhat happens with dkim dns set up, would I need to configure new entries? \n\nI cant have any downtime, emails are a super critical part of our business. Switching to some other domain is not suitable due to need for warmup that can take up to 2 months. ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0gmwiv",
          "author": "CSYVR",
          "text": "They are the same resources, just with different APIs to configure them.\n\nYou can add the v2 resources and run imports gradually, there's not even a huge problem managing the two resources at the same time, as long as you're not making any changes.\n\nAlternative is just deleting the v1s from the state (terraform state rm <resourceid>) and importing the new ones (e.g.  terraform import aws\\_sesv2\\_email\\_identity.example [example.com](http://example.com) )",
          "score": 3,
          "created_utc": "2026-01-19 11:52:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jvjrr",
              "author": "sloveubagukaraliui",
              "text": "wait what\n\nare you saying that I should be able to create a v2 resource using the same domain alongside to an existing v1 domain identity?",
              "score": 1,
              "created_utc": "2026-01-19 21:34:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0jxdt7",
                  "author": "CSYVR",
                  "text": "Yes, just add and import it:\n\n    #v1 resource\n    resource \"aws_ses_domain_identity\" \"example\" {\n      domain = \"example.com\"\n    }\n    \n    #v2 resource\n    resource \"aws_sesv2_email_identity\" \"example\" {   \n      email_identity = \"example.com\" \n    } \n    \n    #Import statement for v2 resource so no new identity is created\n    import {\n      to = aws_sesv2_email_identity.example\n      id = \"example.com\"\n    }\n\nPretty simple once you get the hang of it :)",
                  "score": 2,
                  "created_utc": "2026-01-19 21:44:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0grhy6",
          "author": "shisologic",
          "text": "You can test the migration from ses v1 to ses v2.\n\nIf you can't create v1 using terraform, you can deploy it via AWS CLI ses (not sesv2).",
          "score": 1,
          "created_utc": "2026-01-19 12:28:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg1udo",
      "title": "Centralized CI/CD security scanning for 30+ repos. Best practices?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "author": "_1noob_",
      "created_utc": "2026-01-18 07:06:54",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.78,
      "text": "Hi everyone,\n\nWe are currently working on integrating CI/CD security tools across our platform and wanted to sanity-check our approach with the community.\n\nWe have 30+ repositories in bitbucket and are using AWS for CI/CD. \n\nWhat we are trying to achieve:\n\n* A centralized or shared pipeline for security scanning (SAST, SCA, Container Scanning, DAST).\n* Reuse the same scanning logic for all the repos \n* Keep pipelines scalable and maintainable as the number of repos grows.\n\nThe main challenge we are facing:\n\n* Each repository has different variables for SAST (eg sonarqube) \n\nQuestions:\n\n* Is it a good practice to have one shared security pipeline/template used by all repos for scanning?\n* How do teams typically manage repo-specific variables and Sonar tokens when using shared pipelines?\n* Any real-world patterns or pitfalls to watch out for at this scale (30+ pipelines)?\n\n\n\nAgain, goal is to keep security enforcement consistent without over-coupling pipelines as possible. \n\nWould really appreciate hearing how others have solved this in production.\n\nThanks in advance.",
      "is_original_content": false,
      "link_flair_text": "ci/cd",
      "permalink": "https://reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o09995s",
          "author": "no1bullshitguy",
          "text": "My first question would be: Why do you want it separate? Things like SAST / DAST should ideally be part of the individual application pipeline. Then only you can fail the pipeline when the code does not hit a particular baseline you set, let it be Code Quality (Sonarqube), SAST / DAST etc.\n\nNow, having said that,  I have implemented the other way also, like a Central Pipeline. The way I did is, all the fields are parametrized with fields for example Application ID for that particular application in our scan tool, Packaged Artifact URL for doing Opensource Library Scan, GIT Repo URL for downloading source for SAST ,  Branch to name a few (it has been 5 years so I dont remember most)\n\nThen the application build pipeline will trigger the scanning Job by calling REST API of CI/CD tool with above parameters filled in. Things like Artifact URL, GIT Repo URL etc would be already available as environment variables. But application ID for Scanning tool, i had to set it manually as a parameter for each pipeline (Devs will fill it, and I just had to give the template)\n\nAPI key for your Scanning tool would be most probably global key. This key can be stored as a variable in the central pipeline itself\n\nI have scaled both the above models for 1000+ pipelines. Works well, but I strongly suggest you to keep these scans and Quality gates as part of the actual build pipeline itself. It can go in parallel with rest of the stages not affecting deployment times. Because at some point, you would want to break the pipelines when code quality goes south.",
          "score": 1,
          "created_utc": "2026-01-18 07:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7ylt",
          "author": "XohleT",
          "text": "I am working on the same problem but for github. In our company we have 2000+ repositories and a lot of variation in pipelines due to not standardising from the start. \n\nThis makes it hard to enforce a single pipeline for everyone. If we do create one it is up to us to make sure it works for everyone which is a burden we rather not take on. \n\nSo we decided to decouple enforcement from scanning. In github we can create rulesets that require certain scanning tools to have checked the repository before a PR can be merged. We use this for enforcement while providing pipeline templates and private github actions to help implementation of scanning tools. \n\nThis makes it easier to start enforcement while not being a burden because teams can do their own implementation if ours donâ€™t work. \n\nFor scanning tools that dont integrate with github rulesets checks we have created our own tool to check if the scanning is sufficient.",
          "score": 1,
          "created_utc": "2026-01-18 12:58:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bfrty",
          "author": "jefoso",
          "text": "I don't know if it's an approach that I'd follow. IMHO it's too late to fail.\n\nMost of these security/quality checks should happen at the left(the beginning) of the development so the earlier it fails the faster and cheaper it is to fix.\n\nI believe that: \n- developers shoulduse linters, pre-commit hooks, things that are cheaper to run and get possible issues locally \n- feature branches should also do some part of the job and execute more complex tools/scans\n \nCentralized tools should be part of the process, the company would have a release process where everyone agrees that if these integration tests or security scans fails, that feature would be removed from the release or the entire release would be blocked.\nI think this is not just about tools and how to implement them, but also how the company and teams works.",
          "score": 1,
          "created_utc": "2026-01-18 16:53:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fbjet",
              "author": "_1noob_",
              "text": "we are also using pre-commit hooks with a decent configuration.",
              "score": 1,
              "created_utc": "2026-01-19 05:01:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i396l",
          "author": "CodacyKPC",
          "text": "Hello, I'm Kendrick, VP of Technology at Codacy. I would say: use Codacy!\n\nWe connect to your Bitbucket directly and use webhooks to listen for changes and then scan the diff when you submit a PR. We do the scanning on our side in our cloud engine so there's no CI/CD configuration for you to have to handle. You can create multiple overlapping \"coding standards\" that can apply to whichever repositories you want, so can create e.g. a \"baseline security\" standard and a \"javascript standard\" and a \"frontend team standard\". \n\nThen you can gate merging of code into your main branch based on whether the Codacy checks passed in the PR.\n\nExtra plus: we have an IDE extension that will run the same checks locally so that by the time your devs get to the PR they should have already resolved all of the issues.\n\nExtra extra plus: the IDE extension \\_forces\\_ AI coding agents to resolve issues in their workflow, before they hand back control to the dev, so issues can get fixed without developers even knowing about them.\n\nYes, this was an advert. It still seemed relevant. Do DM me and we'll set you up with a free trial.",
          "score": 1,
          "created_utc": "2026-01-19 16:40:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg7a1g",
      "title": "Moving to CloudFormation with Terraform/Terragrunt background, having difficulties",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "author": "hardvochtig",
      "created_utc": "2026-01-18 12:24:11",
      "score": 5,
      "num_comments": 24,
      "upvote_ratio": 0.67,
      "text": "Hi all, I'm used to Terraform/Terragrunt when setting up infra and got used to its DRY principles and all. However my new company requires me to use CloudFormation for setting up a whole infra from scratch due to audit/compliance reasons. Any tips? Because upon research it seems like everybody hates it and no one actually uses it in this great year of 2026. I've encountered it before, but that's when I was playing around AWS, not production.\n\nI've heard of CDK, might lean into this compared to SAM.\n\n[](https://www.reddit.com/submit/?source_id=t3_1qg79f4)",
      "is_original_content": false,
      "link_flair_text": "CloudFormation/CDK/IaC",
      "permalink": "https://reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0a40s3",
          "author": "Sirwired",
          "text": "CDK generates CFn underneath, but it's still very different from TF. (CDK is a way to use Python, Java, TypeScript, JavaScript, C# and Go to generate CFn.)\n\nI have to wonder what audit reasons require them to use CFn directly.",
          "score": 21,
          "created_utc": "2026-01-18 12:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a4r2p",
              "author": "kei_ichi",
              "text": "All I can think is â€œno external tools other than AWS native toolsâ€ bull sh*t",
              "score": 10,
              "created_utc": "2026-01-18 12:34:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a71m7",
                  "author": "hardvochtig",
                  "text": "Well, yes!",
                  "score": 5,
                  "created_utc": "2026-01-18 12:52:18",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a70cm",
              "author": "hardvochtig",
              "text": "For easy drift detection and everything is managed by AWS including the state.",
              "score": 6,
              "created_utc": "2026-01-18 12:52:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cyi21",
                  "author": "dr_barnowl",
                  "text": "The fact that you're forced to use the AWS backend of CloudFormation is likely the reasoning for this ; but there's no real reason why you can't set up a Terraform based IaC backend with the same constraints.\n\nIf you want full auditablility, the solution is the same ; log all the cloudtrail traffic and use that as the basis for any audit. The result is the same - the console, CF, and terraform, all use the same APIs.\n\nIf you want control, you have to do just as much work to do to prevent console meddling.\n\nDrift detection? TF can do that. State? You can put the state in an S3 bucket with strong controls on it.\n\nAll the attitudes preferring CloudFormation to Terraform I've seen ... seem to be rooted in dislike for the idea of programming. The only advantages CF has over TF in my book are that you have a prebuilt IaC setup, and lots of code samples. The rest ... CF is hard to grow, hard to refactor, and a PITA to modularize. And slow, because dependency graphs in CF treat stacks as an entire atomic unit, you can't update anything with an input that depends on an output until the whole stack is done.",
                  "score": 0,
                  "created_utc": "2026-01-18 21:17:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0coxcb",
              "author": "Davidhessler",
              "text": "Possibly CloudFormation Hooks / Guard. There are a lot of teams implementing controls these days using those techniques.",
              "score": 2,
              "created_utc": "2026-01-18 20:27:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a43ra",
          "author": "mrsmiley32",
          "text": "I'd go CDK and then synth the cloudformation from that for the audit purposes. CDK is much nicer to work with than cloudformation.",
          "score": 13,
          "created_utc": "2026-01-18 12:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a73zn",
              "author": "hardvochtig",
              "text": "So Iâ€™ve heard! Definitely the top option, aside from asking them if CF is really necessary",
              "score": 3,
              "created_utc": "2026-01-18 12:52:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aogh8",
                  "author": "AntDracula",
                  "text": "CDK generates CF",
                  "score": 3,
                  "created_utc": "2026-01-18 14:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0akqjl",
          "author": "TheCamerlengo",
          "text": "I used cloud formation and code pipeline for years. I became rather proficient at it. Took a while. Itâ€™s awkward and difficult to debug when things go wrong. It taught me a lot about how AWS IAC provisioning really works. \n\nNew job uses terraform and after 1 day I never looked back. Terraform is light years easier to use but it is an abstraction. Understanding how cloud formation works helped me fill some gaps when using terraform. \n\nBasically you are going to hate cloud formation coming from terraform, but may learn something about how AWS and terraform work under the hood.",
          "score": 2,
          "created_utc": "2026-01-18 14:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ba0dr",
          "author": "ycarel",
          "text": "What are you struggling with?\nSince I donâ€™t know what your pain points are it is hard to give helpful tips.\nThe only high level thing I have for you is to find the tools provided by your IDE for cloud formation. It will provide auto complete, etc. \nUse cfn-nag to help catch errors. \nThink of cloud formation as a low level language where you have to be super detailed.\nWhen deploying use change sets to help you know exactly what is changing.\nAs many have recommended consider CDK as it is a higher level construct that compiles into CFN.",
          "score": 2,
          "created_utc": "2026-01-18 16:26:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e9wwg",
          "author": "dafim",
          "text": "I'm going to get asked to leave over this opinion but here goes.\n\nTf sucks. Every new company or even department you go to has wildly different ways to do tf. You can \"learn\" tf, then move to another company and have no idea what TF is going on. There are more escape hatches in tf that it can be baffling how it even got a name for itself as iac. There is some real shit out there. It's like the little tikes learning kit for iac. In some ways it's the new perl vs python argument of \"there's more than one way to do it\" in perl vs \"there's only one way to do it\" in Python. Which I guess means in some ways it's a derivation of the (big|little) endiness argument.\n\nThe nicer thing about cf is that it's a bit more predictable (outside of using custom resources, etc) and as long as you're not naming things you can pick it up and deploy it in a similar account for dev or stage, etc. it's concept of \"state\" is the not defined by some file you need to keep track of, it's state is it and it's resources existence. It's also not as clever or fearureful as tf, which when you manage huge amounts of resources in huge amounts of stacks across huge amounts of accounts across modest amounts of departments can be a very very nice thing because you can still fit the concept in your head. And by cf I mean cdk and cf.",
          "score": 2,
          "created_utc": "2026-01-19 01:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jukjr",
              "author": "DaWizz_NL",
              "text": "I agree with the gist of it. I do think certain specific service implementations suck a bit with CFN, as every service team is responsible for this themselves. The ChangeSets are also lacking and Drift detection is an afterthought, while on TF these are first class citizens.\n\nOther than that, TF can indeed become really messy. It's also much harder to govern from an enterprise perspective. Multi-account is also very painful when you are talking about scalable platforms with ephemeral accounts and stuff, but I think they just solved the multi-region clunkiness at least.",
              "score": 1,
              "created_utc": "2026-01-19 21:29:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a7o8t",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-18 12:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cnrff",
              "author": "TheP1000",
              "text": "Cdktf is dead last I saw.",
              "score": 1,
              "created_utc": "2026-01-18 20:21:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aat83",
          "author": "pipesed",
          "text": "As others have pointed out, cdk is the programmatic way to compose cloud infrastructure. It does synth cfn templates, and it's code so it is as controllable and auditable as any other code. \n\nTerraform is still the most popular one we see, followed by cdk typescript.",
          "score": 1,
          "created_utc": "2026-01-18 13:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cj098",
          "author": "oneplane",
          "text": "\\> due to audit/compliance reasons\n\nI highly doubt that is really going to 'require' CloudFormation.\n\n\\> Any tips?\n\nSadly, no. While they are both IaC tools, they are rather different in how they work and view implementation choices. Besides informing about the tech stack next time you interview at a company, there isn't much you can do as even  TFCDK (TF-to-Cfn) is dead at this point. If you are a software engineer, you can use the Cfn CDK, but unless it's some sort of useless checkbox compliance (well, most are) that might not fly.",
          "score": 1,
          "created_utc": "2026-01-18 19:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f99bs",
          "author": "Dry_Raspberry4514",
          "text": "I don't understand the hate for CF. It helped us to solve the biggest problem in DevOps space -Stateless IaC.\n\nTerraform has two providers for AWS - aws and awscc. awscc uses cloud control api under the hood which in turn leverages most the stuff from CF excluding stack.\n\nIf you want support for new or updated aws resource types on day 1, you will need awscc which has dependency on CF indirectly as explained above. There have been cases in the past (and it will continue in future as well) where new aws features (e.g. regional NAT gateways) were added to aws provider after weeks when it was available in awscc provider on day 1 through AWS CC API. Unlike terraform, we use only CC API and have not seen any issue with it so far.",
          "score": 1,
          "created_utc": "2026-01-19 04:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jt505",
          "author": "DaWizz_NL",
          "text": "For platforms, I always use CFN. It's fine for Lambdas, S3, SNS, SQS, networking components, etc.. It sucks when you have to deploy a shitload of application components and ECS deployments often are painful with CFN if you don't know what you're doing.",
          "score": 1,
          "created_utc": "2026-01-19 21:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7wdv",
          "author": "Kitchen-Location-373",
          "text": "tbh terragrunt is way way way less DRY for me than sceptre for cloudformation. I get it's a bigger community but terragrunt always turns into spaghetti code meanwhile for cloudformation I usually have like a three line yaml config file per environment",
          "score": 1,
          "created_utc": "2026-01-18 12:58:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a86vc",
              "author": "hardvochtig",
              "text": "For some reason this is the first time Iâ€™ve heard of Sceptre despite researching for the past 3 hours. All I keep seeing is CDK. Iâ€™ll read more on this, thanks!",
              "score": 1,
              "created_utc": "2026-01-18 13:00:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ajgiq",
                  "author": "wunderspud7575",
                  "text": "Sceptre is a poor man's Stacker. Stacker really should have been more successful. Sceptre is junk.",
                  "score": 1,
                  "created_utc": "2026-01-18 14:11:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0dnpfx",
              "author": "SnoopJohn",
              "text": "If you do terragrunt well it can end up very clean and make it really simple to ensure all environments are the same as the use the same module with just differences in the env vars",
              "score": 1,
              "created_utc": "2026-01-18 23:22:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qimtwo",
      "title": "The architecture behind my sub-500ms Llama 3.2 on Lambda benchmark (it's mostly about vCPUs)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "author": "NTCTech",
      "created_utc": "2026-01-21 03:26:42",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 0.78,
      "text": "A few days ago I posted a benchmark here showing Llama 3.2 (3B, Int4) running on Lambda with sub-500ms cold starts. The reaction was skeptical, with many folks sharing their own 10s+ spin-up times for similar workloads.\n\nI wanted to share the specific architecture and configuration that made that benchmark possible. It wasn't a private feature; it was about exploiting how Lambda allocates resources.\n\nHere is the TL;DR of the setup:\n\n**1. The 10GB Memory \"Hack\" is for vCPUs, not RAM.** This is the most critical part. A 3GB model doesn't need 10GB of RAM, but in Lambda, you can't get CPU without memory. At 1,769 MB, you only get 1 vCPU.\n\n* To get the **6 vCPUs** needed to saturate thread pools for parallel model deserialization (e.g., with PyTorch/ONNX Runtime), you need to provision **\\~10GB of memory**.\n* The higher memory also comes with more memory bandwidth, which helps immensely.\n* **Counter-intuitively, this can be cheaper.** The function runs so much faster that the total cost per invocation is often lower than a 4GB function that runs for 5x longer.\n\n**2. Defeating the \"Import Tax\" with Container Streaming.** Standard Python imports like `import torch` are slow. I used Lambda's **container image streaming**. By structuring the Dockerfile so the model weights are in the lower layers, Lambda starts streaming the data *before* the runtime fully initializes, effectively paralleling the two biggest bottlenecks.\n\n**The Results (from my lab):**\n\n* **Vanilla Python (S3 pull):** \\~8s cold start. Unusable.\n* **Optimized Python (10GB + Streaming):** \\~480ms cold start. This was the Reddit post.\n* **Rust + ONNX Runtime:** \\~380ms cold start. The fastest, but highest engineering effort.\n\nI wrote up a full deep dive with the Terraform code, a more detailed benchmark breakdown, and a decision matrix on when *not* to use this approach (e.g., high, steady QPS).\n\n[**https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/**](https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/)\n\nI'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks. Is the trade-off worth it for your use cases?",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0uj87e",
          "author": "Nater5000",
          "text": ">I'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks.\n\n\nWe ended up doing this for some image processing that was part of a REST API. Since that much memory/vCPU was overkill for the rest of the app, we ended up having to have two Lambdas with different memory configs that effectively ran the same code, with the smaller REST API Lambda calling the bigger image processing Lambda as needed. It generally worked, but was more of a headache than one would think at first glance.\n\n\nStill, interesting you managed to make this work in Lambda so effectively. I've played around with running small LLMs in Lambda with some success, so adding some of the details you mentioned might make a big difference.",
          "score": 1,
          "created_utc": "2026-01-21 13:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0unqzg",
              "author": "NTCTech",
              "text": "That is a perfect real-world example of this dynamic in action. Itâ€™s validating to hear you ran into the same CPU-bound constraints with image processing.\n\nRegarding the \"headache\" of splitting into two Lambdas (small router vs. big processor): I feel your pain on the operational overhead, but architecturally, **you absolutely made the right call.**\n\nThis is the classic serverless trade-off: operational complexity vs. execution efficiency. If you ran your lightweight REST API handler on that 10GB instance, youâ€™d be burning significant budget on idle vCPUs just waiting for network I/O. By decoupling them, you aligned the resource profiles to the actual work being done. It hurts to manage, but it's the correct design pattern for cost and performance.\n\nDefinitely give the container streaming setup a shot for your LLM experiments. The high vCPU count *really* shines when it can parallelize the layer download and the model deserialization simultaneously. Please let us know if you see similar gains.",
              "score": -1,
              "created_utc": "2026-01-21 13:29:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0uvv03",
                  "author": "Nater5000",
                  "text": "lol please, I really don't need the overly affirmative LLM-speak on reddit too",
                  "score": 3,
                  "created_utc": "2026-01-21 14:13:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0wo75z",
          "author": "OkSadMathematician",
          "text": "the vcpu angle is underrated. most people think of lambda memory as ram when its really a proxy for compute allocation. seen this same pattern work for build processes and data transforms where you overprovision memory just to get more cpu and end up paying less because runtime drops by 5x\n\ncontainer streaming is clever but i wonder about cache hit rates in production. if youre getting consistent traffic the warm pool keeps things fast anyway but for true sporadic workloads this makes sense. curious what your p99 looks like over a week vs just the cold start number",
          "score": 1,
          "created_utc": "2026-01-21 19:07:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x0167",
              "author": "NTCTech",
              "text": "Yeah, the memory CPU realization is the unlock. I use that same over-provisioning trick for batch jobs now; it feels wrong to throw 10GB at a 500MB process, but the runtime speedup usually makes the pricing math work out in your favor.\n\nOn the weekly P99 question that's the real reality check.\n\nIn my testing over a week with \"choppy\" traffic (enough gaps to trigger frequent cold starts, but some sustained bursts), my weekly P99 hovered around 550msâ€“600ms.\n\nItâ€™s actually slightly *higher* than the pure cold start benchmark (480ms) because real-world noise drags it up network jitters, DynamoDB latency on the lookups, etc.\n\nIf your traffic is totally sporadic (like one request every 2 hours), your P99 is basically just going to be that cold start number every time. But in a mixed workload, the warm starts (sub-100ms) drag the average down, while the cold starts define the tail.",
              "score": 1,
              "created_utc": "2026-01-21 20:01:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}