{
  "metadata": {
    "last_updated": "2026-02-18 17:29:58",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 129,
    "file_size_bytes": 144773
  },
  "items": [
    {
      "id": "1r4yqqp",
      "title": "Small PSA regarding ECR and Docker CLI for pushing images",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "author": "magnetik79",
      "created_utc": "2026-02-14 23:05:45",
      "score": 137,
      "num_comments": 13,
      "upvote_ratio": 0.99,
      "text": "Hey all.\n\n  Quick post of something I noticed over the weekend which might trip up someone else.\n\n\nWas pushing a Docker image into ECR using a GitHub Actions deployment workflow, a workflow that's been same-same for a good six months and suddenly two days prior was failing with the following error:\n\n```\nunknown: unexpected status from HEAD request to https://XXXXX.dkr.ecr.ap-southeast-2.amazonaws.com/v2/XXXX/XXXX/manifests/sha256:XXXX: 403 Forbidden\nmake: *** [Makefile:68: burp] Error 1\nError: Process completed with exit code 2.\n```\n\nAfter a little head scratching, I pulled out a few community threads via Google - all from 1 - 2 years ago, but suspiciously had some very recent comments (two days prior) on them with similar issues:\n\n- https://repost.aws/questions/QUYf5U-mW3SqaYKFEvbr9fzw/suddenly-getting-403-on-pushing-my-containers-to-ecs\n- https://stackoverflow.com/questions/79137398/gitlab-cicd-issue-403-forbidden-while-pushing-docker-image-to-aws-ecr\n\nThe IAM role used in my GitHub workflow was (as it should be) fairly restrictive - with the following IAM actions only:\n\n```\necr:BatchCheckLayerAvailability\necr:CompleteLayerUpload\necr:InitiateLayerUpload\necr:PutImage\necr:UploadLayerPart\n```\n\nThese are all honed against a [specific ECR repository ARN](https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonelasticcontainerregistry.html#amazonelasticcontainerregistry-repository).\n\nTurns out, adding `ecr:BatchGetImage` was the fix - this provides the ability for querying image digests from within ECR, which is exactly where the HTTP HEAD error lies.\n\nSo, it seems a recent release of Docker CLI has changed the behavior of `docker push` to now query image digests during an image push and I can only assume this version recently landed on GitHub managed workflow runners.\n\nAnyway... hopefully this helps someone else out of a bind!\n",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5ffwnp",
          "author": "l0g0ut",
          "text": "Thank you for the in depth investigation report. These kind of post and people like you really made Reddit a treasure",
          "score": 25,
          "created_utc": "2026-02-15 00:20:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fji5o",
              "author": "magnetik79",
              "text": "thanks for the kind words.",
              "score": 4,
              "created_utc": "2026-02-15 00:41:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f5bs0",
          "author": "phaubertin",
          "text": "This is really good to know, thanks for posting.",
          "score": 15,
          "created_utc": "2026-02-14 23:14:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f9egh",
              "author": "magnetik79",
              "text": "cheers.",
              "score": 6,
              "created_utc": "2026-02-14 23:39:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5fsc73",
          "author": "MonkeyArmpit",
          "text": "I wasn‚Äôt aware of docker cli change. I always just set it up as the official documentation suggested \n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push-iam.html",
          "score": 6,
          "created_utc": "2026-02-15 01:39:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5lu3kg",
              "author": "magnetik79",
              "text": "Good callout.\n\nSmall issue there, `ecr:GetAuthorizationToken` doesn't have an ARN association, so technically that second policy example may not actually work.",
              "score": 1,
              "created_utc": "2026-02-16 01:07:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ltpri",
          "author": "puttak",
          "text": "You are saved my life.",
          "score": 2,
          "created_utc": "2026-02-16 01:05:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5rileh",
          "author": "FlowPuzzleheaded4995",
          "text": "Thanks for timely post we were having our CI/CD pipelines failing today this helped alot resolving quickly",
          "score": 2,
          "created_utc": "2026-02-16 22:22:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5riqtg",
              "author": "magnetik79",
              "text": "Not a problem - wasn't sure if my post was gonna just be Internet points farming, but seems I've helped a few people out :)",
              "score": 2,
              "created_utc": "2026-02-16 22:23:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5riv1v",
                  "author": "FlowPuzzleheaded4995",
                  "text": "absolutely!",
                  "score": 1,
                  "created_utc": "2026-02-16 22:24:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hs9uk",
          "author": "thebru",
          "text": "Hit something similar. \n\nWe ended up disabling `provenance` in the build. It was pushing an image index along with the two images we built through. \n\nLambda didn't like this.",
          "score": 1,
          "created_utc": "2026-02-15 11:47:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ffyqc",
          "author": "burnbern",
          "text": "Had the same issue and Opus saved me‚Ä¶lol",
          "score": 1,
          "created_utc": "2026-02-15 00:20:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6snkt",
      "title": "DynamoDB single-table pattern: SaaS Multi-Tenant with 10 access patterns, 1 GSI (full breakdown)",
      "subreddit": "aws",
      "url": "https://singletable.dev/blog/pattern-saas-multi-tenant",
      "author": "tejovanthn",
      "created_utc": "2026-02-17 01:38:12",
      "score": 62,
      "num_comments": 34,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r6snkt/dynamodb_singletable_pattern_saas_multitenant/",
      "domain": "singletable.dev",
      "is_self": false,
      "comments": [
        {
          "id": "o5spqqi",
          "author": "cachemonet0x0cf6619",
          "text": "me likes. i don‚Äôt run single table for multi tenant but  if i ever do this will be the reference. \n\ni really liked the site too. only suggestion is that the tables on mobile are tough to read but not a big deal i look forward to more patterns",
          "score": 4,
          "created_utc": "2026-02-17 02:29:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t3xfa",
              "author": "tejovanthn",
              "text": "Thank you :) \n\nWhat patterns would you like to see sooner? üòÅ",
              "score": 1,
              "created_utc": "2026-02-17 03:58:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5t400s",
              "author": "tejovanthn",
              "text": "Also, how do you handle multitenant? Separate tables per tenant?",
              "score": 1,
              "created_utc": "2026-02-17 03:58:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5t5j35",
          "author": "finitepie",
          "text": "If i understand you correctly, you are worried, that using an GSI to create a tenant index, could cause a hot partition? But how often do you actually need to make that request? I would just create a {pk TENANT#<tenant-id>, sk:METADATA} for each tenant, that has a property TYPE=TENANT and use a GSI to query for the type, to get a full tenant list or something similiar. But would be more worried, that your general pk/sk design leads to hot partitioning, since your pk is always the tenant id, and the pk determines the partition. What I do is, to break it down into subcategories. like {pk: TENANT#<tenant-id>#USER, sk: <user-id>} or {pk: TENANT#<tenant-id>#PROJECT, sk: <project-id>}. That would be already two distinct paritition, instead of a single one by just using the pattern {pk: TENANT#<tenant-id>, sk: PROJECT#<project-id>}, where¬†all items for that tenant compete for the same¬†1,000 WCU / 3,000 RCU per-partition throughput limit. That works also well for me, since i usually have dedicated api routes for subcategories. What is your security model to enforce tenant isolation?",
          "score": 5,
          "created_utc": "2026-02-17 04:09:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t8673",
              "author": "tejovanthn",
              "text": "Great points ‚Äî here's my thinking:\n\nTenant index isn't really a worry because it's an admin operation with low volume. I've handled this with the TENANT\\_LIST GSI, but your TYPE=TENANT approach seems functionally similar.\n\nSplitting PKs into subcategories is an interesting approach - you spread writes across multiple partitions with the tradeoff that you lose the ability to read across entity types in a single operation. I think this really depends on the access patterns. For the multi-tenant case, being able to query \\`TENANT#<id>\\` and get metadata + subscription + users in one call is something I reach for a lot.  \nFor most SaaS apps, from what I understand, the hot partition concern is overblown - 1,000 WCU per partition is a lot, and since 2018 DynamoDB's adaptive capacity redistributes throughput to handle hot partitions without you needing to intervene. It won't proactively split them, but it handles the imbalance. If you're at a scale where a single tenant is consistently pushing past that, you probably have bigger architectural decisions to make anyway.\n\nThe tenant isolation point is legit and something I should address in the article. In my production apps I handle this at the application layer (tRPC + OpenAuth ‚Äî every query is scoped to the authenticated tenant). I'm aware of IAM fine-grained access control with \\`dynamodb:LeadingKeys\\` condition keys as the DB-level option, but haven't needed it yet. Have you had success with that approach in practice, or is there something else you'd recommend?",
              "score": 2,
              "created_utc": "2026-02-17 04:27:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tb242",
                  "author": "finitepie",
                  "text": "I didn't actually have tRPC on the radar. Looks very interesting. Have to learn more about it. So basically, I make sure that the relevant data (tenant id, role, etc) is part of the signed access token, like you do. I have predefined IAM roles with role tags, using the LeadingKeys pattern, and at the API level, the actual dynamodb requests are being done while assuming those roles. This will enforce tenant isolation. But I also have more RBAC/ABAC style of permissions enforced at the middleware level. For all that I build an universal authentication and authorisation system I deploy once (or as often as I want to get more isolation for other reasons)  and can reuse for any other app. It's just plug and play at this point. But was a lot of work to get there. But at the moment I'm still doing REST APIs. Which works nicely, because I'm running Hono with OpenAPI extension, where I only have to define a zod schema as single source of truth, and can easily generate the correctly typed client code via the OpenAPI specs, it automatically generates from that. But the system would work with GraphQL too. ",
                  "score": 1,
                  "created_utc": "2026-02-17 04:47:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5tou1y",
          "author": "mamaBiskothu",
          "text": "Why not have separate tables for each tenant?",
          "score": 3,
          "created_utc": "2026-02-17 06:36:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tspj0",
              "author": "tejovanthn",
              "text": "It's a valid approach and some teams do this ‚Äî especially when you need hard isolation for compliance (HIPAA, SOC2) or you want to offer dedicated-tenancy as a premium tier.\n\nThe tradeoffs though:\n\n\\- Operational overhead scales linearly - Every new tenant means a new table, new GSIs, new CloudWatch alarms, new backup configs. At 100 tenants that's manageable. At 10,000 it's a nightmare.  \n\\- Cross-tenant queries become expensive - \"List all tenants\" or \"aggregate usage across tenants\" requires scanning every table.  \n\\- AWS account limits - There's a default limit of 2,500 tables per account per region. You can request increases, but it's a signal you're fighting the grain.  \n\\- Cost - Each table with on-demand pricing has its own minimum throughput allocation. One shared table is cheaper than N separate ones.\n\nThe single-table approach gives you logical isolation (tenant-scoped partition keys) with the operational simplicity of one table. If you need stronger isolation, the IAM LeadingKeys approach another commenter mentioned gives you DB-level enforcement without separate tables.\n\nThat said, table-per-tenant is the right call for some use cases ‚Äî particularly when tenants have wildly different scale or strict data residency requirements. It's not wrong, just different tradeoffs.",
              "score": 1,
              "created_utc": "2026-02-17 07:10:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tuox5",
                  "author": "mamaBiskothu",
                  "text": "Fair points. I get it. This was a fascinating post, thanks a million.",
                  "score": 2,
                  "created_utc": "2026-02-17 07:28:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5vwxjn",
              "author": "pablo__c",
              "text": "I'd second this. Have multiple tables, one for each tenant, but then do a single table approach for the rest of the stuff. Btw, ignore the \"just use a relational db\" comments. It's ok to try new/different things, and DynamoDB is great for new simple projects with its scale to zero pay as you go model.",
              "score": 1,
              "created_utc": "2026-02-17 16:09:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u8q35",
          "author": "SikhGamer",
          "text": "This is a god awful idea if you have a complicated setup. If your setup is flat and easy to understand _forever_ then _maybe_ this would be a good idea.\n\nOtherwise use an RDBMS _please_.",
          "score": 10,
          "created_utc": "2026-02-17 09:42:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uftvd",
              "author": "tejovanthn",
              "text": "True. DynamoDB isn't the right choice for every workload, and forcing single-table design onto a domain with unpredictable or constantly evolving access patterns is going to hurt. No argument there.\n\nBut when the access patterns are well-understood upfront - which they are for a lot of SaaS CRUD apps - the operational simplicity and scaling characteristics of DynamoDB are hard to beat. The goal of this pattern library is to make the \"well-understood\" part easier to get to. :)",
              "score": 3,
              "created_utc": "2026-02-17 10:47:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5t356u",
          "author": "MmmmmmJava",
          "text": "Edit: you‚Äôve fixed it!\n\n~~Your article‚Äôs phrasing seems to indicate you have 3 GSIs, vs 3 access patterns in 1 GSI.~~",
          "score": 2,
          "created_utc": "2026-02-17 03:53:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t4w4w",
              "author": "tejovanthn",
              "text": "Thanks for the feedback :) could you clarify where I can word it better - the blog article, or the post here?",
              "score": 1,
              "created_utc": "2026-02-17 04:04:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5t657t",
                  "author": "MmmmmmJava",
                  "text": "No problem. I think your post could be rephrased to clarify that you walk through two variations. first multiple GSIs and then an overloaded one.\n\nYour article may also benefit from having an index (no pun intended) at the beginning to show the sections and what‚Äôs coming later in the article.",
                  "score": 1,
                  "created_utc": "2026-02-17 04:13:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5uj1om",
          "author": "teo-tsirpanis",
          "text": "That was the best single-table explainer I've ever seen. üëèüèª üëèüèª",
          "score": 2,
          "created_utc": "2026-02-17 11:15:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5um2mk",
              "author": "tejovanthn",
              "text": "Thanks, appreciate it! üòÑ",
              "score": 1,
              "created_utc": "2026-02-17 11:41:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5td0od",
          "author": "gottcha-",
          "text": "How do you handle schema changes?",
          "score": 1,
          "created_utc": "2026-02-17 05:01:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tfy7a",
              "author": "tejovanthn",
              "text": "Good question - this is one of the genuine pain points with DynamoDB, and one that kept me sticking to rdbms for a very long time. \n\nFor attribute-level changes (adding a new field, changing a default), it's straightforward - DynamoDB is schemaless per item, so new items get the new attribute and old items don't. I handle backfills lazily at read time or with a one-off migration script depending on whether the field is required.\n\nFor key structure changes (modifying a PK/SK pattern or GSI), it's more involved. You can't alter keys on existing items - you have to write new items with the new key pattern and clean up the old ones. ElectroDB's versioning helps here: you define a new entity version and can read both old and new formats during the transition.\n\nFor GSI changes, adding a new GSI is non-disruptive (DynamoDB backfills it from the existing table). Changing or removing one requires a migration plan.\n\nHonestly, this is probably the strongest argument against overly complex single-table designs - the more entities and overloaded indexes you have, the harder migrations get. It's why I'd rather start with clean, well-separated key prefixes and only overload GSIs when the access patterns are stable.\n\nSchema migration tooling is a big gap in the DynamoDB ecosystem right now. It's something I'm thinking about for singletable.dev down the road.",
              "score": -1,
              "created_utc": "2026-02-17 05:23:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ti5x8",
          "author": "kingslayerer",
          "text": "If you are on rust maybe you will find my lib useful \n\nhttps://github.com/Salman-Sali/dynorow",
          "score": 1,
          "created_utc": "2026-02-17 05:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tr86z",
          "author": "Patient-Swordfish906",
          "text": "Good write up, been using single table design in production apps for a few years now.\n\nMy only nitpick with your article is that access pattern #5 is not really covered by your design. You claim you can get a project by ID by using get item on the full SK, but you have the date as a prefix, so you can‚Äôt query only by project ID.",
          "score": 1,
          "created_utc": "2026-02-17 06:57:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5tse2s",
          "author": "Soccham",
          "text": "People at my work have been doing this and it‚Äôs a fucking disaster. \n\nJust use relational databases.",
          "score": 1,
          "created_utc": "2026-02-17 07:07:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vyl5y",
          "author": "TechDebtSommelier",
          "text": "Scan is a \"we'll fix it later\" that becomes a 3am incident. Write-shard the GSI key (TENANT#<0-N>), scatter-gather on read, done. Yes it's annoying. No there's no cleaner way. Welcome to DynamoDB.",
          "score": 1,
          "created_utc": "2026-02-17 16:17:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yke8x",
          "author": "ShakataGaNai",
          "text": "What is this, a [schema diagram for ants](https://imgur.com/a/gPKV00U)? But seriously, I can't read it and can't make it any larger.",
          "score": 1,
          "created_utc": "2026-02-17 23:54:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5t8lgm",
          "author": "the_corporate_slave",
          "text": "Single table pattern is over complicated trash. Unless you are doing an app rewrite where you know exactly what schema you need, this is a mistake",
          "score": -2,
          "created_utc": "2026-02-17 04:30:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tb0tu",
              "author": "tejovanthn",
              "text": "There's a real point here - single-table design has a steep learning curve and if you get your access patterns wrong upfront, refactoring is painful.\n\nBut \"you need to know exactly what schema you need\" is true of DynamoDB in general, not just single-table. Multi-table DynamoDB still requires you to define access patterns before you design. It's not a relational database where you can normalize first and figure out queries later.\n\nWhere I'd push back: single-table isn't all-or-nothing. The modern approach is pragmatic - group entities that are queried together, use a few clean GSIs, don't overload everything into one index just because you can. That's what this pattern does.\n\nThat said, if your app's access patterns are genuinely unknown and/or evolving fast, DynamoDB itself might not be the right choice - and that's a totally valid position.",
              "score": 1,
              "created_utc": "2026-02-17 04:47:30",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5tc35e",
                  "author": "finitepie",
                  "text": "I actually prefer the single table design. Everything boils down to how your data model is defined. But as you said, the problem is often not the single table design, but that you might need access patterns, that you are not aware of, yet. But a profound schema migration is always a pain in the a\\*. :D",
                  "score": 5,
                  "created_utc": "2026-02-17 04:55:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r37abo",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "author": "magnetik79",
      "created_utc": "2026-02-12 22:16:45",
      "score": 35,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1r37abo/aws_backup_adds_crossregion_database_snapshot/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5282yb",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52l92m",
          "author": "Mutjny",
          "text": "\"Logically\" air-gapped throw some big air quotes around that one.",
          "score": 13,
          "created_utc": "2026-02-12 23:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52jq4v",
          "author": "The_Tree_Branch",
          "text": "> Now do cross-region and cross-account in a single backup task.\n\nUnless I'm misunderstanding you, this already exists as of October 2025: https://aws.amazon.com/about-aws/whats-new/2025/10/aws-backup-single-action-database-snapshot-copy-regions/",
          "score": 8,
          "created_utc": "2026-02-12 23:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52lkv4",
              "author": "magnetik79",
              "text": "ü§¶‚Äç‚ôÇÔ∏è oh geez, I totally missed this announcement. Thanks for the heads up - you're indeed correct!\n\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/backup-feature-availability.html#features-by-resource\n\n> Amazon RDS, Aurora, DocumentDB, and Neptune now support cross-Region and cross-account snapshot copying in a single action. \n\nNice! Just need to add KMS keys to existing clusters and.... _recreate them_. Still this makes the process much nicer.",
              "score": 1,
              "created_utc": "2026-02-12 23:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o529jr4",
          "author": "freeriderblack",
          "text": "... and RDS still behind. I have never understood why they don't keep consistency between Aurora and RDS when it comes to AWS Backups features.",
          "score": 6,
          "created_utc": "2026-02-12 22:24:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52mmu0",
              "author": "naggyman",
              "text": "Aurora and RDS have very different tech stacks under the hood - so I‚Äôm guessing it‚Äôd be like developing two entirely separate features. \n\nSo the question then becomes - do you have to hold off releasing support for one because you haven‚Äôt completed development on support for the other.",
              "score": 9,
              "created_utc": "2026-02-12 23:34:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o530b5p",
          "author": "kopi-luwak123",
          "text": "It still does not work with AMK encrypted stuff, right ?",
          "score": 1,
          "created_utc": "2026-02-13 00:53:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o533ji1",
              "author": "magnetik79",
              "text": "No I would assume not - anytime you need to move a backup across regions or accounts you need to be using KMS keys - as Amazon managed keys are unique to each AWS account and region and can't used beyond those bounds.",
              "score": 2,
              "created_utc": "2026-02-13 01:13:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ctrs",
                  "author": "kopi-luwak123",
                  "text": "Yeah, so the intermediate vault is still required.",
                  "score": 1,
                  "created_utc": "2026-02-13 02:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56v79q",
          "author": "gex80",
          "text": "What the hell does logically air-gapped mean? The only definition I know of means no network access",
          "score": 1,
          "created_utc": "2026-02-13 16:43:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59bnvp",
          "author": "ruibranco",
          "text": "the term \"logically air-gapped\" is doing more heavy lifting than any vpc peering config i've ever written",
          "score": 1,
          "created_utc": "2026-02-14 00:13:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5282x0",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -6,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6fzf7",
      "title": "Amazon EC2 supports nested virtualization on virtual Amazon EC2 instances",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r6fzf7/amazon_ec2_supports_nested_virtualization_on/",
      "author": "KayeYess",
      "created_utc": "2026-02-16 17:30:58",
      "score": 35,
      "num_comments": 15,
      "upvote_ratio": 0.97,
      "text": "[https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-nested-virtualization-on-virtual/](https://aws.amazon.com/about-aws/whats-new/2026/02/amazon-ec2-nested-virtualization-on-virtual/)\n\n\"Posted on:¬†Feb 16, 2026: Starting today, customers can create nested environments within virtualized Amazon EC2 instances. Previously, customers could only create and manage virtual machines inside bare metal EC2 instances. With this launch, customers can create nested virtual machines by running KVM or Hyper-V on virtual EC2 instances. Customers can leverage this capability for use cases such as running emulators for mobile applications, simulating in-vehicle hardware for automobiles, and running Windows Subsystem for Linux on Windows workstations.\n\nThis capability is available in all commercial regions on C8i, M8i, and R8i instances. To learn more about enabling hardware virtualization extensions in your environment, see the Amazon EC2 nested virtualization documentation.\"\n\nLink to documentation: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/amazon-ec2-nested-virtualization.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/amazon-ec2-nested-virtualization.html)",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r6fzf7/amazon_ec2_supports_nested_virtualization_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5q15jf",
          "author": "im-a-smith",
          "text": "I can then run Docker inside and have images running inside VMs inside VMs\n\nSweet.¬†",
          "score": 12,
          "created_utc": "2026-02-16 18:05:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qg9wt",
              "author": "visicalc_is_best",
              "text": "This is a great idea, particularly because RAM is so cheap right now",
              "score": 9,
              "created_utc": "2026-02-16 19:14:51",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5rx567",
                  "author": "phaubertin",
                  "text": "It is when it's not your RAM. üòÄ",
                  "score": 3,
                  "created_utc": "2026-02-16 23:41:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5q1fao",
              "author": "samrwalker",
              "text": "Inception",
              "score": 2,
              "created_utc": "2026-02-16 18:06:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5yq7pr",
              "author": "dudeman209",
              "text": "This was Alan Turing‚Äôs vision!",
              "score": 1,
              "created_utc": "2026-02-18 00:26:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5q42ia",
          "author": "mezbot",
          "text": "Lol, the comments are exactly what I wanted to say‚Ä¶ needs more layers!",
          "score": 4,
          "created_utc": "2026-02-16 18:18:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5q4xli",
              "author": "pixeladdie",
              "text": "Yo dawg! I heard you like abstractions‚Ä¶.",
              "score": 4,
              "created_utc": "2026-02-16 18:22:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5qcubx",
                  "author": "HiCookieJack",
                  "text": "So we've put podman in your docker, so you can download layers to download layers of layers¬†",
                  "score": 1,
                  "created_utc": "2026-02-16 18:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5q5dsq",
          "author": "UnluckyTiger5675",
          "text": "I hope this soon gets propagated to AWS workspaces, so my work mandated Windows 11 workspace can run WSL two instead of just WSL one",
          "score": 8,
          "created_utc": "2026-02-16 18:24:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qax17",
              "author": "bobkiwi",
              "text": "I am in the same boat- WSL2 support would help immensely to avoid the \"but Windows 365 VDIs can do it!\"\n\nIf it's in the m8 series, I wouldn't be surprised if it comes to WorkSpaces by Q3... but which year!",
              "score": 1,
              "created_utc": "2026-02-16 18:49:57",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5ylu6j",
              "author": "SammichAffectionate",
              "text": "We are thinking of migrating away from Workspaces but it keeps getting pushed off. Nested virtualization is just one of the reasons.",
              "score": 1,
              "created_utc": "2026-02-18 00:01:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5q1i7c",
          "author": "Alternative-Expert-7",
          "text": "Lets go deeper.",
          "score": 5,
          "created_utc": "2026-02-16 18:07:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qs9j2",
          "author": "MassPatriot",
          "text": "VMception",
          "score": 3,
          "created_utc": "2026-02-16 20:13:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yy2mt",
          "author": "VIDGuide",
          "text": "Yo dawg.. we heard you liked vms, so we put vms in your vms, so you can vm while you vm!",
          "score": 1,
          "created_utc": "2026-02-18 01:09:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60nbpe",
          "author": "ComplianceAuditor",
          "text": "This fucks.",
          "score": 1,
          "created_utc": "2026-02-18 07:59:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r76u7k",
      "title": "How to build a distributed queue in a single JSON file on object storage (S3)",
      "subreddit": "aws",
      "url": "https://turbopuffer.com/blog/object-storage-queue",
      "author": "itty-bitty-birdy-tb",
      "created_utc": "2026-02-17 14:03:33",
      "score": 26,
      "num_comments": 8,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r76u7k/how_to_build_a_distributed_queue_in_a_single_json/",
      "domain": "turbopuffer.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5vx5ax",
          "author": "the8bit",
          "text": "Starting this 'seems like this won't really scale'\n\nEnding it 'ah you are basically reimplementing Kafka. Bold choice '",
          "score": 14,
          "created_utc": "2026-02-17 16:10:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yk71d",
              "author": "itty-bitty-birdy-tb",
              "text": "Ha. Well I guess we'll¬†take¬†\"Kafka but¬†it's one¬†JSON¬†file\" as¬†a¬†compliment",
              "score": 2,
              "created_utc": "2026-02-17 23:52:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yxfp8",
          "author": "ruibranco",
          "text": "The Iceberg comparison is actually really apt ‚Äî both are fundamentally betting that object storage conditional writes are reliable enough to build coordination primitives on top of. The fact that you can get away with a single JSON file instead of a proper consensus protocol says a lot about how far S3's consistency model has come since they went strongly consistent in 2020.",
          "score": 4,
          "created_utc": "2026-02-18 01:06:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5vt3gm",
          "author": "AdCharacter3666",
          "text": "This is kinda like Iceberg but for queues.",
          "score": 3,
          "created_utc": "2026-02-17 15:50:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yk7cz",
              "author": "itty-bitty-birdy-tb",
              "text": "yeah decent comparison actually, same idea of using object storage as the source of truth with atomic metadata updates. Iceberg uses manifest files, we use CAS. the nice thing about both patterns is that object storage handles durability and availability so the compute layer can stay stateless.",
              "score": 1,
              "created_utc": "2026-02-17 23:53:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yaex3",
          "author": "Hackinet",
          "text": "Wait, why use a single file? Why not just do a group commit to a new file for a worker to pick up? \n\nIt still doesn't solve the issue with two workers picking up duplicate work in your article but I feel it would simplify the architecture and the write race conditions that you might run into.",
          "score": 2,
          "created_utc": "2026-02-17 22:59:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yjidl",
              "author": "itty-bitty-birdy-tb",
              "text": "the single file with CAS is what gives us strong consistency for free. the full queue state is always in one place, and CAS guarantees that any mutation¬†(push, claim, heartbeat) is¬†atomic with¬†respect to the current¬†state. if¬†you write new¬†files instead, you need¬†a¬†separate¬†coordination¬†mechanism to establish¬†ordering, track¬†which¬†files have been consumed, and¬†garbage¬†collect old¬†ones. you're¬†basically rebuilding the consistency¬†guarantees that¬†CAS on¬†a single file gives¬†you out¬†of¬†the box.",
              "score": 1,
              "created_utc": "2026-02-17 23:49:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2rc0s",
      "title": "AWS (AI) Support - unassigned case for 24h with Business Support+",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "author": "alex_aws_solutions",
      "created_utc": "2026-02-12 11:47:23",
      "score": 21,
      "num_comments": 15,
      "upvote_ratio": 0.79,
      "text": "I thought the Business Support+ Plan is something different.... but not. Very unsatisfied!",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4zbjg4",
          "author": "kei_ichi",
          "text": "Isn‚Äôt ‚Äúbusiness support+ ‚Äú plan is just ‚Äúdeveloper support‚Äù plan? But they renamed it to look like an ‚Äúupgrade‚Äù but in reality that is just a fancy name and you will ‚Äúmostly‚Äù get answers from AI slop because they fired almost all of their support staff and still continue to do do that! To be honest, even enterprise support plan account are getting answers from bot instead of human so with your 29$ per month support plan‚Ä¶good luck to get your support case handled by human!",
          "score": 19,
          "created_utc": "2026-02-12 13:54:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5271t5",
              "author": "PsychologicalAd6389",
              "text": "You do realize that if you click the option to get a human you‚Äôll get a human",
              "score": 3,
              "created_utc": "2026-02-12 22:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o529ixc",
                  "author": "kei_ichi",
                  "text": "Ya, but in ‚Äútheory‚Äù only. Again, good luck to get support from human with that support plan. You ‚Äúwill‚Äù but with the cost of ‚Äúlong long‚Äù waiting queue because another people demand the same (because AI slop just respond with nonsense answers) but how many support staff ‚Äúleft‚Äù in that company????",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yu21k",
          "author": "Burekitas",
          "text": "Click reply and pick the Chat option, which would expedite the case.",
          "score": 20,
          "created_utc": "2026-02-12 12:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z8b01",
          "author": "AntDracula",
          "text": "Oops sorry about that. Better layoff another 10,000!",
          "score": 21,
          "created_utc": "2026-02-12 13:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ywsdw",
          "author": "ManBearHybrid",
          "text": "They fired all their support staff in favour of AI and customer service is suffering because of it. I wonder if they consider this a bad thing or if it's just worth it to save from paying all those salaries. ",
          "score": 7,
          "created_utc": "2026-02-12 12:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yzagw",
              "author": "CircularCircumstance",
              "text": "People complaining on Reddit comes at no added costs for AWS.  They'll only respond if it begins to affect the bottom line, IE enterprise customers taking their business elsewwhere.\n\nUnfortunately for so many of us, we are so deeply locked into AWS that the costs for us to move to another provider is massive.",
              "score": 7,
              "created_utc": "2026-02-12 12:40:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zgt3y",
                  "author": "CubsFan1060",
                  "text": "This is a great argument for shying away from provider specific tools.  If you build heavily on DynamoDB and Lambda, you're going to struggle to ever be able to actually think about moving.\n\nEveryone likes to talk about the complexity of Kubernetes (which is fair), but if your stack is EKS + postgres + S3, it still isn't _easy_ to move, but it's much much more possible to move.",
                  "score": 2,
                  "created_utc": "2026-02-12 14:22:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4z8l2j",
                  "author": "AntDracula",
                  "text": "Enshittification hits AWS",
                  "score": 3,
                  "created_utc": "2026-02-12 13:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yzb3f",
              "author": "Sirwired",
              "text": "No, they did *not* fire \"all\" the support staff.  Silly exaggeration like this does nobody any favors.",
              "score": -9,
              "created_utc": "2026-02-12 12:40:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8m9r",
                  "author": "AntDracula",
                  "text": "Hi Andy",
                  "score": 0,
                  "created_utc": "2026-02-12 13:38:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o501vfx",
          "author": "mediocretes",
          "text": "Yeah, this is par for the course. There‚Äôs no point to paying for Amazon support. I‚Äôve never once had them meet SLAs when anything significant was happening.",
          "score": 3,
          "created_utc": "2026-02-12 16:07:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yvxwj",
          "author": "AWSSupport",
          "text": "Hello, \n\nThanks for providing your case ID. \n\nI can confirm that your case is in the correct queue. I've reached out internally to have this looked into. \n\nBe sure to keep an eye open for further correspondence from our Support team.\n\n\\- Craig M.",
          "score": 3,
          "created_utc": "2026-02-12 12:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ywqvv",
              "author": "alex_aws_solutions",
              "text": "Thank you Craig.",
              "score": 1,
              "created_utc": "2026-02-12 12:22:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ythgl",
          "author": "AWSSupport",
          "text": "Hello,\n\nI'm sorry for the frustration this has caused. Please DM us your case ID, so we can take a closer look. \n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-12 11:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4k17f",
      "title": "How are you managing Bedrock?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "author": "jmreicha",
      "created_utc": "2026-02-14 12:59:48",
      "score": 19,
      "num_comments": 35,
      "upvote_ratio": 0.91,
      "text": "Looking for perspective on how teams are managing their Bedrock architectures and trying to get a handle on some things. Some questions I have:\n\n\\- How are you managing cost and cost attribution?\n\n\\- Are teams centralizing Bedrock infrastructure and model management? Or deploying models in each account?\n\n\\- How are folks managing security? What kinds of governance and guardrails are being put in place?\n\n\\- What about AgentCore? How is that being managed?\n\n\\- What is everyone using to manage changes? Terraform? Something else? Terraform support seems to be lacking.",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5c7m6h",
          "author": "2BucChuck",
          "text": "Built an API on the front of it in ECS and Lambda  to limit each user based on tokens which can be increased as needed.   In that an Admin can manage users and bots leveraging bedrock and while at it just made it an AWS MCP.  didn‚Äôt want to give bots any direct access to AWS IAM roles so tokens and JWT gateway seemed better to tamp down runaway usage since its early days until we could see how much costs and usage were coming from different places and users and tools",
          "score": 26,
          "created_utc": "2026-02-14 13:49:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dmhnw",
              "author": "aboothe726",
              "text": "I really like that approach. I've done something similar to give internal users access to vendor APIs while controlling for and tracking usage and without having to share the actual credentials for the vendor APIs. Worked really well.",
              "score": 4,
              "created_utc": "2026-02-14 18:18:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cqkr2",
              "author": "2BucChuck",
              "text": "DM me I can share the setup we have but would call is an Alpha release",
              "score": 2,
              "created_utc": "2026-02-14 15:37:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eb4oy",
              "author": "weirdbrags",
              "text": "did you look at litellm?",
              "score": 2,
              "created_utc": "2026-02-14 20:25:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ec3yu",
                  "author": "2BucChuck",
                  "text": "Interesting but no , we have to maintain lots of PII and SOC2 and this whole AI area has too many moving parts for us at the moment.  It‚Äôs the same idea though I see",
                  "score": 3,
                  "created_utc": "2026-02-14 20:31:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5dwsy7",
          "author": "CoopertheFluffy",
          "text": "Everyone always asks \"how are you managing bedrock?\" but nobody ever asks \"how are you managing, bedrock?\"",
          "score": 10,
          "created_utc": "2026-02-14 19:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1h2w",
          "author": "FarkCookies",
          "text": "I could not figure out how to do cost attribution except for having acc per team/env. ",
          "score": 9,
          "created_utc": "2026-02-14 13:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cre3l",
              "author": "pixeladdie",
              "text": "I haven‚Äôt had to test this yet but does [application inference profiles](https://aws.amazon.com/blogs/machine-learning/manage-multi-tenant-amazon-bedrock-costs-using-application-inference-profiles/) do what you need?",
              "score": 7,
              "created_utc": "2026-02-14 15:41:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5czrfp",
                  "author": "iwearhaines",
                  "text": "This is what we use. SCP to deny any model invocation that didn't go through an AIP, with each AIP tagged to the owning team",
                  "score": 4,
                  "created_utc": "2026-02-14 16:24:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5enple",
                  "author": "FarkCookies",
                  "text": "Wow thanks had no idea",
                  "score": 3,
                  "created_utc": "2026-02-14 21:34:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cd9ky",
          "author": "weirdbrags",
          "text": "question of the year.",
          "score": 7,
          "created_utc": "2026-02-14 14:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cos8z",
          "author": "Lba5s",
          "text": "you don‚Äôt",
          "score": 6,
          "created_utc": "2026-02-14 15:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ep3da",
          "author": "jojolejobar",
          "text": "We use litellm \nEach user has a key with a budget\nWorks with Claude, open code, openwebui..",
          "score": 4,
          "created_utc": "2026-02-14 21:41:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1oqv",
          "author": "AWSSupport",
          "text": "Hi there. I've forwarded your feedback to our Bedrock team for further review.\n\n\\- Roman Z.",
          "score": 5,
          "created_utc": "2026-02-14 13:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5crb89",
              "author": "2BucChuck",
              "text": "Ha you might regret posting here but also please fix the pricing on OpenSearch - it‚Äôs outrageous.  We setup one knowledge agent and bill went through the roof.  It‚Äôs not even clear how to undo it since it gets assigned in background.  That said appreciate how fast this was scaled up and the model ecosystem !",
              "score": 6,
              "created_utc": "2026-02-14 15:41:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ficlk",
                  "author": "weirdbrags",
                  "text": "s3 vectors?",
                  "score": 1,
                  "created_utc": "2026-02-15 00:34:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cegjm",
              "author": "japanthrowaway",
              "text": "Hey while you're at it can you tell the team to maintain their bedrock access gateway a bit better? Bedrock doesn't have a native openai api endpoint so we have to use BAG which doesn't even support all the native models on bedrock itself. Insane how AWS preaches being AI forward but they ignore this piece of critical infra.",
              "score": 3,
              "created_utc": "2026-02-14 14:30:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cqpon",
                  "author": "Maxious",
                  "text": "https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-mantle.html\n\n\n¬†is this not an openai API endpoint¬†",
                  "score": 3,
                  "created_utc": "2026-02-14 15:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cy8le",
          "author": "Nearby-Tomato9925",
          "text": "Individual Inference profiles with tags and then those tags enabled for AWS Budgets. Is it amazing? No. But at least it is something.",
          "score": 1,
          "created_utc": "2026-02-14 16:16:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5faimo",
              "author": "jmreicha",
              "text": "How many profiles are you managing? I can get behind doing that part with Terraform if it doesn't become a huge number.",
              "score": 1,
              "created_utc": "2026-02-14 23:46:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d7hs1",
          "author": "VladyPoopin",
          "text": "Application inference profiles for cost attribution to a specific pipeline. Getting more granular can be problematic, but it works.",
          "score": 1,
          "created_utc": "2026-02-14 17:02:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d927u",
          "author": "egoslicer",
          "text": "We use okta, so I built a cost attribution tool by login and token usage. From there, created a leaderboard so we can track usage.",
          "score": 1,
          "created_utc": "2026-02-14 17:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5el0dp",
          "author": "ShakataGaNai",
          "text": "Currently experimenting with [LiteLLM Proxy.](https://docs.litellm.ai/docs/simple_proxy) Conceptually it's perfect for the use case. As it has separate auth, admin API's, cost attribution, etc. However, it doesn't work for things like Claude Code (TBD on OpenCode, haven't tried it yet). \n\nBut, I'd really love something first party from Amazon. Having the ability to track token usage per API key or IAM role would be vastly superior than proxying every request with another tool.",
          "score": 1,
          "created_utc": "2026-02-14 21:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eqiym",
              "author": "Nick4753",
              "text": "LiteLLM is called out specifically in Claude Code's documentation https://code.claude.com/docs/en/llm-gateway#litellm-configuration\n\nLiteLLM is really underselling itself. You can use it as a gateway for just about any purpose, beyond just engineer access for coding.",
              "score": 2,
              "created_utc": "2026-02-14 21:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fzusw",
                  "author": "ShakataGaNai",
                  "text": "It is called out and thats why I tried it, but that doesn't mean it works well. Anthropic is rolling out features that break when running against things like LiteLLM. So it might work for a while, then might break at random. I was having issues with a new beta flag, which you can \"turn off\" in CC....except [it doesn't actually obey the setting](https://github.com/anthropics/claude-code/issues/21676).\n\nAnd the passthrough endpoints on LiteLLM are... meh. There are a bunch of limitations like they don't have good of an idea of the tokens used. They also can't stop usage for a specific key that's over allocation. Also it was, for me, logging hundreds of lines of ... errors(?)... when claude code was working against LiteLLM (and it was in fact working through LiteLLM to Bedrock).\n\nSo yes, it's possible. But if I were someone wanting to use something to control usage for Claude Code for an entire company... I wouldn't rely on that setup. Which is a shame because thats exactly who I am and what I wanted to do.\n\nIf someone has Bedrock/LiteLLM/ClaudeCode setup and working entirely correctly, without kneecapping yourself and losing out on major features, please tell me your config.",
                  "score": 3,
                  "created_utc": "2026-02-15 02:30:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5fdm0r",
              "author": "jmreicha",
              "text": "How does that approach work with inference profiles? Have you found much of the AgentCore tools to have similar functionality to litellm?",
              "score": 1,
              "created_utc": "2026-02-15 00:05:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f3cm1",
          "author": "donkanator",
          "text": "AWS best practices say to segregate workloads into their own accounts. From there, you don't have to worry about teams stepping on each other's toes if they maintain separate applications. If they are fine being under the same account then whoever fits the bill should be fine to pay for them all.\n\nAt the end of the day, any AI application or system is going to have a normal system architecture first and then some API calls. Chances are, containers or storage or support engineers are going to be much more expensive than a few AI calls. \n\nWe use scp and guardrails to ensure that people use only the models we are comfortable with and invokemodel permissions contain a guardrail condition. \n\nAgentcore is still in the pipeline but I'm struggling with the concept of customers being able to call public cloud apis directly (with a role or IDP token). Normally we expect to have some kind of ingress like application load balancer or cloudfront, but agent core pretty much welcomes anyone to call your API which can be a problem with legal and trade. (Honestly, why do we have to go through this all over again)",
          "score": 1,
          "created_utc": "2026-02-14 23:02:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6kyza",
      "title": "Nested virtualization now available on EC2 instances",
      "subreddit": "aws",
      "url": "https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e",
      "author": "ckilborn",
      "created_utc": "2026-02-16 20:29:52",
      "score": 18,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "compute",
      "permalink": "https://reddit.com/r/aws/comments/1r6kyza/nested_virtualization_now_available_on_ec2/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5qvolp",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'compute'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+compute).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-16 20:29:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6fnfx",
      "title": "m8azn single-thread performance tops EC2 benchmarks",
      "subreddit": "aws",
      "url": "https://go.runs-on.com/instances/ec2/m8azn",
      "author": "crohr",
      "created_utc": "2026-02-16 17:19:08",
      "score": 15,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ci/cd",
      "permalink": "https://reddit.com/r/aws/comments/1r6fnfx/m8azn_singlethread_performance_tops_ec2_benchmarks/",
      "domain": "go.runs-on.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5quolc",
          "author": "SkywardSyntax",
          "text": "Finally something that can run my homelab's nginx-proxy-manager docker container and tailscale exit node at the same time",
          "score": 6,
          "created_utc": "2026-02-16 20:24:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5spe0z",
          "author": "Big-Razzmatazz-2899",
          "text": "‚ÄúIt‚Äôs the A Z N, better recognize!‚Äù",
          "score": 1,
          "created_utc": "2026-02-17 02:27:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4fjvp",
      "title": "GuardDuty found outgoing SSH Bruteforce attack - what now?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "author": "Xtrearer",
      "created_utc": "2026-02-14 08:36:19",
      "score": 13,
      "num_comments": 9,
      "upvote_ratio": 0.82,
      "text": "GuardDuty identified outbound traffic that matches SSH brute force attack patterns. \n\nThe traffic originated from one of our Windows Server 2022 instances. The instance is in a private subnet (not visible to the public internet), so no public IP, and has a SG that only allows inbound traffic on ICMP(ping) and RDP,  both of which is restricted to our AWS VPN Client SG. All outbound traffic is currently allowed.\n\nThe outgoing \"attack\" originated from random local ports - 50242 ans 60664 - and targeted what looks like Amazon Public IPs: 15.197.199.235(Washington) and 99.83.130.128(Seattle)  on remote port 22 (SSH)\n\nThe machine was switched off by support, pending investigation. Ive checked the events, services and netstat, but could not find any trace of it. \n\nIve tried Googling this behavior, without any luck. Any ideas?\n\nAt this point I will be rebuilding a new server just to be safe.\n\n[Solved]",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5bh0gs",
          "author": "Xtrearer",
          "text": "Source has been found. Misconfigured internal sftp interface. Occams razor - if no body can get in, it must be your own fault. \n\nThe AWS IPs were linked to a Global Accelerator that fronts our File Transfer Server. This exists in another account which made it difficult to track.\n\nWe were almoat DDOS'd a while back so immediatly assumed bad actors... so yay I guess.",
          "score": 39,
          "created_utc": "2026-02-14 10:11:27",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5c1371",
              "author": "SheriffRoscoe",
              "text": "Thank you, [DenverCoder9](https://xkcd.com/979/).",
              "score": 11,
              "created_utc": "2026-02-14 13:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ck44k",
                  "author": "creamersrealm",
                  "text": "Lol thank you for the reference.",
                  "score": 6,
                  "created_utc": "2026-02-14 15:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5baitc",
          "author": "morimando",
          "text": "Isolate the instance and restore from an known good image. Keep isolation ideally until you‚Äôve verified that clients with access to the server are clean. Review access permissions and user actions. Likely something has laterally moved from your network into the server and potentially has persistence on your network. Ensure endpoint protection is running on all devices and do offline scans of the data layer where possible to find potential root kits.",
          "score": 12,
          "created_utc": "2026-02-14 09:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bh8o6",
              "author": "Xtrearer",
              "text": "Yeah this was exactly my playbook which lead to the \"culprit\".",
              "score": 1,
              "created_utc": "2026-02-14 10:13:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bhmyo",
                  "author": "morimando",
                  "text": "The potentially dangerous bit is if someone had put in a backdoor / remote shell of some sort longer ago that evades detection and made it into backups. \n\nDo you have Guard Duty EC2 Protection on that server? Also in case you happen to be on Enterprise Support, look into enabling Security Incident Response service",
                  "score": 6,
                  "created_utc": "2026-02-14 10:17:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5b8bi3",
          "author": "theculture",
          "text": "I would be considering that whatever is on the other side of that VPN is either compromised or a bad actor.",
          "score": 3,
          "created_utc": "2026-02-14 08:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5be5fo",
          "author": "ChiefOtacon",
          "text": "This one feels like a Security Speciality Certification question :D\n\nMost likely something on the other end of your VPN is compromised and moved on to Your instance",
          "score": 2,
          "created_utc": "2026-02-14 09:43:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b8svk",
          "author": "dghah",
          "text": "Treat as breach and activate your incident response plan. Rebuilding the windows server is correct. Maybe turn on VPC flow logs if not on already.  \n\nFeels like either a RDP user did something dodgy while connected or something installed on windows server got compromised.\n\nSince AWS had to tell you that you got popped consider this a sign that you may not have good visibility elsewhere in your IT landscape ‚Äî maybe your VPN service credentials or a user device that use VPN is compromised or RAT‚Äôed",
          "score": 1,
          "created_utc": "2026-02-14 08:50:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3m2un",
      "title": "Cloud Computing Career Path: SA, DevOps, or ML Engineer?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r3m2un/cloud_computing_career_path_sa_devops_or_ml/",
      "author": "shawnenso",
      "created_utc": "2026-02-13 10:48:35",
      "score": 10,
      "num_comments": 19,
      "upvote_ratio": 0.92,
      "text": "Hey there good people, I'm a computer science grad looking to specialize in cloud computing and I'm stuck between:\n\n1.Solutions Architect\n\n2. DevOps\n\n3. Machine Learning Engineer\n\nI've got 6 months to master one of these. Can anyone share their experience or point me in the right direction? What are the pros and cons of each role? Any roadmaps or resources to get started?\n\nThank you, I really appreciate you in advance.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r3m2un/cloud_computing_career_path_sa_devops_or_ml/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o55yy6g",
          "author": "Dandama",
          "text": "It is important to note that the SA role, especially at AWS, is considered pre-sales. This means you are working as part of a sales team and therefore have a lot of face time with various stakeholders within your customers organization. While it is important to understand the technology to solve business problems, having strong soft skills is just as crtical.",
          "score": 13,
          "created_utc": "2026-02-13 14:04:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o559q64",
          "author": "Sirwired",
          "text": "Well, you won't be \"mastering\" anything in six months...\n\nAn architect needs to be extremely strong in IT infrastructure fundamentals, which is something not commonly taught in college CS classes. You'll need to do a ton of studying on your own.\n\nDevOps is a combination of infrastructure and development; you'll need to understand automated pipeline tools and workload sizing.\n\nML?  If your CS program is math-heavy, then this might be a good choice. ML classes would be best, but barring that ask your professors for advice.",
          "score": 10,
          "created_utc": "2026-02-13 11:20:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o55fuow",
              "author": "enjoytheshow",
              "text": ">An architect needs to be extremely strong in IT infrastructure fundamentals, which is something not commonly taught in college CS classes. You'll need to do a ton of studying on your own.\n\nAlso like 5+ YOE. There aren‚Äôt entry level architect positions. Every good cloud or solution architect has  done it enough times that you have the knowledge and experience of what not to do next time.",
              "score": 2,
              "created_utc": "2026-02-13 12:08:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aqn7b",
                  "author": "shawnenso",
                  "text": "What are you suggesting I should do?",
                  "score": 1,
                  "created_utc": "2026-02-14 06:01:17",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5aqxvt",
              "author": "shawnenso",
              "text": "I am willing to learn and work without getting paid just to gain the experience.",
              "score": 0,
              "created_utc": "2026-02-14 06:03:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5dal0d",
                  "author": "Sirwired",
                  "text": "Doing productive work without pay is not even legal in most countries, unless you can find a charitable organization to volunteer for that could use the (limited) skills of a college student.",
                  "score": 2,
                  "created_utc": "2026-02-14 17:18:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o55b3up",
          "author": "courage_the_dog",
          "text": "I mean you're not going to master any of this in 6months lol most of these are senior level roles normally.\nYou'd have to have been building architecture in order to be an SA, you'd have to have dealt with dev and operstions to become a devops.\nChances of landing a junior role in any of these are slim",
          "score": 3,
          "created_utc": "2026-02-13 11:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aqj4c",
              "author": "shawnenso",
              "text": "Where, how,what can I use to start?",
              "score": 1,
              "created_utc": "2026-02-14 06:00:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5anus7",
          "author": "Human-Job2104",
          "text": "Solutions Architect Professional and Gen AI professional, these are probably the hottest and most relevant skills. Both have Associate level you can do on your way up to pro.\n\nDevops is great, but a little too focused on some AWS specific tool sets that most devs might not use.\n\nML is great, but AI is hotter and growing faster imo.",
          "score": 3,
          "created_utc": "2026-02-14 05:37:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5aqd22",
              "author": "shawnenso",
              "text": "Thank you for this. You are the only one so far who didn't tell me it cannot be done.",
              "score": 2,
              "created_utc": "2026-02-14 05:58:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5as4nv",
                  "author": "Human-Job2104",
                  "text": "You got this!\n\nUdemy courses and practice exams by these guys are great: Stephane Maarek, Neal Davis, Abhishek Singh, Frank Kane\n\nThey are on sale almost every day. Only buy them when 80-90% off.\n\nDo the associate exam first. When you pass, you get a 50% off coupon for the next test. You can even start w/ practitioner. It's the cheapest exam and if you took and passed practitioner, then associate, then pro w/ the cupons, it'd cost the same as taking the pro exam once.\n\nDo the labs in the courses for practice. And take the practice exams till you pass consistently. \n\nMix that with real world work and consistency and you'll be an expert in no time! Good luck!",
                  "score": 1,
                  "created_utc": "2026-02-14 06:14:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5fl3ia",
          "author": "o5mfiHTNsH748KVq",
          "text": "Don't think of DevOps as a career path, think of it as something you do to achieve being an effective Solutions Architect or ML Engineer (i'm guessing you mean ML Ops?)\n\nIt can be a career path, but that line of thinking is limiting. Be a well rounded engineer that values a DevOps mindset.",
          "score": 2,
          "created_utc": "2026-02-15 00:51:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o573vre",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-13 17:25:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58yy97",
          "author": "mylasttry96",
          "text": "‚ú®Delusion‚ú®",
          "score": 1,
          "created_utc": "2026-02-13 22:57:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o58zfb4",
              "author": "mylasttry96",
              "text": "In all seriousness you‚Äôd be lucky to get hired on as a jr cloud engineer w little to no experience",
              "score": 3,
              "created_utc": "2026-02-13 23:00:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5aq4po",
                  "author": "shawnenso",
                  "text": "That's why I asked for a roadmap, those professionals started from somewhere.",
                  "score": 1,
                  "created_utc": "2026-02-14 05:56:55",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r3ytpa",
      "title": "Amazon RDS now supports backup configuration when restoring snapshots",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-aurora-backup-configuration-restoring-snapshots/",
      "author": "risae",
      "created_utc": "2026-02-13 19:36:37",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r3ytpa/amazon_rds_now_supports_backup_configuration_when/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5bubfs",
          "author": "bot403",
          "text": "What's the big deal with just setting it up after it's started? I get this is a nice change but OP implies it fixes some larger issue.",
          "score": 1,
          "created_utc": "2026-02-14 12:14:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e4t24",
              "author": "risae",
              "text": "It doesn't make sense that you can specify certain things, but not this¬†",
              "score": 1,
              "created_utc": "2026-02-14 19:51:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r621ua",
      "title": "When can we get certification vouchers?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r621ua/when_can_we_get_certification_vouchers/",
      "author": "HistoricalTear9785",
      "created_utc": "2026-02-16 06:21:51",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.79,
      "text": "I wanted to check if anyone knows about any upcoming AWS events where free certification vouchers might be offered. Last year, they provided 50% discount vouchers are there any similar opportunities coming up this year?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r621ua/when_can_we_get_certification_vouchers/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5nejtq",
          "author": "MavZA",
          "text": "AWS provides them sporadically really. Sometimes they have certification drives, but it‚Äôs up to their internal team planning etc. we simply don‚Äôt have a view on that.",
          "score": 6,
          "created_utc": "2026-02-16 08:08:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5o1cy4",
          "author": "alex_aws_solutions",
          "text": "When you take an exam they will provide you with an 50% discount for the next one. ",
          "score": 3,
          "created_utc": "2026-02-16 11:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5qrxsu",
          "author": "Thinguist",
          "text": "Just get a job that pays for them. I‚Äôve done 7 now for free.",
          "score": 1,
          "created_utc": "2026-02-16 20:11:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5splkf",
          "author": "socaltrey",
          "text": "Our account manager always seems to be offering them.  I've never found anyone on the team that wants to take AWS on the offer of free certification.",
          "score": 1,
          "created_utc": "2026-02-17 02:28:36",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r324m8",
      "title": "AWS Cognito Experience",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "author": "True_Context_6852",
      "created_utc": "2026-02-12 18:59:57",
      "score": 8,
      "num_comments": 25,
      "upvote_ratio": 0.79,
      "text": "Hello  Good People ,\n\nOur org are planning to  migrate the our legacy app sign up process to  AWS Cognito . So  plan is First start the JIT with lambda for new sign up  and later  second step to  migrate all  user to  Cognito and forced reset password . final steps  when all looks fine than enable MFA to all  users . My question is AWS Cognito  right step or should we look other options  like okta or OAuth ? What you people have experienced during migration  ? What other area we need to look so existing user not lost the credentials?  \n\n ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o518j8p",
          "author": "MuffinMan_Jr",
          "text": "Im using cognito right now for my app, and the developer experience is terrible lol\n\nThat being said, you'd get lots of free MAU so I guess that's cool",
          "score": 29,
          "created_utc": "2026-02-12 19:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51xs9v",
              "author": "True_Context_6852",
              "text": "May I know what is terrible please ?",
              "score": 1,
              "created_utc": "2026-02-12 21:27:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o516zjd",
          "author": "Whend6796",
          "text": "Look elsewhere. \n\n- The documentation is notoriously confusing and poorly organized\n- The service has layers of abstraction that make simple tasks complicated\nAPI Design Issues\n- Inconsistent and unintuitive naming conventions\n- Methods that don‚Äôt follow AWS naming patterns used elsewhere\n- Confusing parameter requirements and error messages\n- The SDK can be clunky to work with\nLimited Flexibility\n- User migration from existing systems is painful\n- Customization options for authentication flows are restrictive\n- The hosted UI is difficult to customize and looks dated\n- Hard to implement certain common auth patterns\nToken Management Problems\n- Token refresh flows can be confusing\n- Limited control over token lifetimes and claims\n- Issues with token validation in certain scenarios\nDeveloper Experience\n- Simple tasks often require digging through documentation and Stack Overflow\n- Error messages that don‚Äôt clearly explain what went wrong\n- Testing authentication flows locally is cumbersome",
          "score": 42,
          "created_utc": "2026-02-12 19:19:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o568zic",
              "author": "methods2121",
              "text": "Props to this correct and succinct overview.   This would be valuable across almost every AWS service to separate the 'hype' vs. reality.  I second that Cognito would be very low on my list based on your requirements above and you should definitely look and preferably test others.",
              "score": 2,
              "created_utc": "2026-02-13 14:56:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o517lty",
          "author": "Wide_Commission_1595",
          "text": "I am usually in the \"AWS all the things\" camp, but Cognito is a tricky one.\n\nCognito _can_ be great for simple sign up flows.  It can even be pretty good with complex federations.  It's also damned cheap compared with other IdPs, but....\n\nThere's a ton of wiring Lambda functions into hooks to make it work the way most people want it to.  If you don't need those things, go with Cognito every day of the week.\n\nIf you want something a little more \"managed\" that just works, I have found external identity providers to be a lot simpler to use.\n\nWe use Okta, but basically any OIDC or SAML IdP (that's all of them!) works well.\n\nYou can even assume roles with web identity etc to do external-IdP-to-AWS role assumption.\n\nGenerally speaking, an external IdP will be simpler, but more expensive, especially as user numbers grow.  Cognito requires more plumbing, but is AWS-native.",
          "score": 12,
          "created_utc": "2026-02-12 19:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530s9s",
          "author": "MrStu56",
          "text": "It's horrible to work with, but when it's up and running it's cheap and reliable. If I had one 2026 AWS wish it would be for AWS to give this service the once over, take a look how people are using it now vs what was envisioned and then re-document it like their other services. This has to be the most opaque service I've ever worked with on AWS. ",
          "score": 6,
          "created_utc": "2026-02-13 00:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ioxny",
              "author": "DocterDum",
              "text": "Now now, we all know ‚Äúgive this service the once over‚Äù will end up being just a new interface slapped on with half the features missing, a few new garbage features nobody asked for, and a massive stack of bugs to boot.\n\n\n\n*Speaking from general large company experience, I haven‚Äôt paid a ton of attention to AWS specifically",
              "score": 1,
              "created_utc": "2026-02-15 15:19:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5iqua9",
                  "author": "MrStu56",
                  "text": "Well I've often wondered if Cognito could work internally with a VPC endpoint like loads of other services. I could see that being really handy, but couldn't see why it was seemingly deliberately left out.",
                  "score": 1,
                  "created_utc": "2026-02-15 15:29:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o518nbb",
          "author": "BadDescriptions",
          "text": "If you have good engineers then use Cognito. If you have bad engineers and loads of money then use okta/auth0",
          "score": 9,
          "created_utc": "2026-02-12 19:27:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53c1ll",
              "author": "BoostedHemi73",
              "text": "This is the most concise advice I‚Äôve seen on this topic.\n\nCognito is full of footguns. Test carefully and completely. If you are using CloudFormation, pay very careful attention to the defaults that are applied (like case sensitive email).\n\nBut the price is great for low/moderate MAU.",
              "score": 3,
              "created_utc": "2026-02-13 02:05:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53t8s3",
              "author": "VladyPoopin",
              "text": "This. If you have a solid engineer who ca actually wrap their head around how it works and utilize your own UI over the hosted UI, it‚Äôll work well for you.\n\nThat being said, that‚Äôs a hurdle for sure.",
              "score": 1,
              "created_utc": "2026-02-13 03:53:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51qwzb",
          "author": "macgoober",
          "text": "Cognito is dirt cheap if your MAU is less than 50k. The dev experience without something like sst.dev is a total nightmare tho.",
          "score": 2,
          "created_utc": "2026-02-12 20:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52vbqj",
          "author": "mouthbuster",
          "text": "Cognito is pain\nOkta/Auth0/Clerky will all get the job done the easiest at the highest cost\n\nCheck out Keycloak if you have the engineering bandwidth - it can do anything you‚Äôd ever want for the sweet cost of hosting it. Can meet any regulatory compliance need I‚Äôve ever ran into, and you can host this thing anywhere.",
          "score": 2,
          "created_utc": "2026-02-13 00:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535f4b",
          "author": "texxelate",
          "text": "Don‚Äôt use Cognito if you have any choice whatsoever. You‚Äôll have another legacy app sign up process from day 1.",
          "score": 2,
          "created_utc": "2026-02-13 01:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59i8t6",
          "author": "Howlla_",
          "text": "The good thing about authentication flows is that you shouldn't be changing that code frequently. It should be thoroughly tested and deployed in a production environment and cognito is the cheapest option.\nIf you need simpler stepup or plan on making many complex requirements then other ISV solutions like okta are amazing.",
          "score": 2,
          "created_utc": "2026-02-14 00:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o513pvk",
          "author": "SoggyGrayDuck",
          "text": "Maybe you can clear something up for me. We had a handful of our data engineers converted to BI engineers but they work with cognito? That's confusing to me",
          "score": 1,
          "created_utc": "2026-02-12 19:03:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516srq",
              "author": "True_Context_6852",
              "text": "I am talking about B2C customer migration as current sign up  process involved with SQL DB where user save credential  and later sign in with  same credentials . Now we want to  migrate all  sues to AWS Cognito  .The ask is what  is over all  experience if any body  did it like our org are on retail end .  ",
              "score": 1,
              "created_utc": "2026-02-12 19:18:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o519g3k",
          "author": "Alternative-Expert-7",
          "text": "Cognito is cheaper comparing to AuthO or Okta. Or the cheapest if you have big number of users.",
          "score": 1,
          "created_utc": "2026-02-12 19:30:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5234rn",
          "author": "Prestigious_Pace2782",
          "text": "The dev experience is pretty poor, but it‚Äôs nice to have it all in CDK and it‚Äôs cheap and mostly just works once it‚Äôs set up. \n\nI normally start a new project with cognito and use it until it becomes painful or doesn‚Äôt support something I need. Sometimes that doesn‚Äôt happen and it‚Äôs fine.\n\nHave used it at work in some pretty big stuff and had to get pretty in the weeds with apig caching and stuff.\n\nTLDR; It‚Äôs cheap and works well but is feature poor and a bit painful to learn.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52fy4b",
              "author": "True_Context_6852",
              "text": "Did you face real challenge with real customer during migration",
              "score": 1,
              "created_utc": "2026-02-12 22:57:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o53fgwe",
          "author": "cuddle-bubbles",
          "text": "horrible but great for your resume. if ur the engineering manager and dont have to do it yourself. may be a good idea to let your developers suffer while you add a great bullet point to your resume at the end of it",
          "score": 1,
          "created_utc": "2026-02-13 02:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54fnpk",
          "author": "hungrysandiegan",
          "text": "If you can leverage the Managed Login, Cognito works great and is cheap! Lots of companies can‚Äôt go the managed login route and have to use custom UI where its a pain!",
          "score": 1,
          "created_utc": "2026-02-13 06:43:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58g9mu",
          "author": "Past-Owl-3180",
          "text": "Won't recommend Cognito for even simpler use-cases. AWS has screwed up evolution of this, once great product.",
          "score": 1,
          "created_utc": "2026-02-13 21:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5963yt",
          "author": "GuavaRevolutionary56",
          "text": "Go with Okta or Ping. So much to bolt on for AWS Cognito.",
          "score": 1,
          "created_utc": "2026-02-13 23:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55a1xy",
          "author": "bajcmartinez",
          "text": "Cognito is just one more service into the hundreds of AWS services and doesn't seem like an important one based on its evolution, documentation and overall DX.\n\nI wouldn't recommend building your own auth, but you can choose from services like Auth0 for easy setup, good docs and DX, though depending on the number of users and features required you can go with a free plan or one of the plans. Alternatively, open-source solutions like Keycloak are pretty good, though that's again, more engineering work required for set up and maintenance.",
          "score": 0,
          "created_utc": "2026-02-13 11:22:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r57wqh",
      "title": "any quick method or automation is available to delete iam roles that are unused ?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r57wqh/any_quick_method_or_automation_is_available_to/",
      "author": "Any_Animator4546",
      "created_utc": "2026-02-15 06:52:27",
      "score": 8,
      "num_comments": 18,
      "upvote_ratio": 0.83,
      "text": "For my better understanding I create a new IAM role every time I create a new service in AWS. I am still learning these access control permissions. I want to know if there is a quick automatic way in which I can delete the IAM roles that are no longer been used ?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r57wqh/any_quick_method_or_automation_is_available_to/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5gzo9v",
          "author": "the_programmr",
          "text": "IaC is your friend here. If you use something with CDK/TF, you can delete all resources and associated IAM roles when you delete a stack.  \n\nIf the IAM roles you‚Äôre referring to here were created manually, would have to create a script using the AWS SDK to loop through roles and delete based on last usage time.",
          "score": 14,
          "created_utc": "2026-02-15 07:13:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5h0rbr",
              "author": "Any_Animator4546",
              "text": "thanks",
              "score": 2,
              "created_utc": "2026-02-15 07:23:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jjfhf",
                  "author": "SpecialistMode3131",
                  "text": "Don't forget you can use IAC Generator to create the cloudformation stack, \\*then\\* blow away what you want gone.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:48:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5hwjgm",
          "author": "weirdbrags",
          "text": "cloud custodian can help \n\nhttps://cloudcustodian.io/docs/aws/resources/iam.html",
          "score": 3,
          "created_utc": "2026-02-15 12:23:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ig0w0",
              "author": "pazarr",
              "text": "This is my preferred way too.",
              "score": 1,
              "created_utc": "2026-02-15 14:31:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hog6t",
          "author": "mrlikrsh",
          "text": "There is a last activity on the iam console for the role, not sure if you can get this programmatically",
          "score": 2,
          "created_utc": "2026-02-15 11:12:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hcp2k",
          "author": "pazarr",
          "text": "You can set up a cloud custodian. I quite like the tool.",
          "score": 1,
          "created_utc": "2026-02-15 09:19:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5he01n",
              "author": "Any_Animator4546",
              "text": "hi i am using a boto3 python script",
              "score": -2,
              "created_utc": "2026-02-15 09:32:21",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ii409",
                  "author": "pazarr",
                  "text": "If you don't want to use anything but boto, you can get last accessed information and than take action. \nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_last-accessed-view-data.html",
                  "score": 1,
                  "created_utc": "2026-02-15 14:43:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ndux5",
          "author": "ilyas-inthe-cloud",
          "text": "Check the \"Last activity\" column in the IAM console, it shows when each role was last used. For the ones showing 30+ days of inactivity you can safely nuke them. But honestly if you're learning, start using CloudFormation or CDK now. When you delete a stack it cleans up all the roles it created. Saves you from this exact problem going forward.",
          "score": 1,
          "created_utc": "2026-02-16 08:01:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5hdfft",
          "author": "pint",
          "text": "no, because there is no such thing as \"used\" role. nobody knows if you have a script somewhere that uses that role. including you yourself, because what if you reused one of these auto-generated roles somewhere, and the forgot?\n\nroles have last access time. also, roles have a trust policy, which tells you where the role is allowed to be used. if only lambda is allowed for example, you know it is not used anywhere else.\n\nif you are not a programmer, you might get an ai chatbot to develop a script for you to make a list with these fields for review. trusting an ai to develop the deletion script is a little more fishy.\n\nif you are some of a programmer, or willing to take on the task, you can use any sdk (e.g. boto3) to do this programmatically.\n\na middle ground is ai developed listing script, followed by manual review, followed by an excel-generated list of aws cli commands in a cmd file (assuming windows).",
          "score": -2,
          "created_utc": "2026-02-15 09:26:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ihrbm",
              "author": "pazarr",
              "text": "In fact you can check the last time an IAM role has been accessed. https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_last-accessed-view-data.html\n\nThis can be easily accessible via aws api or cli.",
              "score": 2,
              "created_utc": "2026-02-15 14:41:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5je2ub",
                  "author": "pint",
                  "text": "that's what i said",
                  "score": 0,
                  "created_utc": "2026-02-15 17:22:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r791ot",
      "title": "How to automate aws savings plans without manual quarterly analysis?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r791ot/how_to_automate_aws_savings_plans_without_manual/",
      "author": "My_Rhythm875",
      "created_utc": "2026-02-17 15:30:12",
      "score": 8,
      "num_comments": 18,
      "upvote_ratio": 1.0,
      "text": "Every quarter there's this ritual where you analyze usage patterns, try to predict future compute needs, calculate optimal savings plan coverage, submit recommendations to leadership, get approval, then finally buy commitments. By the time the whole process finishes usage has already changed and the analysis is outdated.\n\nCommitment recommendations in cost explorer are okay as a starting point but they don't account for upcoming projects, seasonal traffic patterns or planned architecture changes. They just look at historical usage and say \"buy this much\" which is often wrong.\n\nUnder committing means leaving savings on the table, over-committing means paying for capacity you don't use and the optimal middle ground requires constant adjustment. Three year commitments save more but lock you in longer which is risky for startups where everything changes constantly.\n\nCoverage percentage drops randomly when workloads shift and you need to evaluate whether to buy more which savings plan type makes sense (compute vs ec2) and what term length is appropriate. Feels like this should be automated somehow but I haven't found anything that actually works reliably\n\nIs there a good workflow for this or is manual quarterly analysis just the reality?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r791ot/how_to_automate_aws_savings_plans_without_manual/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5wcfwj",
          "author": "SpecialistMode3131",
          "text": "If you pay for it, you can get another human being to do this for you (We do it).  But at the end of the day, unless someone who really cares is looking hard at your spend versus your business objectives, you cannot know if that money is being wisely spent.\n\nSo the only real decision is whether you're doing that in-house, paying someone for it out of house, or just choosing not to do it at all.  People do all three things, with varying degrees of competence, with the variance in results you'd expect.",
          "score": 3,
          "created_utc": "2026-02-17 17:27:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5whnw7",
          "author": "CharacterHand511",
          "text": "Three year commitments are scary for startups yeah, one-year terms are safer because who knows what infrastructure will look like in 2027",
          "score": 2,
          "created_utc": "2026-02-17 17:51:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zk284",
          "author": "MateusKingston",
          "text": "If by the time you're buying the commitment the analysis is outdated either you're taking way too long (3+ months) or you're using SP the wrong way.\n\nIt's a commitment for 1/3 years, it can't get outdated in weeks, otherwise you would have made a wrongful commitment in the first place.\n\nOverall this isn't supposed to be an automated process as there is far too many external variables that no system will take into account and is a task that shouldn't realistically take too much time and isn't very frequent.\n\nYou can have tooling to assist you in that but I don't know of any (besides the built in aws console ones)",
          "score": 2,
          "created_utc": "2026-02-18 03:06:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w2np5",
          "author": "pausethelogic",
          "text": "There are some companies that will handle this for you. In general though, this is a manual process unless you want to automate it yourself. As you‚Äôve mentioned, there is a lot of real risk associated with the different options available",
          "score": 2,
          "created_utc": "2026-02-17 16:38:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5w4qpr",
          "author": "BloodAndTsundere",
          "text": "As far as overcommitting goes, I think there is a secondary market for reserved instances which can mitigate some of that risk.",
          "score": 1,
          "created_utc": "2026-02-17 16:48:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5whzbt",
          "author": "Sea-Car8041",
          "text": "coverage dropping is annoying bc u have to investigate why, is it a good change (moved to cheaper instances) or bad change (accidentally lost coverage)... requires manual analysis either way",
          "score": 1,
          "created_utc": "2026-02-17 17:53:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wklc1",
          "author": "galiyonkegalib",
          "text": "cost explorer recommendations are too simplistic, they don't understand context like \"migrating to lambda next quarter\" or \"traffic doubles in q4 every year\"",
          "score": 1,
          "created_utc": "2026-02-17 18:05:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5wmmjr",
          "author": "lostsomewhere--",
          "text": "Automation would be nice but trusting a tool to automatically buy commitments feels risky without human review first like what if the algorithm makes a mistake and commits you to $50k of unnecessary capacity. Some tools like prosperops try to do this or there's vantage autopilot feature that handles it but I'd want to really understand the logic before letting it run unsupervised",
          "score": 1,
          "created_utc": "2026-02-17 18:14:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o60zqpb",
              "author": "TeekhiSamosaa",
              "text": "yeah auto-buying without approval workflow is terrifying, needs at least a human-in-the-loop to review recommendations before executing",
              "score": 1,
              "created_utc": "2026-02-18 09:55:12",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o619ivt",
                  "author": "Vodka-_-Vodka",
                  "text": "Agreed, automation should help with analysis and maybe executing small incremental adjustments, but big commitment decisions need oversight",
                  "score": 1,
                  "created_utc": "2026-02-18 11:20:22",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61j470",
                  "author": "lostsomewhere--",
                  "text": "Aap bhi paid comment kr rhe üò≠üò≠?",
                  "score": 1,
                  "created_utc": "2026-02-18 12:30:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5wo86r",
          "author": "Connect_Street_867",
          "text": "Compute savings plans vs ec2 specific is another decision point, compute is more flexible but ec2 specific saves more... depends on whether you value flexibility or max savings",
          "score": 1,
          "created_utc": "2026-02-17 18:21:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6153xf",
              "author": "Unlucky_Abroad7440",
              "text": "compute makes sense when instance types change frequently, ec2 specific would lock you into old instance families",
              "score": 1,
              "created_utc": "2026-02-18 10:43:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o62asv8",
                  "author": "lunahanae",
                  "text": "Honestly this whole thing feels like something cloud providers should handle better natively like they have all the usage data why not just offer a \"smart commitment\" option that adjusts automatically",
                  "score": 1,
                  "created_utc": "2026-02-18 15:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5xhihu",
          "author": "TooMuchTaurine",
          "text": "Why quarterly, we just do it once a year, try to maintain about 95% coverage at peak to give us some buffer.",
          "score": 1,
          "created_utc": "2026-02-17 20:39:05",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r53lyo",
      "title": "Any Advice on Billing?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r53lyo/any_advice_on_billing/",
      "author": "GenderSuperior",
      "created_utc": "2026-02-15 02:57:44",
      "score": 8,
      "num_comments": 13,
      "upvote_ratio": 0.83,
      "text": "I know this story is going to sound crazy, and I've been using AWS for years, and have never seen anything like this.\n\nSo, first -\nAWS billed me for resources I tried deleting from CLI. It was hundreds of dollars in resource usage. I found the resources still active when I looked at my account the following month seeing nearly $600 in billing on my account. I disputed the charges, but recognized that it would probably go nowhere.\n\nThen, the next month - I get billed AGAIN for the same resources I had actually deleted - and I look again, and they're still active.. so I'm scratching my head at this point. I also didnt have $1200 in my account so it's now delinquent. Then, the third month comes in, and another $600 bill, and I had actually just reached out to them about trying to get on a payment plan - yet, no response still. I tried setting up billing notifications to tell me when my resource limits hit $85 and $100 .. and I deleted everything but a micro instance.\n\nThen, it gets crazier. I put money in my bank account, and they immediately took $600 out of my account, and 2 days later I get an email stating that my account was suspended.\n\nSo, I'm like \"whatever\" at this point. I honestly am over it after getting screwed out of my account. Mind you, I've had an account with them for years, and managed many client accounts through AWS for years. I've never had any problems, and always had great customer support.\n\nSo.. I start getting emails stating that my account has gone over it's resource limits - and has hit an excess of $100 for the month. I'm panicking thinking WTF. I try to log in .. but my accounts suspended.. so, I reach out to AWS and they tell me - they won't discuss my account details unless I log in to my account. . Which is suspended?!\n\nSo, how is it that they can be continuing to bill me for resources I can't access. My endpoints are offline, so they can't be billing me for resources that aren't running? How can they be charging me for resources I'm not using, on an account I don't have access to?\n\nHow can I get them to resolve this, or to at least stop billing me monthly for resources I don't have access to?\n\nI'm sure I'm not without fault here, but am I crazy? This seems like absolutely insane business practices if they treat people like this regularly?",
      "is_original_content": false,
      "link_flair_text": "billing",
      "permalink": "https://reddit.com/r/aws/comments/1r53lyo/any_advice_on_billing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5g3vd6",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'billing'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+billing).\n\nLooking for more information regarding billing, securing your account or anything related? [Check it out here!](https://www.reddit.com/r/aws/comments/vn4ebe/check_it_first_operating_within_amazon_web/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-15 02:57:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5g724d",
          "author": "nope_nope_nope_yep_",
          "text": "You obviously have not cleaned up everything or they won‚Äôt be charging you. If you don‚Äôt know what you‚Äôre doing the cloud can be an expensive lesson.",
          "score": 13,
          "created_utc": "2026-02-15 03:19:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5itjm8",
              "author": "GenderSuperior",
              "text": "Man I've been working on devops for years and never had this problem with aws with any clients, nor my own account.",
              "score": 0,
              "created_utc": "2026-02-15 15:42:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gtpe1",
          "author": "Drumedor",
          "text": "It would be useful if you wrote what resource types you have deleted and are billed for. If it for example is EC2 instances and you have an ASG setup, then it would spin up more servers to replace the ones you deleted.",
          "score": 3,
          "created_utc": "2026-02-15 06:17:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5itfnv",
              "author": "GenderSuperior",
              "text": "Yeah it was ec2 but I didn't have asg set up",
              "score": 1,
              "created_utc": "2026-02-15 15:42:18",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5jfhnv",
                  "author": "Drumedor",
                  "text": "In that case you did something wrong when terminating the instances, or had instances in other regions than the one you were looking at.",
                  "score": 1,
                  "created_utc": "2026-02-15 17:29:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5g83qx",
          "author": "AWSSupport",
          "text": "I'm sorry to hear about the frustration this has caused. Even with a suspended account, you can sign in to create a support case for this issue here: https://go.aws/4tBuBFZ. Our Support team will be able to help with stopping the resources and associated charges. \\- Holly G.",
          "score": 4,
          "created_utc": "2026-02-15 03:27:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5its67",
              "author": "GenderSuperior",
              "text": "But I can't sign in. The resources were stopped and I'm still being charged, even after my account was suspended, and then closed.\n\nThis is mad work.",
              "score": 2,
              "created_utc": "2026-02-15 15:44:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ix1sz",
                  "author": "AWSSupport",
                  "text": "Is your account suspended or closed? If your account is closed, see this article on how to reopen your closed account: https://go.aws/4qBXYVW. You should have a case ID available if you received a response from Support. Share it with us via private chat, and we can look into this for you.\n\n\\- Marc O.",
                  "score": 1,
                  "created_utc": "2026-02-15 16:00:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5m9ypf",
              "author": "SilentPugz",
              "text": "Hi Holly , just want to say thank you for all the lessons you give on skillbuilder.",
              "score": 1,
              "created_utc": "2026-02-16 02:49:29",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5meom8",
          "author": "IridescentKoala",
          "text": "$100 AWS support is going to reply saying they already emailed you how to fix this. \n\nYou can log in with a suspended account. And what does \"tried to delete resources\" even mean here? You either did or didn't. And then you just waited a month without ever checking?",
          "score": 2,
          "created_utc": "2026-02-16 03:20:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r593tt",
      "title": "How are the Nova 2 models for text processing",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r593tt/how_are_the_nova_2_models_for_text_processing/",
      "author": "2B-Pencil",
      "created_utc": "2026-02-15 08:05:50",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.9,
      "text": "I currently have a text processing workload that is using Gemini 3 Flash: summarization, keyword extraction, etc. Nothing fancy. But I do have to process the occasional 500k token document which is why I like Gemini. It does fairly well even with really big text  \n\n\n\nBut all my infra is on AWS and I have Activate credits for my project so I was strongly considering switching to Nova 2 models for cost savings. \n\n  \nwhat‚Äôs everyone‚Äòs experience with Nova 2 model family?",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1r593tt/how_are_the_nova_2_models_for_text_processing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5hdz7k",
          "author": "Sirwired",
          "text": "Every use case is different; while you could do something fancy with a whole system to score responses for comparison ( [https://aws.amazon.com/bedrock/evaluations/](https://aws.amazon.com/bedrock/evaluations/) ), you can just start by taking a couple of your trickier inputs and eyeballing the result.\n\nCertainly Nova 2 is pretty value-priced.",
          "score": 2,
          "created_utc": "2026-02-15 09:32:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r723uk",
      "title": "How do you build intuition for AWS architecture trade-offs",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r723uk/how_do_you_build_intuition_for_aws_architecture/",
      "author": "Zephpyr",
      "created_utc": "2026-02-17 10:04:21",
      "score": 7,
      "num_comments": 13,
      "upvote_ratio": 0.82,
      "text": "I have been working with AWS for about two years now, mostly ECS deployments and some Lambda functions. My current company uses AWS but most of my work is maintaining what someone else built. I understand how the services work individually but I struggle when asked to design something from scratch.\n\nI have been trying to improve. I go through AWS documentation, watch re:Invent videos, use A Cloud Guru for structured learning and work through small projects to practice IaC code. I use Claude and beyz coding assistant when I am writing Terraform or CDK to make sure my logic makes sense and I am not missing obvious mistakes. I have also started reading through the AWS Well-Architected Framework to understand how AWS recommends thinking about these decisions.\n\nMy problem is I can follow a tutorial but I cannot make architecture trade-offs on my own. When I try to apply it to a real scenario I get stuck. When someone asks why I chose a specific service over another or how I would balance cost versus performance versus operational complexity I do not have a good answer beyond what I read in a blog post. I know the tools exist but I do not know when to pick one over the other.\n\nFor those who went from working with AWS to actually designing AWS solutions, how did you build that intuition for trade-offs? Did you just keep doing practice designs until it clicked or is there a better way to learn the reasoning behind architecture decisions?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r723uk/how_do_you_build_intuition_for_aws_architecture/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5uceos",
          "author": "respectful_stimulus",
          "text": "Your north star should simply be solving the problem in the simplest way possible. And in the most cost effective way possible. Do this and you‚Äôre already at an advantage over the majority who implement unnecessarily expensive and complex architectures.",
          "score": 21,
          "created_utc": "2026-02-17 10:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5wa5nc",
              "author": "justin-8",
              "text": "This plus as a thought exercise when picking various pieces of the architecture: what are the limits. E.g. you pick lambda, the 15m max runtime is an obvious limit, is that important for this workload? Or you're using EC2 instances and an auto scaling group - scaling up can take several minutes, do you need to support bursty workloads or are they predictable? Can you just schedule over scaling during peak hours instead? Or do the busiest apis need some other mitigation (caching, migration elsewhere, etc).\n\nBut picking the simplest way should always be first.",
              "score": 3,
              "created_utc": "2026-02-17 17:15:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5udo2l",
          "author": "Bub697",
          "text": "For me it‚Äôs all experience and solving the problems yourself.  Build a solution, get it working and then ask, ‚Äúwhat if I needed to handle 10x the load?‚Äù  ‚ÄúWhat happens if an AZ fails?  Let‚Äôs try it!‚Äù  ‚ÄúWhat does it actually cost to run this?  What did I estimate it would cost?  Why was I so far off?‚Äù  \n\nI‚Äôd also add the leaning on an LLM for all these answers will not help you improve in the long term.  Read the docs, try things out, break it, fix it.",
          "score": 5,
          "created_utc": "2026-02-17 10:28:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uq8vt",
          "author": "weirdbrags",
          "text": "it‚Äôs 100% experience. the best way to learn how (and why) to choose/do the right thing is to choose/do the wrong thing, and to then do it over. \n\ni know that‚Äôs easier said than done though. the challenge is finding yourself in a role / environment where you have that kind of an opportunity.",
          "score": 7,
          "created_utc": "2026-02-17 12:13:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uwrlj",
          "author": "Sirwired",
          "text": "Look for \"architecture patterns\"; most problems you encounter have been solved by others, who write a blog post or whatever about it.\n\nBut in the end it comes down to hard-won experience.  I was in IT for about seven years or so before I did any architecture, and fifteen years before \"architect\" was part of my job title.  Not saying you can't do it faster, just that you shouldn't be disappointed if you can't go from \"wow, cloud is neat!\" to \"cloud architect\" in a couple years.",
          "score": 3,
          "created_utc": "2026-02-17 12:57:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5vac0p",
              "author": "Own-Manufacturer-640",
              "text": "Exactly this. If i have to make decisions as a junior i just follow the architecture pattern and then research on it",
              "score": 1,
              "created_utc": "2026-02-17 14:14:58",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5v27e9",
          "author": "mrbiggbrain",
          "text": "I have tried to wrap up a very complex topic into words that might make some sense but big concepts tend to not map so cleanly to a Reddit comment. \n\nAs others have said experience is a key factor. But I always like to say experience is not measured in years it is measured in moments. Good decisions, bad decisions, how you handled an outage, how you rebuilt after a disaster. You'll gain way more experience trying and failing then always staying safe. \n\nBut that does not mean you should not learn from others. There are lots of good books / articles / blogs / postmortems out there on systems design written from both the software engineers and infrastructure engineers point of view. \n\n* Understanding CAP theorem and what Consistency, Availability, and Partitioning are. \n* Understanding how large applications fail, when you should let them fail, and how to build in ways to fail gracefully. \n* Understanding how physics affects infrastructure design. \n* Understanding how various patterns work such as the transactional outbox or idempotent writes in log based messaging queues. \n\nLearn, apply, experience, repeat. I tend to read these books and mark off the things I can use now in one color and the things I think are useful but I don't have a use for in another. Then I come back later and see if I have a use for them later. ",
          "score": 2,
          "created_utc": "2026-02-17 13:29:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ufjrb",
          "author": "swiebertjee",
          "text": "Experience, but it's also logical and can be studied. Especially from other people's code.\n\nYou say ECS and Lambda. Have you set up projects with these tools? Do you have a preference? When would you use one vs another?\n\nFor me, I like Lambda for event driven architecture where you want replayability using (dead letter) queues. For API's serving users, I prefer traditional containers as they can keep multiple endpoints warm. Sure you can do that with Lambda too if you configuring API gateway to point multiple API endpoints to a single provisioned \"Lambdaton\". But at that point, wouldn't you like a service that is easier to develop and test locally? Etc etc.\n\nAnd for pricing, you can use the AWS cost calculator and test some scenarios. How does ECS on Fargate compare to ECS on EC2? You'll find out EC2 is cheaper, but does that mean it's better? How does the operational overhead cost compare? And is the (potential) cost saved worth the operational risk?\n\nIt all depends on context.",
          "score": 1,
          "created_utc": "2026-02-17 10:45:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ujh8o",
          "author": "SonOfSofaman",
          "text": "You mentioned using some tools to \"make sure ... I am not missing obvious mistakes\".\n\nI think you're doing yourself a disservice. Try to not rely on those tools. Don't get me wrong, I'm not an AI-hater. The problem isn't the tools. My point is you learn more from making mistakes than you do by avoiding them.\n\nIf you are baking a cake and you follow a recipe, the result is likely going to be a success. But what have you learned other than how to follow a recipe? If you start with no recipe, only a vague knowledge of which ingredients you need, you'll probably get it wrong at first. But then you'll adjust and iterate and learn from the experience.\n\nEmbrace mistakes. Don't avoid them.\n\nCaveat: with any cloud provider, mistakes can be costly! Always, always, always understand how much a service is going to cost before you use it, then clean up anything you aren't using.",
          "score": 1,
          "created_utc": "2026-02-17 11:19:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v9xtd",
          "author": "SpecialistMode3131",
          "text": "You may have to go work at a startup or similar environment so you're involved in making the tradeoffs.",
          "score": 1,
          "created_utc": "2026-02-17 14:12:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yt3xx",
          "author": "donkanator",
          "text": "First unzoom and then refine. Identify pattern first and general purpose and then follow the crumb trail of requirements. Somebody needs something crazy built? Welp, it looks like a three-tier web app to begin with. That's probably 90% of everything out there. Ingress, compute storage. Input > process > output. \n\nUse thought frameworks: Synchronous versus asynchronous (event driven).  Five architectural pillars. Data temperature. \n\nBDAT from TOGAF is a very good thought process. First you lay out business, application, data flows, and then technical architecture snaps in.",
          "score": 1,
          "created_utc": "2026-02-18 00:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o606uzj",
          "author": "philwills",
          "text": "Solve the problem without aws first. Figure out the data structures and interfaces needed. Then, find appropriate services for the different pieces of the solution.",
          "score": 1,
          "created_utc": "2026-02-18 05:37:54",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6jbie",
      "title": "How should i calculate IOPS for Aurora in AWS pricing calculator?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r6jbie/how_should_i_calculate_iops_for_aurora_in_aws/",
      "author": "xodmorfic",
      "created_utc": "2026-02-16 19:29:28",
      "score": 7,
      "num_comments": 14,
      "upvote_ratio": 0.9,
      "text": "I've spent over a week on this and I'm still unsure.\n\n  \nMy team wants to migrate from RDS MySQL to use Aurora (standard) for our database. I've tried to use the AWS pricing calculator to estimate the cost of the new DB, but i think i don't have thescsc right understanding of calculating the storage price for Aurora, and the estimations look way overpriced than expected.\n\n  \nI am replicating our current RDS MySQL setup with 800GB. Pricing calculator asks for \"Baseline I/O rate\" and \"Peak I/O rate\" for estimating the price of Aurora storage, but i am not sure of how to calculate those rates.\n\nThis is an example Total IOPS for test DB, from the metrics, for the last 1 day and a span period of 1 minute:\n\nhttps://preview.redd.it/e89erkt8rwjg1.png?width=567&format=png&auto=webp&s=3a2ede87a7535376607b848267ee9cc1cd04c981\n\n  \nIf i put those values of about 3.7k in the \"Baseline I/O rate\", i end up having a storage cost of about $2k which is a lot. \n\nOur current RDS MySQL database costs about $180 including storage (general purpose gp3). So i know that my input in those I/O fields in the AWS calculator might be wrong, but i don't know how then should i be calculating those values.\n\nhttps://preview.redd.it/mn0dz2yarwjg1.png?width=1700&format=png&auto=webp&s=0cd2675100aec5652be16f22bee1b99ce76b0c5e\n\n  \nHELP!",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1r6jbie/how_should_i_calculate_iops_for_aurora_in_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5ru9yc",
          "author": "Psych76",
          "text": "Assume it will be one million billion and pay up haha this is one reason we had to back out of Aurora (serverless) - the io costs were impossible to predict and our dev instances were racking up fees so fast.",
          "score": 1,
          "created_utc": "2026-02-16 23:24:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ruyai",
              "author": "xodmorfic",
              "text": "I mean, our current RDS for testing only costs about $180/month and using aws calculator, for Aurora it jumps up to over $2k. That is ridiculous, but that is why i think my calculations for IOPS are wrong",
              "score": 2,
              "created_utc": "2026-02-16 23:28:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5sqqos",
                  "author": "Psych76",
                  "text": "The iops unknowns of Aurora were such an unknown for us, with zero temp files ever suddenly we‚Äôd need hundreds of spend daily just on iops but other days $10, it was too all over the map and unpredictable and we lacked a way to see what our ‚Äúfuture iops actuals‚Äù would be.",
                  "score": 1,
                  "created_utc": "2026-02-17 02:35:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5qkehs",
          "author": "Alternative-Theme885",
          "text": "To calculate IOPS for Aurora in the AWS pricing calculator, you need to understand that the baseline I/O rate is the average IOPS your database will use, and the peak I/O rate is the maximum IOPS your database will use. The fix is to monitor your current RDS MySQL instance using CloudWatch metrics, specifically the \"VolumeReadOps\" and \"VolumeWriteOps\" metrics, to get an accurate estimate of your IOPS usage. You can then use these metrics to estimate your baseline and peak I/O rates in the AWS pricing calculator, which should give you a more accurate cost estimate for your Aurora database.",
          "score": -1,
          "created_utc": "2026-02-16 19:34:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5qoqag",
              "author": "TimGustafson",
              "text": "This is incorrect.  Aurora IOPS have nothing to do with EBS IOPs.  They're different things.  You can really only take an educated guess at what Aurora IOPs will look like for a given workload.  That's why AWS has IO Optimized: because this is so hard to figure out and regulate.\n\nThe only way to get accurate Aurora IOPs numbers is to measure them.\n\nSource: I was at AWS for 7+ years, working the last 4 as a Principal Database SA focusing on Aurora.",
              "score": 13,
              "created_utc": "2026-02-16 19:55:45",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5qr53v",
                  "author": "SpecialistMode3131",
                  "text": "Hence the usual \"take RDS and add 20%\" advice.",
                  "score": 5,
                  "created_utc": "2026-02-16 20:07:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5qwe4y",
                  "author": "Alternative-Theme885",
                  "text": "Good point, you're right that Aurora IOPS are separate from EBS. I oversimplified. For Aurora specifically, monitoring CloudWatch metrics like VolumeReadIOPs and VolumeWriteIOPs from an existing workload is probably the best way to estimate.",
                  "score": 2,
                  "created_utc": "2026-02-16 20:33:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5rem5n",
                  "author": "xodmorfic",
                  "text": "So, how can I really measure/estimate those \"Baseline I/O rate\" and \"Peak I/O rate\" for the calculator, if I don't have an Aurora DB yet but only our current RDS MySQL?\n\nI can rely on my current cloudwatch metrics, but if I use the values as i stated on the post/screenshot, the estimated cost just goes to the moon",
                  "score": 1,
                  "created_utc": "2026-02-16 22:02:36",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}