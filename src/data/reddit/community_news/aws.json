{
  "metadata": {
    "last_updated": "2026-01-24 02:29:56",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 145,
    "file_size_bytes": 209769
  },
  "items": [
    {
      "id": "1qjr0s7",
      "title": "ECR finally supports layer sharing",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/01/amazon-ecr-cross-repository-layer-sharing/",
      "author": "waitingforcracks",
      "created_utc": "2026-01-22 10:24:53",
      "score": 70,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qjr0s7/ecr_finally_supports_layer_sharing/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o13jwjl",
          "author": "TechDebtSommelier",
          "text": "TLDR: ECR can now reuse identical image layers across different repos, so pushes are faster and you stop paying to store the same base image over and over. Turn it on once at the registry level and it just works, which is especially nice if you have lots of microservices built on the same images.",
          "score": 29,
          "created_utc": "2026-01-22 19:05:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11g115",
          "author": "aviboy2006",
          "text": "Wow this great addition. Love it.",
          "score": 8,
          "created_utc": "2026-01-22 13:05:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o13l0os",
          "author": "waitingforcracks",
          "text": "Now just waiting for terraform to support the setting so we can enable it.",
          "score": 13,
          "created_utc": "2026-01-22 19:10:26",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o16odyq",
          "author": "wwsean08",
          "text": "As a note this only works for your repositories that are using the same KMS key, if they are using different KMS keys, then the layers won't be shared, which should be expected but at least wasn't initially called out when i read about it earlier this week and asked my TAM to confirm.",
          "score": 4,
          "created_utc": "2026-01-23 04:59:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkm3sa",
      "title": "What AWS service would you not recommend using today unless absolutely necessary and why?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qkm3sa/what_aws_service_would_you_not_recommend_using/",
      "author": "ApprehensiveBar7701",
      "created_utc": "2026-01-23 09:12:05",
      "score": 62,
      "num_comments": 169,
      "upvote_ratio": 0.9,
      "text": "",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qkm3sa/what_aws_service_would_you_not_recommend_using/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o17mqc0",
          "author": "hashkent",
          "text": "Amplify and elastic beanstalk",
          "score": 179,
          "created_utc": "2026-01-23 09:47:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18fpeh",
              "author": "dkode80",
              "text": "Came here to say this. I hate amplify so much. It's such a bloated, broken mess with little support and swaths of bugs. 450+ open issues on GitHub. \n\nI inherited an architecture that uses it heavily and have been moving things out of it. Such a horrid product that's broken in so many ways.",
              "score": 29,
              "created_utc": "2026-01-23 13:25:27",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18ng5k",
              "author": "mr_mgs11",
              "text": "I was going to post Elastic Beanstalk. It's basically containers for people who don't know how to use ecs. My last job there was a huge initiative to get all the container work loads off of it.",
              "score": 15,
              "created_utc": "2026-01-23 14:06:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ae98n",
                  "author": "criminalsunrise",
                  "text": "I use elastic beanstalk to standup POCs quickly. I donâ€™t know another way to do it so quickly and without hassle. I wouldnâ€™t use it for prod stuff though.",
                  "score": 4,
                  "created_utc": "2026-01-23 18:57:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18r7v1",
                  "author": "SpAwN_gUy",
                  "text": "Unless you are not using the containers and enjoy minimal system overhead closer to the metal. + cli deploy + spot instances + better right-sizing + fleet manager, load balancing, rotation, sys updates\n\nIn my head: container = instance, docker/kube cluster = aws region, docker cluster node = aws az\n\nAm I missing some crucial advance of ecs? I'm on ebtalk since 2011",
                  "score": 4,
                  "created_utc": "2026-01-23 14:26:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18i51c",
              "author": "acorah",
              "text": "We are looking at using amplify - we have it on some smaller projects and it works great for just deploying minimal frontend code (note: this is with a separate backend on ec2, we dont use the backend functionality) - is there something you would recommend instead? Just hosting the frontend code on ec2?",
              "score": 6,
              "created_utc": "2026-01-23 13:38:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18vx5k",
                  "author": "coolcosmos",
                  "text": "Use cdk to make a stack with a S3 website bucket to host, then a CloudFront distribution with the bucket as it's source.\n\n\nhttps://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_s3_deployment-readme.html",
                  "score": 13,
                  "created_utc": "2026-01-23 14:49:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1aasdu",
                  "author": "30thnight",
                  "text": "Amplify is a little confusing because itâ€™s better to think about it as 2 separate services, frontend hosting and fullstack app SDK. \n\n\\1. Frontend Hosting \n\nThis is an alternative to Vercel, Netlify, and Cloudflare Pages for deploying SPAs and static websites of all types on AWS.\n\nItâ€™s based on the traditional method (S3 + Cloudfront) but includes additional features that are a bit harder to an SRE team to build out of the box (feature branch deploys, password protection, redirect management)\n\nI honestly think this is best way to handle frontend deployments on AWS so long as you set this up with IaC\n\n\\2. Backend SDK\n\nGen 1 was heavily opinionated, bound to its CLI, and had unclear boundaries with how interfaced with existing IaC. 90% of pain and strife associated to Amplify in general can be attributed here. \n\nGen 2 fixes many these issues and create clear separation of boundaries between your existing infra as itâ€™s largely based on CDK. \n\nIf you are mostly running lambda backends or need to support older Next.js versions, Iâ€™d consider it safe to use\n\nThat said, amplify wouldnâ€™t be my first choice.\n\nI strongly believe sticking to containers simplifies life for everyone, especially when ECS Express Mode or App Runner exist.",
                  "score": 4,
                  "created_utc": "2026-01-23 18:42:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18nu2c",
                  "author": "mr-nobody1992",
                  "text": "Would also love to know why? We use amplify only for frontend as well",
                  "score": 3,
                  "created_utc": "2026-01-23 14:08:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1b1nkv",
                  "author": "Zenin",
                  "text": "Amplify v1 made trivial things easy and hard things impossible.\n\nAmplify v2 made easy things trivial and hard things are a massive pain in the ass.\n\nEvery Amplify project I've been involved with the team spent *most* of their development time working *around* Amplify.  It was very tempting to use *some* kind of framework for all the boiler plate work, but Amplify v1 got this extremely wrong and v2 is very much a \"too little, much too late\" story.\n\nThis is especially true today in the age of AI where AI can get you a *real* stack without all that opinionated cruft and lock in for much the same time and level of effort that you were looking to big frameworks to address.\n\nI've never worked with or even talked to anyone who's moved away from Amplify and regretted it or even missed it.",
                  "score": 1,
                  "created_utc": "2026-01-23 20:47:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18no96",
                  "author": "InsolentDreams",
                  "text": "Itâ€™s not an AWS service but we use fly.io for super cheap and affordable hosting for simpler frontends.  Still better than amplify and more affordable and less fiddly than manual ec2 and way less than ecs/eks",
                  "score": 1,
                  "created_utc": "2026-01-23 14:07:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18t5uu",
                  "author": "progres5ion",
                  "text": "Try ECS Express Mode for your frontend app https://aws.amazon.com/about-aws/whats-new/2025/11/announcing-amazon-ecs-express-mode/",
                  "score": 0,
                  "created_utc": "2026-01-23 14:36:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17vjw1",
              "author": "Legal-Butterscotch-2",
              "text": "I'm using amplify only, why not? so easy to plug to a repository and its works as CI/CD for you",
              "score": 6,
              "created_utc": "2026-01-23 11:05:48",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1841js",
                  "author": "SpoddyCoder",
                  "text": "Creates extremely bloated lambdas and is quite limited in a lot of respects. \n\nThis is one of their products thatâ€™s a response to competitor action - itâ€™s not unusual for these to see limited internal development and support - and to eventually be turned off in 5 years time when they realise to actually compete they would need to spend considerable resources on it.",
                  "score": 12,
                  "created_utc": "2026-01-23 12:11:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o17wscx",
                  "author": "Positive_Method3022",
                  "text": "Doesn't fit with cdk projects well",
                  "score": 2,
                  "created_utc": "2026-01-23 11:16:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18s280",
              "author": "thamesr",
              "text": "Genuine question - what would be an alternative to amplify? I use it all the time and haven't had any issues with it, but I'm not really a frontend person so I'm ignorant.\n\nElastic beanstalk is trash.",
              "score": 2,
              "created_utc": "2026-01-23 14:30:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19j920",
              "author": "Valkiie",
              "text": "On a frontend only standpoint:\n\nAmplify only if you need ssr.\n\nOtherwise go for the classic static sites s3 to cloud front",
              "score": 1,
              "created_utc": "2026-01-23 16:37:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1bl2s0",
              "author": "Asleep_Fox_9340",
              "text": "I have a product running on beanstalk (NodeJS) and Amplify (ReactJS) for the past 6 years. I have a team of 10 developers working on it. There are more QA, DevOps and even more people on the business side like account managers, sales, customer support, etc. The product in question made 3+ million USD revenue last year. \n\nI don't understand all the hate here ðŸ˜…",
              "score": 1,
              "created_utc": "2026-01-23 22:19:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18s88k",
              "author": "thetall0ne1",
              "text": "Just use Kiro CLI and vibe deploy stuff to AWS. You never have to touch the console. AWS even has a prompt library you can use to get started: https://aws.amazon.com/startups/prompt-library",
              "score": -3,
              "created_utc": "2026-01-23 14:31:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18w2b4",
                  "author": "skat_in_the_hat",
                  "text": "\"Hey Kiro, why is my bill 1000/mo?\"",
                  "score": 4,
                  "created_utc": "2026-01-23 14:50:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o17l0xl",
          "author": "CanaryWundaboy",
          "text": "ElasticBeanstalk, itâ€™s horrible.",
          "score": 78,
          "created_utc": "2026-01-23 09:31:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o188uol",
              "author": "HanzJWermhat",
              "text": "Itâ€™s a zombie product at this point anyway",
              "score": 17,
              "created_utc": "2026-01-23 12:44:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18cso1",
                  "author": "yourparadigm",
                  "text": "Yet somehow their AL2023 AMIs got Ruby 3.4 support a year ago!",
                  "score": 3,
                  "created_utc": "2026-01-23 13:08:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17l6mb",
              "author": "ApprehensiveBar7701",
              "text": "Elastic Beanstalk. Tries to be simple PaaS but ends up giving you EC2/ASG/ALB complexity plus an opaque magic layer. Hard to debug, customize, or migrate off. In 2026, ECS/Fargate or EKS are almost always better.",
              "score": 14,
              "created_utc": "2026-01-23 09:33:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1avwfj",
                  "author": "elsefirot_jl",
                  "text": "EBS was already old when I was using it in 2015. Just let that crap die already",
                  "score": 1,
                  "created_utc": "2026-01-23 20:20:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1b3kqw",
                  "author": "Defiant-Ad-3243",
                  "text": "While I understand this take, it's worth mentioning that Beanstalk has been improving lately after years of stagnation. Also it's apples and oranges to compare Beanstalk (app management) to ECS/EKS (infra management).",
                  "score": 1,
                  "created_utc": "2026-01-23 20:56:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o19j913",
              "author": "AWSSupport",
              "text": "Hi there,\n\nSorry to hear that, we're always looking for ways to enhance our services. If you've suggestions that could help improve our Elastic Beanstalk application, share your feedback using this option: http://go.aws/feedback.\n\n\\- Elle G.",
              "score": 2,
              "created_utc": "2026-01-23 16:37:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17q34f",
              "author": "soulseeker31",
              "text": "We have an instance of metabase running for internal use only on it. Haven't touched it because it hasn't broken __yet__.",
              "score": 2,
              "created_utc": "2026-01-23 10:18:05",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1akcug",
              "author": "fonde_la",
              "text": "Surprised to see all the hate for EB. We've used it in production for 10 years and never had an issue. Sure, if I were to set it up from scratch today I might choose a solution with containers but it works well enough that we've had no reason to migrate yet.",
              "score": 1,
              "created_utc": "2026-01-23 19:26:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1c1rn9",
              "author": "ownlessminimalist",
              "text": "I took the leap on my last project to go with ECS/Fargate and thank goodness I did. So much easier to work with",
              "score": 1,
              "created_utc": "2026-01-23 23:46:09",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1aq5j6",
              "author": "EitherAd5892",
              "text": "Why is elastic beanstalk bad? I thought itâ€™s a great tool for managing AWS servicesÂ ",
              "score": 0,
              "created_utc": "2026-01-23 19:53:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1898a4",
          "author": "santhab",
          "text": "DMS is trash",
          "score": 36,
          "created_utc": "2026-01-23 12:46:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18ttrg",
              "author": "Icy_Tumbleweed_2174",
              "text": "Wondered how long Iâ€™d have to scroll to see this. If anyone has tried to use this with force this would be closer to the top. POS.",
              "score": 9,
              "created_utc": "2026-01-23 14:39:25",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19roak",
              "author": "AntDracula",
              "text": "It's so bad. Forget about it if you get an error. Just blow it away and try again from scratch.",
              "score": 3,
              "created_utc": "2026-01-23 17:15:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1afa8h",
              "author": "maddcox",
              "text": "I agree. It has a lot of problems for example CDC is useless for large production database replication. \nBut if you need to migrate db over from one system to another it is very useful. \nI was working on transfering very large outdated mysql from on prem to aws and I needed to have 0 downtime. It was running on Widnows so I couldnt use Percona Xtraboot so my only option was DMS. After a fee tries I got it to work and it saved me a lot of time.",
              "score": 3,
              "created_utc": "2026-01-23 19:02:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19qwrf",
              "author": "wtf",
              "text": "So true. We had to work directly with their team and get a custom patch from them to get it working for us.",
              "score": 2,
              "created_utc": "2026-01-23 17:12:14",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1ajfmj",
              "author": "joelrwilliams1",
              "text": "Works pretty well for us when we need it.  There a few glitches, but we tent to push through them.",
              "score": 2,
              "created_utc": "2026-01-23 19:21:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1ae1w0",
              "author": "saleableautumn5",
              "text": "It's gotten less terrible imo but it took a long time to get there.\n\nEdit: though I still wouldn't say it's not trash",
              "score": 1,
              "created_utc": "2026-01-23 18:57:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17mg69",
          "author": "-Melchizedek-",
          "text": "Pretty much the entirety of AWS IoT, unless you can guarantee that you will always and forever use it exactly like they intended (and that's very narrow). It's a mess, so many strange decisions like forcing immutability on a bunch of things that do not need to be immutable.",
          "score": 24,
          "created_utc": "2026-01-23 09:44:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1825pa",
              "author": "curiousEnt0",
              "text": "Do you suggest any better alternatives? If so, could you please explain why they are better?",
              "score": 5,
              "created_utc": "2026-01-23 11:58:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1865zh",
                  "author": "-Melchizedek-",
                  "text": "Depends what you need. If you need to handle OTA software updates and similar things something like Mender is a better solution. \n\nWe ended up rolling our own system for managing, updating and communicating with devices, with SWUpdate for actually handling updates. But there are platforms out there too.\n\nAWS IoT is probably good if your IoT are extensions of your AWS cloud infra, maybe, but I'm still not convinced.",
                  "score": 2,
                  "created_utc": "2026-01-23 12:26:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1a5p6u",
              "author": "bastion_xx",
              "text": "What are some of the immutable things? I'd agree that the AWS IoT services aren't getting more love (deprecation of Events, Analytics, FleetWise, Fleet Hub, etc.). I would say IoT Core, Rules Engine, and the general fleet provisioning services will be there a long time. And to your point, pretty much as-is.\n\nI will say they have rolled more features to the Rule Engine, early provider of TLS 1.3, and some other security features over time.\n\nThen there is Greengrass. v1. v2. Lite. lol.",
              "score": 1,
              "created_utc": "2026-01-23 18:19:53",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1a8g7o",
              "author": "x86brandon",
              "text": "I wouldn't say it's trash, it's just very opinionated.  It was fairly reliable for me when I used it.   Just, like you said, strongly opinionated on things that aren't aligned with our use case.  We launched some features on it, built some support services and eventually deprecated most of it in favor of our home grown stuff as we scaled.",
              "score": 1,
              "created_utc": "2026-01-23 18:32:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17mi5c",
          "author": "baronas15",
          "text": "Cognito. Yuck ðŸ¤¢",
          "score": 113,
          "created_utc": "2026-01-23 09:45:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17xjbq",
              "author": "ManBearHybrid",
              "text": "I know it used to be terrible, but I've heard there have been recent overhauls. Is it still bad?",
              "score": 16,
              "created_utc": "2026-01-23 11:22:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18p4te",
                  "author": "TheSpaceFace",
                  "text": "My favourite thing in Cognito, though I think they fixed it, is that the hosted login page would throw a weird error until you set up branding guidelines for it, like it wouldn't give you a default, it would just throw a weird 500 Error or something with no explanation xD",
                  "score": 10,
                  "created_utc": "2026-01-23 14:15:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18369p",
                  "author": "baronas15",
                  "text": "Last time I had to use it was 2 years ago. If they had massive changes, that would be great, but at the time competition was far better in comparison. And I bet it still is",
                  "score": 3,
                  "created_utc": "2026-01-23 12:05:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1bco9f",
                  "author": "Fyunculum",
                  "text": "If by overhauls you mean adding a higher price tier that fixes some of the limitations then yeah.",
                  "score": 1,
                  "created_utc": "2026-01-23 21:39:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1874dx",
              "author": "Kralizek82",
              "text": "I find it to work well enough ðŸ¤”",
              "score": 12,
              "created_utc": "2026-01-23 12:32:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o192m28",
              "author": "IntermediateSwimmer",
              "text": "I actually disagree with this. It's good for what it does, but I think people expect it to do a lot more than what it was built for",
              "score": 12,
              "created_utc": "2026-01-23 15:22:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o194toa",
                  "author": "OGwadds",
                  "text": "Iâ€™m with you on this, no one ever has alternatives that are as close in pricing or not unnecessarily convoluted for the use case.\n\nItâ€™s certainly not perfect but it does enough and takes no time to set up.",
                  "score": 5,
                  "created_utc": "2026-01-23 15:32:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o19gddp",
                  "author": "PeteTinNY",
                  "text": "Thatâ€™s exactly the problem.   Customers have been very very vocal about what they need from cognito but AWS and all the product / specialists turn around and decline meetings giving a document that essentially gives a decision chart that says cognito is the wrong product. \n\nWhy not make the right product then?",
                  "score": 1,
                  "created_utc": "2026-01-23 16:24:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o17uz92",
              "author": "SuperDooperX",
              "text": "Opened the thread just to make sure this was listed lol",
              "score": 24,
              "created_utc": "2026-01-23 11:00:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o186k9c",
                  "author": "Sensi1093",
                  "text": "What alternatively are as cheap as cognito?\n\nIâ€™m using it with ~5k users and it costs nothing. None of the competitors I have checked were free beyond like 100 users the last time I checked",
                  "score": 13,
                  "created_utc": "2026-01-23 12:29:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18zugs",
              "author": "atlasmountsenjoyer",
              "text": "Always heard people talk bad about it. Have used it in two large corporate apps and personal one..no issues so far. Maybe our case isn't all that complex though? Not sure what kinda issues you all run into?",
              "score": 4,
              "created_utc": "2026-01-23 15:09:15",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1avguv",
              "author": "kuda09",
              "text": "My only beef with Cognito is that you can't edit or delete custom attributes after a user pool is created.",
              "score": 4,
              "created_utc": "2026-01-23 20:18:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o181xb9",
              "author": "curiousEnt0",
              "text": "What are the best alternatives? And why?",
              "score": 2,
              "created_utc": "2026-01-23 11:56:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1av3tw",
                  "author": "kuda09",
                  "text": "Keycloak is pretty much flexible",
                  "score": 1,
                  "created_utc": "2026-01-23 20:16:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1b3l4v",
              "author": "Zenin",
              "text": "I use it constantly and have little issue with it, but my use cases might be different.  I work in corporate space mostly, not end user, so for me it's much more about hooking auth into ALBs, API Gateway, etc and linking that into Okta or Identity Center.\n\nGetting actual IAM credentials via Identity Pools on per-user basis is also a *HUGE* win architecturally for me as I can then use IAM directly to auth users by policy to API Gateway or direct writes to dynamodb, etc from the browser.  IAM policy based access controls and full audit traceability is a great win in my space especially vs trusting backend code to correctly handle RBAC decision trees.  My API code then only has to care about its actual task knowing the security is handled upstream.",
              "score": 2,
              "created_utc": "2026-01-23 20:56:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17ur7h",
              "author": "Safeword_Broccoli",
              "text": "Oh boy, someone suggested it to me yesterday. Why should I avoid it?",
              "score": 1,
              "created_utc": "2026-01-23 10:59:05",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1873w1",
                  "author": "ReturnOfNogginboink",
                  "text": "No multi region support.",
                  "score": 7,
                  "created_utc": "2026-01-23 12:32:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o188nr8",
                  "author": "pint",
                  "text": "just one example to get a taste of the service, but expect a lot of this:\n\nthe user can define multiple mfa methods, and optionally can select a default. if a default is selected, mfa choice is not offered at all, but the login flow automatically proceeds with the default one. there is no way to select another one at all. the user can change or remove the default only after a successful login. thus, if the method is temporarily not available, bad luck, the user can't log in. the conclusion is that you should never allow users to select a default method, the functionality is defective.",
                  "score": 10,
                  "created_utc": "2026-01-23 12:42:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1a8tpw",
              "author": "x86brandon",
              "text": "Yup.  I launched some internal tools on it and then replaced it with a Rust/Actix based home made service.",
              "score": 1,
              "created_utc": "2026-01-23 18:33:44",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1a49st",
              "author": "defel",
              "text": "I disagree. It can do everything, it works, is performant, the big issues from years ago are fixed.",
              "score": 1,
              "created_utc": "2026-01-23 18:13:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o181zp0",
              "author": "mixxituk",
              "text": "My god the new British gov app is horrific for loginÂ ",
              "score": 0,
              "created_utc": "2026-01-23 11:56:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17ufjb",
          "author": "Beautiful_Spot5404",
          "text": "Amplify",
          "score": 25,
          "created_utc": "2026-01-23 10:56:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18cb6w",
          "author": "ppernik",
          "text": "Amplify - not even if it's necessary. Just migrate, run away or quit software development. It's a failed attempt at a Firebase competitor. Buggy, hard to work with in a team, undocumented edge cases, doesn't work well with IaC, and most importantly it fucking hides away the actual infrastructure used. Like you won't be able to access and tweak any of the Lambdas, S3 or CloudFront distributions used. I've spent so much time working around Amplify it's ridiculous.\n\nCognito - for such an integral service it's severely undercooked with tons of weird undocumented edge cases. Once you know your way around it, it's fairly reliable, but it's definitely frustrating to get there.",
          "score": 23,
          "created_utc": "2026-01-23 13:05:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18fscu",
              "author": "vyle_or_vyrtue",
              "text": "What do you recommend as alternatives?\n\nIâ€™m using cognito and amplify as part of a small saas, and I agree amplify keeps hitting walls. I havenâ€™t had issues with cognito but based on this thread, I need to do more research.",
              "score": 2,
              "created_utc": "2026-01-23 13:25:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18jkyr",
                  "author": "ppernik",
                  "text": "Cognito will work. Just be aware there can be weird edge cases. Given how integrated with the rest of AWS it is, if you're mostly or fully on AWS, it's worth it.\n\nAmplify - depends what you're hosting there. If it's a static web app, you'll be fine with an S3 + CloudFront combo. For Next.js, you're probably best off putting it in Docker and throwing it on Fargate or something similar. OpenNext didn't work well for me.\nFor Amplify backend it depends entirely on what you need, whether it's Lambdas, API Gateway, EC2, Fargate or a combination. I'm running a GraphQL server on Lambda + API Gateway combo and it's been working well. Moved away from AppSync, too. Everything Amplify CLI can create you can create yourself using CloudFormation, CDK or Terraform. Plus it's going to be more reliable.",
                  "score": 2,
                  "created_utc": "2026-01-23 13:46:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19w9r1",
          "author": "suur-siil",
          "text": "Redshift.Â  It just doesn't scale well beyond a certain point.Â  Every solution proposed is basically \"gib more money\" and doesn't improve anything.",
          "score": 9,
          "created_utc": "2026-01-23 17:37:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19r2am",
          "author": "AntDracula",
          "text": "REDSHIFT\n\nBecause even though it's like 12 years old, it still behaves as if it's a beta product.",
          "score": 13,
          "created_utc": "2026-01-23 17:12:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1awnei",
              "author": "DoINeedChains",
              "text": "And hasn't had any meaningful features added since Spectrum.  And is still based on an ancient PostgreSQL 9 core\n\nI kind of suspect the original engineers that forked PostgreSQL are no longer involved and the current team is just sustainingthe thing",
              "score": 3,
              "created_utc": "2026-01-23 20:24:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1b3xik",
              "author": "KipT800",
              "text": "Data sharing helps and you can create a multi cluster architecture â€¦.. but but but â€¦ yeah it is pants.Â ",
              "score": 1,
              "created_utc": "2026-01-23 20:58:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18pvsu",
          "author": "TwoWrongsAreSoRight",
          "text": "This one is very controversial but IMO Cloudformation.  It's a good idea in theory, in practice it's severely lacking and will cause you many hours of frustration.  A few examples of why I find it problematic. \n\n\\* It doesn't have any real state management so if someone changes something outside cloudformation, it won't pick up that change when you run the stack, no warning just silently ignore unless it conflicts and the whole stack will fail.\n\n\\* It treats the whole stack as a single entity so it'll deploy all or nothing.  Some consider this a pro, most just find it annoying because say for example you mistype a security group id you're referencing.  Instead of refusing to create the resource that relies on that group so you can quickly fix it, you need to wait for it to rollback (remove all changes in that stack, get to a good state (UPDATE\\_ROLLBACK\\_COMPLETE) and then you can try again.  That means depending on your stack size, it could take over an hour to fix that simple problem.\n\n\\* It can be difficult to figure out what actually went wrong during stack creation and depending on the state it ends up in, can be difficult to fix and sometimes require you to delete the stack and redeploy.  Another fun feature is the first time you deploy a stack, if it errors out, you have to delete the stack manually.\n\n\\* Some strange behaviors that aren't well documented.  Example: when changing a db subnet group, you remove subnets 1234 and 5678 and add 1919.  It will add 1919 but fail to delete the other 2 even if nothing is using them.\n\nI'm sure others will give many more examples.",
          "score": 30,
          "created_utc": "2026-01-23 14:19:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o197ref",
              "author": "dr_barnowl",
              "text": "It's bloody awkward to refactor as well, whereas refactoring Terraform configs is relatively easy.\n\nThe sole advantages of CloudFormation are\n\n- It's the \"official\" thing, which means all the docs and examples use it\n- There are lots of community examples in it\n- There's a cloud-side execution platform for it out of the box\n\n... on the other hand, it's relatively simple to port CF templates to Terraform\n\nCreating a cloud-side Terraform executor isn't super awful to do.\n\nSomeone will say \"CDK\" to which I say, CDK just generates CloudFormation which means it just generates all these problems faster.",
              "score": 7,
              "created_utc": "2026-01-23 15:46:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19jn1u",
                  "author": "chesterfeed",
                  "text": "Not really. Cdkv2 isnâ€™t a bijection to CFT",
                  "score": 1,
                  "created_utc": "2026-01-23 16:39:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o19xmno",
              "author": "blooping_blooper",
              "text": "yeah the delete thing is so annoying, like why can't I just push again after I fix the template errors instead of having to go in and delete the stack.",
              "score": 1,
              "created_utc": "2026-01-23 17:43:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1a8v5w",
              "author": "guterz",
              "text": "Itâ€™s really nice for general account bootstrapping though. I use it to deploy a stackset in my clients CFT delegated admin account to setup our access roles and terraform execution roles so any new account we create has the necessary permissions from the jump.",
              "score": 1,
              "created_utc": "2026-01-23 18:33:55",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1aw492",
              "author": "jesusrambo",
              "text": "Lambdas taking 2 hours to deploy when it has to create a new ENI ðŸ™ƒ\n\nThis is only tangentially/vaguely documented, and in like a single place",
              "score": 1,
              "created_utc": "2026-01-23 20:21:36",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o188lu3",
          "author": "candyman_forever",
          "text": "Glue, it basically just creates abstractions on top of Spark and doesn't let you do anything easily. It has weird python shell jobs you can run that are not using newer versions of python.",
          "score": 18,
          "created_utc": "2026-01-23 12:42:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18au04",
              "author": "leeharrison1984",
              "text": "Glue is such a strange beast. The UI looks like someone banged it out in a weekend as a POC and then went on holiday, never to return.",
              "score": 27,
              "created_utc": "2026-01-23 12:56:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19ryav",
                  "author": "AntDracula",
                  "text": "> I must go, my people need me",
                  "score": 2,
                  "created_utc": "2026-01-23 17:17:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1ayy8t",
              "author": "DoINeedChains",
              "text": "Glue was clearly not designed by anyone who had any expertise in designing or managing ETL flows at scale",
              "score": 2,
              "created_utc": "2026-01-23 20:35:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18bne9",
          "author": "dobby96harry",
          "text": "Inspector - but mostly due to costÂ ",
          "score": 8,
          "created_utc": "2026-01-23 13:01:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b6821",
              "author": "Contrandy_",
              "text": "Yeah especially if you use primarily lambdas, it's CRAZY compared to EC2-only scanning.",
              "score": 1,
              "created_utc": "2026-01-23 21:09:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cgswy",
                  "author": "dobby96harry",
                  "text": "Yup that's what got us to stop using it",
                  "score": 1,
                  "created_utc": "2026-01-24 01:08:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18d7k2",
          "author": "CanyonSlim",
          "text": "I recommend against using Control Tower even if you're starting fresh in AWS. There are some benefits to it, especially if you're unfamiliar with managing multiple AWS accounts in an environment, but its neither flexible nor robust, so you're likely going to put a lot of work into supplementing it anyway while being unable to change things that are locked down by the service.",
          "score": 9,
          "created_utc": "2026-01-23 13:11:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18rae7",
              "author": "k3mjay",
              "text": "What's the alternative?",
              "score": 3,
              "created_utc": "2026-01-23 14:26:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o19yrfk",
                  "author": "CanyonSlim",
                  "text": "I don't think there is really one tool that quite does what Control Tower does, but that's for a good reason. Under the hood, Control Tower is just a bunch of existing AWS services stitched together, but with added restrictions because AWS doesn't want you changing too much.\n\nI would recommend getting familiar with underlying services that Control Tower relies on - AWS Organizations, IAM Identity Center, CloudFormation StackSets, etc - and building your own version of Control Tower that is suited to your exact needs and preferences. Even with Control Tower we've largely wound up doing that anyway.",
                  "score": 4,
                  "created_utc": "2026-01-23 17:48:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1b5tny",
                  "author": "Ihavenocluelad",
                  "text": "Put the minimum in control tower and organisations and apply the rest via iac/scps/bootstrapping",
                  "score": 1,
                  "created_utc": "2026-01-23 21:07:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o19caza",
          "author": "SecureConnection",
          "text": "Cognito. They are not so good in user facing identities and access management, as demonstrated by AWS and Amazon sign ins.  \n\nCloudWatch is poor for what it costs. \n\nSecurity Hub. You end up needing to manage state for the different findings. It doesnâ€™t integrate with other AWS services without adding some Lambda spackle yourself. The API is terribly slow and rate limited.",
          "score": 7,
          "created_utc": "2026-01-23 16:06:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1b6eh9",
              "author": "Contrandy_",
              "text": "\\+1 on SecurityHub issues. Very slow response rate and the rate limiting is terrible.",
              "score": 2,
              "created_utc": "2026-01-23 21:10:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bdv1f",
                  "author": "AWSSupport",
                  "text": "Hi there, \n\nI've sent our Support team your feedback about SecurityHub for further review. \n\n\\- Gee J.",
                  "score": 1,
                  "created_utc": "2026-01-23 21:44:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o1bd113",
              "author": "AWSSupport",
              "text": "Hi there, \n\nI have forwarded this feedback to our internal teams for further review. \n\n\\- Gee J.",
              "score": 2,
              "created_utc": "2026-01-23 21:41:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o1891mv",
          "author": "BeyondLimits99",
          "text": "AWS Personalize\n\nIts also incredibly expensive",
          "score": 3,
          "created_utc": "2026-01-23 12:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19dbh6",
          "author": "Ok_Whole_1665",
          "text": "Opensearch serverless. It sounds good on paper: Less management than a full Opensearch cluster and reduced cost due to serverless infrastructure.\n\nIn reality it's buggy, performance is lagging and it becomes \\_very\\_ expensive very quickly!",
          "score": 3,
          "created_utc": "2026-01-23 16:11:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19iv8q",
              "author": "BitterDinosaur",
              "text": "Expensive is an understatement.",
              "score": 3,
              "created_utc": "2026-01-23 16:35:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19m2hg",
          "author": "Solopher",
          "text": "Cognito and Elastic Beanstalk",
          "score": 3,
          "created_utc": "2026-01-23 16:50:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19r511",
          "author": "mattingly890",
          "text": "Code Commit \n\nIt was a zombie before, then they tried to kill it, now I think it is back to being a zombie.\n\nWe have a just a few legacy things that still have to go through code commit, and it is very unreliable.",
          "score": 3,
          "created_utc": "2026-01-23 17:13:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1avbip",
              "author": "JackBauerTheCat",
              "text": "Five or so years ago I helped a startup with their initial build out, so I used code commit just so everything was under one roof for whatever engineer they got to pickup the full time job.\n\n\nand that person was me. \n\n\n\nfirst project: move to github",
              "score": 2,
              "created_utc": "2026-01-23 20:17:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1cefev",
                  "author": "_chrisdunne",
                  "text": "Now GitHub is down all the time and only care about AI",
                  "score": 1,
                  "created_utc": "2026-01-24 00:54:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18m75y",
          "author": "intelignciartificial",
          "text": "Cloudformation its very akward",
          "score": 7,
          "created_utc": "2026-01-23 14:00:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18u6gp",
              "author": "distresssignal",
              "text": "This would be my choice. I have built things with Cloudformation in the past. It is rarely the best tool for the job. In my experience, it's a tool of convenience and it really isn't even great there.",
              "score": 2,
              "created_utc": "2026-01-23 14:41:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1bexvc",
                  "author": "dazedmusiclover",
                  "text": "What other resources would you recommend instead?",
                  "score": 1,
                  "created_utc": "2026-01-23 21:49:55",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o18w93q",
          "author": "mkmrproper",
          "text": "Hey AWS, nice try.",
          "score": 7,
          "created_utc": "2026-01-23 14:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17xbyq",
          "author": "HighlightFrosty3580",
          "text": "Athena/Redshift/Glue. Fucking hate them all",
          "score": 11,
          "created_utc": "2026-01-23 11:20:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o18e1di",
              "author": "titos_and_mojitos",
              "text": "Athena is good from my experience.\n\nRedshift is steaming shit. Literally try any other data warehouse solution and theyâ€™re all light years ahead of Redshit. Weâ€™d get random segfaults and assertion errors WITH NO CONTEXT.",
              "score": 19,
              "created_utc": "2026-01-23 13:16:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1azf97",
                  "author": "DoINeedChains",
                  "text": "> Athena is good from my experience.\n\nPresto/Trino are good.  Athena is just a wrapper around those that doesn't give you access to the underlying engine",
                  "score": 1,
                  "created_utc": "2026-01-23 20:37:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18a03q",
              "author": "vxd",
              "text": "Athena is great.",
              "score": 27,
              "created_utc": "2026-01-23 12:51:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o182jih",
              "author": "pazarr",
              "text": "Don't forget DMS. Absolutely unreliable. I have found critical bugs they are unable to solve and gaslighting me for half a year now. Memory leak forces me to restart CDC daily basis, otherwise it crashes every night.It's just the tip of the iceberg. Not production ready.",
              "score": 12,
              "created_utc": "2026-01-23 12:00:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o18dpwf",
                  "author": "titos_and_mojitos",
                  "text": "Oh my god managing DMS was horrendous. We also were constantly restarting tasks, sometimes they would just â€œpeter outâ€ and do nothing (with no easy way of alerting!)\n\nI hope AWS really improves this shite software soon, it could be so useful.",
                  "score": 7,
                  "created_utc": "2026-01-23 13:14:10",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o18321u",
                  "author": "HighlightFrosty3580",
                  "text": "Never used it but I can imagine. Think all AWSs data tools are shit. QuickSight more like QuickShite",
                  "score": 3,
                  "created_utc": "2026-01-23 12:04:36",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o19lps9",
                  "author": "AWSSupport",
                  "text": "Hi there.\n\nApologies for the experience you've shared.\n\nIf you happen to have a support case, share it via chat message with additional details, so we can pass this along to our internal teams.\n\n\\- Elle G.",
                  "score": 1,
                  "created_utc": "2026-01-23 16:48:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o18d67i",
              "author": "yourparadigm",
              "text": "Going to have to disagree with you on Athena. Some much cheaper to store our logs in S3, but still have them queryable. Sick of paying crazy expensive vendors just to search logs occasionally.",
              "score": 9,
              "created_utc": "2026-01-23 13:10:58",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19ctp6",
              "author": "Ok_Whole_1665",
              "text": "I find Athena as a service very useful in a lot of use cases.",
              "score": 5,
              "created_utc": "2026-01-23 16:08:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o18ujr9",
              "author": "preinheimer",
              "text": "I hate athena's documentation, but I love the service.",
              "score": 3,
              "created_utc": "2026-01-23 14:43:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19s8ig",
              "author": "AntDracula",
              "text": "> Redshift\n\nAHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH",
              "score": 2,
              "created_utc": "2026-01-23 17:18:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19eo38",
          "author": "CheekkyNandos",
          "text": "App Runner - Itâ€™s handy for a quick PoC, but the limitations are frustrating.",
          "score": 2,
          "created_utc": "2026-01-23 16:17:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19xin2",
              "author": "nekokattt",
              "text": "Last I checked it capped apps at 100 concurrent calls, is that still the case?",
              "score": 1,
              "created_utc": "2026-01-23 17:43:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19z095",
          "author": "Dej28",
          "text": "SES, because you have to do 3 backflips and spin around three times when the moon is a waning gibbous to get approval, and then it's still more of a pain in the ass than just using another provider",
          "score": 2,
          "created_utc": "2026-01-23 17:49:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1af1lf",
          "author": "saleableautumn5",
          "text": "The worst I've ever used is AWS Managed Workflows for Apache Airflow. \n\nExpensive and if you make it VPC only it becomes a nightmare to configure. I actually gave up on it after a week of trying and got self hosted running in half a day.",
          "score": 2,
          "created_utc": "2026-01-23 19:01:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ah6i0",
              "author": "AWSSupport",
              "text": "Sorry to hear about that experience with AWS Managed Workflows for Apache Airflow.\n\nIf you're interested in sharing ways that we can improve, feel free to submit your feedback these ways: http://go.aws/feedback. \n\n\\- Aimee K.",
              "score": 1,
              "created_utc": "2026-01-23 19:11:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o19ff6x",
          "author": "adamousg",
          "text": "Bedrock Agents",
          "score": 1,
          "created_utc": "2026-01-23 16:20:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ashwe",
          "author": "Avocado_Infinite",
          "text": "Appstream",
          "score": 1,
          "created_utc": "2026-01-23 20:04:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bf2js",
          "author": "Fyunculum",
          "text": "Transfer Family is my personal pet peeve.",
          "score": 1,
          "created_utc": "2026-01-23 21:50:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkwt8",
          "author": "Bad_Runner",
          "text": "CodeCommit, lack of features, bad performance",
          "score": 1,
          "created_utc": "2026-01-23 22:18:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c6pcc",
          "author": "tonybenbrahim",
          "text": "Elastic beanstalk and aws batch, or any abstraction over ECS. It's a beginner s trap, and actually harder than ECS over time",
          "score": 1,
          "created_utc": "2026-01-24 00:12:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1cengz",
          "author": "_chrisdunne",
          "text": "Audit Manager was pretty shit when I tried it a few years ago.",
          "score": 1,
          "created_utc": "2026-01-24 00:55:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o188hro",
          "author": "jkz88",
          "text": "CodeBuild and CloudFormation",
          "score": -2,
          "created_utc": "2026-01-23 12:41:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18cx5j",
          "author": "Perryfl",
          "text": "RDS is overpriced... your not really getting a managed service just a configured one...\n\nEC2 you are paying 6 to 8 times the what it should cost to rent a dedicated server and your on essentially a glorified VPS.\n\nPremium support... cool i get to talk to a jr engineer in pakistan....\n\ncognito... 1 it sucks but its also expensive and auth is actually very easy to roll on your own...\n\nto not be too negative some great serives: sqs, sns, ses, eventbridge",
          "score": -9,
          "created_utc": "2026-01-23 13:09:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19yb07",
              "author": "blooping_blooper",
              "text": "If you hate AWS support you should try Azure, where they will tell you you're wrong because <insert answer they quoted from copilot>.",
              "score": 1,
              "created_utc": "2026-01-23 17:46:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18vhe9",
          "author": "Dear-Walk-4045",
          "text": "Bedrock. It basically only works in us-east-1 for many of the features and the requests per minute rate limiting is low. Getting the limits raised is not easy. It will probably be better in a year or so.",
          "score": 0,
          "created_utc": "2026-01-23 14:47:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19mhod",
          "author": "hudvin",
          "text": "Lambda. Extremely useful for handling spike loads, but for generic use cases itâ€™s a pain in the ass when it comes to deployment, development, and debugging.",
          "score": -6,
          "created_utc": "2026-01-23 16:52:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o19ref6",
              "author": "Gasp0de",
              "text": "Why is it more painful than any other service? We deploy via terraform, log to Loki. You can even run lambdas locally to debug them.\n\n\nEspecially for interfacing with queues such as Kinesis or SQS I find it much easier than running code yourself that keeps Kinesis checkpoints etc.",
              "score": 2,
              "created_utc": "2026-01-23 17:14:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o19pue0",
              "author": "Straight_Waltz_9530",
              "text": "CDK",
              "score": -1,
              "created_utc": "2026-01-23 17:07:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17myia",
          "author": "ducki666",
          "text": "Any. Why should I use it if not necessary?",
          "score": -13,
          "created_utc": "2026-01-23 09:49:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o190w4y",
          "author": "KayeYess",
          "text": "I would add R53 ARC (Application Recovery Controller) to the list. It is a complicated and expensive service that AWS pushed to customers because of limitations with R53 Contol Plane.\n\n\nAWS recently announced HA for R53 Public Hosted Zone control plane but with a 1 hour SLA, it's does not meet requirements for most enterprises.",
          "score": 0,
          "created_utc": "2026-01-23 15:14:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o197f7n",
              "author": "x86brandon",
              "text": "I would argue most enterprises don't have the software proficiency to use ARC or have multi-region redundancies.  A lot of software that is bought simply doesn't have the architecture to support multi-region active/active.  AWS isn't geared towards Enterprise, it's geared towards tech companies, which at this point, have considerably more infrastructure than your average F500 \"enterprise\".   Being able to recover on the other side of the country in under an hour surviving a control plane failure would be a dream come true for most.\n\nI'm not aware of another DNS provider that isn't single control plane design.  Cloudflare, etc.  Amazon's ability to guarantee a DNS control plane failover in under an hour is unique and a step up above anyone else.   Remember, this isn't a region redundancy, R53 is any cast globally.  This is so if the R53 control plane has issues, you can fail over to a secondary control plane of R53.",
              "score": 2,
              "created_utc": "2026-01-23 15:44:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o190ame",
          "author": "yarrowy",
          "text": "Aws",
          "score": -7,
          "created_utc": "2026-01-23 15:11:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17k034",
          "author": "elchicodeallado",
          "text": "API Destination, Bedrock, Step Function HTTP Task so literally every AWS managed service",
          "score": -16,
          "created_utc": "2026-01-23 09:21:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o182i59",
              "author": "curiousEnt0",
              "text": "Why Bedrock?",
              "score": 5,
              "created_utc": "2026-01-23 12:00:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o17kr08",
              "author": "ApprehensiveBar7701",
              "text": "Canâ€™t even argue. Use them when they solve a real problem, not just because they exist.",
              "score": 1,
              "created_utc": "2026-01-23 09:28:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o17rr14",
                  "author": "elchicodeallado",
                  "text": "not even sure why it got so many downvotes, people here probably donâ€˜t use these services in scale, but I faced only issues with those mentioned. With managed services I donâ€™t refer to lambda, dynamo etc. but with those higher level wrapper services AWS often build and then dont iterate on",
                  "score": 4,
                  "created_utc": "2026-01-23 10:33:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhutpm",
      "title": "If a person spends a billion dollars and buys all the compute on EC2 for today, what happens to the rest of the people requesting it?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "author": "PrestigiousZombie531",
      "created_utc": "2026-01-20 07:40:30",
      "score": 38,
      "num_comments": 69,
      "upvote_ratio": 0.76,
      "text": "- Just an honest question / showerthought, whatever you want to call it",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qhutpm/if_a_person_spends_a_billion_dollars_and_buys_all/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0mpzwk",
          "author": "Murky-Sector",
          "text": "Amazon would still limit your capacity. They would looove to setup all kinds of dedicated capacity just for you though, which you could use with wild abandon. For a price of course.",
          "score": 116,
          "created_utc": "2026-01-20 07:46:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mscs4",
              "author": "katatondzsentri",
              "text": "This. We actually use \"aws assisted capacity reservations\" which basically means they deployed a few racks with servers in the AZ we needed it.",
              "score": 29,
              "created_utc": "2026-01-20 08:07:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rgst7",
                  "author": "x86brandon",
                  "text": "Those aren't even deploying racks, that's just earmarking things in the scheduler.   Their large customers have earmarked fleet allocations and don't run into the same capacity problems as most.  And when you get big enough, you stop fussing with reservations, etc and just get a fixed EDP discount across all services and you generally will never see an unavailable error.  From experience anyways.",
                  "score": 12,
                  "created_utc": "2026-01-20 23:49:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0rgcuz",
              "author": "x86brandon",
              "text": "You don't need dedicated capacity.   Amazon simply limits spend in incremental amounts as a credit risk management.  Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.",
              "score": 7,
              "created_utc": "2026-01-20 23:47:21",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rlypo",
                  "author": "Murky-Sector",
                  "text": ">Brand new customer isn't going to spend $10 million in their first month without a conversation with finance, conversion to terms, etc.\n\nI think its hysterical youre taking such great pains to analyze a hypothetical question about spending $1,000,000,000 on EC2. But ok.",
                  "score": -8,
                  "created_utc": "2026-01-21 00:17:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mpmrf",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 86,
          "created_utc": "2026-01-20 07:42:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0oikm4",
              "author": "yarenSC",
              "text": "This would only be if somehow the account had gotten infinite quotas approved, which wouldn't be the case",
              "score": 10,
              "created_utc": "2026-01-20 15:28:16",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0rftzz",
                  "author": "x86brandon",
                  "text": "Depends on the relationship, I have no limits on my accounts, but that's a 10 digit account spend.",
                  "score": -1,
                  "created_utc": "2026-01-20 23:44:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sjhbi",
              "author": "mr_jim_lahey",
              "text": "Kind of moot given account limits/quotas, and that the question is more generally about \"all the compute\", but I think it's possible AWS could provision a billion dollars' worth of on-demand instances in a single (major) region, assuming they were somewhat spread across instance types. Certainly they could accommodate it easily if spread across multiple regions. They have an unfathomable amount of capacity. $1B is like 1% of their ARR.",
              "score": 1,
              "created_utc": "2026-01-21 03:28:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqkhb",
          "author": "casce",
          "text": "It happens occasionally that AWS temporarily runs out of specific instance type in specific regions.\n\nWhat happens is you can't deploy new ones in that case but your running stuff is fine. Just don't stop and start it or you might be unable to start it again.\n\nThe same would happen if someone literally requested all of AWS' instances without AWS stopping them. AWS would most certainly stop them though (wouldn't be worth it to anger ALL other customers).",
          "score": 13,
          "created_utc": "2026-01-20 07:51:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w28xt",
              "author": "look_of_centipede",
              "text": "If you need to stop/start it, a brief capacity reservation can prevent someone from sniping it out from under you.",
              "score": 1,
              "created_utc": "2026-01-21 17:31:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mq6ph",
          "author": "No_Pomegranate7508",
          "text": "Reminds me of another similar question: \"Would you still love me if I were a worm?\"",
          "score": 25,
          "created_utc": "2026-01-20 07:47:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mpp3u",
          "author": "soundman32",
          "text": "The people who really need have paid for reserved instances for years ahead.",
          "score": 11,
          "created_utc": "2026-01-20 07:43:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0mq8ke",
              "author": "Tall-Reporter7627",
              "text": "Like....if they bought a Dell server and stuffed it in their own rack, but at twice the cost?",
              "score": 4,
              "created_utc": "2026-01-20 07:48:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0mqxsu",
                  "author": "Loko8765",
                  "text": "No. AWS allows you to reserve instances in advance. You actually pay a lower price, but of course you commit to the duration. If you know you will use it, it is win-win.",
                  "score": 8,
                  "created_utc": "2026-01-20 07:54:43",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0u47g2",
                  "author": "SlinkyAvenger",
                  "text": "More like two ISPs, two gateways, four switches, four firewalls, eight servers, two power connections, and two generators",
                  "score": 2,
                  "created_utc": "2026-01-21 11:14:48",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0msv40",
                  "author": "mba_pmt_throwaway",
                  "text": "2x the cost of a server isnâ€™t bad, actually. Just the ops overhead maintaining the servers + DC costs could cost more than the raw server costs. Ofc at a certain scale the math tips back in favor of self managing, but for most customers 2x would be great value.",
                  "score": 3,
                  "created_utc": "2026-01-20 08:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0nc08x",
              "author": "pint",
              "text": "yes, because, you know, there are no use cases where you need ephemeral instances. none.",
              "score": 1,
              "created_utc": "2026-01-20 11:09:35",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0rh9ji",
              "author": "x86brandon",
              "text": "However, their billion dollar customers just get a flat discount and don't deal with this stuff at least.  EDP ends up being a revenue commitment and a flat discount off list without dealing with the micro managing of instance types, etc.",
              "score": 1,
              "created_utc": "2026-01-20 23:52:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0w31oe",
              "author": "look_of_centipede",
              "text": "Capacity reservations generally don't tie to long term cost, cost reservations generally don't reserve capacity.  There are edge cases but they're rare.",
              "score": 1,
              "created_utc": "2026-01-21 17:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mqm02",
          "author": "vacri",
          "text": "System isn't set up for putting on that much compute at once - you'll run into Limits, and you're not going to be able to set them particularly high without satisfying AWS\n\nAssuming that it was all prepped beforehand and they could buy up the compute power and pay double the going rate to make it worth AWS's time, AWS still wouldn't do it because the damage to the brand by taking everyone's servers off them for 1 day would have many substantial customers fleeing to other vendors.",
          "score": 7,
          "created_utc": "2026-01-20 07:51:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rh2g1",
              "author": "x86brandon",
              "text": "System is set up for a lot of load.   Credit limits are not.  :)\n\nI have launched groups of 5,000 p4.24xd's at a time.",
              "score": 2,
              "created_utc": "2026-01-20 23:51:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0sqi2q",
                  "author": "Alborak2",
                  "text": "Ive probably seen the downsteam effects of that launch lol. ML workloads move sooooo much data around.\n\nAnd yeah your other comments about limits are right. If you have the keys to the castle we'll pretty much let you run until the physical capacity is gone. Not many of those around. Our internal test accounts are unlimited and will launch thousands of instances with 20+ EBS volumes on each.",
                  "score": 1,
                  "created_utc": "2026-01-21 04:12:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mt5c1",
          "author": "FlyingFalafelMonster",
          "text": "Insufficient capacity. Happens already for GPU instances. Unless you buy capacity reservations, then even if you do not use instance it still is reserved for you.Â ",
          "score": 8,
          "created_utc": "2026-01-20 08:14:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rizzh",
              "author": "x86brandon",
              "text": "For what it's worth, east-1 is the only place I see GPU issues...  the other regions I haven't had problems with since 2021.  west-2 I have very high launch rate success.",
              "score": 1,
              "created_utc": "2026-01-21 00:01:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0vd1go",
                  "author": "nagyz_",
                  "text": "I haven't been able to reserve the p6 gb200. Does it show as reservable for you as in you get an actual time slot with a price?",
                  "score": 1,
                  "created_utc": "2026-01-21 15:38:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o10gn1t",
                  "author": "CategoryRepulsive699",
                  "text": "Try Australia",
                  "score": 1,
                  "created_utc": "2026-01-22 08:14:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qlnfz",
          "author": "ComplianceAuditor",
          "text": "You can't do that even with a billion dollars, because it would cause a lot more than a billion dollars in \"damage\" to their other customers if they suddenly have no capacity.\n\nIt's also not possible. There is no scenario ever, where AWS takes away an on demand instance from a customer just because another customer wants to use it.\n\nIdk why this is being downvoted though. Guess being curious is off limits for the internet.",
          "score": 6,
          "created_utc": "2026-01-20 21:13:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0n1m87",
          "author": "TekintetesUr",
          "text": "Unfortunately nothing, doesn't matter how hard we try. In-use on-demand capacity will not be taken away from current users. Existing reservations won't be cancelled by a higher bid. Etc.",
          "score": 3,
          "created_utc": "2026-01-20 09:34:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rg41y",
          "author": "x86brandon",
          "text": "AWS has an internal allocation mapping.  A single customer and account can't hit the entire fleet.  And also, a billion dollars at retail prices would not actually consume the entire fleet.   Their fleet is probably much larger than you might imagine.",
          "score": 3,
          "created_utc": "2026-01-20 23:46:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p4pfm",
          "author": "Quinnypig",
          "text": "The more interesting version of this question revolves around spending that billion dollars in S3 storage. There are no known quotas around that.",
          "score": 5,
          "created_utc": "2026-01-20 17:11:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0muov0",
          "author": "danizumi",
          "text": "In the AWS management console, look at the Service Quotas page, each service has hard and soft limits for each service. You should definitely be looking at these limits before putting a service into a production environment to ensure you donâ€™t hit a limit, or at least be aware of the limits.",
          "score": 2,
          "created_utc": "2026-01-20 08:29:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0nkrre",
          "author": "KayeYess",
          "text": "Quotas and other limitations will kick in long before a single customer can purchase and use even a small fraction of all the available resources.",
          "score": 2,
          "created_utc": "2026-01-20 12:18:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s2own",
          "author": "Sowhataboutthisthing",
          "text": "Nice try, Elon.",
          "score": 2,
          "created_utc": "2026-01-21 01:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0s4cjx",
          "author": "Human-Job2104",
          "text": "Service Quotas will stop them.",
          "score": 2,
          "created_utc": "2026-01-21 02:01:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vsr0s",
          "author": "FinOps_4ever",
          "text": "All of the people who purchased ODCR's to properly cover their EC2 needs will all get substantial bonuses.\n\nBut the proper answer is account limits and usage quotas.",
          "score": 2,
          "created_utc": "2026-01-21 16:48:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0thzu2",
          "author": "oscarolim",
          "text": "Billion dollars? Thatâ€™s like 5 instances for a week.",
          "score": 2,
          "created_utc": "2026-01-21 07:48:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mts6b",
          "author": "Complex86",
          "text": "This is impossible. Each family is not equal and it would be honestly really difficult for 1 person to consume 100% of instances across all zones in all regions",
          "score": 1,
          "created_utc": "2026-01-20 08:20:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rhg2n",
              "author": "x86brandon",
              "text": "Not to mention, a billion dollars probably wouldn't get you there.   :)",
              "score": 3,
              "created_utc": "2026-01-20 23:53:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0mwzk3",
          "author": "Soccer_Vader",
          "text": "If you are consuming all of the instances that aws has available at any given point, and not reserved for any internal/external use case, you are spending some developing countries gdp in a day. They would love that tho.",
          "score": 1,
          "created_utc": "2026-01-20 08:50:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oinsm",
          "author": "plaaam",
          "text": "What type of question is that :skull:",
          "score": 1,
          "created_utc": "2026-01-20 15:28:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0p0n8q",
          "author": "SpecialistMode3131",
          "text": "You can't buy it all precisely because that would be bad for Amazon's overall business, so they have limits across all services.",
          "score": 1,
          "created_utc": "2026-01-20 16:52:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ro677",
          "author": "Top-Shopping410",
          "text": "Keep getting out of capacity I guess. I had this issue when I worked for another cloud provider and we just waited for the hardware installed",
          "score": 1,
          "created_utc": "2026-01-21 00:29:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0rpzjg",
          "author": "Storage-Proper",
          "text": "They would continue to sell it",
          "score": 1,
          "created_utc": "2026-01-21 00:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0t3yg1",
          "author": "Burekitas",
          "text": "He won't be able to do that, he will need so much accounts and quota increase requests, it will take 20 years to get to that position. \n\n  \nBut if he did, people asking for EC2 will encounter issues, but in a couple of weeks AWS will fill the gap.",
          "score": 1,
          "created_utc": "2026-01-21 05:47:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tg5t0",
          "author": "suur-siil",
          "text": "They have the official quotas on your account, and all kinds of other hidden limits too.\n\nI used to have a quota of 20k across various instance-types in a fairly small region and ended up having interesting chats with AWS engineers after trying to spin up large jobs.\n\nThere's also reserved capacity for those who think ahead.",
          "score": 1,
          "created_utc": "2026-01-21 07:31:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tme95",
          "author": "alapha23",
          "text": "This happens all the time for c8g in where binance is running. And gpus as well.",
          "score": 1,
          "created_utc": "2026-01-21 08:29:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0yd3yn",
          "author": "Expensive-Virus3594",
          "text": "Rest of the people will get insufficient capacity errors. This will trigger a severity 2 incident of not a sev 1. \n\nIn reality you canâ€™t make a huge allocation due to account level caps etc.  \n\nThis issue happens in AWS time to time  when something internally breaks.",
          "score": 1,
          "created_utc": "2026-01-21 23:57:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0znyge",
          "author": "plinkoplonka",
          "text": "Nothing. It's limited by account quota.",
          "score": 1,
          "created_utc": "2026-01-22 04:26:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o10h936",
          "author": "CategoryRepulsive699",
          "text": "There are various limits including how much you can procure per second. But I do remember moving sliders in the internal UI that caused truckloads of equipment delivered into the datacenters...",
          "score": 1,
          "created_utc": "2026-01-22 08:19:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12h6t3",
          "author": "PeteTinNY",
          "text": "People get ICEâ€™d all the time.   Insufficient Capacity Error.   \n\nI helped a major broadcast network that wanted wanted to move their TV content from onprem to the cloud and we needed gpu instances.   Unfortunately there wasnâ€™t enough capacity and we had to work with the EC2 team for months to get things sorted.",
          "score": 1,
          "created_utc": "2026-01-22 16:12:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o19gopz",
          "author": "messiah-of-cheese",
          "text": "In the early early days of AWS they had intel and amd CPUs for VMs and the intel CPUs were far superior for the same price, but the CPU was allocated randomly.\n\nAn engineer found he could request a VM and check if it was intel or amd, if it was amd he would discard it and if it was intel he would hold it.\nHe ended up with all the AWS intel VMs and all everyone else could get was amd.\n\nHe talked about it at the first AWS conference and while he was talking someone from the audience working for AWS had his account banned.\n\nEdit: I believe the guy worked for github and was an early employee. We had him as a contractor at our business, he told us the story at the pub.",
          "score": 1,
          "created_utc": "2026-01-23 16:26:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0mqct9",
          "author": "lasthunter657",
          "text": "You cant buy all of them AWS have limit on how many EC2 you can have at the same time",
          "score": 1,
          "created_utc": "2026-01-20 07:49:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qiehod",
      "title": "How are you segregating AWS IAM Identity Center (SSO) permission sets at scale?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "author": "sajed8950",
      "created_utc": "2026-01-20 21:41:12",
      "score": 18,
      "num_comments": 12,
      "upvote_ratio": 1.0,
      "text": "Hello everyone,\n\nI am looking for guidance on how organizations design and manage AWS IAM Identity Center (SSO) permission sets at scale.\n\n**Context**  \nOur AWS permission sets are mapped to AD/Okta groups. Some groups are team-based and have access to multiple AWS accounts. Team membership changes frequently, and we also have users who work across multiple teams.\n\nBecause access is granted at the group level, we often run into situations where access requested for one individual results in broader access for others in the same group who didnâ€™t need or ask for it.\n\nWe also receive a high volume of access change requests. While we try to enforce least privilege, weâ€™re struggling to balance that with operational overhead and permission set sprawl.\n\n**Discussion points**\n\n* How do you structure permission sets and groups to scale without constant rework?\n* Do you use team-based, job-based, or hybrid permission sets?\n* Do you create separate groups per account + team + job role, or use a different model?\n* Do you provide birthright access for engineers? If so:\n   * What does that access look like?\n   * Is it different in sandbox vs non-prod vs prod?\n* How do you determine what access a team actually needs, especially when users donâ€™t know what permissions they require?\n* How do you manage temporary access to a permission set? Do you use cyberark sca?\n* Who approves access to permission set groups (manager, app owner, platform, security, etc.)?\n\nAny real-world patterns, lessons learned, or â€œwhat not to doâ€ stories would be appreciated.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qiehod/how_are_you_segregating_aws_iam_identity_center/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0quz2h",
          "author": "tlf01111",
          "text": "I do Identity Center at very large scale (15,000 team members,  5000+ groups, 400 aws accounts, etc.)\n\nUsing IdC in conjunction with standard fare static RBAC IAM permissions & group assignments will result in permission set sprawl at scale.   It just is what it is.     \n  \nWe use set of enterprise-wide console roles that are used for most daily access needs, but also provide account-specific permission sets which engineering teams can use to fine-grain their access if it is needed over above the standard roles.\n\nWe had to build quite a bit of custom code to automate a lot of this (based on CloudTrail events coming in from identity store), but a few years in it's working pretty well.\n\nWe also use customer managed policy references heavily to build more granularity:  With some planning you can grant differing permissions using the same permission set, depending on the target (useful for environment tiers in our case).  \n\nBut it could be better.   The next big milestone is to slowly move to an ABAC model where feasible, which should (in theory) help cut down the number of permission sets needed. \n\nAnyway if you have any specific questions feel free to ask.  I'll try to answer best I can.",
          "score": 7,
          "created_utc": "2026-01-20 21:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ub54i",
              "author": "Lazy-Bicycle-8504",
              "text": " When you say \"we\" do you talk about a whole team of x people just doing this as their daily work? Given your scale this sound like at least 1-2 seniors/architects and 3-5 juniors, is this correct?",
              "score": 2,
              "created_utc": "2026-01-21 12:08:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0y13ak",
                  "author": "tlf01111",
                  "text": "Team of three architect-level, we me doing most of the lifting, and my peer assisting.\n\n\nI have to stress we have extensive automation which handles nearly 100% of the day to day.Â  Â That automation was a six month build for this team.",
                  "score": 2,
                  "created_utc": "2026-01-21 22:53:45",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o0v7ccb",
                  "author": "AWS_Chaos",
                  "text": "This is what I came to ask. And notice it took the team \"a few years\". Meaning at scale, this isn't a one man job. the move to ABAC must be daunting.",
                  "score": 1,
                  "created_utc": "2026-01-21 15:11:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0qvhqr",
          "author": "bailantilles",
          "text": "We tend to use permission sets that are mapped to job role per account. Each job role and account is mapped to an AD group. Each AWS account has an owner, backup owner, and support group. Itâ€™s up to one of those constituencies to tell us what permissions each job role requires and who does each role. When the question arises of â€œthis person needs different access than others in their job roleâ€ we as them the question: Do we need to create a new job role for this person or do all the others in that group get the additional permission. In the end, itâ€™s up to them to keep track of all of that as they need to do user access audits quarterly for their application.",
          "score": 4,
          "created_utc": "2026-01-20 21:58:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuyca",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qxw34",
          "author": "Healthy_Gap_5986",
          "text": "It's all about defining an RBAC structure and having the discipline to stick to it. Define roles, determine what they need to do in what environments, create PermissionsSets for them then rolling them out. The roles should be enforcing your operating model. e.g.\n\nExamples.\n\nDeveloperSet\n\n* gets almost FullAccess in Dev environments only.\n* SCP whitelist only grants everyone access to specific services.\n* PermissionsBoundary prevents them from self escalating.\n\nTesterSet\n\n* Can read logs, maybe set some data sources.\n* Applies to Dev and UAT.\n\nDevOpsSet\n\n* Access to Prod. Can read logs, manage Support tickets etc.\n* No write access.\n\nAdminSet\n\n* AD group is empty and only used through an audting temporary elevation process.\n* * Prod.\n\nPlatformAdmins\n\n* Gods. Like domain admins. \n* This is you, and you don't get involved in operations. :)\n\nThe same User can be in one or more of the above roles. e.g. Developers and Testers because they are performing those roles. If someone asks for a permission that's not included in the roles above then they are often asking to circumvent the operating model, either because the model is deficient, in which case it needs fixed, or they are just cowboys. (e.g. I want to get into UAT to clickops something because our testing isn't complete and product owner is all over me).\n\nOn defining privileges. YOu tailor it to allow them to get \"quality\" work done quickly. So developers can do a lot in the dev environment, but after that we want the model encourage the maturity of the CICD. So no clickops after Dev environment. It should all be driven by CICD with testing etc all automated.",
          "score": 3,
          "created_utc": "2026-01-20 22:10:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0vuzgo",
              "author": "sajed8950",
              "text": "How many groups and accounts do you currently manage?",
              "score": 1,
              "created_utc": "2026-01-21 16:58:46",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0zv5ky",
                  "author": "Healthy_Gap_5986",
                  "text": "Tiny atm. 10 workload accounts + LZA platform accounts. Last place had 100+ accounts, pretty much the same model.",
                  "score": 1,
                  "created_utc": "2026-01-22 05:15:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qhotxo",
      "title": "Infrastructure as Software: Beyond Infrastructure as Code",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "author": "whudduptho",
      "created_utc": "2026-01-20 02:36:43",
      "score": 18,
      "num_comments": 16,
      "upvote_ratio": 0.64,
      "text": "I've been working on a topic over the last 4 years: building out infrastructure using AWS CDK through an SRE lens.\n\nBeing in the DevOps, SRE, and Platform Engineering domains, I kept asking myself why aren't all the key NFRs built into the constructs we use as golden paths? Focused on reliability and developer experience, I put together a construct library where services have cost-savings, reliability, security, and scalability baked in from the start.\n\nThis is where I want to introduce a phrase I'm calling Infrastructure as Software. The idea is that these constructs, with minimal input, can be stitched together to build fault-tolerant systems. I built this site as a forcing function to showcase what I've been working on, but more importantly it's how an SRE approaches building self-healing infrastructure.\n\nThere's still more to this project, but for now I want to introduce the philosophy of Infrastructure as Software as I continue to illustrate how these constructs work together to build autonomous systems.\n\nWould love to get the communityâ€™s input. \n\n[https://github.com/crmagz/cdk-constructs-library](https://github.com/crmagz/cdk-constructs-library)\n\n[https://thepractitioner.cloud/blog/infrastructure-as-software](https://thepractitioner.cloud/blog/infrastructure-as-software)\n\n[https://thepractitioner.cloud/guides/infrastructure-as-software/introduction](https://thepractitioner.cloud/guides/infrastructure-as-software/introduction)\n\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qhotxo/infrastructure_as_software_beyond_infrastructure/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0lppjt",
          "author": "lost12487",
          "text": "This looks like a vibe-coded [SST ](https://sst.dev/docs/examples)with your opinion of the \"golden path\" baked in. It sounds like you generally have good ideas about the topic, but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.",
          "score": 38,
          "created_utc": "2026-01-20 03:26:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0lv0i0",
              "author": "whudduptho",
              "text": "I believe you are referring to the site [https://thepractitioner.cloud](https://thepractitioner.cloud/blog/infrastructure-as-software). It uses [https://vite.dev/](https://vite.dev/). And no not vibe coded. Some of us actually know how to write software and use AI as the tool it is.\n\nThe project I'm discussing is a culmination of years of multi-region active-active systems building. If you know infra and can read code then taking a look at the constructs [https://github.com/crmagz/cdk-constructs-library/tree/main/packages](https://github.com/crmagz/cdk-constructs-library/tree/main/packages) shouldn't be an issue for you, but I don't believe you have.\n\nWhat this project offers is the same as Construct Hub but centralized, opinionated from an SRE/PE focus, and with minimal inputs needed.",
              "score": -16,
              "created_utc": "2026-01-20 03:56:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0lxtyl",
                  "author": "lost12487",
                  "text": "I'm not referring to your blog site, I'm referring to your obviously AI-generated source code.",
                  "score": 24,
                  "created_utc": "2026-01-20 04:13:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0pft5h",
              "author": "o5mfiHTNsH748KVq",
              "text": "> but there's just no way I'm letting anything with AI-generated everything anywhere near my critical infrastructure.\n\nwhy? you could always just read the code and make sure it does what you think it does. seems like unnecessary effort.",
              "score": -3,
              "created_utc": "2026-01-20 18:02:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0pkdi1",
                  "author": "lost12487",
                  "text": "Because if you don't even put in the effort to remove the completely superfluous comments that the agent adds to functions then I'm not going to put in the effort to find out where else you were lazy.",
                  "score": 7,
                  "created_utc": "2026-01-20 18:22:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0mdcaj",
          "author": "vincentdesmet",
          "text": "this topic would do much better on https://cdk.dev community channels \n\nSpecifically collaboration with OpenConstructs foundation may be interesting for you\n\nIâ€™m still stuck enabling TF teams to adopt L2, moving to L3 afterwards (my project is terraconstructs.dev and I am one of core maintainers for http://cdktn.io - the CDKTF fork)",
          "score": 8,
          "created_utc": "2026-01-20 05:59:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0lsrns",
          "author": "behusbwj",
          "text": "Havenâ€™t looked at the code, but the concept is solid and this is how the big players use CDK internally. The reason you donâ€™t see libraries often is because the observability tends to be not worth abstracting when the whole company does it one or two ways.",
          "score": 1,
          "created_utc": "2026-01-20 03:43:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ifz",
              "author": "whudduptho",
              "text": "Thanks for the feedback. I have a few nice abstractions on the roadmap that really capture the IaS philosophy of building self-healing multi-region infra. Feel free to leave any additional feedback if you get a chance to read/use the constructs.Â ",
              "score": 1,
              "created_utc": "2026-01-20 04:55:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lm2bc",
          "author": "o5mfiHTNsH748KVq",
          "text": "I like that you included skills for the repo!",
          "score": -1,
          "created_utc": "2026-01-20 03:06:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0m4ujp",
              "author": "whudduptho",
              "text": "Yes, force multiplier for sure. Iâ€™ll likely create a repo for some of these soon across TS/Go/Python and GitOps tooling.Â ",
              "score": -3,
              "created_utc": "2026-01-20 04:57:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgshy7",
      "title": "What is the value proposition of AWS MCP server?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qgshy7/what_is_the_value_proposition_of_aws_mcp_server/",
      "author": "Dry_Raspberry4514",
      "created_utc": "2026-01-19 03:00:43",
      "score": 12,
      "num_comments": 26,
      "upvote_ratio": 0.78,
      "text": "One of the tools (aws\\_\\_\\_call\\_aws) in AWS MCP server (confusing name, should have been called AWS Core MCP Server) simply takes same input as aws cli. Most the people using aws will have cli installed already and so if an MCP client has the cli command matching a prompt then it can simply invoke cli to get the job done. What is the advantage of using this tool over cli?\n\nMatching a prompt to corresponding cli command or input for aws query APIs is the main (and toughest) problem and most LLMs stuggle with it because their training data is old and web search tools used by these LLMs are not that effective.\n\nIdeally this tool should have accepted the prompt as input, use documentation search tool internally to find matching command and then return the result after executing the command.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qgshy7/what_is_the_value_proposition_of_aws_mcp_server/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0f2ghv",
          "author": "[deleted]",
          "text": "Reason: Hype\n\nBoard: \"Large companies are providing access via MCP, we need to do the same.\"",
          "score": 17,
          "created_utc": "2026-01-19 04:00:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0he0fs",
              "author": "Xerxero",
              "text": "What does it add? \nI can feed the AWS documentation to Claude and let it run api calls.",
              "score": 1,
              "created_utc": "2026-01-19 14:42:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0g4fre",
          "author": "Sirwired",
          "text": "There are more uses for MCP servers than AI Coding tools; there are a ton of AI agents that are not going to have bash access.  (And the users might not have AWS permissions at all; you can assume a role with your agent and set permissions that way.)",
          "score": 8,
          "created_utc": "2026-01-19 09:04:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gan5t",
              "author": "HiCookieJack",
              "text": "except you give them a bash MCP :D",
              "score": 3,
              "created_utc": "2026-01-19 10:03:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0gtq6i",
                  "author": "Sirwired",
                  "text": "I know you are kidding, but for those not getting the joke: AI agents that run on the web don't necessarily run in anything that has a shell prompt on it.",
                  "score": 2,
                  "created_utc": "2026-01-19 12:44:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0g4e9y",
          "author": "runitzerotimes",
          "text": "â€œCLI can handle everything, why do we need API?â€\n\nâ€œREST API can handle everything, why do we need SDK?â€\n\nâ€œScripts can handle everything, why do we need IAC?â€\n\nEvery single technology is just a different version of what came before it with QOL changes. Donâ€™t be the wanker who stands there complaining like a dinosaur about new tech â€œwhen the old way works fineâ€.",
          "score": 14,
          "created_utc": "2026-01-19 09:03:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fhsjf",
          "author": "Zenin",
          "text": "One possible reason I could think of is it seems difficult for some systems (such as Q / kiro) to safely trust specific CLI commands.  Meaning if I trust \"aws\" I'm also trusting \"rm\" because the actual tool is \"bash\".  So even if I have my aws profiles configured for safety, I still can't safely trust my agent to use it because AWS isn't actually the tool it's using, bash is.\n\nClaude Code IIRC is better about its tools having more nuance here so you can trust \"curl\" without trusting all possible CLI commands.\n\nIn these environments it may be easier to control trust with an MCP server than can be done with CLI commands.",
          "score": 3,
          "created_utc": "2026-01-19 05:47:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0h63ql",
              "author": "ObjectiveAide9552",
              "text": "Redditors: llm suck, you canâ€™t trust them to do anything right. Also Redditors: why donâ€™t you just give llmâ€™s full access to your cli?",
              "score": 3,
              "created_utc": "2026-01-19 14:00:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0fpvgy",
          "author": "VIDGuide",
          "text": "Could it be to do with permissions? The CLi needs a IAM key assigned one way or another, effectively, how is authentication to the MCP handled? I havenâ€™t looked into it, itâ€™s probably similar or IAM based anyway, but curious if it could abstract away from the IAM key completely perhaps?",
          "score": 1,
          "created_utc": "2026-01-19 06:52:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0gvzha",
              "author": "Sirwired",
              "text": "Bingo.  Assume a role with your agent service, and you don't need to hand out IAM permissions to your users at all.",
              "score": 1,
              "created_utc": "2026-01-19 12:59:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0lhjv8",
          "author": "jed_l",
          "text": "Itâ€™s a checkbox tbh. This drives usage, but once the hype train slows down, you will end up with well designed MCP servers that are not just mimics of the API. 95% of the APIs AWS offers are not directly called, a quarter are paginated, and the rest have little documentation on usage. \n\nWell designed MCP servers are not parities of the API.",
          "score": 1,
          "created_utc": "2026-01-20 02:41:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ewrey",
          "author": "Spaceman_Zed",
          "text": "I was curious as well, although I use the MCP daily, and know it works better, I couldn't quite put words to it. So please accept this through AI answer.\n\n1. Reliability & Hallucination Prevention\nLLM + CLI (The Risk): When an LLM generates a CLI command, it is guessing the syntax based on its training data. If a flag has changed, or if the model \"hallucinates\" a parameter (e.g., inventing a --force-delete flag that doesn't exist), the command fails. You then have to paste the error back to the LLM to debug.  \nAWS MCP (The Solution): The MCP server exposes defined tools to the LLM. The LLM doesn't guess the command; it selects a tool from a list of valid options provided by the server. The MCP server then constructs the correct API call or CLI command under the hood, ensuring syntax accuracy.  \n2. Context Window Efficiency\nLLM + CLI: To get an LLM to understand your infrastructure via CLI, you often have to run aws ec2 describe-instances, copy the massive JSON output, and paste it into the chat. This eats up your context window rapidly with irrelevant noise.\nAWS MCP: MCP servers are \"context-aware.\" They can fetch only the relevant resources (resources) or summarize data before sending it to the LLM. This keeps the conversation focused and prevents the model from \"forgetting\" earlier instructions due to context overflow.  \n3. Security & Guardrails\nLLM + CLI: If you give an LLM access to a terminal (e.g., via a \"bash\" tool), it effectively has the permissions of your local user. It could accidentally delete resources or upload credentials if you aren't watching every character it types.\nAWS MCP:\nLeast Privilege: You can run the MCP server with a specific, restricted AWS profile or role, independent of your main local credentials.  \nSandboxing: MCP servers can verify the \"intent\" of a command before executing it.\nRead-Only Modes: Many MCP implementations allow you to set the server to \"read-only,\" meaning the LLM can look at your S3 buckets but physically cannot execute a delete or put command, regardless of what the prompt says.\n4. Structured Data vs. Text Parsing\nLLM + CLI: CLI output is text. The LLM has to parse whitespace, tables, or raw JSON text. Complex outputs (like CloudWatch logs or deeply nested JSON) are difficult for an LLM to read reliably without formatting errors.\nAWS MCP: The protocol allows the server to pass structured objects directly to the LLM. It acts like an API integration, meaning the LLM receives clean data structures (lists, dictionaries) rather than a wall of text it has to OCR/parse.\n5. Discovery & Up-to-Date Knowledge\nLLM + CLI: The LLM's knowledge of AWS CLI commands is cut off at its training date. It won't know about a new AWS service released last month.\nAWS MCP: The MCP server is a piece of software you update. If AWS releases a new feature and you update your MCP server, the LLM immediately has access to that \"tool\" and its documentation via the protocol, even if the model itself hasn't been retrained.",
          "score": -6,
          "created_utc": "2026-01-19 03:25:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ez4c3",
              "author": "Buttleston",
              "text": "We're so cooled",
              "score": 7,
              "created_utc": "2026-01-19 03:39:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0h5llh",
              "author": "ObjectiveAide9552",
              "text": "This is absolutely correct. Reddit just has a luddite hate boner for anything generated by llm.",
              "score": 1,
              "created_utc": "2026-01-19 13:57:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0et4oy",
          "author": "rlt0w",
          "text": "This? https://awslabs.github.io/mcp/#available-aws-mcp-servers",
          "score": 0,
          "created_utc": "2026-01-19 03:05:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0eufyf",
              "author": "Dry_Raspberry4514",
              "text": "This one - [https://docs.aws.amazon.com/aws-mcp/latest/userguide/what-is-mcp-server.html](https://docs.aws.amazon.com/aws-mcp/latest/userguide/what-is-mcp-server.html)",
              "score": 1,
              "created_utc": "2026-01-19 03:12:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0euqwd",
                  "author": "rlt0w",
                  "text": "I know what MCP is, I guess I have no idea what you're asking. I use them daily and find great utility in them.",
                  "score": 2,
                  "created_utc": "2026-01-19 03:13:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qj132z",
      "title": "I made DynamoLens: FOSS desktop companion for DynamoDB",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "author": "rasjonell",
      "created_utc": "2026-01-21 15:35:32",
      "score": 9,
      "num_comments": 3,
      "upvote_ratio": 0.85,
      "text": "Iâ€™ve been building DynamoLens, a free and open-source desktop app for Amazon DynamoDB. Itâ€™s a non-Electron (Wails) desktop client that makes it easy to explore tables, inspect/mutate items, and juggle multiple environments without living in the console or CLI.\n\nHighlights:\n\n\\- Visual workflows to compose repeatable item/table operationsâ€”save, share, and replay without redoing manual steps\n\n\\- Dynamo-first explorer: list tables, view schema details, scan/query, and create/update/delete items and tables\n\n\\- Multiple auth modes: AWS profiles, static creds, or custom endpoints (DynamoDB Local works great)\n\n\\- Modern UI with command palette, pinning, and theming\n\nIf you want to try it: [https://dynamolens.com/](https://dynamolens.com/)\n\nRepo: [https://github.com/rasjonell/dynamo-lens](https://github.com/rasjonell/dynamo-lens) (free & open source)\n\nWould love feedback from folks who live in DynamoDB day to day, whatâ€™s missing or rough?",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qj132z/i_made_dynamolens_foss_desktop_companion_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0vcgsw",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o16fx3m",
          "author": "OkSadMathematician",
          "text": "nice work. wails is solid choice over electron bloat. add batch operations and you got a winner",
          "score": 2,
          "created_utc": "2026-01-23 04:04:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0vcgrk",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -2,
          "created_utc": "2026-01-21 15:35:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qis9yz",
      "title": "Service recommendation",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "author": "Artistic-Analyst-567",
      "created_utc": "2026-01-21 08:15:57",
      "score": 9,
      "num_comments": 11,
      "upvote_ratio": 0.9,
      "text": "Hello folks,\n\nLooking for recommendations for storing and searching across a large volume of data\n\nWe basically have a flattened table structure that holds around 300 million records, probably close to 50 columns\n\nWe need to provide fuzzy text search on some fields, expecting fairly high queries per second volume, and latency has to be on par with synchronous api style (200ms up to 1s)\n\nWe were initially thinking about loading the data into our RDS Aurora (MySQL, r6g.xlarge) but i never dealt with that kind of data volume and i imagine the indexes will be massive and maintenance will be painful\n\nThen i thought about Dynamodb but the fuzzy search requirement ruled that option out\n\nNow thinking OpenSearch serverless might be a good candidate\n\nAnyone worked on a similar scenario? we don't expect that table to get much updates, maybe once a month at most",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qis9yz/service_recommendation/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0tkzyh",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 08:15:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tqhx8",
          "author": "proxwell",
          "text": "This is really squarely in OpenSearch's wheelhouse.\n\nYou have a high read/query to write ratio, high QPS, infrequent updates, and need to support fuzzy text search.\n\nWhile you could do this in Aurora, I think your experience would be very unpleasant relative to OpenSearch.  With Aurora, you'd have massive fulltext indexes, slow/unpredictable index rebuilds, and performance is likely to bog down quickly under concurrent fuzzy searches.  Also, the scaling story is pretty painful, as youâ€™ll hit IOPS, buffer pool, or CPU ceilings faster than expected.\n\nI think OpenSearch serverless is the way to go in your scenario.  You'll have a little less low-level control for a couple niche tuning settings, and you'll want to do some proactive cost estimation to make sure you know what you're on the hook for, but I still think serverless is the clear winner here.",
          "score": 12,
          "created_utc": "2026-01-21 09:08:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ujx36",
          "author": "dataflow_mapper",
          "text": "your instinct is pretty solid. RDS will work on paper but at that scale the index bloat and tuning pain usually outweigh the benefits, especially for fuzzy search. DynamoDB is basically out once you need flexible text matching. OpenSearch is the tool most teams land on for this pattern, especially with mostly read traffic and infrequent bulk updates. The key is modeling the index carefully and being very intentional about analyzers so you do not blow up query latency. If the data really is mostly append or monthly refresh, reindexing is manageable. I have seen similar setups hit your latency targets as long as the queries stay scoped and you resist turning every field into a fuzzy search field.",
          "score": 4,
          "created_utc": "2026-01-21 13:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umk1i",
              "author": "Artistic-Analyst-567",
              "text": "Very insightful, will keep those recommendations in mind\nI just saw that there is a dedicated ingestion service for OS serverless (OSIS), this will come in handy since the data will probably reside in S3",
              "score": 1,
              "created_utc": "2026-01-21 13:22:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uk25w",
          "author": "solo964",
          "text": "You're storing 300m records and need to support sustained high query volumes with predictable performance, so I would say that regular managed OpenSearch could be a better option. Run the numbers but it could be more cost-effective as well as improve query latencies. Downside is the higher operational burden.",
          "score": 3,
          "created_utc": "2026-01-21 13:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0umrhk",
              "author": "Artistic-Analyst-567",
              "text": "Makes sense, it's probably worth running a couple of POCs and see what the trade-offs and cost implications are",
              "score": 1,
              "created_utc": "2026-01-21 13:24:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0tqeks",
          "author": "Horciodedayo",
          "text": "RemindMe! -1 day",
          "score": 1,
          "created_utc": "2026-01-21 09:07:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqh1c",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 1 day on [**2026-01-22 09:07:43 UTC**](http://www.wolframalpha.com/input/?i=2026-01-22%2009:07:43%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/aws/comments/1qis9yz/service_recommendation/o0tqeks/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Faws%2Fcomments%2F1qis9yz%2Fservice_recommendation%2Fo0tqeks%2F%5D%0A%0ARemindMe%21%202026-01-22%2009%3A07%3A43%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201qis9yz)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-01-21 09:08:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ve5ce",
          "author": "TechDebtSommelier",
          "text": "300 million rows plus fuzzy text search is basically OpenSearchâ€™s whole personality, so your instinct there is right. Aurora will technically work but youâ€™ll hate your life maintaining giant text indexes and still miss your latency targets once QPS ramps up. DynamoDB is a non starter for fuzzy search unless you bolt something else on.\n\nOpenSearch Serverless fits well here since your data is mostly read heavy and rarely updated, but do budget time for index tuning and shard sizing because it is not magic. If you want boring and predictable performance at that scale, search engine plus source of truth in S3 or RDS is the usual pattern, not trying to force a relational database to cosplay as a search engine.",
          "score": 1,
          "created_utc": "2026-01-21 15:43:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wnhal",
          "author": "gwinerreniwg",
          "text": "What about S3 Tables and like Athena on top or maybe OpenSearch?",
          "score": 1,
          "created_utc": "2026-01-21 19:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0tkzxv",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -1,
          "created_utc": "2026-01-21 08:15:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg8ebs",
      "title": "Principals, tags, SCPs, and ABAC",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "author": "bobaduk",
      "created_utc": "2026-01-18 13:20:11",
      "score": 8,
      "num_comments": 4,
      "upvote_ratio": 0.91,
      "text": "Hello friends.\n\nI have a reasonably complex AWS account structure with a bunch of workloads and sandboxes in an AWS Organization. I'm thinking about applying ABAC to simplify IAM setup in certain cases. For example, imagine that we have an account sandbox-bobaduk, where I have broad access for playing around. We also have an account secret-data where we store some dataset in an S3 bucket.\n\nWe use Google Workspace as our IDP, and I can apply tags to my role session based on attributes. For example, I authenticate as arn:aws:sts::$sandbox-bobaduk:assumed-role/AWSReservedSSO_MyRole_08759cec7ee3fdc9/bobaduk@org.org. Because I used sso to authenticate, I have the tag `team=data-guy` on my role session.\n\nI can write a resource policy for my s3 bucket that allows GetObject if the OrgId=myorg, and the team tag has the value \"data-guy\".\n\nSo far so good.\n\nMy question, which I'm struggling a little to answer is \"can I trust the provenance of that tag?\".\n\nMy thinking is that I can use an SCP that denies tagging a session with the \"team\" tag, unless the user is adopting a role matching \"AWSReservedSSO_*\". \n\nI should also have an SCP that prevents a user from creating a new role or user with that tag.\n\nthe AWSReservedSSO_* roles can only be created by identity centre, and the trust policy restricts their use to identity centre, so with those SCPs in place, am I missing anything? \n\nI don't need transitive tagging for role chaining, because these tags are _only_ used for this kind of cross-account access based on a resource policy. if I assume another role, I should only have the permissions granted explicitly to that role.",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1qg8ebs/principals_tags_scps_and_abac/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0aklds",
          "author": "Iliketrucks2",
          "text": "Had a long chat about just this the other day, same set of problems.  We are moving trust from fairly easy to control IAM policy to tag management.  And we want our CD system and users to set both our required tags, but any tags they want, so we need to find a way to namespace tags so we can control how those tags get modified which looks doable but a lot of work.  \n\nAWS does not make this easy, as always.",
          "score": 3,
          "created_utc": "2026-01-18 14:18:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0amoy5",
              "author": "bobaduk",
              "text": "Namespacing I have *down*, I have two sets of tags, `myorg:sso:attrib` that gets used for humans, and `myorg:cap:attrib` that gets applied to roles used in automation etc.\n\nsoo attributes are used to say \"this person is in this team, this department whatever, so they can do these things\", capability tags are used to say \"this role can do this particular set of operations\". Given the namespacing, it's easy to say things like  \n\n* \"you may never tag a session as myorg:cap:...\" \n* or \"you may never tag a role myorg:sso:...\"  \n* and \"you may only tag a session as myorg:sso:... if you're assuming an SSO role\",\n\nbut I feel ... unsafe :D",
              "score": 1,
              "created_utc": "2026-01-18 14:29:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0b0vhq",
                  "author": "Iliketrucks2",
                  "text": "Clever. We were going to do similar with corp::{secuirty|cost|access|governance|misc}::{tags} and limit with scps which role(s) can manage which tags, but we still have the omnipotent deployer role that we want to protect against while allowing to create the tags we need in each namespace.  Our concern is around a malicious user rather than an ignorant one - someone who wanted to get access to data could plan a deploy to change tags on things and circumvent our controls.  We have a human review on PR but are concerned about asking devops teams to know enough about tagging to enforce policy - we want technical controls\n\nI think for our most sensitive data we may end up using tagging but adding auditing or a hard scp with specific resources and tag values so only our security team can set/change those tags, then loosen the control and guardrails as data becomes less sensitive so we minimize impact to developers",
                  "score": 1,
                  "created_utc": "2026-01-18 15:42:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qimtwo",
      "title": "The architecture behind my sub-500ms Llama 3.2 on Lambda benchmark (it's mostly about vCPUs)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "author": "NTCTech",
      "created_utc": "2026-01-21 03:26:42",
      "score": 8,
      "num_comments": 8,
      "upvote_ratio": 0.78,
      "text": "A few days ago I posted a benchmark here showing Llama 3.2 (3B, Int4) running on Lambda with sub-500ms cold starts. The reaction was skeptical, with many folks sharing their own 10s+ spin-up times for similar workloads.\n\nI wanted to share the specific architecture and configuration that made that benchmark possible. It wasn't a private feature; it was about exploiting how Lambda allocates resources.\n\nHere is the TL;DR of the setup:\n\n**1. The 10GB Memory \"Hack\" is for vCPUs, not RAM.** This is the most critical part. A 3GB model doesn't need 10GB of RAM, but in Lambda, you can't get CPU without memory. At 1,769 MB, you only get 1 vCPU.\n\n* To get the **6 vCPUs** needed to saturate thread pools for parallel model deserialization (e.g., with PyTorch/ONNX Runtime), you need to provision **\\~10GB of memory**.\n* The higher memory also comes with more memory bandwidth, which helps immensely.\n* **Counter-intuitively, this can be cheaper.** The function runs so much faster that the total cost per invocation is often lower than a 4GB function that runs for 5x longer.\n\n**2. Defeating the \"Import Tax\" with Container Streaming.** Standard Python imports like `import torch` are slow. I used Lambda's **container image streaming**. By structuring the Dockerfile so the model weights are in the lower layers, Lambda starts streaming the data *before* the runtime fully initializes, effectively paralleling the two biggest bottlenecks.\n\n**The Results (from my lab):**\n\n* **Vanilla Python (S3 pull):** \\~8s cold start. Unusable.\n* **Optimized Python (10GB + Streaming):** \\~480ms cold start. This was the Reddit post.\n* **Rust + ONNX Runtime:** \\~380ms cold start. The fastest, but highest engineering effort.\n\nI wrote up a full deep dive with the Terraform code, a more detailed benchmark breakdown, and a decision matrix on when *not* to use this approach (e.g., high, steady QPS).\n\n[**https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/**](https://www.rack2cloud.com/lambda-cold-start-optimization-llama-3-2-benchmark/)\n\nI'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks. Is the trade-off worth it for your use cases?",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1qimtwo/the_architecture_behind_my_sub500ms_llama_32_on/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0uj87e",
          "author": "Nater5000",
          "text": ">I'm curious if others have played with high-memory Lambdas specifically for the CPU benefits on CPU-bound init tasks.\n\n\nWe ended up doing this for some image processing that was part of a REST API. Since that much memory/vCPU was overkill for the rest of the app, we ended up having to have two Lambdas with different memory configs that effectively ran the same code, with the smaller REST API Lambda calling the bigger image processing Lambda as needed. It generally worked, but was more of a headache than one would think at first glance.\n\n\nStill, interesting you managed to make this work in Lambda so effectively. I've played around with running small LLMs in Lambda with some success, so adding some of the details you mentioned might make a big difference.",
          "score": 2,
          "created_utc": "2026-01-21 13:02:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0unqzg",
              "author": "NTCTech",
              "text": "That is a perfect real-world example of this dynamic in action. Itâ€™s validating to hear you ran into the same CPU-bound constraints with image processing.\n\nRegarding the \"headache\" of splitting into two Lambdas (small router vs. big processor): I feel your pain on the operational overhead, but architecturally, **you absolutely made the right call.**\n\nThis is the classic serverless trade-off: operational complexity vs. execution efficiency. If you ran your lightweight REST API handler on that 10GB instance, youâ€™d be burning significant budget on idle vCPUs just waiting for network I/O. By decoupling them, you aligned the resource profiles to the actual work being done. It hurts to manage, but it's the correct design pattern for cost and performance.\n\nDefinitely give the container streaming setup a shot for your LLM experiments. The high vCPU count *really* shines when it can parallelize the layer download and the model deserialization simultaneously. Please let us know if you see similar gains.",
              "score": -1,
              "created_utc": "2026-01-21 13:29:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0uvv03",
                  "author": "Nater5000",
                  "text": "lol please, I really don't need the overly affirmative LLM-speak on reddit too",
                  "score": 5,
                  "created_utc": "2026-01-21 14:13:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0wo75z",
          "author": "OkSadMathematician",
          "text": "the vcpu angle is underrated. most people think of lambda memory as ram when its really a proxy for compute allocation. seen this same pattern work for build processes and data transforms where you overprovision memory just to get more cpu and end up paying less because runtime drops by 5x\n\ncontainer streaming is clever but i wonder about cache hit rates in production. if youre getting consistent traffic the warm pool keeps things fast anyway but for true sporadic workloads this makes sense. curious what your p99 looks like over a week vs just the cold start number",
          "score": 1,
          "created_utc": "2026-01-21 19:07:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0x0167",
              "author": "NTCTech",
              "text": "Yeah, the memory CPU realization is the unlock. I use that same over-provisioning trick for batch jobs now; it feels wrong to throw 10GB at a 500MB process, but the runtime speedup usually makes the pricing math work out in your favor.\n\nOn the weekly P99 question that's the real reality check.\n\nIn my testing over a week with \"choppy\" traffic (enough gaps to trigger frequent cold starts, but some sustained bursts), my weekly P99 hovered around 550msâ€“600ms.\n\nItâ€™s actually slightly *higher* than the pure cold start benchmark (480ms) because real-world noise drags it up network jitters, DynamoDB latency on the lookups, etc.\n\nIf your traffic is totally sporadic (like one request every 2 hours), your P99 is basically just going to be that cold start number every time. But in a mixed workload, the warm starts (sub-100ms) drag the average down, while the cold starts define the tail.",
              "score": 1,
              "created_utc": "2026-01-21 20:01:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o183u84",
          "author": "SameInspection219",
          "text": "I am wondering why Rust is paired with ONNX instead of llama.cpp. Is there a specific reason for this?\n\nAlso, is the 3B limit for Lambda, or could it potentially support 7B models?",
          "score": 1,
          "created_utc": "2026-01-23 12:10:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql9hn8",
      "title": "AWS IP Ranges hit 100 million IPv4 IP addresses.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1ql9hn8/aws_ip_ranges_hit_100_million_ipv4_ip_addresses/",
      "author": "seligman99",
      "created_utc": "2026-01-24 01:33:27",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Mildly interesting milestone:  AWS's ip-ranges just crossed the 100 million IPv4 IPs threshold.  They've been on an adding spree in the last few days.\n\nComplete history available in [my repo](https://github.com/seligman/aws-ip-ranges) for those that are curious.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1ql9hn8/aws_ip_ranges_hit_100_million_ipv4_ip_addresses/",
      "domain": "self.aws",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qkjl43",
      "title": "ECS anywhere cluster strategy for on prem servers",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qkjl43/ecs_anywhere_cluster_strategy_for_on_prem_servers/",
      "author": "Full_Bee_920",
      "created_utc": "2026-01-23 06:36:51",
      "score": 8,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "My company has 200+ remote locations across the country with on-premises servers running our application. These servers basically serve our customers at those locations.\n\nWe intend to containerise these applications so we can have them managed centrally using ECS anywhere.\n\nThere are some strict requirements:\n\n1. The multiple servers on that location is designed to failover to the redundant servers only on that location (not cross location)\n\nIn terms of clustering setup, what is the best approach? Should I create one cluster per location? or group all my locations as one cluster? ",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qkjl43/ecs_anywhere_cluster_strategy_for_on_prem_servers/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o18951j",
          "author": "dataflow_mapper",
          "text": "I would strongly lean toward one cluster per location given those requirements. ECS Anywhere still treats a cluster as a shared scheduling and control boundary, so putting all locations into one cluster makes it much easier for something to accidentally cross a boundary you do not want crossed. Even if you add constraints, you are fighting the model a bit.\n\nOne cluster per site keeps failure domains clean and matches how your redundancy is designed. It also makes it easier to reason about capacity, deployments, and outages when something goes wrong at a single location. The tradeoff is more clusters to manage, but that tends to be an operational problem you can automate, while cross location blast radius is harder to undo later.",
          "score": 3,
          "created_utc": "2026-01-23 12:46:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17gj93",
          "author": "TheLargeCactus",
          "text": "Sounds like distributed scada? Likely for powerplants? In my experience, you significantly reduce your blast radius and points of failure by keeping these locations isolated, so why add a layer that unifies them on purpose?",
          "score": 1,
          "created_utc": "2026-01-23 08:49:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17l0l5",
              "author": "Full_Bee_920",
              "text": "yes pretty much. the thing is we have a central HQ and dev team that handles all the in-house software development and we need a reliable way to deploy these containers to all these locations and monitor their status",
              "score": 1,
              "created_utc": "2026-01-23 09:31:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o18yri2",
          "author": "oneplane",
          "text": "I think your orchestration needs are better handled with Kubernetes, EKS Anywhere will work for that. As a bonus, you can also easily run that locally so development can get closer to deployed application semantics for a shorter dev loop.",
          "score": 1,
          "created_utc": "2026-01-23 15:03:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1722fb",
          "author": "ducki666",
          "text": "Sounds like 200+ clusters.\nNightmare",
          "score": 1,
          "created_utc": "2026-01-23 06:41:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o182op0",
              "author": "owengo1",
              "text": "It seems much better than a single cluster.  \nYou can deploy cluster by cluster, manage failed ones etc.   \nA single cluster is a catastrophe waiting to happen. The wrong container, the wrong service configuration will automatically destroy 200 locations.   \nNote also that IaC ( terraform or other ) will have no issue managing 200 clusters",
              "score": 1,
              "created_utc": "2026-01-23 12:01:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o17dyfs",
          "author": "LemmyUserOnReddit",
          "text": "One k8s cluster",
          "score": 0,
          "created_utc": "2026-01-23 08:25:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18h4vh",
          "author": "aviboy2006",
          "text": "To decide your strategy, think about it using these two models:\n\n**thought model (how you organise)** imagine each location is a **small shop**.\n\n**- one cluster per location:** it is like having 200 different managers. it is very safe, but hard to talk to all of them at once.\n\n**- one big cluster:** like one manager for 200 shops. it is easy to manage, but if the manager gets sick, every shop stops.\n\n**- the middle path:** group shops into **districts**. maybe 10 clusters of 20 sites each. it is easier to manage, and if one district has a problem, the others stay safe.\n\n**Decision model (how you act local)** to follow your rule of \"local failover only,\" use **labels**. think of it like a **delivery truck**:\n\n\\- even if 10 shops are in one district (cluster), each box has a **home address** (a location tag).\n\n\\- if a shelf breaks in shop a, the box stays in shop a. it does not go to shop b because the address label does not match.\n\n**how to make your choice:**\n\n\\- check your team size: if you have a small team, \"200 managers\" (200 clusters) will break your workflow.\n\n\\- check your risk level: if \"one big cluster\" feels scary because a mistake kills everything, move toward the \"district\" model.\n\n\\- check compliance: sometimes the number of clusters depends on what compliance or security rules you need for each location. if one site needs different rules, it might need its own cluster.\n\nTrust the labels: remember that the cluster is for your management ease, but the label is what enforces your local failover rule.",
          "score": 0,
          "created_utc": "2026-01-23 13:33:14",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh10yo",
      "title": "AWS S3 Batch Replication (operation: replicate). Both buckets are versioned. What happens on object key collision?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "author": "IceAdministrative711",
      "created_utc": "2026-01-19 10:48:50",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 0.89,
      "text": "**Context**  \nI configure [S3 Batch Operation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html) (to replicate existing objects). Manifest is generated automatically and includes all objects. Both buckets are versioned. Batch Job is configured based on existing (Live) replication configuration.\n\n**Question**  \nI know that both buckets have one object with the same key but different versions. Which version will become current? Is there any documentation on that matter?\n\n\\---\n\n**PS**  \nI observed 2 behaviours:\n\n1. source object's version becomes current version in the Destination Bucket\n2. The Destination object version remains current while source object version is added to the non-current versions in the Destination Bucket\n\nI can only assume that it depends on \\`last modified\\` date and the newest version (be it source or destination) wins",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qh10yo/aws_s3_batch_replication_operation_replicate_both/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0hiji7",
          "author": "SpecialistMode3131",
          "text": "I think you're right about what will happen.\n\nMore importantly, you should change your system so this is never even an issue.  Just get rid of this problem.  There is no way this kind of complexity is benefiting you, and you will be able to eliminate it with some thought.",
          "score": 3,
          "created_utc": "2026-01-19 15:05:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0huxs1",
          "author": "menge101",
          "text": "Completely agree with /u/specialistmode3131 , this seems like an [XY problem](https://xyproblem.info/) as well.  \n\nWhat is it you are trying to do?",
          "score": 2,
          "created_utc": "2026-01-19 16:03:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj44kp",
      "title": "Does AWS close accounts for lack of use?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qj44kp/does_aws_close_accounts_for_lack_of_use/",
      "author": "mntgoat",
      "created_utc": "2026-01-21 17:24:33",
      "score": 6,
      "num_comments": 14,
      "upvote_ratio": 0.65,
      "text": "I got an email this morning saying my account is closed. This is a personal account that I don't use. I think I created it years ago. I do use my business account but that is a different account. The last email prior to this from AWS was 2022. Could it have been closed because of lack of use? \n\n\n\n>This e-mail confirms that the Amazon Web Services account associated with account ID XXXX is permanently closed and cannot be reopened. Any content remaining in this account is inaccessible and will be erased.\n\n>  \n",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qj44kp/does_aws_close_accounts_for_lack_of_use/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0w7s4i",
          "author": "xxwetdogxx",
          "text": "Most likely you had something running, and at some point you got a new credit card- after failing to bill the old card AWS shut down the account for non-payment. AWS doesn't shut down accounts simply due to lack of use.",
          "score": 23,
          "created_utc": "2026-01-21 17:55:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wart0",
              "author": "mntgoat",
              "text": "It could be but I don't have any emails from them.\n\nI do remember I used have a charge of cents per month a while ago but I think I shut that down.",
              "score": 2,
              "created_utc": "2026-01-21 18:08:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w1jz2",
          "author": "DarthKey",
          "text": "No.",
          "score": 7,
          "created_utc": "2026-01-21 17:28:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0w5iml",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear about your AWS account being closed. You can fill out the following form to contact our Support team for assistance with this: go.aws/account-support. \n\n\\- Gee J.",
          "score": 2,
          "created_utc": "2026-01-21 17:45:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wahwm",
              "author": "mntgoat",
              "text": "I did but they told me they couldn't help me without logging in but when I log in I just get message that it is closed and when I click on support it asks me to log in again.",
              "score": 5,
              "created_utc": "2026-01-21 18:07:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w2ipq",
          "author": "seanv507",
          "text": "I'm pretty sure the same thing happened to me.",
          "score": 1,
          "created_utc": "2026-01-21 17:32:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1054g1",
          "author": "Every-Barracuda-320",
          "text": "Billing billing... I have an AWS account I haven't used for 10 years and it's still active. They don't close accounts like that unless you don't pay. It could be just a few cents but if not paid, it can cause them to close the account but they sent many warnings before they do it.",
          "score": 1,
          "created_utc": "2026-01-22 06:33:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15ku8i",
              "author": "gadgetvirtuoso",
              "text": "I use SES personally and my bill is often just $0.01 many months and they never actually charge me. I donâ€™t know what the actual threshold is but Iâ€™d guess more than $1 otherwise they lose money on the CC processing fees.",
              "score": 1,
              "created_utc": "2026-01-23 01:08:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o161w03",
                  "author": "Every-Barracuda-320",
                  "text": "Same here. I had many of these $0.01 monthly bills but they were never charged. \n\nSometimes people miss services in other region. My previous company was getting high bills but they couldn't see many services to justify it. I went on exploring. They had a bunch of EC2 running in Singapore region. They were started months ago and forgot about them as they don't usually use that region./",
                  "score": 1,
                  "created_utc": "2026-01-23 02:43:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o121pb8",
          "author": "wesleyaplix",
          "text": "AWS generally doesnâ€™t close accounts *just* for inactivity. The fact that the email says â€œpermanently closed and cannot be reopenedâ€ makes it sound more like an internal compliance or billing trigger than simple lack of use.",
          "score": 1,
          "created_utc": "2026-01-22 15:00:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0wjr8q",
          "author": "AWSSupport",
          "text": "Hi there, \n\nThanks for the quick follow up. Could you chat message us your case ID? We can provide your feedback to our Support team, and let them know about your case. \n\n\\- Gee J.",
          "score": -4,
          "created_utc": "2026-01-21 18:48:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wrfn7",
              "author": "mntgoat",
              "text": "Sure thing. Thanks.",
              "score": 2,
              "created_utc": "2026-01-21 19:22:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0x1yh5",
                  "author": "AWSSupport",
                  "text": "Hi Carlos, \n\nThanks for sending us your case ID. We're unable to discuss account details over social media for security purposes. I recommend working with our Support team on your support case for additional assistance. \n\n\\- Gee J.",
                  "score": -10,
                  "created_utc": "2026-01-21 20:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0w9lux",
          "author": "SoggyGrayDuck",
          "text": "They shut off access to ec2, you just have to change the root password and put a ticket in.\n\nEdit: I didn't read the whole comment, you must have waited longer than I did.",
          "score": -9,
          "created_utc": "2026-01-21 18:03:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi650u",
      "title": "How do you keep system context from rotting over time?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "author": "kennetheops",
      "created_utc": "2026-01-20 16:43:17",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 1.0,
      "text": "Former SRE here, looking for advice.\n\nI know there are a lot of tools focused on root cause analysis after things break. Cool, but thatâ€™s not whatâ€™s wearing me down. What actually hurts is the constant context switching while trying to understand how a system fits together, what depends on what, and what changed recently.\n\nAs systems grow, this feels like it gets exponentially harder. Add logs and now youâ€™ve created a million new events to dig through.. Add another database and suddenly youâ€™re dealing with subnet constraints or a DB choice thatâ€™s expensive as hell, and no one noticed until later. Everyone knows their slice, but the full picture lives nowhere, so bit rot just keeps creeping in.\n\nThis feels even worse now that AI agents are pushing a ton of slop ..i mean code and config changes quickly. Things are moving at lightspeed, I cant be the only one feeling like my understanding is falling behind daily.\n\nIâ€™m honestly stuck on how people handle this well in practice. For folks dealing with real production systems, whatâ€™s actually helped? Diagrams, docs, tribal knowledge, tooling, something else? ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qi650u/how_do_you_keep_system_context_from_rotting_over/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0p00z3",
          "author": "SpecialistMode3131",
          "text": "You need to write real documents (preferably outside the codebase, as in wiki type environments) that pull together the business reasons for the system to exist, alongside the high level code decisions that were made.\n\nThere's a lot of different schools of thought - for example, my claim that putting docs outside the codebase is good will be disputed by some - but end of the day you cannot use a tool to skip taking the time to thoroughly describe your intent in laying out the systems as they exist now.\n\nDocs rot, too, so a dedicated hunk of time every week, month, etc to sweep your core foundational documents to ensure they're up to date is critical to keeping important stuff well understood and running.\n\nOnly you can decide if you have the will to do so - if it's important enough.  Just remember you reap as you sow.\n\nWhen I deliver for clients, I always leave behind a thorough high level documentation base for future maintainers, and when I am given existing legacy systems to deal with, building synthesis is the first order of business.",
          "score": 3,
          "created_utc": "2026-01-20 16:49:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p0yso",
              "author": "kennetheops",
              "text": "I like the idea of having the docs outside of the code base. \n\nWhat are you doing to capture info said in chat threads? Or do you assume this as a just a losing battle?",
              "score": 1,
              "created_utc": "2026-01-20 16:53:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0p1onv",
                  "author": "SpecialistMode3131",
                  "text": "Human beings are present in chat threads. Hold them accountable to putting the important content they learn down in the docs in a good way.  Make keeping docs in good shape part of their evaluation criteria at review time.\n\nThere is a tendency in tech to try and make everything a tool. When work requires judgment, as in documentation, that's a big mistake and it leads to a completely predictable decaying useless mess. Just refuse to make that mistake, and require human beings to own the documentation fully.  And keep the documentation high level so it doesn't become a burden.",
                  "score": 1,
                  "created_utc": "2026-01-20 16:57:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0p58ws",
          "author": "oneplane",
          "text": "What's helped is having responsibilities tied together, i.e. a change in some IaC is done for a reason, and depending on the size and complexity that reason (or intent) needs to be in the code, in the docs along side the code, in the global system docs or in business docs, or a mix of all of them.\n\nIn theory with static systems you'd be tracing from a business need to a functional need to a technical need to a requirement to a design to an implementation. In reality that doesn't really work out very often, but what you can do is apply the same rules as you'd do in namespaces/modules/packages/boundaries, things that only matter very close to the technical 'thing' and don't spill over into other areas (outside of its own boundary) would be in your commit message, code comments, or repository docs for example. You'd have to have rules and processes in place to not merge code that doesn't have an intent described and attached to it.",
          "score": 1,
          "created_utc": "2026-01-20 17:13:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0pezrs",
              "author": "kennetheops",
              "text": "Is this a process or do you use a tool for this?",
              "score": 1,
              "created_utc": "2026-01-20 17:58:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0pzasq",
                  "author": "oneplane",
                  "text": "We use Atlantis, OPA and a custom coverage tool to only allow a Terraform apply if coverage on the PR is over 90%, we're experimenting with doing more in a workflow pipeline but it's mostly an optimisation rather than a change in features.\n\nSimilar results can be achieved with pre-commit.",
                  "score": 1,
                  "created_utc": "2026-01-20 19:30:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0panru",
          "author": "dr_barnowl",
          "text": "Descriptive code.\n\nThe slopcode is a problem for this approach.\n\nWrite abstractions that help you comprehend things. That's basically what all code is once you stop writing raw machine code as byte values into memory.\n\nOnce I get a project started, I don't write a VPC by writing all the little ins and outs. I have a module. I say \"this is VPC #23, it's for this\". The code works out the CIDR blocks from the VPC number, and the module has a standard structured output that application modules expect to see, that describes the available subnets, etc. I just pass this output to the application module which is written to use it.\n\nLook at the top and you can see a VPC, an application, a link of the VPC to the transit gateway. Dig down and you can see the detail, which you make as consistent as possible so it's understandable.\n\n(NB CloudFormation sucks at this, Terraform is much better).",
          "score": 1,
          "created_utc": "2026-01-20 17:38:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0peupd",
              "author": "kennetheops",
              "text": "we are doing this for infra, but how are you tracking code dependencies  to infra resources? For example say we have 2 dbs but 1 db is dev and the other is prod, and 10 vms. Obviously the prod vms have a higher risk for changes than the dev vms.",
              "score": 1,
              "created_utc": "2026-01-20 17:58:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0qf9db",
                  "author": "dr_barnowl",
                  "text": "Prod vs dev my choice would always be account separation ; setting up cross-account deployment involves some extra work, but in an ideal world, no dev has access to production resources. The clearest way to ensure this is to ensure they have no access to entire accounts.",
                  "score": 1,
                  "created_utc": "2026-01-20 20:44:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qh1n3l",
      "title": "SESv2 migration",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "author": "sloveubagukaraliui",
      "created_utc": "2026-01-19 11:23:20",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Hi, I use terraform to manage aws deployments. \n\nSes is deployed using v1 api and now I want to migrate to v2. \n\nWhat are the steps? \n\nDo I destroy v1 resources first and deploy v2? \n\nwhat happens with dkim dns set up, would I need to configure new entries? \n\nI cant have any downtime, emails are a super critical part of our business. Switching to some other domain is not suitable due to need for warmup that can take up to 2 months. ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qh1n3l/sesv2_migration/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0gmwiv",
          "author": "CSYVR",
          "text": "They are the same resources, just with different APIs to configure them.\n\nYou can add the v2 resources and run imports gradually, there's not even a huge problem managing the two resources at the same time, as long as you're not making any changes.\n\nAlternative is just deleting the v1s from the state (terraform state rm <resourceid>) and importing the new ones (e.g.  terraform import aws\\_sesv2\\_email\\_identity.example [example.com](http://example.com) )",
          "score": 4,
          "created_utc": "2026-01-19 11:52:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jvjrr",
              "author": "sloveubagukaraliui",
              "text": "wait what\n\nare you saying that I should be able to create a v2 resource using the same domain alongside to an existing v1 domain identity?",
              "score": 1,
              "created_utc": "2026-01-19 21:34:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0jxdt7",
                  "author": "CSYVR",
                  "text": "Yes, just add and import it:\n\n    #v1 resource\n    resource \"aws_ses_domain_identity\" \"example\" {\n      domain = \"example.com\"\n    }\n    \n    #v2 resource\n    resource \"aws_sesv2_email_identity\" \"example\" {   \n      email_identity = \"example.com\" \n    } \n    \n    #Import statement for v2 resource so no new identity is created\n    import {\n      to = aws_sesv2_email_identity.example\n      id = \"example.com\"\n    }\n\nPretty simple once you get the hang of it :)",
                  "score": 2,
                  "created_utc": "2026-01-19 21:44:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0grhy6",
          "author": "shisologic",
          "text": "You can test the migration from ses v1 to ses v2.\n\nIf you can't create v1 using terraform, you can deploy it via AWS CLI ses (not sesv2).",
          "score": 1,
          "created_utc": "2026-01-19 12:28:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1clcuw",
          "author": "jsonpile",
          "text": "Something else that may help is the ses:ApiVersion condition key: \n\nhttps://docs.aws.amazon.com/ses/latest/dg/control-user-access.html#iam-and-ses-examples",
          "score": 1,
          "created_utc": "2026-01-24 01:34:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg1udo",
      "title": "Centralized CI/CD security scanning for 30+ repos. Best practices?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "author": "_1noob_",
      "created_utc": "2026-01-18 07:06:54",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.78,
      "text": "Hi everyone,\n\nWe are currently working on integrating CI/CD security tools across our platform and wanted to sanity-check our approach with the community.\n\nWe have 30+ repositories in bitbucket and are using AWS for CI/CD. \n\nWhat we are trying to achieve:\n\n* A centralized or shared pipeline for security scanning (SAST, SCA, Container Scanning, DAST).\n* Reuse the same scanning logic for all the repos \n* Keep pipelines scalable and maintainable as the number of repos grows.\n\nThe main challenge we are facing:\n\n* Each repository has different variables for SAST (eg sonarqube) \n\nQuestions:\n\n* Is it a good practice to have one shared security pipeline/template used by all repos for scanning?\n* How do teams typically manage repo-specific variables and Sonar tokens when using shared pipelines?\n* Any real-world patterns or pitfalls to watch out for at this scale (30+ pipelines)?\n\n\n\nAgain, goal is to keep security enforcement consistent without over-coupling pipelines as possible. \n\nWould really appreciate hearing how others have solved this in production.\n\nThanks in advance.",
      "is_original_content": false,
      "link_flair_text": "ci/cd",
      "permalink": "https://reddit.com/r/aws/comments/1qg1udo/centralized_cicd_security_scanning_for_30_repos/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o09995s",
          "author": "no1bullshitguy",
          "text": "My first question would be: Why do you want it separate? Things like SAST / DAST should ideally be part of the individual application pipeline. Then only you can fail the pipeline when the code does not hit a particular baseline you set, let it be Code Quality (Sonarqube), SAST / DAST etc.\n\nNow, having said that,  I have implemented the other way also, like a Central Pipeline. The way I did is, all the fields are parametrized with fields for example Application ID for that particular application in our scan tool, Packaged Artifact URL for doing Opensource Library Scan, GIT Repo URL for downloading source for SAST ,  Branch to name a few (it has been 5 years so I dont remember most)\n\nThen the application build pipeline will trigger the scanning Job by calling REST API of CI/CD tool with above parameters filled in. Things like Artifact URL, GIT Repo URL etc would be already available as environment variables. But application ID for Scanning tool, i had to set it manually as a parameter for each pipeline (Devs will fill it, and I just had to give the template)\n\nAPI key for your Scanning tool would be most probably global key. This key can be stored as a variable in the central pipeline itself\n\nI have scaled both the above models for 1000+ pipelines. Works well, but I strongly suggest you to keep these scans and Quality gates as part of the actual build pipeline itself. It can go in parallel with rest of the stages not affecting deployment times. Because at some point, you would want to break the pipelines when code quality goes south.",
          "score": 1,
          "created_utc": "2026-01-18 07:51:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7ylt",
          "author": "XohleT",
          "text": "I am working on the same problem but for github. In our company we have 2000+ repositories and a lot of variation in pipelines due to not standardising from the start. \n\nThis makes it hard to enforce a single pipeline for everyone. If we do create one it is up to us to make sure it works for everyone which is a burden we rather not take on. \n\nSo we decided to decouple enforcement from scanning. In github we can create rulesets that require certain scanning tools to have checked the repository before a PR can be merged. We use this for enforcement while providing pipeline templates and private github actions to help implementation of scanning tools. \n\nThis makes it easier to start enforcement while not being a burden because teams can do their own implementation if ours donâ€™t work. \n\nFor scanning tools that dont integrate with github rulesets checks we have created our own tool to check if the scanning is sufficient.",
          "score": 1,
          "created_utc": "2026-01-18 12:58:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0bfrty",
          "author": "jefoso",
          "text": "I don't know if it's an approach that I'd follow. IMHO it's too late to fail.\n\nMost of these security/quality checks should happen at the left(the beginning) of the development so the earlier it fails the faster and cheaper it is to fix.\n\nI believe that: \n- developers shoulduse linters, pre-commit hooks, things that are cheaper to run and get possible issues locally \n- feature branches should also do some part of the job and execute more complex tools/scans\n \nCentralized tools should be part of the process, the company would have a release process where everyone agrees that if these integration tests or security scans fails, that feature would be removed from the release or the entire release would be blocked.\nI think this is not just about tools and how to implement them, but also how the company and teams works.",
          "score": 1,
          "created_utc": "2026-01-18 16:53:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0fbjet",
              "author": "_1noob_",
              "text": "we are also using pre-commit hooks with a decent configuration.",
              "score": 1,
              "created_utc": "2026-01-19 05:01:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0i396l",
          "author": "CodacyKPC",
          "text": "Hello, I'm Kendrick, VP of Technology at Codacy. I would say: use Codacy!\n\nWe connect to your Bitbucket directly and use webhooks to listen for changes and then scan the diff when you submit a PR. We do the scanning on our side in our cloud engine so there's no CI/CD configuration for you to have to handle. You can create multiple overlapping \"coding standards\" that can apply to whichever repositories you want, so can create e.g. a \"baseline security\" standard and a \"javascript standard\" and a \"frontend team standard\". \n\nThen you can gate merging of code into your main branch based on whether the Codacy checks passed in the PR.\n\nExtra plus: we have an IDE extension that will run the same checks locally so that by the time your devs get to the PR they should have already resolved all of the issues.\n\nExtra extra plus: the IDE extension \\_forces\\_ AI coding agents to resolve issues in their workflow, before they hand back control to the dev, so issues can get fixed without developers even knowing about them.\n\nYes, this was an advert. It still seemed relevant. Do DM me and we'll set you up with a free trial.",
          "score": 1,
          "created_utc": "2026-01-19 16:40:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg7a1g",
      "title": "Moving to CloudFormation with Terraform/Terragrunt background, having difficulties",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "author": "hardvochtig",
      "created_utc": "2026-01-18 12:24:11",
      "score": 5,
      "num_comments": 26,
      "upvote_ratio": 0.65,
      "text": "Hi all, I'm used to Terraform/Terragrunt when setting up infra and got used to its DRY principles and all. However my new company requires me to use CloudFormation for setting up a whole infra from scratch due to audit/compliance reasons. Any tips? Because upon research it seems like everybody hates it and no one actually uses it in this great year of 2026. I've encountered it before, but that's when I was playing around AWS, not production.\n\nI've heard of CDK, might lean into this compared to SAM.\n\n[](https://www.reddit.com/submit/?source_id=t3_1qg79f4)",
      "is_original_content": false,
      "link_flair_text": "CloudFormation/CDK/IaC",
      "permalink": "https://reddit.com/r/aws/comments/1qg7a1g/moving_to_cloudformation_with_terraformterragrunt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0a40s3",
          "author": "Sirwired",
          "text": "CDK generates CFn underneath, but it's still very different from TF. (CDK is a way to use Python, Java, TypeScript, JavaScript, C# and Go to generate CFn.)\n\nI have to wonder what audit reasons require them to use CFn directly.",
          "score": 22,
          "created_utc": "2026-01-18 12:29:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a4r2p",
              "author": "kei_ichi",
              "text": "All I can think is â€œno external tools other than AWS native toolsâ€ bull sh*t",
              "score": 8,
              "created_utc": "2026-01-18 12:34:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0a71m7",
                  "author": "hardvochtig",
                  "text": "Well, yes!",
                  "score": 4,
                  "created_utc": "2026-01-18 12:52:18",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0a70cm",
              "author": "hardvochtig",
              "text": "For easy drift detection and everything is managed by AWS including the state.",
              "score": 4,
              "created_utc": "2026-01-18 12:52:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0cyi21",
                  "author": "dr_barnowl",
                  "text": "The fact that you're forced to use the AWS backend of CloudFormation is likely the reasoning for this ; but there's no real reason why you can't set up a Terraform based IaC backend with the same constraints.\n\nIf you want full auditablility, the solution is the same ; log all the cloudtrail traffic and use that as the basis for any audit. The result is the same - the console, CF, and terraform, all use the same APIs.\n\nIf you want control, you have to do just as much work to do to prevent console meddling.\n\nDrift detection? TF can do that. State? You can put the state in an S3 bucket with strong controls on it.\n\nAll the attitudes preferring CloudFormation to Terraform I've seen ... seem to be rooted in dislike for the idea of programming. The only advantages CF has over TF in my book are that you have a prebuilt IaC setup, and lots of code samples. The rest ... CF is hard to grow, hard to refactor, and a PITA to modularize. And slow, because dependency graphs in CF treat stacks as an entire atomic unit, you can't update anything with an input that depends on an output until the whole stack is done.",
                  "score": 0,
                  "created_utc": "2026-01-18 21:17:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0coxcb",
              "author": "Davidhessler",
              "text": "Possibly CloudFormation Hooks / Guard. There are a lot of teams implementing controls these days using those techniques.",
              "score": 3,
              "created_utc": "2026-01-18 20:27:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a43ra",
          "author": "mrsmiley32",
          "text": "I'd go CDK and then synth the cloudformation from that for the audit purposes. CDK is much nicer to work with than cloudformation.",
          "score": 14,
          "created_utc": "2026-01-18 12:29:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a73zn",
              "author": "hardvochtig",
              "text": "So Iâ€™ve heard! Definitely the top option, aside from asking them if CF is really necessary",
              "score": 3,
              "created_utc": "2026-01-18 12:52:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0aogh8",
                  "author": "AntDracula",
                  "text": "CDK generates CF",
                  "score": 3,
                  "created_utc": "2026-01-18 14:39:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0akqjl",
          "author": "TheCamerlengo",
          "text": "I used cloud formation and code pipeline for years. I became rather proficient at it. Took a while. Itâ€™s awkward and difficult to debug when things go wrong. It taught me a lot about how AWS IAC provisioning really works. \n\nNew job uses terraform and after 1 day I never looked back. Terraform is light years easier to use but it is an abstraction. Understanding how cloud formation works helped me fill some gaps when using terraform. \n\nBasically you are going to hate cloud formation coming from terraform, but may learn something about how AWS and terraform work under the hood.",
          "score": 2,
          "created_utc": "2026-01-18 14:18:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ba0dr",
          "author": "ycarel",
          "text": "What are you struggling with?\nSince I donâ€™t know what your pain points are it is hard to give helpful tips.\nThe only high level thing I have for you is to find the tools provided by your IDE for cloud formation. It will provide auto complete, etc. \nUse cfn-nag to help catch errors. \nThink of cloud formation as a low level language where you have to be super detailed.\nWhen deploying use change sets to help you know exactly what is changing.\nAs many have recommended consider CDK as it is a higher level construct that compiles into CFN.",
          "score": 2,
          "created_utc": "2026-01-18 16:26:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0e9wwg",
          "author": "dafim",
          "text": "I'm going to get asked to leave over this opinion but here goes.\n\nTf sucks. Every new company or even department you go to has wildly different ways to do tf. You can \"learn\" tf, then move to another company and have no idea what TF is going on. There are more escape hatches in tf that it can be baffling how it even got a name for itself as iac. There is some real shit out there. It's like the little tikes learning kit for iac. In some ways it's the new perl vs python argument of \"there's more than one way to do it\" in perl vs \"there's only one way to do it\" in Python. Which I guess means in some ways it's a derivation of the (big|little) endiness argument.\n\nThe nicer thing about cf is that it's a bit more predictable (outside of using custom resources, etc) and as long as you're not naming things you can pick it up and deploy it in a similar account for dev or stage, etc. it's concept of \"state\" is the not defined by some file you need to keep track of, it's state is it and it's resources existence. It's also not as clever or fearureful as tf, which when you manage huge amounts of resources in huge amounts of stacks across huge amounts of accounts across modest amounts of departments can be a very very nice thing because you can still fit the concept in your head. And by cf I mean cdk and cf.",
          "score": 2,
          "created_utc": "2026-01-19 01:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0jukjr",
              "author": "DaWizz_NL",
              "text": "I agree with the gist of it. I do think certain specific service implementations suck a bit with CFN, as every service team is responsible for this themselves. The ChangeSets are also lacking and Drift detection is an afterthought, while on TF these are first class citizens.\n\nOther than that, TF can indeed become really messy. It's also much harder to govern from an enterprise perspective. Multi-account is also very painful when you are talking about scalable platforms with ephemeral accounts and stuff, but I think they just solved the multi-region clunkiness at least.",
              "score": 1,
              "created_utc": "2026-01-19 21:29:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0a7o8t",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-01-18 12:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0cnrff",
              "author": "TheP1000",
              "text": "Cdktf is dead last I saw.",
              "score": 1,
              "created_utc": "2026-01-18 20:21:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0aat83",
          "author": "pipesed",
          "text": "As others have pointed out, cdk is the programmatic way to compose cloud infrastructure. It does synth cfn templates, and it's code so it is as controllable and auditable as any other code. \n\nTerraform is still the most popular one we see, followed by cdk typescript.",
          "score": 1,
          "created_utc": "2026-01-18 13:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0cj098",
          "author": "oneplane",
          "text": "\\> due to audit/compliance reasons\n\nI highly doubt that is really going to 'require' CloudFormation.\n\n\\> Any tips?\n\nSadly, no. While they are both IaC tools, they are rather different in how they work and view implementation choices. Besides informing about the tech stack next time you interview at a company, there isn't much you can do as even  TFCDK (TF-to-Cfn) is dead at this point. If you are a software engineer, you can use the Cfn CDK, but unless it's some sort of useless checkbox compliance (well, most are) that might not fly.",
          "score": 1,
          "created_utc": "2026-01-18 19:58:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0f99bs",
          "author": "Dry_Raspberry4514",
          "text": "I don't understand the hate for CF. It helped us to solve the biggest problem in DevOps space -Stateless IaC.\n\nTerraform has two providers for AWS - aws and awscc. awscc uses cloud control api under the hood which in turn leverages most the stuff from CF excluding stack.\n\nIf you want support for new or updated aws resource types on day 1, you will need awscc which has dependency on CF indirectly as explained above. There have been cases in the past (and it will continue in future as well) where new aws features (e.g. regional NAT gateways) were added to aws provider after weeks when it was available in awscc provider on day 1 through AWS CC API. Unlike terraform, we use only CC API and have not seen any issue with it so far.",
          "score": 1,
          "created_utc": "2026-01-19 04:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jt505",
          "author": "DaWizz_NL",
          "text": "For platforms, I always use CFN. It's fine for Lambdas, S3, SNS, SQS, networking components, etc.. It sucks when you have to deploy a shitload of application components and ECS deployments often are painful with CFN if you don't know what you're doing.",
          "score": 1,
          "created_utc": "2026-01-19 21:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0a7wdv",
          "author": "Kitchen-Location-373",
          "text": "tbh terragrunt is way way way less DRY for me than sceptre for cloudformation. I get it's a bigger community but terragrunt always turns into spaghetti code meanwhile for cloudformation I usually have like a three line yaml config file per environment",
          "score": 1,
          "created_utc": "2026-01-18 12:58:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0a86vc",
              "author": "hardvochtig",
              "text": "For some reason this is the first time Iâ€™ve heard of Sceptre despite researching for the past 3 hours. All I keep seeing is CDK. Iâ€™ll read more on this, thanks!",
              "score": 1,
              "created_utc": "2026-01-18 13:00:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0ajgiq",
                  "author": "wunderspud7575",
                  "text": "Sceptre is a poor man's Stacker. Stacker really should have been more successful. Sceptre is junk.",
                  "score": 1,
                  "created_utc": "2026-01-18 14:11:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0dnpfx",
              "author": "SnoopJohn",
              "text": "If you do terragrunt well it can end up very clean and make it really simple to ensure all environments are the same as the use the same module with just differences in the env vars",
              "score": 1,
              "created_utc": "2026-01-18 23:22:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qiycaa",
      "title": "I Created One Site to Check Any AWS Lambda Event Payload",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qiycaa/i_created_one_site_to_check_any_aws_lambda_event/",
      "author": "[deleted]",
      "created_utc": "2026-01-21 13:48:19",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 0.73,
      "text": "One Ring to rule them all\"\n\nI built a very simple and straightforward website to look up the payloads for each service that AWS Lambda can receive (through the event variable).\n\nIt is a simple piece of information, but the fact that we have to navigate through AWS documentation to find each payload, and that this information is not available on a single page, is quite frustrating for anyone who frequently builds Lambda functions.\n\nNot all services are covered yet, but I plan to complete them by the end of the month.\n\nNext week, I will also make the project open source.\n\nCompletely free :)\n\nI don't know if something similar is already in use by the community, but there you go:\n\nhttps://lambda.clis.codes/\n\nI miss websites that are simple and minimalist, that only display information and perform one action, but that actually help the professional: like gitignore.io\n\nI'm trying to create a opensource platform that has these \"minimalist mini-tools\": CLIs & Codes.\n\nBut that's a conversation for another time :)",
      "is_original_content": false,
      "link_flair_text": "serverless",
      "permalink": "https://reddit.com/r/aws/comments/1qiycaa/i_created_one_site_to_check_any_aws_lambda_event/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0ur2t4",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'serverless'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+serverless).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-01-21 13:48:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11ymgf",
          "author": "workmakesmegrumpy",
          "text": "The go doc for lambda events package lay it all out but really whatâ€™s a pain in the ass is that I canâ€™t generate sample events easily",
          "score": 3,
          "created_utc": "2026-01-22 14:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o16fzjh",
              "author": "OkSadMathematician",
              "text": "yeah sample event generator would be clutch. aws sam cli has some but limited",
              "score": 3,
              "created_utc": "2026-01-23 04:05:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qhx8d0",
      "title": "Looking for feedback for my CDK approach",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qhx8d0/looking_for_feedback_for_my_cdk_approach/",
      "author": "thexavikon",
      "created_utc": "2026-01-20 10:07:03",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "I usually work on small projects that share the same AWS stack (dynamodb, lambda, cognito, sqs, s3).\n\nI made a starter template for myself to standardize that.\n\nLooking for feedback if this is a good approach, or if there are better way to do this.   \nI have read people criticizing CodePipeline. Should I move to Github actions instead for the CI/CD pipeline?\n\nHere's the repo: [https://github.com/rohankshah/cdk-starter-template](https://github.com/rohankshah/cdk-starter-template)",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qhx8d0/looking_for_feedback_for_my_cdk_approach/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o0n6nms",
          "author": "TurboPigCartRacer",
          "text": "if you plan on sharing it as a starter template i would focus on the structure and configuration of the tools that make a starter worth using instead of supplying it with random constructs (maybe one construct to show as example would be fine). codepipeline for ci/cd is really niche, if you plan on hosting the repo in github it might make more sense to utilize what github has to offer with actions.",
          "score": 1,
          "created_utc": "2026-01-20 10:22:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0naddl",
              "author": "thexavikon",
              "text": "Thank you for your feedback! I guess it's time to move away from code pipeline. I have noticed more people are using Github Actions.",
              "score": 1,
              "created_utc": "2026-01-20 10:55:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0nosm1",
                  "author": "cachemonet0x0cf6619",
                  "text": "this would be my preference. if you need to run your pipeline in your account you can use codebuild as a github actions runner.",
                  "score": 1,
                  "created_utc": "2026-01-20 12:46:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0npz1x",
          "author": "cachemonet0x0cf6619",
          "text": "This is a good start. my only two points of feedback is that you might want to consider separating stacks by volatility. think about separating into stateful and stateless. stateful is things like your db table and your queue. stateless would be your lambdas. \n\nyou have two choices with that. nested stacks or using string parameter names and import existing resources. \n\ntwo, your constructs arenâ€™t composable at all. your queue construct doesnâ€™t allow me to configure it. allow a user to pass some things into the construct like the visibility timeout or something. \n\noh, and finally donâ€™t name anything. you force a name into your queue. names are for pets. use tags for that stuff and let cdk create dynamic names for you. this makes replacement easier in the future.",
          "score": 1,
          "created_utc": "2026-01-20 12:53:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0nzuuv",
              "author": "thexavikon",
              "text": "Thank you so much! This is very useful for me. \n\n>you have two choices with that. nested stacks or using string parameter names and import existing resources.\n\nI'm not really sure how to go about this.\n\nBut point 2 and 3 are something I will definitely implement.",
              "score": 1,
              "created_utc": "2026-01-20 13:51:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0odd17",
                  "author": "cachemonet0x0cf6619",
                  "text": "look it up. whatâ€™s the tradeoffs of using cdk nested stacks and using string parameters to share resources. youâ€™ll want an educated answer to this question",
                  "score": 1,
                  "created_utc": "2026-01-20 15:02:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}