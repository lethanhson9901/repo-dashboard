{
  "metadata": {
    "last_updated": "2026-02-11 03:30:00",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 197,
    "file_size_bytes": 222270
  },
  "items": [
    {
      "id": "1qwgz6i",
      "title": "[Final Update] 164K views, Executive Escalations involved, 2 days of silence - we're moving to GCP",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qwgz6i/final_update_164k_views_executive_escalations/",
      "author": "charm88_baby",
      "created_utc": "2026-02-05 09:40:02",
      "score": 609,
      "num_comments": 100,
      "upvote_ratio": 0.9,
      "text": "This is the follow-up to my account suspension post from 2 days ago that got 164K views.\n\nEric G from AWS Executive Escalations sent my documents to Trust & Safety for review. That was his last message. It's been 2 days of complete silence since then.\n\nNo response on the support portal. No response from the multiple AWS support reps who were tagged here and on LinkedIn. Nothing. Just silence while my startup sits completely offline.\n\nWe made the decision yesterday to migrate everything to GCP. We can't wait any longer. Every day of silence costs us thousands in lost revenue and damages customer relationships we spent months building. Our business needs to function.\n\nWhat's wild is that even with 164K people seeing this, even with Executive Escalations directly involved, even with multiple support reps across every channel saying they escalated it - AWS just went silent. No updates, no timeline, no communication at all.\n\nThe community response here was incredible. People reached out, offered advice, tagged AWS employees, shared their own stories. Thank you to everyone who tried to help. It meant a lot even though AWS never showed up.\n\nCase 176984120700770 if AWS ever decides to respond. But we've moved on.\n\nTo anyone else building on AWS, have a backup plan. Because this can happen to you too, and 164K views apparently isn't enough to get a response.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qwgz6i/final_update_164k_views_executive_escalations/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3oyjno",
          "author": "rocketbunny77",
          "text": "Eric G probably got laid off. RIP",
          "score": 376,
          "created_utc": "2026-02-05 10:10:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pko2y",
              "author": "nucking_futs_001",
              "text": "Those were my thoughts as well.",
              "score": 44,
              "created_utc": "2026-02-05 13:05:04",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pb24t",
              "author": "Hydroshock",
              "text": "nah, last tuesday was it",
              "score": 14,
              "created_utc": "2026-02-05 11:59:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3pbqoq",
                  "author": "rocketbunny77",
                  "text": "2k more today",
                  "score": 34,
                  "created_utc": "2026-02-05 12:04:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3uj3cf",
              "author": "billysacco",
              "text": "Eric G is probably an LLM",
              "score": 9,
              "created_utc": "2026-02-06 04:36:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3wlgjj",
                  "author": "AWS_Chaos",
                  "text": "Eric G-> G Eric-> Generic. \n\n  \nI cracked the code!",
                  "score": 6,
                  "created_utc": "2026-02-06 14:17:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3twzk4",
              "author": "dinosaurkiller",
              "text": "As well as whoever he escalated it to.",
              "score": 0,
              "created_utc": "2026-02-06 02:18:02",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p2b7z",
          "author": "perthguppy",
          "text": "When a megascorp goes full radio silence on a customer it means exactly 1 thing:\n\nLegal is involved. Either they think they fucked up and you’re going to sue, or they think you’re doing something illegal and legal has said to cut all ties immediately. \n\nAt this point you’re never going to get anything more out of them unless you start legal action. Is going down that path going to get you a return on your investment? Probably not.",
          "score": 444,
          "created_utc": "2026-02-05 10:45:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q8d3q",
              "author": "TaonasSagara",
              "text": "The fact they even told you it was getting sent to Trust and Safety is a big red flag.\n\nEven at our big enterprise support level, getting told that stuff needs to get escalated to T&S is like pulling teeth. We have had issues where it was found that it was AWS screwing up stuff and not setting flags right on our accounts and their T&S systems causing the issues. And it took all kind of NDA and disclosed meetings to get told what happened.\n\nGCP isn’t going to be some panacea. If you’ve only worked in AWS, the model of GCP is going to be a mindfuck for a few months until you get it all aligned.",
              "score": 79,
              "created_utc": "2026-02-05 15:14:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r2qrw",
                  "author": "perthguppy",
                  "text": "T&S kind of has to be like that because many reasons they have to get involved is because of laws that also bind them to not disclose what’s happening or why, and if they said why when they could but not when they can’t, in some cases that would violate their legal requirement to not say anything in some cases. It’s a broken system forced on them by governments. One example is if the US government issues them a national security letter pertaining to your tenant. The law is clear you can not disclose that a national security letter exists, or imply that one exists by omission.",
                  "score": 21,
                  "created_utc": "2026-02-05 17:36:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3p8fdx",
              "author": "servermeta_net",
              "text": "Wise words.",
              "score": 39,
              "created_utc": "2026-02-05 11:38:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ulprb",
              "author": "zxLFx2",
              "text": "I just want to say, I work for a mega-corp, and we've had shit fall on the floor because of three people having PTO and forgetting the hand things over, or someone's spam filter is too sensitive, or similar dumb reasons. Maybe the guy got laid off and no one was there to push the ticket through.\n\nYou might definitely be right with the Legal suggestion, I'm just saying... companies are made of squishy people that act like humans sometimes.",
              "score": 7,
              "created_utc": "2026-02-06 04:54:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3un3mn",
                  "author": "perthguppy",
                  "text": "I was more thinking of the fact that he’s escalated through many many people who have all gone quiet at once.",
                  "score": 4,
                  "created_utc": "2026-02-06 05:04:49",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3wlstm",
                  "author": "AWS_Chaos",
                  "text": "Can confirm, am squishy. ",
                  "score": 2,
                  "created_utc": "2026-02-06 14:19:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3qb8sp",
              "author": "yarenSC",
              "text": "Or they're just overloaded with cases and fired too many people to be able to keep up",
              "score": 19,
              "created_utc": "2026-02-05 15:28:45",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3qvcxc",
              "author": "Sea-Us-RTO",
              "text": "> they think you’re doing something illegal and legal has said to cut all ties immediately.\n\nbeen in the industry ~9 years, its usually this lol.  especially when the customer attempts this \"the world is watching\" social engineering junk. what kinda business are you running, u/charm88_baby\n\n\nedit: after sleeping on it... i kinda agree with  /u/realitythreek more and more",
              "score": 24,
              "created_utc": "2026-02-05 17:01:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3thoia",
                  "author": "realitythreek",
                  "text": "This is a dumb callout. They’re obviously a small business. And support escalation is a thing, it happens all the time in THIS subreddit. Stop defending megacorps.",
                  "score": 6,
                  "created_utc": "2026-02-06 00:46:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p4qnb",
          "author": "vacri",
          "text": ">To anyone else building on AWS, have a backup plan.\n\nTo anyone building on anything, including self-hosted, have a backup plan.",
          "score": 124,
          "created_utc": "2026-02-05 11:07:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ua7ch",
              "author": "gloves085",
              "text": "Just as important, have a RECOVERY plan.... and TEST it!",
              "score": 14,
              "created_utc": "2026-02-06 03:37:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p1ram",
          "author": "---why-so-serious---",
          "text": ">We made the decision yesterday to migrate everything to GCP.. Every day of silence costs us\n\nAhh yes, google, a company well known for reachable, responsive customer service.",
          "score": 417,
          "created_utc": "2026-02-05 10:40:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p65ya",
              "author": "SMS-T1",
              "text": "I would pay good money to have data comparing the service quality between AWS, Azure and GCP. Because imhe AWS is the best (still mid) and GCP and Azure are equally worse.",
              "score": 100,
              "created_utc": "2026-02-05 11:19:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3r3xjg",
                  "author": "perthguppy",
                  "text": "In my experience, if comparing apples to apples, azure seems to have slightly better reliability of their IaaS and PaaS products, worse reliability of their SaaS products, much better partner ecosystem, and easier to contact support but that is more useless due to the v- outsourcing system.",
                  "score": 12,
                  "created_utc": "2026-02-05 17:42:03",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3slaml",
                  "author": "nekoken04",
                  "text": "I just have anecdotal info from working across all 3 clouds.  AWS; usually responsive unless it is a screwed up billing issue, and I can escalate to our account manager or our TAM.  Azure; very haphazard but last ticket I filed they were calling me even after the issue was resolved to make sure it met my satisfaction.  GCP; there's an extra layer of impedance to get through due to going through a reseller but they seemed mediocrely responsive.  Google themselves though? ugh.  Good luck getting hold of anyone.  When we were pushing hundreds of millions of dollars through their ad platform we still had a heck of a time even getting to a person.",
                  "score": 5,
                  "created_utc": "2026-02-05 21:52:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3p89ro",
              "author": "Independent_Buy5152",
              "text": "Gemini can respond any customer queries 24/7",
              "score": 30,
              "created_utc": "2026-02-05 11:37:22",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ptn2h",
              "author": "jakesyl",
              "text": "Have spent mid 6 figures at both for years. Google’s support is an order of magnitude better than Amazon.\n\nOn anything other than cloud, my experience has been the opposite",
              "score": 3,
              "created_utc": "2026-02-05 13:57:03",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3pc8dn",
              "author": "ConsiderationSuch846",
              "text": "I get the quip, but I have real people I meet with there every other week.   They are responsive, we have a relationship.  They have a reseller model and my team at the reseller is responsive and gets me real people.  We spend under $1m/year with GCP.  \n\nJust saying it doesn’t match my experience over the last 5 years.",
              "score": 2,
              "created_utc": "2026-02-05 12:07:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3piive",
              "author": "Lulzagna",
              "text": "Actually, yes. At least in my experience",
              "score": 2,
              "created_utc": "2026-02-05 12:51:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ox50v",
          "author": "Alternative-Expert-7",
          "text": "Can you link original post?",
          "score": 25,
          "created_utc": "2026-02-05 09:57:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oxuh7",
              "author": "hursofid",
              "text": "https://www.reddit.com/r/aws/s/SUeIlQfqcw",
              "score": 22,
              "created_utc": "2026-02-05 10:04:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3q3psi",
          "author": "kzgrey",
          "text": "What was your AWS system running? Anything that could be considered illegal?\nNo response from a security team is a data point. There's definitely more to this story but maybe they are not telling you.",
          "score": 20,
          "created_utc": "2026-02-05 14:50:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pkz1w",
          "author": "d70",
          "text": "Probably borderline illegal business.",
          "score": 49,
          "created_utc": "2026-02-05 13:06:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q5897",
              "author": "x86_64Ubuntu",
              "text": "What is an \"illegal business\" in the cloud world?",
              "score": 3,
              "created_utc": "2026-02-05 14:58:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qabxc",
                  "author": "liquidpele",
                  "text": "The most typical are \"marketing\" things, that are in reality spam and web bots.",
                  "score": 22,
                  "created_utc": "2026-02-05 15:24:19",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qrl4e",
                  "author": "RedditUserData",
                  "text": "Performing regulated activities improperly. I've seen a few in my years, one was a company selling pharmaceuticals and they were sourcing their drugs from some place sketchy. Co-worker went to join them on their Web development team. First day in the office they got raided by the FBI and shut down, luckily for him my company let him come back.\n\n\nI worked with a client whose company got shut down by FDA for not properly making their products. Their website didn't get seized like the first one did.\n\n\nAnother was marketing supplements with basically lies. \n\n\nThe government can request any cloud provider pull content, or shutdown services. I don't know how often that happens or how often the providers go along with it, but it does happen. ",
                  "score": 11,
                  "created_utc": "2026-02-05 16:44:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3r4jpo",
                  "author": "perthguppy",
                  "text": "The usual. Scams, spams, gambling in many cases, adult content in many cases, money laundering, CSAM, drugs, working with Russia, Iran, North Korea or Cuba, etc.",
                  "score": 8,
                  "created_utc": "2026-02-05 17:44:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3palrt",
          "author": "SikhGamer",
          "text": "Nah, you aren't giving us the full story. What is _exactly_ your business?",
          "score": 69,
          "created_utc": "2026-02-05 11:55:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pcjbj",
              "author": "actually_I_am_human9",
              "text": "Exactly, I don’t want to defend a company I’m not part of but, indeed, what’a your business? what’s AWS’s explanation? What really happened? AWS just chose you, told you that they suspended your account they don’t respond any more? 15 years of experience, I always got a response even when It’s our configuration mistake, saw customers not paying for 6 months but still running workloads etc.",
              "score": 44,
              "created_utc": "2026-02-05 12:10:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qkoci",
                  "author": "Nblearchangel",
                  "text": "Op mysteriously silent on that piece.",
                  "score": 29,
                  "created_utc": "2026-02-05 16:12:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3pbpzt",
              "author": "jorel43",
              "text": "Scheduling software apparently",
              "score": 10,
              "created_utc": "2026-02-05 12:04:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3s8hy5",
                  "author": "ZYy9oQ",
                  "text": "Is the scheduling of legal or illegal activities?",
                  "score": 6,
                  "created_utc": "2026-02-05 20:50:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ow7j4",
          "author": "droning-on",
          "text": "I didn't see the other post.  But what's the nature of your business? Is it something AWS might feel uncomfortable with for legal reasons?",
          "score": 44,
          "created_utc": "2026-02-05 09:48:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ozcf7",
              "author": "brunporr",
              "text": "> a legitimate SaaS company building scheduling automation software.\n\nScandalous use case for sure",
              "score": 49,
              "created_utc": "2026-02-05 10:18:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3unccs",
                  "author": "irbinator",
                  "text": "> a legitimate SaaS company\n\nNarrator: It wasn’t.",
                  "score": 8,
                  "created_utc": "2026-02-06 05:06:33",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3qciuz",
                  "author": "Glebun",
                  "text": "scheduling drug deals, maybe?",
                  "score": 5,
                  "created_utc": "2026-02-05 15:34:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3pc0gm",
          "author": "sp_dev_guy",
          "text": "Still better than Cloudflare enterprise support",
          "score": 10,
          "created_utc": "2026-02-05 12:06:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3r7mzm",
              "author": "mountainlifa",
              "text": "Wow really? I thought they were supposed to be \"better\"?",
              "score": 2,
              "created_utc": "2026-02-05 17:58:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3rjf7z",
                  "author": "sp_dev_guy",
                  "text": "The overall product is extreamely versatile & pretty reliable. The WAF let's things through that it shouldn't and isn't the best that I've ever seen but its pretty good. Their support for any real issue is an absolute abomination, if I had any choice I'd leave running. But there's no drop in alternative & they know it\n\nUsed to have good support experiences but mostly very simple questions.\n\nNow.. 9mo+ of production outages due product issues on their end while begging for escalations, reaching out to our rep, etc... would get a vague unhelpful email every 3-6 weeks from generic support that made it clear they weren't even reading the ticket. My company has experienced this more than once with them, it is the expected response at this point. Fuck them.",
                  "score": 6,
                  "created_utc": "2026-02-05 18:52:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p7n7v",
          "author": "BadDescriptions",
          "text": "Have you ever looked into how bad GCPs support is compared to AWS? You may find yourself moving to Azure after GCP support fails you, soon after you’ll realise Azure is worse than GCP. \n\nWhich AWS support plan were you paying for? Every time we’ve had an issue with our enterprise plan they’ve been quick to resolve issues. ",
          "score": 31,
          "created_utc": "2026-02-05 11:32:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p84oy",
          "author": "Independent_Buy5152",
          "text": "perhaps those guys were laid off so nobody was working on your ticket",
          "score": 15,
          "created_utc": "2026-02-05 11:36:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r7nqe",
          "author": "Previous_Stomach_986",
          "text": "Something is missing here. Do you have a website?",
          "score": 4,
          "created_utc": "2026-02-05 17:59:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3t57en",
          "author": "planedrop",
          "text": "I'm legit curious, this is not a bait comment, does your workload even HAVE to be in the cloud? \n\n  \nI'm asking because if management is so upset about this that they will move the entire stack to a new cloud provider, what happens when Google does the same thing to you? This is one of the issues with cloud heavy stuff, it can happen at any VPS or any of the big 3. \n\n  \nMy question is, does on-prem make more sense given the uptime requirements even if that costs more?\n\n  \nOr maybe you should be preparing to duplicate all this in Azure **and** GCP for redundancy? \n\n  \nI don't know your actual requirements, I'm just legit curious here, maybe it's more about the lack of response and less about the downtime caused by this.",
          "score": 3,
          "created_utc": "2026-02-05 23:35:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v9sba",
          "author": "johnnysgotyoucovered",
          "text": "Your original post and this post doesn’t include any information of what your startup does. I highly doubt AWS or any cloud provider would want to lose you as a customer unless it puts their reputation at risk or subject to legal liability",
          "score": 3,
          "created_utc": "2026-02-06 08:15:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p741j",
          "author": "newbietofx",
          "text": "Are you on ams or uops or enterprise support? ",
          "score": 5,
          "created_utc": "2026-02-05 11:27:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r44qh",
          "author": "Nolubrication",
          "text": "About a year ago, I saw on LinkedIn that the internal recruiter who headhunted me to interview for a TAM role had transitioned into a TAM role himself. He had no IT background in his education or work experience, aside from the SAA certification he earned while working in talent acquisition at Amazon.\n\nI couldn't pass the loop for a TAM role with 20+ years of experience, a CS degree, and an MBA, but a twentysomething kid who took a Udemy course fits their culture, I guess. \n\nAnecdotal, for sure, but I suspect that it's emblematic of the type of support AWS provides.",
          "score": 6,
          "created_utc": "2026-02-05 17:42:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qp7aj",
          "author": "charm88_baby",
          "text": "Update: AWS just responded after 2 days of silence.\n\nThey're claiming our account is \"related to other AWS accounts\" and told me to check my other email addresses for an email titled \"Your AWS Account Inquiry\" that was supposedly sent to these other accounts.\n\nI've checked every email address associated with our company. There's no such email because there are no other company accounts. We created this account on October 24, 2025 when we launched. This is our first and only company AWS account.\n\nI personally created this account 4 months ago for our startup. There are no related company accounts because they don't exist.\n\nI've told AWS this directly in my response. I've provided passport, bank statements, business formation documents - everything proving we're a legitimate company with legitimate identity.\n\nTheir system has made an error connecting our account to others. I cannot prove accounts don't exist when they were never created in the first place.\n\nWe're already migrating to GCP at this point. But getting our data back from AWS would be useful since our entire production database is on that account.\n\nu/AWSSupport \\- Case 176984120700770",
          "score": 7,
          "created_utc": "2026-02-05 16:33:14",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3r5kge",
              "author": "perthguppy",
              "text": "Company aside, have you or any of your cofounders ever had an AWS account, or had another company with an AWS account? Sounds like one of you have ended up being blacklisted and Amazon has made the decision to no longer work with you or any successor entities.",
              "score": 13,
              "created_utc": "2026-02-05 17:49:30",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3uxqd7",
                  "author": "spacelama",
                  "text": "Which funnily enough, is something that Google have been recognised as doing, multiple times, with mere employees.",
                  "score": 5,
                  "created_utc": "2026-02-06 06:28:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3pljkk",
          "author": "Sirauto420",
          "text": "No one gives a shit about your 10k year/arr business. Go to GCP",
          "score": 10,
          "created_utc": "2026-02-05 13:10:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pmxbj",
              "author": "Sirauto420",
              "text": "Your business is also probably a scam since you won’t give any details about why you got suspended",
              "score": 24,
              "created_utc": "2026-02-05 13:18:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3u0k5a",
          "author": "cynicaljerkahole",
          "text": "Have you escalated to Chris Hemsworth?",
          "score": 4,
          "created_utc": "2026-02-06 02:39:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ozg56",
          "author": "brunporr",
          "text": "OP, share your story with tech media and places like hn",
          "score": 3,
          "created_utc": "2026-02-05 10:19:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r796y",
          "author": "mountainlifa",
          "text": "As a former AWS employee I can testament that they only care about enterprise customers. Unless you're Netflix, Airbnb etc then they don't give AF ",
          "score": 4,
          "created_utc": "2026-02-05 17:57:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qxx8j",
          "author": "blenderman73",
          "text": "Good luck, aws support has been lagging more and more this year as teams are flooded with less and less headcount and more and more tickets.\n\nIt’s going to be less of a customer obsession and more of a you should fight to get to us since we’re the best and biggest system.\n\nNothing wrong with GCP.",
          "score": 2,
          "created_utc": "2026-02-05 17:13:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3wsv3d",
          "author": "Significant_Oil3089",
          "text": "Just so everyone can stop being all afraid that AWS is suspending accounts willy nilly.\n\nThis person's account was suspended for fraud. Potentially forged documents, inconsistent business documents showing different areas of residence and business dealings and multiple closed accounts under the same credit card.\n\nSo, no AWS is not arbitrarily suspending accounts or ignoring this customer. Don't do dirt and you will be fine.",
          "score": 2,
          "created_utc": "2026-02-06 14:55:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xqigb",
              "author": "sexyflying",
              "text": "And why should we believe you, internet stranger?",
              "score": 0,
              "created_utc": "2026-02-06 17:36:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3xrr63",
                  "author": "Significant_Oil3089",
                  "text": "This guy posted his case id which means people with access at AWS can read it. \n\nTrust me or not, idc. Just giving people the facts so they aren't unnecessarily afraid that this can randomly happen to their AWS account.",
                  "score": 2,
                  "created_utc": "2026-02-06 17:42:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3p5i8d",
          "author": "Wesleyinjapan",
          "text": "When I had problems my company was offline for two weeks. They not have the best customer support at all.",
          "score": 2,
          "created_utc": "2026-02-05 11:13:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qsqfj",
          "author": "m4ch1-15",
          "text": "We decentralized to centralize on someone else’s on-prem",
          "score": 1,
          "created_utc": "2026-02-05 16:49:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3r7g0x",
          "author": "KayeYess",
          "text": "Always have a plan B. If you moved to Google, still have a plan B (maybe Azure). The world is not perfect, and neither is Cloud.",
          "score": 1,
          "created_utc": "2026-02-05 17:58:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v6k85",
          "author": "mikeblas",
          "text": "How long will it take to migrate to GCP?",
          "score": 1,
          "created_utc": "2026-02-06 07:45:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o414m9z",
          "author": "phantom-virus-lives",
          "text": "Likely riffed em all.",
          "score": 1,
          "created_utc": "2026-02-07 04:52:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qclli",
          "author": "wp4nuv",
          "text": "My company is already working to migrate to Azure.",
          "score": 1,
          "created_utc": "2026-02-05 15:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pihd3",
          "author": "Positive-Twist-6071",
          "text": "M-m-m-multi cloud!",
          "score": 0,
          "created_utc": "2026-02-05 12:51:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q7klg",
          "author": "mintzie",
          "text": "Migrate to an AWS SPP org",
          "score": 0,
          "created_utc": "2026-02-05 15:10:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p1gvi",
          "author": "SmartEntertainer6229",
          "text": "scary.  easiest way to create a full AWS backup outside AWS, for situations like this (if there's one)?",
          "score": -4,
          "created_utc": "2026-02-05 10:38:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3p5bxx",
              "author": "pint",
              "text": "what do you think backups will do for you? it is not the lost data, but the lost service. you imagine setting up the service somewhere else without a need for re-implementing, and most likely some re-design as well?",
              "score": 11,
              "created_utc": "2026-02-05 11:12:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3psngg",
          "author": "BigDeliciousSeaCow",
          "text": "Have you tried emailing jeff@amazon.com with your story? This seems like the basis for a good \"question mark\" email.",
          "score": -5,
          "created_utc": "2026-02-05 13:51:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q40tl",
              "author": "Sirauto420",
              "text": "He’s not doing it for this lmao",
              "score": 1,
              "created_utc": "2026-02-05 14:52:35",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3pkqwd",
          "author": "Victorxdev",
          "text": "Pls take serious legal action against them. This is just horrible to process.",
          "score": -13,
          "created_utc": "2026-02-05 13:05:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q4501",
              "author": "Sirauto420",
              "text": "Lmao what legal action is this dude gonna take?",
              "score": 6,
              "created_utc": "2026-02-05 14:53:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3q828v",
          "author": "crustyeng",
          "text": "This is why we’re so adamant about building our generative ai apps outside of any agent runtime or single-source api.  Portability just saved you!",
          "score": -2,
          "created_utc": "2026-02-05 15:13:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pphdn",
          "author": "roberts2727",
          "text": "Multi cloud with an extrapolation layer for management.",
          "score": -2,
          "created_utc": "2026-02-05 13:33:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3oxzpr",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -4,
          "created_utc": "2026-02-05 10:05:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oyb4o",
              "author": "Additional-Wash-5885",
              "text": "Yeah, because the startups usually immediately invest in their own data centers",
              "score": 21,
              "created_utc": "2026-02-05 10:08:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3oyohe",
                  "author": "mightybob4611",
                  "text": "I could feel the sarcasm in that one",
                  "score": 3,
                  "created_utc": "2026-02-05 10:12:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3ozrpp",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -35,
          "created_utc": "2026-02-05 10:22:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3q1iwl",
              "author": "gex80",
              "text": "Maybe for something you're building for a side project or you're a company the size of 20 people.",
              "score": 1,
              "created_utc": "2026-02-05 14:39:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvqv6w",
      "title": "The actual ways to get AWS credits right now (Feb 2026 updated)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qvqv6w/the_actual_ways_to_get_aws_credits_right_now_feb/",
      "author": "alex_aws_solutions",
      "created_utc": "2026-02-04 15:02:42",
      "score": 75,
      "num_comments": 14,
      "upvote_ratio": 0.9,
      "text": "I keep seeing the same questions about AWS credits, and most of the answers are either outdated or vague. We went through this ourselves last year when building on AWS. So here’s what actually works as of February 2026\n\nNo affliate links, no fluff. Just what’s currently real and worked for us.\n\n\n\n**1. The fintech route - $5K in about 15 minutes**\n\nMost people overlook this one. A few startup banking platforms are official AWS Activate Providers, which means their customers can apply for AWS credits directly through them. Sometimes you will get notified from them if you are eligable.\n\nWe used Brex, but the same logic applies to other fintechs offering benefit. Once your business account is set up, you can apply through the AWS Activate Portfolio tier using the provider’s organization ID (you’ll find it inside their perks or startup programs section).\n\nA few important details:\n\n\\- Your AWS Accouunt should list your fintechs card as default payment method before applying.\n\n\\- The Company needs to be under 10 years old and must not have already received more than $5K in Activate Credits.\n\n\\- Credits usually land in about a week and expire after 12 months.\n\n\\- Your support plan needs be Business Support+. \n\n\n\n**2. AWS Activate Founders - $1K, open to almost anyone**\n\nGot to [https://aws.amazon.com/startups](https://aws.amazon.com/startups) and apply for the Founders tier.\n\nRequirements:\n\n\\- Company founded within the last 10 years\n\n\\- Pre-series B\n\n\\- AWS Account on a paid plan\n\n\\- Real company website (not a placeholder)\n\n\n\nTwo common mistakes:\n\n\\- Don’t use a Gmail or Yahoo adress, use your company domain instead.\n\n\\- Make sure your website hast actual content. Empty sites often get auto-rejected\n\n\n\n**3. AWS Activate Portfolio - $25K to $100K**\n\nIf you are backed by a VC or went through an accelerator, ask them. Most investors are AWS Activate Providers but never proactively mention it.\n\n\n\n**4. The Free Tier changed in mid-2025**\n\nNew Accounts after July 15, 2025 get $100 in credits automatically, plus another $100 unlocked by using core services (e.g. EC2, Lambda, Budgets).\n\n\n\n**5. Accelerator programs - $100K+ if you get in**\n\nY Combinator gives $100K standard and up to $500K for AI startups.\n\nEven YC’s Startup School (free, online, open to anyone) includes $2.5K in AWS credits.\n\n\n\n**6. Nonprofits and researchers - $1K to $5K**\n\nRegistered nonprofits can get $1K - $5K per year through TechSoup’s AWS program.\n\n\n\n**What doesn’t work!**\n\n\\- Buying credits from „brokers“, violates AWS ToS.\n\n\\- Creating multiple accounts to stack Founders credits, AWS tracks at the company level\n\n\\- Using personal AWS account and later converting it to business, just start fresh with a business account.\n\n\\- waiting too long after funding round, the 12-month Portfolio window is hard-coded.\n\n\n\n**TL;DR**\n\nFastest route if you’re an early-stage startup:\n\n1. Open a fintech business account (Brex or Mercury both work)\n\n2. Apply through their AWS Activate partnership -> $5K in credits.\n\n3. Apply for Founders ($1K) seperately.\n\n4. If you have investors, ask for their Activate org ID -> $25K - $100K.\n\n\n\nHappy to answer questions. We’ve gone through most of these paths ourselves.",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1qvqv6w/the_actual_ways_to_get_aws_credits_right_now_feb/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3kq3x9",
          "author": "ruibranco",
          "text": "Solid breakdown. One thing worth adding -- the Business Support plan requirement for the fintech route is a hidden cost people miss. That's $100/month minimum, so factor that into the $5K credit math. Still net positive obviously, but I've seen people surprised by the support plan charge eating into their credits.\n\n  \nAlso for anyone reading this in a non-US context: the fintech route through Brex/Mercury only works if you have a US-incorporated entity. For international startups, the Activate Founders tier is usually the first real option.\n\n  \nOne more gotcha on the Portfolio tier -- some VCs have already used up their Activate allocations for the quarter and won't tell you. If your investor says they're an Activate Provider but the application gets rejected, ask them to check their remaining allocation. They get a fixed number of referrals per period.\n\n  \nThe personal vs business account advice is critical. Starting fresh with a business account from day one saves weeks of back-and-forth with support trying to convert later.",
          "score": 8,
          "created_utc": "2026-02-04 18:33:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kx3ij",
              "author": "alex_aws_solutions",
              "text": "Some great add-ons. Thanks you!\n\nDefinitely worth commenting that the Business Support+ expenses starting at $99/month and still absolutely an advantage using those credits to pay for this plan.\n\nThanks for the input!",
              "score": 1,
              "created_utc": "2026-02-04 19:04:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3mvwwx",
                  "author": "yarenSC",
                  "text": "I always thought credits couldn't be used for support plans?",
                  "score": 1,
                  "created_utc": "2026-02-05 01:01:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3l9bwp",
          "author": "perciva",
          "text": "AWS also has lots of credits for open source software.  Like \"I've never seen anyone not get approved for whatever they ask for\" amounts of credits.\n\nNot relevant for startups, of course.",
          "score": 4,
          "created_utc": "2026-02-04 20:01:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3larmd",
              "author": "alex_aws_solutions",
              "text": "Also a great Input. Just skimmed the blog post in aws about this. Quite interesting. \nTo be eligable for this \"the organisation must have an OSI-approved license and can't be dominated by a single vendor or VC-funded.\"",
              "score": 2,
              "created_utc": "2026-02-04 20:08:39",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3ls2x3",
                  "author": "perciva",
                  "text": "Yeah, that's basically just \"this has to be real open source\".",
                  "score": 4,
                  "created_utc": "2026-02-04 21:31:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0hm2o",
      "title": "Support cases unassigned. Anyone still alive at AWS?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "author": "symgenix",
      "created_utc": "2026-02-09 21:44:20",
      "score": 57,
      "num_comments": 72,
      "upvote_ratio": 0.71,
      "text": "Have any of you experienced the same situation? I've got 3 tickets, none of them being actually addressed, the oldest one being created 11d ago.\n\nI am wondering if I should send a registered letter or send a pigeon with my case file, as those would probably arrive quicker than someone actually responding to my online cases. We seem to revert to stone age soon, at least at AWS. AWS would then become ASS right? Amazon Stone Services.\n\nEdit: Basic Support level. Low priority is automatically assigned everywhere.\n\nhttps://preview.redd.it/rbk5wd3hgjig1.png?width=666&format=png&auto=webp&s=6b6b7784a742e28f3d6ed3fda06bb60a2b8357e0",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4i9jbq",
          "author": "anoeuf31",
          "text": "What support level are you on and what severity level were these cases opened at ?",
          "score": 40,
          "created_utc": "2026-02-09 21:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i9rvg",
              "author": "symgenix",
              "text": "Basic -> Low\n\nSo, one could no longer receive any support unless one pays for a support subscription? :D That must be a compelling business decision.",
              "score": -74,
              "created_utc": "2026-02-09 21:50:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ihda4",
                  "author": "nemec",
                  "text": "> That must be a compelling business decision.\n\nMoney can be exchanged for goods and (support) services",
                  "score": 80,
                  "created_utc": "2026-02-09 22:28:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iam0c",
                  "author": "anoeuf31",
                  "text": "Unironically yes - do you think support engineers work out of the goodness of their hearts ? Business support starts at 29 bucks a month . \n\nIf you think whatever you are running on AWS isn’t worth the 29 bucks a month, don’t be surprised when support treats your cases with the same level of importance",
                  "score": 85,
                  "created_utc": "2026-02-09 21:54:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ixz5b",
                  "author": "planedrop",
                  "text": "Dude, pretending that support should just be included doesn't really make sense.\n\n  \nThe point of a lot of cloud services is to be *as cheap as possible* which means cutting support unless you want to pay for that on your own as well. ",
                  "score": 6,
                  "created_utc": "2026-02-09 23:57:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4id9v5",
          "author": "mistuh_fier",
          "text": "Unfortunately if you’re not paying for support then there’s not much differentiating you vs. mass registrations by AI agents to abuse the Free Tier. \n\nFree tier support tickets to a specific service are essentially aggregated and treated as a canary for widespread issues.",
          "score": 44,
          "created_utc": "2026-02-09 22:07:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4idiwe",
          "author": "PracticalTwo2035",
          "text": "Dude, setup bedrock playground? Wtf, there is no setup, just usage. Please try to search in the internet and maybe read the docs.",
          "score": 31,
          "created_utc": "2026-02-09 22:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j9mat",
          "author": "d70",
          "text": "Basic support = you are free to read documentation on your own. From [the FAQ](https://aws.amazon.com/premiumsupport/faqs/):\n\n>How are the enhanced AWS Support tiers different from Basic Support?\n\n>AWS Basic Support offers all AWS customers access to our Resource Center, Service Health Dashboard, Product FAQs, and Discussion Forums – at no additional charge. Customers who desire a deeper level of support can subscribe to AWS Support at the Business Support+, Enterprise, or Unified Operations level.",
          "score": 5,
          "created_utc": "2026-02-10 01:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i9h47",
          "author": "Outrageous_Lab_6228",
          "text": "What is your support tier?",
          "score": 14,
          "created_utc": "2026-02-09 21:48:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iaarh",
              "author": "symgenix",
              "text": "Basic. I'd rather switch to a different provider than pay for support subscriptions lol.. especially since nothing seems to be properly working without a PHD in AWS apparently. ",
              "score": -48,
              "created_utc": "2026-02-09 21:52:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iciao",
                  "author": "caughtinthought",
                  "text": "FYI the providers that are a layer above AWS (i.e., hand hold more) typically charge much more too. The further from the foundation you go, the more shit costs. ",
                  "score": 21,
                  "created_utc": "2026-02-09 22:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iaufs",
                  "author": "anoeuf31",
                  "text": "When you find this magical cloud provider that’ll respond to your cases on priority without a support fee , please let us all know !!",
                  "score": 37,
                  "created_utc": "2026-02-09 21:55:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iolp9",
                  "author": "Dave4lexKing",
                  "text": "If whatever you’re building isn’t worth $29/mo for support, then it can’t be very good?",
                  "score": 5,
                  "created_utc": "2026-02-09 23:06:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ikssi",
                  "author": "Nemphiz",
                  "text": "That kinda sounds like a skill issue tbh.",
                  "score": 8,
                  "created_utc": "2026-02-09 22:46:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ih6sp",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear that your support cases have not been responded to yet. I've passed along your feedback to our Support team. Any updates about your support cases will be sent to your inbox. \n\n\\- Gee J.",
          "score": 11,
          "created_utc": "2026-02-09 22:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kp4wa",
          "author": "MavZA",
          "text": "Reading how you’ve responded to comments then maybe you should either consider switching as you’ve threatened you would. Doesn’t seem like you’ve put any effort into learning AWS and how to use the services or how the services fundamentally work. You say you need a PHD, but clearly you’ve come in without any fundamentals and are frustrated because it doesn’t work the way you think it should.",
          "score": 5,
          "created_utc": "2026-02-10 06:49:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4icdhs",
          "author": "Horror_Response_1991",
          "text": "If you aren’t giving them money for support or giving them a lot of money for regular use, they do not care.  They only have so much support staff and they’re all busy helping the money.",
          "score": 5,
          "created_utc": "2026-02-09 22:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jqlu3",
          "author": "stephenin916",
          "text": "NOPE everything is going into AI and they have reduced the front line personnel ...if you pay the big money then you get more attention but the days of customer obsession are GONE and the shareholder days have arrived. ",
          "score": 3,
          "created_utc": "2026-02-10 02:43:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kb4hu",
          "author": "teambob",
          "text": "They layed off thousands of people",
          "score": 2,
          "created_utc": "2026-02-10 04:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k6g1b",
          "author": "RuinEnvironmental394",
          "text": "Did you try sending a telegram? And no I'm not talking about the app. 😭",
          "score": 1,
          "created_utc": "2026-02-10 04:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iab9q",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-02-09 21:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j5exp",
              "author": "gbonfiglio",
              "text": "It’s important to debunk this one: there is no mechanism in AWS Support which causes ‘simple’ cases to be ignored.\n\nCases are routed to engineers based on a range of parameters like service, complexity, time since open, support tier etc - so there can’t be any structural decision to ignore these cases.",
              "score": 5,
              "created_utc": "2026-02-10 00:39:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iamdq",
              "author": "symgenix",
              "text": "Yes, I did try multiple times via their amazing AI, which, in my experience, was only able to circle around non-related stuff and point me to nonsensical locations. They probably outsource their baisc support AI model to the first model of gpt.",
              "score": -15,
              "created_utc": "2026-02-09 21:54:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iedap",
                  "author": "InterestedBalboa",
                  "text": "Basic support is no support, just how it works",
                  "score": 8,
                  "created_utc": "2026-02-09 22:13:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0ufs2",
      "title": "Localstack killing community edition - what do we do?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "author": "xenographer",
      "created_utc": "2026-02-10 07:31:10",
      "score": 55,
      "num_comments": 45,
      "upvote_ratio": 0.92,
      "text": "[https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change](https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change)\n\nLocalstack are killing their community edition and making everyone register for a free plan (ugh), so I guess that'll mean they'll slowly nerf the free plant to the point where it's unuseable/put horrible limits on it so you have to pay.\n\nIs there any realistic alternative to localstack out there? Anyone?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4lan0b",
          "author": "alvsanand",
          "text": "It’s ironic to read them calling it as an 'open-source experiment' rather than a full project, especially since their entire reputation was built on being open-source. They have the right to do it, but they shouldn’t insult our intelligence by pretending otherwise",
          "score": 34,
          "created_utc": "2026-02-10 10:14:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lowhl",
          "author": "tuple32",
          "text": "aws should buy localstack and make it available to their customers for free.",
          "score": 23,
          "created_utc": "2026-02-10 12:14:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nb4lp",
              "author": "HanzJWermhat",
              "text": "This was pitched internally as an idea. I don’t think it was ever taken seriously (I can’t be more specific because my part of the business wasn’t well suited to own it anyway)\n\nThe problem is expectations. If AWS does it, it needs to support everything out of the box. Every API call of which there are 14000+",
              "score": 10,
              "created_utc": "2026-02-10 17:20:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4okuvi",
                  "author": "seanamos-1",
                  "text": "I don't know how seriously they thought about this, but I can't overstate what a significant competitive advantage localstack has been for AWS, and they are losing it.",
                  "score": 4,
                  "created_utc": "2026-02-10 20:51:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kw57x",
          "author": "DevWithImagination",
          "text": "Depending on the services you need moto is a great alternative (in fact, localstack uses moto under the hood for some things). We moved quite a bit over to it for speed of testing while using some of the simpler base services (S3, DynamoDb etc)",
          "score": 24,
          "created_utc": "2026-02-10 07:53:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kw94x",
              "author": "xenographer",
              "text": "Nice! [https://github.com/getmoto/moto](https://github.com/getmoto/moto) for reference",
              "score": 13,
              "created_utc": "2026-02-10 07:54:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4l6c3m",
          "author": "omenking",
          "text": "https://github.com/project-vera/vera-aws\n\nThis project has popped up very recently. It's a research project that is open source.",
          "score": 8,
          "created_utc": "2026-02-10 09:33:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lgpsu",
          "author": "PlanB2019",
          "text": "I would totally pay like 10$ as a hobbyist/individual dev but the currrent entry for premium is just too much to justify for my projects. I wish they had a better entry package, that wasn’t more than my current aws costs haha",
          "score": 7,
          "created_utc": "2026-02-10 11:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kuzx9",
          "author": "HatchedLake721",
          "text": "Why’s not just pay for it? It’s a valuable service and people behind it deserve to be paid for it. Anyone not paying for AWS with their own credit card should just put this through their work.\n\nOtherwise, you can just fork and carry on using it as it is today.",
          "score": 22,
          "created_utc": "2026-02-10 07:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lx07v",
              "author": "ippem",
              "text": "Looking from my current company's perspective, we happily pay for things we need, but in our case, the price model (no monthly option plus would need to buy lots of these \"CI credits\" probably) has always killed the idea (for both app developers/CI runs plus for our Terraform development + CI runs).  \nI wish they would have a monthly payment - and have it through e.g. AWS Marketplace would make the adoption way easier.\n\nThat was a hint above how to grow your business, probably exponentially. 🙂 Companies do not like to commit on things that they don't know the actual usage patterns.",
              "score": 10,
              "created_utc": "2026-02-10 13:08:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4n72d7",
              "author": "GoofAckYoorsElf",
              "text": "A goes from Open Source to freemium - why not pay for it? \n\nB goes from Open Source to freemium - why not pay for it?\n\nC goes from Open Source to freemium - why not pay for it?\n\nBecause I already fucking pay for A and B! What am I Croesus? \n\nOpen Source projects grow on contribution by the community. Shitting on the community and telling them to suddenly pay for the stuff they actually contributed themselves is a fucking dick move, that's what it is!",
              "score": 6,
              "created_utc": "2026-02-10 17:01:43",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kxg57",
          "author": "seany1212",
          "text": "Genuine question, why would anyone pay for this? If you’re at a company that takes AWS seriously then they should create you a test environment/account so you don’t need to “simulate” an AWS environment.  \n\nIf you’re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nThis just seems to add another abstraction layer that will potentially introduce unseen differences when you actually try to port that to AWS.",
          "score": 9,
          "created_utc": "2026-02-10 08:05:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kzo4f",
              "author": "flooberoo",
              "text": "Because with _N_ features being developed simultaneously you ideally have at least _N_ environments. And that can get expensive and slow quite fast.",
              "score": 20,
              "created_utc": "2026-02-10 08:27:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4l4lwm",
                  "author": "lost12487",
                  "text": "I'm not sure why you'd need an account per feature? Why not just give each team a prod and a non-prod account and deploy feature branches within the non-prod account, cleaning up the resources when the feature branch is merged?",
                  "score": -3,
                  "created_utc": "2026-02-10 09:16:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4l6y8d",
              "author": "xenographer",
              "text": "LOL, every time someone starts a sentence with \"Genuine question\" or \"I'm genuinely curious why\" you know that it's bullshit and they're just setting themselves up so they can argue the case against. So intellectually dishonest.\n\n\\> If you’re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nthe whole point is that it's LOCAL and you don't have to set up AWS credentials or resources. Same with integration tests in CI.  \n  \nI'm not sure where \"another abstraction layer\" comes into it.",
              "score": 14,
              "created_utc": "2026-02-10 09:39:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ldrcx",
                  "author": "seany1212",
                  "text": "If it’s local then why bother simulating AWS at all? Just build your app/platform with services/VMs/Docker/Kubernetes\n\nThe logic doesn’t even make sense, I’m going to simulate a cloud platform that provides an abundance of products and services with potentially infinite compute, locally with none of that.\n\nAgain, why would anyone PAY for that, when it was your initial complaint in the OP",
                  "score": -9,
                  "created_utc": "2026-02-10 10:43:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mqy7w",
              "author": "DZello",
              "text": "Creating ressources in AWS can take forever, databases are a good exemple.",
              "score": 1,
              "created_utc": "2026-02-10 15:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4kw9x3",
          "author": "smutje187",
          "text": "Do you make money with the software you build on LocalStack? Buy a license, just like you buy IDE licenses, rent an office, buy a computer.\n\nOtherwise, AWS credits and use ephemeral environments, most AWS Services that run in LS cost next to nothing for private use.",
          "score": 3,
          "created_utc": "2026-02-10 07:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4olp5o",
          "author": "ruibranco",
          "text": "the realistic answer for most teams is you don't actually need to mock all of AWS locally. SAM CLI + DynamoDB local covers 80% of what people actually use localstack for. the rest you test against a real dev account with short-lived resources. it's less elegant but it's also not going to rug-pull you in 6 months.",
          "score": 1,
          "created_utc": "2026-02-10 20:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ombcp",
          "author": "ruibranco",
          "text": "the \"free plan\" to \"slowly nerf it\" pipeline is so predictable at this point. moto covers a surprising number of services if you haven't tried it — not as polished but no registration, no usage tracking, and it actually runs offline. for anything more complex, a dedicated AWS dev account with tight billing alerts is honestly more reliable than hoping a third-party tool stays free.",
          "score": 1,
          "created_utc": "2026-02-10 20:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4npdyv",
          "author": "mountainlifa",
          "text": "This is why building for cloud is a regression. Developers are forced into using these third party tools to mock services to build and test features. This should either be native or not required. We are moving our of serverless lambda, dynamo etc to bare bones fast API, docker, postgres that I can run on a single workstation and build, test end to end. No more mocking dozens of services and patching all of my tests.",
          "score": 1,
          "created_utc": "2026-02-10 18:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1yky",
          "author": "cachemonet0x0cf6619",
          "text": "and this is why i will never recommend local testing of services. mock unit test and architect your application such that it can be tested in isolation.\n\neta: only people downvoting me are local stack employees that thought it was a good idea to charge for this and the the people using local stack that bought the lies",
          "score": -4,
          "created_utc": "2026-02-10 13:37:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4m5eu2",
              "author": "yesman_85",
              "text": "You don't do e2e test then? ",
              "score": 0,
              "created_utc": "2026-02-10 13:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4m5t18",
                  "author": "cachemonet0x0cf6619",
                  "text": "i do e2e in the cloud against actual resources",
                  "score": 4,
                  "created_utc": "2026-02-10 13:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1e6pa",
      "title": "Global cloudfront issues",
      "subreddit": "aws",
      "url": "https://health.aws.amazon.com/health/status",
      "author": "dennusb",
      "created_utc": "2026-02-10 21:43:13",
      "score": 42,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1e6pa/global_cloudfront_issues/",
      "domain": "health.aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4oyd3u",
          "author": "Difficult-Ad-3938",
          "text": "DNS =)",
          "score": 23,
          "created_utc": "2026-02-10 21:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owf8z",
          "author": "MidgardDragon",
          "text": "Yep RingCentral Contact Center was hard down for about an hour for us. Traced it back to CloudFront.",
          "score": 7,
          "created_utc": "2026-02-10 21:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pe35c",
          "author": "return_of_valensky",
          "text": "my company is having issues with docusign.. i figure this is as good of a reason as any why that might be.. errors logging in, sending documents etc",
          "score": 3,
          "created_utc": "2026-02-10 23:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pmphj",
          "author": "UpgradingLight",
          "text": "Jira was affected today for us, not sure if it’s this yet",
          "score": 1,
          "created_utc": "2026-02-11 00:03:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owvm2",
          "author": "rhaksw",
          "text": "AppSync is having issues for us",
          "score": 1,
          "created_utc": "2026-02-10 21:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p0nse",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -5,
          "created_utc": "2026-02-10 22:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p7xed",
              "author": "brile_86",
              "text": "global outages exist since way before vibe coding, not sure when you have started in IT",
              "score": 20,
              "created_utc": "2026-02-10 22:41:27",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxub7w",
      "title": "Bedrock - Requests for Future",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qxub7w/bedrock_requests_for_future/",
      "author": "Live_Bus7425",
      "created_utc": "2026-02-06 21:21:14",
      "score": 37,
      "num_comments": 14,
      "upvote_ratio": 0.95,
      "text": "Hello, my team has been using Bedrock since its infancy and we're a platinum tier Amazon partner. Here are my suggestions for Bedrock:\n\n\\* Add a new **embedding model**. Titan v2 is ok, but its 2 years old. Qwen/Qwen3-Embedding-0.6B is much better at 1024 dimensions. There are many open source models that excel at 512 dimensions also. We're using EC2 (or really ECS with EC2) to host them locally, but having them in Bedrock at a reasonable price would make things easier to maintain.\n\n\\* Add some inexpensive and easy to use **reranker** models that are open source. Cohere is just too expensive... we've been hosting some models on EC2, but we'd rather use Bedrock for jina-reranker-v3 / mxbai-rerank-large-v1 / bge-reranker-v2-m3 / qwen3-reranker-0.6B. \n\n\\* You're fast to add Anthropic models, which we really appreciate. But can you add other open source LLMs that you started investing into already? Where is **DeepSeek v3.2**? Where is **Kimi K2.5**? **MiniMax 2.1**? It feels like a lot of models you host are slightly outdated.\n\n\\* I don't know if anyone is using your **Nova models**. We've benchmarked them, and for the price/performance they always fall short. Sorry... If they were 2x cheaper, we would probably use them in some places.\n\nThis is my team's feedback on AWS Bedrock. I'm curious what other people think about Bedrock and where its lacking.",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1qxub7w/bedrock_requests_for_future/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o40596d",
          "author": "ruibranco",
          "text": "The embedding model situation is spot on. Titan v2 was fine when it launched but the open source space has moved so far ahead that hosting your own on ECS starts making more sense, which kind of defeats the purpose of a managed service. Same story with rerankers, Cohere pricing just doesn't work if you're doing any serious volume of reranking. Would love to see them add jina-reranker-v3 or even the smaller qwen models as first-class Bedrock options.",
          "score": 11,
          "created_utc": "2026-02-07 01:03:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3z3k9a",
          "author": "alex_aws_solutions",
          "text": "I can't get into detail because I just started with Bedrock. Our main object and an advantage is to host the llm's locally. But yes, they are definitely behind with some models.",
          "score": 5,
          "created_utc": "2026-02-06 21:35:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3z561b",
              "author": "Live_Bus7425",
              "text": "Yeah. I agree that local is usually better, but our use case requires data privacy and our usage is very spiky. At night we are almost idle, at peak times we're hitting bedrock limits. Bedrock is nice, because you don't have to maintain any infrastructure. ",
              "score": 3,
              "created_utc": "2026-02-06 21:43:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o406mo4",
          "author": "SoftwarePP",
          "text": "The nova models are incredible for their price offset. There are no models they can do as an example summarization cheaper.",
          "score": 3,
          "created_utc": "2026-02-07 01:11:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o409ezg",
              "author": "Live_Bus7425",
              "text": "Really? Our benchmarks show Haiku 4.5 and even gpt-oss-120B better and cheaper than Nova 2 Pro. Public benchmarks seem to agree. The other thing we didn't like is the speed of Nova models. I'd expect them to be insanely fast, but that was not the case.",
              "score": 1,
              "created_utc": "2026-02-07 01:28:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o42dn57",
                  "author": "SoftwarePP",
                  "text": "Nova lite and micro are pretty much free.",
                  "score": 3,
                  "created_utc": "2026-02-07 11:44:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3z8uzx",
          "author": "d70",
          "text": "Re: embedding - Tried amazon.nova-2-multimodal-embeddings-v1:0? Released at last re:Invent",
          "score": 3,
          "created_utc": "2026-02-06 22:01:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zgup2",
              "author": "Live_Bus7425",
              "text": "Really nice embedding model. We've used it for Audio and its kinda cool. I was talking about text embeddings, which is probably 99% of use cases for embedding models... at least in my little bubble =)",
              "score": 3,
              "created_utc": "2026-02-06 22:43:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o43d1on",
                  "author": "Opening-Concert826",
                  "text": "Have you looked at the docs? It supports text: https://docs.aws.amazon.com/nova/latest/nova2-userguide/embeddings.html",
                  "score": 2,
                  "created_utc": "2026-02-07 15:29:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o41wa01",
          "author": "Nepgyaaa",
          "text": "DeepSeek v3.2, Kimi K2.5, MiniMax 2.1 are all available now on Bedrock.",
          "score": 3,
          "created_utc": "2026-02-07 08:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41z47c",
          "author": "ChlorrOfTheMask",
          "text": "Yes, please new embedding and reranking models!",
          "score": 1,
          "created_utc": "2026-02-07 09:24:43",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyukj6",
      "title": "ECS is supposed to be simple?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qyukj6/ecs_is_supposed_to_be_simple/",
      "author": "ReturnOfNogginboink",
      "created_utc": "2026-02-08 00:42:51",
      "score": 32,
      "num_comments": 30,
      "upvote_ratio": 0.83,
      "text": "I've spent the day banging my head against the wall here. I have a container definition in a task definition in a service definition. I have an ECS cluster and a VPC and I have three subnets in three AZs and I have a private endpoint to ECR. I have a security group that should allow these pieces to talk to each other. I have a task execution role that has permissions on ECR and CloudWatch Logs.\n\nECS can't pull the task from ECR and I don't know why.\n\nThe SSM runbook \"**TroubleshootECSTaskFailedToStart**\" runs four out of the twelve steps and says 'success' without giving me any output.\n\nDoes anyone have a sample Terraform stack that shows creating a soup-to-nuts ECS service?\n\nCan anyone opine what might be causing ECS to fail to pull from RDS?\n\nThis is one of my more frustrating days with AWS.\n\nEDIT: The error I finally get is:  \nTask stopped at: 2026-02-08T00:42:44.811Z\n\n`ResourceInitializationError: unable to pull secrets or registry auth: The task cannot pull registry auth from Amazon ECR: There is a connection issue between the task and Amazon ECR. Check your task network configuration. operation error ECR: GetAuthorizationToken, exceeded maximum number of attempts, 3, https response error StatusCode: 0, RequestID: , request send failed, Post \"https://api.ecr.us-west-2.amazonaws.com/\": dial tcp 34.223.24.13:443: i/o timeout`\n\nHm... my ECR interface endpoint is for com.amazonaws.us-west-2.ecr.dkr and is in 10.0.x.y... Did I create an interface endpoint for the wrong service??",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1qyukj6/ecs_is_supposed_to_be_simple/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o469zum",
          "author": "Traditional_Donut908",
          "text": "Does the fact that you have a private endpoint to ECR mean this is in a private subnet with no NAT gateway? If so you actually need 3 different endpoints.",
          "score": 51,
          "created_utc": "2026-02-08 00:46:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47dedi",
              "author": "cabblinlmao",
              "text": "to answer OP's question, no. ECS is not Lambda. it will be more complicated lol",
              "score": 3,
              "created_utc": "2026-02-08 05:05:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46amxg",
              "author": "water_bottle_goggles",
              "text": "nice",
              "score": 5,
              "created_utc": "2026-02-08 00:50:36",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o46hxy0",
              "author": "ReturnOfNogginboink",
              "text": "One endpoint with three subnet attachments is how it shows up in the GUI.",
              "score": -6,
              "created_utc": "2026-02-08 01:36:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o46ly0f",
                  "author": "clintkev251",
                  "text": "Nope, that's not the same thing. That's one single endpoint. You're missing at least 1 (I see elsewhere you say you have S3)",
                  "score": 19,
                  "created_utc": "2026-02-08 02:01:30",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46d687",
          "author": "low_freq",
          "text": "4 key things I found to get ECS up and running in a private subnet (no internet gateway or NAT).\n\n1. VPC Gateway endpoint for s3 (service_name= com.amazonaws.region.s3) (this tripped me up the most, but ECR actually has some backing in S3 apparently)\n2. VPC interface endpoint for ecr api (service_name=com.amazonaws.region.ecr.api)\n3. VPC interface endpoint for ecr for (servicename=com.amazonaws.region.ecr.dkr)\n4. Appropriate perms. Deployer should have “ecr:GetAuthorizationToken”, amongst all the other ecr actions needed, and look at managed policy “AmazonECSTaskExecutionRolePolicy” for a starting point for the role to assign to the task definition. \n\nApologies for formatting, on mobile.",
          "score": 27,
          "created_utc": "2026-02-08 01:06:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46ekb2",
          "author": "Important_Winner_477",
          "text": "your interface endpoint is only half the battle. you likely missed the `com.amazonaws.us-west-2.ecr.api` endpoint or forgot the s3 gateway endpoint required for the actual layer downloads. without the api endpoint, your task times out trying to hit the public ecr auth range (34.223.x.x) from a private subnet with no nat gateway. check if your security group allows inbound 443 from the task's cidr on *all* required endpoints. are you also allowing egress to s3 in your task security group, or is the missing s3 gateway endpoint what's actually hanging the pull?",
          "score": 15,
          "created_utc": "2026-02-08 01:14:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46i1ow",
              "author": "ReturnOfNogginboink",
              "text": "I do have an S3 gateway interface. But you're right; I have to check the security group(s) on that.",
              "score": 2,
              "created_utc": "2026-02-08 01:36:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o46ngvp",
                  "author": "Important_Winner_477",
                  "text": "Glad the S3 tip helped. Since you're still hitting timeouts, I'd bet it's the missing ECR API endpoint or a SG rule. I'm a certified cloud pen tester looking for more hands-on cases if you want, I can help you audit your Security Groups and IAM roles for free just to get the practice in?",
                  "score": -3,
                  "created_utc": "2026-02-08 02:11:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o46cdk9",
          "author": "clintkev251",
          "text": ">I have a private endpoint to ECR\n\nI have some doubts in your configuration there. The error clearly shows that the request is going out to a public IP. If you had a correctly configured interface endpoint for ECR, this request would be going to a private IP. Take another look at your configuration there. Remember there are multiple endpoints required for a successful image pull\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html",
          "score": 10,
          "created_utc": "2026-02-08 01:01:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bwff4",
              "author": "ReturnOfNogginboink",
              "text": "I had the interface endpoint I had it associated with the right subnets and route table, but hadn't turned on private DNS resolution on it.",
              "score": 1,
              "created_utc": "2026-02-08 22:21:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46g63a",
          "author": "bryantbiggs",
          "text": "https://github.com/aws-ia/ecs-blueprints",
          "score": 5,
          "created_utc": "2026-02-08 01:25:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46czci",
          "author": "JEHonYakuSha",
          "text": "There’s a few permissions required for ECS to retrieve from ECR. Did you provide them all?\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/ECR_on_ECS.html",
          "score": 3,
          "created_utc": "2026-02-08 01:04:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o46i6sp",
              "author": "ReturnOfNogginboink",
              "text": "Yes, those are in the policies on the task execution role. Thank you.",
              "score": 2,
              "created_utc": "2026-02-08 01:37:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o46a9hj",
          "author": "Nearby-Middle-8991",
          "text": "It has been a while, but if it's running on top of an ec2 ASG, the role in the ec2s also need tweaking ",
          "score": 2,
          "created_utc": "2026-02-08 00:48:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48j50v",
          "author": "guareber",
          "text": "Amazon Q is surprisingly not-terrible at finding out issues with existing resources and errors when they are AWS related. Try walking it through the scenario and allowing it to look up your resources.",
          "score": 2,
          "created_utc": "2026-02-08 11:25:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4863eq",
          "author": "forsgren123",
          "text": "Hook up Claude Code to your Terraform codebase and AWS MCP server (or AWS CLI), and it will tell you what's wrong in two minutes.",
          "score": 3,
          "created_utc": "2026-02-08 09:22:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46a51i",
          "author": "SnoopJohn",
          "text": "Can you share you terraform might make it easier to see the problem ",
          "score": 1,
          "created_utc": "2026-02-08 00:47:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o48ln5n",
          "author": "SoggyGrayDuck",
          "text": "Personally i feel like it's one of the more complicated pieces, that and ec2 BUT I've never really dealt with on prem. I think it's the opposite for experienced onprem moving to the cloud",
          "score": 1,
          "created_utc": "2026-02-08 11:48:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4bdxif",
          "author": "2BucChuck",
          "text": "I guess I get why people bash Claude but build an IAM role with display only access to the landscape resources you need and just ask Claude code to help troubleshoot- it will use the CLI and boto to find the issue. Guaranteed.  There is some learning value to banging your head on the wall but AWS is a steep learning curve at first and if Q doesn’t help you solve it Claude code will for sure",
          "score": 1,
          "created_utc": "2026-02-08 20:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c520s",
              "author": "MealVan",
              "text": "Best answer. Claude’s ability to diagnose infra issues with just AWS CLI read only commands and some Python scripts is unmatched.",
              "score": 3,
              "created_utc": "2026-02-08 23:10:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4f0ca9",
          "author": "KayeYess",
          "text": "I presume you are not using an Internet NAT Gateway or forward proxy or some other solution like natting to a Public VIF. If so, you would need VPC End-points for all AWS services you use\n\n\nYou would need both ECR VPC end-points ... one for Docker and one for the core API itself:\n\ncom.amazonaws.region.ecr.dkr\ncom.amazonaws.region.ecr.api\n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html\n\nECS itself has a few\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/vpc-endpoints.html\n\nFor a list of all AWS Services that supports VPC end-points, check this document: https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.html",
          "score": 1,
          "created_utc": "2026-02-09 11:27:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o46i8gn",
          "author": "angcritic",
          "text": "Try using Kiro. As a non-cloud engineer who seems to get trapped in cloud issues, it has changed my life and probably added a couple of years to my late career. (Kiro is Amazon's AI and if you logged in or credentialed, it will answer and analyze a lot of these nightmares.)",
          "score": 0,
          "created_utc": "2026-02-08 01:38:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47l5yd",
              "author": "japanthrowaway",
              "text": "Kiro is terrible imo.  Claude code with boto or AWS CLI is leap years ahead. ",
              "score": 3,
              "created_utc": "2026-02-08 06:09:07",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o47ncob",
              "author": "CamilorozoCADC",
              "text": "start rant\n\nI'm a Kiro power user and all in for it. but one thing that I need to overcorrect repeatedly is the poor thing noticing that I deploy on ECS within a Private Subnet which causes a desire for adding a NAT Gateway. And asking the thing for troubleshooting in OP's situation doesn't help at all because it always resorts to the NAT Gateway solution. I know its dumb but it happens so often its irritating\n\nEnd rant",
              "score": 2,
              "created_utc": "2026-02-08 06:28:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46g263",
          "author": "FunkyDoktor",
          "text": "Claude, analyze why this doesn’t work. Give me a detailed analysis document with current issues and what can be improved. Make sure the deployment is secure. I will check back once I’ve had my coffee. Off you go.",
          "score": 0,
          "created_utc": "2026-02-08 01:24:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o472w22",
          "author": "yarenSC",
          "text": "Not now, but general advise:\n\nIf possible, adding an IGW (and route to it) is a simple way to debug a problem in a dev environment.  That'll help narrow down if it's a connectivity issue or not.\n\nReachability Analyzer is also quite useful for debugging",
          "score": 0,
          "created_utc": "2026-02-08 03:50:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o47j7bw",
              "author": "yourparadigm",
              "text": "That only works if you give your containers public IPs, which you should never do.",
              "score": 3,
              "created_utc": "2026-02-08 05:52:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o46aud7",
          "author": "Old_Cry1308",
          "text": "aws is always a headache, try checking your security group settings.",
          "score": -7,
          "created_utc": "2026-02-08 00:51:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0ldl9",
      "title": "Structured outputs now available in Amazon Bedrock",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/structured-outputs-available-amazon-bedrock/",
      "author": "ckilborn",
      "created_utc": "2026-02-10 00:12:23",
      "score": 26,
      "num_comments": 2,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1r0ldl9/structured_outputs_now_available_in_amazon_bedrock/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4jzhfn",
          "author": "omenking",
          "text": "Hmmm. Structured outputs is always a gotcha with multiple models and so I'd be wary to believe it works across all available models.",
          "score": -1,
          "created_utc": "2026-02-10 03:37:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kkgdu",
              "author": "Seref15",
              "text": "It lists which models it works with at the bottom of the article.",
              "score": 4,
              "created_utc": "2026-02-10 06:08:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qw5snt",
      "title": "When using SQS and Lambda, what is the best way to rate limit how many messages the lambda can process per minute?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qw5snt/when_using_sqs_and_lambda_what_is_the_best_way_to/",
      "author": "PuppyLand95",
      "created_utc": "2026-02-05 00:13:49",
      "score": 21,
      "num_comments": 53,
      "upvote_ratio": 0.93,
      "text": "My app allows users to do a bulk import of many products. When the user triggers a bulk import, each product will get enqueued to the sqs queue as a message. There is a lambda worker that will process from the queue. The problem is that in order to import the product I need to call a third party API which is rate limited (using a fixed window, e.g. 5000 api calls per day). Since there could be multiple users that trigger a bulk import at the same time, I was planning to use SQS \"fair\" queues to avoid the noisy neighbor problem.\n\nMy original idea was to create an internal rate limiter that would allow the lambda to process X amount of messages per minute. For example, 3 messages per minute. Once the limit per minute is reached, I was planning to use changeMessageVisibility() for any other messages it picks up until the next one-minute window begins. So for example, if there are 30 seconds left until the next minute window starts, I would make the message invisible for 30 seconds. But I realize now that if some messages are \"unlucky\" and keep getting changeMessageVisibility() called on them, then the receive count will increase and eventually they will be added to the dead letter queue. And for bulk imports, the queue will be quite full, so the lambda would be picking up messages continuously for a period of time.\n\nI'm aware we can use \"maximum concurrency\" on the SQS side and \"reserved concurrency\" on the lambda side, but this doesn't give me the granularity of control on the rate of processing that I am seeking.",
      "is_original_content": false,
      "link_flair_text": "serverless",
      "permalink": "https://reddit.com/r/aws/comments/1qw5snt/when_using_sqs_and_lambda_what_is_the_best_way_to/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3mnd6j",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'serverless'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+serverless).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-05 00:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mvc7v",
          "author": "_rundude",
          "text": "My suggestion:\nEvent bridge schedule to trigger the lambda\nLambda calls the message queue to process batches.\n\nSet the schedule to the relevant limit you need.\n5000/day = about 1 every 17 seconds. Which falls below the granularity of 1 minute. But that’s easy enough to create 3 or 4 schedules. (Or Eventbridge to sns > multiple lambdas. \n\nKeeps it all serverless.",
          "score": 31,
          "created_utc": "2026-02-05 00:57:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mydbo",
              "author": "bdavid21wnec",
              "text": "I like this answer, don't need to mess with any crazy lambda settings, just need to think about sqs retention period, your lambda should return an error if it fails to process and might need another dlq with a redrive policy or something",
              "score": 6,
              "created_utc": "2026-02-05 01:15:13",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3r8hpw",
              "author": "SpecialistMode3131",
              "text": "by far the simplest approach and I've used it too.",
              "score": 3,
              "created_utc": "2026-02-05 18:02:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mwccw",
          "author": "Zenin",
          "text": "One possible pattern that's not too hacky, if you can suffer a slight delay in processing your requests:\n\n**Inbox/Outbox Pattern**\n\nTwo SQS, two Lambdas, 1 DynamoDB table for quota tracking.\n\nDynamoDB: 1 row per hour storing an int for a count, configured with a TTL to auto-expire after 24 hours.  This is how we'll support a rolling daily rate limit check.  If you have a hard daily limit that rolls over at x time daily, just switch this to a single daily row.\n\nSenders -> Inbox SQS\n\nLambda A on cron such as \"rate(5 minutes)\": Reads all items from DynamoDB newer than 24 hours ago and sums the counts.  If the count is lower than your daily limit, take the difference and pull that many messages off the Inbox SQS and send them to the Outbox SQS for processing.  Update the current hour item count with however many more you've sent to Outbox making sure to set the TTL to 24 hours in the future for cleanup.  If you've reached your limit, just exit and try again next rate(5 minutes) or whatever.  Since each hour is an item and they are TTL set to auto-expire after 24 hours, DynamoDB will handle the cleanup of your old counts. -Expirations can take a while, even if they are usually quick, so don't rely on them for the scan() to only pull the latest 24...but the count is low enough a scan() + filter is very cheap here.\n\nLambda B subscribes to Outbox SQS: This is the setup you have now, just processes as fast as it can and doesn't care about limits because the first half of this already manages the rate limit into this SQS.\n\nThis Inbox/Outbox model gives you complete control on your processing rate for 3rd party calls while still allowing clients to burst without worry.  Add DLQ to everything of course, monitoring, etc, but that's the basic framework.\n\nThere's other ways to do this you might consider, such as manually handling exponential backoff + jitter and retry patterns using a 3 queue model and metadata in the message attributes, but if we're strictly talking about honoring 3rd party rate limits the above inbox/outbox pattern has worked well for me and doesn't waste costly CPU/memory cycles on sleep() calls.",
          "score": 10,
          "created_utc": "2026-02-05 01:03:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3morzy",
          "author": "aromaticfoxsquirrel",
          "text": "I would look at using a single Fargate container to process the whole queue.  You can have a lot more control over the rate that way.\n\nThe downside, of course, is that it's a bit more to set up and it's more expensive.",
          "score": 12,
          "created_utc": "2026-02-05 00:21:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mpmyy",
              "author": "PuppyLand95",
              "text": "Yeah I was considering using fargate as well. I guess I can just make the fargate task sleep for however long it needs to until the next minute-window, instead of constantly receiving messages from the queue and having to call changeMessageVisibility()",
              "score": 2,
              "created_utc": "2026-02-05 00:26:19",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3mq6pi",
                  "author": "aromaticfoxsquirrel",
                  "text": "I think you might be able to do something with Step Functions as well, but I have no idea how that would work with pricing.  And setting that up would be a real pain.",
                  "score": 4,
                  "created_utc": "2026-02-05 00:29:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3mrgpv",
                  "author": "Dangle76",
                  "text": "You can set a poll rate with an algo instead of using sleeps. It’s a better control pattern",
                  "score": 2,
                  "created_utc": "2026-02-05 00:36:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3mspo5",
                  "author": "x86brandon",
                  "text": "Overthinking it with message visibility.  SQS is durable.  \n\nWhen you're not doing Lambda triggers you have to make 2 calls.  Receive and Delete.  \n\nSo you Receive a message, hit the API, if throttled, retry and back off.  Once you get confirmation from the API, \\*then\\* Delete the message.  It's very ok for things to live in SQS for days.\n\nYou shouldn't have to throttle your calls to them as they should return a 429 to you.",
                  "score": 2,
                  "created_utc": "2026-02-05 00:43:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3mphmj",
          "author": "JustinSK1",
          "text": "Set Maximum Concurrency / Event Source Mapping [https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-scaling.html](https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-scaling.html)",
          "score": 18,
          "created_utc": "2026-02-05 00:25:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mt3kx",
              "author": "Zenin",
              "text": "How does this help?  It's entirely possible to saturate the 3rd party API limits with a single Lambda process, so reducing concurrency doesn't reliably throttle.",
              "score": -2,
              "created_utc": "2026-02-05 00:45:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mxqd3",
                  "author": "Donzulu",
                  "text": "Agree if you are limited to 5000/day, depending on how many API calls a single event can do, and even if it is only 1 api call, you can still do 5000 lambda invocation with max concurrency of 2 batch size of 1 in way less than a day. Let’s say each lambda takes 1 second to do the API calls, in 42 minutes you but your 5k cap.\n\nIf you are limited to 5/sec this solution is more feasible.",
                  "score": 3,
                  "created_utc": "2026-02-05 01:11:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3mu3v9",
                  "author": "kilobrew",
                  "text": "That’s the exact way to do it though…..",
                  "score": 9,
                  "created_utc": "2026-02-05 00:50:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3pi7i2",
              "author": "alapha23",
              "text": "This is the best way to",
              "score": 0,
              "created_utc": "2026-02-05 12:49:30",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3mu6z4",
              "author": "kilobrew",
              "text": "This is the way. It’s a well known pattern. Just ask chatGPT.",
              "score": -7,
              "created_utc": "2026-02-05 00:51:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3mqpm9",
          "author": "SonOfSofaman",
          "text": "The Fargate solution recommended by u/aromaticfoxsquirrel is probably the \"best\" solution, but another solution might be to use EventBridge Scheduler to fire off the Lambda function instead of using the SQS Event Source Mapping to trigger it. You can control the schedule as precisely as you need. This isn't the best solution because you might (will) end up triggering the Lambda function even when the queue is empty.\n\nWith either of these solutions, you'll end up polling the queue manually from the function instead of letting the Event Source Mapping do that for you.",
          "score": 8,
          "created_utc": "2026-02-05 00:32:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mq8dc",
          "author": "Forward_Context1013",
          "text": "check this out:\n\n[https://github.com/aws-samples/fine-grained-rate-limit-demo](https://github.com/aws-samples/fine-grained-rate-limit-demo)\n\nyou can set up something like this and reuse it for different apis with different rate limits ",
          "score": 3,
          "created_utc": "2026-02-05 00:29:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mti5p",
              "author": "Zenin",
              "text": "That's for API Gateway, which is great for adding rate limits to your *own* API providers, but does little to address the OP's ask of accommodating the rate limits of *third party APIs*.",
              "score": 2,
              "created_utc": "2026-02-05 00:47:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mu6no",
                  "author": "Forward_Context1013",
                  "text": "I think it is relevant still. OP can use the leaky bucket/token bucket concepts outside of api gateway implementation . But, fair point to clarify this",
                  "score": 2,
                  "created_utc": "2026-02-05 00:51:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3mrumn",
          "author": "Dull_Caterpillar_642",
          "text": "You get coarse grained control over it with these settings on the SQS trigger config:\n\n\n- Batch Size\n- Max Concurrency\n- Max Batching Window \n\n\nBut the unfortunate fact is AWS still doesn’t have a way to precisely dial in the requests per second.  You have to roll your own with something like a fargate task which serves as the consumer which triggers your lambdas, step functions, whatever.  But if you can get by with the coarse level of control you get by combining those things above, you can go purely lambda which is nice if you can swing it.\n\nI’ve done some experimenting with and you can actually get pretty slow and extremely fast with a purely lambda solution.  But you won’t get to just say “I want to go exactly 17 messages per second”",
          "score": 3,
          "created_utc": "2026-02-05 00:38:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3n66nt",
          "author": "ifyoudothingsright1",
          "text": "Eventbridge api destinations work for something measured in requests per second.\n\nStep functions also has some rate limiting functionality similar to above.\n\nFor something that low measured per day, it might be good to have an initial queue feed a lambda that keeps a atomically updated/read counter in dynamodb, and based on that counter schedules future events in aws scheduler.\n\nYou could also use step function wait steps instead of aws scheduler, using a dynamodb based counter like above.",
          "score": 2,
          "created_utc": "2026-02-05 02:00:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3n57ra",
          "author": "HKChad",
          "text": "If you get consumed/available counts in the results run it though a step function, use up your allocated amount then pause the step function, fill it up with queue.",
          "score": 1,
          "created_utc": "2026-02-05 01:54:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3otj0w",
          "author": "droning-on",
          "text": "I might skip sqs and just go with dynamo.   \n\nThe problem with sqs is tracking.  And you might need that in the event you have an error scenario and have to retry.  \n\nThe event bridge solution is nice but it slows the batch down on lighter days.  \n\nI'd say process as fast as you can.   When you reach your daily quota - or even at batch upload time - you could tell your consumer if their jobs will be processed today or tomorrow.",
          "score": 1,
          "created_utc": "2026-02-05 09:22:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p8nzl",
          "author": "RecordingForward2690",
          "text": "In addition to the other possibilities, there's another pattern that we have talked about internally, but never fully implemented. It requires two queues.\n\nQueue #1 is your existing queue where all the work is dumped into, irrespective of quota limits.\n\nYou then have a Lambda that is scheduled periodically (say, every 1-15 minutes), and reads messages from Queue #1. This Lambda knows about the rate limit, and only puts a number of messages into Queue #2 that can be handled within the schedule period. But here is the trick: Every time a message is inserted into Queue #2, it configures a DelaySeconds in the \"release\" of the message: This is an SQS SendMessage parameter that ensure messages are not becoming visible immediately, but only after a while. Obviously you ensure that the DelaySeconds is spread evenly over the schedule period.\n\n[https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API\\_SendMessage.html](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SendMessage.html) \\- see the DelaySeconds attribute. Note that this can have a maximum of 15 minutes, so you need to schedule the Lambda above at least every 15 minutes.\n\nThe last bit is the Lambda that reads Queue #2 and invokes the 3rd party API call. Due to the way the messages are released from Queue #1, you don't have to worry about rate limits anymore in this Lambda.",
          "score": 1,
          "created_utc": "2026-02-05 11:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o44w56e",
          "author": "ManyInterests",
          "text": "I would reconsider the architecture to use a different service to hold your pending imports. That's really what's making this problem harder than it has to be.",
          "score": 1,
          "created_utc": "2026-02-07 20:03:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o44zvpn",
              "author": "PuppyLand95",
              "text": "Which service do you think?",
              "score": 1,
              "created_utc": "2026-02-07 20:23:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o45nly3",
                  "author": "ManyInterests",
                  "text": "I'm guessing your system already includes a database of some sort, it can probably handle it.\n\nThe toughest problem you have is how work gets pulled off an SQS queue and its 'fairness'.\n\nIf your pending orders were, say, in a relational database, it would be really easy to pull out a \"fair\" subset of pending orders and execute on them (or submit them to a queue for immediate processing without processor handling any concerns of fairness).\n\nMake your code, not the queue, responsible for figuring out what should be processing at each given interval. Then you won't be limited by SQS mechanics.\n\nIf you don't already have a database of some sort, DynamoDB or even S3 could work, with some careful considerations.",
                  "score": 1,
                  "created_utc": "2026-02-07 22:32:07",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3mqi5i",
          "author": "x86brandon",
          "text": "Using Lambda to do that is an anti-pattern to Lambda.  You're better running a container worker.  And also, throttling is asking to increase your Lambda costs for no reason.  You want that to process the item as fast as possible to reduce # of seconds of CPU/RAM time.   If you throttle, you're slowing down something you pay per second, pay per invocation.\n\nIf you must use a Lambda and you have potentially a backlog of async processing with a throttled API, I would split the workers to have 1 Lambda handle the incoming, make state changes and then drop it into a queue that makes the external calls.  That queue you can set a Max Concurrency of 2.   It also gives you a place to do batching.   Especially if you're using single threaded stuff like Python, this gives you the ability to take a bunch of randomized incoming requests, enqueue them in a 2 worker batch queue.  The batching will let you pull like 100 messages and then throttle your calls in batches.",
          "score": -1,
          "created_utc": "2026-02-05 00:31:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3njjs6",
              "author": "ReporterNervous6822",
              "text": "Yeah idk why you are getting downvoted here using lambda just isn’t the right call. You need something in the middle triggering lambdas or to do it statefully or like use a database to orchestrate against",
              "score": 3,
              "created_utc": "2026-02-05 03:16:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3n6i8z",
          "author": "BoringTone2932",
          "text": "This would be hacky, but couldn’t you have the lambda disable the event source mapping, effectively to stop it from getting messages? \n\nYou’d have to solve for re-enabling it though, which would require a secondary lambda.\n\nBut you could theoretically have the processing lambda disable its own event source mapping and tag itself with a “re-enable” timestamp. Have another lambda check every X minutes to re-enable the mapping.\n\nLike I said, hacky.",
          "score": 0,
          "created_utc": "2026-02-05 02:02:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwgyaw",
      "title": "Trust and safety team to do not fill me with trust or safety",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qwgyaw/trust_and_safety_team_to_do_not_fill_me_with/",
      "author": "ergonomicpineapple",
      "created_utc": "2026-02-05 09:38:27",
      "score": 17,
      "num_comments": 3,
      "upvote_ratio": 0.76,
      "text": "I submitted a DMCA takedown notice to the trust and safety team via the appropriate channel. Days later, I finally received a response telling me the content was no longer available so they wouldn’t pursue it further. I immediately verified that the content was still available and highlighted the URLs again. They then sent me another email saying my report doesn’t meet requirements and I need to do XYZ - all stuff I provided in the original submission. And now silence... Classic Amazon customer service.\n\nThis is a relatively small issue in the grand scheme of things but God forbid I had anything serious to report.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qwgyaw/trust_and_safety_team_to_do_not_fill_me_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3qnrwj",
          "author": "ruibranco",
          "text": "The loop of \"we closed it\" followed by \"you didn't fill out the form right\" is painfully familiar. Had a similar experience with abuse reports - they acknowledge receipt, do nothing, then ask for info already provided. At some point you realize the process exists to exhaust you into giving up.",
          "score": 6,
          "created_utc": "2026-02-05 16:26:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3sh3ro",
              "author": "No-Rip-9573",
              "text": "I’m sure all the necessary KPIs were met and the support manager got their bonus!",
              "score": 4,
              "created_utc": "2026-02-05 21:32:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3qt6t0",
          "author": "AWSSupport",
          "text": "Hi there,\n\nI'm sorry to hear about your experience with receiving conflicting responses after submitting two DMCA notices for the same concern. We'd like to take a closer look into this. If you have report IDs for both submissions, please provide them via chat message.\n\n \\- Kita B.",
          "score": 3,
          "created_utc": "2026-02-05 16:51:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qza7v3",
      "title": "Silent behavioral change in NLB DNS publishing for empty AZs? (Breaking change for DR/Failover)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "author": "atawii",
      "created_utc": "2026-02-08 14:24:46",
      "score": 17,
      "num_comments": 19,
      "upvote_ratio": 0.96,
      "text": "Hi everyone,\n\nI’m noticing a significant discrepancy in behavior between legacy Network Load Balancers and newly created ones regarding how they handle DNS for Availability Zones with 0 registered targets.\n\n**The Setup:**\n\n* **Architecture:** Internet-facing NLB -> Target Group (Instance Type) -> K8s Nodes (NodePort).\n* **Cross-Zone Load Balancing:** **Disabled** (intentionally, for cost/latency reasons in a specific multi-AZ setup).\n* **Scenario:** 3 AZs with one specific AZ (e.g., `ca-central-1d`) has no healthy targets (0 nodes).\n\n**The Discrepancy:**\n\n1. **Old NLB (Created \\~2024):**\n   * **Behavior:** The NLB automatically removes the IP address of the empty AZ from the DNS record.\n   * **Result:** `dig comand` returns only 2 IPs (for the healthy AZs). Traffic is never routed to the empty AZ. Everything works.\n   * If we terminate all instances from the first AZ (1a) with AWS FIS, the DNS assigned from this AZ was also removed, so we have only one DNS remaining.\n2. **New NLB (Created Feb 2026):**\n   * **Configuration:** Identical to the old one (Terraform/OpenTofu code is the same).\n   * **Behavior:** The NLB **continues to publish the IP** of the empty AZ in the DNS record.\n   * **Result:** `dig` returns 3 IPs. Client traffic is round-robined to the empty AZ (\\~33% of requests). Since Cross-Zone is disabled and there are no local targets, these packets are blackholed, causing immediate connection timeouts/failures.\n\n**Support's Response:** I opened a ticket, and AWS Support claims *\"*After reviewing your case and consulting with our internal resources, I can confirm that \\*\\*this is the expected behavior for Network Load Balancers\\*\\*, and there has been no recent change to how NLBs handle DNS resolution for AZs with no registered targets*.\"*\n\nHowever, the empirical evidence (side-by-side `dig` results on same-region, same-config LBs) suggests otherwise.\n\n**The Impact:** This feels like a silent breaking change. Previously, we relied on the NLB's ability to \"drain\" an AZ from DNS if the backend was dead (fail-open style). Now, it seems new NLBs are \"sticky\" to their AZs regardless of backend health, which breaks standard DR/Failover patterns where you might spin down an AZ to save costs or during an outage.\n\n**Questions:**\n\n* Has anyone else noticed this shift in \"Fail Open\" behavior on recent NLBs?\n* Is there a new attribute (hidden or documented) that controls this \"DNS draining\" behavior?\n* Is the only solution now to force Cross-Zone Load Balancing (and pay the transfer costs) or manually manipulate Subnet mappings during an incident?\n\nThanks for any insights.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o499urc",
          "author": "ggbcdvnj",
          "text": "The amount of times support has told me “there’s been no change” when you eventually pull it out of the service team after enough escalation that there actually was a change kills me\n\nDealing with L1 AWS support drains my will to live\n\n</rant>\n\nSorry, all I can say is I wish you the best",
          "score": 14,
          "created_utc": "2026-02-08 14:34:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49brec",
              "author": "atawii",
              "text": "It's incorrect, but honestly, it's the best support response I've had in the last year. At least I got it in under 24 hours.",
              "score": 4,
              "created_utc": "2026-02-08 14:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49s8fv",
                  "author": "MateusKingston",
                  "text": "\"At least I got told the incorrect information fast\".\n\nLol.\n\nThey also even lied, if it was under 24h they didn't even check anything with anyone",
                  "score": 1,
                  "created_utc": "2026-02-08 16:10:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4cu6wz",
              "author": "Ok-Helicopter525",
              "text": "Ok the flip side, customers are very quick to say “the service must have changed or broken something” only to find out, oops, it’s their environment that has the issue.",
              "score": 3,
              "created_utc": "2026-02-09 01:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o499f7m",
          "author": "notathr0waway1",
          "text": "This sounds super weird and interesting.  I feel like you documented it well and I hope someone competent actually addresses it.",
          "score": 9,
          "created_utc": "2026-02-08 14:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49cplf",
              "author": "atawii",
              "text": "I'm able to reproduce with old NLB  the behavior. I have report with AWS FIS (for example testing to disrupt an AZ), that is impossible with the new behavior. I'm pretty sure to be not alone.\n\nThe next think I want to test, if I reproduce in another AWS region.",
              "score": 2,
              "created_utc": "2026-02-08 14:50:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4akqy2",
          "author": "ruibranco",
          "text": "Check the target group attributes with \\`aws elbv2 describe-target-group-attributes\\` on both old and new. Specifically look at \\`target\\_group\\_health.dns\\_failover.minimum\\_healthy\\_targets.count\\` and the unhealthy state routing settings. AWS changed some defaults on newer TGs and it's not always reflected in the Terraform state if you're importing or if the provider version changed between the two deploys.",
          "score": 6,
          "created_utc": "2026-02-08 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c0ldy",
              "author": "atawii",
              "text": "Yes, I already check with the UI (and now with the CLI) the minimum\\_healthy\\_targets value is 1 on tjhe old and the new target group. That same to be the default and minimal settings.",
              "score": 1,
              "created_utc": "2026-02-08 22:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ca8le",
                  "author": "ruibranco",
                  "text": "Interesting, if TG attributes match then it's probably at the NLB level. Check if cross-zone load balancing is configured the same on both, and also compare the \\`dns\\_record.client\\_routing\\_policy\\` attribute on the NLB itself. AWS quietly introduced zonal affinity settings that can affect DNS behavior when an AZ has no healthy targets.",
                  "score": 1,
                  "created_utc": "2026-02-08 23:40:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49ae1u",
          "author": "yarenSC",
          "text": "Definitely push back on the support case to explain what's different between the 2.  It's either a bug (since the public docs explicitly say DNS fail over should happen), or something is different \n\nAre you sure there isn't a second target group on the new NLB?  And are all targets healthy?\nWhat you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS",
          "score": 3,
          "created_utc": "2026-02-08 14:37:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49c677",
              "author": "atawii",
              "text": ">since the public docs explicitly say DNS fail over should happen\n\nDo you have a link to the documentation that explain that? I don't find it.\n\n>Are you sure there isn't a second target group on the new NLB? And are all targets healthy? What you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS\n\nYes, I'm sure all instances are healthy on the target group.",
              "score": 2,
              "created_utc": "2026-02-08 14:47:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49drfz",
                  "author": "yarenSC",
                  "text": "[https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health)\n\n  \nThis also has a list of things for you to check to see why it might be failing open.  Note there's a new setting that could be impacting this where you can change the minimum healthy hosts required for an AZ to be considered healthy.  Although if your terraform is identical, then presumably it isn't being used on your new NLB\n\n[https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/](https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/)",
                  "score": 3,
                  "created_utc": "2026-02-08 14:56:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ao28f",
          "author": "x86brandon",
          "text": "Couple of things:\n\nAre you doing the dig against your CNAME or the AWS NLB hostname?  What are you running the dig against? AWS auth or your local DNS?  There are quite a few cases where DNS providers do not honor the low TTL and I have seen places like Comcast take 5-10 minutes to expire the record regardless of the 60 second TTL.  That could be at play here.   I would be curious to see if you still see that after a minute or two from AWS auth servers.  \n  \nDepending on your SLA/SLO, you shouldn't rely on failover this way anyways, you will always have several minutes of black hole potential with an NLB.  In my most critical of apps, before zonal shift existed, I used to do NLB per AZ and orchestrate my traffic failover myself.   It also triples my capacity capability.  However, if you want to purposefully shut down an AZ, I would suggest using zonal shift to get traffic it off it before you remove the AZ.",
          "score": 2,
          "created_utc": "2026-02-08 18:42:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bzwzn",
              "author": "atawii",
              "text": "We use CloudFront in front of the ELB, so it relies solely on AWS's internal DNS resolver, bypassing client-side DNS issues. We have tested this multiple times, and the downtime during an AZ disruption is only 10 seconds. Zonal Shift is still interesting, but we view it as complementary.\n\nIn our case, we have the exact same result after 1m or 60minutes from AWS DNS resolver or internet resolver.",
              "score": 2,
              "created_utc": "2026-02-08 22:40:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4asmwb",
          "author": "x86brandon",
          "text": "Interestingly, Terraform changed the way subnets are handled because of a new API function added.   And folks are complaining about stale IP's being left in target groups creating a similar behavior too.   Something to look at that might explain the differences between the 2 NLB's, especially if your old one was created one way and the new one created another.   As the underlying API interaction in Terraform changed last year.\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41418](https://github.com/hashicorp/terraform-provider-aws/issues/41418)\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41880](https://github.com/hashicorp/terraform-provider-aws/issues/41880)",
          "score": 2,
          "created_utc": "2026-02-08 19:03:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qx5llu",
      "title": "Performance impact after migrating to Aurora Global Database ?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qx5llu/performance_impact_after_migrating_to_aurora/",
      "author": "rinvn",
      "created_utc": "2026-02-06 02:39:37",
      "score": 16,
      "num_comments": 14,
      "upvote_ratio": 0.87,
      "text": "We currently operate an **Amazon Aurora MySQL** cluster with **4 instances in a single AWS Region**, and we are considering migrating to **Aurora Global Database** with a **headless secondary cluster** for **disaster recovery (DR)**.\n\nFrom what I understand, Aurora Global Database uses a **dedicated replication mechanism at the storage layer** to continuously copy data from the primary Region to the secondary Region. Because replication is handled at the storage layer (rather than by typical MySQL replication on the writer instance), I *expect* the performance impact on the primary cluster to be limited.\n\nI would greatly appreciate if anyone could share **real-world operational experience** with Aurora Global Database, specifically:\n\n* Performance impact on the primary cluster (writer and readers)\n* Any technical issues or operational pitfalls you encountered\n* Practical advice for production operations and DR readiness\n\n**Note:** I have already reviewed the official documentation on Aurora Global Database limitations, but I’m looking for additional **hands-on experience and real-world lessons learned**.",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1qx5llu/performance_impact_after_migrating_to_aurora/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3u0mph",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-06 02:39:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uaaqr",
          "author": "davvblack",
          "text": "Surprisingly, there's almost no impact.  They do some crazy voodoo with the storage layer, but the reader load is quite separated.  Admittedly we mostly use Postgres, not MySQL, but aurora has been great for us.  It does cheat in a small way, certain workloads on the aurora readers get terminated if they would cause WAL lag to grow over some very low number.  In some cases this has meant we need some separate way to do a reader instead.  I don't know if MySQL has a similar circumstance.\n\nTLDR: no writer problems, but your reader isn't as powerful in this setup.",
          "score": 9,
          "created_utc": "2026-02-06 03:38:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3uexdj",
          "author": "ruibranco",
          "text": "We ran Aurora Global Database with MySQL for about a year before switching the DR strategy. Writer performance was basically unchanged, the storage-level replication really does stay out of the way. The one thing that bit us was the replication lag during heavy write bursts. Normally it sits under a second, but during bulk imports or schema migrations it could spike to 5-10 seconds. Not a problem for DR, but if you ever plan to promote the secondary for read traffic or active-active, keep that in mind. The headless secondary setup is solid for pure DR though. Just make sure you actually test the failover process regularly because the promotion itself takes a couple minutes and there are some gotchas around DNS caching and connection draining that the docs gloss over.",
          "score": 7,
          "created_utc": "2026-02-06 04:08:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3unaym",
              "author": "rinvn",
              "text": "\\>The headless secondary setup is solid for pure DR, though.\n\nIt's reassuring to know this, thank you.\n\n\n\n\\>Just make sure you actually test the failover process regularly because the promotion itself takes a >couple of minutes, and there are some gotchas around DNS caching and connection draining that the >documentation glosses over.\n\nCould you share more details?\n\nDNS caching: Do you mean the application still keeps a DNS cache pointing to the old primary? Should we use the cluster endpoint instead of the global endpoint (i think we will update the database endpoint in the app to ensure transparency and avoid split-brain)",
              "score": 5,
              "created_utc": "2026-02-06 05:06:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3w6qqd",
                  "author": "davvblack",
                  "text": "an example is, if your app connection pools, it will try to keep writing to the reader after the failover unless you explicitly handle it.\n\nSomething like PGBouncer or RDSproxy can manage that for you, but that comes at the cost of a little latency, so the other path is to know how to do it inside the app.",
                  "score": 1,
                  "created_utc": "2026-02-06 12:55:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3vshaj",
          "author": "ruibranco",
          "text": "You're right that the storage-layer replication means minimal impact on the writer compared to binlog-based replication. In practice we saw maybe 1-2% write latency increase on the primary, which is basically noise. The bigger gotcha is replication lag to the secondary region, which is typically under a second but can spike during heavy write bursts. Make sure you understand what that means for your RPO targets. The other thing that catches people is failover time. Aurora Global Database failover isn't instant, you're looking at around 1-2 minutes for a managed planned failover and potentially longer for unplanned. If your DR requirements need sub-30-second failover you might want to look at Aurora Global Database with write forwarding or a multi-region active-active pattern instead. Also test your failover runbook regularly, the number of teams that set up Global Database for DR and never actually test a failover is way too high.",
          "score": 5,
          "created_utc": "2026-02-06 11:10:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3w93q8",
              "author": "rinvn",
              "text": "Thank you for your advice !\n\nI will consider it and test it thoroughly.",
              "score": 1,
              "created_utc": "2026-02-06 13:09:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3y6rb3",
          "author": "KayeYess",
          "text": "Whatever AWS does behind the scenes, cross region replication has to traverse the network between regions. There in comes async lag.\n\n\nIf you want high consistency across regions, DSQL is an option but because the writes are replicated at commit time in sync, they will be slightly slower than async based replication.\n\n\nThe best way to figure out what works for you is to test different scenarios against your requirements.",
          "score": 4,
          "created_utc": "2026-02-06 18:53:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zxehd",
              "author": "rinvn",
              "text": "Thank you. ",
              "score": 1,
              "created_utc": "2026-02-07 00:17:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xrhqq",
          "author": "StandardCompote6662",
          "text": "Minor version updates are the only pain I have come across with the global database.  You have to remove the secondary cluster, update the primary and then re-add the secondary which takes time.  Or use the new blue green failover which is still painful.",
          "score": 2,
          "created_utc": "2026-02-06 17:41:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3zxcbr",
              "author": "rinvn",
              "text": "Thank you. \nI checked that limitation in AWS document.",
              "score": 1,
              "created_utc": "2026-02-07 00:17:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3u0mo9",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-06 02:39:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwywkb",
      "title": "Designing ID verification for retail POS and questioning if serverless architecture can handle offline requirements",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qwywkb/designing_id_verification_for_retail_pos_and/",
      "author": "ForexedOut",
      "created_utc": "2026-02-05 21:53:31",
      "score": 15,
      "num_comments": 14,
      "upvote_ratio": 1.0,
      "text": "Building identity verification for retail age-restricted sales. Works great online with Lambda functions calling third-party verification APIs. Now client wants the same verification at physical registers.\n\nProblem is network connectivity isn't guaranteed in all store locations. Started looking at offline-first design with edge processing but that means running verification logic locally on tablets which seems fragile.\n\nHas anyone built identity verification that works both online and offline or is this a case where I need completely different architectures for each use case?",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1qwywkb/designing_id_verification_for_retail_pos_and/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3sn1sq",
          "author": "Due-Philosophy2513",
          "text": "lol nobody in retail runs actual biometric verification at registers. They scan IDs to log the transaction for compliance but the cashier is still eyeballing whether the person matches. Automated verification for age restricted sales is definitely overkill.",
          "score": 11,
          "created_utc": "2026-02-05 22:01:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3uadjm",
              "author": "ppafford",
              "text": "welcome to the new age of retail\n\n\\* [https://www.justwalkout.com](https://www.justwalkout.com)\n\n\\* [https://www.popid.com](https://www.popid.com)\n\n\\* [https://microblink.com/products/platform/?feature=liveness](https://microblink.com/products/platform/?feature=liveness)\n\n\\* [https://www.yoti.com/blog/yoti-age-estimation-white-paper/](https://www.yoti.com/blog/yoti-age-estimation-white-paper/)\n\nwhy rely on someone to verify, when a camera and scanner would giver a more accurate validation. I can imagine restricted product store owners might be offered a lower insurance rate, credit card rate, etc... for the additional validation metrics, when they could be simple to use or automated all together",
              "score": 2,
              "created_utc": "2026-02-06 03:38:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3sql7r",
          "author": "Smooth-Machine5486",
          "text": "You're gonna end up with two completely different systems. Online gets real verification with API calls and fraud detection while offline gets cached validation that checks if the ID format looks right and hopes for the best. Understand that retail stores have been checking IDs manually for decades, automation isn't always the answer here.",
          "score": 9,
          "created_utc": "2026-02-05 22:18:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tjfse",
          "author": "ShakataGaNai",
          "text": "Backup a step. How do you verify an ID? You said you reached out to 3rd party API's. So Lambda or local compute or coconut carrying swallow... it doesn't matter if you NEED to reach out to a 3rd party.\n\nSo you need to answer the question is \"How do we verify an ID without anyone else being involved?\". That almost seems like a service in and of itself. In fact I'd wager that someone probably already does sell it. Of course, it depends on how \"verified\" you need.\n\nDo you need to check state DL database? Well.... ya can't do that offline. Or do you just need to verify that a picture of someone matches the pictures on a DL? That's an easier problem.\n\nAlso also. Why not just fix the network connectivity? Startlink? Amazon Leo? 5G backup?",
          "score": 4,
          "created_utc": "2026-02-06 00:57:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3suzmg",
          "author": "Only_Helicopter_8127",
          "text": "Offline verification sounds good until you realize how much data verification actually needs to phone home. watchlists, document databases, fraud signals all require connectivity. Eventually ended up with au10tix after testing a few options because their mobile SDK can run basic validation offline and queue results for full verification later. But, offline-first and security don't play nice together.",
          "score": 3,
          "created_utc": "2026-02-05 22:40:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3syep3",
          "author": "Similar_Cantaloupe29",
          "text": "Essentially network connectivity is required for age restricted sales and have a manual fallback policy when internet dies because offline verification is a liability nightmare waiting to happen for compliance teams.",
          "score": 1,
          "created_utc": "2026-02-05 22:58:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ton9l",
          "author": "ruibranco",
          "text": "The pattern that works well here is \"offline-first with deferred verification.\" Do the basic format checks locally on the tablet (barcode parsing, expiry date, ID format validation) and let the sale go through in a degraded mode. Then queue the full verification request to SQS once connectivity is back, and flag the transaction for review if it fails async. AppSync with local resolvers or just a local SQLite db on the tablet with a sync Lambda can handle this nicely. You're never going to get the same confidence offline as you do with real-time API verification, so the architecture question is really about how much risk the business is willing to accept during outages.",
          "score": 1,
          "created_utc": "2026-02-06 01:28:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tvmuj",
          "author": "cloudnavig8r",
          "text": "“Client wants”  - with enough money anything is possible.\n\nBut the 3rd party APi dependency is a constraint.\n\nYou need to have a business requirements conversation.\n\nI’ve worked with clients (retail) that had many stores that **needed** to operate disconnected from corporate.  This was a scenario of describing the limitations of being offline (example: credit card processing needs to communicate with an external bank)\n\nThe recovery is another consideration, you want to automatically go back to full online capacity\n\nYou should be looking at getting the business to understand a circuit breaker approach and the trade-offs.\n\nYou can address where redundancy can assist in increasing availability- and at what costs",
          "score": 1,
          "created_utc": "2026-02-06 02:10:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tzwae",
          "author": "d70",
          "text": "How many deployments would you be maintaining and troubleshooting for all of the offline locations? PTSD from writing software used in subs.",
          "score": 1,
          "created_utc": "2026-02-06 02:35:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3u7x15",
          "author": "ppafford",
          "text": "Hmm, in the past I did a POC using this company [https://microblink.com/products/platform/?feature=liveness](https://microblink.com/products/platform/?feature=liveness) seems related to what you're trying to do. It's been a while but I do remember doing offline verifications",
          "score": 1,
          "created_utc": "2026-02-06 03:23:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3vtdzh",
          "author": "RecordingForward2690",
          "text": "Talk to a lawyer or read up on the details of the law itself. Depending on how the law/regulation is phrased, offline/delayed validation may not be a legal option at all. After all, you can't really undo a retail sale once the customer has walked out the door.\n\nIt sounds much more practical to ensure network connectivity is always there. Even if it means attaching a 4G/5G modem with a prepaid SIM to the store network as a backup solution. That won't be able to handle the employees watching Netflix during their break, but it will provide enough bandwidth for these kinds of verifications.",
          "score": 1,
          "created_utc": "2026-02-06 11:18:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lzptz",
          "author": "idkbm10",
          "text": "It seems like you need to do offline first development using iot services of an mqtt service like iot core",
          "score": 1,
          "created_utc": "2026-02-10 13:25:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvid5g",
      "title": "How to evaluate if hybrid AWS GCP setup improves cost and resilience",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qvid5g/how_to_evaluate_if_hybrid_aws_gcp_setup_improves/",
      "author": "SlightReflection4351",
      "created_utc": "2026-02-04 07:42:06",
      "score": 14,
      "num_comments": 17,
      "upvote_ratio": 0.86,
      "text": "spent the last month designing a hybrid AWS/GCP setup that optimizes for cost and resilience. used GCP for our data pipeline and ML workloads, AWS for application hosting and compute. included proper failover, cross region redundancy, the whole thing.  \npresented it yesterday and got the usual questions. \"isn't this too complex?\" \"what if something breaks between clouds?\" \"why not just stay on AWS?\"\n\ni have good answers for all of this but now i'm wondering if i'm overcomplicating things. maybe the single cloud simplicity is worth the vendor lock in and higher costs? or maybe i'm just second guessing myself because i got pushback.  \nhow do you know when multi cloud is actually the right call versus just being architecture for the sake of architecture?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1qvid5g/how_to_evaluate_if_hybrid_aws_gcp_setup_improves/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3hvrdw",
          "author": "wy100101",
          "text": "You are probably over complicating things. It sounds like you are probably less robust now since you are now fully dependent on 2 providers instead of one.\n\nA more resilient multi cloud strategy would be where everything keeps working if either go down.",
          "score": 14,
          "created_utc": "2026-02-04 08:13:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ibxon",
              "author": "LemonFishSauce",
              "text": "Totally concur. OP is doubling their risk. Now they are impacted if any one of the two clouds are down.",
              "score": 8,
              "created_utc": "2026-02-04 10:45:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3htzpi",
          "author": "UnluckyTiger5675",
          "text": "Correct me if I’m wrong but you still couldn’t “lose” one cloud, right? Should AWS have a multi-region multi-service outage (again), is your production still not down? It sounds like you’re as resilient in AWS as you can get, and I don’t know your app(s), but what about such an outage at google? How integral to your apps are the ML/datapipe components? Do they have a different RTO/RPO?",
          "score": 11,
          "created_utc": "2026-02-04 07:57:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3hxljb",
              "author": "EconomistAnxious5913",
              "text": "In this case a country/or region, could ban a cloud provider from a different geo.\n\ne.g. say the EU could ban US cloud providers, even today there are lot of restrictions on using US cloud providers vs EU based cloud providers for certain EU sponsored projects.\n\nto add, this specific problem isn't going to be solved AWS v/s GCP",
              "score": -5,
              "created_utc": "2026-02-04 08:30:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3hu6i1",
          "author": "behusbwj",
          "text": "Multicloud if:\n* a different platform offers a unique solution that reduces complexity more than multi-cloud increases complexity\n* a different platform offers a price that is lower than the cost of the time spent managing additional complexity (billing, onboarding, maintenance, operations etc will be forever costs).\n\nBoth of those points are rare to fulfill. There are few problems that can’t be solved on either platform.",
          "score": 10,
          "created_utc": "2026-02-04 07:59:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ishom",
          "author": "invidiah",
          "text": "Multicloud is always more expensive because of the maintenance costs. And if you need to comply with some regulation rules or pass any kind of data protection audit that would be a hell.\n\n  \nHave you included already egress costs into your calculations?",
          "score": 4,
          "created_utc": "2026-02-04 12:51:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iuxu2",
          "author": "ReturnOfNogginboink",
          "text": "Agree or disagree, this is worth reading: https://www.lastweekinaws.com/blog/multi-cloud-is-the-worst-practice/",
          "score": 3,
          "created_utc": "2026-02-04 13:06:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3huahd",
          "author": "inphinitfx",
          "text": "Simply, when the real benefits outweigh the real downsides. That may be that there is a capability that one cloud platform provides that is fundamentally better for your use case, while other cloud platforms offer similar advantages in other areas. \n\nFrom your description, I'm assuming you've got different workloads in each cloud platform, rather than a single workload that spans both (although the question of what happens if something breaks between clouds kind of makes this one murky). This can be viable, but you need to ensure you've looked at all the relevant aspects - TCO (including operational overheads form complexity), security impact, etc. I've seen plenty of architects overlook these, and their $50k savings is eaten up by $100k in additional operational overheads to string it together.",
          "score": 2,
          "created_utc": "2026-02-04 08:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3iwx3v",
          "author": "yeochin",
          "text": "Having been someone who has made these calls before (as the final decision maker) - multi-cloud hybrids make no sense financially, resiliency-wise, and operationally. If you're going to use Azure, AWS, or GCP - stick to one.\n\nI am skeptical if you are truly calculating lower-costs. Usually:\n\n1. The cost analysis underestimates running Engineering costs required for oncall, maintenance and support. Most teams struggle with distributed systems. Observability of systems across clouds and 3P vendors becomes much more complex and painful.\n2. Temporary discounts provided by the 2nd cloud provider are erroneously factored in. You're making a long-term decision that costs significant money to unwind. Naiive business/tech leaders factor in the discounted run-rate which is a fundamental mistake.\n3. Data-transfer costs (realized and opportunity costs). Cloud providers often eat the costs of intra-network data transfer because its folded into the cost of setting up and maintaining compute. They are forced to charge some degree of ingress/egress costs because that is a cost born from another party (namely ISPs). The data-costs add up in both dollars and time (the amount of data that can move between compute nodes is several times greater than traversing the public internet).\n\nFor most businesses - going back to a hybrid on-prem is a wiser business and architectural decision for the same CapEX and OpEX you would need to operate a hybrid cloud. If you're trying to avoid vendor lock-in, going into a hybrid on-prem solution is a better architectural choice.\n\n* You will be forced to modularize your systems in a way that can be executed either on-prem or in-cloud.\n* You'll select vendors that have built solutions that keep you in the drivers-seat with how you use them. You'll find yourself \"owning\" what you purchase instead of \"renting it\" - meaning that you'll start to really assess the cost/value of holding a subscription.\n* You'll be intentional with your data-sovereignty ; leading to less headaches and less likely you get hit with the regulatory schtick which is due to whack a few folks in the upcoming years as the world starts to decouple with the American cloud providers.\n\nOnboarding a second cloud does not structurally reduce your running costs - it increases it. If you're going to increase it - its better to achieve real vendor independence.",
          "score": 2,
          "created_utc": "2026-02-04 13:18:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hy7dz",
          "author": "PokeRestock",
          "text": "What exactly does GCP have that AWS doesnt? For disaster recovery I would think Azure to be better, and if youre looking for VM specifics again Azure could be beneficial. \n\nBut Im not seeing how youre saving money with GCP in the mix. Also not seeing how you would share data between the two where you now have a separated monolith pipeline.",
          "score": 1,
          "created_utc": "2026-02-04 08:36:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3jga55",
              "author": "Dull-Engineer-1757",
              "text": "BigQuery is magic ",
              "score": 1,
              "created_utc": "2026-02-04 15:01:22",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3ixd4a",
          "author": "xxwetdogxx",
          "text": "I'd also consider data transfer costs, anything exiting one cloud provider to the other will be charged where typically within a cloud it wouldn't be, unless maybe it's cross-region",
          "score": 1,
          "created_utc": "2026-02-04 13:21:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ryiyo",
          "author": "SpecialistMode3131",
          "text": "It's important to let business needs drive this.  There should be someone on the business (product, whatever you call it) side telling you you need to be multi cloud for:\n\n1. contractual reasons (frequent)\n2. fear of losing reputation (unlikely but possible)\n3. fear of losing money (possible if you're a 24x7 serious money printing machine, are you?)\n\nClarify what your company actually needs by talking to the people who own those decisions.  \nThen when you present, you will simply state why XYZ is necessary. Or you'll cut it from the design because it isn't.\n\nWe can help.",
          "score": 1,
          "created_utc": "2026-02-05 20:03:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ic7fc",
          "author": "LemonFishSauce",
          "text": "If it’s me, I will read up on which companies were affected by the previous AWS outage. Then I’ll ask myself if my business is bigger than those companies.",
          "score": 1,
          "created_utc": "2026-02-04 10:47:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3hyhhx",
          "author": "Timely-Dinner5772",
          "text": "Failover across clouds sounds hypothetical until your primary region becomes the bottleneck.",
          "score": 0,
          "created_utc": "2026-02-04 08:39:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzzckx",
      "title": "(New here) Is each EC2 instance a part of a VPC?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "author": "itspiris",
      "created_utc": "2026-02-09 09:00:41",
      "score": 13,
      "num_comments": 20,
      "upvote_ratio": 0.85,
      "text": "hey guys. as the title shows, im new here. im taking a course from coursera on AWS to diversify my career as a software developer into the cloud and devops maybe.\n\nnot the point, i am reading about the route tables and VPCs and how to secure them. I just wanted to check if all EC2 instances are part of a VPC or not.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4emovt",
          "author": "Wide_Commission_1595",
          "text": "You can think of a VPC as a container for a network, and all of the things attached to that network!\n\nA VPC alone doesn't do anything, but you can create subnets, which require route tables.  You can create an Internet gateway to route to/from the internet, or endpoints (think network port) to give access to other services.\n\nInside the vpc you could put an EC2 instance, or RDS database etc.  if it has an IP address it's got an interface connected to your VPC.\n\nA thing in your VPC can also have a security group which is like a simple firewall which defines what traffic is allowed in or out.  This can reference an IP range, or another security group.\n\nBeyond that there are DHCP options, acls etc but honestly, they're way less important.  When you need them you'll know why and Google will be your friend 🙂\n\nOne slightly odd definition that is confusing to start with is public/private subnets.\n\nIn a public subnet you route 0.0.0.0/0 to the Internet gateway.  In a private subnet you don't!  That way resources in the private subnet cannot access or be accessed from the internet.  You can add a NAT gateway if you need outbound internet.  Ironically, because the NAT gateway needs Internet access it lives in the public subnet, but your private route tables have a default route to it.\n\nI hope that's helpful.  AWS networking is weirdly simple once you get used to it, but it can be very confusing initially 👍",
          "score": 19,
          "created_utc": "2026-02-09 09:17:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eolnm",
              "author": "itspiris",
              "text": "thank you bro. it makes sense to have it as a rule, i just wanted to make sure i understood their infrastructure correctly.\ni am now a little confused between the \"network ACLs\" and \"security groups\", but im sure I'll get the hang of it 🙂. to me they feel like they're exactly the opposite, but it seems that acls have everything open, while security groups have everything closed until you open. don't they have conflicts with each other? we shall know soon enough",
              "score": 2,
              "created_utc": "2026-02-09 09:36:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4f3es1",
                  "author": "Get-ADUser",
                  "text": "> i am now a little confused between the \"network ACLs\" and \"security groups\"\n\nFrom my 3 and a half years as an AWS Support engineer, you're now a member of a large club 🤣. Think of Network ACLs as \"dumb\" rules that just work on IP address and port numbers, akin to `iptables` and they're applied on the subnet level.  Security Groups are smarter - instead of just IP ranges as sources/targets you can use rules like \"members of this security group\", \"members of another security group\", etc. and they're applied on the security group level (which can span several subnets).\n\nI'd strongly advise you use one or the other, never both if you can help it.  Using both together is just a recipe for confusion when traffic isn't working that you think should be because of interactions between the two.  The one you use should (nearly) always be security groups.  Only use network ACLs if you really know what you're doing and have a specific need.  They usually only come into play when you're doing fancier stuff like VPC peering or connecting your VPC back to your datacenter with a VPN.",
                  "score": 5,
                  "created_utc": "2026-02-09 11:53:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ny662",
                  "author": "Wide_Commission_1595",
                  "text": "In over a decade I've very rarely use ACLs tbh.  Security groups let you define traffic in one direction and the return traffic is automatically allowed, e.g you connect out to something and the return packets can come back in.\nACLs on the other hand are one way.\nIn the distant past you could use them a bit like a waf IP blocker, so your web server is allowing https from 0.0.0.0/0 but 1.2.3.4 is DoS'ing your site.  Block 1.2.3.4 inbound on the VPC and you're good!  It's free, but tbh I'd rather pay for WAF and it's more friendly API and automation 🤣",
                  "score": 2,
                  "created_utc": "2026-02-10 19:05:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4enm67",
          "author": "ohmer123",
          "text": "Nowadays, yes. There used to be something called classic link in the early days but it was retired.",
          "score": 6,
          "created_utc": "2026-02-09 09:26:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jlaxe",
              "author": "metarx",
              "text": "You call it classic link, but it originally was the only way it worked.  It became classic link, after vpcs were a thing.",
              "score": 1,
              "created_utc": "2026-02-10 02:12:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4elv5w",
          "author": "SnoopJohn",
          "text": "They are as much as any computer(ec2) connected to a network(vpc) is.\nYou can't launch an ec2 without or outside a vpc.",
          "score": 3,
          "created_utc": "2026-02-09 09:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4f3n0w",
          "author": "omerhaim",
          "text": "EC2 launched only in VPC\n\nIn the past there was classic that were not a part of a VPC, but it’s not an option anymore",
          "score": 3,
          "created_utc": "2026-02-09 11:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4elobg",
          "author": "conairee",
          "text": "EC2 instances run *inside* a VPC, they get an IP address from the VPC CIDR block.\n\nImagine if you and your friends are gaming on a LAN, the VPC is like the LAN and your computers are the EC2 instances.",
          "score": 2,
          "created_utc": "2026-02-09 09:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4els1m",
          "author": "swiebertjee",
          "text": "I believe that by default, EC2 instances are part of the default VPC in each region. You can or course create a new/custom VPC and connect them to it.\n\nGood luck on your cloud adventure!",
          "score": 1,
          "created_utc": "2026-02-09 09:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4emta3",
          "author": "Old_Cry1308",
          "text": "yep, every ec2 instance is in a vpc. it's how aws does networking, whether you like it or not.",
          "score": 1,
          "created_utc": "2026-02-09 09:18:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4en23t",
          "author": "undernocircumstance",
          "text": "Yes, this is required now.",
          "score": 1,
          "created_utc": "2026-02-09 09:21:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4enysl",
          "author": "cloudnavig8r",
          "text": "U/Wide_Commission_1595 made the distinction!  EC2 instances need a network address.  That address is part of a subnet, which is part of a VPC.  So indirectly, *yes*\n\nThe truth is, the Subnet is a range of addresses within the VPC.  And, a subnet is associated with a physical Availability Zone.  (The VPC is an address range across the whole region).\n\nSo, an EC2 instance is on a physical server that is inside an Availability Zone.  It will have an address associated to that AZ (subnet).  \n\nEach subnet can have its own route table as well.  By default the VPC level traffic is “local” between all subnets.",
          "score": 1,
          "created_utc": "2026-02-09 09:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4har35",
          "author": "Important_Winner_477",
          "text": "Essentially, yes if you started your AWS journey anytime in the last decade, every EC2 instance you launch is sitting inside a VPC. There used to be an \"EC2-Classic\" mode where instances sat on a shared flat network, but AWS killed that off years ago. I run a cloud + AI pentesting firm and I have learn to find ancient \"ghost\" instances in legacy accounts, but for a new developer, the VPC is your non-negotiable boundary",
          "score": 1,
          "created_utc": "2026-02-09 18:57:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvpj6t",
      "title": "AWS Organizations",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qvpj6t/aws_organizations/",
      "author": "Razzleberry_Fondue",
      "created_utc": "2026-02-04 14:09:30",
      "score": 10,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "We have three seperate AWS accounts, we are looking to create an org. One account is gov which holds web apps, one account holds DNS and one account has AWS bedrock and does billing. I havent done too much with AWS, so i just wanted a little advice. If i create an organization to have all accounts under the org, will it cause any impact to our services? Reading through the domcumentation it seems like no, but wanted to double check",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qvpj6t/aws_organizations/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3j7wjz",
          "author": "CyberViking949",
          "text": "It won't impact your services. However, if you have a gov account, im assuming you have a fedramp env? \n\nAdding your fedramp environment to an organization introduces a significant change. It also brings the org master into scope. Which means any change in the org you need to do for the other accounts, is subject to SI and fedramp controls, oversight, and reporting. \n\nTLDR, do NOT mix your fedramp account in with the others. I would create 2 orgs. 1 fedramp, 1 normal.",
          "score": 16,
          "created_utc": "2026-02-04 14:18:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3j8fwg",
              "author": "Razzleberry_Fondue",
              "text": "Great point",
              "score": 2,
              "created_utc": "2026-02-04 14:21:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3j8c3f",
          "author": "menge101",
          "text": "I am not sure you can bring your gov account into the same Org, in fact fairly certain you can't.\n\nGov cloud isn't a different region, its a different partition, its a higher level division in AWS.",
          "score": 7,
          "created_utc": "2026-02-04 14:20:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3j84f6",
          "author": "AWSSupport",
          "text": "Hi there.\n\nFor additional guidance on creating an AWS Organization for your accounts, you're welcome to reach out to our Support team by creating a case via our Support Center: http://go.aws/support-center.\n\n\\- Roman Z.",
          "score": 2,
          "created_utc": "2026-02-04 14:19:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3k0355",
          "author": "omerhaim",
          "text": "You can’t add gov account to regular accounts. \nThose are different partitions \n\nLike china account. \n\nNot sharing the same IAM",
          "score": 2,
          "created_utc": "2026-02-04 16:34:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ql1m1",
          "author": "taH_pagh_taHbe",
          "text": "Hire a security consultant before you do this.",
          "score": 1,
          "created_utc": "2026-02-05 16:14:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s6qdk",
          "author": "xxwetdogxx",
          "text": "To add and clarify -\n\nGovcloud and commercial are separate partitions, and Organizations only works WITHIN a partition. So all the commercial accounts can be added to an organization, including the commercial account that's attached to the gov account and holds the billing. But the govcloud account itself can only enter an org with other govcloud accounts- the billing flows through the commercial org, but the gov org would let you use things like SCPs, etc.",
          "score": 1,
          "created_utc": "2026-02-05 20:42:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4dzkji",
          "author": "cklingspor",
          "text": "Hey there, I have done this a couple times. \nTL/DR: create a completely new account. This will be your root account. Create the organization in there and invite everyone into it.\n\n\nFor starters: [here](https://docs.aws.amazon.com/pdfs/whitepapers/latest/organizing-your-aws-environment/organizing-your-aws-environment.pdf) is the AWS whitepaper (99 pages though 😄)\n\nA [short version](https://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/aws-organizations.html) introducing the topic\n\nThe interesting part will be access and if you not only want to have consolidated billing (all bills into one) but also unified access via AWS Identity Center (which is pretty cool and easy I think)\n\nAll the best!",
          "score": 1,
          "created_utc": "2026-02-09 05:44:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r10ppv",
      "title": "Is Google Drive really cheaper than S3 storage?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "author": "nucleustt",
      "created_utc": "2026-02-10 13:27:49",
      "score": 10,
      "num_comments": 52,
      "upvote_ratio": 0.65,
      "text": "I was in the process of building a cloud backup solution for my company to store files in S3 buckets on our AWS account (US-EAST-1).\n\nNaturally, I did some research on the estimated costs and compared them with other Cloud Storage solutions, like Google Drive.\n\nThat's when I discovered that using Google Drive was actually cheaper.\n\nThis also makes it difficult to compete against Google Drive if you're building your own cloud storage solution.\n\nAre there any Cloud Storage solutions or AWS tiers that are cheaper than Google Drive?\n\nGoogle Drive ($1.99/month for 100GB, further savings on yearly plans)\n\nAWS S3 ($2.30/month for 100GB, not including request fees)",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4m1auu",
          "author": "ReturnOfNogginboink",
          "text": "AWS Glacier Deep Archive is about $1/TB/mo.\n\nThe costs hit when you need to retrieve data. For backups, that happens rarely.",
          "score": 62,
          "created_utc": "2026-02-10 13:34:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mpwdj",
              "author": "ohad1282",
              "text": "And it is slow retrieval, unless you use Glacier IR which is a good potential combination for both low cost storage and quick retrieval",
              "score": 6,
              "created_utc": "2026-02-10 15:42:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nhszu",
                  "author": "enjoytheshow",
                  "text": "Retrieval costs are way more though IIRC",
                  "score": 2,
                  "created_utc": "2026-02-10 17:51:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mux3r",
              "author": "Vista_Lake",
              "text": "Yes, this is exactly right. I've been using Deep Archive for years, have never had to retrieve a file, and probably never will, since I also keep a local backup.",
              "score": 5,
              "created_utc": "2026-02-10 16:05:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m2gm7",
          "author": "No-Rip-9573",
          "text": "Correct me if I’m wrong but I believe Google drive does not do snapshots or WORM protection, which you would want for backup solution. If you’re just looking for a place to dump some files cheaply that’s ok, but don’t call it backup if any random malware can just encrypt/overwrite/delete it for you.",
          "score": 30,
          "created_utc": "2026-02-10 13:40:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m3aik",
          "author": "solo964",
          "text": "Did you mean Google Drive or Google Cloud Storage?  \n  \nAmazon S3 and Google Drive both store files but they are very different storage systems and were designed for fundamentally different purposes. S3's primary audience is developers and applications while Google Drive's audience is end users. They have different access mechanisms, different service tiering, different pricing models, different integration with other services, etc. Aside from storing files, they are totally different.",
          "score": 34,
          "created_utc": "2026-02-10 13:45:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfsqf",
              "author": "PlanB2019",
              "text": "Yet the product targeted for developers to ideally serve an end product is more expensive than Google Drive. That’s the parallel op is trying to point out. It’s how the offerings are so expensive.",
              "score": 6,
              "created_utc": "2026-02-10 14:52:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pi78z",
                  "author": "nucleustt",
                  "text": "you are correct",
                  "score": 2,
                  "created_utc": "2026-02-10 23:37:48",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m1dlz",
          "author": "DominusGod",
          "text": "I would look at Backblaze B2 for backups. They are way cheaper than AWS. Also Google Drive does have limits",
          "score": 16,
          "created_utc": "2026-02-10 13:34:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oqe9a",
              "author": "magnetik79",
              "text": "Backblaze B2 for sure if you're looking for object storage on cost. \n\nThey also have a compatible S3 API as well, so it can work with AWS S3 based tooling as well.",
              "score": 2,
              "created_utc": "2026-02-10 21:17:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m24v1",
          "author": "the_birds_and_bees",
          "text": "$0.023 / GB is for standard tier access, which is probably overkill for backups. Pricing here [https://aws.amazon.com/s3/pricing/](https://aws.amazon.com/s3/pricing/) but assuming you are happy with slower retrieval times you can go much cheaper.\n\nBroadly, cheaper => slower access times and higher cost per request. You'd need to pick a tier which works for your business (think \"will I feel comfortable waiting {x time} while prod db is down and the boss is breathing down my neck while I wait for the backup to download\").",
          "score": 6,
          "created_utc": "2026-02-10 13:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pipzf",
              "author": "nucleustt",
              "text": "I wanted frequent access and quick retrieval. So that's why I didn't choose Glacier or deep archive",
              "score": 1,
              "created_utc": "2026-02-10 23:40:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ppco5",
                  "author": "mikebailey",
                  "text": "At scale you may also have issues on Google Drive if that was your pattern: https://developers.google.com/workspace/drive/api/guides/limits",
                  "score": 1,
                  "created_utc": "2026-02-11 00:18:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7tzl",
          "author": "Sirwired",
          "text": "Google Drive and S3 are *very* different use-cases; they aren't really comparable.  Google Drive is an end-user file collaboration tool, S3 is an entire enterprise-grade object storage system.",
          "score": 12,
          "created_utc": "2026-02-10 14:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pik43",
              "author": "nucleustt",
              "text": "This is true. \n\nI wanted to create my own Google Drive-type app, but using S3 since we already have the infrastructure.\n\nAlso, if I wanted to make a competitor to Google Drive, I obviously can't compete on costs.",
              "score": 1,
              "created_utc": "2026-02-10 23:39:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pjg40",
                  "author": "Sirwired",
                  "text": "Frankly, because of all the other costs involved with end-user services (development, marketing, support, billing, etc.), you'd have a tough time competing with Google Drive if your back-end storage was free.\n\nGoogle can provide the per-GB costs they do because most users only use a fraction of their quota, vs. S3, which is purely a consumption-based service.",
                  "score": 2,
                  "created_utc": "2026-02-10 23:45:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7sc5",
          "author": "powersline",
          "text": "Check out backblaze B2 and/or Wasabi.   Both are s3 compatible at a fraction of the price",
          "score": 3,
          "created_utc": "2026-02-10 14:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pis8q",
              "author": "nucleustt",
              "text": "Will do, thanks",
              "score": 1,
              "created_utc": "2026-02-10 23:41:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mb225",
          "author": "johndburger",
          "text": "S3’s data durability is 99.999999999% (eleven nines). Does Google even advertise a figure for Drive?\n\nI can set up auto-delete (e.g. 30 days) for S3, no such option for Drive, as far as I can tell.\n\nI can configure S3 buckets to automatically move files to cheaper storage under various circumstances. Again, no such option in Google Drive as far as I can tell.\n\nThey’re just fundamentally different products, designed for very different use cases.",
          "score": 6,
          "created_utc": "2026-02-10 14:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nuk0n",
              "author": "AnomalyNexus",
              "text": ">Does Google even advertise a figure for Drive?\n\nNot directly, but it is backed by same tech as their cloud storage so 11 9s too. All google's consumer facing product stuff is redundancy'd to high heavens.\n\nSuspect the challenge here isn't reliability but rather variability of throughput. All these sync based drive things are all over the place on what performance you get when",
              "score": 3,
              "created_utc": "2026-02-10 18:49:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pp3tx",
                  "author": "mikebailey",
                  "text": "This isn’t how SLAs actually trickle, since adding those layers of abstraction can impede it. Source: our company sells something that sits on top of BQ, yet our SLA is like 99% or something way lower.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:16:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mfarm",
              "author": "PlanB2019",
              "text": "The complaint which is completely valid is the cost storage and egress fees are more than Google Drive. File storage is a pretty common feature set in applications, it’s odd that a file storage service is multiple times more expensive than Google Drive. Listing features on top the core service doesn’t really change it for me, as I’m sure it doesn’t for others.",
              "score": -5,
              "created_utc": "2026-02-10 14:49:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mr8zy",
                  "author": "justin-8",
                  "text": "I don't know if I'd call the 15% difference the OP pointed out is \"multiple times more expensive\"",
                  "score": 5,
                  "created_utc": "2026-02-10 15:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mygcy",
          "author": "ioannisthemistocles",
          "text": "Years ago I used Google Drive to store shell scripts, before I started using github. \n\nI found that Google inserted hidden characters in the scripts that broke them. I don't know if that is still the case,\n\nNevertheless, a backup isn't a backup unless you do a test restore and validation.",
          "score": 2,
          "created_utc": "2026-02-10 16:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pjox0",
              "author": "nucleustt",
              "text": ">Years ago I used Google Drive to store shell scripts, before I started using github.\n\nYou sound like an OG hacker.\n\nGoogle messing with the EOL char is crazy. Auto \\\\r\\\\n to \\\\n or vice versa",
              "score": 0,
              "created_utc": "2026-02-10 23:46:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mhcds",
          "author": "benpakal",
          "text": "Standard access rate is for live access from apps to files. not backup. Check glacier rates.",
          "score": 1,
          "created_utc": "2026-02-10 15:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mjtlq",
          "author": "OhMyTechticlesHurts",
          "text": "You mean Google Cloud Storage which Google Drive is built on top of. Cloud Storage is an IaaS service while Google Drive is a SaaS product technically speaking.",
          "score": 1,
          "created_utc": "2026-02-10 15:12:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mswdl",
          "author": "ohad1282",
          "text": "1. Dumping the data to Google Drive may be cheap on storage cost, but think about egress/networking cost if taking the data out of your s3 as well.\n2. Google Drive will indeed provide you a copy, but this is not immutable, no proper retention policy, etc - which you probably need for your back solution and compliance needs. Think about ransomware.\n3. You have backup solutions for that - AWS backup, Rubrik, Commvault, etc. Not cheap but real backup solutions. \n4. Goofle drive and most backup solutions/vendors - those do not provide INCREMENTAL changes so if you change a small portion of a file/object, you need to save the whole copy.\n4. Eon.io is another backup solution which stores the data deduped, compressed and most importantly for object storage - incrementally. So honestly, I truly belive this is exactly what you need. It will save you a lot of money and protect you properly. Disclaimer - I work for Eon.",
          "score": 1,
          "created_utc": "2026-02-10 15:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n3o8n",
          "author": "Bourne069",
          "text": "I dont see how. I get 1TB of S3 storage from Wasabi for $5 per month per TB...",
          "score": 1,
          "created_utc": "2026-02-10 16:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pl30v",
              "author": "nucleustt",
              "text": "I just learned about Wasabi",
              "score": 1,
              "created_utc": "2026-02-10 23:54:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nd98w",
          "author": "siddharthnibjiya",
          "text": "Backblaze is $7/month for NO data limit. I found that to be quite a compelling option when evaluating",
          "score": 1,
          "created_utc": "2026-02-10 17:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nrzcc",
          "author": "MavZA",
          "text": "Google Drive is not comparable to Amazon S3 in the way you’re intending to use it. Maybe take a look at S3 compatible object storage solutions and compare from there. S3 is extremely resilient object storage whereas Google Drive is file storage that you’d use for day to day files.",
          "score": 1,
          "created_utc": "2026-02-10 18:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plgt0",
              "author": "nucleustt",
              "text": "Yes, with an additional app, I hoped to make S3 behave like Google Drive. But then I saw the costs and noticed it didnt make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:56:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pphf1",
                  "author": "mikebailey",
                  "text": "In the other direction, Drive has more limits than S3 at the filesystem/API level.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:18:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4o8bcg",
          "author": "AdPhysical9992",
          "text": "Does google drive provides programmatic APIs to get the file content and other things , like event triggers that we have in s3?",
          "score": 1,
          "created_utc": "2026-02-10 19:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plw0k",
              "author": "nucleustt",
              "text": "I'm not sure. \n\nIn that sense, there's no comparison. But for simple cloud sync (with a custom S3 app), the cost didn't make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:58:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ppkdw",
              "author": "mikebailey",
              "text": "Yes, there’s a huge drive SDK\n\nEvent triggers though I don’t think so",
              "score": 1,
              "created_utc": "2026-02-11 00:19:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ppq4q",
          "author": "dubidub_no",
          "text": "[rsync.net](http://rsync.net) is $0.012 per GB per month single region, no ingress/egress. They have a warrant canary.",
          "score": 1,
          "created_utc": "2026-02-11 00:20:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1llz",
          "author": "indigomm",
          "text": "S3 has many options depending on what service you need. Look at S3 Infrequent Access, Glacier Flexible or Instant Access, or even Glacier Deep Archive. They are all much cheaper. But be aware of transfer and retrieval costs on some products.",
          "score": 1,
          "created_utc": "2026-02-10 13:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk2wb",
              "author": "nucleustt",
              "text": "I actually needed frequent access.\n\n>But be aware of transfer and retrieval costs on some products.\n\nI'm not a fan of the transfer fees. IMO, the storage fees should be lower to compensate.",
              "score": 1,
              "created_utc": "2026-02-10 23:48:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mgfvc",
          "author": "mojo21136",
          "text": "Building your own backup solution (or any other solved problems) is not a good use of time. Other providers have solved cheaper than you can do and if something goes wrong when restore is necessary it will be a resume generating event.",
          "score": 1,
          "created_utc": "2026-02-10 14:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk942",
              "author": "nucleustt",
              "text": ">Building your own backup solution (or any other solved problems) is not a good use of time. \n\nThat's what I figured out after investigating the costs. I thought it would have been cheaper to host on S3 TBH.",
              "score": 1,
              "created_utc": "2026-02-10 23:49:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mzjnh",
          "author": "blenderman73",
          "text": "Yeah S3 ingress and egress really adds up haha - it turns into a cost monster over time",
          "score": 1,
          "created_utc": "2026-02-10 16:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nixmp",
              "author": "Sirwired",
              "text": "Errr... what ingress charges?  And what do you imagine the egress charges will be for a remote backup?  It's not like these files will be read often, if ever.",
              "score": 3,
              "created_utc": "2026-02-10 17:56:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ow3i6",
                  "author": "blenderman73",
                  "text": "Then drive is fine. When I worked with s3 based raw layers for EMR we were getting extremely heavy unplanned read loads at the prefix level when teams used the backup product which added up surprisingly. Primary due to how we partitioned.\n\nI.E. LIST operations are priced as writes ($0.005/1K) out of aws \n\nOr a glacier + s3 solution works",
                  "score": 1,
                  "created_utc": "2026-02-10 21:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m4fpj",
          "author": "Old_Cry1308",
          "text": "yeah, google drive cheaper. s3 has hidden fees. good luck competing with that.",
          "score": -6,
          "created_utc": "2026-02-10 13:51:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxkw7y",
      "title": "Quickly register phone number for SNS",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qxkw7y/quickly_register_phone_number_for_sns/",
      "author": "healthiestsalad",
      "created_utc": "2026-02-06 15:37:39",
      "score": 7,
      "num_comments": 10,
      "upvote_ratio": 0.89,
      "text": "Hello, I am trying to spin up an SNS system. I created a topic and when I try to add a phone number to the subscription, i get this error:\n\nAn error occurred while attempting to add a phone number to the SMS sandbox. The phone number was not added.\n\nError code: UserError - Error message: No origination entities available to send\n\n  \nI figured out that this was due to me not setting up an origination number, which I need to resgister for in AWS. However, it says after registering it can take up to two weeks to be verified. \n\nCan I register a phone number to send out the texts quickly? This is just for a sandbox environment. \n\nThank you! ",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qxkw7y/quickly_register_phone_number_for_sns/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3x22ia",
          "author": "sryan2k1",
          "text": "\"How quickly can I send spam?\"\n\n  \nThe protections are there for a reason. ",
          "score": 15,
          "created_utc": "2026-02-06 15:41:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x81om",
              "author": "healthiestsalad",
              "text": "I agree, however since sandbox mode can only send to verified numbers this shouldnt be a concern",
              "score": 4,
              "created_utc": "2026-02-06 16:09:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3x2r4e",
          "author": "Old-Astronomer3995",
          "text": "Sending SMS with AWS is not easy if you want to use this kind of features outside Sanbox because they don’t want to spam people and break Telco laws. \n\nYou can send SMS in sandbox without a problem. For test purposes it shouldn’t matter which numer sends this sms.",
          "score": 3,
          "created_utc": "2026-02-06 15:44:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x7xxo",
              "author": "healthiestsalad",
              "text": "How do I do this? Is there a resource you can point me to? Thank you",
              "score": 2,
              "created_utc": "2026-02-06 16:08:51",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3xaw4f",
                  "author": "Old-Astronomer3995",
                  "text": "AWS SNS --> Mobile --> Text messaging (SMS) --> \"Sandbox destination phone numbers (1)\". You will get SMS on this phone number and you have to accept it.\n\nThen you can use this number in Subscriptions as Endpoint when you choose SMS as protocol.\n\nYou can have maximum 10 numbers as destination in sandbox.  \n[https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox.html](https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox.html)\n\nIf you want to leave sandbox you need to create ticket to AWS and have valid reason, your account has to be trusted etc.\n\n[https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox-moving-to-production.html](https://docs.aws.amazon.com/sns/latest/dg/sns-sms-sandbox-moving-to-production.html)\n\nMany things like delegated number, sender id depend on your country and country to which you want to send sms [https://docs.aws.amazon.com/sms-voice/latest/userguide/sender-id-request.html](https://docs.aws.amazon.com/sms-voice/latest/userguide/sender-id-request.html)",
                  "score": 6,
                  "created_utc": "2026-02-06 16:22:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3xeygj",
          "author": "ronkinkade",
          "text": "In my experience, 10DLC registration through developer-heavy platforms like AWS can feel like shouting into a void. It is incredibly frustrating to wait weeks just to get a \"rejected\" notice with no clear explanation why.  \n  \nUsually, these rejections happen because of tiny details in your opt-in language or missing disclaimers on your web forms. Carriers are very picky about seeing exactly how people sign up.  \n  \nTo be honest, it shouldn't be this hard. We handle the 10DLC mess for business customers (pre-built vs build-your-own). Our team manually reviews your registration to ensure it passes the first time. Most registrations are complete within 1-2 business days.  \n  \nFull disclosure: I'm with the team at Text-Em-All. We focus on doing SMS marketing and mass messaging the right way so your messages actually deliver without the technical headaches.",
          "score": 2,
          "created_utc": "2026-02-06 16:41:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yu5in",
          "author": "omeganon",
          "text": "This is not an AWS specific delay. This registration and approval is done with and by a third party entity for any business/commercial use of SMS messaging (e.g. not from your personal phone). That entity is The Campaign Registry (TCR), which is made up of those mobile network operators that control the destination phone networks. They must review and approve SMS applications from \\_all\\_  providers, not just AWS. They review the application and example campaigns that you have provided, and make a determination as to whether that is acceptable on the networks. Only once they approve your campaigns will a 10DLC number be issued that Amazon can then use to send your content.\n\nThe timelines are based on the estimated processing times of TCR.",
          "score": 1,
          "created_utc": "2026-02-06 20:48:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qvi031",
      "title": "AWS EKS networking question",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qvi031/aws_eks_networking_question/",
      "author": "DopeyMcDouble",
      "created_utc": "2026-02-04 07:20:08",
      "score": 6,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "Hello all, I have a question on this process. Currently we have 4 VPCs:\n\n* dev\n* stage\n* production\n* internal\n\nWe have dev, stage, production and not internal yet.\n\nMy plan is to host our Gitlab server, Grafana stack, and VPN server all on internal VPC CIDR. Now, we will be hosting the Grafana stack and Gitlab runners on the EKS cluster; however, I do have a question though.\n\nWould it be correct to set the EKS cluster's \"Cluster Endpoint access\" to \"Private\" and use Transit Gateway to have the internal VPC CIDR communicate to all other VPC CIDRs (i.e. dev, stage, production)? I have seen companies setup a \"Public and Private\" setup where Security Groups were paramount in the setup for access.  \n  \nWould appreciate any help or documentation on this.",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1qvi031/aws_eks_networking_question/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o3kd657",
          "author": "sirstan",
          "text": "\\> We have dev, stage, production and not internal yet.\n\nSetup AWS Organization before you move forward.  Setup a billing account.  An org account.  And four accounts (dev, stage, prod, internal).",
          "score": 14,
          "created_utc": "2026-02-04 17:34:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ocnix",
              "author": "GuyWithLag",
              "text": "This. It will make billing much cleaner than whatever tagging system you come up with.",
              "score": 2,
              "created_utc": "2026-02-05 06:44:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3jgytw",
          "author": "Living_off_coffee",
          "text": "I'm not too sure about the endpoint setup, but I'd suggest you go a bit further with your isolation and have separate aws accounts for dev/prod/infrastructure. You can link them together with an organisation so you still only pay one bill.\n\nThis way, you have a greater separation of concerns - you have less risk of something in dev breaking prod and you can set tighter restrictions on prod.",
          "score": 3,
          "created_utc": "2026-02-04 15:04:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3s0y0u",
          "author": "Old-Astronomer3995",
          "text": "Easier it will be to divide environments by accounts in AWS Organization. Then you can have this same terraform code just with different variables for tags and environment. \nPrivate endpoints means that your apps can access EKS api from internal VPC so it will be useful for your runners because traffic doesn’t have to go via public internet\n\nPublic access depends what you need but safer is private + vpn etc.\n\n\nAnother thing:\n\nStart small if this is a new project for startup or new company. Don’t waste budget on many eks clusters. Maybe it is easier and cheaper to start with ECS, EC2 and lambdas than building big Kubernetes ecosystem.",
          "score": 2,
          "created_utc": "2026-02-05 20:14:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3im9yl",
          "author": "alex_aws_solutions",
          "text": "I would do it as you mentioned as well. Cluster Endpoint Private and than use the TGW. Be aware of the proper  config of DNS and Routing.",
          "score": 1,
          "created_utc": "2026-02-04 12:09:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r06jkd",
      "title": "Verification loop - \"documents not required\" then reverify 2 days later",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "author": "teasingcupcakeLuv",
      "created_utc": "2026-02-09 15:04:52",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 0.63,
      "text": "Went through AWS verification. Submitted docs multiple times because support kept asking for the same stuff repeatedly.\n\nFeb 7 - Two emails same day. One says hold removed. Another says \"we no longer require verification documents, disregard the request.\"\n\nFeb 9 - New email. Account on hold for verification again. Need to submit docs by Feb 14 or suspension.\n\nThey just told me documents weren't required 48 hours ago. Now I'm back at square one with a deadline.\n\nSupport has been completely useless. Generic responses, no actual help. Given the recent layoffs and AI support rollout, I'm guessing this is just automated systems conflicting with each other while there's nobody left to actually fix it.\n\nAnyone successfully escaped one of these verification loops? Or is this just the new normal with AWS running everything through automation now?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4g8sx6",
          "author": "AWS_Chaos",
          "text": "If recent posts have taught us anything, back all your stuff up OUTSIDE of this account if it is production! :)",
          "score": 6,
          "created_utc": "2026-02-09 15:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g0c6y",
          "author": "AWSSupport",
          "text": "Hi there, \n\nSorry to hear about your account verification issue. \n\nWe're unable to discuss account-specific info here, but you can send us a private chat with your case ID and we'll check from our end that the case has been routed correctly. \n\n\\- Reece W.",
          "score": -1,
          "created_utc": "2026-02-09 15:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g8xwv",
          "author": "AWSSupport",
          "text": "Thanks for the info. \n\nAs explained, we're unable to discuss account-specific info here, but I reviewed your Support case and I see that our team have provided the final decision. We're unable to influence the outcome or discuss the matter further here as well.  \n\nApologies if the outcome was unfavorable.\n\n\\- Reece W.",
          "score": -3,
          "created_utc": "2026-02-09 15:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4glqsl",
              "author": "teasingcupcakeLuv",
              "text": "Reece, you need to actually look at what happened.\n\nMy account was REINSTATED on February 7, 2026. I have the emails from AWS confirming the hold was removed and verification documents were no longer required.\n\nOn February 9, 2026, my account was suspended AGAIN with a new verification request.\n\nThe \"final decision\" you're referring to was reinstatement. This is a different suspension that happened 48 hours after AWS told me my account was verified and clear.\n\nYour response shows you didn't even review what actually happened before responding. Please look at the facts instead of giving boilerplate responses about final decisions.",
              "score": 6,
              "created_utc": "2026-02-09 16:59:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}