{
  "metadata": {
    "last_updated": "2026-02-15 08:59:58",
    "time_filter": "week",
    "subreddit": "aws",
    "total_items": 20,
    "total_comments": 155,
    "file_size_bytes": 171525
  },
  "items": [
    {
      "id": "1r4yqqp",
      "title": "Small PSA regarding ECR and Docker CLI for pushing images",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "author": "magnetik79",
      "created_utc": "2026-02-14 23:05:45",
      "score": 86,
      "num_comments": 6,
      "upvote_ratio": 0.99,
      "text": "Hey all.\n\n  Quick post of something I noticed over the weekend which might trip up someone else.\n\n\nWas pushing a Docker image into ECR using a GitHub Actions deployment workflow, a workflow that's been same-same for a good six months and suddenly two days prior was failing with the following error:\n\n```\nunknown: unexpected status from HEAD request to https://XXXXX.dkr.ecr.ap-southeast-2.amazonaws.com/v2/XXXX/XXXX/manifests/sha256:XXXX: 403 Forbidden\nmake: *** [Makefile:68: burp] Error 1\nError: Process completed with exit code 2.\n```\n\nAfter a little head scratching, I pulled out a few community threads via Google - all from 1 - 2 years ago, but suspiciously had some very recent comments (two days prior) on them with similar issues:\n\n- https://repost.aws/questions/QUYf5U-mW3SqaYKFEvbr9fzw/suddenly-getting-403-on-pushing-my-containers-to-ecs\n- https://stackoverflow.com/questions/79137398/gitlab-cicd-issue-403-forbidden-while-pushing-docker-image-to-aws-ecr\n\nThe IAM role used in my GitHub workflow was (as it should be) fairly restrictive - with the following IAM actions only:\n\n```\necr:BatchCheckLayerAvailability\necr:CompleteLayerUpload\necr:InitiateLayerUpload\necr:PutImage\necr:UploadLayerPart\n```\n\nThese are all honed against a [specific ECR repository ARN](https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonelasticcontainerregistry.html#amazonelasticcontainerregistry-repository).\n\nTurns out, adding `ecr:BatchGetImage` was the fix - this provides the ability for querying image digests from within ECR, which is exactly where the HTTP HEAD error lies.\n\nSo, it seems a recent release of Docker CLI has changed the behavior of `docker push` to now query image digests during an image push and I can only assume this version recently landed on GitHub managed workflow runners.\n\nAnyway... hopefully this helps someone else out of a bind!\n",
      "is_original_content": false,
      "link_flair_text": "technical resource",
      "permalink": "https://reddit.com/r/aws/comments/1r4yqqp/small_psa_regarding_ecr_and_docker_cli_for/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5f5bs0",
          "author": "phaubertin",
          "text": "This is really good to know, thanks for posting.",
          "score": 13,
          "created_utc": "2026-02-14 23:14:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5f9egh",
              "author": "magnetik79",
              "text": "cheers.",
              "score": 4,
              "created_utc": "2026-02-14 23:39:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ffwnp",
          "author": "l0g0ut",
          "text": "Thank you for the in depth investigation report. These kind of post and people like you really made Reddit a treasure",
          "score": 12,
          "created_utc": "2026-02-15 00:20:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fji5o",
              "author": "magnetik79",
              "text": "thanks for the kind words.",
              "score": 3,
              "created_utc": "2026-02-15 00:41:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5fsc73",
          "author": "MonkeyArmpit",
          "text": "I wasnâ€™t aware of docker cli change. I always just set it up as the official documentation suggested \n\nhttps://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push-iam.html",
          "score": 5,
          "created_utc": "2026-02-15 01:39:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ffyqc",
          "author": "burnbern",
          "text": "Had the same issue and Opus saved meâ€¦lol",
          "score": 1,
          "created_utc": "2026-02-15 00:20:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0ufs2",
      "title": "Localstack killing community edition - what do we do?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "author": "xenographer",
      "created_utc": "2026-02-10 07:31:10",
      "score": 73,
      "num_comments": 55,
      "upvote_ratio": 0.94,
      "text": "[https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change](https://blog.localstack.cloud/the-road-ahead-for-localstack/#why-were-making-a-change)\n\nLocalstack are killing their community edition and making everyone register for a free plan (ugh), so I guess that'll mean they'll slowly nerf the free plant to the point where it's unuseable/put horrible limits on it so you have to pay.\n\nIs there any realistic alternative to localstack out there? Anyone?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r0ufs2/localstack_killing_community_edition_what_do_we_do/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4lan0b",
          "author": "alvsanand",
          "text": "Itâ€™s ironic to read them calling it as an 'open-source experiment' rather than a full project, especially since their entire reputation was built on being open-source. They have the right to do it, but they shouldnâ€™t insult our intelligence by pretending otherwise",
          "score": 40,
          "created_utc": "2026-02-10 10:14:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lowhl",
          "author": "tuple32",
          "text": "aws should buy localstack and make it available to their customers for free.",
          "score": 38,
          "created_utc": "2026-02-10 12:14:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nb4lp",
              "author": "HanzJWermhat",
              "text": "This was pitched internally as an idea. I donâ€™t think it was ever taken seriously (I canâ€™t be more specific because my part of the business wasnâ€™t well suited to own it anyway)\n\nThe problem is expectations. If AWS does it, it needs to support everything out of the box. Every API call of which there are 14000+",
              "score": 14,
              "created_utc": "2026-02-10 17:20:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4okuvi",
                  "author": "seanamos-1",
                  "text": "I don't know how seriously they thought about this, but I can't overstate what a significant competitive advantage localstack has been for AWS, and they are losing it.",
                  "score": 10,
                  "created_utc": "2026-02-10 20:51:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4rh613",
                  "author": "ippem",
                  "text": "Ultimately yes, but not from the start; look at CloudFormation support how it grows still slowly after all of these years ðŸ˜",
                  "score": 4,
                  "created_utc": "2026-02-11 07:39:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kw57x",
          "author": "DevWithImagination",
          "text": "Depending on the services you need moto is a great alternative (in fact, localstack uses moto under the hood for some things). We moved quite a bit over to it for speed of testing while using some of the simpler base services (S3, DynamoDb etc)",
          "score": 24,
          "created_utc": "2026-02-10 07:53:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kw94x",
              "author": "xenographer",
              "text": "Nice! [https://github.com/getmoto/moto](https://github.com/getmoto/moto) for reference",
              "score": 14,
              "created_utc": "2026-02-10 07:54:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ombcp",
          "author": "ruibranco",
          "text": "the \"free plan\" to \"slowly nerf it\" pipeline is so predictable at this point. moto covers a surprising number of services if you haven't tried it â€” not as polished but no registration, no usage tracking, and it actually runs offline. for anything more complex, a dedicated AWS dev account with tight billing alerts is honestly more reliable than hoping a third-party tool stays free.",
          "score": 4,
          "created_utc": "2026-02-10 20:58:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4l6c3m",
          "author": "omenking",
          "text": "https://github.com/project-vera/vera-aws\n\nThis project has popped up very recently. It's a research project that is open source.",
          "score": 8,
          "created_utc": "2026-02-10 09:33:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4lgpsu",
          "author": "PlanB2019",
          "text": "I would totally pay like 10$ as a hobbyist/individual dev but the currrent entry for premium is just too much to justify for my projects. I wish they had a better entry package, that wasnâ€™t more than my current aws costs haha",
          "score": 7,
          "created_utc": "2026-02-10 11:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kuzx9",
          "author": "HatchedLake721",
          "text": "Whyâ€™s not just pay for it? Itâ€™s a valuable service and people behind it deserve to be paid for it. Anyone not paying for AWS with their own credit card should just put this through their work.\n\nOtherwise, you can just fork and carry on using it as it is today.",
          "score": 18,
          "created_utc": "2026-02-10 07:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4lx07v",
              "author": "ippem",
              "text": "Looking from my current company's perspective, we happily pay for things we need, but in our case, the price model (no monthly option plus would need to buy lots of these \"CI credits\" probably) has always killed the idea (for both app developers/CI runs plus for our Terraform development + CI runs).  \nI wish they would have a monthly payment - and have it through e.g. AWS Marketplace would make the adoption way easier.\n\nThat was a hint above how to grow your business, probably exponentially. ðŸ™‚ Companies do not like to commit on things that they don't know the actual usage patterns.",
              "score": 11,
              "created_utc": "2026-02-10 13:08:50",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4n72d7",
              "author": "GoofAckYoorsElf",
              "text": "A goes from Open Source to freemium - why not pay for it? \n\nB goes from Open Source to freemium - why not pay for it?\n\nC goes from Open Source to freemium - why not pay for it?\n\nBecause I already fucking pay for A and B! What am I Croesus? \n\nOpen Source projects grow on contribution by the community. Shitting on the community and telling them to suddenly pay for the stuff they actually contributed themselves is a fucking dick move, that's what it is!",
              "score": 11,
              "created_utc": "2026-02-10 17:01:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o50t458",
                  "author": "HatchedLake721",
                  "text": "Oh please, I can bet my savings less than 1% of localstack users ever contributed to it.\n\nIf you did contribute, I'm sure localstack can sort you out, or feel free to fork it and carry on using and contributing to it, they're not taking away what you already have.\n\nWe have multi-billion companies built on sweat of people writing open source for free. I never have issue with open-source projects going commercial and asking companies to pay for it. Especially in a space like AWS, which is an iPaaS for businesses, not a $9.99 p/m B2C host my hairsalon website pls.",
                  "score": -1,
                  "created_utc": "2026-02-12 18:14:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4kxg57",
          "author": "seany1212",
          "text": "Genuine question, why would anyone pay for this? If youâ€™re at a company that takes AWS seriously then they should create you a test environment/account so you donâ€™t need to â€œsimulateâ€ an AWS environment. Â \n\nIf youâ€™re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nThis just seems to add another abstraction layer that will potentially introduce unseen differences when you actually try to port that to AWS.",
          "score": 14,
          "created_utc": "2026-02-10 08:05:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kzo4f",
              "author": "flooberoo",
              "text": "Because with _N_ features being developed simultaneously you ideally have at least _N_ environments. And that can get expensive and slow quite fast.",
              "score": 24,
              "created_utc": "2026-02-10 08:27:26",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4l4lwm",
                  "author": "lost12487",
                  "text": "I'm not sure why you'd need an account per feature? Why not just give each team a prod and a non-prod account and deploy feature branches within the non-prod account, cleaning up the resources when the feature branch is merged?",
                  "score": -6,
                  "created_utc": "2026-02-10 09:16:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4l6y8d",
              "author": "xenographer",
              "text": "LOL, every time someone starts a sentence with \"Genuine question\" or \"I'm genuinely curious why\" you know that it's bullshit and they're just setting themselves up so they can argue the case against. So intellectually dishonest.\n\n\\> If youâ€™re not, why pay for a layer that simulates an AWS account when you can use most of the free tier and use the money for anything additional.\n\nthe whole point is that it's LOCAL and you don't have to set up AWS credentials or resources. Same with integration tests in CI.  \n  \nI'm not sure where \"another abstraction layer\" comes into it.",
              "score": 18,
              "created_utc": "2026-02-10 09:39:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ldrcx",
                  "author": "seany1212",
                  "text": "If itâ€™s local then why bother simulating AWS at all? Just build your app/platform with services/VMs/Docker/Kubernetes\n\nThe logic doesnâ€™t even make sense, Iâ€™m going to simulate a cloud platform that provides an abundance of products and services with potentially infinite compute, locally with none of that.\n\nAgain, why would anyone PAY for that, when it was your initial complaint in the OP",
                  "score": -11,
                  "created_utc": "2026-02-10 10:43:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mqy7w",
              "author": "DZello",
              "text": "Creating ressources in AWS can take forever, databases are a good exemple.",
              "score": 3,
              "created_utc": "2026-02-10 15:47:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4olp5o",
          "author": "ruibranco",
          "text": "the realistic answer for most teams is you don't actually need to mock all of AWS locally. SAM CLI + DynamoDB local covers 80% of what people actually use localstack for. the rest you test against a real dev account with short-lived resources. it's less elegant but it's also not going to rug-pull you in 6 months.",
          "score": 2,
          "created_utc": "2026-02-10 20:55:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4rx4z6",
          "author": "realqmaster",
          "text": "This fucking sucks. I get that devs ought to be paid, but a credits system for CI builds is unreasonable. I could get behind a one time purchase or a yearly subscription, but tying the costs to the number of builds is flat out wrong. Some projects are built frequently and would burn through their plans (and I think's that's exactly why they target CI for the monetization). Imagine using a Jetbrains IDE and having to pay for each project you create. I hope alternatives emerge in the future, especially if integrated in TestContainers as LocalStack is. For now I'll resort to pinning the version, and move away for future projects.",
          "score": 2,
          "created_utc": "2026-02-11 10:09:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4u3vch",
              "author": "remotesynth",
              "text": "I understand your concerns around CI. I wish I could give more detail right now but what I can share is that we are revising the CI credit system for our plans that may help address your concerns. We should have more details soon.\n\n(NOTE: Probably obvious but I work for LocalStack)",
              "score": 2,
              "created_utc": "2026-02-11 17:47:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4yrg57",
                  "author": "ippem",
                  "text": "Thanks for the sympathy u/remotesynth ðŸ™‚\n\nA pretty please: have a look also on selling the product through the marketplaces; it really shows that companies are waay happier to contract through them. It probably is more effort for you (plus they for sure have their fees) to establish these, but it might really pay off and help you sell more.\n\nYou have a good product: you need to be able to sell it the easiest ways possible. Going monthly + going marketplaces solves that problem.",
                  "score": 1,
                  "created_utc": "2026-02-12 11:41:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4npdyv",
          "author": "mountainlifa",
          "text": "This is why building for cloud is a regression. Developers are forced into using these third party tools to mock services to build and test features. This should either be native or not required. We are moving our of serverless lambda, dynamo etc to bare bones fast API, docker, postgres that I can run on a single workstation and build, test end to end. No more mocking dozens of services and patching all of my tests.",
          "score": 2,
          "created_utc": "2026-02-10 18:25:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kw9x3",
          "author": "smutje187",
          "text": "Do you make money with the software you build on LocalStack? Buy a license, just like you buy IDE licenses, rent an office, buy a computer.\n\nOtherwise, AWS credits and use ephemeral environments, most AWS Services that run in LS cost next to nothing for private use.",
          "score": 3,
          "created_utc": "2026-02-10 07:54:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53olo3",
          "author": "javatextbook",
          "text": "I just use Moto server",
          "score": 1,
          "created_utc": "2026-02-13 03:23:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o50fiue",
          "author": "rad15h",
          "text": "There is an alternative - build it yourself. Hear me out.\n\nAI agents open up options that never would have been sensible or economical before. And this is one of those cases.\n\nI work on a service that runs in AWS and depends on a fair number of AWS services - S3, DDB, EventBridge, Fargate, Lambda, SQS, and probably others I've forgotten about. Testing the full service and running end-to-end tests is painful, and requires deploying a lot of CFN stacks to a dev account.\n\nWe have started using agents to write our code (Kiro CLI + Claude 4.5 Opus) and are producing _far_ more code than we can realistically test. So we needed a new way to test it that the agents could use without human intervention.\n\nI watched a video where someone talked about exactly this problem, and he suggested faking your dependencies and testing locally; that is a lot of work, but it is the kind of work that AI can do extremely easily. It's not complicated or subtle, it just requires knowledge of all the AWS APIs.\n\nIn a few days of running an agent as a background task while I did my day job I had the entire service running on my laptop without using a single real AWS service. The agent built local HTTP servers that fake the AWS service APIs so my service code SDK calls still work. I just have to set `AWS_ENDPOINT_URL_<SERVICE>` to override the service URL to be `localhost:<port>`.\n\nI never would have thought is was possible until I tried it, but I believe it now. I think this is one of the challenges of adopting AI - opening your eyes to the things that you never would have considered before, but which are possible now.\n\nEdit: To clarify, my fake AWS services only implement the small subset of the AWS API that my service code uses. Faking the _entire_ API for all of those services would be a big job, but it's one you don't have to do if you are faking services just for your use case.",
          "score": 1,
          "created_utc": "2026-02-12 17:10:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1yky",
          "author": "cachemonet0x0cf6619",
          "text": "and this is why i will never recommend local testing of services. mock unit test and architect your application such that it can be tested in isolation.\n\neta: only people downvoting me are local stack employees that thought it was a good idea to charge for this and the the people using local stack that bought the lies",
          "score": -5,
          "created_utc": "2026-02-10 13:37:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4m5eu2",
              "author": "yesman_85",
              "text": "You don't do e2e test then?Â ",
              "score": 0,
              "created_utc": "2026-02-10 13:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4m5t18",
                  "author": "cachemonet0x0cf6619",
                  "text": "i do e2e in the cloud against actual resources",
                  "score": 7,
                  "created_utc": "2026-02-10 13:58:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1e6pa",
      "title": "Global cloudfront issues",
      "subreddit": "aws",
      "url": "https://health.aws.amazon.com/health/status",
      "author": "dennusb",
      "created_utc": "2026-02-10 21:43:13",
      "score": 66,
      "num_comments": 8,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1e6pa/global_cloudfront_issues/",
      "domain": "health.aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4oyd3u",
          "author": "Difficult-Ad-3938",
          "text": "DNS =)",
          "score": 33,
          "created_utc": "2026-02-10 21:54:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owf8z",
          "author": "MidgardDragon",
          "text": "Yep RingCentral Contact Center was hard down for about an hour for us. Traced it back to CloudFront.",
          "score": 8,
          "created_utc": "2026-02-10 21:44:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pe35c",
          "author": "return_of_valensky",
          "text": "my company is having issues with docusign.. i figure this is as good of a reason as any why that might be.. errors logging in, sending documents etc",
          "score": 4,
          "created_utc": "2026-02-10 23:14:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sn7pn",
          "author": "AntDracula",
          "text": "Neat. Better lay off another few thousand!",
          "score": 3,
          "created_utc": "2026-02-11 13:26:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4owvm2",
          "author": "rhaksw",
          "text": "AppSync is having issues for us",
          "score": 2,
          "created_utc": "2026-02-10 21:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4pmphj",
          "author": "UpgradingLight",
          "text": "Jira was affected today for us, not sure if itâ€™s this yet",
          "score": 1,
          "created_utc": "2026-02-11 00:03:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4p0nse",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -5,
          "created_utc": "2026-02-10 22:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4p7xed",
              "author": "brile_86",
              "text": "global outages exist since way before vibe coding, not sure when you have started in IT",
              "score": 21,
              "created_utc": "2026-02-10 22:41:27",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8hkc",
                  "author": "AntDracula",
                  "text": "Jarvis, google what \"frequency\" means.",
                  "score": 1,
                  "created_utc": "2026-02-12 13:37:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r0hm2o",
      "title": "Support cases unassigned. Anyone still alive at AWS?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "author": "symgenix",
      "created_utc": "2026-02-09 21:44:20",
      "score": 57,
      "num_comments": 72,
      "upvote_ratio": 0.71,
      "text": "Have any of you experienced the same situation? I've got 3 tickets, none of them being actually addressed, the oldest one being created 11d ago.\n\nI am wondering if I should send a registered letter or send a pigeon with my case file, as those would probably arrive quicker than someone actually responding to my online cases. We seem to revert to stone age soon, at least at AWS. AWS would then become ASS right? Amazon Stone Services.\n\nEdit: Basic Support level. Low priority is automatically assigned everywhere.\n\nhttps://preview.redd.it/rbk5wd3hgjig1.png?width=666&format=png&auto=webp&s=6b6b7784a742e28f3d6ed3fda06bb60a2b8357e0",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r0hm2o/support_cases_unassigned_anyone_still_alive_at_aws/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4i9jbq",
          "author": "anoeuf31",
          "text": "What support level are you on and what severity level were these cases opened at ?",
          "score": 40,
          "created_utc": "2026-02-09 21:48:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4i9rvg",
              "author": "symgenix",
              "text": "Basic -> Low\n\nSo, one could no longer receive any support unless one pays for a support subscription? :D That must be a compelling business decision.",
              "score": -74,
              "created_utc": "2026-02-09 21:50:10",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ihda4",
                  "author": "nemec",
                  "text": "> That must be a compelling business decision.\n\nMoney can be exchanged for goods and (support) services",
                  "score": 80,
                  "created_utc": "2026-02-09 22:28:53",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iam0c",
                  "author": "anoeuf31",
                  "text": "Unironically yes - do you think support engineers work out of the goodness of their hearts ? Business support starts at 29 bucks a month . \n\nIf you think whatever you are running on AWS isnâ€™t worth the 29 bucks a month, donâ€™t be surprised when support treats your cases with the same level of importance",
                  "score": 85,
                  "created_utc": "2026-02-09 21:54:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ixz5b",
                  "author": "planedrop",
                  "text": "Dude, pretending that support should just be included doesn't really make sense.\n\n  \nThe point of a lot of cloud services is to be *as cheap as possible* which means cutting support unless you want to pay for that on your own as well. ",
                  "score": 6,
                  "created_utc": "2026-02-09 23:57:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4id9v5",
          "author": "mistuh_fier",
          "text": "Unfortunately if youâ€™re not paying for support then thereâ€™s not much differentiating you vs. mass registrations by AI agents to abuse the Free Tier. \n\nFree tier support tickets to a specific service are essentially aggregated and treated as a canary for widespread issues.",
          "score": 44,
          "created_utc": "2026-02-09 22:07:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4idiwe",
          "author": "PracticalTwo2035",
          "text": "Dude, setup bedrock playground? Wtf, there is no setup, just usage. Please try to search in the internet and maybe read the docs.",
          "score": 31,
          "created_utc": "2026-02-09 22:09:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4j9mat",
          "author": "d70",
          "text": "Basic support = you are free to read documentation on your own. From [the FAQ](https://aws.amazon.com/premiumsupport/faqs/):\n\n>How are the enhanced AWS Support tiers different from Basic Support?\n\n>AWS Basic Support offers all AWS customers access to our Resource Center, Service Health Dashboard, Product FAQs, and Discussion Forums â€“ at no additional charge. Customers who desire a deeper level of support can subscribe to AWS Support at the Business Support+, Enterprise, or Unified Operations level.",
          "score": 5,
          "created_utc": "2026-02-10 01:04:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4i9h47",
          "author": "Outrageous_Lab_6228",
          "text": "What is your support tier?",
          "score": 14,
          "created_utc": "2026-02-09 21:48:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4iaarh",
              "author": "symgenix",
              "text": "Basic. I'd rather switch to a different provider than pay for support subscriptions lol.. especially since nothing seems to be properly working without a PHD in AWS apparently. ",
              "score": -48,
              "created_utc": "2026-02-09 21:52:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iciao",
                  "author": "caughtinthought",
                  "text": "FYI the providers that are a layer above AWS (i.e., hand hold more) typically charge much more too. The further from the foundation you go, the more shit costs. ",
                  "score": 21,
                  "created_utc": "2026-02-09 22:04:02",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iaufs",
                  "author": "anoeuf31",
                  "text": "When you find this magical cloud provider thatâ€™ll respond to your cases on priority without a support fee , please let us all know !!",
                  "score": 37,
                  "created_utc": "2026-02-09 21:55:38",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4iolp9",
                  "author": "Dave4lexKing",
                  "text": "If whatever youâ€™re building isnâ€™t worth $29/mo for support, then it canâ€™t be very good?",
                  "score": 5,
                  "created_utc": "2026-02-09 23:06:24",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ikssi",
                  "author": "Nemphiz",
                  "text": "That kinda sounds like a skill issue tbh.",
                  "score": 8,
                  "created_utc": "2026-02-09 22:46:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ih6sp",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear that your support cases have not been responded to yet. I've passed along your feedback to our Support team. Any updates about your support cases will be sent to your inbox. \n\n\\- Gee J.",
          "score": 11,
          "created_utc": "2026-02-09 22:27:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kp4wa",
          "author": "MavZA",
          "text": "Reading how youâ€™ve responded to comments then maybe you should either consider switching as youâ€™ve threatened you would. Doesnâ€™t seem like youâ€™ve put any effort into learning AWS and how to use the services or how the services fundamentally work. You say you need a PHD, but clearly youâ€™ve come in without any fundamentals and are frustrated because it doesnâ€™t work the way you think it should.",
          "score": 5,
          "created_utc": "2026-02-10 06:49:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4icdhs",
          "author": "Horror_Response_1991",
          "text": "If you arenâ€™t giving them money for support or giving them a lot of money for regular use, they do not care. Â They only have so much support staff and theyâ€™re all busy helping the money.",
          "score": 5,
          "created_utc": "2026-02-09 22:03:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4jqlu3",
          "author": "stephenin916",
          "text": "NOPE everything is going into AI and they have reduced the front line personnel ...if you pay the big money then you get more attention but the days of customer obsession are GONE and the shareholder days have arrived. ",
          "score": 3,
          "created_utc": "2026-02-10 02:43:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4kb4hu",
          "author": "teambob",
          "text": "They layed off thousands of people",
          "score": 2,
          "created_utc": "2026-02-10 04:56:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4k6g1b",
          "author": "RuinEnvironmental394",
          "text": "Did you try sending a telegram? And no I'm not talking about the app. ðŸ˜­",
          "score": 1,
          "created_utc": "2026-02-10 04:23:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4iab9q",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": -3,
          "created_utc": "2026-02-09 21:52:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4j5exp",
              "author": "gbonfiglio",
              "text": "Itâ€™s important to debunk this one: there is no mechanism in AWS Support which causes â€˜simpleâ€™ cases to be ignored.\n\nCases are routed to engineers based on a range of parameters like service, complexity, time since open, support tier etc - so there canâ€™t be any structural decision to ignore these cases.",
              "score": 5,
              "created_utc": "2026-02-10 00:39:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o4iamdq",
              "author": "symgenix",
              "text": "Yes, I did try multiple times via their amazing AI, which, in my experience, was only able to circle around non-related stuff and point me to nonsensical locations. They probably outsource their baisc support AI model to the first model of gpt.",
              "score": -15,
              "created_utc": "2026-02-09 21:54:29",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4iedap",
                  "author": "InterestedBalboa",
                  "text": "Basic support is no support, just how it works",
                  "score": 8,
                  "created_utc": "2026-02-09 22:13:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r37abo",
      "title": "AWS Backup adds cross-Region database snapshot copy to logically air-gapped vaults",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/aws-backup-adds-cross-region-database-snapshot-logically-air-gapped-vaults/",
      "author": "magnetik79",
      "created_utc": "2026-02-12 22:16:45",
      "score": 35,
      "num_comments": 15,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "database",
      "permalink": "https://reddit.com/r/aws/comments/1r37abo/aws_backup_adds_crossregion_database_snapshot/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5282yb",
          "author": "AutoModerator",
          "text": "Try [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": 1,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52l92m",
          "author": "Mutjny",
          "text": "\"Logically\" air-gapped throw some big air quotes around that one.",
          "score": 11,
          "created_utc": "2026-02-12 23:27:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52jq4v",
          "author": "The_Tree_Branch",
          "text": "> Now do cross-region and cross-account in a single backup task.\n\nUnless I'm misunderstanding you, this already exists as of October 2025: https://aws.amazon.com/about-aws/whats-new/2025/10/aws-backup-single-action-database-snapshot-copy-regions/",
          "score": 8,
          "created_utc": "2026-02-12 23:18:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52lkv4",
              "author": "magnetik79",
              "text": "ðŸ¤¦â€â™‚ï¸ oh geez, I totally missed this announcement. Thanks for the heads up - you're indeed correct!\n\nhttps://docs.aws.amazon.com/aws-backup/latest/devguide/backup-feature-availability.html#features-by-resource\n\n> Amazon RDS, Aurora, DocumentDB, and Neptune now support cross-Region and cross-account snapshot copying in a single action. \n\nNice! Just need to add KMS keys to existing clusters and.... _recreate them_. Still this makes the process much nicer.",
              "score": 1,
              "created_utc": "2026-02-12 23:28:51",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o529jr4",
          "author": "freeriderblack",
          "text": "... and RDS still behind. I have never understood why they don't keep consistency between Aurora and RDS when it comes to AWS Backups features.",
          "score": 7,
          "created_utc": "2026-02-12 22:24:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52mmu0",
              "author": "naggyman",
              "text": "Aurora and RDS have very different tech stacks under the hood - so Iâ€™m guessing itâ€™d be like developing two entirely separate features. \n\nSo the question then becomes - do you have to hold off releasing support for one because you havenâ€™t completed development on support for the other.",
              "score": 9,
              "created_utc": "2026-02-12 23:34:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o530b5p",
          "author": "kopi-luwak123",
          "text": "It still does not work with AMK encrypted stuff, right ?",
          "score": 1,
          "created_utc": "2026-02-13 00:53:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o533ji1",
              "author": "magnetik79",
              "text": "No I would assume not - anytime you need to move a backup across regions or accounts you need to be using KMS keys - as Amazon managed keys are unique to each AWS account and region and can't used beyond those bounds.",
              "score": 1,
              "created_utc": "2026-02-13 01:13:02",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o53ctrs",
                  "author": "kopi-luwak123",
                  "text": "Yeah, so the intermediate vault is still required.",
                  "score": 1,
                  "created_utc": "2026-02-13 02:10:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o56v79q",
          "author": "gex80",
          "text": "What the hell does logically air-gapped mean? The only definition I know of means no network access",
          "score": 1,
          "created_utc": "2026-02-13 16:43:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59bnvp",
          "author": "ruibranco",
          "text": "the term \"logically air-gapped\" is doing more heavy lifting than any vpc peering config i've ever written",
          "score": 1,
          "created_utc": "2026-02-14 00:13:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5282x0",
          "author": "AutoModerator",
          "text": "Here are a few handy links you can try:\n\n- https://aws.amazon.com/products/databases/\n- https://aws.amazon.com/rds/\n- https://aws.amazon.com/dynamodb/\n- https://aws.amazon.com/aurora/\n- https://aws.amazon.com/redshift/\n- https://aws.amazon.com/documentdb/\n- https://aws.amazon.com/neptune/\n\nTry [this search](https://www.reddit.com/r/aws/search?q=flair%3A'database'&sort=new&restrict_sr=on) for more information on this topic.\n\n^Comments, ^questions ^or ^suggestions ^regarding ^this ^autoresponse? ^Please ^send ^them ^[here](https://www.reddit.com/message/compose/?to=%2Fr%2Faws&subject=autoresponse+tweaks+-+database).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/aws) if you have any questions or concerns.*",
          "score": -4,
          "created_utc": "2026-02-12 22:16:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r10ppv",
      "title": "Is Google Drive really cheaper than S3 storage?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "author": "nucleustt",
      "created_utc": "2026-02-10 13:27:49",
      "score": 27,
      "num_comments": 59,
      "upvote_ratio": 0.73,
      "text": "I was in the process of building a cloud backup solution for my company to store files in S3 buckets on our AWS account (US-EAST-1).\n\nNaturally, I did some research on the estimated costs and compared them with other Cloud Storage solutions, like Google Drive.\n\nThat's when I discovered that using Google Drive was actually cheaper.\n\nThis also makes it difficult to compete against Google Drive if you're building your own cloud storage solution.\n\nAre there any Cloud Storage solutions or AWS tiers that are cheaper than Google Drive?\n\nGoogle Drive ($1.99/month for 100GB, further savings on yearly plans)\n\nAWS S3 ($2.30/month for 100GB, not including request fees)",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r10ppv/is_google_drive_really_cheaper_than_s3_storage/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4m1auu",
          "author": "ReturnOfNogginboink",
          "text": "AWS Glacier Deep Archive is about $1/TB/mo.\n\nThe costs hit when you need to retrieve data. For backups, that happens rarely.",
          "score": 87,
          "created_utc": "2026-02-10 13:34:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mpwdj",
              "author": "ohad1282",
              "text": "And it is slow retrieval, unless you use Glacier IR which is a good potential combination for both low cost storage and quick retrieval",
              "score": 10,
              "created_utc": "2026-02-10 15:42:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4nhszu",
                  "author": "enjoytheshow",
                  "text": "Retrieval costs are way more though IIRC",
                  "score": 2,
                  "created_utc": "2026-02-10 17:51:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mux3r",
              "author": "Vista_Lake",
              "text": "Yes, this is exactly right. I've been using Deep Archive for years, have never had to retrieve a file, and probably never will, since I also keep a local backup.",
              "score": 7,
              "created_utc": "2026-02-10 16:05:50",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4qm7aw",
                  "author": "madwolfa",
                  "text": "Same, I've been using it as an off-site backup for my NAS for many years too.Â ",
                  "score": 1,
                  "created_utc": "2026-02-11 03:35:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m2gm7",
          "author": "No-Rip-9573",
          "text": "Correct me if Iâ€™m wrong but I believe Google drive does not do snapshots or WORM protection, which you would want for backup solution. If youâ€™re just looking for a place to dump some files cheaply thatâ€™s ok, but donâ€™t call it backup if any random malware can just encrypt/overwrite/delete it for you.",
          "score": 38,
          "created_utc": "2026-02-10 13:40:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m3aik",
          "author": "solo964",
          "text": "Did you mean Google Drive or Google Cloud Storage?  \n  \nAmazon S3 and Google Drive both store files but they are very different storage systems and were designed for fundamentally different purposes. S3's primary audience is developers and applications while Google Drive's audience is end users. They have different access mechanisms, different service tiering, different pricing models, different integration with other services, etc. Aside from storing files, they are totally different.",
          "score": 48,
          "created_utc": "2026-02-10 13:45:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4mfsqf",
              "author": "PlanB2019",
              "text": "Yet the product targeted for developers to ideally serve an end product is more expensive than Google Drive. Thatâ€™s the parallel op is trying to point out. Itâ€™s how the offerings are so expensive.",
              "score": 6,
              "created_utc": "2026-02-10 14:52:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o571rgs",
                  "author": "solo964",
                  "text": "Yes, fair point. I just wanted to be sure the OP understood that this was somewhat comparing apples to oranges. Google Drive seems a lot cheaper per GB because it targets priceâ€‘sensitive users who rarely access their data and who are relatively latency-insensitive. Google can therefore likely use cheaper infrastructure with lower SLAs. Amazon S3 offers significantly more features, more capability, etc.",
                  "score": 1,
                  "created_utc": "2026-02-13 17:14:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4pi78z",
                  "author": "nucleustt",
                  "text": "you are correct",
                  "score": 1,
                  "created_utc": "2026-02-10 23:37:48",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m1dlz",
          "author": "DominusGod",
          "text": "I would look at Backblaze B2 for backups. They are way cheaper than AWS. Also Google Drive does have limits",
          "score": 20,
          "created_utc": "2026-02-10 13:34:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4oqe9a",
              "author": "magnetik79",
              "text": "Backblaze B2 for sure if you're looking for object storage on cost. \n\nThey also have a compatible S3 API as well, so it can work with AWS S3 based tooling as well.",
              "score": 3,
              "created_utc": "2026-02-10 21:17:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m24v1",
          "author": "the_birds_and_bees",
          "text": "$0.023 / GB is for standard tier access, which is probably overkill for backups. Pricing here [https://aws.amazon.com/s3/pricing/](https://aws.amazon.com/s3/pricing/) but assuming you are happy with slower retrieval times you can go much cheaper.\n\nBroadly, cheaper => slower access times and higher cost per request. You'd need to pick a tier which works for your business (think \"will I feel comfortable waiting {x time} while prod db is down and the boss is breathing down my neck while I wait for the backup to download\").",
          "score": 7,
          "created_utc": "2026-02-10 13:38:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pipzf",
              "author": "nucleustt",
              "text": "I wanted frequent access and quick retrieval. So that's why I didn't choose Glacier or deep archive",
              "score": 0,
              "created_utc": "2026-02-10 23:40:49",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ppco5",
                  "author": "mikebailey",
                  "text": "At scale you may also have issues on Google Drive if that was your pattern: https://developers.google.com/workspace/drive/api/guides/limits",
                  "score": 3,
                  "created_utc": "2026-02-11 00:18:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7tzl",
          "author": "Sirwired",
          "text": "Google Drive and S3 are *very* different use-cases; they aren't really comparable.  Google Drive is an end-user file collaboration tool, S3 is an entire enterprise-grade object storage system.",
          "score": 18,
          "created_utc": "2026-02-10 14:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pik43",
              "author": "nucleustt",
              "text": "This is true. \n\nI wanted to create my own Google Drive-type app, but using S3 since we already have the infrastructure.\n\nAlso, if I wanted to make a competitor to Google Drive, I obviously can't compete on costs.",
              "score": 0,
              "created_utc": "2026-02-10 23:39:53",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pjg40",
                  "author": "Sirwired",
                  "text": "Frankly, because of all the other costs involved with end-user services (development, marketing, support, billing, etc.), you'd have a tough time competing with Google Drive if your back-end storage was free.\n\nGoogle can provide the per-GB costs they do because most users only use a fraction of their quota, vs. S3, which is purely a consumption-based service.",
                  "score": 5,
                  "created_utc": "2026-02-10 23:45:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4m7sc5",
          "author": "powersline",
          "text": "Check out backblaze B2 and/or Wasabi.   Both are s3 compatible at a fraction of the price",
          "score": 4,
          "created_utc": "2026-02-10 14:09:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pis8q",
              "author": "nucleustt",
              "text": "Will do, thanks",
              "score": 1,
              "created_utc": "2026-02-10 23:41:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mb225",
          "author": "johndburger",
          "text": "S3â€™s data durability is 99.999999999% (eleven nines). Does Google even advertise a figure for Drive?\n\nI can set up auto-delete (e.g. 30 days) for S3, no such option for Drive, as far as I can tell.\n\nI can configure S3 buckets to automatically move files to cheaper storage under various circumstances. Again, no such option in Google Drive as far as I can tell.\n\nTheyâ€™re just fundamentally different products, designed for very different use cases.",
          "score": 7,
          "created_utc": "2026-02-10 14:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nuk0n",
              "author": "AnomalyNexus",
              "text": ">Does Google even advertise a figure for Drive?\n\nNot directly, but it is backed by same tech as their cloud storage so 11 9s too. All google's consumer facing product stuff is redundancy'd to high heavens.\n\nSuspect the challenge here isn't reliability but rather variability of throughput. All these sync based drive things are all over the place on what performance you get when",
              "score": 2,
              "created_utc": "2026-02-10 18:49:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4pp3tx",
                  "author": "mikebailey",
                  "text": "This isnâ€™t how SLAs actually trickle, since adding those layers of abstraction can impede it. Source: our company sells something that sits on top of BQ, yet our SLA is like 99% or something way lower.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:16:39",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4mfarm",
              "author": "PlanB2019",
              "text": "The complaint which is completely valid is the cost storage and egress fees are more than Google Drive. File storage is a pretty common feature set in applications, itâ€™s odd that a file storage service is multiple times more expensive than Google Drive. Listing features on top the core service doesnâ€™t really change it for me, as Iâ€™m sure it doesnâ€™t for others.",
              "score": -4,
              "created_utc": "2026-02-10 14:49:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4mr8zy",
                  "author": "justin-8",
                  "text": "I don't know if I'd call the 15% difference the OP pointed out is \"multiple times more expensive\"",
                  "score": 4,
                  "created_utc": "2026-02-10 15:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mygcy",
          "author": "ioannisthemistocles",
          "text": "Years ago I used Google Drive to store shell scripts, before I started using github. \n\nI found that Google inserted hidden characters in the scripts that broke them. I don't know if that is still the case,\n\nNevertheless, a backup isn't a backup unless you do a test restore and validation.",
          "score": 2,
          "created_utc": "2026-02-10 16:22:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pjox0",
              "author": "nucleustt",
              "text": ">Years ago I used Google Drive to store shell scripts, before I started using github.\n\nYou sound like an OG hacker.\n\nGoogle messing with the EOL char is crazy. Auto \\\\r\\\\n to \\\\n or vice versa",
              "score": 0,
              "created_utc": "2026-02-10 23:46:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4mzjnh",
          "author": "blenderman73",
          "text": "Yeah S3 ingress and egress really adds up haha - it turns into a cost monster over time",
          "score": 2,
          "created_utc": "2026-02-10 16:27:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4nixmp",
              "author": "Sirwired",
              "text": "Errr... what ingress charges?  And what do you imagine the egress charges will be for a remote backup?  It's not like these files will be read often, if ever.",
              "score": 3,
              "created_utc": "2026-02-10 17:56:32",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4ow3i6",
                  "author": "blenderman73",
                  "text": "Then drive is fine. When I worked with s3 based raw layers for EMR we were getting extremely heavy unplanned read loads at the prefix level when teams used the backup product which added up surprisingly. Primary due to how we partitioned.\n\nI.E. LIST operations are priced as writes ($0.005/1K) out of aws \n\nOr a glacier + s3 solution works",
                  "score": 1,
                  "created_utc": "2026-02-10 21:43:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mhcds",
          "author": "benpakal",
          "text": "Standard access rate is for live access from apps to files. not backup. Check glacier rates.",
          "score": 1,
          "created_utc": "2026-02-10 15:00:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mjtlq",
          "author": "OhMyTechticlesHurts",
          "text": "You mean Google Cloud Storage which Google Drive is built on top of. Cloud Storage is an IaaS service while Google Drive is a SaaS product technically speaking.",
          "score": 1,
          "created_utc": "2026-02-10 15:12:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4mswdl",
          "author": "ohad1282",
          "text": "1. Dumping the data to Google Drive may be cheap on storage cost, but think about egress/networking cost if taking the data out of your s3 as well.\n2. Google Drive will indeed provide you a copy, but this is not immutable, no proper retention policy, etc - which you probably need for your back solution and compliance needs. Think about ransomware.\n3. You have backup solutions for that - AWS backup, Rubrik, Commvault, etc. Not cheap but real backup solutions.Â \n4. Goofle drive and most backup solutions/vendors - those do not provide INCREMENTAL changes so if you change a small portion of a file/object, you need to save the whole copy.\n4. Eon.io is another backup solution which stores the data deduped, compressed and most importantly for object storage - incrementally. So honestly, I truly belive this is exactly what you need. It will save you a lot of money and protect you properly. Disclaimer - I work for Eon.",
          "score": 1,
          "created_utc": "2026-02-10 15:56:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4n3o8n",
          "author": "Bourne069",
          "text": "I dont see how. I get 1TB of S3 storage from Wasabi for $5 per month per TB...",
          "score": 1,
          "created_utc": "2026-02-10 16:46:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pl30v",
              "author": "nucleustt",
              "text": "I just learned about Wasabi",
              "score": 1,
              "created_utc": "2026-02-10 23:54:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4nd98w",
          "author": "siddharthnibjiya",
          "text": "Backblaze is $7/month for NO data limit. I found that to be quite a compelling option when evaluating",
          "score": 1,
          "created_utc": "2026-02-10 17:30:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4nrzcc",
          "author": "MavZA",
          "text": "Google Drive is not comparable to Amazon S3 in the way youâ€™re intending to use it. Maybe take a look at S3 compatible object storage solutions and compare from there. S3 is extremely resilient object storage whereas Google Drive is file storage that youâ€™d use for day to day files.",
          "score": 1,
          "created_utc": "2026-02-10 18:37:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plgt0",
              "author": "nucleustt",
              "text": "Yes, with an additional app, I hoped to make S3 behave like Google Drive. But then I saw the costs and noticed it didnt make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:56:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4pphf1",
                  "author": "mikebailey",
                  "text": "In the other direction, Drive has more limits than S3 at the filesystem/API level.",
                  "score": 1,
                  "created_utc": "2026-02-11 00:18:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4o8bcg",
          "author": "AdPhysical9992",
          "text": "Does google drive provides programmatic APIs to get the file content and other things , like event triggers that we have in s3?",
          "score": 1,
          "created_utc": "2026-02-10 19:52:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4plw0k",
              "author": "nucleustt",
              "text": "I'm not sure. \n\nIn that sense, there's no comparison. But for simple cloud sync (with a custom S3 app), the cost didn't make sense.",
              "score": 1,
              "created_utc": "2026-02-10 23:58:34",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o4ppkdw",
              "author": "mikebailey",
              "text": "Yes, thereâ€™s a huge drive SDK\n\nEvent triggers though I donâ€™t think so",
              "score": 1,
              "created_utc": "2026-02-11 00:19:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ppq4q",
          "author": "dubidub_no",
          "text": "[rsync.net](http://rsync.net) is $0.012 per GB per month single region, no ingress/egress. They have a warrant canary.",
          "score": 1,
          "created_utc": "2026-02-11 00:20:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4qtvc1",
          "author": "basedcooking",
          "text": "Thereâ€™s also Wasabi, itâ€™s about 5.99/TB - with no egress fees and instant access. But minimum 90 day retention.",
          "score": 1,
          "created_utc": "2026-02-11 04:27:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4siyl8",
          "author": "joeyx22lm",
          "text": "Iâ€™ve done both. I gave up on Google Drive once I got hit with rolling 24hr rate limit for exceeding 750gb data transfer.",
          "score": 1,
          "created_utc": "2026-02-11 13:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4m1llz",
          "author": "indigomm",
          "text": "S3 has many options depending on what service you need. Look at S3 Infrequent Access, Glacier Flexible or Instant Access, or even Glacier Deep Archive. They are all much cheaper. But be aware of transfer and retrieval costs on some products.",
          "score": 1,
          "created_utc": "2026-02-10 13:35:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk2wb",
              "author": "nucleustt",
              "text": "I actually needed frequent access.\n\n>But be aware of transfer and retrieval costs on some products.\n\nI'm not a fan of the transfer fees. IMO, the storage fees should be lower to compensate.",
              "score": 1,
              "created_utc": "2026-02-10 23:48:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o560yc6",
                  "author": "AggieDan1996",
                  "text": "The transfer fees are a holdover from the telephone system. \n\nLet's say you use AT&T and one of your friends uses AT&T and the other uses Verizon. If you call the guest friend, AT&T gets money to provide service to both of you, so there's no additional fee. But, let's say you call the other friend. AT&T has to pay Verizon so they'll complete the call for you. \n\nBack in the dialup Internet days this led to lots of ISPs being phone companies that didn't provide phone service to individuals. So all calls were inbound this requiring your phone company to pay as well as you paying for the service. \n\nThe Internet still has the same logic. That's why you pay to get your data back, AWS gets charged from their ISP because your ISP effectively charges them. They're just passing on their cost. It's also why inter-AZ and inter-region costs exist. AWS is likely using different last mile providers just due to geography.",
                  "score": 1,
                  "created_utc": "2026-02-13 14:15:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4mgfvc",
          "author": "mojo21136",
          "text": "Building your own backup solution (or any other solved problems) is not a good use of time. Other providers have solved cheaper than you can do and if something goes wrong when restore is necessary it will be a resume generating event.",
          "score": 1,
          "created_utc": "2026-02-10 14:55:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4pk942",
              "author": "nucleustt",
              "text": ">Building your own backup solution (or any other solved problems) is not a good use of time. \n\nThat's what I figured out after investigating the costs. I thought it would have been cheaper to host on S3 TBH.",
              "score": 1,
              "created_utc": "2026-02-10 23:49:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4m4fpj",
          "author": "Old_Cry1308",
          "text": "yeah, google drive cheaper. s3 has hidden fees. good luck competing with that.",
          "score": -8,
          "created_utc": "2026-02-10 13:51:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r0ldl9",
      "title": "Structured outputs now available in Amazon Bedrock",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/structured-outputs-available-amazon-bedrock/",
      "author": "ckilborn",
      "created_utc": "2026-02-10 00:12:23",
      "score": 26,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "ai/ml",
      "permalink": "https://reddit.com/r/aws/comments/1r0ldl9/structured_outputs_now_available_in_amazon_bedrock/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o4jzhfn",
          "author": "omenking",
          "text": "Hmmm. Structured outputs is always a gotcha with multiple models and so I'd be wary to believe it works across all available models.",
          "score": 0,
          "created_utc": "2026-02-10 03:37:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4kkgdu",
              "author": "Seref15",
              "text": "It lists which models it works with at the bottom of the article.",
              "score": 4,
              "created_utc": "2026-02-10 06:08:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r2rc0s",
      "title": "AWS (AI) Support - unassigned case for 24h with Business Support+",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "author": "alex_aws_solutions",
      "created_utc": "2026-02-12 11:47:23",
      "score": 21,
      "num_comments": 15,
      "upvote_ratio": 0.79,
      "text": "I thought the Business Support+ Plan is something different.... but not. Very unsatisfied!",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r2rc0s/aws_ai_support_unassigned_case_for_24h_with/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4zbjg4",
          "author": "kei_ichi",
          "text": "Isnâ€™t â€œbusiness support+ â€œ plan is just â€œdeveloper supportâ€ plan? But they renamed it to look like an â€œupgradeâ€ but in reality that is just a fancy name and you will â€œmostlyâ€ get answers from AI slop because they fired almost all of their support staff and still continue to do do that! To be honest, even enterprise support plan account are getting answers from bot instead of human so with your 29$ per month support planâ€¦good luck to get your support case handled by human!",
          "score": 17,
          "created_utc": "2026-02-12 13:54:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5271t5",
              "author": "PsychologicalAd6389",
              "text": "You do realize that if you click the option to get a human youâ€™ll get a human",
              "score": 2,
              "created_utc": "2026-02-12 22:11:37",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o529ixc",
                  "author": "kei_ichi",
                  "text": "Ya, but in â€œtheoryâ€ only. Again, good luck to get support from human with that support plan. You â€œwillâ€ but with the cost of â€œlong longâ€ waiting queue because another people demand the same (because AI slop just respond with nonsense answers) but how many support staff â€œleftâ€ in that company????",
                  "score": 1,
                  "created_utc": "2026-02-12 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4yu21k",
          "author": "Burekitas",
          "text": "Click reply and pick the Chat option, which would expedite the case.",
          "score": 19,
          "created_utc": "2026-02-12 12:02:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4z8b01",
          "author": "AntDracula",
          "text": "Oops sorry about that. Better layoff another 10,000!",
          "score": 20,
          "created_utc": "2026-02-12 13:36:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ywsdw",
          "author": "ManBearHybrid",
          "text": "They fired all their support staff in favour of AI and customer service is suffering because of it. I wonder if they consider this a bad thing or if it's just worth it to save from paying all those salaries. ",
          "score": 8,
          "created_utc": "2026-02-12 12:22:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4yzagw",
              "author": "CircularCircumstance",
              "text": "People complaining on Reddit comes at no added costs for AWS.  They'll only respond if it begins to affect the bottom line, IE enterprise customers taking their business elsewwhere.\n\nUnfortunately for so many of us, we are so deeply locked into AWS that the costs for us to move to another provider is massive.",
              "score": 6,
              "created_utc": "2026-02-12 12:40:00",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4zgt3y",
                  "author": "CubsFan1060",
                  "text": "This is a great argument for shying away from provider specific tools.  If you build heavily on DynamoDB and Lambda, you're going to struggle to ever be able to actually think about moving.\n\nEveryone likes to talk about the complexity of Kubernetes (which is fair), but if your stack is EKS + postgres + S3, it still isn't _easy_ to move, but it's much much more possible to move.",
                  "score": 2,
                  "created_utc": "2026-02-12 14:22:59",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4z8l2j",
                  "author": "AntDracula",
                  "text": "Enshittification hits AWS",
                  "score": 2,
                  "created_utc": "2026-02-12 13:37:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4yzb3f",
              "author": "Sirwired",
              "text": "No, they did *not* fire \"all\" the support staff.  Silly exaggeration like this does nobody any favors.",
              "score": -7,
              "created_utc": "2026-02-12 12:40:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4z8m9r",
                  "author": "AntDracula",
                  "text": "Hi Andy",
                  "score": 0,
                  "created_utc": "2026-02-12 13:38:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o501vfx",
          "author": "mediocretes",
          "text": "Yeah, this is par for the course. Thereâ€™s no point to paying for Amazon support. Iâ€™ve never once had them meet SLAs when anything significant was happening.",
          "score": 4,
          "created_utc": "2026-02-12 16:07:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4yvxwj",
          "author": "AWSSupport",
          "text": "Hello, \n\nThanks for providing your case ID. \n\nI can confirm that your case is in the correct queue. I've reached out internally to have this looked into. \n\nBe sure to keep an eye open for further correspondence from our Support team.\n\n\\- Craig M.",
          "score": 2,
          "created_utc": "2026-02-12 12:16:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4ywqvv",
              "author": "alex_aws_solutions",
              "text": "Thank you Craig.",
              "score": 1,
              "created_utc": "2026-02-12 12:22:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ythgl",
          "author": "AWSSupport",
          "text": "Hello,\n\nI'm sorry for the frustration this has caused. Please DM us your case ID, so we can take a closer look. \n\n\\- Craig M.",
          "score": 0,
          "created_utc": "2026-02-12 11:57:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qza7v3",
      "title": "Silent behavioral change in NLB DNS publishing for empty AZs? (Breaking change for DR/Failover)",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "author": "atawii",
      "created_utc": "2026-02-08 14:24:46",
      "score": 19,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nIâ€™m noticing a significant discrepancy in behavior between legacy Network Load Balancers and newly created ones regarding how they handle DNS for Availability Zones with 0 registered targets.\n\n**The Setup:**\n\n* **Architecture:** Internet-facing NLB -> Target Group (Instance Type) -> K8s Nodes (NodePort).\n* **Cross-Zone Load Balancing:** **Disabled** (intentionally, for cost/latency reasons in a specific multi-AZ setup).\n* **Scenario:** 3 AZs with one specific AZ (e.g., `ca-central-1d`) has no healthy targets (0 nodes).\n\n**The Discrepancy:**\n\n1. **Old NLB (Created \\~2024):**\n   * **Behavior:** The NLB automatically removes the IP address of the empty AZ from the DNS record.\n   * **Result:** `dig comand` returns only 2 IPs (for the healthy AZs). Traffic is never routed to the empty AZ. Everything works.\n   * If we terminate all instances from the first AZ (1a) with AWS FIS, the DNS assigned from this AZ was also removed, so we have only one DNS remaining.\n2. **New NLB (Created Feb 2026):**\n   * **Configuration:** Identical to the old one (Terraform/OpenTofu code is the same).\n   * **Behavior:** The NLB **continues to publish the IP** of the empty AZ in the DNS record.\n   * **Result:** `dig` returns 3 IPs. Client traffic is round-robined to the empty AZ (\\~33% of requests). Since Cross-Zone is disabled and there are no local targets, these packets are blackholed, causing immediate connection timeouts/failures.\n\n**Support's Response:** I opened a ticket, and AWS Support claims *\"*After reviewing your case and consulting with our internal resources, I can confirm that \\*\\*this is the expected behavior for Network Load Balancers\\*\\*, and there has been no recent change to how NLBs handle DNS resolution for AZs with no registered targets*.\"*\n\nHowever, the empirical evidence (side-by-side `dig` results on same-region, same-config LBs) suggests otherwise.\n\n**The Impact:** This feels like a silent breaking change. Previously, we relied on the NLB's ability to \"drain\" an AZ from DNS if the backend was dead (fail-open style). Now, it seems new NLBs are \"sticky\" to their AZs regardless of backend health, which breaks standard DR/Failover patterns where you might spin down an AZ to save costs or during an outage.\n\n**Questions:**\n\n* Has anyone else noticed this shift in \"Fail Open\" behavior on recent NLBs?\n* Is there a new attribute (hidden or documented) that controls this \"DNS draining\" behavior?\n* Is the only solution now to force Cross-Zone Load Balancing (and pay the transfer costs) or manually manipulate Subnet mappings during an incident?\n\nThanks for any insights.",
      "is_original_content": false,
      "link_flair_text": "technical question",
      "permalink": "https://reddit.com/r/aws/comments/1qza7v3/silent_behavioral_change_in_nlb_dns_publishing/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o499urc",
          "author": "ggbcdvnj",
          "text": "The amount of times support has told me â€œthereâ€™s been no changeâ€ when you eventually pull it out of the service team after enough escalation that there actually was a change kills me\n\nDealing with L1 AWS support drains my will to live\n\n</rant>\n\nSorry, all I can say is I wish you the best",
          "score": 14,
          "created_utc": "2026-02-08 14:34:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49brec",
              "author": "atawii",
              "text": "It's incorrect, but honestly, it's the best support response I've had in the last year. At least I got it in under 24 hours.",
              "score": 4,
              "created_utc": "2026-02-08 14:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49s8fv",
                  "author": "MateusKingston",
                  "text": "\"At least I got told the incorrect information fast\".\n\nLol.\n\nThey also even lied, if it was under 24h they didn't even check anything with anyone",
                  "score": 1,
                  "created_utc": "2026-02-08 16:10:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4cu6wz",
              "author": "Ok-Helicopter525",
              "text": "Ok the flip side, customers are very quick to say â€œthe service must have changed or broken somethingâ€ only to find out, oops, itâ€™s their environment that has the issue.",
              "score": 4,
              "created_utc": "2026-02-09 01:34:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o499f7m",
          "author": "notathr0waway1",
          "text": "This sounds super weird and interesting.  I feel like you documented it well and I hope someone competent actually addresses it.",
          "score": 11,
          "created_utc": "2026-02-08 14:32:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49cplf",
              "author": "atawii",
              "text": "I'm able to reproduce with old NLB  the behavior. I have report with AWS FIS (for example testing to disrupt an AZ), that is impossible with the new behavior. I'm pretty sure to be not alone.\n\nThe next think I want to test, if I reproduce in another AWS region.",
              "score": 2,
              "created_utc": "2026-02-08 14:50:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4akqy2",
          "author": "ruibranco",
          "text": "Check the target group attributes with \\`aws elbv2 describe-target-group-attributes\\` on both old and new. Specifically look at \\`target\\_group\\_health.dns\\_failover.minimum\\_healthy\\_targets.count\\` and the unhealthy state routing settings. AWS changed some defaults on newer TGs and it's not always reflected in the Terraform state if you're importing or if the provider version changed between the two deploys.",
          "score": 7,
          "created_utc": "2026-02-08 18:27:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4c0ldy",
              "author": "atawii",
              "text": "Yes, I already check with the UI (and now with the CLI) the minimum\\_healthy\\_targets value is 1 on tjhe old and the new target group. That same to be the default and minimal settings.",
              "score": 1,
              "created_utc": "2026-02-08 22:44:28",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4ca8le",
                  "author": "ruibranco",
                  "text": "Interesting, if TG attributes match then it's probably at the NLB level. Check if cross-zone load balancing is configured the same on both, and also compare the \\`dns\\_record.client\\_routing\\_policy\\` attribute on the NLB itself. AWS quietly introduced zonal affinity settings that can affect DNS behavior when an AZ has no healthy targets.",
                  "score": 1,
                  "created_utc": "2026-02-08 23:40:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o49ae1u",
          "author": "yarenSC",
          "text": "Definitely push back on the support case to explain what's different between the 2.  It's either a bug (since the public docs explicitly say DNS fail over should happen), or something is different \n\nAre you sure there isn't a second target group on the new NLB?  And are all targets healthy?\nWhat you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS",
          "score": 3,
          "created_utc": "2026-02-08 14:37:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o49c677",
              "author": "atawii",
              "text": ">since the public docs explicitly say DNS fail over should happen\n\nDo you have a link to the documentation that explain that? I don't find it.\n\n>Are you sure there isn't a second target group on the new NLB? And are all targets healthy? What you described should happen if all AZs are viewed as unhealthy by the NLB, and it's failing open on DNS\n\nYes, I'm sure all instances are healthy on the target group.",
              "score": 2,
              "created_utc": "2026-02-08 14:47:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o49drfz",
                  "author": "yarenSC",
                  "text": "[https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/network-load-balancers.html#load-balancer-zonal-health)\n\n  \nThis also has a list of things for you to check to see why it might be failing open.  Note there's a new setting that could be impacting this where you can change the minimum healthy hosts required for an AZ to be considered healthy.  Although if your terraform is identical, then presumably it isn't being used on your new NLB\n\n[https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/](https://aws.amazon.com/blogs/networking-and-content-delivery/using-load-balancer-target-group-health-thresholds-to-improve-availability/)",
                  "score": 3,
                  "created_utc": "2026-02-08 14:56:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4ao28f",
          "author": "x86brandon",
          "text": "Couple of things:\n\nAre you doing the dig against your CNAME or the AWS NLB hostname?  What are you running the dig against? AWS auth or your local DNS?  There are quite a few cases where DNS providers do not honor the low TTL and I have seen places like Comcast take 5-10 minutes to expire the record regardless of the 60 second TTL.  That could be at play here.   I would be curious to see if you still see that after a minute or two from AWS auth servers.  \n  \nDepending on your SLA/SLO, you shouldn't rely on failover this way anyways, you will always have several minutes of black hole potential with an NLB.  In my most critical of apps, before zonal shift existed, I used to do NLB per AZ and orchestrate my traffic failover myself.   It also triples my capacity capability.  However, if you want to purposefully shut down an AZ, I would suggest using zonal shift to get traffic it off it before you remove the AZ.",
          "score": 2,
          "created_utc": "2026-02-08 18:42:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4bzwzn",
              "author": "atawii",
              "text": "We use CloudFront in front of the ELB, so it relies solely on AWS's internal DNS resolver, bypassing client-side DNS issues. We have tested this multiple times, and the downtime during an AZ disruption is only 10 seconds. Zonal Shift is still interesting, but we view it as complementary.\n\nIn our case, we have the exact same result after 1m or 60minutes from AWS DNS resolver or internet resolver.",
              "score": 2,
              "created_utc": "2026-02-08 22:40:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4asmwb",
          "author": "x86brandon",
          "text": "Interestingly, Terraform changed the way subnets are handled because of a new API function added.   And folks are complaining about stale IP's being left in target groups creating a similar behavior too.   Something to look at that might explain the differences between the 2 NLB's, especially if your old one was created one way and the new one created another.   As the underlying API interaction in Terraform changed last year.\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41418](https://github.com/hashicorp/terraform-provider-aws/issues/41418)\n\n[https://github.com/hashicorp/terraform-provider-aws/issues/41880](https://github.com/hashicorp/terraform-provider-aws/issues/41880)",
          "score": 2,
          "created_utc": "2026-02-08 19:03:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r209uo",
      "title": "Amazon Textract vs GPT",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "author": "nucleustt",
      "created_utc": "2026-02-11 15:24:44",
      "score": 18,
      "num_comments": 22,
      "upvote_ratio": 0.79,
      "text": "I just had a look at Amazon Textract's pricing, and I'm certain that token usage on a multi-modal GPT model can extract the text from an image into a structured JSON document for much less.\n\nWhat are the advantages of using Amazon Textract vs GPT?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r209uo/amazon_textract_vs_gpt/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tcrbo",
          "author": "kapowza681",
          "text": "Textract is deterministic, so youâ€™ll typically get the same result every time. Itâ€™s much better at recognizing hand written characters. It gives you the precise location of the characters, which may or may not be useful depending on what youâ€™re hoping to accomplish. \n\nYou can also use both. I sometimes pass along the Textract extracted text to the model along with the document/image as a kind of â€œhelperâ€ text.",
          "score": 48,
          "created_utc": "2026-02-11 15:40:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4tj7k7",
              "author": "RecordingForward2690",
              "text": "The precise location stuff is really handy. We were building an application that had to deal with copies of ID documents. Once the document was uploaded, we had to obfuscate the Dutch equivalent of the SSN due to privacy regulations. Textract and ImageMagick made that easy.\n\nMind the (relatively low) throughput quota though.",
              "score": 14,
              "created_utc": "2026-02-11 16:11:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4w4xat",
                  "author": "trashtiernoreally",
                  "text": "Quotas can be increased both in terms of async submissions per second and simultaneous running requests.Â ",
                  "score": 2,
                  "created_utc": "2026-02-11 23:44:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o4tg83s",
              "author": "nucleustt",
              "text": "Those are solid advantages. \n\nAnd you're right, it may be best to use them in combination to increase reliability when reading critical documents.",
              "score": 4,
              "created_utc": "2026-02-11 15:57:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tinpb",
          "author": "kievmozg",
          "text": "I have to slightly disagree on the handwriting part. While Textract is decent, it lacks semantic context. If a handwritten '5' looks like an 'S', Textract often guesses wrong based on pixel shape alone. A Vision LLM (like GPT-4o or Claude) looks at the surrounding text, understands it's a 'Quantity' field, and correctly identifies it as '5'.\n\nâ€‹Textract is definitely superior for bounding boxes (coordinates) and pure speed on massive datasets. But if your goal is extracting structured JSON from complex/messy documents where field logic matters more than pixel-perfect coordinates, Vision models are usually cheaper and more accurate in practice. We actually benchmarked this extensively for ParserData and found Vision models reduced 'logic errors' by nearly 40% compared to raw Textract output.",
          "score": 12,
          "created_utc": "2026-02-11 16:08:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4w9nxj",
              "author": "enjoytheshow",
              "text": "We feed our handwritten output from textract into Bedrock with a prompt explaining it to clean it up. We tried all combinations and that was most successful for us",
              "score": 3,
              "created_utc": "2026-02-12 00:11:15",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o4weqhg",
                  "author": "kievmozg",
                  "text": "That stack is definitely robust. We used it too for a while.\n\n\nâ€‹The only reason we switched to direct Vision models was to kill the 'double tax'. Paying for Textract pages plus Bedrock tokens adds up fast at scale. Going direct to Vision cut our latency and bill by about 40% since we skip the OCR step entirely.",
                  "score": 3,
                  "created_utc": "2026-02-12 00:40:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4tvk45",
          "author": "Ok-Data9207",
          "text": "Make an evaluation set and test both. \n\nIf Image is like some ID or bill, textract works really well because it is trained on really large set of such documents and they have different API calls for them.",
          "score": 3,
          "created_utc": "2026-02-11 17:08:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wkssy",
          "author": "Hydroshock",
          "text": "[This is not my blog](https://hidekazu-konishi.com/entry/amazon_bedrock_for_titling_commenting_ocr_with_claude3_haiku.html), but this guy did some testing using Claude Haiku. There are other blogs where people did similar.\n\nI've done some pretty extensive testing myself with using LLM (mainly Claude 3.7 generation) vs. Textract on scanned paper documents. The main problem I've had is essentially the LLM \"count to 100\" or \"how many r's are in strawberry\" problem.\n\nLLM would often give a slower and incomplete response, hitting token limits, hallucinating details or re-interpret some lines. I tried again more recently and the models flat out do a tool call to Tesseract.\n\nIt really depends what your use case is though and how accurate you need the OCR. If you have a good quality source image with high DPI and text is well aligned, you get a long way. Textract does give a confidence value on the interpreted text and at the end of the day, Textract is using AI/ML for it's engine, it's just not LLM.",
          "score": 2,
          "created_utc": "2026-02-12 01:17:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ttzgx",
          "author": "SpecialistMode3131",
          "text": "1. Integration - part of a huge platform with obvious integration advantages.\n\n2. Stabilized - GPT constantly changes.  Nobody (but you) is QC'ing result quality.  At any point model changes may blow up your entire approach and what then?\n\n3. Focused - its whole job is to extract text.  It'll get better at its one job over time.",
          "score": 2,
          "created_utc": "2026-02-11 17:01:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bw4bf",
              "author": "bot403",
              "text": "As a longtime textract user id say llms are getting better MUCH faster then textract. They've made some improvements over the years but we got better results switching to LLMs. I've only seen textract improve slowly or barely at all.\n\n\nDisclaimer, part of our results with LLMs though are the bit of analysis and business domain interpretation we want on the 100% correct OCR result. We can do it in 1 pass with a LLM vs scan+interpret with textract.",
              "score": 1,
              "created_utc": "2026-02-14 12:29:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5dvxex",
                  "author": "SpecialistMode3131",
                  "text": "Seems legit to me.  You've built a bespoke system to solve your business problem.  As long as it has good monitoring and QC, that sounds like exactly the right way to solve it.",
                  "score": 2,
                  "created_utc": "2026-02-14 19:05:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4w78e0",
          "author": "2BucChuck",
          "text": "The only thing keeping me there is handwriting on forms - claude4.5 was the first model I saw that could get tables and forms as well",
          "score": 1,
          "created_utc": "2026-02-11 23:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4wozui",
          "author": "hcsteve",
          "text": "We have a workflow that needs to extract text from unstructured documents and then do some processing and summarization. Weâ€™ve seen better accuracy by extracting with Textract first and then running through a multimodal model for processing, rather than just running raw docs through the model, especially for complex tabular data. It can be more expensive but the improved accuracy is worth it for us in this case.",
          "score": 1,
          "created_utc": "2026-02-12 01:43:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xgmrc",
          "author": "koinos_bios",
          "text": "Maybe checkout Bedrock Data Automation",
          "score": 1,
          "created_utc": "2026-02-12 04:38:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4xv1k3",
          "author": "Sadboy2403",
          "text": "textract is an ML model and GPT is generative AI, if you need to have accurate results go for tetract.",
          "score": 1,
          "created_utc": "2026-02-12 06:36:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o57gg0f",
          "author": "GeekLifer",
          "text": "If you need accurate OCR use textract. We used both and the problem with LLM is their vision is terrible. Lots of hallucinations",
          "score": 1,
          "created_utc": "2026-02-13 18:25:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o57q29a",
              "author": "nucleustt",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-13 19:11:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4ulcu8",
          "author": "Lendari",
          "text": "Textract existed before GPT models.",
          "score": 1,
          "created_utc": "2026-02-11 19:08:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qzzckx",
      "title": "(New here) Is each EC2 instance a part of a VPC?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "author": "itspiris",
      "created_utc": "2026-02-09 09:00:41",
      "score": 15,
      "num_comments": 22,
      "upvote_ratio": 0.86,
      "text": "hey guys. as the title shows, im new here. im taking a course from coursera on AWS to diversify my career as a software developer into the cloud and devops maybe.\n\nnot the point, i am reading about the route tables and VPCs and how to secure them. I just wanted to check if all EC2 instances are part of a VPC or not.",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1qzzckx/new_here_is_each_ec2_instance_a_part_of_a_vpc/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4emovt",
          "author": "Wide_Commission_1595",
          "text": "You can think of a VPC as a container for a network, and all of the things attached to that network!\n\nA VPC alone doesn't do anything, but you can create subnets, which require route tables.  You can create an Internet gateway to route to/from the internet, or endpoints (think network port) to give access to other services.\n\nInside the vpc you could put an EC2 instance, or RDS database etc.  if it has an IP address it's got an interface connected to your VPC.\n\nA thing in your VPC can also have a security group which is like a simple firewall which defines what traffic is allowed in or out.  This can reference an IP range, or another security group.\n\nBeyond that there are DHCP options, acls etc but honestly, they're way less important.  When you need them you'll know why and Google will be your friend ðŸ™‚\n\nOne slightly odd definition that is confusing to start with is public/private subnets.\n\nIn a public subnet you route 0.0.0.0/0 to the Internet gateway.  In a private subnet you don't!  That way resources in the private subnet cannot access or be accessed from the internet.  You can add a NAT gateway if you need outbound internet.  Ironically, because the NAT gateway needs Internet access it lives in the public subnet, but your private route tables have a default route to it.\n\nI hope that's helpful.  AWS networking is weirdly simple once you get used to it, but it can be very confusing initially ðŸ‘",
          "score": 20,
          "created_utc": "2026-02-09 09:17:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4eolnm",
              "author": "itspiris",
              "text": "thank you bro. it makes sense to have it as a rule, i just wanted to make sure i understood their infrastructure correctly.\ni am now a little confused between the \"network ACLs\" and \"security groups\", but im sure I'll get the hang of it ðŸ™‚. to me they feel like they're exactly the opposite, but it seems that acls have everything open, while security groups have everything closed until you open. don't they have conflicts with each other? we shall know soon enough",
              "score": 2,
              "created_utc": "2026-02-09 09:36:44",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4f3es1",
                  "author": "Get-ADUser",
                  "text": "> i am now a little confused between the \"network ACLs\" and \"security groups\"\n\nFrom my 3 and a half years as an AWS Support engineer, you're now a member of a large club ðŸ¤£. Think of Network ACLs as \"dumb\" rules that just work on IP address and port numbers, akin to `iptables` and they're applied on the subnet level.  Security Groups are smarter - instead of just IP ranges as sources/targets you can use rules like \"members of this security group\", \"members of another security group\", etc. and they're applied on the security group level (which can span several subnets).\n\nI'd strongly advise you use one or the other, never both if you can help it.  Using both together is just a recipe for confusion when traffic isn't working that you think should be because of interactions between the two.  The one you use should (nearly) always be security groups.  Only use network ACLs if you really know what you're doing and have a specific need.  They usually only come into play when you're doing fancier stuff like VPC peering or connecting your VPC back to your datacenter with a VPN.",
                  "score": 5,
                  "created_utc": "2026-02-09 11:53:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o4ny662",
                  "author": "Wide_Commission_1595",
                  "text": "In over a decade I've very rarely use ACLs tbh.  Security groups let you define traffic in one direction and the return traffic is automatically allowed, e.g you connect out to something and the return packets can come back in.\nACLs on the other hand are one way.\nIn the distant past you could use them a bit like a waf IP blocker, so your web server is allowing https from 0.0.0.0/0 but 1.2.3.4 is DoS'ing your site.  Block 1.2.3.4 inbound on the VPC and you're good!  It's free, but tbh I'd rather pay for WAF and it's more friendly API and automation ðŸ¤£",
                  "score": 2,
                  "created_utc": "2026-02-10 19:05:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4enm67",
          "author": "ohmer123",
          "text": "Nowadays, yes. There used to be something called classic link in the early days but it was retired.",
          "score": 7,
          "created_utc": "2026-02-09 09:26:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4jlaxe",
              "author": "metarx",
              "text": "You call it classic link, but it originally was the only way it worked.  It became classic link, after vpcs were a thing.",
              "score": 1,
              "created_utc": "2026-02-10 02:12:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4elv5w",
          "author": "SnoopJohn",
          "text": "They are as much as any computer(ec2) connected to a network(vpc) is.\nYou can't launch an ec2 without or outside a vpc.",
          "score": 3,
          "created_utc": "2026-02-09 09:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4f3n0w",
          "author": "omerhaim",
          "text": "EC2 launched only in VPC\n\nIn the past there was classic that were not a part of a VPC, but itâ€™s not an option anymore",
          "score": 3,
          "created_utc": "2026-02-09 11:55:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4elobg",
          "author": "conairee",
          "text": "EC2 instances run *inside* a VPC, they get an IP address from the VPC CIDR block.\n\nImagine if you and your friends are gaming on a LAN, the VPC is like the LAN and your computers are the EC2 instances.",
          "score": 2,
          "created_utc": "2026-02-09 09:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4els1m",
          "author": "swiebertjee",
          "text": "I believe that by default, EC2 instances are part of the default VPC in each region. You can or course create a new/custom VPC and connect them to it.\n\nGood luck on your cloud adventure!",
          "score": 1,
          "created_utc": "2026-02-09 09:08:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4emta3",
          "author": "Old_Cry1308",
          "text": "yep, every ec2 instance is in a vpc. it's how aws does networking, whether you like it or not.",
          "score": 1,
          "created_utc": "2026-02-09 09:18:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4en23t",
          "author": "undernocircumstance",
          "text": "Yes, this is required now.",
          "score": 1,
          "created_utc": "2026-02-09 09:21:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4enysl",
          "author": "cloudnavig8r",
          "text": "U/Wide_Commission_1595 made the distinction!  EC2 instances need a network address.  That address is part of a subnet, which is part of a VPC.  So indirectly, *yes*\n\nThe truth is, the Subnet is a range of addresses within the VPC.  And, a subnet is associated with a physical Availability Zone.  (The VPC is an address range across the whole region).\n\nSo, an EC2 instance is on a physical server that is inside an Availability Zone.  It will have an address associated to that AZ (subnet).  \n\nEach subnet can have its own route table as well.  By default the VPC level traffic is â€œlocalâ€ between all subnets.",
          "score": 1,
          "created_utc": "2026-02-09 09:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4har35",
          "author": "Important_Winner_477",
          "text": "Essentially, yes if you started your AWS journey anytime in the last decade, every EC2 instance you launch is sitting inside a VPC. There used to be an \"EC2-Classic\" mode where instances sat on a shared flat network, but AWS killed that off years ago. I run a cloud + AI pentesting firm and I have learn to find ancient \"ghost\" instances in legacy accounts, but for a new developer, the VPC is your non-negotiable boundary",
          "score": 1,
          "created_utc": "2026-02-09 18:57:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4fjvp",
      "title": "GuardDuty found outgoing SSH Bruteforce attack - what now?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "author": "Xtrearer",
      "created_utc": "2026-02-14 08:36:19",
      "score": 15,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "GuardDuty identified outbound traffic that matches SSH brute force attack patterns. \n\nThe traffic originated from one of our Windows Server 2022 instances. The instance is in a private subnet (not visible to the public internet), so no public IP, and has a SG that only allows inbound traffic on ICMP(ping) and RDP,  both of which is restricted to our AWS VPN Client SG. All outbound traffic is currently allowed.\n\nThe outgoing \"attack\" originated from random local ports - 50242 ans 60664 - and targeted what looks like Amazon Public IPs: 15.197.199.235(Washington) and 99.83.130.128(Seattle)  on remote port 22 (SSH)\n\nThe machine was switched off by support, pending investigation. Ive checked the events, services and netstat, but could not find any trace of it. \n\nIve tried Googling this behavior, without any luck. Any ideas?\n\nAt this point I will be rebuilding a new server just to be safe.\n\n[Solved]",
      "is_original_content": false,
      "link_flair_text": "security",
      "permalink": "https://reddit.com/r/aws/comments/1r4fjvp/guardduty_found_outgoing_ssh_bruteforce_attack/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5bh0gs",
          "author": "Xtrearer",
          "text": "Source has been found. Misconfigured internal sftp interface. Occams razor - if no body can get in, it must be your own fault. \n\nThe AWS IPs were linked to a Global Accelerator that fronts our File Transfer Server. This exists in another account which made it difficult to track.\n\nWe were almoat DDOS'd a while back so immediatly assumed bad actors... so yay I guess.",
          "score": 36,
          "created_utc": "2026-02-14 10:11:27",
          "is_submitter": true,
          "replies": [
            {
              "id": "o5c1371",
              "author": "SheriffRoscoe",
              "text": "Thank you, [DenverCoder9](https://xkcd.com/979/).",
              "score": 11,
              "created_utc": "2026-02-14 13:06:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ck44k",
                  "author": "creamersrealm",
                  "text": "Lol thank you for the reference.",
                  "score": 5,
                  "created_utc": "2026-02-14 15:02:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5baitc",
          "author": "morimando",
          "text": "Isolate the instance and restore from an known good image. Keep isolation ideally until youâ€™ve verified that clients with access to the server are clean. Review access permissions and user actions. Likely something has laterally moved from your network into the server and potentially has persistence on your network. Ensure endpoint protection is running on all devices and do offline scans of the data layer where possible to find potential root kits.",
          "score": 11,
          "created_utc": "2026-02-14 09:07:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5bh8o6",
              "author": "Xtrearer",
              "text": "Yeah this was exactly my playbook which lead to the \"culprit\".",
              "score": 1,
              "created_utc": "2026-02-14 10:13:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5bhmyo",
                  "author": "morimando",
                  "text": "The potentially dangerous bit is if someone had put in a backdoor / remote shell of some sort longer ago that evades detection and made it into backups. \n\nDo you have Guard Duty EC2 Protection on that server? Also in case you happen to be on Enterprise Support, look into enabling Security Incident Response service",
                  "score": 4,
                  "created_utc": "2026-02-14 10:17:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5b8bi3",
          "author": "theculture",
          "text": "I would be considering that whatever is on the other side of that VPN is either compromised or a bad actor.",
          "score": 3,
          "created_utc": "2026-02-14 08:45:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5be5fo",
          "author": "ChiefOtacon",
          "text": "This one feels like a Security Speciality Certification question :D\n\nMost likely something on the other end of your VPN is compromised and moved on to Your instance",
          "score": 2,
          "created_utc": "2026-02-14 09:43:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5b8svk",
          "author": "dghah",
          "text": "Treat as breach and activate your incident response plan. Rebuilding the windows server is correct. Maybe turn on VPC flow logs if not on already.  \n\nFeels like either a RDP user did something dodgy while connected or something installed on windows server got compromised.\n\nSince AWS had to tell you that you got popped consider this a sign that you may not have good visibility elsewhere in your IT landscape â€” maybe your VPN service credentials or a user device that use VPN is compromised or RATâ€™ed",
          "score": 1,
          "created_utc": "2026-02-14 08:50:16",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1y6ri",
      "title": "I built a Python DynamoDB ORM with real async - Rust + Tokio under the hood, GIL released",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "author": "leandro_damascena",
      "created_utc": "2026-02-11 14:02:22",
      "score": 13,
      "num_comments": 13,
      "upvote_ratio": 0.68,
      "text": "Hey r/aws,\n\nI've been working on an open source DynamoDB library called **pydynox**. It's a Python ORM but the heavy lifting happens in Rust via PyO3.\n\nWanted to share how I handle async because I think it's interesting.\n\n## The problem with most Python DynamoDB libraries\n\nThey either do sync-only, or they wrap sync calls with `asyncio.to_thread()`. That's not real async. You're still blocking a thread somewhere.\n\n## What I do instead\n\nThe Rust core uses Tokio (Rust's async runtime) to talk to DynamoDB. When you call an async method from Python, it goes like this:\n\n1. Python `await`s the call\n2. PyO3 hands it to Tokio on the Rust side\n3. Tokio makes the HTTP request without holding the GIL\n4. Result comes back to Python\n\nThe GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\n## Why this matters\n\nThis helps in any Python app â€” Lambda, ECS, FastAPI, Django, scripts, whatever.\n\n- Serialization/deserialization happens in Rust â€” type conversion is fast\n- Compression (zstd) and encryption (AES-GCM) also run in Rust with the GIL released\n- Zero Python runtime dependencies, so installs are small and there are no conflicts\n- On Lambda specifically, cold starts stay lean and warm invocations hit the Rust fast path\n\n## Quick example\n\n```python\nimport asyncio\nfrom pydynox import Model, ModelConfig, DynamoDBClient\n\nclient = DynamoDBClient()\n\nclass User(Model):\n    model_config = ModelConfig(table=\"users\")\n    pk: str\n    name: str\n    email: str\n\nasync def main():\n    user = User(pk=\"USER#1\", name=\"John\", email=\"john@example.com\")\n    await user.save()\n\n    found = await User.get(pk=\"USER#1\")\n    print(found.name)\n\nasyncio.run(main())\n```\n\nSync works too â€” same API, just drop the `await`.\n\n## Performance\n\nSerialization alone is faster because Rust handles the Python-to-DynamoDB type conversion directly instead of going through multiple dict transformations.\n\nThe library is Apache 2.0 and on GitHub.\n\nDocs: [https://ferrumio.github.io/pydynox/](https://ferrumio.github.io/pydynox/)\n\nIf you've tried mixing Rust and Python for AWS stuff, I'd love to hear how it went. Questions are welcome too.\n",
      "is_original_content": false,
      "link_flair_text": "article",
      "permalink": "https://reddit.com/r/aws/comments/1r1y6ri/i_built_a_python_dynamodb_orm_with_real_async/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4tabjj",
          "author": "ElectricSpice",
          "text": "> The GIL is released during the entire network call. Your other Python coroutines keep running. No threads wasted sitting idle waiting for DynamoDB to respond.\n\nPython doesnâ€™t lock up waiting for the network, that would be ridiculous. Other threads will happily run while waiting on the HTTP response.\n\nThe other reasons are more compelling:  boto3 is a humongous dependency and its serde is quite slow.",
          "score": 23,
          "created_utc": "2026-02-11 15:29:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4ulcyq",
          "author": "idkbm10",
          "text": "Is there something like this for nodejs?",
          "score": 2,
          "created_utc": "2026-02-11 19:08:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4sxa6c",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-02-11 14:22:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t04kx",
              "author": "Turbulent-Log5758",
              "text": "This comment looks more of an AI slop than the library.",
              "score": 13,
              "created_utc": "2026-02-11 14:37:44",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4sxnzw",
          "author": "Spoonyyy",
          "text": "Ayo this sounds awesome. Will check it out.",
          "score": 2,
          "created_utc": "2026-02-11 14:24:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4tdtlf",
          "author": "AdPhysical9992",
          "text": "There is one module called pynamodb , that does the same thing i guess",
          "score": 2,
          "created_utc": "2026-02-11 15:45:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4vjn14",
              "author": "KainMassadin",
              "text": "comparing this to pynamo isnt fair for pynamo, lol",
              "score": 8,
              "created_utc": "2026-02-11 21:53:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o4tfu9n",
          "author": "mylasttry96",
          "text": "Can this be installed in lambda environments ?",
          "score": 2,
          "created_utc": "2026-02-11 15:55:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o52gubg",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2026-02-12 23:02:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4k17f",
      "title": "How are you managing Bedrock?",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "author": "jmreicha",
      "created_utc": "2026-02-14 12:59:48",
      "score": 13,
      "num_comments": 32,
      "upvote_ratio": 0.88,
      "text": "Looking for perspective on how teams are managing their Bedrock architectures and trying to get a handle on some things. Some questions I have:\n\n\\- How are you managing cost and cost attribution?\n\n\\- Are teams centralizing Bedrock infrastructure and model management? Or deploying models in each account?\n\n\\- How are folks managing security? What kinds of governance and guardrails are being put in place?\n\n\\- What about AgentCore? How is that being managed?\n\n\\- What is everyone using to manage changes? Terraform? Something else? Terraform support seems to be lacking.",
      "is_original_content": false,
      "link_flair_text": "architecture",
      "permalink": "https://reddit.com/r/aws/comments/1r4k17f/how_are_you_managing_bedrock/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o5c7m6h",
          "author": "2BucChuck",
          "text": "Built an API on the front of it in ECS and Lambda  to limit each user based on tokens which can be increased as needed.   In that an Admin can manage users and bots leveraging bedrock and while at it just made it an AWS MCP.  didnâ€™t want to give bots any direct access to AWS IAM roles so tokens and JWT gateway seemed better to tamp down runaway usage since its early days until we could see how much costs and usage were coming from different places and users and tools",
          "score": 18,
          "created_utc": "2026-02-14 13:49:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5dmhnw",
              "author": "aboothe726",
              "text": "I really like that approach. I've done something similar to give internal users access to vendor APIs while controlling for and tracking usage and without having to share the actual credentials for the vendor APIs. Worked really well.",
              "score": 3,
              "created_utc": "2026-02-14 18:18:18",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5cqkr2",
              "author": "2BucChuck",
              "text": "DM me I can share the setup we have but would call is an Alpha release",
              "score": 2,
              "created_utc": "2026-02-14 15:37:21",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5eb4oy",
              "author": "weirdbrags",
              "text": "did you look at litellm?",
              "score": 1,
              "created_utc": "2026-02-14 20:25:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ec3yu",
                  "author": "2BucChuck",
                  "text": "Interesting but no , we have to maintain lots of PII and SOC2 and this whole AI area has too many moving parts for us at the moment.  Itâ€™s the same idea though I see",
                  "score": 1,
                  "created_utc": "2026-02-14 20:31:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5c1h2w",
          "author": "FarkCookies",
          "text": "I could not figure out how to do cost attribution except for having acc per team/env. ",
          "score": 8,
          "created_utc": "2026-02-14 13:09:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5cre3l",
              "author": "pixeladdie",
              "text": "I havenâ€™t had to test this yet but does [application inference profiles](https://aws.amazon.com/blogs/machine-learning/manage-multi-tenant-amazon-bedrock-costs-using-application-inference-profiles/) do what you need?",
              "score": 5,
              "created_utc": "2026-02-14 15:41:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5czrfp",
                  "author": "iwearhaines",
                  "text": "This is what we use. SCP to deny any model invocation that didn't go through an AIP, with each AIP tagged to the owning team",
                  "score": 3,
                  "created_utc": "2026-02-14 16:24:15",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5enple",
                  "author": "FarkCookies",
                  "text": "Wow thanks had no idea",
                  "score": 2,
                  "created_utc": "2026-02-14 21:34:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cd9ky",
          "author": "weirdbrags",
          "text": "question of the year.",
          "score": 4,
          "created_utc": "2026-02-14 14:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5cos8z",
          "author": "Lba5s",
          "text": "you donâ€™t",
          "score": 5,
          "created_utc": "2026-02-14 15:28:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5dwsy7",
          "author": "CoopertheFluffy",
          "text": "Everyone always asks \"how are you managing bedrock?\" but nobody ever asks \"how are you managing, bedrock?\"",
          "score": 6,
          "created_utc": "2026-02-14 19:09:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5ep3da",
          "author": "jojolejobar",
          "text": "We use litellm \nEach user has a key with a budget\nWorks with Claude, open code, openwebui..",
          "score": 2,
          "created_utc": "2026-02-14 21:41:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5c1oqv",
          "author": "AWSSupport",
          "text": "Hi there. I've forwarded your feedback to our Bedrock team for further review.\n\n\\- Roman Z.",
          "score": 3,
          "created_utc": "2026-02-14 13:10:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5crb89",
              "author": "2BucChuck",
              "text": "Ha you might regret posting here but also please fix the pricing on OpenSearch - itâ€™s outrageous.  We setup one knowledge agent and bill went through the roof.  Itâ€™s not even clear how to undo it since it gets assigned in background.  That said appreciate how fast this was scaled up and the model ecosystem !",
              "score": 4,
              "created_utc": "2026-02-14 15:41:10",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5ficlk",
                  "author": "weirdbrags",
                  "text": "s3 vectors?",
                  "score": 1,
                  "created_utc": "2026-02-15 00:34:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5cegjm",
              "author": "japanthrowaway",
              "text": "Hey while you're at it can you tell the team to maintain their bedrock access gateway a bit better? Bedrock doesn't have a native openai api endpoint so we have to use BAG which doesn't even support all the native models on bedrock itself. Insane how AWS preaches being AI forward but they ignore this piece of critical infra.",
              "score": 2,
              "created_utc": "2026-02-14 14:30:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5cqpon",
                  "author": "Maxious",
                  "text": "https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-mantle.html\n\n\nÂ is this not an openai API endpointÂ ",
                  "score": 3,
                  "created_utc": "2026-02-14 15:38:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5cy8le",
          "author": "Nearby-Tomato9925",
          "text": "Individual Inference profiles with tags and then those tags enabled for AWS Budgets. Is it amazing? No. But at least it is something.",
          "score": 1,
          "created_utc": "2026-02-14 16:16:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5faimo",
              "author": "jmreicha",
              "text": "How many profiles are you managing? I can get behind doing that part with Terraform if it doesn't become a huge number.",
              "score": 1,
              "created_utc": "2026-02-14 23:46:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5d7hs1",
          "author": "VladyPoopin",
          "text": "Application inference profiles for cost attribution to a specific pipeline. Getting more granular can be problematic, but it works.",
          "score": 1,
          "created_utc": "2026-02-14 17:02:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5d927u",
          "author": "egoslicer",
          "text": "We use okta, so I built a cost attribution tool by login and token usage. From there, created a leaderboard so we can track usage.",
          "score": 1,
          "created_utc": "2026-02-14 17:10:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5el0dp",
          "author": "ShakataGaNai",
          "text": "Currently experimenting with [LiteLLM Proxy.](https://docs.litellm.ai/docs/simple_proxy) Conceptually it's perfect for the use case. As it has separate auth, admin API's, cost attribution, etc. However, it doesn't work for things like Claude Code (TBD on OpenCode, haven't tried it yet). \n\nBut, I'd really love something first party from Amazon. Having the ability to track token usage per API key or IAM role would be vastly superior than proxying every request with another tool.",
          "score": 1,
          "created_utc": "2026-02-14 21:19:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eqiym",
              "author": "Nick4753",
              "text": "LiteLLM is called out specifically in Claude Code's documentation https://code.claude.com/docs/en/llm-gateway#litellm-configuration\n\nLiteLLM is really underselling itself. You can use it as a gateway for just about any purpose, beyond just engineer access for coding.",
              "score": 1,
              "created_utc": "2026-02-14 21:49:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fzusw",
                  "author": "ShakataGaNai",
                  "text": "It is called out and thats why I tried it, but that doesn't mean it works well. Anthropic is rolling out features that break when running against things like LiteLLM. So it might work for a while, then might break at random. I was having issues with a new beta flag, which you can \"turn off\" in CC....except [it doesn't actually obey the setting](https://github.com/anthropics/claude-code/issues/21676).\n\nAnd the passthrough endpoints on LiteLLM are... meh. There are a bunch of limitations like they don't have good of an idea of the tokens used. They also can't stop usage for a specific key that's over allocation. Also it was, for me, logging hundreds of lines of ... errors(?)... when claude code was working against LiteLLM (and it was in fact working through LiteLLM to Bedrock).\n\nSo yes, it's possible. But if I were someone wanting to use something to control usage for Claude Code for an entire company... I wouldn't rely on that setup. Which is a shame because thats exactly who I am and what I wanted to do.\n\nIf someone has Bedrock/LiteLLM/ClaudeCode setup and working entirely correctly, without kneecapping yourself and losing out on major features, please tell me your config.",
                  "score": 1,
                  "created_utc": "2026-02-15 02:30:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5fdm0r",
              "author": "jmreicha",
              "text": "How does that approach work with inference profiles? Have you found much of the AgentCore tools to have similar functionality to litellm?",
              "score": 1,
              "created_utc": "2026-02-15 00:05:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5f3cm1",
          "author": "donkanator",
          "text": "AWS best practices say to segregate workloads into their own accounts. From there, you don't have to worry about teams stepping on each other's toes if they maintain separate applications. If they are fine being under the same account then whoever fits the bill should be fine to pay for them all.\n\nAt the end of the day, any AI application or system is going to have a normal system architecture first and then some API calls. Chances are, containers or storage or support engineers are going to be much more expensive than a few AI calls. \n\nWe use scp and guardrails to ensure that people use only the models we are comfortable with and invokemodel permissions contain a guardrail condition. \n\nAgentcore is still in the pipeline but I'm struggling with the concept of customers being able to call public cloud apis directly (with a role or IDP token). Normally we expect to have some kind of ingress like application load balancer or cloudfront, but agent core pretty much welcomes anyone to call your API which can be a problem with legal and trade. (Honestly, why do we have to go through this all over again)",
          "score": 1,
          "created_utc": "2026-02-14 23:02:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r3ytpa",
      "title": "Amazon RDS now supports backup configuration when restoring snapshots",
      "subreddit": "aws",
      "url": "https://aws.amazon.com/about-aws/whats-new/2026/02/rds-aurora-backup-configuration-restoring-snapshots/",
      "author": "risae",
      "created_utc": "2026-02-13 19:36:37",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "general aws",
      "permalink": "https://reddit.com/r/aws/comments/1r3ytpa/amazon_rds_now_supports_backup_configuration_when/",
      "domain": "aws.amazon.com",
      "is_self": false,
      "comments": [
        {
          "id": "o5bubfs",
          "author": "bot403",
          "text": "What's the big deal with just setting it up after it's started? I get this is a nice change but OP implies it fixes some larger issue.",
          "score": 1,
          "created_utc": "2026-02-14 12:14:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5e4t24",
              "author": "risae",
              "text": "It doesn't make sense that you can specify certain things, but not thisÂ ",
              "score": 1,
              "created_utc": "2026-02-14 19:51:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r324m8",
      "title": "AWS Cognito Experience",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "author": "True_Context_6852",
      "created_utc": "2026-02-12 18:59:57",
      "score": 7,
      "num_comments": 23,
      "upvote_ratio": 0.77,
      "text": "Hello  Good People ,\n\nOur org are planning to  migrate the our legacy app sign up process to  AWS Cognito . So  plan is First start the JIT with lambda for new sign up  and later  second step to  migrate all  user to  Cognito and forced reset password . final steps  when all looks fine than enable MFA to all  users . My question is AWS Cognito  right step or should we look other options  like okta or OAuth ? What you people have experienced during migration  ? What other area we need to look so existing user not lost the credentials?  \n\n ",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r324m8/aws_cognito_experience/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o518j8p",
          "author": "MuffinMan_Jr",
          "text": "Im using cognito right now for my app, and the developer experience is terrible lol\n\nThat being said, you'd get lots of free MAU so I guess that's cool",
          "score": 30,
          "created_utc": "2026-02-12 19:26:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o51xs9v",
              "author": "True_Context_6852",
              "text": "May I know what is terrible please ?",
              "score": 1,
              "created_utc": "2026-02-12 21:27:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o516zjd",
          "author": "Whend6796",
          "text": "Look elsewhere. \n\n- The documentation is notoriously confusing and poorly organized\n- The service has layers of abstraction that make simple tasks complicated\nAPI Design Issues\n- Inconsistent and unintuitive naming conventions\n- Methods that donâ€™t follow AWS naming patterns used elsewhere\n- Confusing parameter requirements and error messages\n- The SDK can be clunky to work with\nLimited Flexibility\n- User migration from existing systems is painful\n- Customization options for authentication flows are restrictive\n- The hosted UI is difficult to customize and looks dated\n- Hard to implement certain common auth patterns\nToken Management Problems\n- Token refresh flows can be confusing\n- Limited control over token lifetimes and claims\n- Issues with token validation in certain scenarios\nDeveloper Experience\n- Simple tasks often require digging through documentation and Stack Overflow\n- Error messages that donâ€™t clearly explain what went wrong\n- Testing authentication flows locally is cumbersome",
          "score": 42,
          "created_utc": "2026-02-12 19:19:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o568zic",
              "author": "methods2121",
              "text": "Props to this correct and succinct overview.   This would be valuable across almost every AWS service to separate the 'hype' vs. reality.  I second that Cognito would be very low on my list based on your requirements above and you should definitely look and preferably test others.",
              "score": 2,
              "created_utc": "2026-02-13 14:56:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o517lty",
          "author": "Wide_Commission_1595",
          "text": "I am usually in the \"AWS all the things\" camp, but Cognito is a tricky one.\n\nCognito _can_ be great for simple sign up flows.  It can even be pretty good with complex federations.  It's also damned cheap compared with other IdPs, but....\n\nThere's a ton of wiring Lambda functions into hooks to make it work the way most people want it to.  If you don't need those things, go with Cognito every day of the week.\n\nIf you want something a little more \"managed\" that just works, I have found external identity providers to be a lot simpler to use.\n\nWe use Okta, but basically any OIDC or SAML IdP (that's all of them!) works well.\n\nYou can even assume roles with web identity etc to do external-IdP-to-AWS role assumption.\n\nGenerally speaking, an external IdP will be simpler, but more expensive, especially as user numbers grow.  Cognito requires more plumbing, but is AWS-native.",
          "score": 13,
          "created_utc": "2026-02-12 19:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o530s9s",
          "author": "MrStu56",
          "text": "It's horrible to work with, but when it's up and running it's cheap and reliable. If I had one 2026 AWS wish it would be for AWS to give this service the once over, take a look how people are using it now vs what was envisioned and then re-document it like their other services. This has to be the most opaque service I've ever worked with on AWS. ",
          "score": 7,
          "created_utc": "2026-02-13 00:56:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o518nbb",
          "author": "BadDescriptions",
          "text": "If you have good engineers then use Cognito. If you have bad engineers and loads of money then use okta/auth0",
          "score": 8,
          "created_utc": "2026-02-12 19:27:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o53c1ll",
              "author": "BoostedHemi73",
              "text": "This is the most concise advice Iâ€™ve seen on this topic.\n\nCognito is full of footguns. Test carefully and completely. If you are using CloudFormation, pay very careful attention to the defaults that are applied (like case sensitive email).\n\nBut the price is great for low/moderate MAU.",
              "score": 3,
              "created_utc": "2026-02-13 02:05:17",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o53t8s3",
              "author": "VladyPoopin",
              "text": "This. If you have a solid engineer who ca actually wrap their head around how it works and utilize your own UI over the hosted UI, itâ€™ll work well for you.\n\nThat being said, thatâ€™s a hurdle for sure.",
              "score": 1,
              "created_utc": "2026-02-13 03:53:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o51qwzb",
          "author": "macgoober",
          "text": "Cognito is dirt cheap if your MAU is less than 50k. The dev experience without something like sst.dev is a total nightmare tho.",
          "score": 2,
          "created_utc": "2026-02-12 20:54:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o535f4b",
          "author": "texxelate",
          "text": "Donâ€™t use Cognito if you have any choice whatsoever. Youâ€™ll have another legacy app sign up process from day 1.",
          "score": 2,
          "created_utc": "2026-02-13 01:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o59i8t6",
          "author": "Howlla_",
          "text": "The good thing about authentication flows is that you shouldn't be changing that code frequently. It should be thoroughly tested and deployed in a production environment and cognito is the cheapest option.\nIf you need simpler stepup or plan on making many complex requirements then other ISV solutions like okta are amazing.",
          "score": 2,
          "created_utc": "2026-02-14 00:52:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o513pvk",
          "author": "SoggyGrayDuck",
          "text": "Maybe you can clear something up for me. We had a handful of our data engineers converted to BI engineers but they work with cognito? That's confusing to me",
          "score": 1,
          "created_utc": "2026-02-12 19:03:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o516srq",
              "author": "True_Context_6852",
              "text": "I am talking about B2C customer migration as current sign up  process involved with SQL DB where user save credential  and later sign in with  same credentials . Now we want to  migrate all  sues to AWS Cognito  .The ask is what  is over all  experience if any body  did it like our org are on retail end .  ",
              "score": 1,
              "created_utc": "2026-02-12 19:18:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o519g3k",
          "author": "Alternative-Expert-7",
          "text": "Cognito is cheaper comparing to AuthO or Okta. Or the cheapest if you have big number of users.",
          "score": 1,
          "created_utc": "2026-02-12 19:30:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5234rn",
          "author": "Prestigious_Pace2782",
          "text": "The dev experience is pretty poor, but itâ€™s nice to have it all in CDK and itâ€™s cheap and mostly just works once itâ€™s set up. \n\nI normally start a new project with cognito and use it until it becomes painful or doesnâ€™t support something I need. Sometimes that doesnâ€™t happen and itâ€™s fine.\n\nHave used it at work in some pretty big stuff and had to get pretty in the weeds with apig caching and stuff.\n\nTLDR; Itâ€™s cheap and works well but is feature poor and a bit painful to learn.",
          "score": 1,
          "created_utc": "2026-02-12 21:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o52fy4b",
              "author": "True_Context_6852",
              "text": "Did you face real challenge with real customer during migration",
              "score": 1,
              "created_utc": "2026-02-12 22:57:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o52vbqj",
          "author": "mouthbuster",
          "text": "Cognito is pain\nOkta/Auth0/Clerky will all get the job done the easiest at the highest cost\n\nCheck out Keycloak if you have the engineering bandwidth - it can do anything youâ€™d ever want for the sweet cost of hosting it. Can meet any regulatory compliance need Iâ€™ve ever ran into, and you can host this thing anywhere.",
          "score": 1,
          "created_utc": "2026-02-13 00:24:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o53fgwe",
          "author": "cuddle-bubbles",
          "text": "horrible but great for your resume. if ur the engineering manager and dont have to do it yourself. may be a good idea to let your developers suffer while you add a great bullet point to your resume at the end of it",
          "score": 1,
          "created_utc": "2026-02-13 02:26:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o54fnpk",
          "author": "hungrysandiegan",
          "text": "If you can leverage the Managed Login, Cognito works great and is cheap! Lots of companies canâ€™t go the managed login route and have to use custom UI where its a pain!",
          "score": 1,
          "created_utc": "2026-02-13 06:43:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o58g9mu",
          "author": "Past-Owl-3180",
          "text": "Won't recommend Cognito for even simpler use-cases. AWS has screwed up evolution of this, once great product.",
          "score": 1,
          "created_utc": "2026-02-13 21:22:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5963yt",
          "author": "GuavaRevolutionary56",
          "text": "Go with Okta or Ping. So much to bolt on for AWS Cognito.",
          "score": 1,
          "created_utc": "2026-02-13 23:39:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o55a1xy",
          "author": "bajcmartinez",
          "text": "Cognito is just one more service into the hundreds of AWS services and doesn't seem like an important one based on its evolution, documentation and overall DX.\n\nI wouldn't recommend building your own auth, but you can choose from services like Auth0 for easy setup, good docs and DX, though depending on the number of users and features required you can go with a free plan or one of the plans. Alternatively, open-source solutions like Keycloak are pretty good, though that's again, more engineering work required for set up and maintenance.",
          "score": 0,
          "created_utc": "2026-02-13 11:22:46",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r1d9ra",
      "title": "AWS Marketplace KYC",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1d9ra/aws_marketplace_kyc/",
      "author": "olearyboy",
      "created_utc": "2026-02-10 21:09:06",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Filled out all the forms, got preliminary approval then started the KYC. \n\nUploaded back statements, certificate of validity, passport, internet bill for address verification. \n\nAnd then got rejected\n\n\\- Passport not signed (ehhh yeah biometric passports aren't signed, haven't been since \\~2008) \n\n\\- Something about valid business docs, it requested a certificate of validity - i provided a cert of validity, had to go pay for the damn thing. \n\n  \nThe help pages go to 404's \n\nThere's not enough places to upload more supporting doc, replaced passport with drivers license front & back.\n\n  \nI can already tell they're still not requesting the correct documents like those required for say I-9 (even though I'm not getting work, it's the fastest validation for the US) \n\nFor some unknown reason they're processing all of the details in the EU?? I've verified that I'm on the US portal, and that's it's recognized I'm registering a US business  \n\n\nSupport doesn't seem to be available, and I am at a loss as to what to do next",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r1d9ra/aws_marketplace_kyc/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4spva1",
          "author": "AWSSupport",
          "text": "Hi there, \n\nI'm sorry to hear about the trouble you're having with registering for AWS Marketplace. You can contact our Support team by filling out the following form: \n\nhttp://go.aws/contact-us-marketplace.\n\nIf you already have a case open with them, you can chat message us the case ID, and we'll assist you further.\n\n\\- Craig M.",
          "score": 1,
          "created_utc": "2026-02-11 13:41:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4voj8a",
              "author": "olearyboy",
              "text": "Contact form filled out thanks for the outreach ",
              "score": 1,
              "created_utc": "2026-02-11 22:16:57",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4vpx1r",
                  "author": "AWSSupport",
                  "text": "Hi there, \n\nWe're glad we could help with this!\n\n\\- Gee J.",
                  "score": 1,
                  "created_utc": "2026-02-11 22:23:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r1u1hx",
      "title": "Insert my cert to Traefik in ECS via Terraform/Secrets Manager",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "author": "Budget-Industry-3125",
      "created_utc": "2026-02-11 10:39:43",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "Hi,\n\nI need to create a configuration where I implement a NLB for a TLS passthrough towards my Traefik container within the cluster.\n\nThe traefik container needs to serve my own certificate, and i don't know how to import it. \n\nI tried to use secrets manager, but I don't know how to implement it. is there any other way? ",
      "is_original_content": false,
      "link_flair_text": "containers",
      "permalink": "https://reddit.com/r/aws/comments/1r1u1hx/insert_my_cert_to_traefik_in_ecs_via/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4sclg0",
          "author": "Living_off_coffee",
          "text": "Have you tried AWS Certificate Manager (ACM)? It's designed for things like this.\n\nBut is there a specific reason you want to have TLS pass through with the NLB? You can terminate it at the load balancer instead which might be easier.",
          "score": 6,
          "created_utc": "2026-02-11 12:18:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4siyfo",
          "author": "KayeYess",
          "text": "What was the challenge with pulling the certificate keys from Secrets Manager? It's just like pulling any other secret.\n\n\nYou could also pull your certs from S3, SSM or ACM (which now allows private keys to be exported).",
          "score": 2,
          "created_utc": "2026-02-11 13:01:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t7avu",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.  \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o4tbmbm",
                  "author": "KayeYess",
                  "text": "OK. The certs are in secrets manager.\n\n\ntraefik itself is not capable of accessing aws secrets but a separate script (like cert-manager) can be used to sync them to kube secrets, which trafiek can refer to.",
                  "score": 2,
                  "created_utc": "2026-02-11 15:35:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o4skir6",
          "author": "safeinitdotcom",
          "text": "Hi,\n\nWhat exactly failed for you in implementing secrets manager for this? Typically you should've been able to inject the secrets to ecs and then write them to files during startup :D ",
          "score": 2,
          "created_utc": "2026-02-11 13:10:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4t79ds",
              "author": "Budget-Industry-3125",
              "text": "not ACM, i tried but wasnt capable. i don't seem to be able to define crrectly the terraform snipet for the TRAEFIK task, and it fails when deploying that container.   \n  \nis it wrong? how should i define the task so that it implements my secrets manager certificate and key?",
              "score": 1,
              "created_utc": "2026-02-11 15:14:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r06jkd",
      "title": "Verification loop - \"documents not required\" then reverify 2 days later",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "author": "teasingcupcakeLuv",
      "created_utc": "2026-02-09 15:04:52",
      "score": 7,
      "num_comments": 6,
      "upvote_ratio": 0.68,
      "text": "Went through AWS verification. Submitted docs multiple times because support kept asking for the same stuff repeatedly.\n\nFeb 7 - Two emails same day. One says hold removed. Another says \"we no longer require verification documents, disregard the request.\"\n\nFeb 9 - New email. Account on hold for verification again. Need to submit docs by Feb 14 or suspension.\n\nThey just told me documents weren't required 48 hours ago. Now I'm back at square one with a deadline.\n\nSupport has been completely useless. Generic responses, no actual help. Given the recent layoffs and AI support rollout, I'm guessing this is just automated systems conflicting with each other while there's nobody left to actually fix it.\n\nAnyone successfully escaped one of these verification loops? Or is this just the new normal with AWS running everything through automation now?",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r06jkd/verification_loop_documents_not_required_then/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4g8sx6",
          "author": "AWS_Chaos",
          "text": "If recent posts have taught us anything, back all your stuff up OUTSIDE of this account if it is production! :)",
          "score": 6,
          "created_utc": "2026-02-09 15:57:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g0c6y",
          "author": "AWSSupport",
          "text": "Hi there, \n\nSorry to hear about your account verification issue. \n\nWe're unable to discuss account-specific info here, but you can send us a private chat with your case ID and we'll check from our end that the case has been routed correctly. \n\n\\- Reece W.",
          "score": -1,
          "created_utc": "2026-02-09 15:16:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o4g8xwv",
          "author": "AWSSupport",
          "text": "Thanks for the info. \n\nAs explained, we're unable to discuss account-specific info here, but I reviewed your Support case and I see that our team have provided the final decision. We're unable to influence the outcome or discuss the matter further here as well.  \n\nApologies if the outcome was unfavorable.\n\n\\- Reece W.",
          "score": -2,
          "created_utc": "2026-02-09 15:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4glqsl",
              "author": "teasingcupcakeLuv",
              "text": "Reece, you need to actually look at what happened.\n\nMy account was REINSTATED on February 7, 2026. I have the emails from AWS confirming the hold was removed and verification documents were no longer required.\n\nOn February 9, 2026, my account was suspended AGAIN with a new verification request.\n\nThe \"final decision\" you're referring to was reinstatement. This is a different suspension that happened 48 hours after AWS told me my account was verified and clear.\n\nYour response shows you didn't even review what actually happened before responding. Please look at the facts instead of giving boilerplate responses about final decisions.",
              "score": 6,
              "created_utc": "2026-02-09 16:59:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r0e1ar",
      "title": "Opinion: LEX bots are a poor fit for connect integrations.",
      "subreddit": "aws",
      "url": "https://www.reddit.com/r/aws/comments/1r0e1ar/opinion_lex_bots_are_a_poor_fit_for_connect/",
      "author": "DrollAntic",
      "created_utc": "2026-02-09 19:34:34",
      "score": 7,
      "num_comments": 4,
      "upvote_ratio": 0.77,
      "text": "Lex bots use a legacy keyword-based utterance matching approach for intent selection. For all but the simplest contact center solutions, this isnâ€™t a great fit.\n\nConversational promptâ€“based intent selection is more accurate, provides a better CX experience, and eliminates the need for questions designed to constrain CX replies to specific keywords. It also removes the painful maintenance work of managing long keyword lists to keep intent matching accurate.\n\nTo put it more bluntly, I see Lex bots as technical debt. I continually have to engineer around them to create dynamic interactions that feel like real conversations, rather than a â€œbot with slotsâ€ experience.\n\nI believe a new type of â€œGet Customer Inputâ€ block is needed â€” one that can interact directly with my prompts and Bedrock. This would allow seamless data exchange between Connect and the conversational AI layer, enabling path and route selections based on GenAI responses rather than basic keyword matching.\n\nIâ€™m aware that Lex now supports â€œgenerative assessmentâ€ for keyword intents. However, in my testing, enabling this made intent selection worse, not better. The reality is that keyword-based selection simply doesnâ€™t work for advanced conversational interactions â€” especially when customers may not know the exact keyword that corresponds to their reason for calling.\n\nIâ€™m a huge fan of Connect and have used it for years, but lately, working with Lex has become frustrating. It creates more barriers than bridges, and I believe thatâ€™s a serious issue.",
      "is_original_content": false,
      "link_flair_text": "discussion",
      "permalink": "https://reddit.com/r/aws/comments/1r0e1ar/opinion_lex_bots_are_a_poor_fit_for_connect/",
      "domain": "self.aws",
      "is_self": true,
      "comments": [
        {
          "id": "o4l08tw",
          "author": "AWSSupport",
          "text": "Hello,\n\nYour feedback is appreciated.\n\nI've shared this internally for further review.  \n\n\\- Adri N.",
          "score": 2,
          "created_utc": "2026-02-10 08:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4maggn",
              "author": "DrollAntic",
              "text": "Thanks Adri!  I appreciate you passing this along.\n\n",
              "score": 1,
              "created_utc": "2026-02-10 14:24:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o50k021",
          "author": "dmaciasdotorg",
          "text": "Lex has been and continues to be one of the weakest point of the whole Connect ecosystem. AWS tries to bolt on Bedrock on it, but in my opinion there needs to be a complete different service that AWS needs to create here. Some sort of understanding action service that has conversation, outcomes, and guardrails all in one place. I doubt this would every happen though.",
          "score": 2,
          "created_utc": "2026-02-12 17:31:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o50xau1",
              "author": "DrollAntic",
              "text": "I agree with you. I told an AWS support tech last week that LEX is technical debt for connect, they need something better. Let's hope the feedback to the team results in a better integration. The number of times I've been in a design meeting engineering around LEX limits, is a problem. :) ",
              "score": 1,
              "created_utc": "2026-02-12 18:33:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}