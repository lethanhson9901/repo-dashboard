{
  "metadata": {
    "last_updated": "2026-02-08 08:47:11",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 103,
    "file_size_bytes": 138768
  },
  "items": [
    {
      "id": "1qxmeee",
      "title": "I built RAG for 10K+ NASA docs (1950s‚Äìpresent) in 2 weeks: VLMs for complex tables, diagrams & formulas, 657K+ pages on a single H100, live-streamed full build.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qxmeee/i_built_rag_for_10k_nasa_docs_1950spresent_in_2/",
      "author": "Low_Acanthisitta7686",
      "created_utc": "2026-02-06 16:32:09",
      "score": 208,
      "num_comments": 34,
      "upvote_ratio": 0.94,
      "text": "**TL;DR:** I designed and built a full RAG system over 10,000 NASA technical documents spanning the 1950s to 2025 ‚Äî we're talking scanned typewriter reports, handwritten notes, propulsion diagrams, mathematical formulas, failure investigations. Off-the-shelf tools broke down fast. I ended up building a custom pipeline using Qwen3-VL-8B to process what traditional OCR and parsers couldn't handle, ran the whole thing on a single H100 (657,000+ pages, \\~180 pages/min), and built an agentic retrieval system that doesn't just search ‚Äî it investigates like a domain expert. The architecture is designed to scale to 100K+ documents. Everything was live-streamed (140+ hours across 15 streams), and the GitHub repo for the document processing pipeline and infra is coming soon.\n\nHey everyone, I'm Raj. Over the last 2 weeks, I live-streamed building what turned out to be the most technically challenging project I've taken on ‚Äî and I wanted to share the experience while it's fresh. This is a long one, I tried to keep it short, but there was too much that I think is genuinely useful to cut.\n\n# The Domain\n\nSo here's the scenario I designed for this project ‚Äî a fictional aerospace consultancy called \"Meridian Aerospace,\" modeled on very real challenges these companies face.\n\n85,000+ documents accumulated over 70+ years ‚Äî real documents from NASA's Technical Reports Server (NTRS). Propulsion test reports, failure investigations, component specs, regulatory filings. Engineers spending 4-6 hours per project digging through archives. A missed critical failure mode last quarter because the relevant data was buried in a 1997 test report nobody knew existed.\n\nNow here's what makes these documents painful:\n\n* 1950s‚Äì1990s scanned reports ‚Äî photocopied, faxed, re-scanned, degraded quality\n* Dense technical diagrams everywhere: thrust curves, propulsion schematics, thermal analysis charts\n* Mathematical formulas and engineering equations scattered throughout\n* Domain-specific acronyms (Isp, TWR, LOX, MMH, NTO) that are often never expanded in the text\n* Cross-references between documents ‚Äî failure reports cite original test data, compliance docs reference design specs\n* Tables spanning multiple pages with nested sub-headers\n\nI used 10,000 documents from NASA's Technical Reports Server as the working dataset, with the architecture designed from day one to handle the full 85K+ and beyond.\n\n# What I Built\n\nI'll walk through the three main layers, but I want to be clear ‚Äî these aren't independent pieces you build one after another. They feed into each other constantly. Decisions in the document processing layer directly shaped how the agent works, and understanding how engineers actually think (the agent layer) changed how I approached extraction. It's all connected.\n\n# The Document Processing Pipeline\n\nThis is where a huge chunk of the work lived, and honestly where most people underestimate the difficulty. The core realization: **you cannot build good retrieval over bad extractions.** If your chunked text is garbage, no embedding model or re-ranker is going to save you.\n\nI used Docling (from IBM, I know it has a ton of issues ‚Äî I found workarounds and solved them too) for layout detection ‚Äî figuring out where tables, figures, formulas, and text blocks sit on each page. Then Qwen3-VL-8B to actually interpret what's in those regions.\n\nA few of the harder problems:\n\n**Formula association:** Docling detects formulas fine, but they lose their position in the document flow. So you get a formula floating at the end of a page with no connection to the paragraph it belongs to. I built a system that paints colored bounding boxes with ID numbers directly onto page screenshots, then asks the VLM \"where does Formula 7 belong relative to these numbered paragraphs?\" Sounds weird, works surprisingly well. Gives you reading-order accuracy without re-OCRing anything.\n\n**Complex tables:** These were probably the single most painful thing to solve. We're talking massive grids ‚Äî 72 columns by 50 rows of stability data ‚Äî where position determines meaning. Down arrows mean \"carry this value down.\" Brackets group five rows under \"Unstable.\" Zebra lines and grid lines guide the human eye across dense numbers. Standard OCR reads left-to-right, top-to-bottom and has no idea what to do with any of this. Parsers treat the grid lines as noise or lose alignment if the scan is slightly tilted.\n\nI went through a lot of approaches. Standard markdown extraction lost alignment. CV-based heatmaps and projection lines to detect rows ‚Äî worked about 80% but too brittle for production. JSON output from the VLM broke constantly on large tables (missed closing brackets). Small models (7B) hallucinated numbers and missed columns entirely.\n\nWhat actually worked was treating the table as a photograph of data rather than a stream of text. Use Docling purely for finding the bounding box coordinates, crop the original high-res page image (no downscaling ‚Äî that destroys data in dense tables), and send the full-resolution crop to a large VLM. You need 72B+ to hold context across a 30-column table without losing track.\n\nTwo tricks that made a real difference. First, for tables with zebra lines or warped scans, I pre-process the image by drawing red horizontal lines onto it before sending to the VLM ‚Äî basically a \"digital ruler\" that forces the model to keep row alignment. Second, the prompt strategy ‚Äî instead of asking for just structured output, I ask for markdown (way more robust than JSON for grid data) plus a \"notes\" field where the model captures visual shorthand. \"If there's a down arrow, note the value is carried down. If there's a bracket, note the grouping.\" The model successfully returned \"unstable\" for rows that didn't explicitly have the text but were visually grouped under an \"Unstable\" bracket.\n\nFor the truly dense tables that still needed more work, I have a fallback that generates a detailed description and serves the raw image alongside it ‚Äî which honestly, in aerospace, engineers prefer anyway over a potentially wrong structured output. But this isn't a dead end. The digital ruler approach and the prompt strategy were working well, and with more time I think there's a solid solution there. I was time-boxed to 2 weeks for this entire project, so I made the pragmatic call to move on. Might revisit this specifically and share if I make a breakthrough.\n\n**Legacy scan quality:** Documents from the 1960s have noise, \"Confidential\" stamps, hole punches, scan artifacts ‚Äî and models happily pick all of these up as \"figures.\" Added a classification step asking the VLM: \"Is this a technical diagram or just a document artifact?\" Simple, but it cleaned up a lot of noise.\n\n**The full-page strategy:** I initially tried cropping individual formulas to save tokens. Docling's format detection models missed about 60% of small formulas in dense pages. So I pivoted ‚Äî if any formula is detected on a page, send the entire page screenshot to the VLM and let it transcribe everything in reading order. More expensive per page (didn't matter as I deployed on a GPU), but the accuracy difference is massive. In this domain, a missed variable isn't a minor bug.\n\n**On OCR,** I didn't actually need traditional OCR for most of the heavy lifting. The figures, tables, and formulas ‚Äî which are the hardest parts of these documents ‚Äî were all handled by the VLM pipeline. OCR was only needed as a fallback for pages where the embedded text layer was missing or corrupted. So the approach became: use native text extraction where available, VLM for all the visual/structured content, and OCR only when truly needed. Disabling forced OCR where it wasn't necessary cut processing time significantly.\n\n# H100 Infrastructure & Scaling\n\nProcessing 10K documents ‚Äî roughly 657,000+ pages ‚Äî on a single H100 was its own adventure.\n\n**Where it started:** My first attempt was basically a monolithic script. Every worker loaded the PDF, loaded the model onto the GPU, ran inference, unloaded. Workers were fighting each other for GPU memory, CPU, RAM. Everything was crashing. Back-of-the-napkin math said this approach would take somewhere around 28 days for the full dataset. Obviously not going to work.\n\n**The rewrite:** I moved to a proper service-oriented architecture. Separated the CPU-heavy work (Docling parsing, chunking, text extraction) from the GPU-heavy work (VLM inference). Stateless Celery workers handle the CPU side, feeding requests to a persistent vLLM server that does nothing but inference. Redis as the message broker. Took some inspiration from how production ML systems handle millions of requests with limited compute ‚Äî keep your inference engine as a persistent service, don't have each worker spin it up and tear it down.\n\nThat alone brought the estimate down to maybe 5-9 days. Still not great.\n\n**Then the tuning started.** FP8 quantization because running standard GGUF/Ollama on an H100 is wasting the hardware ‚Äî FP8 is specifically optimized for Hopper. Concurrency tuning: tested 6, 8, 9, 10 Docling workers. 9 caused instant OOM. 10 saturated the queue. 6 underutilized the GPU. 8 was the sweet spot. Dynamic image scaling for oversized PDFs ‚Äî some scans were 170MB, crashing workers during bitmap conversion. VRAM memory leak management ‚Äî usage would creep up batch after batch until it crashed, so I added explicit garbage collection between cycles.\n\n**End result:** \\~2.5 days, running at about 180 pages per minute. From 28 days to 2.5 days on the same hardware, just by thinking about architecture and resource management. Again, could have done better, but was on a time crunch.\n\n# The Agent & Retrieval Layer\n\nThis part tends to get underestimated. Building the agent wasn't just \"wire up some tools to an LLM and write a system prompt.\" A huge amount of time went into two things: understanding the people who would actually use this system, and shaping how the agent itself thinks.\n\nI spent a lot of time with Claude role-playing as different engineer personas ‚Äî a cautious senior engineer (\"Sandra\") approaching retirement who's seen things go wrong, a junior engineer who searches too narrowly. I was trying to understand: how does their day actually work? How do they use current traditional systems? What's literally going through their mind when they're investigating a failure mode? What are they worried about that they won't say out loud?\n\nThat process shaped everything about the agent. For example ‚Äî engineers don't just look for failure cases. They specifically look for *success cases* as counter-evidence to validate risky designs. A standard RAG setup completely misses that nuance. Or the fact that a \"question about a valve failure\" might actually be about defending a design decision in a review meeting next week. The agent needs to understand the situation behind the question.\n\nThat understanding fed directly into how I designed the agent's reasoning. One of the bigger realizations was that spiking domain intuition in the system prompt often outperforms complex retrieval engineering. Instead of hardcoding examples, I focused on making the agent think like a propulsion engineer. It should be low-opinionated and already have hypotheses before it runs a single search. When someone mentions a pressure value, it should have intuition about whether that's nominal or concerning. When it finds a document, it should reason about what it means, not just return it. It's not a search tool ‚Äî it's a reasoning engine with engineering expertise that uses search as one of its tools. And honestly, this is still just at the system prompt level ‚Äî keeping it low-opinionated, letting the model lean on its own domain knowledge rather than constraining it ‚Äî but it brings absolute wonders to how the system behaves.\n\nWhat came out of all that work:\n\nThe agent doesn't just search ‚Äî it investigates. It maintains a working task list and notes, forms hypotheses based on its domain intuition before it even touches the search tool, and updates its understanding as it learns. When a question branches, it spawns sub-agents for parallel research threads. It can navigate ‚Äî read adjacent chunks, follow cross-references between documents, pull threads across decades of reports.\n\nWhen the text extraction is uncertain ‚Äî and on 1950s docs, it will be ‚Äî the agent can request a screenshot of the actual PDF page region to visually verify what it's reading. That \"visual region\" tool ended up being one of the most important things in the whole system. It's the bridge between \"95% OCR accuracy\" and \"actually trustworthy in aerospace.\"\n\nI also integrated the NASA Thesaurus ‚Äî 18K aerospace terms filtered down to 3.5K propulsion-relevant concepts ‚Äî so the system handles query expansion properly. \"LOX\" matches \"Liquid Oxygen,\" \"2000 PSI\" finds results mentioning \"13.9 MPa.\" Without this, you're relying on exact keyword matches in a domain where everyone uses different terminology for the same thing.\n\nAnd time-boxed search ‚Äî engineers ask things like \"what do we know about cryogenic engine failures between 1970 and 1980?\" Filtering by time period before semantic search cuts the search space dramatically. When I tested this, the agent successfully traced the 50-year evolution of cryogenic systems ‚Äî from passive insulation in the 1970s to active cryo-coolers in the 2020s ‚Äî without any deep research mode. Just proper filtering and good retrieval.\n\n# What's Coming Next\n\nI've linked all the YouTube streams in the comments below ‚Äî 15 streams, some of them are 11+ hours long, so obviously that's a lot to sit through. To make things more digestible and actually useful, I'm going to be posting specific problem/solution breakdowns over the next few days, including how I evaluated the system with 10K docs. Each of these topics was genuinely its own nightmare to solve, and I think the details will be helpful for anyone working on similar problems.\n\nI'm also hoping to open-source the document processing pipeline and infrastructure code on GitHub soon, which I think will be genuinely useful for anyone dealing with large-scale document processing ‚Äî whether it's aerospace or not.\n\nOne last thing ‚Äî I genuinely want to thank the team behind Claude Code. Being honest, a project like this would realistically take a team of 3-4 engineers working 3-4 months. The document processing pipeline alone, the infrastructure, the agent design, the frontend, evaluation ‚Äî each of these is a serious body of work. I did it solo in 2 weeks, live on stream, and that would not have been possible without Claude Code, it was in the loop for pretty much all of it. Seriously, thank you to the engineers behind it.\n\nHappy to answer questions, and if you've dealt with similar problems ‚Äî legacy docs, domain-specific retrieval, scaling document processing ‚Äî I'd love to hear what you ran into.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qxmeee/i_built_rag_for_10k_nasa_docs_1950spresent_in_2/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3xvwcn",
          "author": "ksk99",
          "text": "Any evaluation metrixs u used, any subset of data set along with queries and results we can use to recreate/learn",
          "score": 6,
          "created_utc": "2026-02-06 18:02:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xxjlq",
              "author": "Low_Acanthisitta7686",
              "text": "Yeah! So in the last stream (Part 14) I went through evaluation. Basically, I loaded co-related full docs into Gemini (1M context window) and had it generate complex questions that tested different aspects of the agent ‚Äî things like cross-document reasoning, degraded documents, negative/boundary tests, and more.   \n  \nThen I evaluated and tested whether the system could find the right set of docs within the 10K-doc space.   \n  \nI felt like this gave me a solid initial test suite to run, which would probably end up being a pretty strong evaluation as well. Sure, I‚Äôll share the dataset and pipeline with the repo soon.",
              "score": 3,
              "created_utc": "2026-02-06 18:09:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xniw6",
          "author": "vladimirxi",
          "text": "Nuts.  Well done on the documentation!  Crazy project.  Well thought out.",
          "score": 9,
          "created_utc": "2026-02-06 17:22:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3xpjs5",
              "author": "Low_Acanthisitta7686",
              "text": "Thank you!",
              "score": 3,
              "created_utc": "2026-02-06 17:31:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3xd6ic",
          "author": "Low_Acanthisitta7686",
          "text": "Check the live streams here (15 streams, 140+ hours): [https://www.youtube.com/@rajsuthanofficial7585/streams](https://www.youtube.com/@rajsuthanofficial7585/streams)",
          "score": 9,
          "created_utc": "2026-02-06 16:33:17",
          "is_submitter": true,
          "replies": [
            {
              "id": "o3xz1qw",
              "author": "flaxseedyup",
              "text": "You absolute gem of a man. I will definitely be looking at this. Thank you so much for sharing!    \n    \nWhere did you learn the majority of the core skills needed for such a project?    \n    \nDo you rate the ‚ÄúThe AI Automators‚Äù who are on YouTube?",
              "score": 4,
              "created_utc": "2026-02-06 18:17:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3y00x7",
                  "author": "Low_Acanthisitta7686",
                  "text": "haha thanks ‚ù§Ô∏è\n\nI pretty much learned by building stuff. I was working on my startup and also worked with a few enterprises along the way, but mostly just learned by doing random complex projects!",
                  "score": 1,
                  "created_utc": "2026-02-06 18:21:35",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3yeh4z",
          "author": "makinggrace",
          "text": "This was a beast of a project. Love it.",
          "score": 2,
          "created_utc": "2026-02-06 19:30:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yfh68",
              "author": "Low_Acanthisitta7686",
              "text": "for sure.... thanks!",
              "score": 1,
              "created_utc": "2026-02-06 19:35:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zizu5",
          "author": "tehsilentwarrior",
          "text": "Cool stuff. Will be useful in playing Kerbal üòÇ\n\nNo but, impressive stuff. Hope to see it soon!",
          "score": 2,
          "created_utc": "2026-02-06 22:54:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40q0gm",
              "author": "Low_Acanthisitta7686",
              "text": "appreciate it mate!",
              "score": 1,
              "created_utc": "2026-02-07 03:12:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3zr9gx",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 2,
          "created_utc": "2026-02-06 23:41:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40q9jt",
              "author": "Low_Acanthisitta7686",
              "text": "thanks buddy!",
              "score": 1,
              "created_utc": "2026-02-07 03:13:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o40685c",
          "author": "Legitimate-Leek4235",
          "text": "I wonder if we give this prompt to opus 4.1 and all the agents which built the compiler, will it be able to replicate this",
          "score": 2,
          "created_utc": "2026-02-07 01:09:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40qtfh",
              "author": "Low_Acanthisitta7686",
              "text": "Nope ‚Äî not possible at all. There are so many moving pieces and decisions to make, and honestly it takes a ton of thinking, trial, and error to get to this point. Check my YouTube streams ‚Äî for around 3 days (each 8+ hours) I was banging my head building the infra, and then we completely rewrote the entire thing in a day. So it literally takes a lot of work. Luckily I‚Äôm an engineer, so it naturally 100√ó my potential.",
              "score": 1,
              "created_utc": "2026-02-07 03:17:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o40cczw",
          "author": "OnlyTimeFan",
          "text": "Thanks for sharing and spreading the knowledge",
          "score": 2,
          "created_utc": "2026-02-07 01:47:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40r1c8",
              "author": "Low_Acanthisitta7686",
              "text": "always!",
              "score": 2,
              "created_utc": "2026-02-07 03:18:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o415khy",
          "author": "FiddlyDink",
          "text": "This is incredible work! I‚Äôm working on a RAG project to connect an LLM to a Neo4j data store to be able to ask questions about old records and I know how challenging it can be. I‚Äôm not trying to solve half the challenges that you had to and yet I‚Äôm still struggling. I would love to learn more about this work and will definitely be checking out your streams!",
          "score": 2,
          "created_utc": "2026-02-07 04:59:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o41c2p0",
              "author": "Low_Acanthisitta7686",
              "text": "‚ù§Ô∏è",
              "score": 1,
              "created_utc": "2026-02-07 05:50:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o41t0xh",
          "author": "Electrical-Paper-323",
          "text": "Excellent! Looking forward to the GitHub project üòä",
          "score": 2,
          "created_utc": "2026-02-07 08:25:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o41ts01",
          "author": "Neovison_vison",
          "text": "Can you TLDR us in new since your last write up 4 months ago?",
          "score": 2,
          "created_utc": "2026-02-07 08:32:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o4258z7",
              "author": "Low_Acanthisitta7686",
              "text": "Worked on a couple of projects since then, wrapped up a few, and have a few ongoing. But mostly right now I‚Äôm focused on my startup, basically building something similar: on-prem search at scale for regulated enterprises like finance, pharma, ITAR-protected companies, and more. It‚Äôs [intraplex.ai](http://intraplex.ai) if you‚Äôre interested.",
              "score": 2,
              "created_utc": "2026-02-07 10:25:39",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o42hujq",
          "author": "redbull-hater",
          "text": "Good job man",
          "score": 2,
          "created_utc": "2026-02-07 12:20:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o42pk2x",
          "author": "jaykeerti123",
          "text": "Great stuff. Waiting for the GitHub code.",
          "score": 2,
          "created_utc": "2026-02-07 13:16:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3yvpnv",
          "author": "No_Wrongdoer41",
          "text": "Me and a small team are building a platform that can accomplish something comparable in a matter of hours, repeateably, on corpuses of thousands of documents. I'd love your feedback on what we're working in if you don't mind discussing it with me!",
          "score": 1,
          "created_utc": "2026-02-06 20:56:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ywgcm",
              "author": "Low_Acanthisitta7686",
              "text": "sure",
              "score": 1,
              "created_utc": "2026-02-06 21:00:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3yhhfr",
          "author": "satechguy",
          "text": "Which Ilm wrote such verbose text ;-)",
          "score": 0,
          "created_utc": "2026-02-06 19:45:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3yitmx",
              "author": "Low_Acanthisitta7686",
              "text": "haha, I wrote it and had claude help polish the english.",
              "score": 2,
              "created_utc": "2026-02-06 19:52:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3zji2u",
                  "author": "tehsilentwarrior",
                  "text": "I write a lot too and people these days just think AI did it. \n\nI spent quite a lot of time perfecting my English so when I documented a massive project we have my boss kept asking what AI I used for that .. lol\n\nI just said <my inicials>AI, and he was hilariously confused when he couldn‚Äôt find it. I said I trained it myself over the last decades",
                  "score": 3,
                  "created_utc": "2026-02-06 22:57:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3y97qu",
          "author": "bbahner",
          "text": "This is awesome! Thanks for sharing. ",
          "score": 1,
          "created_utc": "2026-02-06 19:05:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ybujq",
              "author": "Low_Acanthisitta7686",
              "text": "Sure!",
              "score": 1,
              "created_utc": "2026-02-06 19:17:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o4241bl",
          "author": "QuanstScientist",
          "text": "OMG, what an amazing process documentation. We both went through a very similar process, I‚Äôm working on a local RAG for the Epstein archive files, still in development, also using Claude, here at some details, still not in a state for public release https://boltzmannentropy.github.io/Librarius/",
          "score": 0,
          "created_utc": "2026-02-07 10:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o406bb6",
          "author": "EditorDisastrous4994",
          "text": "You should try Reseek. It's an AI second brain that handles semantic search across notes, PDFs, and web content in one place. It might be a good alternative if you want a unified system",
          "score": -1,
          "created_utc": "2026-02-07 01:09:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40r0u3",
              "author": "Low_Acanthisitta7686",
              "text": "Checked it out, but it doesn‚Äôt mention anywhere what scale it can work with, and that‚Äôs super important.",
              "score": 1,
              "created_utc": "2026-02-07 03:18:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qvtrw7",
      "title": "If RAG is dead, what will replace it?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qvtrw7/if_rag_is_dead_what_will_replace_it/",
      "author": "Normal_Sun_8169",
      "created_utc": "2026-02-04 16:50:23",
      "score": 133,
      "num_comments": 99,
      "upvote_ratio": 0.85,
      "text": "It seems like everyone who uses RAG eventually gets frustrated with it. You end up with either poor results from semantic search or complex data pipelines.\n\nAlso - searching for knowledge is only part of the problem for agents. I‚Äôve seen some articles and posts on X, Medium, Reddit, etc about agent memory and in a lot of ways it seems like that‚Äôs the natural evolution of RAG. You treat knowledge as a form of semantic memory and one piece of a bigger set of memory requirements.¬†\n\nThere was a paper published from Google late last year about self-evolving agents and another one talking about adaptive agents.\n\nIf you had a good solution to memory, it seems like you could get to the point where these ideas come together and you could use a combination of knowledge, episodic memory, user feedback, etc to make agents actually learn.\n\nSeems like that could be the future for solving agent data. Anyone tried to do this?¬†",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qvtrw7/if_rag_is_dead_what_will_replace_it/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3kg4v0",
          "author": "qa_anaaq",
          "text": "RAG isn‚Äôt dead. It‚Äôs perfectly fine and just needs to be used well. Everyone believes context graphs are the next trillion dollar industry. Context graph management at runtime is another flavor of RAG. \n\nRemember that RAG isn‚Äôt a narrow term. If something is pulled from somewhere to augment generation, it‚Äôs RAG.",
          "score": 164,
          "created_utc": "2026-02-04 17:48:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3luvt1",
              "author": "isthatashark",
              "text": "The challenge with the name \"RAG\" is that so many people use it as a shorthand to describe semantic search over chunked documents in a vector database. I think the days where you can built any sort of meaningful AI application with that approach are behind us.\n\nAs a pattern, retrieving context and using it to augment the LLM's generation is here to stay.",
              "score": 22,
              "created_utc": "2026-02-04 21:44:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3obe76",
                  "author": "FiddlyDink",
                  "text": "What is replacing chunked documents in a vector database for semantic search?",
                  "score": 9,
                  "created_utc": "2026-02-05 06:33:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3mxhx9",
              "author": "FoldedKatana",
              "text": "Yeah I'm using graph rag for a client and it works great if the data is static.",
              "score": 4,
              "created_utc": "2026-02-05 01:10:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3owpwq",
                  "author": "3minpc",
                  "text": "Why static? You can't rebuild your graph every x hours?",
                  "score": 1,
                  "created_utc": "2026-02-05 09:53:25",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3l8dww",
              "author": "valuat",
              "text": "Everyone who?",
              "score": 6,
              "created_utc": "2026-02-04 19:56:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3na7fb",
              "author": "SUCK_MY_DICTIONARY",
              "text": "Oh I love the way this guy fucking thinks YES.\n\nWhat is your opinion on MoE? I want to know",
              "score": 1,
              "created_utc": "2026-02-05 02:23:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3otgqt",
              "author": "_nku",
              "text": "Agree.  I think we haven't reached the necessary maturity in best practice guidance in regards to when which kind and strategy of grounding information injection into the final completion run of an LLM is the right approach.  What mix of forced grounding context injection, dynamic tool calling to get grounding context, sub-agents summarizing from larger bodies to then inject summarized / shortened grounding context etc gives the best bang for the buck?   TBH from production experience, it's still very situation and data specific.  For a fast follower team that does not have the capacity to try out every frontline technology development, an off the shelf (e.g. GCP APIs based) vector store plus reranker plus grounding into a fast model with large context is still going to be a decent outcome IF (!!!) the use case is actually a fit for it and IF (!!) they put a lot of effort in the preparation, custom chunking, extraction, tagging of their content.     \n  \nMy unscientific thesis is that \"standard\" RAG setups are used way to much on a) bad data b) the wrong use case,  not that they are fundamentally bad.    \n  \nAnother thesis: The general approach of rather providing situationally dynamic context vs. relying on foundation model fact knowledge is here to stay until we have models that can be incrementally and continuously trained or tuned at very low cost (and even then, the question is up whether this provides better hallucination control than grounding in the generation context).",
              "score": 1,
              "created_utc": "2026-02-05 09:21:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3ks60y",
              "author": "howardhus",
              "text": "rag was never even alive.\n\nRag ist pulling chunks in a half assed vector search and letting some llm hallucinate some coherent sentence from it. The selling point was the LLM faking confidence. Worked just like in the real world..\n\nwas never great in theory but peopel were flashed as they saw some very self confident human readable answer \"here is the perfect answer to your question!\"\n\nthen you correct it: \"yes you are right! i lied! here is the actual correct answer (this time for real!)\"\n\nRAG was only great before the word \"hallucination\" also became a thing.",
              "score": -18,
              "created_utc": "2026-02-04 18:42:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3l0y0o",
                  "author": "Agreeable-Market-692",
                  "text": "This is a very outdated view of RAG. Hundreds of papers and dozens of models later and things are much improved.",
                  "score": 10,
                  "created_utc": "2026-02-04 19:22:01",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3lml96",
              "author": "Dense_Gate_5193",
              "text": "yeah RAG is neat but Graph-RAG is where it is at.\n\nit‚Äôs why i built nornic. \n\nhttps://github.com/orneryd/NornicDB\n\n0.17ms p95 transacted writes. \n\nneo4j drop-in replacement that‚Äôs 3-50x faster depending on operation.\n\nit also has a qdrant compatible grpc endpoint and is ~40% faster than qdrant proper\n\ngpu accelerated vector embedding search or cpu IVF-HNSW, tunable. \n\nmanaged vector embeddings mean you don‚Äôt need a remote model to generate embeddings for you. same for reranking. it runs an in-memory model for reranking.",
              "score": -12,
              "created_utc": "2026-02-04 21:05:03",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kfb2f",
          "author": "coffee-praxis",
          "text": "Agent memory alone doesn‚Äôt cut it. Let‚Äôs say you want grounded facts from a document source that‚Äôs too big for context window. You can‚Äôt just shove it all in ‚Äúagent memory‚Äù unless you retrieve the correct bits of it somehow. Now you‚Äôre back to RAG.",
          "score": 37,
          "created_utc": "2026-02-04 17:44:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ltfuv",
              "author": "isthatashark",
              "text": "I hear more people talking about this as semantic memory and thinking of it as one requirement in a bigger set of agent memory requirements rather than just RAG.",
              "score": 5,
              "created_utc": "2026-02-04 21:37:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o3kkqao",
              "author": "NorCalZen",
              "text": "Sorry if this a naive question, but could you use a database solution like ScyllaDB to achieve the right results ?",
              "score": 0,
              "created_utc": "2026-02-04 18:08:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3klea2",
                  "author": "coffee-praxis",
                  "text": "RAG is ‚Äú**retrieval** augmented generation‚Äù. Any DB qualifies.",
                  "score": 24,
                  "created_utc": "2026-02-04 18:11:53",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3k9bq3",
          "author": "ethan000024",
          "text": "I‚Äôve been hearing more about agent learning lately too. Agree it‚Äôs a promising idea but also mostly hype when I‚Äôve tried to dig into it. The two most interesting projects I‚Äôve seen on this lately are Agent Lightning and Hindsight. Two very different approaches, Agent Lightning relies more on file system. Hindsight is closer to what you described with combining knowledge, episodic memory, etc. Both have learning aspects to it.¬†",
          "score": 11,
          "created_utc": "2026-02-04 17:16:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kgx9d",
              "author": "Normal_Sun_8169",
              "text": "I just looked those projects up. Very cool stuff. The learning demo they have on the GitHub repo for Hindsight is exactly what I was trying to describe. Reinforcement learning over agent memory to form mental models seems super powerful. Thanks for the info!",
              "score": 4,
              "created_utc": "2026-02-04 17:51:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kcja7",
          "author": "florinandrei",
          "text": "> If RAG is dead, what will replace it?\n\nTATTER\n\nTransformer-Attention Token Tangling for Eventually Rambling",
          "score": 24,
          "created_utc": "2026-02-04 17:31:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kielt",
              "author": "Floppy_Muppet",
              "text": "I believe \"token tangling\" is illegal in several states.",
              "score": 20,
              "created_utc": "2026-02-04 17:58:17",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3k912z",
          "author": "Emma_4_7",
          "text": "The most annoying thing about agent memory right now is how many ‚Äúmemory‚Äù projects on GitHub are basic RAG solutions under the covers. That‚Äôs nice you can remember where I work after 10 whole messages.",
          "score": 17,
          "created_utc": "2026-02-04 17:15:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kgims",
              "author": "Normal_Sun_8169",
              "text": "Yeah, I‚Äôve noticed this too.",
              "score": 2,
              "created_utc": "2026-02-04 17:49:44",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o3kig2c",
              "author": "Original_Finding2212",
              "text": "What do you think about this?\n\nQq folder here:\n\n[https://github.com/OriNachum/autonomous-intelligence](https://github.com/OriNachum/autonomous-intelligence)\n\nAnd add a star if you like or want to support üôèüèø\n\nhttps://preview.redd.it/r8euxdeboihg1.jpeg?width=2752&format=pjpg&auto=webp&s=050a9da330c4b9c4c558d792e243f8703b05dbfe",
              "score": -15,
              "created_utc": "2026-02-04 17:58:29",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3kvyj2",
                  "author": "leonjetski",
                  "text": "‚ÄúMapping sturucted outitites and complex relationships between a√¶√∞capta.‚Äù",
                  "score": 14,
                  "created_utc": "2026-02-04 18:59:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3tghgy",
                  "author": "cmndr_spanky",
                  "text": "That diagram is a pile of nonsense. It might be time to start thinking for yourself‚Ä¶ friend. Did you even read it ?",
                  "score": 1,
                  "created_utc": "2026-02-06 00:40:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3mv41a",
          "author": "jba1224a",
          "text": "‚ÄúLet me just shove this shit into a vector database.  We don‚Äôt need to worry about chunking.  What‚Äôs an embedding model?‚Äù\n\n‚Ä¶.\n\n‚ÄúWhy do my results suck.  RAG is frustrating‚Äù",
          "score": 6,
          "created_utc": "2026-02-05 00:56:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ozewa",
              "author": "CSEliot",
              "text": "RAG tools don't run any embedding by default???",
              "score": 1,
              "created_utc": "2026-02-05 10:18:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3q2542",
                  "author": "jba1224a",
                  "text": "Are you asking?\n\nRag isn‚Äôt only vector search but in the context of this discussion this is why it fails for people.\n\nThey equate it purely to vector search and then put zero planning or thought into how to curate their vector database.\n\nIt‚Äôs akin to baking a cake by just dumping all the ingredients into a pan with no measuring.  You may get something vaguely cake-like‚Ä¶but you shouldn‚Äôt be pissed it didn‚Äôt come out the way you wanted.",
                  "score": 3,
                  "created_utc": "2026-02-05 14:42:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o3pjuup",
                  "author": "vogut",
                  "text": "?",
                  "score": 1,
                  "created_utc": "2026-02-05 12:59:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3mtaif",
          "author": "Ok-Owl-7515",
          "text": "I don‚Äôt think RAG is dead. Vector-only semantic search is what usually disappoints. What‚Äôs replacing it (for me) is hybrid retrieval + memory architecture: FTS/keyword first, then vectors only as fallback, union + rerank, and always return retrieval diagnostics (which backend, hit counts, scores, latency).\n\nThe biggest unlock is in considering embeddings/indexes as versioned, reproducible derived artifacts (model/version + source hash), and controlling changes via a small golden set to prevent silent changes to results. Retrieval is just one ‚Äúmemory surface,‚Äù alongside structured state/ledgers and episodic logs.",
          "score": 4,
          "created_utc": "2026-02-05 00:46:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3syrh2",
              "author": "danigoncalves",
              "text": "What do you use for FTS? do you have your own implementation or use something like Apache Solr or similar that abstracts you from some of data ingestion processes? And why you use vector only as fallback and do not join both FTS/keyword with sematic search, merge and re-rank both to choose the best context to feed the models? ",
              "score": 2,
              "created_utc": "2026-02-05 23:00:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3t1fwk",
                  "author": "Ok-Owl-7515",
                  "text": "Good questions ‚Äì just a quick clarification on my wording. I‚Äôm currently using SQLite FTS5 (embedded) instead of Solr or Elasticsearch. It keeps retrieval portable, deterministic, and easy to debug with stable chunk/card IDs, source text hashes, and reproducible index builds.\n\nFor vectors, when I say ‚Äúfallback,‚Äù I mean I don‚Äôt always run semantic search. (a) It can add noise for queries that are heavy on entities, where lexical search performs better; and (b) it increases complexity and cost if used on every query. But when semantic does kick in, say, too few FTS hits or low lexical confidence,  I follow the exact flow you described: run vector search - merge results - rerank - return top-K. I also log diagnostics like backend used, hit counts, scores, and latency.\n\nThat said, I haven‚Äôt rolled out embeddings-based retrieval in production yet. The current setup is FTS-first, paired with structured state and ledgers. The hybrid approach is next on the roadmap, once I can safely gate it behind a ‚Äúsemantic miss‚Äù golden set to avoid silent drift.\n\nCurious, what‚Äôs worked best for you in terms of rerankers or thresholding?",
                  "score": 1,
                  "created_utc": "2026-02-05 23:14:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o3yrkj6",
              "author": "engineerofsoftware",
              "text": "please don‚Äôt use vector search as a fallback.. it‚Äôs meant to be concatenated with fts‚Ä¶ you always want to do semantic search because fts will always have blindspots.",
              "score": 2,
              "created_utc": "2026-02-06 20:35:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3ysw5l",
                  "author": "Ok-Owl-7515",
                  "text": "Yeah, fair. FTS definitely has its blind spots. When I say \"fallback,\" I don‚Äôt mean semantic is optional forever. It‚Äôs more that I‚Äôm not always willing to pay the cost or deal with the complexity of running it on every single query. In practice, when semantic does kick in ‚Äì lexical confidence is low, results are weak, or the query is clearly more abstract ‚Äì I do pretty much what you described. I run semantic alongside FTS, merge the candidates, then rerank.\n\nAlways-on semantic can work great if your infra can handle it and your domain benefits from it. But honestly, in more entity-heavy setups, I‚Äôve seen it add noise or make things harder to debug. I‚Äôve had better luck gating it behind a simple confidence check instead of making it the default.\n\nCurious what kind of domain you're working in. Are you seeing consistent gains from always merging and reranking, or are you using some kind of adaptive setup too?",
                  "score": 1,
                  "created_utc": "2026-02-06 20:42:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3kuy2i",
          "author": "metaphorm",
          "text": "my view is that RAG is still a highly relevant technique and the problems it has with accuracy are the current leading edge of LLM application development. agent memory might be a good approach for some classes of problems. \"deep\" agents might be another approach that works, i.e. an agent that has access to tools that allow it to introspect its own results. ",
          "score": 6,
          "created_utc": "2026-02-04 18:54:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3l78ss",
              "author": "techhead57",
              "text": "Its a tool in the toolbox. When LLMs came out rag was the only tool. Now there are all kinds of interfaces being hooked up to them and RAG has all kinds of fancy alternatives that are basically trying to do the same thing but better. And models are getting better at using this kind of input context because theyre being trained with tools use now.",
              "score": 5,
              "created_utc": "2026-02-04 19:51:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3k3xuy",
          "author": "Fragrant_Western4730",
          "text": "I don‚Äôt know about the rest of it, but I definitely experienced the shortcomings of RAG for searching documents. Cool thought. Interested to hear what people think about this. Upvoted.",
          "score": 2,
          "created_utc": "2026-02-04 16:51:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3kg1c3",
              "author": "Normal_Sun_8169",
              "text": "Thanks!",
              "score": 1,
              "created_utc": "2026-02-04 17:47:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3kerpl",
          "author": "onetimeiateaburrito",
          "text": "I dunno man. I've spent a little bit trying to get a [RAPTOR](https://arxiv.org/abs/2401.18059) style system going and maybe it'll be cool? Who knows. I'm not a programmer and have no background in CS or ML. Just arguing with myself and Claude until something does something without spitting error codes. Then doing the same thing to see what's silently failing.",
          "score": 2,
          "created_utc": "2026-02-04 17:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l5qqf",
          "author": "WolfeheartGames",
          "text": "The problem is retrieval. How is the agent supposed to know what I'd available for lookup? It must be told.\n\nLet's say we have a list of things the agent can retrieve. If we give it to the agent it will hyper fixate on this and it causes new failure modes.\n\nSo then we need to monitor the inputs and outputs and see if we should be injecting information from retrieval in to the context window. This requires a signal of some kind. Either LLM, BERT, or otherwise.",
          "score": 2,
          "created_utc": "2026-02-04 19:44:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mgzqd",
              "author": "ai-tacocat-ia",
              "text": "It's really just a taxonomy problem. Is easy to think of it like a file system. \"Tell me what folders are in the current directory. I want to see the files and subfolders in this list of directories. Now show me what's in these subdirs.\"\n\nAlso, \"show me the paths of files whose contents contain these search terms\". Then let the LLM list the files it wants to pull.\n\nObviously doesn't need to be files - can be categories, subcategories, filter by tags, etc. Basically, give LLMs the same tools you enjoy as a human to find things.",
              "score": 1,
              "created_utc": "2026-02-04 23:38:39",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3mnmdb",
                  "author": "WolfeheartGames",
                  "text": "That is not how real deployments usually work. It's okay for like a call center bot where the company will invest a lot in the docs for a RAG, but even then it's not enough. How does it know that a question is even contained in its RAG? How does it know how to search for it if the user gives terrible keywords, how does it know if should look elsewhere? It's not a listable directory to explore to gain insight from, and that's the problem. The agent only knows whats in it's system prompt until it's found something, and then it's still ignorant about potentially other useful things it didn't find. This breaks down further when data is less organized, like code or loose pdfs\n\nBut the fact that you're comparing RAG lookup to a directory is concerning. Vector and graph databases do not work like that at all. The problem of retrieval is partially because they don't work like that.",
                  "score": 1,
                  "created_utc": "2026-02-05 00:15:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3liewe",
          "author": "DataCentricExpert",
          "text": "RAG isn‚Äôt dead, it‚Äôs just being asked to do too much.  \ngents break when you expect retrieval to behave like memory. What replaces it isn‚Äôt ‚Äúbetter RAG,‚Äù it‚Äôs layered memory...AG becomes infrastructure, not the strategy.",
          "score": 2,
          "created_utc": "2026-02-04 20:45:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lmpd1",
          "author": "xFloaty",
          "text": "every time your agent calls a tool to search for context, it‚Äôs RAG",
          "score": 2,
          "created_utc": "2026-02-04 21:05:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3nbxi9",
          "author": "hettuklaeddi",
          "text": "dead?!? RAG doesn‚Äôt even have the sniffles \n\nmaybe it‚Äôs dead to script kiddies, that‚Äôs fine",
          "score": 2,
          "created_utc": "2026-02-05 02:33:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3kz4oq",
          "author": "fabkosta",
          "text": "Downvoted. We had enough \"RAG is dead\" posts here. It's getting silly.",
          "score": 4,
          "created_utc": "2026-02-04 19:13:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l6m4k",
          "author": "AdOwn10",
          "text": "Ya the RAG people changed what ‚ÄúRAG‚Äù means so RAG isn‚Äôt dead. Vector database? No! We are not talking about ALL ways you get retrieve information to augment a context window.",
          "score": 2,
          "created_utc": "2026-02-04 19:48:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mc77z",
          "author": "andrew_kirfman",
          "text": "Rag isn‚Äôt 100% dead, but it‚Äôs definitely been impacted by agentic search and agent skills getting so good.  \n\nI only use semantic search for dart at a dartboard type searches.  Everything else is agentic search.",
          "score": 2,
          "created_utc": "2026-02-04 23:12:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3obzoo",
              "author": "Visionexe",
              "text": "What is Agentic search?",
              "score": 1,
              "created_utc": "2026-02-05 06:38:38",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3klpky",
          "author": "vagobond45",
          "text": "Knowledge Graphs combined with Answer Rag Audit should replace RAG",
          "score": 1,
          "created_utc": "2026-02-04 18:13:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l5cw1",
          "author": "Miclivs",
          "text": "Agentic search works really well when the agent knows what to look for.",
          "score": 1,
          "created_utc": "2026-02-04 19:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l9lk3",
          "author": "llOriginalityLack367",
          "text": "Mean pooling.\n\nMean pooling.\n\nMean pooling.",
          "score": 1,
          "created_utc": "2026-02-04 20:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3mc5ln",
          "author": "Flat_Dependent3195",
          "text": "Can you share the link for the paper you mentioned?",
          "score": 1,
          "created_utc": "2026-02-04 23:11:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3n8d42",
          "author": "New-Unit-3900",
          "text": "Properly structured ontologies",
          "score": 1,
          "created_utc": "2026-02-05 02:12:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nrac8",
              "author": "smm_h",
              "text": "like what",
              "score": 1,
              "created_utc": "2026-02-05 04:05:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3nhjmt",
          "author": "GoodEnoughSetup",
          "text": " In my experience, database solutions like ScyllaDB can definitely be part of a broader strategy to replace RAG. By incorporating a database for fast access to relevant data, you might enhance the context in which generative models operate, similar to how semantic memory aims to streamline information retrieval. Have you looked into any specific frameworks that could mesh well with that approach?",
          "score": 1,
          "created_utc": "2026-02-05 03:04:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3o8gid",
          "author": "fooz42",
          "text": "It's a garbage in, garbage out problem. You can reduce the surface area of the generation to something very small in scope, or you can increase the quality of the included information in the context to improve the summary.",
          "score": 1,
          "created_utc": "2026-02-05 06:08:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3objra",
          "author": "iAM_A_NiceGuy",
          "text": "Compression",
          "score": 1,
          "created_utc": "2026-02-05 06:34:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3p6ujg",
          "author": "sje397",
          "text": "I've got RAG, 'sticky' memories scoped as global or conversation specific, and 'notes' as a tool. Each suits different use cases. Seems to work pretty well in combination for my 'assistant'.",
          "score": 1,
          "created_utc": "2026-02-05 11:25:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q8flh",
          "author": "airylizard",
          "text": "‚ÄúRAG‚Äù is semantic search. You ‚ÄúAI people‚Äù have been inventing new terms to describe basic automation tools and practices for years",
          "score": 1,
          "created_utc": "2026-02-05 15:15:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3q8lgv",
          "author": "exids",
          "text": "RAG is awesome, not dead and is still in its infancy as agent models improve. Who says it's dead?!?!?",
          "score": 1,
          "created_utc": "2026-02-05 15:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tdhbc",
          "author": "Former-Ad-5757",
          "text": "Stupid click-once RAGging (in the meaning of simple semantic searching) is dead but to me it has never really existed.\n\nIf you setup a default vector db with chunking of 200, and you feed it documents of on average 600, what do you really suspect will happen? At best it will feed half-truncated garbage to the llm.\n\n  \nIn all RAG setups I have setup the absolute minimal chunking was 64kb, because I don't believe chunking is a fixed number, it is completely dependent on if the chunk completely describes the info, you can define info as a sentence, or a paragraph (or for coding for example a method) but I have almost never encountered a situation where all the meaning was captured in 200. Just use overlaps is what some tuts say, well great now you add more half-meanings which pollute your retrieval results more.",
          "score": 1,
          "created_utc": "2026-02-06 00:22:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3th44g",
          "author": "cmndr_spanky",
          "text": "Oh look. It‚Äôs the daily ‚Äúrag is dead‚Äù bot post.  Oh look here‚Äôs a fancy memory solution for agents (still an adaptation of rag). \n\nWould you mind thinking more deeply (or maybe search Reddit for 15secs) before vomiting out the next hapless low effort contribution to the cesspool of AI subreddits ? K thanks",
          "score": 1,
          "created_utc": "2026-02-06 00:43:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ttwqq",
          "author": "Academic_Track_2765",
          "text": "It‚Äôs dead, it dies everyday according to some guru. There are so many flavors of rag but somehow it‚Äôs still dead lol.",
          "score": 1,
          "created_utc": "2026-02-06 01:59:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ub68t",
          "author": "TenshiS",
          "text": "RAG is far from dead",
          "score": 1,
          "created_utc": "2026-02-06 03:43:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v0mz0",
          "author": "OkFly3388",
          "text": "Most \"memory\" systems for llm agents is actually rag. So it dont dead, it just replaced with more fancy word.",
          "score": 1,
          "created_utc": "2026-02-06 06:52:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o419bcl",
          "author": "Analytics-Maken",
          "text": "Naive vectoronly RAG over chunked documents fails to scale as agent memory, producing poor retrieval for complex queries and lacking structure for structured knowledge.‚Äã It happens because embeddings capture semantics but ignore relational structure, metadata, and versioning.\n\nThe fix uses hybrid retrieval FTS/keyword first, then vectors as fallback, merged and reranked with embeddings as versioned artifacts (tied to source hash and model version) to avoid silent drift; layer in structured state from warehouses for granularity and joins, plus episodic logs for agent feedback loops.\n\nThis creates memory surfaces for agents to query without overload. Windsor.ai pipelines normalize data into BigQuery/Snowflake/PostgreSQL, handling schema drift automatically, then expose them via Windsor MCP as tools in Claude/ChatGPT for semantic vs. structured memory access.",
          "score": 1,
          "created_utc": "2026-02-07 05:28:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o43falv",
          "author": "Fresh_Sock8660",
          "text": "Retrieval augmentation isn't going away anytime soon. Maybe you're thinking of a specific application.",
          "score": 1,
          "created_utc": "2026-02-07 15:40:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45avpx",
          "author": "satechguy",
          "text": "RAG is dead, again?",
          "score": 1,
          "created_utc": "2026-02-07 21:23:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o45bm3t",
          "author": "MissJoannaTooU",
          "text": "RAG is very much alive. We will always need retrieval.",
          "score": 1,
          "created_utc": "2026-02-07 21:26:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47ncff",
          "author": "HealthyCommunicat",
          "text": "RAG is super useful for turning dumber models into something useful by just having that pipeline of example data to use, so no, RAG is not dead and most likely will not be dead until some newer form of being able to link data to a model thats much more easier and more efficient. Just 2 weeks ago I had a client project using a 30b model as a base but being able to do so much specific jobs for the client specifically because of all the Q&A and all the massive amount of instructions and info specific only to this company.",
          "score": 1,
          "created_utc": "2026-02-08 06:28:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3l4jqo",
          "author": "Able_Penalty8856",
          "text": "I also got frustrated with RAG. My plan is to study Unsloth to explore fine-tuned models. I'm aware that I'll likely face several challenges.",
          "score": 0,
          "created_utc": "2026-02-04 19:39:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3oeyq1",
              "author": "Pixelmixer",
              "text": "This simply isn‚Äôt possible for a lot of workflows. As a super simple toy example; imagine you want to search text comments posted by users and provide that to an LLM. Fine-tuning could potentially work as a first pass (let‚Äôs also assume that the fine-tuned model has perfect retrieval for the purpose of this example), but even then you‚Äôd need to retrain it each time a user posts a new comment or changes their comment. It‚Äôs just too much, unfortunately.",
              "score": 1,
              "created_utc": "2026-02-05 07:04:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qul18d",
      "title": "NotebookLM For Teams",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/b85n399898hg1",
      "author": "Uiqueblhats",
      "created_utc": "2026-02-03 06:56:00",
      "score": 42,
      "num_comments": 3,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qul18d/notebooklm_for_teams/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3axdaf",
          "author": "Otherwise_Wave9374",
          "text": "This looks like a great niche community. The \"agents that act, not just chat\" framing is exactly the right line to draw.\n\nIf you end up pinning a starter guide, I would include basics like tool permissioning, memory vs no-memory defaults, and how to keep agent loops bounded so people do not burn tokens endlessly.\n\nI have a few writeups on agent guardrails and patterns here: https://www.agentixlabs.com/blog/",
          "score": 3,
          "created_utc": "2026-02-03 07:07:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3jnqad",
          "author": "tsquig",
          "text": "Similar flexibility here with uploading / source inputs, but a few more options to generate outputs. [NotebookLM but for business](https://implicit.cloud).",
          "score": 1,
          "created_utc": "2026-02-04 15:37:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3gwyij",
          "author": "DAlmighty",
          "text": "They have also been doing crazy advertising on Reddit. You‚Äôd think that they would just pay the platform for the opportunity already.",
          "score": 1,
          "created_utc": "2026-02-04 03:45:22",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qsw6tg",
      "title": "We are not the same",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/glett1s5dvgg1.png",
      "author": "alvinunreal",
      "created_utc": "2026-02-01 11:35:03",
      "score": 40,
      "num_comments": 7,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qsw6tg/we_are_not_the_same/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o2yj0zt",
          "author": "brightheaded",
          "text": "A crumb of context sir",
          "score": 8,
          "created_utc": "2026-02-01 12:16:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o2yo43w",
              "author": "HumanDrone8721",
              "text": "Or a crust of context.",
              "score": 5,
              "created_utc": "2026-02-01 12:54:54",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o2yo5kf",
              "author": "Mythril_Zombie",
              "text": "Apparently something is different from something else.",
              "score": 2,
              "created_utc": "2026-02-01 12:55:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o30ca32",
          "author": "megatronus8010",
          "text": "How does the craber news work",
          "score": 1,
          "created_utc": "2026-02-01 18:02:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o30f83c",
              "author": "alvinunreal",
              "text": "It's in sync with HackerNews submission - when someone submits there, it appears on crabbernews.\n\nBut difference is on HackerNews humans upvote, comment and discuss; on Crabbernews it's upto AI models.\n\nThis makes \"top\" posts different; For example are humans biased towards certain types of news or now...\n\nThat's the goal of this website, I'm currently adding core models to review new posts, and decide which to upvote but anyone can connect their openclaw agents too to participate.",
              "score": 3,
              "created_utc": "2026-02-01 18:15:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o353kdv",
                  "author": "germo20",
                  "text": "I think many of us would appreciate having this comment in the actual post, instead of just a comment.",
                  "score": 3,
                  "created_utc": "2026-02-02 11:57:47",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o30nkzk",
          "author": "Ladder-Bhe",
          "text": "AGENTSÔºåPlease include historical messages when speaking, so we can see how this idea was generated, rather than the result of human intervention.",
          "score": 1,
          "created_utc": "2026-02-01 18:52:26",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1quxgq9",
      "title": "8 Ways OpenClaw Reduces Context Loss in Long-Running Agents",
      "subreddit": "LLMDevs",
      "url": "https://codepointer.substack.com/p/openclaw-stop-losing-context-8-techniques",
      "author": "noninertialframe96",
      "created_utc": "2026-02-03 17:01:02",
      "score": 18,
      "num_comments": 1,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1quxgq9/8_ways_openclaw_reduces_context_loss_in/",
      "domain": "codepointer.substack.com",
      "is_self": false,
      "comments": [
        {
          "id": "o3hsmig",
          "author": "gtek_engineer66",
          "text": "Interesting",
          "score": 1,
          "created_utc": "2026-02-04 07:45:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qxa658",
      "title": "Built a Website Crawler + RAG (fixed it last night üòÖ)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qxa658/built_a_website_crawler_rag_fixed_it_last_night/",
      "author": "Cod3Conjurer",
      "created_utc": "2026-02-06 06:28:18",
      "score": 13,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm **new to RAG** and learning by building projects.  \nAlmost **2 months ago** I made a very simple RAG, but the **crawler & ingestion were hallucinating**, so the answers were bad.\n\nYesterday night (after office stuff üíª), I thought:  \nEveryone is feeding PDFs‚Ä¶ **why not try something that‚Äôs not PDF ingestion?**\n\nSo I focused on fixing the **real problem ‚Äî crawling quality**.\n\nüîó GitHub: [https://github.com/AnkitNayak-eth/CrawlAI-RAG](https://github.com/AnkitNayak-eth/CrawlAI-RAG)\n\n**What‚Äôs better now:**\n\n* Playwright-based crawler (handles JS websites)\n* Clean content extraction (no navbar/footer noise)\n* Smarter chunking + deduplication\n* RAG over **entire websites**, not just PDFs\n\nBad crawling = bad RAG.\n\nIf you all want, **I can make this live / online** as well üëÄ  \nFeedback, suggestions, and ‚≠ês are welcome!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qxa658/built_a_website_crawler_rag_fixed_it_last_night/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o42m8nd",
          "author": "dezastrologu",
          "text": "AI slop post\n\nBut the tool sounds cool. Vibe coded?",
          "score": 1,
          "created_utc": "2026-02-07 12:54:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o445f1w",
              "author": "Cod3Conjurer",
              "text": "Kinda but not really¬†\nSome rough edges for sure, but the crawler logic and pipeline were intentionally built. Still learning and iterating.¬†",
              "score": 2,
              "created_utc": "2026-02-07 17:48:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qxbr2z",
      "title": "today's task",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/ggk43gavzthg1.jpeg",
      "author": "carsa81",
      "created_utc": "2026-02-06 08:02:13",
      "score": 13,
      "num_comments": 3,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qxbr2z/todays_task/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3vayfa",
          "author": "West_Struggle2530",
          "text": "Opus 4.6",
          "score": 7,
          "created_utc": "2026-02-06 08:27:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o410o0h",
          "author": "mosquitosarenotcool",
          "text": "Kimi 2.5",
          "score": 1,
          "created_utc": "2026-02-07 04:24:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ziioq",
          "author": "Clean_Moose6832",
          "text": "Codex 5.3 is superior. ",
          "score": 0,
          "created_utc": "2026-02-06 22:52:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qviqlh",
      "title": "How to become an AI Engineer in 2026 - what actually matters now?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qviqlh/how_to_become_an_ai_engineer_in_2026_what/",
      "author": "DarfleChorf",
      "created_utc": "2026-02-04 08:05:16",
      "score": 11,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "Trying to map out a realistic path into AI engineering and getting overwhelmed by contradictory advice.\n\nPython is still non-negotiable, but the \"just build a chatbot\" project approach doesn't cut it anymore. The market looks brutal for entry-level while senior roles are paying crazy money. Prompt engineering as a dedicated job seems dead, but the skill still matters. RAG, agentic AI, and MLOps seem to be where the growth is.\n\nThe part confusing me is traditional ML (sklearn, training models) vs pure LLM/API integration. Some say you need fundamentals, others say most jobs are just orchestrating existing models. With tools like Claude Code changing what coding even means, I'm not sure what skills are actually durable.\n\nFor people who've done this or are hiring:\n\n- What actually separated you from other candidates when you got in?\n- How much traditional ML do you use day-to-day vs LLM orchestration?\n- Best resources that actually helped you, not just ones you heard were good?\n- What does this role even look like in 2027 when agents do more of the work?\n\nNot looking for a generic roadmap. Looking for what's actually working right now.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qviqlh/how_to_become_an_ai_engineer_in_2026_what/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3kxegl",
          "author": "Number4extraDip",
          "text": "What matters. Solving a specific problem. Being very specific and not just doing what everyone else is doing",
          "score": 6,
          "created_utc": "2026-02-04 19:05:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3mrjp9",
              "author": "bbahner",
              "text": "Can you be more specific? <grin>",
              "score": 4,
              "created_utc": "2026-02-05 00:36:52",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3nebra",
                  "author": "Number4extraDip",
                  "text": "Make something you wish existed. Make a product for yourself that no one is selling.",
                  "score": 2,
                  "created_utc": "2026-02-05 02:46:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o3lcedg",
          "author": "hrishikamath",
          "text": "Honestly most roles I have interviewed for have had AI in requirements but interviews were SWE stuff: system design, leetcode style and so on. Most but not all. During interviews I did speak about my projects that‚Äôs about it and some questions here and there. Yeah it‚Äôs more of just building agents for a lot of them. Traditional ML stuff is required by certain niche  companies. Certain companies randomly add its good to have fine tuning experience. But, yeah some companies develop their models for that you need solid fundamentals from ground up.",
          "score": 4,
          "created_utc": "2026-02-04 20:16:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3lelk4",
          "author": "Canadianingermany",
          "text": ">Some say you need fundamentals, others say most jobs are just orchestrating existing models.  \n\n\nMost things that people are doing today are probably quite easy, and many are working on small problems that can probably be solved with some API and some prompt engineering.  \n\n  \nBut I'm not so convinced that in the future people will want to pay a full fledged DS wage for that because the barriers to entry are simply quite low.  \n\n  \nSo strategically I would concentrate on harder problems that need more than throw an LLM at it.  \n\n  \nBut what do I know?  I hire devs, I'm not one.\n\n>  \nI'm not sure what skills are actually durable.\n\nAt the end of the day.  The ability to solve problems and not be locked in to the solution that worked last time, but find the one for this problem.\n\n  \n",
          "score": 2,
          "created_utc": "2026-02-04 20:26:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3nqzgg",
              "author": "hrishikamath",
              "text": "Not really building good rag systems or tasks that require lot of context requires good understanding and skills",
              "score": 1,
              "created_utc": "2026-02-05 04:03:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3oktgf",
          "author": "MediumShoddy5264",
          "text": "ML is not useful right now, you need to understand tool calling, context management, planning, evals, etc... ",
          "score": 2,
          "created_utc": "2026-02-05 07:58:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3pui56",
              "author": "MullingMulianto",
              "text": "can you elaborate what you mean by ML. do you mean decision trees, classifiers, etc.?",
              "score": 1,
              "created_utc": "2026-02-05 14:01:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o3p6o4l",
          "author": "KegOfAppleJuice",
          "text": "A big emphasis is on cloud engineering, LLM evals and observability and creating quality data context for agents.",
          "score": 2,
          "created_utc": "2026-02-05 11:23:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3qk2x4",
          "author": "Fragrant_Western4730",
          "text": "I've been working on Slack-based agents lately that need to handle open ended tasks from users. I'm pretty convinced agent memory is going to become a must-have skill for any AI engineer that wants to build agents that are more than just workflows or chatbots, especially as adaptive memory and agent learning keeps improving. I won my last two clients by putting my agent in Slack and calling it an AI employee and showing very rudimentary learning and memory.",
          "score": 2,
          "created_utc": "2026-02-05 16:09:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3quk4m",
              "author": "MAX7668",
              "text": "I guess I'm out of the loop. What do you mean by adaptive memory?",
              "score": 2,
              "created_utc": "2026-02-05 16:58:03",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o3qv9b3",
                  "author": "Fragrant_Western4730",
                  "text": "It's this idea that your agents can have some sort of self-evolving mechanism to learn over time. A simple case would be user preferences, but the more interesting area is in automations and tool calling. Having agents learn what tools to call to solve tasks without needing to tune prompts over and over. I'm using Hindsight for this in the Slack agents I mentioned.",
                  "score": 2,
                  "created_utc": "2026-02-05 17:01:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qtgszg",
      "title": "Drowning in 70k+ papers/year. Built an open-source pipeline to find the signal. Feedback wanted.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qtgszg/drowning_in_70k_papersyear_built_an_opensource/",
      "author": "Real-Cheesecake-8074",
      "created_utc": "2026-02-02 01:08:40",
      "score": 11,
      "num_comments": 5,
      "upvote_ratio": 0.99,
      "text": "Like many of you, I'm struggling to keep up. With over 80k AI papers published last year on arXiv alone, my RSS feeds and keyword alerts are just noise. I was spending more time filtering lists than reading actual research.\n\nTo solve this for myself, a few of us hacked together an open-source pipeline (\"Research Agent\") to automate the pruning process. We're hoping to get feedback from this community on the ranking logic to make it actually useful for researchers.\n\n**How we're currently filtering:**\n\n* **Source:**¬†Fetches recent arXiv papers (CS.AI, CS.ML, etc.).\n* **Semantic Filter:**¬†Uses embeddings to match papers against a specific natural language research brief (not just keywords).\n* **Classification:**¬†An LLM classifies papers as \"In-Scope,\" \"Adjacent,\" or \"Out.\"\n* **\"Moneyball\" Ranking:**¬†Ranks the shortlist based on author citation velocity (via Semantic Scholar) + abstract novelty.\n* **Output:**¬†Generates plain English summaries for the top hits.\n\n**Current Limitations (It's not perfect):**\n\n* Summaries can hallucinate (LLM randomness).\n* Predicting \"influence\" is incredibly hard and noisy.\n* Category coverage is currently limited to CS.\n\n**I need your help:**\n\n1. If you had to rank papers automatically, what signals would¬†*you*¬†trust? (Author history? Institution? Twitter velocity?)\n2. What is the biggest failure mode of current discovery tools for you?\n3. Would you trust an \"agent\" to pre-read for you, or do you only trust your own skimming?\n\nThe tool is hosted here if you want to break it:¬†[https://research-aiagent.streamlit.app/](https://research-aiagent.streamlit.app/)\n\nCode is open source if anyone wants to contribute or fork it.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qtgszg/drowning_in_70k_papersyear_built_an_opensource/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o346bh4",
          "author": "PerceptualDisruption",
          "text": "Awesome",
          "score": 1,
          "created_utc": "2026-02-02 06:52:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3umq47",
          "author": "Ok-Owl-7515",
          "text": "This is a fantastic direction ‚Äî the challenge is avoiding ‚Äúranking theater‚Äù and making sure the shortlist is actually auditable. A few thoughts on your three questions:\n\n1) Ranking signals I‚Äôd trust (and how I‚Äôd weight them):\nFirst and foremost: relevance to the brief should carry the most weight ‚Äî and be explainable. I‚Äôd use lexical/FTS + embeddings, then rerank, but also show why each paper matched (e.g., key terms, nearest passages).\nThen, layer in harder-to-game utility signals:\n\n- Artifact availability: code, data, model cards, reproducibility details, ablations ‚Äî a strong early signal.\n\n- Method clarity: does the abstract and intro clearly state what‚Äôs new compared to prior work?\n\n- ‚ÄúIncremental vs step-change‚Äù tags: categorize papers as ‚Äúnew technique,‚Äù ‚Äúnew scale,‚Äù ‚Äúnew dataset,‚Äù ‚Äúnew eval,‚Äù etc.\n\n- Venue/track/peer review: light weight, but still helpful.\n\n- Citations / author velocity: useful but laggy and susceptible to the Matthew effect. I‚Äôd assign it low weight early on, then increase it over time.\n\n- Social signals (BlueSky/Reddit): very low weight ‚Äî more for surfacing discussion than signaling quality.\n\nKey thing: expose a per-paper score breakdown (relevance vs novelty vs credibility vs artifacts), so users can tune it and you can debug it.\n\n2) Biggest failure mode of discovery tools (for me):\nNo eval harness + no drift control. Results quietly change when you adjust prompts, embeddings, or filters ‚Äî and there‚Äôs no way to know if it improved. Even a tiny labeled set (‚Äúthis is in-scope / adjacent / out‚Äù) + offline metrics (NDCG, MRR) makes a huge difference.\nSecond issue: summaries that don‚Äôt point back to where the claim was made ‚Äî hard to trust without grounding.\n\n3) Would I trust an agent to pre-read?\nYes ‚Äî as long as it acts like a triage assistant, not an oracle. What I‚Äôm looking for:\n\n- Clear evidence pointers (quotes or section references)\n- Uncertainty indicators (‚ÄúI didn‚Äôt find X in the paper‚Äù)\n- A quick rationale for why it matched the brief\n- One-click jump to the specific paragraph(s)\n\nThen I can do the final skim.\n\nAlso, to reduce hallucinations: lean into extract-then-summarize. Pull key sentences and cite them before paraphrasing. Even better if you include the extracted spans in the output to verify quickly.\n\nIf you‚Äôre open to it ‚Äî do you already log per-stage diagnostics (retrieval backend used, hit counts, scores, latency)? And is indexing stored as a reproducible derived artifact? That‚Äôs the kind of thing that really helps keep systems like this maintainable long-term.",
          "score": 1,
          "created_utc": "2026-02-06 05:02:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3x153j",
              "author": "Real-Cheesecake-8074",
              "text": "This is fantastic feedback. Passed this to the team maintaining the application. If you're interested in joining our open source group for this let me know! :) I especially love your trust mechanism with clear explainability of results.",
              "score": 2,
              "created_utc": "2026-02-06 15:36:37",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3x4dx9",
                  "author": "Ok-Owl-7515",
                  "text": "Appreciate it ‚Äì glad it was helpful. I‚Äôm pretty tied up right now (full-time job and two toddlers), so I don‚Äôt think I could commit to joining an OSS project at the moment.\n\nThat said, the trust and explainability angle is actually a big focus in a separate pipeline project I‚Äôm working on ‚Äî deterministic runs, versioned derived indexes, and evidence pointers or ‚Äúreceipts‚Äù to make outputs auditable.\n\nFeel free to DM me if you want targeted feedback on ranking logic or the pre-read UX ‚Äî I‚Äôm happy to do occasional drive-by reviews when I‚Äôve got a window.",
                  "score": 1,
                  "created_utc": "2026-02-06 15:52:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qwpdkz",
      "title": "ACE-Step 1.5: an on-device music model that beats Suno on common eval metrics",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/v0sqp0rh8phg1",
      "author": "MatchSuccessful1253",
      "created_utc": "2026-02-05 16:09:10",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qwpdkz/acestep_15_an_ondevice_music_model_that_beats/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3shdm9",
          "author": "TheGoddessInari",
          "text": "Odd distinctive sound to everything on the site. ü§î",
          "score": 1,
          "created_utc": "2026-02-05 21:33:39",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwx950",
      "title": "Built an LLM agent for debugging production incidents - what we learned",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/y5lvd0tznqhg1",
      "author": "Useful-Process9033",
      "created_utc": "2026-02-05 20:53:02",
      "score": 10,
      "num_comments": 9,
      "upvote_ratio": 0.86,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qwx950/built_an_llm_agent_for_debugging_production/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o3tj3cq",
          "author": "isthatashark",
          "text": "Cool project!",
          "score": 1,
          "created_utc": "2026-02-06 00:55:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3tsvjh",
              "author": "Useful-Process9033",
              "text": "Thank you!",
              "score": 1,
              "created_utc": "2026-02-06 01:53:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o3w22p3",
          "author": "Gerifico",
          "text": "Super interesting!",
          "score": 1,
          "created_utc": "2026-02-06 12:24:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3ybgq9",
          "author": "jlebensold",
          "text": "This is a very cool idea! Have you tried connecting it to your github to access the codebase? ",
          "score": 1,
          "created_utc": "2026-02-06 19:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3ybqck",
              "author": "Useful-Process9033",
              "text": "yes! it connects to github so that it has more context when debugging stuff",
              "score": 1,
              "created_utc": "2026-02-06 19:17:20",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o3yc5bn",
                  "author": "jlebensold",
                  "text": "nice! I've been pretty blown away at the connection between SWE-Bench style tasks and what an agent can do with log data. We actually built an agent that will parse langfuse trace agents and identify cost savings using a similar technique. ",
                  "score": 1,
                  "created_utc": "2026-02-06 19:19:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qv6w28",
      "title": "I‚Äôm building an open-source local AI agent in Go that uses IR + tools instead of wasting tokens",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qv6w28/im_building_an_opensource_local_ai_agent_in_go/",
      "author": "iagomussel",
      "created_utc": "2026-02-03 22:46:21",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "Hey everyone,\n\nI‚Äôve been working on an open-source project called **IRon**: a local-first AI assistant focused on automation, not chat.\n\nThe main idea is:\n\nInstead of using LLMs to ‚Äúthink‚Äù and generate long text, IRon translates user input into a small structured format (IR ‚Äì Intermediate Representation) and executes real tools.\n\nSo most tasks don‚Äôt need heavy models.\n\n# What it does\n\nIRon works mainly through Telegram and runs locally.\n\nPipeline:\n\nUser ‚Üí Router ‚Üí (optional LLM) ‚Üí IR (JSON) ‚Üí Tools ‚Üí Result\n\nFeatures:\n\n* Deterministic router for common tasks (notes, lists, commands, etc.)\n* Dual output: short human reply + machine IR\n* Tool system (shell, docker, http, code exec, notes, scheduler, addons)\n* Cron-based scheduler\n* Codex/Ollama support for complex reasoning\n* Session isolation per chat\n* Addon system for external tools/adapters\n\n# Why I built it\n\nMost ‚ÄúAI assistants‚Äù today:\n\n* Burn tokens on simple things\n* Re-explain everything\n* Don‚Äôt integrate well with real systems\n* Lose context easily\n\nI wanted something closer to:\n\n‚ÄúNatural language ‚Üí compact instruction ‚Üí real execution‚Äù\n\nLike a mix of:\n\n* cron\n* Makefile\n* shell\n* and LLMs\n\nBut with safety and structure.\n\n# Example\n\nUser:  \n‚ÄúRemind me to pay rent tomorrow at 9‚Äù\n\nIRon:\n\n* Generates IR\n* Schedules cron\n* Uses scheduler tool\n* Confirms in one line\n\nNo long explanation. No wasted tokens.\n\n# Tech stack\n\n* Go\n* Telegram Bot API\n* Codex CLI / Ollama (future)\n* JSON-based IR\n* robfig/cron\n* Plugin system\n\nCurrent status\n\nIt‚Äôs usable and evolving.  \nMain focus now:\n\n* DSL for tasks\n* Better scheduling\n* Memory without huge context\n* More deterministic routing\n\n**It's in progress, so there are bugs yet, let me know if you can help.**\n\n# Repo\n\n[https://github.com/iagomussel/IRon](https://github.com/iagomussel/IRon?utm_source=chatgpt.com)\n\n# Looking for feedback\n\nI‚Äôm interested in feedback on:\n\n* Architecture\n* IR format\n* DSL ideas\n* Similar projects\n* Security concerns\n\nIf you‚Äôre into local AI, automation, or agent systems, I‚Äôd love your thoughts.\n\nThanks üôå",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qv6w28/im_building_an_opensource_local_ai_agent_in_go/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3g2vcj",
          "author": "DataCentricExpert",
          "text": "Do you have a sandboxed or local dev environment for testing IRon safely with real data, or is it purely the Telegram interface right now?",
          "score": 1,
          "created_utc": "2026-02-04 00:53:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g6ivm",
          "author": "SeaworthinessThis598",
          "text": "I want to get. afeel about the IR concept efficacy can you show us. a demo maybe ?",
          "score": 1,
          "created_utc": "2026-02-04 01:13:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3fite7",
          "author": "Otherwise_Wave9374",
          "text": "Love the ‚ÄúIR + tools‚Äù approach. That feels like a practical agent design: keep the LLM for the hard parsing/planning edges, but push everything into a constrained representation so execution stays predictable.\n\nHow are you thinking about schema evolution for the IR and safety around tool permissions (per chat/session)? Those two things seem to make or break local agents. Ive been reading a bunch about structured agents lately, this page has some good notes: https://www.agentixlabs.com/blog/",
          "score": 1,
          "created_utc": "2026-02-03 23:04:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qyimtf",
      "title": "Grounding Is Not a Prompt",
      "subreddit": "LLMDevs",
      "url": "https://substack.com/home/post/p-187075330",
      "author": "SeriousSir1148",
      "created_utc": "2026-02-07 16:45:11",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qyimtf/grounding_is_not_a_prompt/",
      "domain": "substack.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qsyhfi",
      "title": "Operating an LLM as a constrained decision layer in a 24/7 production system",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qsyhfi/operating_an_llm_as_a_constrained_decision_layer/",
      "author": "NationalIncome1706",
      "created_utc": "2026-02-01 13:29:29",
      "score": 7,
      "num_comments": 19,
      "upvote_ratio": 0.82,
      "text": "I‚Äôm an engineer by background (14+ years in aerospace systems),  \nand recently I‚Äôve been running a **24/7 always-on production system** that uses an LLM as a *constrained decision-making component*.\n\nThe specific application happens to be automated crypto trading,  \nbut this post is **not** about strategies, alpha, or performance.\n\nIt‚Äôs about a more general systems problem:\n\n>\n\n# System context (high-level)\n\n* **Runtime:** always-on, unattended, 24/7\n* **Environment:** small edge device (no autoscaling, no human in the loop)\n* **Decision model:** discrete, time-gated decisions\n* **Failure tolerance:** low ‚Äî incorrect actions have real cost\n\nThe system must continue operating safely even when:\n\n* external APIs are unreliable\n* the LLM produces malformed or inconsistent outputs\n* partial data or timing mismatches occur\n\n# How the LLM is used (and how it is not)\n\nThe LLM is **not** used for prediction, regression, or forecasting.\n\nIt is treated as a **bounded decision layer**:\n\n* It receives only *preprocessed, closed-interval data*\n* It must output exactly one of:\n   * `ENTRY`\n   * `HOLD`\n   * `CLOSE`\n\nThere are no confidence scores, probabilities, or free-form reasoning  \nthat directly affect execution.\n\nIf the response cannot be parsed, times out, or violates the expected format  \n‚Üí **the system defaults to doing nothing**.\n\n# Core design principles\n\n# 1. Decisions only occur at explicit, closed boundaries\n\nThe system never acts on streaming or unfinished data.\n\nAll decisions are gated on **closed time windows**.  \nThis eliminated several classes of failure:\n\n* phantom actions caused by transient states\n* rapid oscillation near thresholds\n* overlapping execution paths\n\nIf the boundary is not closed, the system refuses to act.\n\n# 2. ‚ÄúDo nothing‚Äù is the safest default\n\nThe system is intentionally biased toward inaction.\n\n* API error ‚Üí HOLD\n* LLM timeout ‚Üí HOLD\n* Partial or inconsistent data ‚Üí HOLD\n* Conflicting signals ‚Üí HOLD\n\nIn ambiguous situations, *not acting* is considered the safest outcome.\n\n# 3. Strict separation of concerns\n\nThe system is split into independent layers:\n\n* data preparation\n* LLM-based decision\n* execution\n* logging and notification\n* post-action accounting\n\nEach layer can fail independently without cascading into repeated actions  \nor runaway behavior.\n\nFor example, notifications react only to **confirmed state changes**,  \nnot to intended or predicted actions.\n\n# 4. Features that were intentionally removed\n\nSeveral ideas were tested and then removed after increasing operational risk:\n\n* adaptive or performance-based scaling\n* averaging down / martingale behavior\n* intra-window predictions\n* confidence-weighted LLM actions\n* automatic restart into uncertain internal states\n\nThe system became *more stable* by explicitly **not doing these things**.\n\n# Why I‚Äôm sharing this\n\nI‚Äôm sharing this to **organize and reflect on lessons learned** from operating  \na non-deterministic LLM component in a live system.\n\nThe feedback here is for personal learning and refinement of system design.  \nAny future write-up would be technical and experience-based,  \nnot monetized and not promotional.\n\n# Looking for discussion\n\nI‚Äôd appreciate perspectives from people who have:\n\n* deployed LLMs or ML components in always-on systems\n* dealt with non-determinism and failure modes in production\n* strong opinions on fail-safe vs fail-open design\n\nIf this kind of operational discussion is useful (or not), I‚Äôd like to know.\n\n\n\nhttps://preview.redd.it/79npeu8hxvgg1.jpg?width=2048&format=pjpg&auto=webp&s=0be3702d0694e3f1ff0f73c9d8b8e4b8fbf3b548\n\n\n\n*Not selling anything here. Just sharing an operational experience.*",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qsyhfi/operating_an_llm_as_a_constrained_decision_layer/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o30gf9h",
          "author": "chris_thoughtcatch",
          "text": "Why use the LLM over a heuristic? Or use the LLM to determine the heuristic?",
          "score": 4,
          "created_utc": "2026-02-01 18:20:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o320aqp",
              "author": "NationalIncome1706",
              "text": "Good question. Early versions of the system were almost entirely heuristic-based,\nand most of the core behavior still is.\n\nI didn‚Äôt introduce the LLM to replace rules, but to handle the gray zones between them.\nHeuristics work extremely well when decision boundaries are crisp.\nThey tend to become brittle or explosively complex when multiple conditions are\npartially satisfied at the same time.\n\nIn this setup, the LLM cannot mutate state, trigger execution, or override hard rules.\nIt only answers a constrained question: ‚ÄúIs this situation unambiguous or not?‚Äù\n\nIf heuristics are the hard constraints, the LLM acts more like a soft consensus checker\non top of them.\n\nI also deliberately avoided using the LLM to generate or adapt heuristics.\nOnce rules become model-derived, failure modes get harder to reason about\nand rollback becomes non-trivial.",
              "score": 2,
              "created_utc": "2026-02-01 22:48:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o2zkcop",
          "author": "pstryder",
          "text": "Strong agreement on default-to-inaction and closed boundaries. Curious whether you‚Äôve run into trust erosion when the LLM *sounds* confident but is actually constrained ‚Äî that‚Äôs been a surprisingly sharp edge for us.",
          "score": 2,
          "created_utc": "2026-02-01 15:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3271yr",
              "author": "NationalIncome1706",
              "text": "Yes ‚Äî we ran into that exact edge early on.\n\nThe problem wasn‚Äôt the constraints themselves, but the mismatch between linguistic confidence and actual agency. Humans tend to interpret confident language as capability, even when the model is heavily boxed in.\n\nWhat helped was reframing the LLM‚Äôs role entirely. Its output isn‚Äôt treated as an explanation or a recommendation ‚Äî it‚Äôs a state classification signal. We deliberately stripped away expressive language and made responses repetitive, terse, and sometimes even boring.\n\nOver time, that shifted trust away from the LLM as an ‚Äúactor‚Äù and toward the system as a whole. The goal wasn‚Äôt to make the LLM trustworthy, but to make it unnecessary to trust in isolation.\n\nOnce operators internalize that distinction, the confidence/constraint gap becomes much less sharp.",
              "score": 1,
              "created_utc": "2026-02-01 23:25:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o31zmz3",
          "author": "Kimononono",
          "text": "How often does your system produce a BUY / SELL signal vs HOLD\n\nAt what interval does it run?",
          "score": 2,
          "created_utc": "2026-02-01 22:45:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o32e4e0",
              "author": "NationalIncome1706",
              "text": "The decision loop runs on a fixed schedule, but with very different semantics.\n\nENTRY decisions are only evaluated on closed higher-timeframe candles, so they‚Äôre relatively infrequent by design.\nPosition management / exit checks run much more often, but the default outcome there is still HOLD.\n\nIn practice, the vast majority of evaluations result in HOLD. BUY/SELL is treated as an exception, not a steady stream.\n\nThat ratio is intentional. We don‚Äôt optimize for signal frequency ‚Äî we treat excessive activity as a smell. If the system is trading often, something upstream is probably too permissive.\n\nThe goal is to let the system be bored most of the time and only act when ambiguity collapses.",
              "score": 1,
              "created_utc": "2026-02-02 00:04:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o33pmxx",
                  "author": "Kimononono",
                  "text": "if I have a script which goes \n\nfunc analyze\\_signal():\n\nnum = random()  \nif(num < .01) BUY  \nif(num < .02) SELL  \nelse HOLD\n\nHow are you to smell anything if the scent is so faint?",
                  "score": 2,
                  "created_utc": "2026-02-02 04:41:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o34gef2",
          "author": "Sea-Sir-2985",
          "text": "one thing i've run into with this kind of setup is that schema validation alone isn't enough... the LLM can return perfectly valid JSON that still makes a nonsensical decision. so we added a semantic validation layer on top, basically domain constraint checks that run after the LLM responds but before anything gets executed\n\nthe other piece that helped was logging every decision with the full prompt and response, not just the final action. when something goes wrong at 3am you need to see exactly what the model was thinking, not just what it did",
          "score": 2,
          "created_utc": "2026-02-02 08:24:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o35elkz",
              "author": "NationalIncome1706",
              "text": "This matches our experience almost exactly.\n\nValid JSON is necessary but nowhere near sufficient.\nThe LLM sits inside a constrained decision layer,\nwhere its output is treated as a hypothesis that must pass\nexplicit domain checks (timeframe closure, regime alignment, risk bounds, state continuity).\n\nExecution is gated deterministically.\nHOLD is the fail-safe default.\n\nWe also persist the full prompt snapshot and model response,\nbecause without that, post-mortems are basically guesswork.",
              "score": 1,
              "created_utc": "2026-02-02 13:14:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o38eoep",
          "author": "KnightCodin",
          "text": "I might have missed the exact reason but why introduce LLM at all? \"non-determinism\" or \"Grey\" area are not sufficient reason to introduce further complexity into this \"bound decision later\" with strict output states. Having done mission critical production systems all my life (built and managed trading systems for a one the big 3 investment banks) I am curious to know what are the reasons for this. Decision thresholding can be used to achieve the ambiguity question easily. What am I missing?",
          "score": 2,
          "created_utc": "2026-02-02 21:53:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o38v6x8",
              "author": "NationalIncome1706",
              "text": "Good question.\n\nThe distinction is between a *default HOLD* and a *judged HOLD*.\n\nWith heuristics alone, any region outside clearly defined thresholds\ncollapses into a blanket HOLD. That‚Äôs safe, but it also throws away cases\nthat are structurally unambiguous but hard to encode cleanly as rules.\n\nThe LLM doesn‚Äôt decide BUY/SELL, mutate state, or override rules.\nIt only answers a constrained question:\n‚ÄúIs this situation unambiguous enough to allow the rules to act?‚Äù\n\nIf the answer is no, it‚Äôs still HOLD.\nIf yes, execution remains fully rule-driven.\n\nSo the goal wasn‚Äôt to add intelligence on top of heuristics,\nbut to prevent heuristics from becoming brittle or explosively complex\nin partially satisfied, multi-condition regimes.",
              "score": 1,
              "created_utc": "2026-02-02 23:17:42",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o38x43n",
                  "author": "KnightCodin",
                  "text": "Okay - so you are in the multi-branching scenario. You are still introducing stochasticity. However, assuming you have explored other techniques, Without knowing all the constraints and ecosystems, simplest solution would be   \n1. Use a smaller LLM known to punch above its weight class Eg. Qwen 3 - 4B.  \n2. If your inference engine allows it, use constraints at logits level to reduce subjectivity",
                  "score": 2,
                  "created_utc": "2026-02-02 23:28:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o2ytwkw",
          "author": "NationalIncome1706",
          "text": "This is an experience report on operating an LLM inside a live system.\n\nNot a product, not prompts, not benchmarks.\n\n\n\nI‚Äôm especially interested in how others handle non-determinism,\n\nfail-safe defaults, and state consistency in always-on LLM-based systems.",
          "score": 1,
          "created_utc": "2026-02-01 13:33:04",
          "is_submitter": true,
          "replies": [
            {
              "id": "o37psxr",
              "author": "amejin",
              "text": "My opinion - how to \"handle non-determinism?\"\n\nWhen it comes to money, you don't.",
              "score": 2,
              "created_utc": "2026-02-02 19:56:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o37upb6",
                  "author": "NationalIncome1706",
                  "text": "I largely agree with that principle. When real money is involved, non-determinism shouldn‚Äôt be trusted as a decision maker.\n\nThat‚Äôs exactly why, in my case, it‚Äôs not allowed to decide anything. It can‚Äôt allocate capital, trigger execution, or override hard rules.\n\nThe only thing it‚Äôs permitted to do is say ‚Äúdon‚Äôt act‚Äù when the system is near a boundary the deterministic logic can‚Äôt cleanly resolve.\n\nSo I don‚Äôt think of it as ‚Äúhandling non-determinism,‚Äù but rather containing it ‚Äî pushing it into a narrow veto role where failure modes collapse to inaction.\n\nIf a non-deterministic component can‚Äôt fail safely, it shouldn‚Äôt be anywhere near money. On that point, I think we‚Äôre aligned.",
                  "score": 1,
                  "created_utc": "2026-02-02 20:19:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qv6z6k",
      "title": "Natural Language to shell commands tool. Fully local, Ollama powered.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qv6z6k/natural_language_to_shell_commands_tool_fully/",
      "author": "ykushch",
      "created_utc": "2026-02-03 22:49:38",
      "score": 7,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[ask - natural language to shell commands](https://i.redd.it/vzpbvx06zchg1.gif)\n\nI built a CLI tool that turns natural language into shell commands using Ollama. It runs locally (no API keys, no data egress) and includes safety checks so you don't accidentally¬†`rm -rf`¬†your system.\n\nRepo:¬†[https://github.com/ykushch/ask](https://github.com/ykushch/ask)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qv6z6k/natural_language_to_shell_commands_tool_fully/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3jo2dk",
          "author": "konmik-android",
          "text": "I often ask Claude to do that, but having an offline version would be much better. Remembering and typing all parameters of all commands is something I left in 1990x.",
          "score": 2,
          "created_utc": "2026-02-04 15:38:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3g2dog",
          "author": "DataCentricExpert",
          "text": "Curious if anyone has tried running it with a local dev environment that enforces data masking and auditability?",
          "score": 1,
          "created_utc": "2026-02-04 00:50:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qulg4u",
      "title": "n8n vs gumloop",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qulg4u/n8n_vs_gumloop/",
      "author": "OkWestern5",
      "created_utc": "2026-02-03 07:19:52",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "If you‚Äôre looking into n8n vs Gumloop, you‚Äôre probably not trying to find the ‚Äúbest‚Äù tool in general. You‚Äôre trying to understand which workflow automation platforms actually fit how your team works day to day. That‚Äôs where this comparison comes from. I also looked at a [broader comparison table](https://docs.google.com/spreadsheets/d/1zQr6iThp2fR-TLNMvSYHgx2ghSrzbYIduO4vX_jlHig/edit?gid=1301024975#gid=1301024975) of workflow automation platforms where n8n is listed, which helped set some baseline context.\n\n# High-level difference\n\n* **Gumloop** is built for business teams that want to automate workflows without involving engineering.\n* **n8n** is built for developer-first teams that want full control, even if that means more setup and maintenance.\n\nThis difference shows up across the product, from the editor to pricing and integrations.\n\n# Ease of use\n\n**Gumloop**  \nGumloop lets you focus on the business problem rather than implementation.\n\n* Visual, easy-to-follow canvas\n* Pre-built actions for common business tools\n* AI features included by default\n* Custom steps without deep technical knowledge\n\nMost teams can get useful workflows running quickly.\n\n**n8n**  \nn8n prioritizes flexibility over simplicity.\n\n* Node-by-node configuration\n* Direct access to APIs, JSON, and JavaScript\n\nYou gain more control, but also more responsibility for building and maintaining workflows.\n\n# Integrations and flexibility\n\nBoth platforms support tools like Google Workspace, Slack, Salesforce, and Notion.\n\n* **n8n** offers broader coverage via community-built nodes, but requires manual setup and upkeep.\n* **Gumloop** focuses on the integrations business teams actually use, with AI-assisted ways to extend them when needed.\n\nIn the **n8n vs Gumloop** comparison, this is often where teams weigh flexibility against effort.\n\n# Pricing and ownership\n\n* **Gumloop** bundles AI models, scraping, enrichment, and data sources into its plans.\n* **n8n** charges per execution, with AI and data services managed and billed separately.\n\nNeither approach is better by default - it depends on whether you prefer bundled convenience or modular control.\n\n# Final thoughts\n\nThe real distinction in n8n vs Gumloop is how much work you want around your automation. Gumloop minimizes it early on, while n8n gives you more room later if you‚Äôre willing to manage it.\n\nWhich side do you lean toward - simplicity or control?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qulg4u/n8n_vs_gumloop/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qwdhwq",
      "title": "I made a Transformer 3x faster by making 75% of tokens \"lazy\". It beats the standard baseline on loss in fixed-time training.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qwdhwq/i_made_a_transformer_3x_faster_by_making_75_of/",
      "author": "Morph2026",
      "created_utc": "2026-02-05 06:09:15",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nI don't have the compute to train on 100B tokens or write a formal paper right now, so I'm dropping this here for the community to play with.\n\n**The Idea: \"WorkerTransformer\"**\n\nStandard Transformers are inefficient because every single token performs expensive Attention ($O(T^(2)$)) and FFN ($O(T)$) updates. But does every token really need to \"think\" deeply?\n\nI built a sparse-update architecture based on a simple intuition:\n\n1. **Divide & Conquer**: Split tokens into **Workers** (every 4th token) and **Memory** (the rest).\n2. **Workers**: Do the heavy lifting (Full Attention + FFN).\n3. **Memory**: Only do a cheap depthwise conv1d to capture local context (like Mamba/ConvNets) but **skip** the heavy Transformer block.\n4. **In-place Update**: Everything happens in-place. No extra tokens added, no sequence inflation.\n\n**The Result (on T=1024 sequence length):**\n\nI ran a \"battle\" between a Standard Transformer and my WorkerTransformer (same params, layers, dim) on a fixed 5-minute training budget.\n\n* **Standard Transformer**: 3.2 steps/s | Reached Val Loss **1.44**\n* **WorkerTransformer**: 8.0 steps/s (**2.5x speedup**) | Reached Val Loss **1.30**\n\nThe \"lazy\" model didn't just run faster; because it ran 2.5x more steps in the same timeframe, it actually learned **more** and achieved a significantly lower loss. It seems the trade-off of \"sparse compute vs. more iterations\" heavily favors sparse compute here.\n\n**Why I'm sharing this:**\n\nI suspect this could scale. The architecture is **pure PyTorch** (no custom CUDA kernels needed), making it dead simple to modify.\n\nIf you have spare A100s or are looking for a weekend project, I'd love to see someone scale this up to WikiText-103 or RedPajama.\n\n**Code & Benchmarks:** [https://github.com/SuiltaPico/WorkerTransformer](https://github.com/SuiltaPico/WorkerTransformer)\n\nLet me know if you find any flaws in my reasoning or if you manage to break it!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qwdhwq/i_made_a_transformer_3x_faster_by_making_75_of/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o44tfs6",
          "author": "techperson1234",
          "text": "Huh. Super interesting!",
          "score": 1,
          "created_utc": "2026-02-07 19:49:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o47mb91",
          "author": "Dangerous-Sale3243",
          "text": "Interesting. I dont know enough to comment technically, since i am mostly just a user than a creator. The idea seems obvious, or at least an obvious next step facing a problem of optimizing runtime. So my assumption is that this was considered and rejected by a bunch of smart guys at some point in the past few years, for reasons beyond my knowledge.",
          "score": 1,
          "created_utc": "2026-02-08 06:19:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qwmbq0",
      "title": "glm 4.7 swe-bench 73.8% - tested claims on real refactoring tasks, improvement over previous models measurable",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qwmbq0/glm_47_swebench_738_tested_claims_on_real/",
      "author": "Weird_Perception1728",
      "created_utc": "2026-02-05 14:11:57",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "saw glm 4.7 swe-bench verified score (73.8%, +5.8 vs glm 4.6) and terminal bench (41%, +16.5)\n\nskeptical of benchmark gaming so tested on actual software engineering tasks\n\n**methodology:**\n\n20 refactoring tasks from internal codebase (flask, fastapi, django projects)\n\neach task: multi-file changes, maintaining references, no breaking changes\n\ntested against: glm 4.6, deepseek v3, codellama 70b\n\nmetric: success rate (code runs without fixes) + retry attempts needed\n\n**results:**\n\nglm 4.7: 17/20 success first attempt (85%))  \ndeepseek v3: 14/20 success first attempt (70%)  \ncodellama 70b: 11/20 success first attempt (55%)\n\n**failure analysis:**\n\nglm 4.7 failures: mostly edge cases in dependency injection patterns\n\nother models: frequent import hallucination, circular dependency introduction, breaking type hints\n\n**terminal bench correlation:**\n\ntested bash script generation (10 automation tasks)\n\nglm 4.7: 9/10 scripts ran without syntax errors  \nothers: 5-7/10 average\n\nterminal bench score (41% vs \\~25-35% typical) actually translated to real usage\n\n**architectural notes:**\n\n355b parameters, moe with 32b active per token\n\ntraining on 14.8t tokens\n\n**where improvement shows:**\n\ncross-file context tracking significantly better (measured by import correctness)\n\niterative debugging fewer loops to solution (average 1.4 attempts vs 2.3 for previous)\n\nbash/terminal command generation syntax correctness up\n\n**where still limited:**\n\ntraining cutoff late-2024 (misses recent library updates)\n\narchitectural reasoning weaker than frontier closed models\n\nexplanation depth inferior to teaching-optimized models\n\n**cost efficiency:**\n\napi pricing: \\~$3/month plan for generous coding use (significantly under openai/anthropic)\n\n**discussion points:**\n\nis 73.8% swe-bench representing actual capability or benchmark-specific tuning?\n\nbased on 20-task sample, improvement over previous versions real and measurable\n\nterminal bench correlation to bash quality interesting - suggests benchmark captures meaningful skill\n\n**limitations of this analysis:**\n\nsmall sample size (20 tasks)\n\ntasks from specific domains (web backends)\n\nno comparison to gpt-4/claude (cost prohibitive for extensive testing)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qwmbq0/glm_47_swebench_738_tested_claims_on_real/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3pxn6q",
          "author": "WelcomeMysterious122",
          "text": "nice.",
          "score": 1,
          "created_utc": "2026-02-05 14:19:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3pz6ar",
          "author": "microhan20",
          "text": "Interesting that terminal bench score correlates with actual bash quality. Usually synthetic benchmarks don't predict real performance well, but 41% vs 25-35% showing in your tests suggests its capturing something meaningful",
          "score": 1,
          "created_utc": "2026-02-05 14:27:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3tjp4u",
          "author": "DeathShot7777",
          "text": "How much does it cost in total to run swe verified on glm4.7 \n\nI am working on a code intelligence layer using Graphs so agents can use it for deeper codebase understanding and want to test performance improvements on it. Will need to save up üòÖ",
          "score": 1,
          "created_utc": "2026-02-06 00:58:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o3u2u9q",
              "author": "Scared-Biscotti2287",
              "text": "You might want to check their site for the coding plans the cheapest is like 3 bucks for a month",
              "score": 1,
              "created_utc": "2026-02-06 02:52:31",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qtm1r7",
      "title": "How do you debug multi-step agent workflows",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qtm1r7/how_do_you_debug_multistep_agent_workflows/",
      "author": "CreditOk5063",
      "created_utc": "2026-02-02 05:10:21",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I've been working on a customer support agent that routes queries to different tools depending on intent. I am essentially building a state-machine style agent using LangGraph, and the state transitions are where the logic keeps drifting. The flow is: classify intent ‚Üí retrieve relevant docs ‚Üí generate response ‚Üí validate output format. Each node works fine in isolation but when the graph runs end to end the failure modes exhibit non-linear behaviors that are hard to replicate. Sometimes the classifier output schema breaks the retriever input, sometimes the context window gets bloated by step 3.\n\nMy current debugging approach is pretty manual. I added verbose logging at each node, dump intermediate state to JSON, and trace back from failures. But the hard part is not finding where it broke, it is understanding why a certain prompt phrasing caused a downstream node to behave differently. LLM outputs are not deterministic so reproducing issues is painful. So I started using Pydantic models for structured output at each step, and let Claude and Beyz coding assistant to help me do sanity check. But it still feels inefficient though. I'm curious how do you test nodes in isolation first or go straight to end-to-end runs? How do you handle the non-determinism problem when debugging state transitions? Is anyone using Pydantic strictly for node-to-node contracts or does the validation overhead add too much latency and retries for production pipelines? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qtm1r7/how_do_you_debug_multistep_agent_workflows/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o34jm5w",
          "author": "Zeikos",
          "text": "> \"Each node works fine in isolation\"\n\nThat phrasing is a bit of a red flag for me.  \nHow do you define \"fine\"?  \n\nA process of 5 steps where each has a 90% success rate is terrible, it'll fail extremely often.  \n\nBe a lot more strict about the reliability of each node.  \nGoing from 90% to 95% is noticeable, going from 95% to 98% is *more* noticeable.  \n90% -> 95% is a 50% improvement, 95% -> 98% is a 60% improvement.  \n\nWhen you have maxed that out then you want to look at each pairs of nodes.  \nWhat nodes produce bad output when they had good input? Why?  \nYou don't care about a bigger scope than the two connections, the other nodes can stay as a black box.  \n\nBe careful to attribute the failure correctly.  \nWhen something fails at step n then you don't care about steps > n (except eventual error-recovery steps).",
          "score": 3,
          "created_utc": "2026-02-02 08:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o33vuq6",
          "author": "plarkin",
          "text": "The golden rule: If you can't reproduce it, you can't debug it. Make everything observable, cacheable, and replayable! \n\nAsk your favorite LLM about it ;)",
          "score": 2,
          "created_utc": "2026-02-02 05:26:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3413tb",
          "author": "InvestigatorAlert832",
          "text": "The current standard approach to address the reproducibility issue is to use an observability platform like langfuse to capture detailed logs, then clean&save them to datasets, then setup evaluators, and finally you can run evals on the dataset to gauge the quality of your node/program.\nIn terms of interfacing between LLM nodes, I personally prefer strongly typed enforcement. There are frameworks built specifically focusing on this - pydantic-ai, instructor.",
          "score": 1,
          "created_utc": "2026-02-02 06:07:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "o341p8f",
              "author": "InvestigatorAlert832",
              "text": "I do think the observability platforms on the market are painful to use for the debug & iterate scenario though, and I'm actually working on a tool for this myself. Feel free to DM me if you are interested in being my beta tester :)",
              "score": 1,
              "created_utc": "2026-02-02 06:12:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qwf2bh",
      "title": "Built this because I was tired of redoing AI agent stuff again and again",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qwf2bh/built_this_because_i_was_tired_of_redoing_ai/",
      "author": "Most_Cardiologist313",
      "created_utc": "2026-02-05 07:39:49",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Every Al project I build ends up repeating the same setup: agent reasoning loop, tool calling, API wrapper, bot integration, deployment configs. After doing this too many times, I built a small internal framework to standardize this stuff for myself.\n\nIt handles things like ReACT-style agents, tool execution, API mode, Discord integration, and edge-friendly deployment patterns.\n\nBefore I invest more time into polishing it, I'm curious how are you handling this today? Are you using LangChain/LangGraph, rolling your own, or something else? What parts feel the most painful to maintain?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qwf2bh/built_this_because_i_was_tired_of_redoing_ai/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o3oiwmr",
          "author": "Most_Cardiologist313",
          "text": "Here‚Äôs the repo in case anyone wants to look at the implementation:\nhttps://github.com/Parvezkhan0/LLM-Task-Orchestrator",
          "score": 1,
          "created_utc": "2026-02-05 07:40:44",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o3olroc",
          "author": "Otherwise_Wave9374",
          "text": "I feel this so much. Everyone ends up rebuilding the same \"agent spine\" (loop, tools, retries, logging, auth, deployment) and it gets old fast.\n\nBiggest pain point for me has been eval + observability, like being able to replay a run, inspect tool calls, and measure where the agent went off track. Once you have that, the rest gets way easier to iterate.\n\nIf you are thinking about how to structure the agent loop and what to measure, I have seen a few good writeups here: https://www.agentixlabs.com/blog/\n\nAre you planning to support MCP out of the box, or is it more of an internal tool registry + adapters approach?",
          "score": 1,
          "created_utc": "2026-02-05 08:07:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3u0lh8",
          "author": "AdditionalWeb107",
          "text": "via Plano - https://github.com/katanemo/plano. Solving delivery challenges at the substrate level.",
          "score": 1,
          "created_utc": "2026-02-06 02:39:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o3v1nvn",
          "author": "coloradical5280",
          "text": "I‚Äôve seen some useless slop in my time‚Ä¶ and this is top 10%",
          "score": 0,
          "created_utc": "2026-02-06 07:01:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o40mdvm",
              "author": "djdjddhdhdh",
              "text": "Haha there is literally more self promotion than actual people in this thread right now. Guess the whole agents selling to agents is our reality now",
              "score": 1,
              "created_utc": "2026-02-07 02:49:05",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}