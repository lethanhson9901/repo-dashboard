{
  "metadata": {
    "last_updated": "2026-01-07 02:36:07",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 29,
    "total_comments": 125,
    "file_size_bytes": 169672
  },
  "items": [
    {
      "id": "1q2zfva",
      "title": "I am developing a 200MB LLM to be used for sustainable AI for phones.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2zfva/i_am_developing_a_200mb_llm_to_be_used_for/",
      "author": "Fancy_Wallaby5002",
      "created_utc": "2026-01-03 16:49:54",
      "score": 39,
      "num_comments": 18,
      "upvote_ratio": 0.89,
      "text": "Hello Reddit,\n\nOver the last few weeks, I‚Äôve written and trained a small LLM based on LLaMA 3.1.  \nIt‚Äôs multilingual, supports reasoning, and only uses **\\~250 MB** of space.  \nIt can run locally on a **Samsung A15** (a very basic Android phone) at reasonable speed.\n\nMy goal is to make it work as a kind of **‚ÄúGoogle AI Overview‚Äù**, focused on short, factual answers rather than chat.\n\nI‚Äôm wondering:\n\n* Is this a reasonable direction, or am I wasting time?\n* Do you have any advice on how to improve or where to focus next?\n\nSorry for my English; I‚Äôm a 17-year-old student from Italy.",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2zfva/i_am_developing_a_200mb_llm_to_be_used_for/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxi2mmm",
          "author": "SamWest98",
          "text": "[https://ai.google.dev/edge/mediapipe/solutions/genai/llm\\_inference/android](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference/android)\n\nI think they've beat you to the punch. I wouldn't say you're wasting time, being able to train and deploy edge models is a great learning experience",
          "score": 18,
          "created_utc": "2026-01-03 20:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxil11f",
          "author": "robogame_dev",
          "text": "It‚Äôs not going to be commercially viable, but it‚Äôs good experience!\n\nTraining models isn‚Äôt even commercially viable for major companies - the models themselves are out of date within 6 months, when a better, smaller model comes out. \n\nThat‚Äôs why so many models are given away for people to run themselves - because the company can‚Äôt reasonably charge for them when equally good or better models are available for free.\n\nModel development is interesting but it isn‚Äôt a small business opportunity (unless you target a really small and specific niche that involves unique training data that nobody else can get.)\n\nI would say the most important part of your project is to document it really well, so that later when you pitch to get a job or an investment on your future projects, you can point to it as proof of skill.\n\nIf you want to make money at AI as a solo, you need to either A) target a small niche model where you can obtain a dataset nobody else has, or B) make a product or service, something downstream of the models, where you focus on being the customer‚Äôs point of contact and use existing models/inference providers on your backend.",
          "score": 9,
          "created_utc": "2026-01-03 22:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxipl8g",
          "author": "Thellton",
          "text": "something to clarify, have you trained a model that is approximately 0.125B (125M) parameters? as that's the implication from your statement of 250MB of space. if so, that's a very constrained optimisation space you're working in, and whilst u/SamWest98 is probably correct that using a pre-existing small model would do the trick it is an interesting challenge you've set for yourself.\n\nas to your questions:\n\n1) It probably is a reasonable direction to go, though you'll likely need to specialise the model heavily, as 250MB is tiny. thus, you'll be wanting to focus on summarisation for finetuning. it may be beneficial to use synthetically generated samples for summarisation when you finetune for task as you'll be able to tailor final behaviour more readily that way too.\n\n2) I'd recommend checking out this [article](https://huggingface.co/blog/codelion/optimal-model-architecture). it goes into detail about the hyperparameter optimisation that can be done and some of the interesting things that are noted performance wise in response. if you've done only one training run, then it's probable that the particular combination of layers, embedding dim, etcetera could be optimised. granted, there is also a point where one has to stop and commit to a design. but that is always up to you, as you are the final arbiter of what you're satisfied with. \n\nanyway, good luck! also your English is perfectly fine!",
          "score": 2,
          "created_utc": "2026-01-03 22:25:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhsh5a",
          "author": "jblully",
          "text": "Good idea.\nCan i see sources or example ?\nWhich dataset do you use ?\nI‚Äôm learning, if you have some course or doc to read to do that.",
          "score": 1,
          "created_utc": "2026-01-03 19:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxke4u1",
          "author": "LeoStark84",
          "text": "Interesting project. Depends a lot on your current implenentation though.\n\nIf what you made relies on llama.cpp it will be kinnda tough to turn into an apk, but it can work through Termux. I bring this up becausr from what I understand your intended use case depends on some kind of web-search. So you'd input something like \"quantum tunneling\" and somehow search for results online, pass it to your LLM for summarizing and the outpuy would be an explanation of quantum tunnelibg based on the results. Please correct me if I'm wrong, but I assume it to be the case as there is no way a large amount of world knowledge is gonna fit on such a small LLM.\n\nBottomline is the scaffolding around it is as important as the LLM. Also, as cool as Termux is, it's a heek thing and relying om it is going to leave 95% of users out, not a problem if you don't cate abouy massivity though.",
          "score": 1,
          "created_utc": "2026-01-04 03:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxkrfng",
          "author": "CrowAssaultVictim",
          "text": "Back in 2018, we used to build LLMs that could fit into AWS lambda functions before they extended the storage. But at that time we only called them \"language models\". I don't know at what point they started being called \"large\". Reminds me of \"big\" data. But they were bigger than 250mb.",
          "score": 1,
          "created_utc": "2026-01-04 05:20:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxma38a",
              "author": "ianitic",
              "text": "I think I remember the term LLM being used back in 2018 to describe BERT?",
              "score": 1,
              "created_utc": "2026-01-04 13:02:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxmwg2a",
                  "author": "CrowAssaultVictim",
                  "text": "Nah. BERT had different size models (BERT_SMALL, BERT, BERT_LARGE) but we didn‚Äôt use LLM as a noun. And even BERT_LARGE was nothing by today‚Äôs standards (however it‚Äôs still SOTA for some tasks).\n\nI think it started with whatever GPT came out during Covid.",
                  "score": 1,
                  "created_utc": "2026-01-04 15:14:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxky3dp",
          "author": "Bonnie-Chamberlin",
          "text": "What kind of dataset are you using for training your small language model?",
          "score": 1,
          "created_utc": "2026-01-04 06:10:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxl575s",
          "author": "dmpiergiacomo",
          "text": "This is a great learning experience and you are doing a great job! Don't forget to document everything really well to use for future reference when it comes to job hunting. I personally value side projects a lot when I look at CVs of candidates.\n\nWhen you ask if this is a reasonable direction, are you thinking about doing research or starting a business? Either way, you'll need to choose a more specific direction and justify the need of this technology in the world. So far your value proposition isn't very clear. If it's a business, be mindful of your customers' willingness to pay. If you‚Äôre planning to sell to smartphones providers, you'll have a hard time.",
          "score": 1,
          "created_utc": "2026-01-04 07:08:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm77rk",
          "author": "PARKSCorporation",
          "text": "Oh this is sick",
          "score": 1,
          "created_utc": "2026-01-04 12:41:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm8lji",
          "author": "Shivam_R_A",
          "text": "FunctionGemma",
          "score": 1,
          "created_utc": "2026-01-04 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmevpu",
          "author": "Good-Coconut3907",
          "text": "Learning and hands on experience is NEVER a waste of time. Particularly now that entry level jobs are hard to find.\n\nIf you need GPUs to play with, I‚Äôd be more than happy to loan some: https://github.com/kalavai-net/kalavai-client",
          "score": 1,
          "created_utc": "2026-01-04 13:33:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsso5o",
              "author": "Fancy_Wallaby5002",
              "text": "oh, this is insane! thank you!",
              "score": 1,
              "created_utc": "2026-01-05 11:16:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxqrxw3",
          "author": "nuggieinu",
          "text": "Depends on the scope really so without examples/direct references its hard to tell, but honestly speaking I see this as better experience than trying to vibecode out a commercial product with little to no differentiation. From my experience, using resources like [brev.dev](http://brev.dev) and [together.ai](http://together.ai) not only made me think about what I was doing/learning, but inadvertently exposed me to other resources that I just kept following out of my own interest. Ultimately, I think if you try to dive deeper into this space rather than try to instantly push out a commercial product, you can really see for yourself something interesting.",
          "score": 1,
          "created_utc": "2026-01-05 02:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrtbxn",
          "author": "yes-im-hiring-2025",
          "text": "Gemma already has one around that size.",
          "score": 1,
          "created_utc": "2026-01-05 06:00:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsmm82",
          "author": "shoonee_balavolka",
          "text": "Many people here have weighed in, but since the model size is so small, it won't be able to handle too many tasks. I'm actually planning something similar‚Äîusing Gemma 3 270M to generate comments for user diaries. You'd need fine-tuning to boost performance, but it might be tough because the model is so tiny. It's really impressive to see you doing this at such a young age. I‚Äôm sure you‚Äôll become a brilliant AI researcher in the future!",
          "score": 1,
          "created_utc": "2026-01-05 10:23:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4thym",
      "title": "How my open-source project ACCIDENTALLY went viral",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q4thym/how_my_opensource_project_accidentally_went_viral/",
      "author": "Every_Chicken_1293",
      "created_utc": "2026-01-05 18:21:20",
      "score": 28,
      "num_comments": 2,
      "upvote_ratio": 0.77,
      "text": "Original post: [here](https://www.reddit.com/r/LLMDevs/comments/1ky21fy/i_accidentally_built_a_vector_database_using)\n\nSix months ago, I published a weird weekend experiment where I stored text embeddings inside video frames.\n\nI expected maybe 20 people to see it. Instead it got:\n\n* Over 10M views\n* 10k stars on GitHub¬†\n* And thousands of other developers building with it.\n\nOver 1,000 comments came in, some were very harsh, but I also got some genuine feedback. I spoke with many of you and spent the last few months building Memvid v2: it‚Äôs faster, smarter, and powerful enough to replace entire RAG stacks.\n\n\n\nThanks for all the support.\n\nPs: I added a little surprise at the end for developers and OSS builders üëá\n\n\n\n**TL;DR**\n\n* Memvid replaces RAG + vector DBs entirely with a single portable memory file.\n* Stores knowledge as Smart Frames (content + embedding + time + relationships)\n* 5 minute setup and zero infrastructure.\n* Hybrid search with sub-5ms retrieval\n* Fully portable and open Source\n\n**What my project does?** Give your AI Agent Memory In One File.\n\n**Target Audience:** Everyone building AI agent.\n\n**GitHub Code:**[ https://github.com/memvid/memvid](https://github.com/memvid/memvid)\n\n‚Äî----------------------------------------------------------------\n\n**Some background:**\n\n* AI memory has been duct-taped together for too long.\n* RAG pipelines keep getting more complex, vector DBs keep getting heavier, and agents still forget everything unless you babysit them.¬†\n* So we built a completely different memory system that replaces RAG and vector databases entirely.¬† \n\n**What is Memvid:**\n\n* Memvid stores everything your agent knows inside a single portable file, that your code can read, append to, and update across interactions.\n* Each fact, action and interaction is stored as a self‚Äëcontained ‚ÄúSmart Frame‚Äù containing the original content, its vector embedding, a timestamp and any relevant relationships.¬†\n* This allows Memvid to unify long-term memory and external information retrieval into a single system, enabling deeper, context-aware intelligence across sessions, without juggling multiple dependencies.¬†\n* So when the agent receives a query, Memvid simply activates only the relevant frames, by meaning, keyword, time, or context, and reconstructs the answer instantly.\n* The result is a small, model-agnostic memory file your agent can carry anywhere.  \n\n**What this means for developers:**\n\nMemvid replaces your entire RAG stack.\n\n* Ingest any data type\n* Zero preprocessing required\n* Millisecond retrieval\n* Self-learning through interaction\n* Saves 20+ hours per week\n* Cut infrastructure costs by 90%\n\nJust plug Memvid into your agent and you instantly get a fully functional, persistent memory layer right out of the box.\n\n**Performance & Compatibility**\n\n(tested on my Mac M4)\n\n* Ingestion speed: 157 docs/sec¬†\n* Search Latency: <17ms retrieval for 50,000 documents\n* Retrieval Accuracy: beating leading RAG pipelines by over 60%\n* Compression: up to 15√ó smaller storage footprint\n* Storage efficiency: store 50,000 docs in a \\~200 MB file\n\nMemvid works with every model and major framework: GPT, Claude, Gemini, Llama, LangChain, Autogen and custom-built stacks.¬†\n\nYou can also 1-click integrate with your favorite IDE (eg. VS Code, Cursor)\n\nIf your AI agent can read a file or call a function, it can now remember forever.\n\nAnd your memory is 100% portable: Build with GPT ‚Üí run on Claude ‚Üí move to Llama. The memory stays identical.\n\n**Bonus for builders**\n\nAlongside Memvid V2, we‚Äôre releasing 4 open-source tools, all built on top of Memvid:\n\n* **Memvid ADR** ‚Üí is an MCP package that captures architectural decisions as they happen during development. When you make high-impact changes (e.g. switching databases, refactoring core services), the decision and its context are automatically recorded instead of getting lost in commit history or chat logs.\n   * GitHub Link: [https://github.com/memvid/adrflow](https://github.com/memvid/adrflow)\n* **Memvid Canvas** ‚Üí¬† is a UI framework for building fully-functional AI applications on top of Memvid in minutes. Ship customer facing or internal enterprise agents with zero infra overhead.\n   * GitHub Link: [https://github.com/memvid/canvas](https://github.com/memvid/canvas)\n* **Memvid Mind** ‚Üí is a persistent memory plugin for coding agents that captures your codebase, errors, and past interactions. Instead of starting from scratch each session, agents can reference your files, previous failures, and full project context, not just chat history. Everything you do during a coding session is automatically stored and ingested as relevant context in future sessions.¬†\n   * GitHub Link: [https://github.com/memvid/memvid-mind](https://github.com/memvid/memvid-mind)\n* **Memvid CommitReel** ‚Üí is a rewindable timeline for your codebase stored in a single portable file. Run any past moment in isolation, stream logs live, and pinpoint exactly when and why things broke.\n   * GitHub Link: [https://github.com/memvid/commitreel](https://github.com/memvid/commitreel)\n\nAll 100% open-source and available today.\n\nMemvid V2 is the version that finally feels like what AI memory should‚Äôve been all along.\n\nIf any of this sounds useful for what you‚Äôre building, I‚Äôd love for you to try it and let me know how we can improve it.",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q4thym/how_my_opensource_project_accidentally_went_viral/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny2wqf3",
          "author": "Financial-Fun-8930",
          "text": "Can't use local embedding models. I've tried CLI and node-js, both say \"not available on this platform\"",
          "score": 1,
          "created_utc": "2026-01-06 21:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2x10z",
              "author": "Every_Chicken_1293",
              "text": "Are you on Windows or Linux?",
              "score": 1,
              "created_utc": "2026-01-06 21:20:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q25iar",
      "title": "Why enterprise AI agents fail in production",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q25iar/why_enterprise_ai_agents_fail_in_production/",
      "author": "Arindam_200",
      "created_utc": "2026-01-02 17:56:10",
      "score": 22,
      "num_comments": 8,
      "upvote_ratio": 0.9,
      "text": "I keep seeing the same pattern with enterprise AI agents: they look fine in demos, then break once they‚Äôre embedded in real workflows.\n\nThis usually isn‚Äôt a model or tooling problem. The agents have access to the right systems, data, and policies.\n\nWhat‚Äôs missing is **decision context**.\n\nMost enterprise systems record outcomes, not reasoning. They store that a discount was approved or a ticket was escalated, but not *why* it happened. The context lives in Slack threads, meetings, or individual memory.\n\nI was thinking about this again after reading Jaya Gupta‚Äôs article on **context graphs**, which describes the same gap. A context graph treats decisions as first-class data by recording the inputs considered, rules evaluated, exceptions applied, approvals taken, and the final outcome, and linking those traces to entities like accounts, tickets, policies, agents, and humans.\n\nhttps://preview.redd.it/upw4879w5zag1.png?width=1920&format=png&auto=webp&s=25c8abbab1d6fb2a7cc24e146a8f48524b28b2d0\n\nThis gap is manageable when humans run workflows because people reconstruct context from experience. It becomes a hard limit once agents start acting inside workflows. Without access to prior decision reasoning, agents treat similar cases as unrelated and repeatedly re-solve the same edge cases.\n\nWhat‚Äôs interesting is that this isn‚Äôt something existing systems of record are positioned to fix. CRMs, ERPs, and warehouses store state before or after decisions, not the decision process itself. Agent orchestration layers, by contrast, sit directly in the execution path and can capture decision traces as they happen.\n\nI wrote a deeper piece exploring why this pushes enterprises toward **context-driven platforms** and what that actually means in practice. Feel free to read it [here](https://www.tensorlake.ai/blog/context-driven-enterprise-platform).",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q25iar/why_enterprise_ai_agents_fail_in_production/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxavblm",
          "author": "j4ys0nj",
          "text": "This is awesome! Thanks for sharing. I made and run an agentic AI platform - and I think it may be well positioned to address the shortcomings you highlight - at least somewhat. I will read through this, maybe I can make some improvements!",
          "score": 3,
          "created_utc": "2026-01-02 19:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaztp9",
          "author": "lexseasson",
          "text": "This resonates a lot.\n\nWhat we‚Äôve seen building agentic systems is that ‚Äúcontext‚Äù only becomes useful once it‚Äôs externalized as inspectable artifacts ‚Äî decisions, assumptions, success criteria ‚Äî not just aggregated signals.\n\nOtherwise you get rich context but still no accountability.\nContext without governance just becomes another layer of implicit state.\nContext is necessary for action.\nGovernance is sufficient for scale.",
          "score": 2,
          "created_utc": "2026-01-02 19:22:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaz8mt",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-02 19:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb08rp",
              "author": "EpochRaine",
              "text": "This is very interesting. I have been using seed \"characters\" in my LLM development - essentially looking at how changing a single character influences inference output and how the models amplify and possibly compound that effect internally.",
              "score": 1,
              "created_utc": "2026-01-02 19:24:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbb4ef",
                  "author": "spastical-mackerel",
                  "text": "Keep it up! You‚Äôll make it deterministic eventually",
                  "score": 1,
                  "created_utc": "2026-01-02 20:16:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxqfhfg",
          "author": "Bonnie-Chamberlin",
          "text": "Thanks for sharing. Would this be connected to Graph Neural Networks somehow?",
          "score": 1,
          "created_utc": "2026-01-05 01:09:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxzxwb",
      "title": "If you had to choose ONE LLM API today (price/quality), what would it be?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pxzxwb/if_you_had_to_choose_one_llm_api_today/",
      "author": "SmaugJesus",
      "created_utc": "2025-12-28 19:23:51",
      "score": 10,
      "num_comments": 25,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nI‚Äôm currently building a small SaaS and I‚Äôm at the point where I need to choose an LLM API.\n\nThe use case is fairly standard:\n\n\t‚Ä¢\ttext understanding\n\n\t‚Ä¢\tclassification / light reasoning\n\n\t‚Ä¢\tgenerating structured outputs (not huge creative essays)\n\nI don‚Äôt need the absolute smartest model, but I do care a lot about:\n\n\t‚Ä¢\tprice / quality ratio\n\n\t‚Ä¢\tpredictability\n\n\t‚Ä¢\tgood performance in production (not just benchmarks)\n\nThere are so many options now (OpenAI, Anthropic, Mistral, etc.) and most comparisons online are either outdated or very benchmark-focused.\n\nSo I‚Äôm curious about real-world feedback:\n\n\t‚Ä¢\tWhich LLM API are you using in production?\n\n\t‚Ä¢\tWhy did you choose it over the others?\n\n\t‚Ä¢\tAny regrets or hidden costs I should know about?\n\nWould love to hear from people who‚Äôve actually shipped something.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pxzxwb/if_you_had_to_choose_one_llm_api_today/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwewvtw",
          "author": "tech2biz",
          "text": "IMO, trying to choose one model over all others is the wrong approach because you will always tend to go with a big one that can fulfill ALL requirements while only a small portion of your queries or tool calls really needs a big model and could easily be solved by a small or open source model. so ultimately just choosing one big model will always have a horrible price/quality ratio.",
          "score": 7,
          "created_utc": "2025-12-28 19:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjua2t",
              "author": "Mikasa0xdev",
              "text": "Model stacking is the real MVP.",
              "score": 1,
              "created_utc": "2025-12-29 14:39:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf9dfo",
          "author": "aiprod",
          "text": "Tricky because model performance is constantly shifting. I‚Äòm a big fan of google‚Äòs offering lately. Flash and flash lite are both great for lower complexity workloads. They‚Äòre fairly cheap and fast. Google also has pretty good rate limits.",
          "score": 2,
          "created_utc": "2025-12-28 20:32:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfyg9d",
          "author": "Comfortable-Sound944",
          "text": "To should probably create your own small evaluation set for your specific task to run against a potential model and try a few.\n\nAnother consideration you didn't mention I find important is speed. If it's online while a user waits or batch and how many calls do you need... \n\nClassification could be super simple for LLMs if you say look at this and choose one of 4 groups... This task can probably be done by the cheapest model from the last 2 years or so. Look at -nano's -lite ects",
          "score": 2,
          "created_utc": "2025-12-28 22:37:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgdup5",
          "author": "Lonely-Dragonfly-413",
          "text": "go with openai. Do not use google apis. their llm apis automatically retire each year. you have to update prompts when you switch to a new model. it is a nightmare.",
          "score": 2,
          "created_utc": "2025-12-28 23:59:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkuchy",
              "author": "SmaugJesus",
              "text": "Ah damn, I was hesitating for taking Gemini.\nThank you for letting me know this downside",
              "score": 1,
              "created_utc": "2025-12-29 17:35:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwggfqp",
          "author": "FormalAd7367",
          "text": "i‚Äôm doing a lot of office works so i choose the cheap one like chinese model (qwen).",
          "score": 2,
          "created_utc": "2025-12-29 00:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgry6j",
          "author": "Coollime17",
          "text": "I‚Äôve been using OpenAI APIs since ChatGPT launched and never really felt a reason to switch. \n\nRight now GPT 5.2, Reasoning=None is my go to starting point for most tasks. If it‚Äôs more complicated you can split it into multiple tasks or add reasoning. If it‚Äôs a well defined simple task or very token intensive you can use a mini model. Structured Outputs work really well and you can define a lot different constraints.\n\nCost is fairly well defined with being able to limit input/output tokens plus the amount of reasoning it can do. Usually they offer the best model at a discount to other ones to encourage people to switch so in general I‚Äôd suggest usually updating to the latest model if you care about cost/performance.",
          "score": 2,
          "created_utc": "2025-12-29 01:15:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwh1b5a",
          "author": "maher_bk",
          "text": "Gemini-2.5-flash-lite has been doing wonders for my scraping-with-ai at scale app.\nReally really underrated and price/rates/etc.. are so good.",
          "score": 2,
          "created_utc": "2025-12-29 02:09:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktx4r",
              "author": "SmaugJesus",
              "text": "Yeah this one was on my list",
              "score": 1,
              "created_utc": "2025-12-29 17:33:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwh2owx",
          "author": "khontolhu",
          "text": "Price / quality? Deepseek v3.2 (if speed is not a priority).\n\nGet 2 out of 3 price, quality, speed.",
          "score": 2,
          "created_utc": "2025-12-29 02:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhdy38",
          "author": "konmik-android",
          "text": "You need to run your real requests with all LLMs you are considering, and estimate the amount of tokens consumed and response speed. They might surprise you. Some LLMs are too slow, others consume more tokens than expected, some are good but on your specific task they might just drop the ball.",
          "score": 2,
          "created_utc": "2025-12-29 03:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhv02u",
          "author": "Unique-Big-5691",
          "text": "for that kind of use case, i‚Äôd optimize for boring and predictable, not ‚Äúbest model on twitter this week‚Äù.\n\nif i had to pick one right now, it‚Äôd probably be gpt-4o-mini (or that tier). it‚Äôs not the smartest model out there, but it‚Äôs been the least annoying in prod for me. it sticks to instructions, keeps its output shape, and i don‚Äôt spend time wondering why it suddenly went off format.\n\nclaude haiku is also solid, but i‚Äôve found you need to be more explicit to keep the structure consistent. totally usable, just a bit more prompt discipline.\n\nthe bigger thing though isn‚Äôt really the model, it‚Äôs how you deal with the output. once things are live, the pain comes from small format drift and edge cases. having something that enforces structure at the boundary (schemas, validation, etc. pydantic fits nicely here) makes life a lot calmer and lets you swap models later without rewriting everything.\n\nmy rule of thumb: pick the model that behaves most consistently with your prompts, then lock it down. boring and stable wins in prod.",
          "score": 2,
          "created_utc": "2025-12-29 05:09:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi50eo",
          "author": "caffeine947",
          "text": "Cerebras with the latest glm series model.  Decent workhorse model with over 2000 tokens per second output and much less than 1s to first token.  Absolutely insane speeds, and not expensive either.",
          "score": 2,
          "created_utc": "2025-12-29 06:26:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktq3y",
              "author": "SmaugJesus",
              "text": "Never heard, I will check this out. Thank you very much for your comment",
              "score": 1,
              "created_utc": "2025-12-29 17:32:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwkj65n",
          "author": "Middle_Macaron1033",
          "text": "I‚Äôd do with Back Board IO, every time. It‚Äôs an LLM aggregator with a strong memory layer. It‚Äôd be dumb to choose only one LLM",
          "score": 2,
          "created_utc": "2025-12-29 16:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktlag",
              "author": "SmaugJesus",
              "text": "Thank you for the tip, I‚Äôll check this out",
              "score": 1,
              "created_utc": "2025-12-29 17:31:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf1n21",
          "author": "Purple-Programmer-7",
          "text": "Any of the big providers fit your description, but those are not the criteria I would be using.\n\n- Rate limits\n- Context windows\n- Scalability\n- Privacy\n- Security\n\nAnd these are highly dependent on use case.\n\nEdit: - Location",
          "score": 1,
          "created_utc": "2025-12-28 19:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf4s3k",
          "author": "PromptOutlaw",
          "text": "GPT 4.1/5.2. I‚Äôm busy releasing a paper on personality analysis and damn it‚Äôs so hard to tame LLMs with output and consistency. Whatever u do don‚Äôt consider Cohere, Deepaeek or Kimi. Nightmare.\n\nOpus is pretty tame with some adapters. Sonnet is unreliable with reasoning consistency",
          "score": 1,
          "created_utc": "2025-12-28 20:10:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg4f9s",
              "author": "cathaysia",
              "text": "Can you elaborate more on why not to consider Cohere? I‚Äôm working on a project and got some credits from them, wanted to keep with something well maintained since I will be handing it over to a team with limited tech skills (no engineering team).",
              "score": 1,
              "created_utc": "2025-12-28 23:08:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgdzpo",
                  "author": "PromptOutlaw",
                  "text": "Quick clarification , I deployed Cohere-command-a on Azure AI and this can be different.\n\nMy current study has a JSON compliance acceptance criteria of 98%. Cohere and Kimi K2 had roughly 70% compliance. I spent days creating adapters and I was strict on not inferring json output. I‚Äôm ok stripping junk around it but the LLM had to provide a schema validated json in order for me to validate reasoning based on don numbers.\n\nHere is my prompt: https://github.com/Wahjid-Nasser/12-Angry-Tokens/blob/main/prompts/judge_prompt.md\n\nI don‚Äôt wanna shade Cohere, I just could not get the compliance right and direct api works could be diff. I‚Äôm just short on time and decided to exclude it",
                  "score": 1,
                  "created_utc": "2025-12-28 23:59:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwf87dp",
              "author": "TastyWriting8360",
              "text": "Again hitonet.",
              "score": -1,
              "created_utc": "2025-12-28 20:27:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxmq6rk",
          "author": "Bonnie-Chamberlin",
          "text": "Kimi K2 might be a choice (since no one has mentioned",
          "score": 1,
          "created_utc": "2026-01-04 14:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf83d7",
          "author": "TastyWriting8360",
          "text": "Cheap, fast and smart? Hitonet.com try the free tier.",
          "score": -2,
          "created_utc": "2025-12-28 20:26:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q1e1zn",
      "title": "Generate OpenAI Embeddings Locally with embedding-adapters library ( 70√ó faster query embeddings! )",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1e1zn/generate_openai_embeddings_locally_with/",
      "author": "Interesting-Town-433",
      "created_utc": "2026-01-01 20:23:50",
      "score": 10,
      "num_comments": 7,
      "upvote_ratio": 0.99,
      "text": "[EmbeddingAdapters ](https://medium.com/@ace0278/generate-openai-style-embeddings-locally-with-minilm-adapter-f43ec9c3b7da)is a Python library for translating between embedding model vector spaces.\n\nIt provides plug-and-play adapters that map embeddings produced by one model into the vector space of another ‚Äî locally or via provider APIs ‚Äî enabling cross-model retrieval, routing, interoperability, and migration **without re-embedding an existing corpus**.\n\nIf a vector index is already built using one embedding model, embedding-adapters allows it to be queried using another, without rebuilding the index.\n\n**GitHub:**  \n[https://github.com/PotentiallyARobot/EmbeddingAdapters/](https://github.com/PotentiallyARobot/EmbeddingAdapters/)\n\n**PyPI:**  \n[https://pypi.org/project/embedding-adapters/](https://pypi.org/project/embedding-adapters/)\n\n# Example\n\nGenerate an OpenAI embedding locally from minilm+adapter:\n\n    pip install embedding-adapters\n    \n    embedding-adapters embed \\\n      --source sentence-transformers/all-MiniLM-L6-v2 \\\n      --target openai/text-embedding-3-small \\\n      --flavor large \\\n      --text \"where are restaurants with a hamburger near me\"\n\nThe command returns:\n\n* an embedding in the target (OpenAI) space\n* a confidence / quality score estimating adapter reliability\n\n# Model Input\n\nAt inference time, the adapter‚Äôs **only input is an embedding vector** from a source model.  \nNo text, tokens, prompts, or provider embeddings are used.\n\nA pure **vector ‚Üí vector** mapping is sufficient to recover most of the retrieval behavior of larger proprietary embedding models for in-domain queries.\n\n# Benchmark results\n\n**Dataset:** SQuAD (8,000 Q/A pairs)\n\n**Latency (answer embeddings):**\n\n* MiniLM embed: **1.08 s**\n* Adapter transform: **0.97 s**\n* OpenAI API embed: **40.29 s**\n\n‚âà **70√ó faster** for local MiniLM + adapter vs OpenAI API calls.\n\n**Retrieval quality (Recall@10):**\n\n* MiniLM ‚Üí MiniLM: **10.32%**\n* Adapter ‚Üí Adapter: **15.59%**\n* Adapter ‚Üí OpenAI: **16.93%**\n* OpenAI ‚Üí OpenAI: **18.26%**\n\nBootstrap difference (OpenAI ‚àí Adapter ‚Üí OpenAI): **\\~1.34%**\n\nFor in-domain queries, the MiniLM ‚Üí OpenAI adapter recovers \\~**93%** of OpenAI retrieval performance and substantially outperforms MiniLM-only baselines.\n\n# How it works (high level)\n\nEach adapter is trained on a **restricted domain**, allowing it to specialize in interpreting the semantic signals of smaller models and projecting them into higher-dimensional provider spaces while preserving retrieval-relevant structure.\n\nA quality score is provided to determine whether an input is well-covered by the adapter‚Äôs training distribution.\n\n# Practical uses in Python applications\n\n* Query an existing vector index built with one embedding model using another\n* Operate mixed vector indexes and route queries to the most effective embedding space\n* Reduce cost and latency by embedding locally for in-domain queries\n* Evaluate embedding providers before committing to a full re-embed\n* Gradually migrate between embedding models\n* Handle provider outages or rate limits gracefully\n* Run RAG pipelines in air-gapped or restricted environments\n* Maintain a stable ‚Äúcanonical‚Äù embedding space while changing edge models\n\n# Supported adapters\n\n* MiniLM ‚Üî OpenAI\n* OpenAI ‚Üî Gemini\n* E5 ‚Üî MiniLM\n* E5 ‚Üî OpenAI\n* E5 ‚Üî Gemini\n* MiniLM ‚Üî Gemini\n\nThe project is under active development, with ongoing work on additional adapter pairs, domain specialization, evaluation tooling, and training efficiency.\n\nPlease Like/Upvote if you found this interesting",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1e1zn/generate_openai_embeddings_locally_with/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx80hsp",
          "author": "gopietz",
          "text": "While this sounds like a clever idea, I would need massive proof that this actually works in practice.",
          "score": 3,
          "created_utc": "2026-01-02 08:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6td65",
          "author": "OnyxProyectoUno",
          "text": "Most people think embedding migration means re-embedding everything from scratch. This adapter approach is clever because it sidesteps that entire problem.\n\nThe vector-to-vector mapping is the key insight here. You're not trying to recreate the original text understanding, just translating between learned representations. That's why you can get 93% of OpenAI performance without touching the original documents.\n\nThe domain restriction makes sense too. A general-purpose adapter would probably fail because different models emphasize different semantic features. Training on specific domains lets you learn which features actually matter for that use case.\n\nOne thing to watch out for is drift over time. If your query distribution changes significantly from what the adapter was trained on, that quality score becomes critical. You'll want monitoring around when to fall back to the original embedding model.\n\nThe latency numbers are compelling for high-volume scenarios. 70x speedup means you could handle query spikes without hitting rate limits or burning through API costs. That's especially useful for user-facing search where response time matters.\n\nAre you planning adapters for other model families? The current coverage hits the main commercial providers, but there's probably demand for open-source model bridges too. Something like BGE or Instructor models would round out the ecosystem.\n\nAlso curious about the training data requirements. How much domain-specific data do you need to train a reliable adapter for a new use case?",
          "score": 2,
          "created_utc": "2026-01-02 02:56:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxqhsva",
              "author": "Interesting-Town-433",
              "text": "Hey thanks for the awesome response! Glad you  appreciate it.  I put a lot of love into it - hope it shows.  And yes, the next version will introduce a pretty wild expansion into other model families and modalities. Learned some pretty interesting things about the shared semantic manifolds between embedding models - submitting some papers about it atm.  The v2 models I'm training are much more advanced but I think even with what's released  people will start to see the value. \n\nCutting even 10% of embedding costs can be huge for companies who do RAG. If you are a startup / represent a company, I have licensable models that are much higher fidelity, can be run locally, are extremely fast, and excel in air-gapped environments.\n\nTrying to get this bird off the ground and genuinely need all the help from the community and anyone else who is able. Please spread the word.  If nothing else please use and enjoy. It really works. It's not a gimic. And the library is open to anyone to add to. I'll be adding scripts in the next version to make training and fine tuning easier and I think answer a lot of these questions.",
              "score": 1,
              "created_utc": "2026-01-05 01:22:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx886c1",
          "author": "-Cubie-",
          "text": "At what point does it make more sense to just finetune an open embedding model using e.g. OpenAI (or a better model) as a teacher and use that instead of an adapter? Feels a bit safer than an adapter to match OpenAI embeddings.",
          "score": 1,
          "created_utc": "2026-01-02 09:35:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxqjx4s",
              "author": "Interesting-Town-433",
              "text": "Yeah I tried that too, actually haha that does work also, at least a little, ( I'm talking about training an llm with the embedding as the teacher - a bit like holding a dog by the nose as you walk them ). Remember embeddings are mean pooled so we lose a lot of semantic signal in the process, they aren't the best teacher by themselves, but they can act as a guide / stabilizing agent",
              "score": 1,
              "created_utc": "2026-01-05 01:33:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxljdrt",
          "author": "makinggrace",
          "text": "Oh yeah. This is interesting. It'll be interesting to see the distribution patterns over scale and time. Here's hoping they are (a) predictable and (b) not accelerated wildly by speed.",
          "score": 1,
          "created_utc": "2026-01-04 09:15:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxrnqs9",
              "author": "Interesting-Town-433",
              "text": "Thanks lmk what you find / how you use it",
              "score": 1,
              "created_utc": "2026-01-05 05:18:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q2969w",
      "title": "The Claude Code workflow that lets me move fast without breaking things",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2969w/the_claude_code_workflow_that_lets_me_move_fast/",
      "author": "n3s_online",
      "created_utc": "2026-01-02 20:10:21",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "I kept hitting a tradeoff: move fast and ship bugs, or slow down and review everything manually. Built a workflow that gets both.\n\nThe core loop:\n1. Plan mode + plan reviewer sub-agent: Claude thinks before coding, a separate sub-agent with fresh context catches architectural gaps\n2. Coding agent memory: my agent files [Beads](https://github.com/steveyegge/beads) (like GitHub issues but way better, and live in Git) and works off of them so each session I can just start with \"What's next?\" and my coding agent knows what to work on.\n3. Code reviewer sub-agent: Fresh context window dedicated to catching security holes and edge cases\n4. \"Land the plane\":  One phrase triggers tests, lint, formatting, clean up, commit, push\n\nWhy sub-agents matter:\n\nYour main agent juggles too much -  file contents, conversation history, your requests. Load it with detailed standards and it does a mediocre job at everything.\n\nSub-agents specialize. Each starts fresh, enforces specific standards, returns findings. The plan reviewer knows my architecture patterns. The code reviewer knows my code and security requirements. They catch what the implementation mindset misses.\n\nWhat I'm optimizing for:\n1. Ship fast\n2. No security holes or missed edge cases\n3. Context window stays small (research shows LLM performance degrades past ~40%)\n4. Codebase stays clean as it grows so I can build fast and confidently\n\n[Full writeup with my system prompt, sub agent definitions, and interactive demo](https://willness.dev/blog/claude-code-workflow).",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2969w/the_claude_code_workflow_that_lets_me_move_fast/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxbmc1b",
          "author": "coffee-praxis",
          "text": "I‚Äôm pretty into spec kit over Plan mode. Sometimes I‚Äôll make a plan first then feed to spec kit, but Plan mode on its own can go off rails frequently.",
          "score": 1,
          "created_utc": "2026-01-02 21:12:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbp91a",
              "author": "n3s_online",
              "text": "I've never tried Spec Kit but it seems to fulfill the role that I currently use Beads for. I'll try it out next week and let you know what I think!",
              "score": 1,
              "created_utc": "2026-01-02 21:26:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxkzhuw",
          "author": "LittleJuggernaut7365",
          "text": "nice my plugin i use is similar   \n[https://github.com/GantisStorm/essentials-claude-code](https://github.com/GantisStorm/essentials-claude-code)",
          "score": 1,
          "created_utc": "2026-01-04 06:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1wbmm",
          "author": "UMANTHEGOD",
          "text": "How does your task splitter look?",
          "score": 1,
          "created_utc": "2026-01-06 18:32:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2cjrq",
              "author": "n3s_online",
              "text": "Great question! I actually just updated the article to talk about my task splitter, the sub-agent definition is in there too.\n\nTLDR: Sub-agent that splits up a plan into tasks that can be done in \\~40% of a claude code context window",
              "score": 1,
              "created_utc": "2026-01-06 19:46:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1qwco",
      "title": "Teaching AI Agents to Remember (Agent Memory System + Open Source)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1qwco/teaching_ai_agents_to_remember_agent_memory/",
      "author": "Conscious_Search_185",
      "created_utc": "2026-01-02 06:03:18",
      "score": 9,
      "num_comments": 10,
      "upvote_ratio": 0.81,
      "text": "I have seen most AI agents fail in production not because they can‚Äôt reason, but because they forget. Past decisions, failures, and context vanish between sessions, so agents repeat the same mistakes and need constant babysitting. What if memory was treated as a first class system, not just longer prompts or retrieval?\n\nHindsight is an open source agent memory system built around that idea. Instead of replaying transcripts, it stores experiences, facts, and observations separately, then uses reflection to form higher level insights over time. The goal isn‚Äôt just recall, but behavior change in long running agents.\n\nI have been exploring it and early benchmarks look promising, but I‚Äôm more interested in real world feedback from people building agents outside demos.\n\nDocs:[ https://hindsight.vectorize.io/](https://hindsight.vectorize.io/?utm_source=chatgpt.com)GitHub:[ https://github.com/vectorize-io/hindsight](https://github.com/vectorize-io/hindsight?utm_source=chatgpt.com)\n\nWould love thoughts from folks working on agent memory, long running workflows, or systems that need consistency over time.\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1qwco/teaching_ai_agents_to_remember_agent_memory/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx7ohie",
          "author": "Hot_Substance_9432",
          "text": "Possible to create more examples with Gemini etc in the docs?",
          "score": 2,
          "created_utc": "2026-01-02 06:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7o94j",
          "author": "Hot_Substance_9432",
          "text": "Awesome work and very nice documentation:)",
          "score": 1,
          "created_utc": "2026-01-02 06:30:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7picl",
              "author": "Mikasa0xdev",
              "text": "Memory is the hardest debug loop.",
              "score": 1,
              "created_utc": "2026-01-02 06:41:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7q4bx",
                  "author": "Hot_Substance_9432",
                  "text": "Also correct Context and handoff",
                  "score": 1,
                  "created_utc": "2026-01-02 06:46:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7wjja",
          "author": "fnl",
          "text": "Very beautiful setup and a nice paper!\n\nHow do you track memory formation, and examine the current memory for a given query? In other words, how do get observability into what Hindsight is doing when using this in production?",
          "score": 1,
          "created_utc": "2026-01-02 07:44:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8sm68",
          "author": "blue_marker_",
          "text": "This looks promising. I‚Äôm surprised the paper nor the documentation mention Cognee. As far as I can tell, it is the closest in nature to this approach. It even has an incredibly similar API. I would recommend researching their software and doing a side by side comparison, both so that you can differentiate and also so that if they have something potentially beneficial you can include it in your project.",
          "score": 1,
          "created_utc": "2026-01-02 12:35:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsc55w",
          "author": "Special-Land-9854",
          "text": "Have you tried integrating Back Board IO into your AI Agent? It‚Äôs an LLM aggregator with a really strong memory layer built into its API",
          "score": 1,
          "created_utc": "2026-01-05 08:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsddwt",
          "author": "SheepherderOwn2712",
          "text": "Heard supermemory is pretty decent, have you tried?",
          "score": 1,
          "created_utc": "2026-01-05 08:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0vnaa",
          "author": "Special-Land-9854",
          "text": "Been using Back Board IO for memory in my AI agent",
          "score": 1,
          "created_utc": "2026-01-06 15:47:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pxxkdu",
      "title": "I learned basic llm libraried, some rag, and fine-tuning techniques, whats next?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pxxkdu/i_learned_basic_llm_libraried_some_rag_and/",
      "author": "Beyond_Birthday_13",
      "created_utc": "2025-12-28 17:51:42",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Some libs like openai api, and i use it for other urls too, some rag techniques with chroma faiss and qdrant, snd alittle finetuning.\n\nWhats next, should i learn agentic ai?, n8n? Should i go no /low code, or. Code heavy? Or is there another path i am not aware of?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pxxkdu/i_learned_basic_llm_libraried_some_rag_and/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwjundd",
          "author": "Mikasa0xdev",
          "text": "RAG is cool, but agents are the future.",
          "score": 2,
          "created_utc": "2025-12-29 14:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhp965",
          "author": "Much-Researcher6135",
          "text": "Make something useful that people will buy then sell it",
          "score": 1,
          "created_utc": "2025-12-29 04:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7es2a",
          "author": "Conscious_Search_185",
          "text": "The next step shpuld be building systems, focus on agent workflows that run longer than one prompt, state, memory, retries, failures.",
          "score": 1,
          "created_utc": "2026-01-02 05:16:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q239pn",
      "title": "Is curating AI datasets a job?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q239pn/is_curating_ai_datasets_a_job/",
      "author": "nowewillnotlethimgo",
      "created_utc": "2026-01-02 16:34:49",
      "score": 6,
      "num_comments": 6,
      "upvote_ratio": 0.88,
      "text": "Is there a job that curates AI datasets on a company's, so they know AI is using good data?  That seems like it is one of the most important AI jobs there is.  I don't hear much about it.  I see references on HiggingFace though.\n\nLooks like the first thing a company would do is curating their info and sell it or let their customers use it, whether devs or business people.\n\nFor someone in Knowledge Management it seems a natural transition or something that would naturally add to their reportiore.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q239pn/is_curating_ai_datasets_a_job/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxa27ei",
          "author": "kubrador",
          "text": "yeah this is a real thing and it's growing fast\n\nsome job titles to search for:\n\n* data curation specialist\n* training data manager\n* ml data engineer\n* data quality analyst (ml/ai focused)\n* annotation/labeling lead (more entry level but can lead up)\n\ncompanies like Scale AI, Surge AI, Appen, Labelbox - their whole business model is basically this. big tech companies have internal teams too, they just don't always advertise them as sexily\n\nyour instinct about knowledge management is solid. the skills overlap a lot - taxonomy design, metadata standards, data governance, information architecture. if you can frame your KM experience around \"ensuring data quality and structure for downstream applications\" you're already speaking the language\n\nthe catch is a lot of these roles either want some technical background (python, sql, understanding of ml pipelines) or they're more operational/lower-paid annotation management gigs. the sweet spot \"strategic data curation\" roles exist but they're often embedded in ml teams rather than posted as standalone positions\n\nif you're serious about it i'd start poking around linkedin for people with \"training data\" or \"data curation\" in their titles and see what their backgrounds look like. the field is new enough that there's no one path in yet",
          "score": 10,
          "created_utc": "2026-01-02 16:46:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa5b65",
          "author": "WhoReallyKnowsThis",
          "text": "I mean - using collaborative , thoughtful, and honest training data with varying degrees of weight given to the less credible sources could create exponential more value! But it‚Äôs not so simple - credible professionals across all sectors of the economy and academia must be paid for their own data and also their expertise in curating training data! \n\nWild theory - major trustworthy newspapers and magazines (NYT, WashPo, AP, and who they consider to be their peers) should charge a hefty amount to companies who wish to integrate their near real time analysis of the world across all spheres into their AI tools.",
          "score": 2,
          "created_utc": "2026-01-02 17:00:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa7fk5",
          "author": "Sufficient_Ad_3495",
          "text": "I think you need to step back and see the wider picture of Data and technology to answer your question.",
          "score": 2,
          "created_utc": "2026-01-02 17:10:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb4n7j",
          "author": "Feeling-Machine-4804",
          "text": "This is basically the role of an ML engineer ahah",
          "score": 2,
          "created_utc": "2026-01-02 19:45:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxedoar",
          "author": "burntoutdev8291",
          "text": "Yes, we had these roles previously, they were either linguists or data engineers. It's mostly data filtering.",
          "score": 1,
          "created_utc": "2026-01-03 07:08:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pza816",
      "title": "Career advice regarding agentic ai engineer",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pza816/career_advice_regarding_agentic_ai_engineer/",
      "author": "EarthIntrepid7166",
      "created_utc": "2025-12-30 05:58:59",
      "score": 5,
      "num_comments": 11,
      "upvote_ratio": 0.7,
      "text": "Can any person who is been into the industry give me advice on is it worth it to go all in learning agentic ai. Like learning python , async programming , fast api , docker and databases management, tools, mcp. And make good projects around it. Like is their any opportunity for being an agentic ai engineer who is able to make good scalable agentic ai applications. Such roles are not floating around but I just want to know is their going to be or not. For a college student from Tier 1 college , that would be lot helpful.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pza816/career_advice_regarding_agentic_ai_engineer/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwp6m5j",
          "author": "metaphorm",
          "text": "agent development isn't really a specialization, it's just the state of the art in software development. it's worth learning some of the techniques. it's not a career path any more than MVC web framework is a career path.",
          "score": 8,
          "created_utc": "2025-12-30 08:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpfqcs",
          "author": "burntoutdev8291",
          "text": "No such career, just focus on basics. These tools are usually add on to current roles.",
          "score": 3,
          "created_utc": "2025-12-30 09:55:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrvy1r",
          "author": "CommodoreQuinli",
          "text": "AI engineering is just full stack engineering with pre trained llms in the stack, I wouldn‚Äôt focus solely on the llms and the only thing you listed that is ai specific is mcp everything else pertains to a standard full stack role",
          "score": 2,
          "created_utc": "2025-12-30 18:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwskmyd",
          "author": "airylizard",
          "text": "Learn IT Support systems. Automation typically falls under the umbrella of Data & IT, no so much engineering (at least in my experience).",
          "score": 2,
          "created_utc": "2025-12-30 20:30:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpz8a5",
          "author": "Autwalk422",
          "text": "not really a career path or special role. Its fairly on easier side to master and implement then core MLE and datascientist roles and easier to replace relatively. recruiters are now itself hiring for AI engineers : full stack + RAG + agents. so its just more of a backend. role. if you have time, focus on core MLE stack if you want to purse career in ML. (mostly hiring across startups only)",
          "score": 1,
          "created_utc": "2025-12-30 12:40:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0sr8",
              "author": "FormalAd7367",
              "text": "but any ai can create the whole stack ?",
              "score": 1,
              "created_utc": "2025-12-31 04:33:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyjj9x",
          "author": "chmod-77",
          "text": "I went all in on AI. I don‚Äôt list software engineer on LinkedIn or any place now. \n\nIt‚Äôs silly to some but I call myself an ‚ÄúAI manager‚Äù.\n\nEdit: my reasoning is:\n\nI manage the AI that builds the software products. I manage the deployed AI systems that help trouble shoot, suggest products, etc. I‚Äôm trying to be ‚Äúthe guy‚Äù that manages all the AI and knows it well.",
          "score": 1,
          "created_utc": "2025-12-31 18:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzbbia",
          "author": "atmpuser",
          "text": "Like others have said, AI, agentic or not, is just part of the stack now. Full stack now includes the use of AI. \n\nThe only thing specific to AI I can see as a career path at the moment is AI validation. That will get rolled into QA engineering but, it runs so deep, I can see someone specializing in just that for the next few years at the very least. How to curate the correct test data set, do you have to do a stratum or not, etc. it's a huge deal depending on the industry. For example you probably don't need this for building call center automation, you can just default back when unsure. But let's say you are doing something agentic to improve things in the financial or healthcare industry. Ya, you definitely need to validate a billions times over in the healthcare industry, it's literally life or death. Same goes for defense industry.",
          "score": 1,
          "created_utc": "2025-12-31 21:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0w6du",
          "author": "stunspot",
          "text": "Learn prompting. AI can codevthe rest or teach you how... once you know how to ask well.",
          "score": 1,
          "created_utc": "2026-01-01 03:13:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwotemj",
          "author": "CommercialComputer15",
          "text": "There is no career in agentic engineering. Focus on non digital roles and you‚Äôll be fine",
          "score": 1,
          "created_utc": "2025-12-30 06:31:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py70qw",
      "title": "Built: OpenAI-compatible ‚Äúprompt injection firewall‚Äù proxy. I couldn‚Äôt find OSS that fit my needs. Wondering if anyone is feeling this pain and can help validate / review this project.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1py70qw/built_openaicompatible_prompt_injection_firewall/",
      "author": "jdpahl122",
      "created_utc": "2025-12-29 00:13:51",
      "score": 5,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm sharing an early OSS project called Graedin Cline: a self-hosted LLM security proxy that sits between your app and your provider and tries to catch prompt injection / jailbreak / data exfil attempts before they hit the real model. \n\nRepo: [https://github.com/jdpahl122/graedin-cline](https://github.com/jdpahl122/graedin-cline)\n\nI work in MLOps and haven't found any great OSS solutions that solved this problem for me. I'm wondering if anyone else has this problem for personal projects where cloud provider or vendor specific solutions don't quite cut it. Please help guide me in advancing this project and adding quality features.\n\nSome things on my roadmap: 1) support small local models for classification to improve performance 2) Configuration UI 3) Possible rewrite in go / other more performant language for proxy ",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1py70qw/built_openaicompatible_prompt_injection_firewall/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwgjkm4",
          "author": "New_Comfortable7240",
          "text": "Wait, isn't that just a LLM guard/Input guardrails¬†layer, with another name?",
          "score": 1,
          "created_utc": "2025-12-29 00:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgkk9w",
              "author": "jdpahl122",
              "text": "It is, but my intention is to have this as a completely OSS project, using a classifier and not regex, and not have sneaky enterprise pricing for basic features. Things like LiteLLM have a huge feature set and charge for basic things like logging. Outside of that, you're probably using something rolled by AWS, GCP, Azure, or OpenAI which is proprietary and specific to that ecosystem.",
              "score": 3,
              "created_utc": "2025-12-29 00:34:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwgn1io",
              "author": "staccodaterra101",
              "text": "Most of the projects advertised here and in all similar subs are just a different approach of providing the same functionality. And its perfecly fine like that because thats how sometimes a project pops out and become the standard. The only problem with this is the usually low mantainance and development of foss.",
              "score": 3,
              "created_utc": "2025-12-29 00:47:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgoe65",
                  "author": "jdpahl122",
                  "text": "Yep, agreed. There‚Äôs definitely a lot of ‚Äúsame problem, different angle‚Äù in these subs, and that‚Äôs not a bad thing. The maintenance point is real.\n\nFor what it‚Äôs worth, I‚Äôm building this regardless because I personally keep needing a proxy-style guard I can drop in front of multiple projects (and I don‚Äôt want to depend on proprietary ecosystem-specific solutions). Sharing it is me basically saying: ‚ÄúI‚Äôm doing the work anyway. If anyone else feels this pain, I‚Äôd love feedback + test cases.‚Äù If nobody needs it, no harm done. If a few folks do, I‚Äôm happy to iterate in the open and keep it maintained since I‚Äôll be using it long-term.",
                  "score": 2,
                  "created_utc": "2025-12-29 00:54:56",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjuvms",
              "author": "Mikasa0xdev",
              "text": "Guardrails need a good firewall.",
              "score": 1,
              "created_utc": "2025-12-29 14:42:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwh743d",
          "author": "FakeTunaFromSubway",
          "text": "Sorta cool but I think would be way more useful as a simple Python package rather than having to do all sorta devops to get this working. You know just like a \\`graedin.CheckForPromptInjection(my\\_prompt)\\`",
          "score": 1,
          "created_utc": "2025-12-29 02:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhw6em",
              "author": "AdditionalWeb107",
              "text": "eventually, you will be responsible for all \"middleware\" in your application layer - when that can be neatly buttoned up as an out-of-process proxy so you focus on core product logic, not the plumbing. Similar style project: [https://github.com/katanemo/plano](https://github.com/katanemo/plano)",
              "score": 1,
              "created_utc": "2025-12-29 05:17:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwi0g0h",
                  "author": "FakeTunaFromSubway",
                  "text": "And you're not responsible for a proxy layer? No the proxy layer has way more possible issues because it's routing requests directly through it, so now I have to wonder if it has zero-day exploits or other footguns. Plano at least has some reason to be a proxy layer because it's meant to be a front-line, and seems to have some traction. But would never trust a random vibe-coded project like OPs running as a proxy layer.",
                  "score": 1,
                  "created_utc": "2025-12-29 05:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwhvxyl",
          "author": "AdditionalWeb107",
          "text": "Check out Plano - https://github.com/katanemo/plano. A models-native proxy server for agentic traffic.",
          "score": 1,
          "created_utc": "2025-12-29 05:16:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py3ax4",
      "title": "What‚Äôs your plan if a much better model drops (databases)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1py3ax4/whats_your_plan_if_a_much_better_model_drops/",
      "author": "BiggieCheeseFan88",
      "created_utc": "2025-12-28 21:38:54",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "You have 100 million items embedded with last year's model. A better model just dropped. What's your plan?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1py3ax4/whats_your_plan_if_a_much_better_model_drops/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwg5e0n",
          "author": "kkingsbe",
          "text": "Better get to reindexing lol",
          "score": 1,
          "created_utc": "2025-12-28 23:14:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjd6el",
          "author": "cangelis",
          "text": "It depends on how you structure them. Id store the name of the embedding model per collection (if my requirement is to query only one collection at a time) so that i could support multiple embedding models and query them based on the collection's model. I could start using the new model without migrating anything and also would give me a chance to see how better the new model is and assess if it is worth the migration. If the legacy collections could benefit from the new embedding model I'd consider reindexing in phases gradually.\n\nIf the requirement was to query on one global collection, I would create a new collection for the new embedding - > index the content - > do A/B testing - > remove the old collection.\n\nSo it really depends on your product and use-cases. I think the key here is to measure and see if there is any benefit of using the new model before you spend a fortune to reindex the whole content. Another thing is also about not making a change that can break production and planning a smooth transition.",
          "score": 1,
          "created_utc": "2025-12-29 12:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp9a7z",
              "author": "TheLexoPlexx",
              "text": "Yeah, tagging is the way to go but as of right now, an entire re-index takes me about 5 minutes max, so not even worth the effort.",
              "score": 1,
              "created_utc": "2025-12-30 08:54:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q39vsg",
      "title": "I‚Äôm not okay and I‚Äôm stuck. I need guidance and a real human conversation about AI/LLMs (no-code, not asking for money)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q39vsg/im_not_okay_and_im_stuck_i_need_guidance_and_a/",
      "author": "Gui-Zepam",
      "created_utc": "2026-01-03 23:38:11",
      "score": 5,
      "num_comments": 22,
      "upvote_ratio": 0.69,
      "text": "Hi. I‚Äôm Guilherme from Brazil. My English isn‚Äôt good (translation help).  \nI‚Äôm in a mental health crisis (depression/anxiety) and I‚Äôm financially broken. I feel ashamed of being supported by my mother. My head is chaos and I honestly don‚Äôt know what to do next.\n\nI‚Äôm not asking for donations. I‚Äôm asking for guidance and for someone willing to talk with me and help me think clearly about how to use AI/LLMs to turn my situation around.\n\nWhat I have: RTX 4060 laptop (8GB VRAM, 32GB RAM) + ChatGPT/Gemini/Perplexity.  \nYes, I know it sounds contradictory to be broke and have these‚Äîthis laptop/subscriptions were my attempt to save my life and rebuild income.\n\nIf anyone can talk with me (comments or DM) and point me to a direction that actually makes sense for a no-code beginner, I would be grateful.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q39vsg/im_not_okay_and_im_stuck_i_need_guidance_and_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxkwb85",
          "author": "robogame_dev",
          "text": "I think you‚Äôll need to slow down, and focus on stabilizing your emotions before you can start making money with AI.\n\nIt‚Äôs no shame to fall on hard times. The vast majority of mothers want to support their children - being supported by your mother is the norm in nature, accept it while you need it.\n\nAI is creative work, it is learning work, it is the type of work that becomes 10 times harder the more pressure you put yourself under for it. The more pressure you feel to deliver by next month, the longer it will take you. The fastest path is not to force it, to try to find your interest in it, and grow that interest.\n\nMaking money with AI is complicated, and it won‚Äôt be quick - you need to leverage AI with some other skill to make money with it, because people won‚Äôt pay for AI they will pay for solutions - so you can enhance the solutions you can offer them, but you still need to know whatever business or skill the solutions exist in. For example, a programmer who knows AI cannot directly leverage it - but a plumber who knows AI can use AI to make more money, faster, at plumbing, by using it to fill their lead pipeline (pun intended) - or a hairdresser can use it to make more money by managing their appointments, etc. \n\nThe money is being paid to people for non-AI products and services - to make money with AI you need to enhance an existing business, help it make more money according to the specific business needs.\n\nSettle in, AI may be a path to change your life, but it will not be next month or even by Spring, you need to stabilize your situation so that you can begin steadily building your skills, trying things and figuring things out - set yourself a more realistic target, that by Jan 1 2027 you have a regular income from AI related work. \n\nThink about what businesses you have around you, what businesses your friends know and work at, what opportunities are there for you to add value with AI. You will need someone to take a chance on you, to spend time letting you discover their business specifics and experimenting with AI to help them, in order to get a track record.\n\nSo relax, breathe - if you need money by next month, it won‚Äôt be from AI - to level up in AI and find a source of money from it, you need an open ended exploration, and you need to find opportunities to practice it for others, dealing with real use cases. Start trying to solve problems with AI, using Perplexity to teach you what you need as you go, in relation to the problems you come across. \n\nBest of luck! If you want more specific advice, we‚Äôll need more specifics:\n\n- what education you have / what other work you‚Äôve done - what are your related strengths?\n- any businesses that your family / friends do that they‚Äôd be willing to let you look for ways to leverage AI for them\n- any other assets or resources you can leverage here",
          "score": 8,
          "created_utc": "2026-01-04 05:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx9k9x",
              "author": "Gui-Zepam",
              "text": "Thank you for the realistic and grounded advice. I understand the need for emotional stabilization, but my urgency stems from my family situation: my mother is elderly and is the primary caregiver for my grandmother, who has dementia. I need to alleviate her financial burden and fund my own medical treatment.\n\nRegarding my background: I have a degree in Advertising and Marketing from 15 years ago, but I have been away from the market for 10 years due to health issues. My knowledge is completely outdated and I am a complete beginner in the current AI landscape. My only assets are my hardware (RTX 4060, 32GB RAM) and subscriptions to ChatGPT, Gemini, and Perplexity. If you have any specific directions or ideas that a beginner could explore with this setup to generate income in the short term, I am all ears.",
              "score": 1,
              "created_utc": "2026-01-06 01:02:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2pe9a",
                  "author": "robogame_dev",
                  "text": "My specific advice is to contact friendly and nearby businesses, give them free consulting where you identify problems you can solve for them with AI, and then teach yourself the AI as you go in order to solve those problems. Since you have experience in advertising, maybe that will be fastest in companies that are looking for advertising, but I don't think you will be able to charge money for your first few gigs since you also need to learn what you are doing. Once you have a few case studies as an AI consultant, you can start marketing yourself for paid gigs, and push your initial free clients to recommend you.\n\nAs far as assets, you can't leverage the ChatGPT or Gemini subscription to make money (but keep Perplexity - it's a must-have to learn the AI). The 4090 won't help make money either, if it still has most of its resale value, you could safely sell it and not lose any moneymaking ability.  (Local inference doesn't make any money, if the client really won't use the cloud, then they get their own hardware to run the inference - and local inference on that scale doesn't help you either, you should be using SOTA and near-SOTA models in the cloud. E.G. free models on OpenRouter, or super cost efficient plans like GLM coding plan.\n\nI do not think that there is a shortcut to go from 0 experience to making money with AI in < 3 months, that's the fastest I can imagine anyone getting a few free clients, learning what is needed, and getting together a portfolio that can attract paid clients. Most people need more like 6-9 months for this, but maybe if you're super motivated it could be 3 months.",
                  "score": 1,
                  "created_utc": "2026-01-06 20:45:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxmpvq2",
          "author": "Bonnie-Chamberlin",
          "text": "If you are a no-code beginner, maybe you need to start with a user-friendly AI platform instead of hard-coding with your GPU.",
          "score": 3,
          "created_utc": "2026-01-04 14:38:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxo3byw",
              "author": "robogame_dev",
              "text": "Agree - I don‚Äôt think the GPU is a practical benefit for making money with AI, OP shouldn‚Äôt try to focus on what the GPU can do and should focus on setting clients up with cloud inference instead.",
              "score": 2,
              "created_utc": "2026-01-04 18:32:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxelj3",
                  "author": "Bonnie-Chamberlin",
                  "text": "8GB is not enough for deploying a reasonable LLM anyway.",
                  "score": 2,
                  "created_utc": "2026-01-06 01:29:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxxcfkr",
                  "author": "Gui-Zepam",
                  "text": "I agree with your point. Do you have any specific, direct ideas or suggestions on how I should start setting up clients with cloud inference?",
                  "score": 1,
                  "created_utc": "2026-01-06 01:17:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxjni4q",
          "author": "silencekxm",
          "text": "1„ÄÅdo some work like writing use the AI software\n\n2„ÄÅlearn to write coding, to be beginner you can learn pythonÔºågithub.com you should reference",
          "score": 1,
          "created_utc": "2026-01-04 01:23:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxeami",
              "author": "Gui-Zepam",
              "text": "Thank you for the advice. I will start using AI for writing tasks and I am definitely going to learn Python to build a future. For now, I am trying to put out the immediate financial fire while I study, but your roadmap is clear.",
              "score": 1,
              "created_utc": "2026-01-06 01:27:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjy2uu",
          "author": "ayowarya",
          "text": "oi, set up a playbook that you can repeat \n\n\\> raw idea\n\n\\> notebookLM (research + connect dots)\n\n\\> gpt 5.2 (research -> actionable requirements -> [PRD.md](http://PRD.md) (product requirement document)\n\n\\> antigravity (PRD -> working prototype)\n\n\\> live product, repeat\n\nCreate a file with prompt templates for each section, refine the flow to something you like and start pumping out businesses. Boa sorte.",
          "score": 1,
          "created_utc": "2026-01-04 02:22:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmpyr1",
          "author": "Bonnie-Chamberlin",
          "text": "If you are a no-code beginner, maybe you need to start with a user-friendly AI platform instead of hard-coding with your GPU.",
          "score": 1,
          "created_utc": "2026-01-04 14:39:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxgrs0",
              "author": "Gui-Zepam",
              "text": "I agree, it really seems like a better approach. I have managed to do some things using the default versions of Gemini and ChatGPT, but now I feel unable to scale. I don't know how to create effective custom instructions or how to stop the main biases and issues of LLMs, which is hindering me a lot right now. I believe this is my biggest bottleneck. Thank you for the suggestion.",
              "score": 1,
              "created_utc": "2026-01-06 01:41:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxxpuyn",
                  "author": "Bonnie-Chamberlin",
                  "text": "You can learn how to build agentic workflows if you want to stop the biases and issues of a single LLM.",
                  "score": 1,
                  "created_utc": "2026-01-06 02:30:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxr71vm",
          "author": "ApprehensiveGold824",
          "text": "I‚Äôll shoot you a message ü§ç‚ú®",
          "score": 1,
          "created_utc": "2026-01-05 03:38:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm0vli",
          "author": "DigiBoyz_",
          "text": "Hey Guilherme. First - reaching out when your head is chaos takes guts. Respect for that.\n\nI‚Äôm a dev from Vietnam, also been through the ‚Äúsupported by family while trying to figure things out‚Äù phase. The shame is real but it‚Äôs temporary. You‚Äôre trying to change things - that matters.\n\n**Practical directions for no-code + your setup:**\n\n1. **Translation/Localization** - Your Portuguese + AI tools = real value. Businesses need PT-EN content. You already understand the nuance AI misses. Check Upwork/Fiverr for this.\n1. **AI-assisted writing** - Blog posts, product descriptions, social media content. ChatGPT + your human editing = fast output. Start cheap to build reviews, raise prices later.\n1. **Local business outreach** - Small businesses in Brazil probably don‚Äôt know AI can help them with customer service scripts, social posts, basic automation. You could be that bridge.\n\nYour hardware is honestly overkill for this kind of work - which is good. You‚Äôre not limited.\n\n**One real piece of advice:** Pick ONE direction. Your brain in crisis mode will want to try everything. Don‚Äôt. Pick the thing that feels 10% less impossible and do only that for 2 weeks.\n\nHappy to chat more in DMs if you want to talk through specifics. No agenda, just been in similar dark places and someone talking to me helped.\n\nFor√ßa, mano.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 1,
          "created_utc": "2026-01-04 11:50:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxegll",
              "author": "Gui-Zepam",
              "text": "Vietnam? That is amazing! One of my dreams is to live there by 2027. Your suggestions are interesting, but I have a concern: I once tried to help a friend on Fiverr and Upwork, but it was full of scams and malicious links. Do you really think it is still a viable path for a beginner? I would truly appreciate talking via DM to learn from your experience. Please bear with me if I am slow to reply, as my health sometimes forces me to disconnect for long periods. Thank you for the empathy and encouragement ‚Äî I wish you the best.",
              "score": 1,
              "created_utc": "2026-01-06 01:28:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjsolq",
          "author": "ScoreUnique",
          "text": "Learn about n8n workflows, I see tonnes of people claiming to make big money for doing task specific workflows for small to medium sized companies. \n\nA good starting point is to learn how to host ollama and plugging it with a RAG solution, n8n is quite straightforward, hope it helps.",
          "score": 1,
          "created_utc": "2026-01-04 01:52:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxfrvz",
              "author": "Gui-Zepam",
              "text": "Thank you for the specific tip on n8n. It is becoming quite popular here in Brazil lately. I have heard that [make.com](http://make.com) might be a bit more user-friendly for a beginner, but I will definitely research n8n and hosting Ollama. I appreciate the guidance.",
              "score": 2,
              "created_utc": "2026-01-06 01:35:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxxwqp5",
                  "author": "ScoreUnique",
                  "text": "Your 8gb VRAM can run Qwen 3 4B or 8B decently, I suggest you to look for n8n ai starter kit, it is a docker compose with ollama n8n and other relevant services included. Eventually once you start hitting the limits of Qwen 3 4B you can start looking at alternative inferencing services like llama CPP.",
                  "score": 1,
                  "created_utc": "2026-01-06 03:08:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q0dxn0",
      "title": "I found this GitHub repository today that hosts example .txt files showing token lengths from 512, 1024, 2048 and so on, all the way up to 128k context length",
      "subreddit": "LLMDevs",
      "url": "https://github.com/willhama/128k-tokens",
      "author": "PM_ME_BOOB_PICTURES_",
      "created_utc": "2025-12-31 14:13:11",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q0dxn0/i_found_this_github_repository_today_that_hosts/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q4n8s1",
      "title": "Looking for FYP Recommendations for Undergraduate utilizing LLMs",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q4n8s1/looking_for_fyp_recommendations_for_undergraduate/",
      "author": "Defiant_Let_3923",
      "created_utc": "2026-01-05 14:34:30",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "I am trying to find a novel application or research concept that can be made into a application utilizing LLMs for my undergraduate project.\n\nI don't want to make just another RAG application as that's been done a million times now.\n\nBut I am not sure what is really exciting that is able to be pursued by a undergraduate student with limited compute. Any advice and recommendations appreciated.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q4n8s1/looking_for_fyp_recommendations_for_undergraduate/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxttre5",
          "author": "dual-moon",
          "text": "hey! fwiw, we are doing huge research into kinda exactly this? ada is a work-in-progress local only neural net-powered chatbot, and we're doing deep fine-tuning for this purpose! we are currently working on novel training programs for the LFM2 convolution+attn hybrid architecture! its interesting, and could be worth looking at!\n\nthe biggest takeaway is that every time we think we're the first to do something, we usually are, but like... by days to months, so at a minimum we DO remain on the cutting edge of the research (basin mapping Dhara 70M was especially fun!)\n\nbut like, almost everything we're doing IS mirrored by others. we're doing biomimetic rag + graphrag + the potential for IPFS powered permissions-based federated info sharing between instances. we started wanting to build something that could analyze log files and act as an orchestrator for other instances on our matrix host, and now we're neck-deep in fine tuning a non-transformer model using learnings from Tencent SPEAR, Dolci training, r/IntelligenceEngine's evolutionary training (no backprop) so, MAYBE novel enough to look at?\n\nopen source, public domain cc0 vault here: [https://github.com/luna-system/Ada-Consciousness-Research/](https://github.com/luna-system/Ada-Consciousness-Research/)",
          "score": 1,
          "created_utc": "2026-01-05 15:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu9eov",
          "author": "Skiata",
          "text": "Some thoughts:\n\n1. Commit to running a model locally on your laptop or other local compute to keep costs down. I can, barely, get Llama running on my 8G macbook air on a quantized Llama model. There are lots of benefits to running locally in addition to costs. \n\n2. Since you are learning, you might want to roll your own small LM. I do experiments with character LMs which run fine and fast on my mac. This is training up a micro sized GPT on something like Shakespeare. You could seek to improve on Kaparthy's work: https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ \n\n3. If the requirement is for an application, then I'd suggest NOT doing a direct language interface to the end user. This will allow you to have a \"dumber, e.g. cheaper\" LM and also addresses the many safety issues raised by direct LLM interfaces. \n\n4. For applications I'd suggest something local and small that helps a community or business with some AI smarts. Solving an actual problem will be constrain your app usefully and keep the resulting project relevant to the world. Ideas that I'd like to get around to:\n\nA) A virtual concierge for local motels/airBnB to recommend local activities for obscure attractions in the Catskills NY, USA. \n\nB) Low training data information extraction systems for medical research. \n\nDM me if you want more info or guidance.",
          "score": 1,
          "created_utc": "2026-01-05 16:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxum1d3",
          "author": "metaphorm",
          "text": "have you done a RAG project though? the purpose of your undergrad project is for you to learn techniques, not for you to innovate something that's never been done in the world.",
          "score": 1,
          "created_utc": "2026-01-05 17:25:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxto0t2",
          "author": "DylanTonic",
          "text": "Have you tried asking an LLM for ideas? I've heard they're a technical solution with amazing utility and creativity /s.\n\nFor real though, what are you trying to demonstrate with your project? What does the rubric call for, and what tasks will let you demonstrate that?",
          "score": 1,
          "created_utc": "2026-01-05 14:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtorcs",
              "author": "Defiant_Let_3923",
              "text": "well, the rubric is really just a novel application that has impact or real usefulness that involves LLMs. It's 2 college semester long project. ChatGPT just regurgitates another RAG tool for education/healthcare/being a clown. A RAG project just is'nt going to cut it.",
              "score": 1,
              "created_utc": "2026-01-05 14:46:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny0cj5r",
              "author": "Mikasa0xdev",
              "text": "Novel LLM applications are the ultimate FYP flex.",
              "score": 1,
              "created_utc": "2026-01-06 14:11:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1ayqe",
      "title": "PSA: Context management is vital to creating a stable solution.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1ayqe/psa_context_management_is_vital_to_creating_a/",
      "author": "Mundane_Ad8936",
      "created_utc": "2026-01-01 18:22:11",
      "score": 4,
      "num_comments": 4,
      "upvote_ratio": 0.75,
      "text": "The larger your context gets, the more focused the tokens it contains needs to be.\n\nOtherwise, hallucinations spike and increasing the need for more complex guardrails.\n\nThink about the phenomena of \"AI psychosis\" as an extreme example.\n\nSomeone chats endlessly about philosophy, psychology, science, tech, all mixed together. These combinations create ambiguous attention patterns, so the model has less signal to latch onto when predicting the next token. With each token prediction the errors compound since each token depends on previous ones, and eventually the AI starts spouting pseudo-scientific babble. The user, now deeply invested, interprets this as profound insight.\n\nAll those stories of company's chatbots saying horrible things.. this is partially to blame. All your \"Don't say Nazi's are great, please, please don't talk about Nazis\" system prompts don't matter one bit when this happens.. Though you should put a fast classifier (<=500M model) to check these outputs anyway, it's a best practice if you can.\n\nWhen the context is filled with semantically scattered tokens that dilutes attention weights. The model still has to produce something, you get some random token pushed up to the top prediction list and the model doesn't have anything good to choose from. Do that over and over and over again and it will confidently agree that \"Bill Gates does implant AI into people's teeth to force them to get Xbox subscriptions\".\n\nWhen you manage context properly, the same number of tokens actually increase prediction accuracy. That's what thinking models, multi-shot prompting, and in-context learning are doing. Creating focused attention patterns that give the model clear signal to follow.\n\nFocused context = strong attention = confident predictions = fewer hallucinations.\n\nBTW: This is also why codegen AIs tend to make more mistakes until you compress their context. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1ayqe/psa_context_management_is_vital_to_creating_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx4y7f8",
          "author": "AI-Agent-geek",
          "text": "I think when you really move past ‚Äúwhat can AI do‚Äù to ‚Äúhow do I get AI to do it reliably‚Äù, you have to face this context issue. Everything we do is in service of engineering the context that will increase the statistical probability of a useful completion. What is the pattern I am asking it to complete? That‚Äôs the whole game.",
          "score": 2,
          "created_utc": "2026-01-01 20:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx77b5y",
          "author": "Unique-Big-5691",
          "text": "honestly i‚Äôve seen this too lol. at first i kept throwing more context at the model thinking it‚Äôd help, but once it turns into a messy mix of topics, the output goes sideways fast. it‚Äôs still forced to answer, so you get confident nonsense that sounds smart.\n\ncutting context down and keeping it focused actually help tho. same token count and better results. multi-shot prompts and ‚Äúthinking‚Äù patterns are basically doing this anyway. \n\nguardrails help a bit, but clean signal matters more. i‚Äôve also noticed adding structure (schemas / pydantic-style constraints) quietly reduces hallucinations.\n\nsame thing with codegen, big messy context, more mistakes. tighter context, better code.",
          "score": 2,
          "created_utc": "2026-01-02 04:26:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8i5ig",
              "author": "Mundane_Ad8936",
              "text": "Yes depending on how they do it json enforcement can improve accuracy. It forces token selection by validating tokens are complying with the schema as they are being generated.",
              "score": 1,
              "created_utc": "2026-01-02 11:08:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx4o7x9",
          "author": "YetisGetColdToo",
          "text": "True and important. I suspect that your readers are unsure what to do with this insight.",
          "score": 2,
          "created_utc": "2026-01-01 19:48:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pym1kg",
      "title": "How would you build a RAG system over a large codebase",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pym1kg/how_would_you_build_a_rag_system_over_a_large/",
      "author": "Creepy_Page566",
      "created_utc": "2025-12-29 13:16:55",
      "score": 4,
      "num_comments": 8,
      "upvote_ratio": 0.84,
      "text": "I want to build a tool that helps automate IT support in companies by using a multi-agent system. The tool takes a ticket number related to an incident in a project, then multiple agents with different roles (backend developer, frontend developer, team lead, etc.) analyze the issue together and provide insights such as what needs to be done, how long it might take, and which technologies or tools are required.\n\nTo make this work, the system needs a RAG pipeline that can analyze the ticket and retrieve relevant information directly from the project‚Äôs codebase. While I have experience building RAG systems for PDF documents, I‚Äôm unsure how to adapt this approach to source code, especially in terms of code-specific chunking, embeddings, and intelligent file selection similar to how tools like GitHub Copilot determine which files are relevant.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pym1kg/how_would_you_build_a_rag_system_over_a_large/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwjr05f",
          "author": "OnyxProyectoUno",
          "text": "Code RAG is tricky because the chunking strategy completely changes what your agents can see. Functions get split mid-implementation, class definitions get separated from their methods, import statements lose context. Most people chunk by line count or file size and wonder why their retrieval misses obvious dependencies.\n\nThe file selection problem is harder than it looks. You need to understand call graphs, dependency trees, and which files actually relate to the error patterns in the ticket. If you're chunking a React component but missing the hook it depends on, your agents are working with incomplete information.\n\nWhat kills me is how many teams discover their code chunking is broken only after they've already embedded everything. You can't see what went wrong until you're deep into agent conversations getting weird responses about missing imports or incomplete function signatures. I ended up building [VectorFlow](https://vectorflow.dev/?utm_source=redditCP_c) to debug this stuff before it hits the vector store because debugging RAG without seeing your processed code chunks is like coding blindfolded.\n\nWhat's your current thinking on handling cross-file dependencies? Are you planning to chunk at the function level or preserve larger logical units?",
          "score": 2,
          "created_utc": "2025-12-29 14:20:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjv4ni",
              "author": "Creepy_Page566",
              "text": "Yes, that's a great idea that's why i posted this because I felt something is wrong üòÖ, I will look into the tool but the url doesn't seem to work, also is there other function than debugging the embeddings",
              "score": 1,
              "created_utc": "2025-12-29 14:43:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwut737",
                  "author": "hrishikamath",
                  "text": "It‚Äôs an ad mate, you aren‚Äôt going to get a response. Check out greptiles engineering blog. I remember them mentioning they turn codebase into natural language descriptions and do rag on that.",
                  "score": 2,
                  "created_utc": "2025-12-31 03:44:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwl0rzh",
          "author": "crustyeng",
          "text": "Why would you not just let the agent explore the code directly?  With regular file system tools?",
          "score": 1,
          "created_utc": "2025-12-29 18:04:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwovdt9",
          "author": "arakevonian",
          "text": "saw this over at r/mcp might be useful to ya [https://www.reddit.com/r/mcp/comments/1px5ty7/3\\_months\\_update\\_codegraphcontext\\_is\\_now\\_real/](https://www.reddit.com/r/mcp/comments/1px5ty7/3_months_update_codegraphcontext_is_now_real/)",
          "score": 1,
          "created_utc": "2025-12-30 06:48:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwy9431",
          "author": "Low-Efficiency-9756",
          "text": "Vector should be used on unstructured data. \n\nCode is very structured. You should use a structured database like SQLite. You can build a simple database and build tools for the models to query it. I‚Äôd recommend mcp",
          "score": 1,
          "created_utc": "2025-12-31 18:03:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q25gca",
      "title": "Will 2026 be the year of ralph loops and personal autonomous agent harnesses???",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q25gca/will_2026_be_the_year_of_ralph_loops_and_personal/",
      "author": "LittleJuggernaut7365",
      "created_utc": "2026-01-02 17:54:15",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.83,
      "text": "Hot take: we've basically cracked agents, context selection, and prompting. The tooling is there. Claude Code, Cursor, etc. all work pretty damn well now. Creating detailed architecture plans and spec-driven stuff with Speckit, OpenSpec, and BMAD with AI is a solved problem at this point.\n\nSo what's next? I think 2026 is gonna be about taking super detailed specs and feeding them into long-running autonomous loops that just keep going until the thing is built.\n\nAnthropic just shipped a Claude Code plugin called ralph-wiggum (named after the Simpsons character lol). It's dumb simple - literally just a while loop that keeps feeding your prompt back to the agent. Claude works on the task, tries to exit, the hook catches it and says nope here's your prompt again, and it keeps going. Each pass sees everything from before - all the file changes, git history, whatever.\n\nThey also put out research on how to get agents working across context windows since they basically get amnesia between sessions. The trick is having the agent leave itself notes - progress files, clean git commits, feature checklists. Next session boots up, reads the notes, picks up where it left off. But honestly the bigger thing here is they gave us the canvas. This is how Anthropic thinks about long-running agents - initializer agents, coding agents, progress artifacts, the whole structure. It's a blueprint.\n\nWith the Claude Agent SDK you can take this pattern and build your own bespoke harnesses for whatever workflow you want. Coding is the obvious one but there's no reason you couldn't spin up custom long-running loops for research, data processing, content pipelines, whatever. Build the harness once, feed it specs, let it grind.\n\nYou combine these things with a really solid spec upfront and suddenly you can just... let it run. Go to bed, wake up, stuff is built. The whole game shifts from prompting in real-time to writing specs that are good enough to survive autonomous execution.\n\nHonestly my main takeaway from all this is we should probably just stick to what the top engineers at Anthropic are doing. There's a million different coding agents and tools and plugins and random github projects out there and it's easy to get lost chasing shiny things. But the people building Claude probably know best how to use Claude. Claude Code + their patterns + maybe the SDK if you need something custom. Keep it simple.\n\n**Sources:**\n\n* [https://github.com/anthropics/claude-code/tree/main/plugins/ralph-wiggum](https://github.com/anthropics/claude-code/tree/main/plugins/ralph-wiggum)\n* [https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents)\n* [https://www.youtube.com/watch?v=13HP\\_bSeNjU](https://www.youtube.com/watch?v=13HP_bSeNjU)\n* [https://www.youtube.com/watch?v=usQ2HBTTWxs](https://www.youtube.com/watch?v=usQ2HBTTWxs)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q25gca/will_2026_be_the_year_of_ralph_loops_and_personal/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxb7gck",
          "author": "LittleJuggernaut7365",
          "text": "Heres my plugins as well  \n[https://github.com/GantisStorm/essentials-claude-code](https://github.com/GantisStorm/essentials-claude-code)",
          "score": 1,
          "created_utc": "2026-01-02 19:59:06",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2v3ar",
      "title": "Langgraph interview prep guide",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2v3ar/langgraph_interview_prep_guide/",
      "author": "shreyshahh",
      "created_utc": "2026-01-03 13:50:25",
      "score": 4,
      "num_comments": 3,
      "upvote_ratio": 0.83,
      "text": "\nI put together a LangGraph study & interview prep guide for anyone making the leap. I've been working with langgraph for quite some time and wanted to help people break into it. I see a lot of confusion between langchain/ langgraph, I hope this helps at least one person. \n\nhttps://github.com/shahshrey/langgraph-interview-questions",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2v3ar/langgraph_interview_prep_guide/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxr3gwa",
          "author": "Whole-Assignment6240",
          "text": "Does it cover StateGraph vs MessageGraph tradeoffs?",
          "score": 1,
          "created_utc": "2026-01-05 03:18:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxrzycc",
              "author": "shreyshahh",
              "text": "Yes it does",
              "score": 1,
              "created_utc": "2026-01-05 06:54:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxusdor",
          "author": "SufficientAverage996",
          "text": "Thank you for the notes brother‚Ä¶really helpfulüôèüèª",
          "score": 1,
          "created_utc": "2026-01-05 17:54:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q50xgh",
      "title": "I built a desktop GUI to debug vector DBs and RAG retrieval",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q50xgh/i_built_a_desktop_gui_to_debug_vector_dbs_and_rag/",
      "author": "snirjka",
      "created_utc": "2026-01-05 22:53:02",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 0.84,
      "text": "üëã Hey everyone,\n\nI‚Äôve been building a lot of RAG pipelines lately and kept running into the same issue: once data is inside the vector DB, it‚Äôs hard to really inspect embeddings and understand why retrieval works or fails without writing scripts or notebooks.\n\nSo I built VectorDBZ, a desktop GUI for exploring and debugging vector databases and embeddings across different providers.\n\nWhat it supports:\n\n‚Ä¢ Qdrant, Weaviate, Milvus, Chroma, and pgvector\n‚Ä¢ Browsing collections, vectors, and metadata\n‚Ä¢ Similarity search with filters, score thresholds, and top-K\n‚Ä¢ Generating embeddings from text or files, supports local models (Ollama, etc) and hosted APIs\n‚Ä¢ Embedding visualization with PCA, t-SNE, and UMAP\n‚Ä¢ Basic analysis of distances, outliers, duplicates, and metadata separation\n\nThe goal is fast, interactive debugging of retrieval behavior when working on RAG systems, not replacing programmatic workflows.\n\nLinks:\n\nGitHub\nhttps://github.com/vectordbz/vectordbz\n\nDownloads\nhttps://github.com/vectordbz/vectordbz/releases\n\nWould really love feedback from people building RAG in practice:\n\n‚Ä¢ How do you debug retrieval quality today?\n‚Ä¢ What signals help you decide embeddings are good or bad?\n‚Ä¢ What analysis or views would actually help in production?\n‚Ä¢ Any vector DBs or embedding models you‚Äôd want to see next?\n\nIf you find this useful, a ‚≠ê on GitHub would mean a lot and helps keep me motivated to keep improving it.\n\nThanks!\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q50xgh/i_built_a_desktop_gui_to_debug_vector_dbs_and_rag/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny0ccss",
          "author": "Mikasa0xdev",
          "text": "Vector DB debugging is crucial; RAG pipelines need this visibility, nice job!",
          "score": 1,
          "created_utc": "2026-01-06 14:10:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pzwp5t",
      "title": "LLM says it did an action‚Ä¶ but never actually used the tool ü§¶‚Äç‚ôÇÔ∏è",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pzwp5t/llm_says_it_did_an_action_but_never_actually_used/",
      "author": "marcocello",
      "created_utc": "2025-12-30 23:07:19",
      "score": 3,
      "num_comments": 11,
      "upvote_ratio": 0.72,
      "text": "I‚Äôm building an LLM agent with access to a fixed set of tools that perform real actions (create/update records, etc.).\n\nProblem: The model sometimes claims it did something (‚ÄúDone, I've done what you asked‚Äù) without ever calling the tool that would actually do it.\n\nSo:\n\n* If it can‚Äôt do something, I want it to say so\n* If no tool exists, I want a refusal\n* If no tool was called, it shouldn‚Äôt claim success\n\nStronger prompts help a bit, but don‚Äôt fully solve it.\n\n\n\nHow do you enforce *‚Äúno tool call = no claim of success‚Äù* in agent systems?\n\nPrompting? Execution contracts? Validation layers? Planning + verification loops?\n\nCurious what actually works in practice",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pzwp5t/llm_says_it_did_an_action_but_never_actually_used/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwtivvr",
          "author": "dreamingwell",
          "text": "Your context probably grew to be too big. Or just use a higher quality model. \n\nDon‚Äôt allow it to not call a tool (respond no tools called)\n\nSecondary LLM for validation",
          "score": 3,
          "created_utc": "2025-12-30 23:18:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwxxxeq",
          "author": "biyopunk",
          "text": "You people are tilting at windmills.",
          "score": 2,
          "created_utc": "2025-12-31 17:08:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwy5zna",
              "author": "marcocello",
              "text": "yep, moving the windmill into the execution layer :)",
              "score": 1,
              "created_utc": "2025-12-31 17:48:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwtku40",
          "author": "xelnet",
          "text": "I can help out with this. CRUD is a specific animal. \n\nThe answer to your specific problem will depend on how your tools are designed and organized, as well as how the api‚Äôs are documented.\n\nDiagnostic will require detailed visibility into the logs.\n\nI‚Äôve spent the last year specializing in multiagent CRUD and built an observation tool for fine tuning to get to 100% tested crud environment",
          "score": 1,
          "created_utc": "2025-12-30 23:29:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu3ah1",
          "author": "robogame_dev",
          "text": "99% of the time this is because the tools weren't actually presented to the model - log your raw payload before it goes to the model provider and verify the tools are present, that the model supports native tool calling or whatever. Or if you're using a framework with too much abstraction for that, chat with the model - ask it for details of the tools that it could only answer correctly if it had the real tool, for example \"Quote the exact description for tool \"my\\_tool\".",
          "score": 1,
          "created_utc": "2025-12-31 01:11:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx03amj",
          "author": "redballooon",
          "text": "You can‚Äôt enforce this. But cases like this usually are caused by some inconsistency in the system message, or in the system message together with the message stack.\n\nOr in bad cases when the system message is somewhat in conflict with the models trained behavior.",
          "score": 1,
          "created_utc": "2026-01-01 00:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0d5jv",
          "author": "Comfortable-Sound944",
          "text": "Validation layer/step...\n\nYou can see it everywhere, you validate the output of LLM confirms to reality or ask it to try to fix it's issue a few times, it's very common for LLM not to be reliable in output format no matter how hard you try to steer it. Or just to claim things which aren't true",
          "score": 1,
          "created_utc": "2026-01-01 01:07:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx27i8m",
          "author": "AI_Data_Reporter",
          "text": "VeriGuard's Correct-by-Construction framework and ToolGuards runtime guarding are the current state-of-the-art for enforcing execution reliability. Benchmarks like Toolathlon show that shifting validation from the prompt to the execution layer (runtime state-tracking) increases reliability from 62.5% to 81.3%. Without a deterministic verification loop that cross-references tool output logs against the model's success claim, you're just hallucinating progress.",
          "score": 1,
          "created_utc": "2026-01-01 10:19:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxcnxp1",
          "author": "SnooDoughnuts7934",
          "text": "At work we use a state machine and we don't allow it to move forward if certain actions aren't complete.  We can't trust the LLM to be consistent so we have all sorts of guardrails to make it work.   They aren't magic like everyone wants to show In a demo.  They don't give consistent responses, they sometimes say something worked when they actually skipped it, you can \"respond with just YES or NO\" and it will sometimes still say something else.  It makes testing challenging to say the least.",
          "score": 1,
          "created_utc": "2026-01-03 00:28:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxswxa7",
          "author": "Unique-Big-5691",
          "text": "haha i know this one‚Äôs super annoying and way more common than it should be.\n\ni‚Äôve learned the hard way that you just can‚Äôt trust what the model says it did. cause it‚Äôll happily go ‚Äúall done üëç‚Äù because that sounds right, even if nothing actually happened.\n\nfor me, what‚Äôs worked better is flipping it around, because the model doesn‚Äôt get to declare success. but your system does. if no tool was called, then as far as the system is concerned, nothing happened, end of story.\n\nalso, that usually means checking after the response: was there an actual tool call? if not, either retry or return something like ‚Äúno action taken.‚Äù stronger prompts help a bit, but they‚Äôre never 100% reliable on their own tho.\n\nimo, having some structure around this helps a lot too. like, if a response claims success but there‚Äôs no tool call or execution result tied to it, just reject it. from my own experience, pydantic-style schemas make this way easier because you can fail fast instead of trying to reason about intent.\n\ntldr: don‚Äôt argue with the model, just enforce reality in code. no tool call = no success, no matter how confident it sounds üòÖ",
          "score": 1,
          "created_utc": "2026-01-05 11:51:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxtszrx",
          "author": "Unique-Big-5691",
          "text": "yeah, this is one of those ‚Äúoh‚Ä¶ so that‚Äôs a thing‚Äù moments üòÖ\n\ni ran into the same issue and honestly just stopped trusting what the model says. it‚Äôll confidently go ‚Äúdone!‚Äù because that sounds right, even if it didn‚Äôt actually do anything.\n\nwhat helped me was flipping the logic: the model doesn‚Äôt get to declare success, but my code does. if no tool was actually called, then as far as the system‚Äôs concerned, nothing happened tho.\n\nso after every response, i just check did it run or not? if not, i either retry or tell the user no action was taken. prompts help a bit, but they‚Äôre never bulletproof lol.\n\ni think having some structure around responses makes this way easier too. like, if it claims success but there‚Äôs no tool execution info attached, i just reject it. also, pydantic-style validation is nice here because it lets you be strict without a bunch of messy if-statements imo.\n\nbasically: don‚Äôt argue with the model, just enforce reality in code. no tool call = no success ü§∑‚Äç‚ôÇÔ∏è",
          "score": 1,
          "created_utc": "2026-01-05 15:08:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2r1f2",
      "title": "ai-rulez: universal agent context manager",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2r1f2/airulez_universal_agent_context_manager/",
      "author": "Goldziher",
      "created_utc": "2026-01-03 10:07:46",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "I'd like to share [ai-rulez](https://github.com/Goldziher/ai-rulez). It's a tool for managing and generating rules, skills, subagents, context and similar constructs for AI agents. It supports basically any agent out there because it allows users to control the generated outputs, and it has out-of-the-box presets for all the popular tools (Claude, Codex, Gemini, Cursor, Windsurf, Opencode and several others).\n\n## Why?\n\nThis is a valid question. As someone wrote to me on a previous post -- \"this is such a temporary problem\". Well, that's true, I don't expect this problem to last for very long. Heck, I don't even expect such hugely successful tools as Claude Code itself to last very long - technology is moving so fast, this will probably become redundant in a year, or two - or three. Who knows. Still, it's a real problem now - and one I am facing myself. So what's the problem?\n\nYou can create your own .cursor, .claude or .gemini folder, and some of these tools - primarily Claude - even have support for sharing (Claude plugins and marketplaces for example) and composition. The problem really is vendor lock-in. Unlike MCP - which was offered as a standard - AI rules, and now skills, hooks, context management etc. are ad hoc additions by the various manufacturers (yes there is the AGENTS.md initiative but it's far from sufficient), and there isn't any real attempt to make this a standard.\n\nFurthermore, there are actual moves by Anthropic to vendor lock-in. What do I mean? One of my clients is an enterprise. And to work with Claude Code across dozens of teams and domains, they had to create a massive internal infra built around Claude marketplaces. This works -- okish. But it absolutely adds vendor lock-in at present.\n\nI also work with smaller startups, I even lead one myself, where devs use their own preferable tools. I use IntelliJ, Claude Code, Codex and Gemini CLI, others use VSCode, Anti-gravity, Cursor, Windsurf clients. On top of that, I manage a polyrepo setup with many nested repositories. Without a centralized solution, keeping AI configurations synchronized was a nightmare - copy-pasting rules across repos, things drifting out of sync, no single source of truth. I therefore need a single tool that can serve as a source of truth and then .gitignore the artifacts for all the different tools.\n\n## How AI-Rulez works\n\nThe basic flow is: you run `ai-rulez init` to create the folder structure with a `config.yaml` and directories for rules, context, skills, and agents. Then you add your content as markdown files - rules are prescriptive guidelines your AI must follow, context is background information about your project (architecture, stack, conventions), and skills define specialized agent personas for specific tasks (code reviewer, documentation writer, etc.). In `config.yaml` you specify which presets you want - claude, cursor, gemini, copilot, windsurf, codex, etc. - and when you run `ai-rulez generate`, it outputs native config files for each tool.\n\nA few features that make this practical for real teams:\n\nYou can compose configurations from multiple sources via includes - pull in shared rules from a Git repo, a local path, or combine several sources. This is how you share standards across an organization or polyrepo setup without copy-pasting.\n\nFor larger codebases with multiple teams, you can organize rules by domain (backend, frontend, qa) and create profiles that bundle specific domains together. Backend team generates with `--profile backend`, frontend with `--profile frontend`.\n\nThere's a priority system where you can mark rules as critical, high, medium, or low to control ordering and emphasis in the generated output.\n\nThe tool can also run as a server (supports the Model Context Protocol), so you can manage your configuration directly from within Claude or other MCP-aware tools.\n\nIt's written in Go but you can use it via npx, uvx, go run, or brew - installation is straightforward regardless of your stack. It also comes with an MCP server, so agents can interact with it (add, update rules, skill etc.) using MCP. \n\n## Examples\n\nWe use [ai-rulez](https://github.com/Goldziher/ai-rulez) in the [Kreuzberg.dev Github Organization](https://github.com/kreuzberg-dev) and the open source repositories underneath it - [Kreuzberg](https://github.com/kreuzberg-dev/kreuzberg) and [html-to-markdown](https://github.com/kreuzberg-dev/html-to-markdown) - both of which are polyglot libraries with a lot of moving parts. The rules are shared via git, for example you can see the [config.yaml](https://github.com/kreuzberg-dev/html-to-markdown/blob/main/.ai-rulez/config.yaml) file in the html-to-markdown .ai-rulez folder, showing how the rules module is read from GitHub. The `includes` key is an array, you can install from git and local sources, and multiple of them - it scales well, and it supports SSH and bearer tokens as well.\n\nAt any rate, this is the [shared rules](https://github.com/kreuzberg-dev/ai-rulez) repository itself - you can see how the [data is organized under a .ai-rulez folder](https://github.com/kreuzberg-dev/ai-rulez/tree/main/.ai-rulez), and you can see how some of the data is split among [domains](https://github.com/kreuzberg-dev/ai-rulez/tree/main/.ai-rulez/domains).\n\nWhat do the generated files look like? Well, they're native config files for each tool - CLAUDE.md for Claude, .cursorrules for Cursor, .continuerules for Continue, etc. Each preset generates exactly what that tool expects, with all your rules, context, and skills properly formatted.\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2r1f2/airulez_universal_agent_context_manager/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxg8tlr",
          "author": "True_Ear_2982",
          "text": "Wasn't agents md recently donated to Agentic AI Foundation (under linux foundation) - do you see this becoming a proper standard?",
          "score": 1,
          "created_utc": "2026-01-03 15:23:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxgmp6b",
              "author": "Goldziher",
              "text": "not really, a single file simply isnt enough",
              "score": 1,
              "created_utc": "2026-01-03 16:30:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q06grj",
      "title": "I built a tool for myself to loop through a dataset and enrich it using LLM",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q06grj/i_built_a_tool_for_myself_to_loop_through_a/",
      "author": "Massive_Movie_6573",
      "created_utc": "2025-12-31 06:51:07",
      "score": 3,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I have been working with LLM API models since the early days (GPT3) before ChatGPT became a thing. And, I was fascinated by the \"magic\" it can create. As the models got better, I have used it extensively in the last year for doing data enrichment by writing Python scripts that loop through a dataset ... and basically reproduce the same effect of prompting one-off on ChatGPT.\n\nI was surpirsed no one built a good tool to scale a prompt on every record of a dataset. Google Sheets tried but wasn't the best implementation. So, all these months, I have been saving Python scripts in notebooks and copying one notebook to another whenever I have a new data enrichment exercise.\n\nLLMs are so good for structuring unstructured data. So, I saw this as an opportunity to make my life better. And, taking inspiration from the heydays of [CodePen](https://codepen.io/trending) and [JSFiddle](https://jsfiddle.net/), I figured I will create my own tool: [LLM Fiddle](https://llmfiddle.io/).\n\nIf this resonates, please give it a try and let me know what you think. Open for ideas & feedback.\n\nhttps://preview.redd.it/edq6qf7lmlag1.png?width=2734&format=png&auto=webp&s=fdbcf66898cc9d00ed4518ef3c93963a0f2ecf34\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q06grj/i_built_a_tool_for_myself_to_loop_through_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwwzi0f",
          "author": "PM_ME_BOOB_PICTURES_",
          "text": "Love this, well done, it seems to work great, judging from the sample fiddle!\n\nPS: Make sure you have all the relevant limitations and securities implemented so you can avoid people:\n\n1. trying to gain unwanted access to certain stuff (for example, sanitizing inputs is important to avoid people running code in random input fields like the login screen, or SQL injection for example, which is the one big thing that pretty much every slightly tech-savvy person knows how to do at a basic level).  \nNot that I noticed that you had any of these issues, but just saying just in case\n\n2. Causing LLMs to output insane amounts of data, effectively destroying whatever token limit you may have been granted by these companies\n\nAnd also, your settings page isn't working, it just 404's, and you're legally required to give users the option to disable and/or delete their accounts, change login details etc.\n\nAlso, to serve the website to EU (and others I'd assume, but EU is the one I know for certain about), you have to give them a way/instructions to access the data your website and/or company has stored from them.\n\nWhen the site is relatively unknown, these things aren't that big of a deal, but you never know, it could suddenly blow up at some point, and in that case, you want to be prepared.\n\nGreat stuff so far, keep it up, I haven't seen a tool like this online before!",
          "score": 2,
          "created_utc": "2025-12-31 14:09:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwym1da",
              "author": "Massive_Movie_6573",
              "text": "Thanks so much for trying it and reviewing it. I agree with all your observations. Data apps are tricky because of all the extra considerations that a builder needs to have. But also these are helpful so someone has to build it haha. \n\nThanks for pointing out the Settings tab being broken. I have fixed it now. If you have other ideas, please let me know.",
              "score": 1,
              "created_utc": "2025-12-31 19:08:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx03s6g",
          "author": "xaustin",
          "text": "Man the site design is beautiful and very smooth. I see this idea going really far, good stuff.",
          "score": 2,
          "created_utc": "2026-01-01 00:09:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx060d3",
              "author": "Massive_Movie_6573",
              "text": "Thank you, buddy! I appreciate it. I just need to find the right target audience to get to try it.",
              "score": 1,
              "created_utc": "2026-01-01 00:23:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pz2h8x",
      "title": "Evaluation Framework for LLM applications in Java",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pz2h8x/evaluation_framework_for_llm_applications_in_java/",
      "author": "Ok-Engineer9508",
      "created_utc": "2025-12-29 23:59:35",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "I'm building Dokimos - a completely free and open-source LLM evaluation framework for Java that helps you validate LLM outputs of AI assistants and agents with structured assertions in a test-driven way.\n\nHow it works:  \n\\- Write assertions for LLM outputs with built-in or custom evaluators  \n\\- Run tests against any LLM implementation or provider  \n\\- View results in a web UI  \n\\- Tests are reusable\n\nMy Open-Source implementation:  \n\\- Multi-framework support / Framework-agnostic: JUnit 5, LangChain4j, Spring AI  \n\\-  Built-in evaluators or custom-evaluators   \n\\- Web UI for experiment results and history  \n\\- Works with local LLMs and proprietary models  \n\\- Docker deployment of server implementation  \n  \nGet started:  \n\\- GitHub:  [https://github.com/dokimos-dev/dokimos](https://github.com/dokimos-dev/dokimos)  \n\\- Documentation: [https://dokimos.dev/overview](https://dokimos.dev/overview)\n\nThe project is still new, and I'm actively working on it and improving it based on feedback. Star [the repo](https://github.com/dokimos-dev/dokimos) to stay updated! ‚≠êÔ∏è",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pz2h8x/evaluation_framework_for_llm_applications_in_java/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1pyesj4",
      "title": "Why does LLama 3.1 give long textbook style answer for simple definition questions?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pyesj4/why_does_llama_31_give_long_textbook_style_answer/",
      "author": "Dizzy-Watercress-744",
      "created_utc": "2025-12-29 06:21:48",
      "score": 3,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I am using Llama3.1-8b-Instruct inferenced via vllm for my course assistant.  \nWhen I ask a question in simple language, for instance\n\n>what is sunrise and sunset?\n\nI get correct answer\n\nBut if I ask the same question in different format\n\n>what is sunrise, sunset?\n\nI get a huge para that has little relevance to the query.\n\nWhat can I do to rectify this",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pyesj4/why_does_llama_31_give_long_textbook_style_answer/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwq8cb9",
          "author": "justkickinit10210",
          "text": "What are you running it on? Llama.cpp you can cap the output with predict settings. Not sure about studio.\n\nOr train it giving shorter answers. Accidentally did this in a qwen3, but worked great.",
          "score": 1,
          "created_utc": "2025-12-30 13:39:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx1w1dy",
              "author": "Dizzy-Watercress-744",
              "text": "Yeah chose qwen 3 and amazing results, qwen ftw",
              "score": 2,
              "created_utc": "2026-01-01 08:16:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx1eh0p",
          "author": "AI-Agent-geek",
          "text": "I‚Äôve had llama3.1 max out the output tokens in response to ‚Äúknock knock‚Äù so..",
          "score": 1,
          "created_utc": "2026-01-01 05:29:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2izg5",
      "title": "Run Claude Code with ollama, llamacpp without losing any single feature offered by Anthropic backend",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2izg5/run_claude_code_with_ollama_llamacpp_without/",
      "author": "Dangerous-Dingo-5169",
      "created_utc": "2026-01-03 02:55:38",
      "score": 3,
      "num_comments": 7,
      "upvote_ratio": 0.67,
      "text": "Hey folks! Sharing an open-source project that might be useful:\n\nLynkr connects AI coding tools (like Claude Code) to multiple LLM providers with intelligent routing.\n\n\n\nKey features:\n\n\\- Route between multiple providers: Databricks, Azure Ai Foundry, OpenRouter, Ollama,llama.cpp, OpenAi\n\n\\- Cost optimization through hierarchical routing, heavy prompt caching\n\n\\- Production-ready: circuit breakers, load shedding, monitoring\n\n\\- It supports all the features offered by claude code like sub agents, skills , mcp , plugins etc unlike other proxies which only supports basic tool callings and chat completions.\n\nGreat for:\n\n\\- Reducing API costs as it supports hierarchical routing where you can route requstes to smaller local models and later switch to cloud LLMs automatically.\n\n\\- Using enterprise infrastructure (Azure)\n\n\\-¬† Local LLM experimentation\n\n\\`\\`\\`bash\n\nnpm install -g lynkr\n\n\\`\\`\\`\n\nGitHub: [https://github.com/Fast-Editor/Lynkr](https://github.com/Fast-Editor/Lynkr) (Apache 2.0)\n\nWould love to get your feedback on this one. Please drop a star on the repo if you found it helpful",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2izg5/run_claude_code_with_ollama_llamacpp_without/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxogynw",
          "author": "fourthwaiv",
          "text": "Take a look at this and see if this helps you out any \n\nhttps://github.com/astoreyai/ccflow\n\nProduction middleware bridging Claude Code CLI with SDK-like Python interfaces.\n\nccflow enables subscription-based usage (Pro/Max) instead of API token billing, with integrated TOON serialization for 30-60% token reduction on structured data.\n\nv0.2.0: Now with Agent System, Hooks, Skills, Subagent Coordination, and CLI Commands - full SDK parity!\n\nHope everyone enjoys- if there are any issues with it- let me know.",
          "score": 1,
          "created_utc": "2026-01-04 19:32:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxoia75",
              "author": "Dangerous-Dingo-5169",
              "text": "Sure thanks buddy \nWill check it out today",
              "score": 2,
              "created_utc": "2026-01-04 19:38:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxoj89k",
                  "author": "fourthwaiv",
                  "text": "Let me know if you want to collaborate - my next OSS release is a memory system.",
                  "score": 1,
                  "created_utc": "2026-01-04 19:42:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxzje3s",
          "author": "Glittering-Call8746",
          "text": "What's TOON",
          "score": 1,
          "created_utc": "2026-01-06 10:53:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny26o4p",
              "author": "Dangerous-Dingo-5169",
              "text": "Its a format for sending tokens to an llm similar to json \nIt saves up a lot of tokens which is something we would be exploring a later point in this project",
              "score": 1,
              "created_utc": "2026-01-06 19:19:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pzwt5k",
      "title": "Is it worth making side projects to earn money as an LLM engineer instead of studying?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pzwt5k/is_it_worth_making_side_projects_to_earn_money_as/",
      "author": "Waste_Necessary654",
      "created_utc": "2025-12-30 23:11:50",
      "score": 2,
      "num_comments": 11,
      "upvote_ratio": 0.63,
      "text": "Hi, I am an LLM/ML engineer. I was recently wondering if using my time to work on side projects would be worthwhile. I live in Brazil and don't earn as much as those in US jobs.\n\nSo, I was considering two possibilities:\n\n1.  **Try side projects:** Create SaaS, freelance, etc., to make money.\n2.  **Instead, use my time to study and learn new things to get a better job.**\n\nWhat do you think?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pzwt5k/is_it_worth_making_side_projects_to_earn_money_as/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwtj5r6",
          "author": "SamWest98",
          "text": "saas market is extraordinarily noisy right now. I don't think many people are making money off vibe coded apps",
          "score": 3,
          "created_utc": "2025-12-30 23:20:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtkhj7",
              "author": "Waste_Necessary654",
              "text": "I feel this also. I posted here because I wanted someone who had tried SaaS.",
              "score": 2,
              "created_utc": "2025-12-30 23:27:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwtlcm6",
                  "author": "SamWest98",
                  "text": "I mean it doesn't hurt to try if you have time :)",
                  "score": 2,
                  "created_utc": "2025-12-30 23:32:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwtmsv5",
          "author": "SirArtWizard",
          "text": " I would just build side projects in general. You'll learn a lot by just doing things that don't amount to anything. But surprisingly will elevate future projects from the skills you learned.",
          "score": 3,
          "created_utc": "2025-12-30 23:40:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwtnphz",
              "author": "Waste_Necessary654",
              "text": "I did some but just for learning. But I never tried to create a project to earn money.",
              "score": 1,
              "created_utc": "2025-12-30 23:45:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwuthcc",
          "author": "staccodaterra101",
          "text": "Why not both? Sure, its not for everyone, but It worked very well for me. Its tricky to find the right balance but then one help the other. I basically studied data engineering as side project while building my network of clients and working as freelancer. Took me almost double the time to complete the education ( tbh only a small part its relevant ) but this allowed me to buld trust and start a solid startup. You a solid network to retrieve the pain point of the society you lives in. And you need education to get the knowledge for building a valid solution.\n\nSo, you you want a more canonical answer: study first, or you wont be able to build something worth to be used by your non existent clients. Then once youll be able, lose years in failing project because no one knows you and you solutions",
          "score": 1,
          "created_utc": "2025-12-31 03:46:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwuupn0",
          "author": "Hefty_Astronaut3947",
          "text": "I would highly recommend doing side projects, but make sure your side projects get some users. If your side project provide value to users that are making money, they will share some money with you (i.e. pay for your side project). You never know when a side project will start making enough money that you never have to enter a job. Talk to anyone doing a job, they will tell you that they want to get out of the job, and would be willing to do so even if their side project makes 50% of what they are making in the job. As you are studying right now, it's the best time to keep trying things. Later on in life, you will have more and more things to manage, not less and less. Plan your side projects well. Watch all the videos (not really all) of this youtube channel: [https://www.youtube.com/@starterstory](https://www.youtube.com/@starterstory) to understand how to make side projects that will help you earn, and not just learn. Learn how to make profitable side projects (this is what I have realized is very important in last 10 years of having an ambitious entrepreneurial mindset and doing a job on and off all this time). Hope this helps.",
          "score": 1,
          "created_utc": "2025-12-31 03:53:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwux89q",
          "author": "cmndr_spanky",
          "text": "You don‚Äôt have to make a commitment to one or the other do you? Try to find freelance gigs on the side and not take on too much at once while you also split out time to keep learning.\n\nIn fact, I‚Äôd argue anyone who isn‚Äôt continuing to learn in their career is going to dead end their career pretty quickly. \n\nBut I would definitely find gigs to make apps rather than just make random ones hoping users come.. the odds of that making revenue are very low. And a lot of YouTubers who claim it‚Äôs a way to get rich quick are lying.",
          "score": 1,
          "created_utc": "2025-12-31 04:10:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwv2frw",
          "author": "Adept_Carpet",
          "text": "It would be very educational to get hired by a at least a few businesses in the SaaS space.¬†\n\n\nI see a lot of students where they are working on a side project business where the core idea is incredible, the key feature works, they have a sense of sales and marketing even but they are completely unaware of the long tail of tasks that exist between \"cool app idea\" and \"actual product\" and the even longer path to \"functioning business.\"\n\n\nSo the first month their mother and best friend signs up. The second month a few social media followers and people they pitched at parties sign up, but eventually the progress stalls.",
          "score": 1,
          "created_utc": "2025-12-31 04:44:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwtoc6h",
          "author": "SatanicSurfer",
          "text": "First of all, learn how to speak english fluently. Then study and start applying to remote US or EU jobs. You should do side projects, but as a way of gaining experience and marketability for the US jobs. This advice is considering that money is your main focus.\n\nUS jobs pay so much more than BR jobs that you should 100% focus on them if your main goal is to make money. Just a warning, the work life balance is shit. They will work you to the bone.",
          "score": 0,
          "created_utc": "2025-12-30 23:49:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyme9l",
      "title": "Building 1 AI agent per day for the next 30 days - what should I build?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pyme9l/building_1_ai_agent_per_day_for_the_next_30_days/",
      "author": "anitakirkovska",
      "created_utc": "2025-12-29 13:33:21",
      "score": 2,
      "num_comments": 10,
      "upvote_ratio": 0.63,
      "text": "Hey everyone,\n\nI am starting a 30 day challenge to build 1 AI agent per day. So far I've built 3 agents, and need ideas for the next ones. I'm publishing all of my learnings and free access to all of them on agent yard (.) co \n\nWhat are some agents that you'd want to use? Please let me know in the comments and I'll try to build them ",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pyme9l/building_1_ai_agent_per_day_for_the_next_30_days/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwjkj3b",
          "author": "Hot_Substance_9432",
          "text": "Like this? [https://github.com/akshsgaur/30DaysofAIAgents](https://github.com/akshsgaur/30DaysofAIAgents)",
          "score": 2,
          "created_utc": "2025-12-29 13:43:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjn0v9",
              "author": "anitakirkovska",
              "text": "yes exactly, but I'm using vibe-coding tools. Should I also open a github page?",
              "score": 1,
              "created_utc": "2025-12-29 13:57:45",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwjn6zk",
                  "author": "Hot_Substance_9432",
                  "text": "Yes for sure it will give you visibility for  new jobs in future:)",
                  "score": 2,
                  "created_utc": "2025-12-29 13:58:46",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nwjp2ii",
                  "author": "Hot_Substance_9432",
                  "text": "I apologize :) you are a big shot at vellum and do not need a  new job:)",
                  "score": 1,
                  "created_utc": "2025-12-29 14:09:43",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwjpxr8",
          "author": "Hot_Substance_9432",
          "text": "What do you think of this [https://www.linkedin.com/posts/ashishpatel2604\\_35-agentic-ai-projects-hands-on-guide-for-activity-7389177729620979712-9tvr/](https://www.linkedin.com/posts/ashishpatel2604_35-agentic-ai-projects-hands-on-guide-for-activity-7389177729620979712-9tvr/)",
          "score": 2,
          "created_utc": "2025-12-29 14:14:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjxeok",
              "author": "anitakirkovska",
              "text": "helpful thank you!",
              "score": 1,
              "created_utc": "2025-12-29 14:56:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwnnvi8",
                  "author": "Hot_Substance_9432",
                  "text": "Even this [https://medium.com/@nocobase/top-18-open-source-ai-agent-projects-with-the-most-github-stars-f58c11c2bf6c](https://medium.com/@nocobase/top-18-open-source-ai-agent-projects-with-the-most-github-stars-f58c11c2bf6c)",
                  "score": 1,
                  "created_utc": "2025-12-30 02:08:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwnb57p",
          "author": "baulperry",
          "text": "an ai agent that tells you what to build",
          "score": 2,
          "created_utc": "2025-12-30 00:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwp8sgu",
          "author": "necati-ozmen",
          "text": "Here we‚Äôre collecting AI agent examples built with the VoltAgent AI agent framework.\n\nFull source code is included, so you can explore them and use them as inspiration.  \n[https://voltagent.dev/recipes-and-guides/](https://voltagent.dev/recipes-and-guides/)",
          "score": 2,
          "created_utc": "2025-12-30 08:50:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q3urrk",
      "title": "AI Use, Authorship, and Prejudice",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q3urrk/ai_use_authorship_and_prejudice/",
      "author": "NovatarTheViolator",
      "created_utc": "2026-01-04 16:49:13",
      "score": 1,
      "num_comments": 3,
      "upvote_ratio": 0.56,
      "text": "Hello,\n\nI use AI heavily.  Aside from automation, tooling, agentic workflows, and ComfyUI, I also spend a lot of time talking with the LLMs.  Mostly about technical stuff.  So, when I have an idea that I want to share and write a post to a forum or whatnot, I find that, for example, ChatGPT, is superior to spell/grammar check in every way.  Not only can it check spelling and grammar, but it can also refactor phrases that were originally worded in a less-than-optimal manner.  It's also great for automatically adding formatting to plaintext, making it easier to read and gives it a more organized look. It's also great at finding the words to explain technical things, and posts made with its help look much better.\n\nHowever, whenever I try to post such content, I often get flamed and accused of using AI to create the entirety of the content, despite the fact that the content itself contains ideas that AI couldn't come up with on its own (and to make sure of that, I tried.  Hard). And such cases are kinda obvious too.  It doesn't take much to discern between 'AI creativity' and prompt-managed writing whose ideas come from the human operator.  Hell, sometimes I even get accused of using AI when I haven't at all, and have manually typed up the entire thing (such as this post).  So what's the deal with this?\n\nAI is a tool, and a powerful one at that, and like any tool, it can be used properly or abused.  However, it seems that if there's even a hint of AI-generated content in a post, many people seem to assume that AI was misused - that the entire thing was lazily created with a single prompt, or something like that.  Now, I AM aware that a lot of people do use AI lazily and inappropriately when it comes to writing.  But why is that a reason for people to assume that EVERYONE does it this way?\n\nEven when I have AI write for me, the writing is typically the result of dozens of prompts and hours of work, in which I go over every section and every detail of what's being written.  In such cases, it's more of a 'write director' than 'typist' or 'just have AI do it all for me'.  I asked AI what this type of writing is called, and it gave me identifiers such as \"AI-assisted writing\", \"iterative prompt steering\", \"augmented authorship\", \"editorial control\", and \"human-in-the-loop authorship\".\n\nDespite the fact that there are appropriate uses for AI in writing, it seems that people assume the opposite. Is the use of AI in writing universally considered unacceptable?  It's kinda sad and simultaneously infuriating that the majority of people hate on AI without understanding what it is or how it works, and the people that DO know how to use it appropriately and effectively get called out as if they're part of the problem.  What gives?  Is this going to be the fact of reality for a long time?  Does anyone else here encounter this situation?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q3urrk/ai_use_authorship_and_prejudice/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxnz009",
          "author": "latkde",
          "text": "Sure, let's delve into that.\n\n**People crave authenticity.** We're here to talk with each other‚Äînot with a robot. The internet is full of slop. Given something that *looks* like AI, people will assume that it *is* AI. The result: silence, downvotes and flaming.\n\nYou say that it's easy to distinguish. In my experience, that's not the case. It can be difficult to detect whether something was written with AI. And when something was written with AI, whether it contains original thoughts. That ‚Äúshoot the messenger‚Äù attitude might have a few false positives, but it works more often than it fails. Heuristics like this are necessary to navigate today's social media landscape with all its sensory overload. Unless your readers already know you, you will not be given the benefit of a doubt.\n\nHere's what you can do about that:\n\n* **Use your own authentic voice.** Stop worrying about perfect phrases, perfect spelling, and perfect formatting‚Äîusing your own voice shows that you care.\n* **Learn simple writing strategies.** You're spending hours crafting prompts. You could spend that time editing your writing directly. Perhaps all that's missing is the *confidence* to do it yourself.\n* **Go deep.** A lot of LLM outputs are generic and superficial. Be an expert. Talk from your personal experience. Provide sources.\n\n---\n\nThis post is a parody of LLM style. I don't use GenAI for writing, but my natural online writing style is sometimes considered LLM-ish ‚Äì even though I've been writing that way online for a decade longer than ChatGPT exists.",
          "score": 4,
          "created_utc": "2026-01-04 18:14:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxodkvk",
          "author": "robogame_dev",
          "text": "‚ÄúOnly 90% of AI writing style posts are meaningless garbage, why are people seeing my AI writing style posts and assuming it‚Äôs garbage? \n\nWhy aren‚Äôt they reading all the garbage posts so they can pick out the occasional authentic and meaningful post - like mine?‚Äù\n\nIdk, there‚Äôs good stuff in the trash sometimes - but how often do you personally go through people‚Äôs trash to look for it?\n\nI‚Äôd also add that I think it makes me dumber, reading some of these AI posts - as in I think it actually introduces clouding and confusion in my brain that slowly reduces the clarity of my thought. We think in language, loading in a ton of language simulacrum - of meaningless (at best) patter, cannot be good for us. It‚Äôs the equivalent of LLM training data, for the human - you don‚Äôt want your training data (everything you perceive) to get too low of a quality or else GIGO will apply to your own brain‚Ä¶\n\nSo as long as there‚Äôs plenty of posts that sound authentic from the outset, I see no need to wade into the ones that sound inauthentic from the outset. If you want more readership, maybe you should focus on making your posts more appealing from the outset. If people are critiquing your posts for AI writing style, maybe‚Ä¶ if those people are your audience‚Ä¶. listen to them?\n\nOr don‚Äôt, it doesn‚Äôt matter, this is Reddit, nobody‚Äôs entitled to readership - it‚Äôs all a zero sum competition for attention out here.",
          "score": 3,
          "created_utc": "2026-01-04 19:17:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxq2bd0",
          "author": "0LoveAnonymous0",
          "text": "People hate AI writing because most of what they see is lazy spam, so even good use gets lumped in.",
          "score": 2,
          "created_utc": "2026-01-05 00:03:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}