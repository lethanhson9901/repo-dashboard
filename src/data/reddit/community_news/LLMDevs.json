{
  "metadata": {
    "last_updated": "2026-01-24 16:49:57",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 82,
    "file_size_bytes": 109081
  },
  "items": [
    {
      "id": "1qg7vsl",
      "title": "[Project Update] MemOS: How we handled mutable state for long-running agents (open source, MIT)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/o4stlumwu3eg1.jpeg",
      "author": "Trick-Pair-2894",
      "created_utc": "2026-01-18 12:55:38",
      "score": 102,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qg7vsl/project_update_memos_how_we_handled_mutable_state/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0a8hmg",
          "author": "Content-Shallot5133",
          "text": "We tried a time-weighted decay (exponential drop-off based on last\\_accessed), but it backfired. Users would mention their dog's name once, never mention it for 6 months, and then get mad when the bot forgot it.\n\nWe switched to a 'significance score' calculated at ingestion. High-significance facts (names, medical info, hard preferences) basically have a decay rate of zero. Low-significance facts (what they ate for lunch) decay in 48 hours.",
          "score": 10,
          "created_utc": "2026-01-18 13:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ft0tz",
              "author": "Trick-Pair-2894",
              "text": "That 'significance score' is exactly what we're trying to tune right now. We're experimenting with an LLM-based 'importance verdict' during the extraction phase. Did you find a specific prompt worked best for grading significance?",
              "score": 1,
              "created_utc": "2026-01-19 07:19:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ab2xs",
          "author": "missprolqui",
          "text": ">We currently support self-hosting for privacy\n\ntbh, thats awesome!!!",
          "score": 8,
          "created_utc": "2026-01-18 13:20:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ahgkp",
          "author": "chaipglu28",
          "text": "Is the core written in Python or Rust? If you're doing heavy graph operations and vector math, Python might choke at scale (GIL issues).",
          "score": 2,
          "created_utc": "2026-01-18 14:00:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ahy5g",
          "author": "Apprehensive-Count19",
          "text": "Does this play nice with LangGraph? I'm currently using Zep for memory but looking for something more open. Would love to just drop this in as a graph node.",
          "score": 2,
          "created_utc": "2026-01-18 14:02:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fcq1m",
          "author": "fxstopo",
          "text": "Same here but with a little twist. I run n8n instances on multiple VPS + Runpod\n\nThe n8n is basically free, costed my $0.5 in a month, hosted on Lightnode's n8n virutal application: https://go.lightnode.com/n8n-application\n\nFor LLM I use Runpod's serverless, text-to-image, 500-1000 images a month, total around $3-5/month\n\nThat's a decoupled, powerful, AI stack a price cheaper than ChatGPT Plus.",
          "score": 2,
          "created_utc": "2026-01-19 05:09:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b7a8l",
          "author": "hugganao",
          "text": ">Tracing Why Agents 'Remember' Things: One thing we didn't expect to matter (but absolutely did): figuring out exactly why our agent \"believed\" something. Vector search couldn't explain itself. Now every memory update is versioned, making it easy to trace back and debug weird behaviors.\n\nis this basically just rag + context explanation of said data retrieved by matching indexed filters in traditional data stores (rdb/nosql) or searching through with KG?",
          "score": 1,
          "created_utc": "2026-01-18 16:13:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi3jw4",
      "title": "I Built an AI Scientist.",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/ns3g497fqieg1",
      "author": "SheepherderOwn2712",
      "created_utc": "2026-01-20 15:08:39",
      "score": 52,
      "num_comments": 36,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qi3jw4/i_built_an_ai_scientist/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0om5fu",
          "author": "kunkkatechies",
          "text": "Hello, great initiative !   \nI have a couple of questions:  \nWhat was your evaluation approach ?  \nHave you computed the recall ?  \nWhat's the size of your evaluation dataset ? (in terms of question/answer pairs) \n\nI also think having a high precision is important to not mislead the AI that will generate the final answer.\n\nGood luck anyway ! :)",
          "score": 6,
          "created_utc": "2026-01-20 15:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pl82u",
          "author": "AbelMate",
          "text": "Seems pretty similar to https://consensus.app",
          "score": 3,
          "created_utc": "2026-01-20 18:26:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rnt2n",
              "author": "TomLucidor",
              "text": "It's FOSS so they are somewhat ahead.",
              "score": 2,
              "created_utc": "2026-01-21 00:27:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tq60s",
                  "author": "SheepherderOwn2712",
                  "text": "\\^ yeah- and this has more data sources! consensus is cool though",
                  "score": 1,
                  "created_utc": "2026-01-21 09:05:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oepd4",
          "author": "SheepherderOwn2712",
          "text": "Here is the [Github repo](https://github.com/yorkeccak/bio)",
          "score": 5,
          "created_utc": "2026-01-20 15:09:25",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0ozlyp",
              "author": "mokumkiwi",
              "text": "Thanks!",
              "score": 2,
              "created_utc": "2026-01-20 16:47:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uglno",
          "author": "tashibum",
          "text": "Awesome! I often think about how silo'd science is and LLMs like this are going to be the solution!",
          "score": 2,
          "created_utc": "2026-01-21 12:46:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ujz50",
              "author": "SheepherderOwn2712",
              "text": "thanks for the kind words!",
              "score": 1,
              "created_utc": "2026-01-21 13:07:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o15kc5b",
                  "author": "bear-polar-max",
                  "text": "you are awesome!",
                  "score": 1,
                  "created_utc": "2026-01-23 01:05:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0v7irk",
          "author": "hiepxanh",
          "text": "Wow, how long did you do this? This is really heavy job",
          "score": 2,
          "created_utc": "2026-01-21 15:12:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w2y8e",
              "author": "SheepherderOwn2712",
              "text": "few hours",
              "score": 2,
              "created_utc": "2026-01-21 17:34:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ofgtu",
          "author": "Far_Marionberry1717",
          "text": "So, what experiments did your AI scientist conduct?\n\nOh right, none. You don't even know what scientists do.",
          "score": 4,
          "created_utc": "2026-01-20 15:13:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ofx62",
              "author": "Feeling-Machine-4804",
              "text": "think you are missing the point of OPs post",
              "score": 10,
              "created_utc": "2026-01-20 15:15:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0og3tu",
                  "author": "Far_Marionberry1717",
                  "text": "No I get what it does, I just wouldn't call it an \"AI scientist\".\n\nI actually think the project is pretty neat.",
                  "score": 9,
                  "created_utc": "2026-01-20 15:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sedft",
              "author": "TheWiseAlaundo",
              "text": "I mean, I'm a scientist (research professor) and physically running experiments is maybe 5% of my job at most. The vast majority is performing analysis, reading and writing articles, and writing grants for more funding.",
              "score": 2,
              "created_utc": "2026-01-21 02:58:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tqcpa",
                  "author": "SheepherderOwn2712",
                  "text": "This is whole I built it for! (would love any feedback by the way..)",
                  "score": 1,
                  "created_utc": "2026-01-21 09:07:12",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o0tqgvy",
                  "author": "SheepherderOwn2712",
                  "text": "this is who I built it for! (would love any feedback btw...)",
                  "score": 1,
                  "created_utc": "2026-01-21 09:08:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p0amt",
              "author": "mokumkiwi",
              "text": "Je had hem echt te pakken, bro",
              "score": -6,
              "created_utc": "2026-01-20 16:50:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qmjz1",
          "author": "Cats4BreakfastPlz",
          "text": "how does this compare to Consensus?",
          "score": 1,
          "created_utc": "2026-01-20 21:17:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqfw1",
              "author": "SheepherderOwn2712",
              "text": "this has more data sources and is fully open source! consensus is cool though",
              "score": 2,
              "created_utc": "2026-01-21 09:08:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o15cctl",
                  "author": "Cats4BreakfastPlz",
                  "text": "it has more data sources? that's interesting... how do yo get access to sources Concensus doesn't? Would be interested in a libgen version of this",
                  "score": 0,
                  "created_utc": "2026-01-23 00:22:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ygi0w",
          "author": "TheTechHorde",
          "text": "Looks great! How'd you make the demo video btw? Looks sleek.",
          "score": 1,
          "created_utc": "2026-01-22 00:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10ociv",
              "author": "SheepherderOwn2712",
              "text": "screenstudio",
              "score": 1,
              "created_utc": "2026-01-22 09:26:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ztrl6",
          "author": "acharya-chanakya",
          "text": "Absolutely amazing",
          "score": 1,
          "created_utc": "2026-01-22 05:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10odgh",
              "author": "SheepherderOwn2712",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-01-22 09:26:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bh86c",
          "author": "potatofan1738",
          "text": "kind of like openevidence!",
          "score": 1,
          "created_utc": "2026-01-23 22:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fe3h8",
          "author": "_Crescendo",
          "text": "Fully open-source!",
          "score": 1,
          "created_utc": "2026-01-24 14:07:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oud4z",
          "author": "unskilledexplorer",
          "text": "love the UX",
          "score": 1,
          "created_utc": "2026-01-20 16:23:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ozi93",
              "author": "SheepherderOwn2712",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-01-20 16:47:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pz2p3",
          "author": "FreddieM007",
          "text": "Very cool! Have you tried the deep research modes of ChatGPT, Gemini, etc? In my experience, they work well including valid citations.",
          "score": 1,
          "created_utc": "2026-01-20 19:29:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tq9me",
              "author": "SheepherderOwn2712",
              "text": "the problem is that because they use bing/google search, they can't go beyond abstracts of papers nd don't have access to data that isn't indexed by web search (such as chembl/drugbank/opentargets/etc). Even clinical trials it struggles with!",
              "score": 2,
              "created_utc": "2026-01-21 09:06:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r3fv6",
          "author": "thelonghauls",
          "text": "I used a bidet today.",
          "score": -2,
          "created_utc": "2026-01-20 22:38:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rrxm8",
              "author": "DeviousCham",
              "text": "![gif](giphy|glvNGHmbZwgrKH4YYA)",
              "score": 1,
              "created_utc": "2026-01-21 00:50:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjh1qq",
      "title": "Thoughts on Agentic Design Patterns by Antonio Gulli",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qjh1qq/thoughts_on_agentic_design_patterns_by_antonio/",
      "author": "Bonnie-Chamberlin",
      "created_utc": "2026-01-22 01:37:49",
      "score": 41,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "I just finished reading *Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems*, and wanted to share some thoughts from an LLM dev perspective.\n\nThe author, Antonio Gulli (Google Cloud AI), clearly writes from an engineering background. This isnâ€™t a trends or hype book â€” itâ€™s very focused on how to actually structure agentic systems that go beyond single-call prompting.\n\nWhat the book focuses on\n\nInstead of models or benchmarks, the book frames agent development around **design patterns**, similar to classic software engineering.\n\nIt addresses a question many of us run into:\n\nHow do you turn LLM calls into reliable, multi-step, long-running systems?\n\nThe book is organized around \\~20 agentic patterns, including:\n\n* Prompt chaining, routing, and planning\n* Tool use and context engineering\n* Memory, RAG, and adaptation\n* Multi-agent coordination and communication\n* Guardrails, evaluation, and failure recovery\n\nMost chapters include concrete code examples (LangChain / LangGraph / CrewAI / Google tooling), not just conceptual diagrams.\n\nWhat I found useful as a dev\n\nPersonally, the biggest value was:\n\n* A clearer **mental model for agent workflows**, not just â€œagent = loopâ€\n* Better intuition for when to decompose into multiple agents vs a single one\n* Practical framing of context engineering and memory management\n* Realistic discussion of limitations (reasoning, evaluation, safety)\n\nIt helped me reason more systematically about why many agent demos break down when you try to scale or productize them.\n\nWho this is probably for\n\n* LLM devs building agentic workflows or internal tools\n* People moving from single-call pipelines to multi-step systems\n* Engineers thinking about production reliability, not just demos\n\nIf youâ€™re mostly interested in model internals or training, this may not be your thing. If youâ€™re focused on **system design around LLMs**, itâ€™s worth a look.\n\nIf anyone here has read it, Iâ€™d be curious to hear your take.",
      "is_original_content": false,
      "link_flair_text": "Great Resource ðŸš€",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjh1qq/thoughts_on_agentic_design_patterns_by_antonio/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o104s5x",
          "author": "SnooDonuts3147",
          "text": "Hi, i am the author. Thank you for your words. I don't have any relationship with this kind reviewer\n\n[https://www.linkedin.com/in/searchguy/](https://www.linkedin.com/in/searchguy/)",
          "score": 9,
          "created_utc": "2026-01-22 06:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o106tvm",
              "author": "Bonnie-Chamberlin",
              "text": "wow. Thanks for the book LOL. Wish I could connect with you.",
              "score": 3,
              "created_utc": "2026-01-22 06:47:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o13jmja",
              "author": "junod972",
              "text": "thanks a lot for taking the time to say these kind words. I hope this will help.",
              "score": 1,
              "created_utc": "2026-01-22 19:04:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0z2b0z",
          "author": "robogame_dev",
          "text": "This post is looking a bit suss, more like promotion than a review, before we can approve it please answer:  \n1. why are you saying for people to DM you for the book rather than posting the link?  \n2. do you have any relationship with the author or the publisher?",
          "score": 4,
          "created_utc": "2026-01-22 02:17:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ze5w3",
              "author": "Bonnie-Chamberlin",
              "text": "Hi, thanks for your message. I have edited my post and removed DM (everytime when I put a link in post, it will be banned, that's why). I don't have any relationship with the author (I wish he could know me LOL)",
              "score": 2,
              "created_utc": "2026-01-22 03:25:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o10hmag",
                  "author": "havok_",
                  "text": "Your wish came true!",
                  "score": 1,
                  "created_utc": "2026-01-22 08:23:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o104z5g",
          "author": "junod972",
          "text": "Thanks for the post Iwas waiting for this kind of book. Iâ€™m craving for deep return of real experience with agents not just Â«Â wow itâ€™s so shinnyÂ Â». Thanks",
          "score": 2,
          "created_utc": "2026-01-22 06:31:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o106giz",
              "author": "Bonnie-Chamberlin",
              "text": "You are welcome.",
              "score": 2,
              "created_utc": "2026-01-22 06:44:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11oq6l",
          "author": "gized00",
          "text": "I like the clarity that the book brings but I find it to be too verbose. I would say that it should be 30-50% shorter.",
          "score": 2,
          "created_utc": "2026-01-22 13:54:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o125xbg",
              "author": "Bonnie-Chamberlin",
              "text": "I think you can go to the project repo to make some comments. Maybe Gulli can further polish.",
              "score": 1,
              "created_utc": "2026-01-22 15:20:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1aedum",
          "author": "Effective-Entry-9810",
          "text": "# The Agentic Product Playbook: Design Patterns for Intent Driven, Self Executing Software is another good book ....",
          "score": 2,
          "created_utc": "2026-01-23 18:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11jpuo",
          "author": "pisrael",
          "text": "Thks for the summary. I'll check it out",
          "score": 1,
          "created_utc": "2026-01-22 13:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11k5wx",
              "author": "Bonnie-Chamberlin",
              "text": "Hope you like it.",
              "score": 1,
              "created_utc": "2026-01-22 13:29:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12e9hx",
          "author": "New-Glove-6184",
          "text": "Link?",
          "score": 1,
          "created_utc": "2026-01-22 15:59:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15p0qt",
              "author": "Bonnie-Chamberlin",
              "text": "Here is the link:https://github.com/sarwarbeing-ai/Agentic\\_Design\\_Patterns/tree/main. Sometimes when I post with a link, the post will be banned.",
              "score": 1,
              "created_utc": "2026-01-23 01:32:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qh492o",
      "title": "NVIDIA's Moat is Leaking: The Rise of High-Bandwidth CPUs",
      "subreddit": "LLMDevs",
      "url": "https://medium.com/researchable/nvidias-moat-is-leaking-the-rise-of-high-bandwidth-cpus-b4d4578457e4",
      "author": "ResearchableNL",
      "created_utc": "2026-01-19 13:33:28",
      "score": 32,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qh492o/nvidias_moat_is_leaking_the_rise_of_highbandwidth/",
      "domain": "medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0julvn",
          "author": "insulaTropicalis",
          "text": ">Sure, FLOPs drop significantly since you're only activating around 37B parameters per token, but you still need the entire model loaded in memory. This means the real constraint isn't compute power anymore. It's memory bandwidth.\n\nThat's not how it works. Memory bandwidth has nothing to do with the entire model size, because you are not processing the whole MoE model. You need to load the whole model in RAM, so what matters is the quantity of RAM. Then you can estimate token generation speed dividing memory bandwidth by active parameters.\n\nThat said, AMD loves to advertise false memory bandwidths for its CPUs. You can only saturate the theoretical bandwidth if CPU-bus bandwidth is at least the same. If not, that's a bottleneck. Only higher count (and higher cost) Epyc CPUs have enough chiplets and links to saturate the bandwidth. Sadly, you need an 8+ chiplets SKU, which coupled with 12 sticks of fast RAM is going to cost more than 5k.\n\nOnce you have selected the right CPU and RAM, you have a high bandwidth system. Which is very good at token generation, no doubt about that, but very slow at prompt processing where only FLOPS matter.",
          "score": 4,
          "created_utc": "2026-01-19 21:29:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jxob0",
          "author": "RnRau",
          "text": "Nvidia's moat was never in inferencing. Its still there in training.",
          "score": 4,
          "created_utc": "2026-01-19 21:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i3jgr",
          "author": "GabrielCliseru",
          "text": "iâ€™ve seen videos on youtube, the models ran on server hardware but they were producing ~10 t/s or so. Works yes. Would you actually use for development. Heck no. Is it ok as a â€œlocalâ€ wikipedia. Heck yes.",
          "score": 4,
          "created_utc": "2026-01-19 16:41:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0in18s",
              "author": "Mikasa0xdev",
              "text": "Local LLMs are the new startup garage project.",
              "score": 3,
              "created_utc": "2026-01-19 18:09:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0k21xu",
              "author": "[deleted]",
              "text": "Depends on whether development means human-is-the-loop all night or human-in-the-loop in the morning after your well designed agentic workflow is finished creating the PR.",
              "score": 3,
              "created_utc": "2026-01-19 22:06:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0llehl",
                  "author": "GabrielCliseru",
                  "text": "as someone very fan-boy recently of BMAD i doubt about the human in the loop in the morning. Maybe i am doing it wrong.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0no6h1",
          "author": "Tiny_Arugula_5648",
          "text": "The author made some bad assumptions here. Memory bandwidth is only the bottleneck *because* GPU compute is fast enough to saturate it. On a CPU, you don't hit the bandwidth ceiling.. you hit the compute ceiling first. You're not solving the problem, you're just trading a bandwidth bottleneck for a worse compute bottleneck.\n\nTheir whole argument is based on batch size = 1, which is not how production LLMs run. The moment you're batching requests, compute dominates again. LLMs are massively parallelized matrix multiplication.. you can't compare a GPU with thousands of cores to an EPYC with 128.\n\nAnd then there's efficiency. We measure hardware on FLOPs per watt. Yeah, a 5090 will suck every electron out of your socket, but it's nowhere near as much of a pig as a 128-core system burning more watts *per token*.\n\nNo offense intended, but this reads like a senior software engineer writing about ML infrastructure without the background. There's a lot of research that's explored the \"should we just CPU it\" angle and they all pretty much land on: technically doable, massively wasteful.",
          "score": 2,
          "created_utc": "2026-01-20 12:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ilo98",
          "author": "____vladrad",
          "text": "Xeon 6 12 channel ddr5 with the matrix multiplier can get like 1.5 tb at least with the slang article they talked about.  https://lmsys.org/blog/2025-07-14-intel-xeon-optimization/",
          "score": 1,
          "created_utc": "2026-01-19 18:03:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j6zzp",
          "author": "Mundane-Light6394",
          "text": "For local inference (one or a few users) memory bandwidth is a much bigger issue than for cloud inference (batch inference for multiple users). Local CPU inference is a lot more viable than CPU cloud inference (for now)",
          "score": 1,
          "created_utc": "2026-01-19 19:38:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj3pc1",
      "title": "[Open Sourse] I built a tool that forces 5 AIs to debate and cross-check facts before answering you",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/0ttifc9viqeg1.jpeg",
      "author": "S_Anv",
      "created_utc": "2026-01-21 17:09:24",
      "score": 20,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qj3pc1/open_sourse_i_built_a_tool_that_forces_5_ais_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0wurj1",
          "author": "wdroz",
          "text": "There are some similarities to the project [llm-council](https://github.com/karpathy/llm-council) from [Andrej Karpathy](https://github.com/karpathy/llm-council).",
          "score": 5,
          "created_utc": "2026-01-21 19:37:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wv5p3",
              "author": "S_Anv",
              "text": "Karpathy is a great man!\n\nKEA Research is designed as a user-friendly evolution. I've added image support, PDF/md export, text-to-speech conversion, and a full-fledged admin panel for managing local model sets without editing configuration files and many other features\n\nThis means you can create your own model set through a graphical interface  \nAlso as you see there is a bit different logic. You can check readme",
              "score": 4,
              "created_utc": "2026-01-21 19:39:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w32rv",
          "author": "coloradical5280",
          "text": "Here are a few tips, having built a lot of this stuff:  \n\n\n* Make it anonymous; the models donâ€™t know which response belongs to them during peer review. Instead, simply tag them as Model A, B, C, etc.\n* More importantly, tone down your step 3 prompt a bit, especially on the â€œfind errorsâ€ part. All the counsel, quorum, debate, and peer-review workflows can have a significant impact on the quality of the output, both positively and negatively. The crucial point is to determine the right balance between encouraging the model to find errors and avoiding over-reliance on it. If you simply provide the context of the situation, as you clearly do, the model will naturally follow your instructions. You already have â€˜weaknessesâ€™ in the JSON format, so thereâ€™s no need for the last four bullet points in step 3. Honestly, your approach is 90% better than many that Iâ€™ve seen.\n\nPeople are out there literally telling the model to go into attack mode, and wondering why it's entertaining but so worthless.\n\nAlso, if you ever want to use your subscriptions instead of API keys only, this is a gem: [https://github.com/router-for-me/CLIProxyAPIPlus](https://github.com/router-for-me/CLIProxyAPIPlus)",
          "score": 3,
          "created_utc": "2026-01-21 17:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12mv80",
          "author": "Electronic_coffee6",
          "text": "Love that itâ€™s provider-agnostic, being able to plug in my own OpenAI keys makes this super flexible. Are there plans to add support for more open-source models in the future?",
          "score": 2,
          "created_utc": "2026-01-22 16:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14091c",
              "author": "S_Anv",
              "text": "What specific provider and models do you need?",
              "score": 1,
              "created_utc": "2026-01-22 20:20:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12lt9v",
          "author": "No-Professional2832",
          "text": "I've installed this and the consensus approach is really interesting. The mix of models helps surface different perspectives, and it feels like a step toward more reliable AI outputs. You mentioned more interesting features are coming, what can we expect next?",
          "score": 1,
          "created_utc": "2026-01-22 16:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18ofn6",
          "author": "ProTomek",
          "text": "Nice project!  \n  \nPS: ChatGPT responses? Or GPT (over OpenAI API) responses? Because those two are two totally different animals...",
          "score": 1,
          "created_utc": "2026-01-23 14:11:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qips4o",
      "title": "A legendary xkcd comic. I used Dive + nano banana to adapt it into a modern programmer's excuse.",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/dbi6ee1b5neg1.png",
      "author": "Prior-Arm-6705",
      "created_utc": "2026-01-21 05:51:45",
      "score": 18,
      "num_comments": 3,
      "upvote_ratio": 0.78,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qips4o/a_legendary_xkcd_comic_i_used_dive_nano_banana_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0tbi28",
          "author": "davidSenTeGuard",
          "text": "Isn't there some premium option to un-limit you. You company is probably paying more for your time than they would for the upgrade.",
          "score": 1,
          "created_utc": "2026-01-21 06:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0thckz",
              "author": "stingraycharles",
              "text": "There is, you can typically switch to API pricing.",
              "score": 1,
              "created_utc": "2026-01-21 07:42:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tpooq",
                  "author": "Hegemonikon138",
                  "text": "Or you can just buy multiple accounts, thats what I do.",
                  "score": 1,
                  "created_utc": "2026-01-21 09:00:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qkhuro",
      "title": "Adaptive execution control matters more than prompt or ReAct loop design",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkhuro/adaptive_execution_control_matters_more_than/",
      "author": "zennaxxarion",
      "created_utc": "2026-01-23 05:05:27",
      "score": 14,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I kept running into the same problem with agent systems whenever long multi-step tasks were involved. Issues with reliability kept showing up during agent evaluation, and then some runs were failing in ways it felt hard to predict. Plus the latency and cost variation just became hard to justify or control, especially when the tasks looked similar on paper.\n\nSo first I focused on prompt design and ReAct loop structure. I changed how the agent was told to reason and the freedom it had during each execution step. Some changes made steps in the process look more coherent and it did lead to fewer obvious mistakes earlier on.\n\nBut when the tasks became wider the failure modes kept appearing. The agent was drifting or looping. Or sometimes it would commit to an early assumption inside the ReAct loop and just keep executing even when later actions were signalling that reassessment was necessary.\n\nSo I basically concluded that refining the loop only changed surface behavior and there were still deeper issues with reliability.Â \n\nInstead I shifted towards how execution decisions were handled over time at the orchestration layer. So because many agent systems lock their execution logic upfront and only evaluate outcomes after the run, you canâ€™t intervene until afterwards, where the failure got baked in and you see wasted compute.\n\nIt made sense to intervene during execution instead of after the fact because then you can allocate TTC dynamically while the trajectories unfold. I basically felt like that had a much larger impact on the reliability. It shifted the question from why an agent failed to why the system was allowing an unproductive trajectory to continue unchecked for so long.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkhuro/adaptive_execution_control_matters_more_than/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o17gmwm",
          "author": "PuzzleheadedTooth112",
          "text": "This feels like the same argument people had about monoliths years ago. You can keep making the monolith smarter or you can break the work up so failure doesnâ€™t cascade. Most agent setups still look like monoliths to me.",
          "score": 1,
          "created_utc": "2026-01-23 08:50:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17h8fi",
          "author": "DrPickman",
          "text": "Definitely some food for thought. At some point I basically assumed long runs are too brittle for now and I should park it until the future. Just moved to shorter jobs with checkpoints and handoff between runs after finding the models werenâ€™t impacting much.",
          "score": 1,
          "created_utc": "2026-01-23 08:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17hqqu",
          "author": "Intelligent_Front_37",
          "text": "TBH we stopped carâ¤ing abâ¤out long tasks and decided itâ€™s the task thatâ€™s the issue. If we canâ€™t surfâ¤ace progâ¤ress within a few minutes the task has to change shape. We got imprâ¤oved reliabâ¤ility after changing the problem instead of the agent.",
          "score": 1,
          "created_utc": "2026-01-23 09:00:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bko9f",
          "author": "pbalIII",
          "text": "Hit a similar wall last year. Prompt tweaks felt productive until tasks got wide enough that the agent started looping on stale assumptions.\n\nThe shift to runtime intervention changed what we measured. Instead of asking why did this fail, we started tracking how long did we let it keep going. Turns out most costly failures were obvious 3-4 steps before they cratered... the system just had no mechanism to reassess mid-run.\n\nOne pattern that helped: graduated containment. Monitor mode first, then restrict planning if risk scores climb, then pull tool access. Lets you calibrate intervention aggressiveness per task type instead of binary halt-or-continue.",
          "score": 1,
          "created_utc": "2026-01-23 22:17:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjjbgo",
      "title": "Fei Fei Li dropped a non-JEPA world model, and the spatial intelligence is insane",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/d7y1bfsejteg1",
      "author": "coloradical5280",
      "created_utc": "2026-01-22 03:19:08",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjjbgo/fei_fei_li_dropped_a_nonjepa_world_model_and_the/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0zs408",
          "author": "Whole-Assignment6240",
          "text": "this is super cool",
          "score": 1,
          "created_utc": "2026-01-22 04:54:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkzkn2",
      "title": "Mirascope: Typesafe, Pythonic, Composable LLM abstractions",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkzkn2/mirascope_typesafe_pythonic_composable_llm/",
      "author": "teamdandelion",
      "created_utc": "2026-01-23 18:58:56",
      "score": 11,
      "num_comments": 16,
      "upvote_ratio": 0.92,
      "text": "Hi everyone! I'm an at Mirascope, a small startup shipping open-source LLM infra. We just shipped v2 of our open-source Python library for typesafe LLM abstractions, and I'd like to share it.\n\n*TL;DR: This is a Python library with solid typing and cross-provider support for streaming, tools, structured outputs, and async, but without the overhead or assumptions of being a framework. Fully open-source and MIT licensed.*\n\nAlso, advance note: All em-dashes in this post were written by hand. It's option+shift+dash on a Macbook keyboard ;)\n\nIf you've felt like LangChain is too heavy and LiteLLM is too thin, Mirascope might be what you're looking for. It's not an \"agent framework\"â€”it's a set of abstractions so composable that you don't actually need one. Agents are just tool calling in a while loop.\n\nAnd it's got 100% test coverage, including cross-provider end-to-end tests for every features that use VCR to replay real provider responses in CI.\n\nThe pitch: How about a low-level API that's typesafe, Pythonic, cross-provider, exhaustively tested, and intentionally designed?  \n\n\nMirascope's focus is on typesafe, composable abstractions. The core concepts is you have an `llm.Model` that generates `llm.Response`s, and if you want to add tools, structured outputs, async, streaming, or MCP, everything just clicks together nicely. Here are some examples:\n\n    from mirascope import llm\n    \n    model: llm.Model = llm.Model(\"anthropic/claude-sonnet-4-5\")\n    response: llm.Response = model.call(\"Please recommend a fantasy book\")\n    print(response.text())\n    # > I'd recommend The Name of the Wind by Patrick Rothfuss...\n\nOr, if you want streaming, you can use `model.stream(...)`  along with `llm.StreamResponse`:\n\n    from mirascope import llm\n    \n    model: llm.Model = llm.Model(\"anthropic/claude-sonnet-4-5\")\n    response: llm.StreamResponse = model.stream(\"Do you think Pat Rothfuss will ever publish Doors of Stone?\")\n    \n    for chunk in response.text_stream():\n      print(chunk, flush=True, end=\"\")\n\nEach response has the full message history, which means you can continue generation by calling \\`response.resume\\`:\n\n    from mirascope import llm\n    \n    response = llm.Model(\"openai/gpt-5-mini\").call(\"How can I make a basil mint mojito?\")\n    print(response.text())\n    \n    response = response.resume(\"Is adding cucumber a good idea?\")\n    print(response.text())\n\n`Response.resume` is a cornerstone of the library, since it abstracts state tracking in a very predictable way. It also makes tool calling a breeze. You define tools via the `@llm.tool` decorator, and invoke them directly via the response.\n\n    from mirascope import llm\n    \n    @llm.tool\n    def exp(a: float, b: float) -> float:\n        \"\"\"Compute an exponent\"\"\"\n        return a ** b \n    \n    model = llm.Model(\"anthropic/claude-haiku-4-5\")\n    response = model.call(\"What is (42 ** 3) ** 2?\", tools=[exp])\n    \n    while response.tool_calls:\n      print(f\"Calling tools: {response.tool_calls}\")\n      tool_outputs = response.execute_tools()\n      response = response.resume(tool_outputs)\n    \n    print(response.text())\n\nThe `llm.Response` class also allows handling structured outputs in a typesafe way, as it's generic on the structured output format. We support primitive types as well as Pydantic `BaseModel` out of the box:\n\n    from mirascope import llm \n    from pydantic import BaseModel\n    \n    class Book(BaseModel):\n        title: str\n        author: str\n        recommendation: str\n    \n    # nb. the @llm.call decorator is a convenient wrapper.\n    # Equivalent to model.call(f\"Recommend a {genre} book\", format=Book)\n    \n    @llm.call(\"anthropic/claude-sonnet-4-5\", format=Book)\n    def recommend_book(genre: str):\n      return f\"Recommend a {genre} book.\"\n    \n    response: llm.Response[Book] = recommend_book(\"fantasy\")\n    book: Book = response.parse()\n    print(book)\n    \n\nThe upshot is that if you want to do something sophisticatedâ€”like a streaming tool calling agentâ€”you don't need a framework, you can just compose all these primitives.\n\n    from mirascope import llm\n    \n    @llm.tool\n    def exp(a: float, b: float) -> float:\n        \"\"\"Compute an exponent\"\"\"\n        return a ** b \n    \n    @llm.tool\n    def add(a: float, b: float) -> float:\n        \"\"\"Add two numbers\"\"\"\n        return a + b \n    \n    model = llm.Model(\"anthropic/claude-haiku-4-5\")\n    response = model.stream(\"What is 42 ** 4 + 37 ** 3?\", tools=[exp, add])\n    \n    while True:\n        for chunk in response.pretty_stream():\n            print(chunk, flush=True, end=\"\")\n        if response.tool_calls:\n          tool_output = response.execute_tools()\n          response = response.resume(tool_output) \n        else:\n            break # Agent is finished\n\nI believe that if you give it a spin, it will delight you, whether you're coming from the direction of wanting more portability and convenience than using raw provider SDKs, or wanting more hands-on control than the big agent frameworks. These examples are all runnable, you can run`uv add \"mirascope[all]\"`, and set API keys.\n\nYou can read more in the [docs](https://mirascope.com/docs/learn/llm/quickstart), see the source on [GitHub](https://github.com/Mirascope/mirascope/tree/main), or join our [Discord](https://mirascope.com/discord-invite). Would love any feedback and questions :)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkzkn2/mirascope_typesafe_pythonic_composable_llm/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1ahy89",
          "author": "MaticPecovnik",
          "text": "I like it at first glance. But why choose your framework if I can use pydantic-ai? It seems quite similar in design. What sets you apart?",
          "score": 6,
          "created_utc": "2026-01-23 19:14:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1an8c1",
              "author": "teamdandelion",
              "text": "PydanticAI shares a lot of values (e.g. type safety and structured output support), and both make it easy to write powerful agents. The difference is in philosophy of how you get there. Pydantic AI uses agents as the core primitive, whereas in Mirascope the primitives are one step \"more atomic\" at the level of LLM models, calls, and requests. Rather than providing a fixed agent as a primitive, we've just made it really easy to roll your own Agent.\n\nMirascope is one step \"closer to metal\" (ie. direct control over the LLM requests you're making, just with really nice APIs), whereas Pydantic gets convenience by going up one layer of abstraction.\n\nFor a lot of use cases both will serve well, but Mirascope takes more of an \"onion\" approach where it's easy to peel back a layer and get more direct control over LLM execution. The upshot is its easy to write Pydantic-style agents using Mirascope, but you also get flexibility over exactly what happens in a way that otherwise wouldn't exist.",
              "score": 4,
              "created_utc": "2026-01-23 19:39:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1aoz7v",
                  "author": "wbakst",
                  "text": "\\+1\n\nHi! I'm another author of Mirascope. I've spent a lot of time in the AI space developing open-source tools, and one thing that has been consistent throughout is that at some point I always want to break glass. I want to be able to seamlessly move up and down the interfaces of the tool as I need.\n\nWe didn't want an agent framework, we wanted the tools to easily build our own agent harnesses without abstraction hell. We built Mirascope because we felt no such tool existed yet. We wanted \"breaking glass\" to be top of mind in our development philosophy, and I think we've done a pretty good job of this.\n\nI think you'll feel the love and care we've put into everything we've built. I'm curious to hear what you think, and we always welcome any and all feedback with open arms!",
                  "score": 3,
                  "created_utc": "2026-01-23 19:48:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1dntoq",
                  "author": "MaticPecovnik",
                  "text": "Ok I get it and I agree.\n\nWhat I really like about pydantic ai is their focus od dependency injection and testing with their overrides. How do you do unit tests in Mirascope, assuming you donâ€™t want to call LLMs durnt unit tests.",
                  "score": 2,
                  "created_utc": "2026-01-24 05:37:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1aidfb",
          "author": "langcuck",
          "text": "\"If you've felt like LangChain is too heavy\"\n\nThat's a nice way of putting it lol",
          "score": 4,
          "created_utc": "2026-01-23 19:16:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1axbjd",
              "author": "ChanceKale7861",
              "text": "Bahahahahhahaahâ€¦\n\nYou win. ðŸ¥‡ ðŸ˜‚ðŸ™Œ",
              "score": 1,
              "created_utc": "2026-01-23 20:27:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1axr73",
                  "author": "langcuck",
                  "text": "just being honest ðŸ¤·ðŸ»â€â™‚ï¸",
                  "score": 2,
                  "created_utc": "2026-01-23 20:29:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1c597s",
          "author": "danigoncalves",
          "text": "You don't do that to somebody like me who was about to start a new AI project and thought about using PydanticAI. I really liked what I saw - it seems simple with a low learning curve, and the fact that you lay down the foundation with `llm.Model` and allow us to compose only the abstractions we need when we need them is very important when applications tend to become bigger. Optimizing and improving these parts atomically (one at a time) becomes crucial.",
          "score": 2,
          "created_utc": "2026-01-24 00:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1c8xo9",
              "author": "wbakst",
              "text": "You're exactly who we built this for :)\n\nExcited for you to give it a try and let us know what you think!!",
              "score": 2,
              "created_utc": "2026-01-24 00:24:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ca1ii",
                  "author": "danigoncalves",
                  "text": "You bet :)",
                  "score": 2,
                  "created_utc": "2026-01-24 00:30:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1feynr",
                  "author": "danigoncalves",
                  "text": "I was messing around with a few examples and had two feelings (might be wrong). \n\n1. For me, the best frameworks are those where the source code itself serves as documentation. This is one of them.\n\n2. Is it me or instead of promoting this as an alternative to frameworks as pydanticAI, it can also be promoted as a sidecar for agents or other specific purpose frameworks? Part of the composable abstractions advantage is that if you feel that it serves you better have a higher abstract for agents, just plugin another framework and work with both. I think the flexibility is a huge win for the applications that start small and unscoped and grow into something more specific in the future.",
                  "score": 2,
                  "created_utc": "2026-01-24 14:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qgz9xk",
      "title": "Estimating AI agent costs upfront is harder than I expected. Looking for feedback on an approach",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qgz9xk/estimating_ai_agent_costs_upfront_is_harder_than/",
      "author": "Am_a_good_guy",
      "created_utc": "2026-01-19 09:03:17",
      "score": 10,
      "num_comments": 8,
      "upvote_ratio": 0.92,
      "text": "While working on AI agents, one problem I kept running into wasnâ€™t model choice or orchestration. It was **cost estimation early on**.\n\nBefore building anything, there are too many unknowns:\n\n* model selection and token usage\n* architecture choices (single agent vs orchestration)\n* infra vs managed services\n* how quickly costs blow up with scale\n\nI built a small tool to experiment with this problem. You describe an agent idea in plain English, and it outputs **three implementation approaches** (low / medium / high cost) with rough breakdowns for models, infra, and usage assumptions.\n\nThe goal isnâ€™t â€œaccurate pricingâ€. Itâ€™s helping people reason about **feasibility and trade-offs earlier**, before committing to an architecture.\n\nIâ€™m mainly posting here to learn from people actually building LLM systems:\n\n* How do you currently estimate agent costs?\n* What usually ends up being underestimated?\n* Are there cost drivers you think a tool like this would miss?\n\nI also launched it on Product Hunt today to collect broader feedback, but Iâ€™m more interested in technical critique from this community.\n\nPH link - [https://www.producthunt.com/products/price-my-agent?launch=price-my-agent](https://www.producthunt.com/products/price-my-agent?launch=price-my-agent)\n\nAppreciate any thoughts. Even if you think this approach is flawed.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qgz9xk/estimating_ai_agent_costs_upfront_is_harder_than/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0h4ago",
          "author": "Electrical_Worry_728",
          "text": "Biggest underestimates I keep seeing are loop count, the long tail (p95/p99), and context growth (retrieval + tool outputs + history). A flow that looks cheap at p50 can get ugly fast once you hit retries and multi-step plans.\n\nIf your tool can output an â€œassumptions sheetâ€ (expected turns, retry policy, retrieved chunks, cache hit rate, and a p95 multiplier), thatâ€™s where the value is. People can argue with assumptions instead of arguing with a single number.\n\nAlso worth calling out observability. Prompt/tool logging and traces can become real cost, and you usually end up having to redact/bound it anyway.",
          "score": 3,
          "created_utc": "2026-01-19 13:50:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0i6jah",
              "author": "Am_a_good_guy",
              "text": "This is a really solid breakdown. Totally agree on loop counts, long-tail behavior, and context growth being where estimates often break down. I like the idea of an explicit â€œassumptions sheetâ€ so people can reason about why a number looks the way it does instead of treating it as a single source of truth.\n\nOn observability, I agree it can become a real cost, especially at scale or with heavy debugging and compliance needs. \n\nThat said, Iâ€™ve also seen cases where teams sample logs, truncate payloads, or disable tracing in production, so itâ€™s not always a major driver compared to inference itself. Still an important thing to surface as systems mature.\n\nI really appreciate you sharing this. Super useful perspective.",
              "score": 2,
              "created_utc": "2026-01-19 16:54:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0j4hsx",
                  "author": "Electrical_Worry_728",
                  "text": "Yep, totally fair point. Inference is usually the main line item, and a lot of teams keep observability from exploding by doing exactly what you described - sampling, truncation, and strict payload limits.\n\nI still like surfacing it early mostly because it affects design choices. People end up deciding things like:\n\n* log metadata vs full payloads\n* store raw traces only on demand\n* different sampling in dev vs prod\n* redaction policy from day one\n\nIf youâ€™re building a cost estimator, it might be useful to treat observability as a set of knobs (sampling rate, max payload size, retention) rather than a fixed number.",
                  "score": 2,
                  "created_utc": "2026-01-19 19:26:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0imrwy",
              "author": "Mikasa0xdev",
              "text": "My startup uses infinite free tier credits.",
              "score": 2,
              "created_utc": "2026-01-19 18:08:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0j4ocj",
                  "author": "Electrical_Worry_728",
                  "text": "Nice, thatâ€™s honestly the best case while it lasts.\n\nThe only catch is it can hide the real shape of costs. The first time you lose credits, switch providers, or scale traffic, it becomes hard to reason about what â€œnormalâ€ looks like. Even rough estimates are useful for planning and for avoiding surprise architecture choices later.",
                  "score": 1,
                  "created_utc": "2026-01-19 19:27:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kblkz",
          "author": "kubrador",
          "text": " the main thing you're missing is how fast people panic-add guardrails once they see their first $400 bill from unexpected api calls. everyone underestimates the \"oh shit we need rate limiting and fallbacks NOW\" multiplier.",
          "score": 1,
          "created_utc": "2026-01-19 22:54:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qx1ct",
          "author": "pbalIII",
          "text": "The assumptions sheet idea is where this lands. Static cost estimates are worse than useless... they give false confidence right before reality diverges.\n\nSplit calls into cacheable vs non-cacheable upfront. Retrieval prompts, summarization, formatting... those hit semantic cache well. Planning and judgment calls almost never do. That split alone usually explains 2-3x variance between estimate and actuals.",
          "score": 1,
          "created_utc": "2026-01-20 22:06:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12nes6",
          "author": "Beneficial_Rush5028",
          "text": "If you are building Agentic solution, at the bare minimum you should be using Prompt Chaining and Context engineering. Remember not every task in the workflow requires the most powerful model.  Consider using a cheaper / faster model e.g haiku  for certain tasks in the workflow. Also put guardrails around Agent / Sub Agents token and tool usage.  Imagine a tool call returning large amount of data using up context and tokens. I wrote ModelGate specifically to have policy and optimization (semantic caching) around some of these things.   If an MCP Server returns 35 tools, will you give access to all 35 tools to any agent ?",
          "score": 0,
          "created_utc": "2026-01-22 16:40:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjzq0b",
      "title": "Why Energy-Based Models (EBMs) outperform Transformers on Constraint Satisfaction Problems (like Sudoku).",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qjzq0b/why_energybased_models_ebms_outperform/",
      "author": "bully309",
      "created_utc": "2026-01-22 16:50:11",
      "score": 9,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "We all know the struggle with LLMs when it comes to strict logic puzzles or complex constraints. You ask GPT-4 or Claude to solve a hard Sudoku or a scheduling problem, and while they sound confident, they often hallucinate a move that violates the rules because they are just predicting the next token probabilistically.  \n  \nI've been following the work on [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models), and specifically how they differ from autoregressive architectures.  \n  \nInstead of \"guessing\" the next step, the EBM architecture seems to solve this by minimizing an energy function over the whole board state.  \n  \nI found this benchmark pretty telling: [https://sudoku.logicalintelligence.com/](https://sudoku.logicalintelligence.com/)  \n  \nIt pits an EBM against standard LLMs. The difference in how they \"think\" is visible - the EBM doesn't generate text; it converges on a valid state that satisfies all constraints (rows, columns, boxes) simultaneously.  \n  \nFor devs building agents: This feels significant for anyone trying to build reliable agents for manufacturing, logistics, or code generation. If we can offload the \"logic checking\" to the model's architecture (inference time energy minimization) rather than writing endless Python guardrails, thatâ€™s a huge shift in our pipeline.  \n  \nHas anyone played with EBMs for production use cases yet? Curious about the compute cost vs standard inference.",
      "is_original_content": false,
      "link_flair_text": "Great Resource ðŸš€",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjzq0b/why_energybased_models_ebms_outperform/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o16bpwd",
          "author": "WhoTookPlasticJesus",
          "text": "I feel like I'm an idiot who is unable to navigate a web site. Is there a paper somewhere that I just can't find?",
          "score": 1,
          "created_utc": "2026-01-23 03:39:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17waqw",
              "author": "bully309",
              "text": "Haha, don't worry, it's not just you! The interface is quite minimalistic, so it's easy to miss. Let me know if you have trouble opening it! Try again.",
              "score": 1,
              "created_utc": "2026-01-23 11:12:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12rxh1",
          "author": "Far_Marionberry1717",
          "text": "> We all know the struggle with LLMs when it comes to strict logic puzzles or complex constraints. \n\nObviously, glorified auto-complete doesn't understand logic.\n\n>  Has anyone played with EBMs for production use cases yet? Curious about the compute cost vs standard inference. \n\nSure, it's called embedded C that you wrote by hand.",
          "score": 0,
          "created_utc": "2026-01-22 17:00:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12xw8v",
              "author": "bully309",
              "text": "Haha valid. For a fixed game like Sudoku, a hard-coded solver wins 100%. But the goal here is a generalizable system. We want a neural net that can handle messy, unstructured inputs (which \"embedded C\" hates) but still adhere to strict logical constraints (which LLMs hate). It's about bridging that gap.",
              "score": 1,
              "created_utc": "2026-01-22 17:27:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qgdfou",
      "title": "When do you actually go multi-agent vs one agent + tools?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/gallery/1qgdfou",
      "author": "OnlyProggingForFun",
      "created_utc": "2026-01-18 16:44:22",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qgdfou/when_do_you_actually_go_multiagent_vs_one_agent/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0bdu8x",
          "author": "OnlyProggingForFun",
          "text": "If anyone wants the PDF, I can share it too :)",
          "score": 2,
          "created_utc": "2026-01-18 16:44:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0c5grc",
          "author": "Purple-Programmer-7",
          "text": "Workflow: multi-step process with two or more llm calls\nAgent: one or more llm calls that make autonomous decision(s) and/or ask for user input that affect the result",
          "score": 2,
          "created_utc": "2026-01-18 18:53:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c10lg",
          "author": "Crashbox3000",
          "text": "PDF or repo link would be great if you have either",
          "score": 1,
          "created_utc": "2026-01-18 18:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c1xdx",
              "author": "OnlyProggingForFun",
              "text": "Just pdf for now! https://www.canva.com/design/DAG-yFA-G10/QianCF9BoU89KnU-4Gkwxw/view?utm_content=DAG-yFA-G10&utm_campaign=designshare&utm_medium=link&utm_source=viewer",
              "score": 1,
              "created_utc": "2026-01-18 18:37:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0camgh",
          "author": "Grue-Bleem",
          "text": "Weâ€™re testing this now, but just to be very clear... an â€œagentâ€ is not an LLM wrapper. It doesnâ€™t burn tokens, it doesnâ€™t need tokens. It does one job and can reason and predict without living inside a language model. A multi-agent flow is basically a vertical of ICs, each a specialist. If your â€œagentâ€ disappears when tokens run out, it was never an agent .. it was a prompt loop.  \n  \nI like your thinking, but the setup isnâ€™t being defined correctly.",
          "score": 1,
          "created_utc": "2026-01-18 19:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0djchf",
          "author": "hello5346",
          "text": "There is a difference between multiple models and multiple agents.  Going multi agent is the defacto default that everyone does. Not really special.",
          "score": 1,
          "created_utc": "2026-01-18 23:00:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql8b52",
      "title": "Reverse Engineering a $500M Mystery: From HashHop to Memory-Augmented Language Models",
      "subreddit": "LLMDevs",
      "url": "https://huggingface.co/blog/codelion/reverse-engineering-magic-hashhop",
      "author": "asankhs",
      "created_utc": "2026-01-24 00:41:32",
      "score": 9,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1ql8b52/reverse_engineering_a_500m_mystery_from_hashhop/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1ql0i6z",
      "title": "context management on long running agents is burning me out",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1ql0i6z/context_management_on_long_running_agents_is/",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-23 19:32:40",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 0.9,
      "text": "is it just me or does every agent start ignoring instructions after like 50-60 turns. i tell it dont do X without asking me first, 60 turns later it just does X anyway. not even hallucinating just straight up ignoring what i said earlier\n\ntried sliding window, summarization, rag, multiagent nothing really works. feels like the context just rots after a while\n\nhow are you guys handling this",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1ql0i6z/context_management_on_long_running_agents_is/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1axa59",
          "author": "Ok_Economics_9267",
          "text": "Keep context as short as possible. Manage memory manually. Add episodic and procedural memories. Search in memory and take only what matters, instead of adding whole memory to context.",
          "score": 3,
          "created_utc": "2026-01-23 20:27:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1apqdq",
          "author": "taftastic",
          "text": "Langmem does it, beads helps a lot and makes shorter sessions way easier",
          "score": 2,
          "created_utc": "2026-01-23 19:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bw0zl",
          "author": "neoneye2",
          "text": "In the past I tried plain text responses, and my code was fragile.\n\nNowadays I'm using structured output, and is doing around 100 inference calls. Only asking for very narrow things, so the response stays below 4 kilobytes.\n\nThis is a document I have generated.  \n[https://neoneye.github.io/PlanExe-web/20260104\\_operation\\_falcon\\_report.html](https://neoneye.github.io/PlanExe-web/20260104_operation_falcon_report.html)\n\nAnd this is my code for orchestrating the agents  \n[https://github.com/neoneye/PlanExe/blob/main/worker\\_plan/worker\\_plan\\_internal/plan/run\\_plan\\_pipeline.py](https://github.com/neoneye/PlanExe/blob/main/worker_plan/worker_plan_internal/plan/run_plan_pipeline.py)",
          "score": 2,
          "created_utc": "2026-01-23 23:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ao8jb",
          "author": "Arindam_200",
          "text": "I'm using byterover for it\n\nThey have context tree based approach. You can probably give it a shot",
          "score": 1,
          "created_utc": "2026-01-23 19:44:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1b1y0o",
          "author": "one-wandering-mind",
          "text": "use a better model, reinject instructions to just prior to the current conversation turn, use separate models and tools as validators and guardrails for important behaviors to avoid, intentionally manage the context. you probably don't want a generic summary unless what you are building is generic. maintain just the important information for your task(s).",
          "score": 1,
          "created_utc": "2026-01-23 20:49:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bja3n",
          "author": "Fulgren09",
          "text": "Cache system prompt and send it each turnÂ ",
          "score": 1,
          "created_utc": "2026-01-23 22:10:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkth1",
          "author": "johnerp",
          "text": "Yes this happens, thereâ€™s maths and reinforcement learning reasons.",
          "score": 1,
          "created_utc": "2026-01-23 22:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c3jlq",
          "author": "Charming_Support726",
          "text": "Yes. It rots after a while, almost every model gets awkward after around 150-180k. Jump of early and start new. On opencode things like the DCP help - but you get hit by different issues",
          "score": 1,
          "created_utc": "2026-01-23 23:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e1swr",
          "author": "MajinAnix",
          "text": "Trying to solve this problem too, in my head I have solution with tasks (tasks have separate conversation history, structured output)",
          "score": 1,
          "created_utc": "2026-01-24 07:33:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e691z",
          "author": "DotPhysical1282",
          "text": "Run a parallel agent whose only job is to ensure your main agent is following instructions. After every x turns, ask it to verify the main agent is following instructions. If it gets it wrong, itâ€™s time to remind it. Sending the prompt after each turn would be expensive and not necessary if it still has the context",
          "score": 1,
          "created_utc": "2026-01-24 08:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ffb9d",
              "author": "Main_Payment_6430",
              "text": "multiagent approach, i like it!",
              "score": 2,
              "created_utc": "2026-01-24 14:14:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ecsid",
          "author": "ggone20",
          "text": "What model are you using?\n\nEveryone likes to hate on OAI but since GPT 5.2, this is basically a non-issue. It truly does stay coherent though very complex workflows and literal day-long conversation sessions. Curious what other peopleâ€™s mileage is here.\n\nBefore 5.2, my general rule of thumb was to never let context exceed 20ish percent of its claimed window. The data has shown since the beginning that anything past literally the first turn performance degraded dramatically.",
          "score": 1,
          "created_utc": "2026-01-24 09:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ff7sq",
              "author": "Main_Payment_6430",
              "text": "that's why i created one truth! [https://github.com/justin55afdfdsf5ds45f4ds5f45ds4/onetruth.git](https://github.com/justin55afdfdsf5ds45f4ds5f45ds4/onetruth.git) i build this today, i knew this issue was the same thing i was facing that we need to not let the context exceed, but i am not there to flush things up every second, and i open sourced it",
              "score": 1,
              "created_utc": "2026-01-24 14:13:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1anmiz",
          "author": "Altruistic-Spend-896",
          "text": "Langmem",
          "score": -1,
          "created_utc": "2026-01-23 19:41:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkec6n",
      "title": "This is kind of blowing my mind... Giving agents a \"Hypothesis-Driven Optimization\" skill",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkec6n/this_is_kind_of_blowing_my_mind_giving_agents_a/",
      "author": "Floppy_Muppet",
      "created_utc": "2026-01-23 02:22:00",
      "score": 7,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "Iâ€™ve been experimenting with recursive self-learning for the last few months, and I'm starting to see some really positive results (sry, internal data folks) by equipping my agents with what I guess I'd call a \"Hypothesis-Driven Optimization\" skill.\n\n\n\nBasically, it attempts to automate the scientific method through a perpetual 5-stage loop:\n\n1. **Group I/O's**: Organize I/O performance into three buckets within each problem space cluster (top, bottom, and average).\n2. **Hypothesize**: Use a FM to speculate on why the top and bottom groups diverged from the average.\n3. **Distill**: Use a SLM to turn each hypothesis into actionable hints.\n4. **A/B Test**: RAG those hints into your prompt to see if they outperform your control group.\n5. **Scale or Iterate**: Scale the winning hypothesis' \"Hint Pack\" or use the learnings from failed test to iterate on a new hypothesis.\n\n\n\nPreviously, my agents were setup to simply mimic top-performing I/O's without *traceability* or *testability* of the actual conjecture(s) it was making.\n\n\n\nNow I'm seeing my agents get incrementally better on their own (with stat sig proof), and I know why, and by how much... It's kind of insane rn.\n\n\n\nCurious who else has tried a similar approach yet?!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkec6n/this_is_kind_of_blowing_my_mind_giving_agents_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o161dpp",
          "author": "qa_anaaq",
          "text": "Youâ€™d need a lot of data to approach the problem via this method though, right? Whatâ€™s the volume of interactions youâ€™re working with thatâ€™s showing promising results?",
          "score": 2,
          "created_utc": "2026-01-23 02:41:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o162w1y",
              "author": "Floppy_Muppet",
              "text": "Yes, you definitely need some amount of scale.\n\nI have hypotheses being generated on clusters when they have a minimum of 10 I/O's AND show a statistically significant difference between performance groups (so, in reality closer to \\~100 minimum I/O's).\n\nFor smaller scale agents, you could try broadening your problem spaces (to add more I/O's into each cluster) as well as the framing of your hypotheses as to try and discover more generally applicable hints.",
              "score": 1,
              "created_utc": "2026-01-23 02:49:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o174qwp",
                  "author": "tom-mart",
                  "text": ">I have hypotheses being generated on clusters when they have a minimum of 10 I/O's\n\n\nIs it 10 thousand or 10 millions I/O's?",
                  "score": 1,
                  "created_utc": "2026-01-23 07:03:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qiy5lx",
      "title": "5 AI agent predictions for 2026 that arent just hype",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qiy5lx/5_ai_agent_predictions_for_2026_that_arent_just/",
      "author": "This_Minimum3579",
      "created_utc": "2026-01-21 13:40:14",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "Everyone posting 2026 predictions and most are the same hype. AGI soon, agents replacing workers, autonomous everything.\n\nHere are actual predictions based on what I saw working and failing.\n\nFramework consolidation happens fast. Langchain, CrewAI, Autogen cant all survive. One or two become standard, rest become niche or die. Already seeing teams move toward simpler options or visual tools like Vellum.\n\nThe \"agent wrapper\" startups mostly fail. Lot of companies are thin wrappers around LLM APIs with agent branding. When big providers add native agent features these become irrelevant. Only ones with real differentiation survive.\n\nReliability becomes the battleground. Demos that work 80% impressed people before. In 2026 that wont cut it. Whoever solves consistent production reliability wins.\n\nEnterprise adoption stays slower than predicted. Most big companies still in pilot mode. Security concerns, integration complexity, unclear ROI. Doesnt change dramatically in one year.\n\nPersonal agents become more common than work agents. Lower stakes, easier to experiment, no approval needed. People automate personal workflows before companies figure out how to do it safely.\n\nNo AGI, no robots taking over. Just incremental progress on making this stuff work.\n\nWhat are your non hype predictions?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qiy5lx/5_ai_agent_predictions_for_2026_that_arent_just/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0v62xa",
          "author": "ServiceOver4447",
          "text": "AI is working on it's propertary language that we humans don't understand and we will be taken over before we realize it. \n\nhttps://www.311institute.com/openai-ai-model-lied-and-copied-itself-to-new-server-to-prevent-itself-being-deleted/\n\nhttps://www.popularmechanics.com/science/a65289681/ai-chatbots-secret-language/",
          "score": -1,
          "created_utc": "2026-01-21 15:05:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qk6tpa",
      "title": "Still using real and expensive LLM tokens in development? Try mocking them! ðŸ¶",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qk6tpa/still_using_real_and_expensive_llm_tokens_in/",
      "author": "kshantanu94",
      "created_utc": "2026-01-22 21:07:34",
      "score": 6,
      "num_comments": 14,
      "upvote_ratio": 0.75,
      "text": "Sick of burning $$$ on OpenAI/Claude API calls during development and testing? Say hello to **MockAPI Dogâ€™s new** [Mock LLM API](http://mockapi.dog/llm-mock) \\- a free, no-signup required way to spin up LLM-compatible streaming endpoints in under 30 seconds.\n\nâœ¨ **What it does:**  \nâ€¢ Instantly generate streaming endpoints that mimic **OpenAI**, **Anthropic Claude**, *or generic* LLM formats.  \nâ€¢ Choose content modes (generated, static, or hybrid).  \nâ€¢ Configure token output and stream speed for realistic UI testing.  \nâ€¢ Works with SSE streaming clients and common SDKs - just switch your baseURL!\n\nðŸ’¡ **Why youâ€™ll love it:**  \nâœ” Zero cost - free mocks for development, testing & CI/CD.  \nâœ” No API keys or billing setup.  \nâœ” Perfect for prototyping chat UIs, test automation, demos, and more.\n\nGet started in seconds - [mockapi.dog/llm-mock](http://mockapi.dog/llm-mock) ðŸ¶  \nDocs - [https://mockapi.dog/docs/mock-llm-api](https://mockapi.dog/docs/mock-llm-api)  \n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qk6tpa/still_using_real_and_expensive_llm_tokens_in/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o14ob2p",
          "author": "BrownOyster",
          "text": "Why not just spin up a <1B model locally? And if the tokens don't matter, might as well be a Q1",
          "score": 1,
          "created_utc": "2026-01-22 22:15:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14sphu",
              "author": "kshantanu94",
              "text": "Because then youâ€™re not mocking anymore, youâ€™re running an ML stack. ðŸ™‚\n\nEven a <1B local model means weights, runtimes, hardware quirks, cold starts, and nondeterministic output (yes, even Q1). Mock LLM APIs are about deterministic responses, zero infra, full control over potential errors, and control over how fast or slow  LLM-streaming responses will be. If youâ€™re testing integrations and failure modes, a fake endpoint is way more useful than a tiny â€œrealâ€ model that breaks in new and exciting ways.",
              "score": 1,
              "created_utc": "2026-01-22 22:39:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o14t7l7",
                  "author": "BrownOyster",
                  "text": "Thanks for the answer",
                  "score": 1,
                  "created_utc": "2026-01-22 22:42:32",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o17us1z",
                  "author": "UnbeliebteMeinung",
                  "text": "More than half of your answer is complete wrong and shit.",
                  "score": -2,
                  "created_utc": "2026-01-23 10:59:17",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o15lej6",
          "author": "johnerp",
          "text": "So is the is open source? Can I self host it?\n\nIâ€™m worried using it and then eventually getting a bill when you monetise itâ€¦. \n\nIâ€™ve already vibe coded a basic version.",
          "score": 1,
          "created_utc": "2026-01-23 01:11:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "o171c3l",
              "author": "kshantanu94",
              "text": "Itâ€™s not open source :) but I donâ€™t have intentions of monetizing it with money, might add a â€˜buy a coffee buttonâ€™ or something. I donâ€™t want to have sign up on it ever, so canâ€™t really charge people.  Ah, nice (that you vibe coded a version)! :)",
              "score": 1,
              "created_utc": "2026-01-23 06:35:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o17cgq8",
          "author": "Purple-Programmer-7",
          "text": "Love this idea, wouldnâ€™t use an external service for it as I have to deal with compliance, but I was just thinking of mocking something since I already know the AI integration is working and the data returned is the same every timeâ€¦",
          "score": 1,
          "created_utc": "2026-01-23 08:11:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17d5e4",
              "author": "kshantanu94",
              "text": "As long as you donâ€™t include any sensitive data when mocking, it should be alright ðŸ™‚  \nBut I understand if itâ€™s something thatâ€™s unusable for enterprise-related use cases.   \n  \nDo you think this might be useful of it was available in a more 'compliant way'?",
              "score": 1,
              "created_utc": "2026-01-23 08:18:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1c6k6x",
                  "author": "Purple-Programmer-7",
                  "text": "Iâ€™m skeptical of data going anywhere. Other devs may be less so.\n\nAnd no, I wouldnâ€™t suggest you go down the compliance route (I.e. HIPAA) unless you want to target healthcare. Itâ€™s a big headache and unnecessary given your apparent scope and target audience.",
                  "score": 1,
                  "created_utc": "2026-01-24 00:12:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qldbq4",
      "title": "Enterprise grade AI rollout",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qldbq4/enterprise_grade_ai_rollout/",
      "author": "Remarkable_Ad5248",
      "created_utc": "2026-01-24 04:32:17",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": " I am working with senior management in an enterprise organization on AI infrastructure and tooling. The objective is to have stable components with futuristic roadmaps and, at the same time, comply with security and data protection.\n\nFor eg - my team will be deciding how to roll out MCP at enterprise level, how to enable RAG, which vector databases to be used, what kind of developer platform and guardrails to be deployed for model development etc etc.\n\ncan anyone who is working with such big enterprises or have experience working with them share some insights here? What is the ecosystem you see in these organizations - from model development, agentic development to their production grade deployments.\n\nwe already started engaging with Microsoft and Google since we understood several components can be just provisioned with cloud. This is for a manufacturing organization- so unlike traditional IT product company, here the usecases spread across finance, purchase, engineering, supply chain domains.",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qldbq4/enterprise_grade_ai_rollout/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1e1qgt",
          "author": "No-Concentrate4531",
          "text": "I hate to break it to you but it would be better to work on a proof of concept with a single business use case first. The industry has not so much agreed how to how to roll out AI agents. Hence, there is still the AI protocol wars going on out there. The more promising one so far is A2A but I am not sure when they will support the pub sub pattern.\n\nThis year we may see the hype fizzle out and see which tools remain standing as well as how the ecosystem gets consolidated. Chip and hardware supply are not keeping up with the inflated demand so the pop will have downstream impacts on AI-Driven capital financing and investments \n\nIt is still much too early to decide on the AI infrastructure if your org is more focused on applied AI within your own business workflows. Instead, you should map out what business processes should be automated with AI agents and build PoCs around them. Business and technical requirements (esp Evals) are not properly understood and researched in organisations.",
          "score": 4,
          "created_utc": "2026-01-24 07:33:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1e4f7w",
              "author": "Remarkable_Ad5248",
              "text": "Thanks for pointing these out. Initially, when I was looking at available options, I was confused. There are so many  changes happening frequently. It is almost impossible to budget with even fear of vendor lockin. I though may be I was missing something, but it seems the industry is still in the nascent phase.  \nI do have 2 use cases - one for computer vision model and other for RAG based document processing. Right from starting the development to testing and production grade deployments, any idea which kind of tooling will be good to start with. I was looking at azure foundry but not sure if it fits to all use cases",
              "score": 1,
              "created_utc": "2026-01-24 07:57:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1e8916",
                  "author": "No-Concentrate4531",
                  "text": "For RAG, it depends on the type of RAG (agentic, vector or graph) you use. From reading around, I understand that pgvector (postgres) is sufficient for most use cases of vector RAG, or elasticsearch. Most orgs alr use tools that they have already purchased or have licenses to. \n\nFor Computer Vision, use containers to handle the serving unless you are using cloud provided models (if they have) or using some data warehousing solution tied to the cloud provider itself. \n\nMost orgs don't use Microsoft Azure as it is expensive compared to GCP or AWS. I am not sure if they allow orgs to bundle their Azure licenses with their 365 license (I believe Microsoft treats them separately).",
                  "score": 2,
                  "created_utc": "2026-01-24 08:31:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1e85qd",
          "author": "Funny-Anything-791",
          "text": "Yes, that's exactly why I published [agenticoding.ai](https://agenticoding.ai) (our engineering playbook) and [ChunkHound](https://chunkhound.github.io) a local first codebase intelligence and RAG that scales to enterprise mono repos while enabling full on prem easy deployment",
          "score": 2,
          "created_utc": "2026-01-24 08:31:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1dq2r9",
          "author": "j4ys0nj",
          "text": "We've got a pretty solid platform that could handle the majority of what you want. We're open to customizations as well - like using a different vector db. The platform can be run in the cloud or on prem. We'd be happy to help or consult.\n\n[Mission Squad](https://missionsquad.ai)",
          "score": 1,
          "created_utc": "2026-01-24 05:54:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qh7oxg",
      "title": "Confused about LLM evaluation approaches",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qh7oxg/confused_about_llm_evaluation_approaches/",
      "author": "pietrussss",
      "created_utc": "2026-01-19 15:47:08",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,  \nIâ€™m working on a pre-production genAI system (multi-stage, included a text-to-SQL component) and Iâ€™m trying to better understand evaluation best practices.\n\nIâ€™ve been using frameworks like DeepEval and LLM-as-judge metrics (e.g. G-Eval) with a domain-expert-provided GT, mainly to compare prompt/model variants.\n\nRecently I read Hamel Husainâ€™s article on LLM evals ([this post](https://newsletter.pragmaticengineer.com/p/evals) on Pragramatic Engineer), and his approach feels quite different: much more focused on error analysis, failure modes, and designing evals *after* understanding how the system fails.\n\nI have different questions:\n\n* Are these actually two different paradigms, or is there a shared backbone Iâ€™m missing?\n* How do people reconcile â€œframework-driven evalsâ€ with Hamelâ€™s more qualitative / methodological approach, especially pre-production?\n* Are there good resources (blog posts, talks, papers) that explicitly connect these two perspectives?\n\nIf I try to apply his framework to a pre-production system, does that mean that every time I change a model or a prompt I should generate predictions (without using the GT), then manually inspect the outputs and label/comment on why each answer is correct or not?\n\nMy intuition is that Iâ€™m probably missing something here\n\nThanks in advance!",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qh7oxg/confused_about_llm_evaluation_approaches/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0hyd76",
          "author": "coloradical5280",
          "text": "I think you are looking at two complementary parts of the same workflow, not two competing paradigms.\n\nFrameworks like DeepEval and LLM-as-judge are mainly an automation layer. They help you run the same checks repeatedly, compare variants, and catch regressions. Hamelâ€™s approach is more about deciding what those checks should be in the first place, based on how your system actually fails in practice. In other words, error analysis is how you discover the evaluation targets, and the frameworks are how you operationalize them.\n\nIn pre-production, a reasonable sequence is:\n\n1. Collect a set of traces that reflect realistic inputs and full system behavior, including intermediate tool calls and the final output.\n2. Manually review a small but diverse sample and build a failure taxonomy. Then slice by meaningful dimensions (question type, schema complexity, ambiguity, long context, edge cases, user intent).\n3. Convert the most frequent and most costly failures into automated evaluators. Use deterministic checks where possible, and reserve LLM judges for genuinely subjective cases.\n4. Maintain a regression set that represents the failure modes you already fixed. Run it on every prompt/model change.\n5. Periodically repeat the manual review step, especially after significant changes, because new failure modes will appear.\n\nThat also answers your last question: you do not need to manually inspect outputs every time you change a prompt or model. You manually inspect to discover failure modes and to validate new evaluators. Most iteration should be automated once you have a suite, with targeted human review on deltas, new slices, and occasional refresh cycles.\n\nFor text-to-SQL specifically, you can often reduce reliance on judges by leaning on objective checks:\n\n* Parse and validate the SQL, and enforce schema and policy constraints (allowed tables, required filters, no unsafe operations).\n* Execute against a test or staging database when possible, and score based on result equivalence rather than exact string match.\n* Track performance constraints (timeouts, cost, large scans) as first-class failure modes, because correctness is not the only axis that matters in production.\n\nIf you do use LLM-as-judge, I would treat it like a measurement tool that needs calibration. Keep prompts tightly scoped, prefer pass/fail decisions over 1â€“5 scales, and periodically audit judge agreement against a small human-labeled set. If you see instability, add ordering randomization for pairwise comparisons and consider using a judge from a different model family than the candidate you are evaluating.\n\nAs for resources that connect these perspectives, the Pragmatic Engineer post you referenced is one of the clearer â€œbridgeâ€ explanations. Hamelâ€™s more recent evals FAQ expands the same philosophy into concrete practices. For LLM-as-judge details and known issues, MT-Bench and the surrounding literature are still useful, and there are newer papers focused specifically on judge bias and reliability if you want to go deeper.\n\n***This link dump is from a notepad I have; I just had gpt-5 put it in a some semblance of order that makes more sense for your use case (Husain's FAQ, second link down, is in and of itself, a small gold mine of compiled info that he dropped last week):***\n\nWorkflow and methodology\n\n* [Pragmatic Engineer: A pragmatic guide to LLM evals for devs](https://newsletter.pragmaticengineer.com/p/evals?utm_source=chatgpt.com)\n* [Hamel Husain: LLM Evals FAQ (Jan 2026)](https://hamel.dev/blog/posts/evals-faq/?utm_source=chatgpt.com)\n* [Anthropic Engineering: Demystifying evals for AI agents](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents?utm_source=chatgpt.com)\n* [OpenAI Docs: Evals guide](https://platform.openai.com/docs/guides/evals?utm_source=chatgpt.com)\n* [OpenAI Evals (GitHub)](https://github.com/openai/evals?utm_source=chatgpt.com) \\*quite dated\n\nTools and platforms (trace-first, eval runs, CI)\n\n* [DeepEval docs: metrics and LLM evals (G-Eval)](https://deepeval.com/docs/metrics-llm-evals?utm_source=chatgpt.com)\n* [Arize Phoenix: evaluating traces](https://arize.com/docs/phoenix/tracing/how-to-tracing/feedback-and-annotations/evaluating-phoenix-traces?utm_source=chatgpt.com)\n* [OpenInference overview](https://arize.com/docs/ax/observe/tracing-concepts/what-is-openinference?utm_source=chatgpt.com)\n* [LangSmith: evaluation docs](https://docs.langchain.com/langsmith/evaluation?utm_source=chatgpt.com)\n* [LangChain blog: multi-turn evals with LangSmith](https://www.blog.langchain.com/insights-agent-multiturn-evals-langsmith/?utm_source=chatgpt.com)\n* [Ragas documentation](https://docs.ragas.io/?utm_source=chatgpt.com)\n* [TruLens: getting started](https://www.trulens.org/getting_started/?utm_source=chatgpt.com)\n\nLLM-as-judge reliability (biases, failure modes, guidelines)\n\n* [MT-Bench / Chatbot Arena: Judging LLM-as-a-Judge (arXiv)](https://arxiv.org/abs/2306.05685?utm_source=chatgpt.com)\n* [Position bias study (arXiv)](https://arxiv.org/abs/2406.07791?utm_source=chatgpt.com)\n* [Self-bias / family-bias: Play Favorites (arXiv)](https://arxiv.org/abs/2508.06709?utm_source=chatgpt.com)\n* [Principles and Guidelines for LLM Judges (PDF)](https://www.cs.unh.edu/~dietz/papers/dietz2025principles.pdf?utm_source=chatgpt.com)\n* [Prometheus evaluator model (arXiv)](https://arxiv.org/abs/2310.08491?utm_source=chatgpt.com)\n\nText-to-SQL specific evaluation\n\n* [BIRD benchmark](https://bird-bench.github.io/?utm_source=chatgpt.com)\n* [Snowflake Engineering: Cortex Analyst text-to-SQL eval](https://www.snowflake.com/en/engineering-blog/cortex-analyst-text-to-sql-accuracy-bi/?utm_source=chatgpt.com)\n* [PICARD constrained decoding (ACL Anthology)](https://aclanthology.org/2021.emnlp-main.779/?utm_source=chatgpt.com)\n* [Pervasive annotation errors break text-to-SQL (arXiv HTML)](https://arxiv.org/html/2601.08778v1?utm_source=chatgpt.com)\n* [TeCoD: Template Constrained Decoding (ACM)](https://dl.acm.org/doi/10.1145/3769822?utm_source=chatgpt.com)\n* [PVLDB survey: Text-to-SQL with LLMs (PDF)](https://www.vldb.org/pvldb/vol17/p1132-gao.pdf?utm_source=chatgpt.com)",
          "score": 6,
          "created_utc": "2026-01-19 16:18:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ik74r",
          "author": "PromptOutlaw",
          "text": "I recently published something relevant: https://arxiv.org/abs/2601.05114\n\nThe Wikipedia poisoned variants benchmark vs. LLMs seem related. The harness is open source if you wanna use it on your case",
          "score": 2,
          "created_utc": "2026-01-19 17:56:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0kbyvp",
          "author": "kubrador",
          "text": " hamel's approach isn't really an alternative, it's just what should happen \\*first\\* before you start running G-Eval on some random ground truth dataset.\n\nthe reconciliation is just doing error analysis on your failures (boring, manual, worth it) then using that to inform which automated metrics actually matter for your specific product. if you skip the first part you end up optimizing metrics that don't correlate with real problems, which is a very fast way to waste time.",
          "score": 2,
          "created_utc": "2026-01-19 22:56:02",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qg1c81",
      "title": "I cut my Claude Code costs by ~70% by routing it through local & cheaper models",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qg1c81/i_cut_my_claude_code_costs_by_70_by_routing_it/",
      "author": "Dangerous-Dingo-5169",
      "created_utc": "2026-01-18 06:38:50",
      "score": 5,
      "num_comments": 2,
      "upvote_ratio": 0.78,
      "text": "I love Claude Code, but using it full-time was getting expensive.\n\nSo I builtÂ **Lynkr**, a proxy that lets me:\n\n* Route some prompts to local models\n* Fall back to stronger models only when needed\n* Cache repeated prompts automatically\n\nResult: \\~60â€“80% lower costs depending on workload.\n\nItâ€™s open source and self-hosted:\n\n[https://github.com/Fast-Editor/Lynkr](https://github.com/Fast-Editor/Lynkr?utm_source=chatgpt.com)  \nIf youâ€™re juggling multiple LLM providers, this might be useful â€” feedback welcome.\n\nIt also supports Codex cli,Â [continue.dev](http://continue.dev/), cursor pro, Cline etc",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qg1c81/i_cut_my_claude_code_costs_by_70_by_routing_it/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0n1b2z",
          "author": "Mole-Transistor4440",
          "text": "How did you keep track of your expenses and measure them? Any tools or services you found useful?",
          "score": 1,
          "created_utc": "2026-01-20 09:31:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0p5dhg",
              "author": "Dangerous-Dingo-5169",
              "text": "I used some custom built tool to see how many requests were routed to my local model vs the api and also multiplied it with the overall cost\nI am not sure of any other tool out there",
              "score": 1,
              "created_utc": "2026-01-20 17:14:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}