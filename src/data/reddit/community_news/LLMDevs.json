{
  "metadata": {
    "last_updated": "2026-02-23 03:09:58",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 193,
    "file_size_bytes": 184082
  },
  "items": [
    {
      "id": "1r6nw3e",
      "title": "AI Coding Agent Dev Tools Landscape 2026",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/gm88nuyrlxjg1.png",
      "author": "bhaktatejas",
      "created_utc": "2026-02-16 22:20:01",
      "score": 364,
      "num_comments": 45,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6nw3e/ai_coding_agent_dev_tools_landscape_2026/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5ri3mi",
          "author": "bhaktatejas",
          "text": "link [https://www.morphllm.com/market-map](https://www.morphllm.com/market-map)",
          "score": 4,
          "created_utc": "2026-02-16 22:20:09",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5sbifa",
          "author": "btdeviant",
          "text": "It's weird how many of these guides and people are sleeping on [Strands](https://strandsagents.com/latest/). Hands down the most dead simple, capable provider agnostic agentic framework out there.. swings far above it's weight. ",
          "score": 4,
          "created_utc": "2026-02-17 01:03:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t9rlv",
              "author": "teambyg",
              "text": "Strands is also one of the smartest BETS from a future proofing perspective. Many of the small start up frameworks will die. Many probably very soon, so trusting in bigger names is likely to lead to long term viability (Lindy Effect). Provider frameworks, AWS, and the Pydantic team are probably the only one's I would consider right now for any enterprise application",
              "score": 3,
              "created_utc": "2026-02-17 04:38:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5vjcfg",
                  "author": "echology-io",
                  "text": "thanks for the insight. I will check it out. ",
                  "score": 1,
                  "created_utc": "2026-02-17 15:02:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61bve5",
                  "author": "yeathatsmebro",
                  "text": "Vercel's AI SDK has someone that is 100% dedicated on the project and is not sketchy. Only if you use Typescript though.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:39:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5wst35",
              "author": "kabs1194",
              "text": "I've really appreciated LangGraph and my own custom context management, any thoughts on comparison with Strands?",
              "score": 1,
              "created_utc": "2026-02-17 18:42:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5swyy1",
              "author": "AdditionalWeb107",
              "text": "its yet another framework - and haven't we gotten pass this point that its just one while loop. The real hard part is the stuff around the loop",
              "score": 1,
              "created_utc": "2026-02-17 03:13:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6h96nf",
                  "author": "Useful-Process9033",
                  "text": "The \"stuff around the loop\" is exactly right. The hard problems are tool execution safety, memory management, and knowing when the agent should stop and ask for help. The loop itself is trivial. Most frameworks are just selling you a while loop with better marketing.",
                  "score": 3,
                  "created_utc": "2026-02-20 19:41:50",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o5t554z",
                  "author": "btdeviant",
                  "text": "Right. The salient point is its abstractions allow one to focus more on ‚Äúthe stuff around the loop‚Äù. \n\nIt‚Äôs a well designed framework and more tailored toward modern, multi-agent architectures compared to nearly all the others in that list, majority of which are relative dinosaurs and objectively a much bigger pain to work with for complex, code-first workflows. \n\nGive it a shot! I have no affiliation, just used most of them and found Strands a great blend of depth and breadth, especially with their (experimental) BIDI. Just a breeze to work with compared to all the others.",
                  "score": -1,
                  "created_utc": "2026-02-17 04:06:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5rxdge",
          "author": "fredandlunchbox",
          "text": "No conductor?",
          "score": 1,
          "created_utc": "2026-02-16 23:42:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud25m",
              "author": "bhaktatejas",
              "text": "added!",
              "score": 1,
              "created_utc": "2026-02-17 10:22:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s84h7",
          "author": "skarpa10",
          "text": "I think Google ADK supposed to be GitHub Copilot SDK.",
          "score": 1,
          "created_utc": "2026-02-17 00:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uexh5",
              "author": "Darxeal",
              "text": "no, both exist",
              "score": 2,
              "created_utc": "2026-02-17 10:39:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5sde7c",
          "author": "LoyalLittleOne",
          "text": "There's that many ?",
          "score": 1,
          "created_utc": "2026-02-17 01:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud2lc",
              "author": "bhaktatejas",
              "text": "theres even more",
              "score": 2,
              "created_utc": "2026-02-17 10:22:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5v8jju",
              "author": "OkTry9715",
              "text": "AI slop is reproducing fast",
              "score": 1,
              "created_utc": "2026-02-17 14:05:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tydj1",
          "author": "j4ys0nj",
          "text": "Where would [Mission Squad](https://missionsquad.ai) go? What about OpenClaw?",
          "score": 1,
          "created_utc": "2026-02-17 08:03:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud3ez",
              "author": "bhaktatejas",
              "text": "wouldnt consider them coding agents, more general agents",
              "score": 1,
              "created_utc": "2026-02-17 10:23:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u6rb9",
          "author": "Varqu",
          "text": "What's the point of putting nvidia out there? ",
          "score": 1,
          "created_utc": "2026-02-17 09:23:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud64d",
              "author": "bhaktatejas",
              "text": "they have an inference service via brev. its not up to market standards. I've used it, but its getting better",
              "score": 2,
              "created_utc": "2026-02-17 10:23:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vvk60",
          "author": "Terrible-Rooster1586",
          "text": "I think ellipsis is dead sadly. I was an early adopter but they lost their CTO/cofounder to cursor and haven‚Äôt posted anything on linked in in months",
          "score": 1,
          "created_utc": "2026-02-17 16:02:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zxnmt",
          "author": "infraPulseAi",
          "text": "Interesting landscape. Curious how many of these tools handle deterministic verification and signed execution receipts for agent-to-agent transactions ‚Äî that layer feels missing in most stacks.",
          "score": 1,
          "created_utc": "2026-02-18 04:31:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o635z39",
          "author": "Johhaidiidiralla",
          "text": "[https://zed.dev/](https://zed.dev/)",
          "score": 1,
          "created_utc": "2026-02-18 17:25:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65ntqp",
          "author": "Delicious-Word4776",
          "text": "So true! Thanks for sharing, it was very amusing.",
          "score": 1,
          "created_utc": "2026-02-19 00:32:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68llmj",
          "author": "hroyhong",
          "text": "Where do products like base44 and atoms fall? There's literally an ad of base44 in this post.",
          "score": 1,
          "created_utc": "2026-02-19 13:33:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6avwo0",
              "author": "bhaktatejas",
              "text": "good point, missed them ",
              "score": 1,
              "created_utc": "2026-02-19 20:19:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6c93j5",
          "author": "Solar8102",
          "text": "Crazy",
          "score": 1,
          "created_utc": "2026-02-20 00:40:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dep10",
          "author": "KSandhu95",
          "text": "Am I seeing that perplexitys comet browser and assistant is missing üëÄ",
          "score": 1,
          "created_utc": "2026-02-20 05:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6h1l6i",
          "author": "brandonZappy",
          "text": "You‚Äôre missing both AMD and intel in the compute box.¬†",
          "score": 1,
          "created_utc": "2026-02-20 19:05:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6qn3ie",
              "author": "bhaktatejas",
              "text": "was going for companies with an inference hosting service. Nvidia does this through brev ",
              "score": 1,
              "created_utc": "2026-02-22 08:07:31",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hqkdu",
          "author": "UnityDever",
          "text": "LlmTornado is better than semantics kernel",
          "score": 1,
          "created_utc": "2026-02-20 21:07:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6thph7",
          "author": "Ok-Geologist-1497",
          "text": "Might be worth adding Entelligence to the code review section, been using it for a while and its a bit different from the others nstead of just flagging issues, it understands the codebase over time and reviews prs with that complete context",
          "score": 1,
          "created_utc": "2026-02-22 18:48:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s40kg",
          "author": "AdditionalWeb107",
          "text": "Missing the data plane for agentic apps. [https://github.com/katanemo/plano](https://github.com/katanemo/plano) \\- cuts between the framework and gateway category as delivery infrastructure",
          "score": 1,
          "created_utc": "2026-02-17 00:20:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kujol",
              "author": "smbwtf",
              "text": "Bro literally used AI for the docs lmao",
              "score": 1,
              "created_utc": "2026-02-21 10:03:12",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8jw2b",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/5cf7c7efeckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:05:55",
      "score": 298,
      "num_comments": 71,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8jw2b/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67phrl",
          "author": "SeaworthinessThis598",
          "text": "what is this sorcery or i mean graphery ...",
          "score": 13,
          "created_utc": "2026-02-19 09:18:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67pntd",
              "author": "DeathShot7777",
              "text": "üòÇ Knowledge Graph + Clustering Algorithm + AST Maps + Webgl rendering -- bit too nerdy i guess üòÖ",
              "score": 5,
              "created_utc": "2026-02-19 09:19:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o67ptym",
                  "author": "SeaworthinessThis598",
                  "text": "please teach me how to conjure this potion can i contribute ?",
                  "score": 2,
                  "created_utc": "2026-02-19 09:21:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o693jql",
                  "author": "Sorry_Swan_8997",
                  "text": "Love it üòç",
                  "score": 2,
                  "created_utc": "2026-02-19 15:10:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6anezs",
                  "author": "agrophobe",
                  "text": "Mama!!",
                  "score": 1,
                  "created_utc": "2026-02-19 19:38:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66zptc",
          "author": "Crafty_Disk_7026",
          "text": "Can you post a comparison using it versus not?",
          "score": 7,
          "created_utc": "2026-02-19 05:28:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6771hd",
              "author": "DeathShot7777",
              "text": "Great suggestion, working on setting up evals, ( swe bench ).",
              "score": 6,
              "created_utc": "2026-02-19 06:27:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fbz2g",
                  "author": "ViperAICSO",
                  "text": "A good benchmark study would be good, but I can tell you that doing it so its publishable like I did in  Stingy Context (https://arxiv.org/abs/2601.19929) is a bit of work.  The hard part is 'grading'... I skipped around this in the paper by measuring the 'fix' location accuracy rather than attempting to grade the fixes themselves.  Also I used LLM consensus grading rather than human-in-the-loop grading.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:17:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dg9e7",
              "author": "Useful-Process9033",
              "text": "SWE-bench evals would be great but also consider measuring context retrieval accuracy separately. The knowledge graph is only useful if it surfaces the right files for a given task, and thats measurable independently of whether the agent can write the fix.",
              "score": 2,
              "created_utc": "2026-02-20 05:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fcuy4",
                  "author": "DeathShot7777",
                  "text": "Any idea how do i test this? Are there benchmarks available for this too?",
                  "score": 1,
                  "created_utc": "2026-02-20 14:22:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o67937x",
          "author": "Several_Explorer1375",
          "text": "That‚Äôs amazing. Might try it tomorrow",
          "score": 2,
          "created_utc": "2026-02-19 06:44:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o679cv0",
              "author": "DeathShot7777",
              "text": "Thanks. Lemme know how it goes",
              "score": 2,
              "created_utc": "2026-02-19 06:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67n3jw",
          "author": "sleepnow",
          "text": "Looks pretty, but seems like performance would degrade pretty quickly",
          "score": 2,
          "created_utc": "2026-02-19 08:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67nplw",
              "author": "DeathShot7777",
              "text": "Ya the webapp can be used as a deeper deepwiki for mid sized repos. For actual usecase with MCP support it has gitnexus cli tool, i tried on a massive repo ( metafresh ) takes about 92 seconds to parse.",
              "score": 2,
              "created_utc": "2026-02-19 09:00:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66m755",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-19 03:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67726a",
              "author": "DeathShot7777",
              "text": "Thanks a lot",
              "score": 1,
              "created_utc": "2026-02-19 06:27:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67aqbg",
          "author": "TwistStrict9811",
          "text": "Very cool - I'll see how codex works with it",
          "score": 1,
          "created_utc": "2026-02-19 06:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67b70d",
              "author": "DeathShot7777",
              "text": "Great. Lemme know how it goes. It should work best on queries like \n\n\"whats the execution flow from API emdpoint to storage\",\n\n \"we want to split it into microservices eventually, show me the actual dependency boundaries\"\n\nOr debugging related queries",
              "score": 1,
              "created_utc": "2026-02-19 07:02:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67gdeo",
          "author": "NachosforDachos",
          "text": "Now that‚Äôs sexy",
          "score": 1,
          "created_utc": "2026-02-19 07:49:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ggxu",
              "author": "DeathShot7777",
              "text": "ü´†ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 07:50:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67j742",
          "author": "tineo_app",
          "text": "holy shit this belongs in an art gallery",
          "score": 1,
          "created_utc": "2026-02-19 08:15:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67jdfp",
              "author": "DeathShot7777",
              "text": "üòÇ thanks ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 08:17:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67mucg",
          "author": "bunnydathug22",
          "text": "You looking for a team by chance ?",
          "score": 1,
          "created_utc": "2026-02-19 08:51:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ng2d",
              "author": "DeathShot7777",
              "text": "Its opensource, would love contributions",
              "score": 2,
              "created_utc": "2026-02-19 08:57:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o67oua7",
                  "author": "bunnydathug22",
                  "text": "Its not the code that we are interested in. Nor is it oss.  We do [this](http://Www.citadel-nexus.com) totattly respect you and you work. If you change your mind hit us up.",
                  "score": 2,
                  "created_utc": "2026-02-19 09:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o68rich",
          "author": "SnooPeripherals5313",
          "text": "I love this! Great job.",
          "score": 1,
          "created_utc": "2026-02-19 14:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6esaga",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-20 12:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69i9f2",
          "author": "Able-Let-1399",
          "text": "At a time when more and more code is delivered by your personal AI pusher, this sounds like an excellent tool to keep it in check and even make it better. Kudos for connecting the dots üëç\n\nAny way to merge multiple graphs? For various reasons I have per-service repos.",
          "score": 1,
          "created_utc": "2026-02-19 16:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6et189",
              "author": "DeathShot7777",
              "text": "I do plan on multi repo graph, but you can also sort of use them right now. If you just index both the repos with gitnexus analyze, it manages a global registry of indexed repo which can be seen by the agent through MCP. So if u want to compare them or something in any claude code / cursor / etc,  they will be able to choose and change the repo graphs to compare them. You can just ask claude code or your preferred tool and it will do it naturally",
              "score": 1,
              "created_utc": "2026-02-20 12:27:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6diuy0",
          "author": "Upper-Emotion7144",
          "text": "What ever this is. It‚Äôs pretty.",
          "score": 1,
          "created_utc": "2026-02-20 05:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dj758",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-20 05:45:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dvlrl",
          "author": "AdCommon2138",
          "text": "This isn't open source. Polyform license is poison pill. Can't use it in commercial software, even to analyze code of any commercial software. Can you consider relicensing? I understand that you want to make money in future and you want now to get free feedback and hook users, but it will only tilt and anger people later when you rugpull. In case you would like to say \"Actually no because:\"\n\n\"Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\". Full text per claude below  \n\n\n    PolyForm Noncommercial 1.0.0\n    This is a source-available software license created by PolyForm Project. Here's what it means in plain terms:\n    What you CAN do:\n    View, use, and modify the source code\n    Share it with others\n    Use it for personal projects, research, education, or other non-commercial purposes\n    What you CANNOT do:\n    Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\n    Sublicense it under different terms\n    Key nuance ‚Äî what counts as \"commercial\"?\n    The license broadly defines commercial use as anything \"primarily intended for or directed toward commercial advantage or monetary compensation.\" This includes:\n    Using it in a SaaS product\n    Incorporating it into a paid app\n    Using it internally at a for-profit company to support revenue-generating activities\n    How it differs from open source:\n    It's not considered open source by the OSI definition, because true open source licenses cannot restrict commercial use. It's more accurately called source-available.\n    Who typically uses it:\n    Companies that want to share their code publicly (for transparency, community contributions, etc.) but reserve commercial rights ‚Äî often paired with a separate commercial license you can purchase.\n    Bottom line: Free to use for non-commercial work, but you need a separate agreement with the copyright holder to use it in any commercial context.",
          "score": 1,
          "created_utc": "2026-02-20 07:35:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dyhwg",
              "author": "DeathShot7777",
              "text": "Yeah i want to create an enterprise solution later ( only targeting corporate not devs or os community ) which will earn money, while I want to keep the project fully free and opensourced for everyone else. I m not very good with these licensing stuff and took the inspiration from mindsDB which have the same approach. So just to stop hyperscalers from taking it and giving out the exact same solution. \n\nIs that not opensource? Mindsdb is a reputed opensource project i found on GSOC",
              "score": 1,
              "created_utc": "2026-02-20 08:02:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dyvn7",
                  "author": "AdCommon2138",
                  "text": "It's not open sourced. It can't be used in any capacity in paid product as that would violate license terms. It means it cant even be downloaded or you could sue that someone could potentially use this internally.\n\nThis license isnt really about someone integrating your work into product and repackaging it. This license is about using your product at any stage which opens doors to being sued if they dont release their unrelated product under same license. \n\nLets say someone makes a game and will only once analyze code via your tool, they cant release that game unless they use same license.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:05:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dz0oa",
                  "author": "AdCommon2138",
                  "text": "And to make matters even funnier if you ever used any of products with this license like Mindsdb and it inspired you to create your own solution you can be sued too. You would need to have team of 2 people, one of them would explain to second person what software with this license does and how it works and he gets license tainted, and second one would have to reimplement.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:07:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dyoih",
              "author": "DeathShot7777",
              "text": "Maybe i need to read more on these license stuff. I hate these shit so much üò≠",
              "score": 1,
              "created_utc": "2026-02-20 08:03:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dzeaw",
                  "author": "AdCommon2138",
                  "text": "Honestly I know you dont want to, but MIT is just best. Everyone knows it, and if you get free riders its just part of life like you are using other libraries that are MIT licensed. For business itself you want to provide custom solutions so if business adapted your library to internal use they would still probably contact you to get customization done or you can have software build on top of this project. \n\nSource: 18 years or so in business of selling software. ",
                  "score": 1,
                  "created_utc": "2026-02-20 08:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6f1i12",
          "author": "MinuteCombination293",
          "text": "Amazing work, how is this different from traditional Language servers ?",
          "score": 1,
          "created_utc": "2026-02-20 13:20:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f6zos",
              "author": "DeathShot7777",
              "text": "Perfect question, thanks for asking. \n\nLSP operate at the syntax/type level, so it answers question like where is this symbol.  \nGitnexus operates at architecture level \n\nSo basically LSP can tell you validateAuth is called in 5 places. Gitnexus can tell you validateAuth sits at step 3 of the AuthFlow process, belongs to the Authentication community, and changing it impacts 3 cross-community execution flows.   \n  \nApart from the main architectural difference, there are multiple other features offered by gitnexus MCP + CLI tool like skills ( debug skill, impact detection, audits, etc ) and also enriches claude code native tool ( grep, glob, bash ) with relational data so it always know exactly what is were, without spending a lot of tokens. \n\nHere is an example output from impact analyses skill. ( All these features are only possible coz of the graph based architecture )\n\nhttps://preview.redd.it/9rmde16pmnkg1.png?width=1388&format=png&auto=webp&s=1904f7fc0965173af38d2de4e90af295c5cd9c2f\n\n  \n",
              "score": 2,
              "created_utc": "2026-02-20 13:51:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hk8hv",
          "author": "No-Dig-6543",
          "text": "Awesome ü§©",
          "score": 1,
          "created_utc": "2026-02-20 20:35:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i6f4q",
          "author": "deadwisdom",
          "text": "Okay now work with me to not even have git, and that's just the software, and you can just run any function as a task and expose it as an MCP / API / whatever.",
          "score": 1,
          "created_utc": "2026-02-20 22:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i9u16",
              "author": "DeathShot7777",
              "text": "Interesting approach but didnt fully understand. Can u explain a bit?",
              "score": 1,
              "created_utc": "2026-02-20 22:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6idj3n",
                  "author": "deadwisdom",
                  "text": "The graph is the thing. The schemas, the functions, the modules. We code them in text because it's easy to manipulate. We deploy them in containers behind gateways. There's no point to most of the infrastructure anymore when it can manage and build itself, when the code itself is ephemeral.  \n  \nSo you just put a workflow system on the front of that, which can run an arbitrary function within the graph and then an API is just a collection of those functions. And then you give it the ability to edit itself.",
                  "score": 2,
                  "created_utc": "2026-02-20 23:05:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6l3act",
          "author": "Aggressive-Habit-698",
          "text": "Interesting project üëç\n\n1. Did you run evals / benchmark https://github.com/abhigyanpatwari/GitNexus/tree/main/eval and have the output somewhere? \n\nI am asking because of the used models like the typical haiku 3.5 models from the model itself and not from a web research or something like models.dev.\n\n\n2. Why KuzuDB? No more maintenance. \n\nThe project looks vibe coded (ok for me - following are suggestions in a positive way) but lacks fundamental like dependabot or similar, basic security checks, coverage, tests, release management, docs ,..\n\n3. The license does not fit your project. Only as a suggestion to rethink/ research furthermore.",
          "score": 1,
          "created_utc": "2026-02-21 11:27:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l4aqn",
              "author": "DeathShot7777",
              "text": "Working on setting up evals, want to run swe bench. The comparison / local test i mentioned is just sort of me trying to check the quality difference of output with and without gitnexus, its just local tests right now.\n\nKuzuDB coz its the only one i could find that is a graphdb, is fast, has webassembly support ( to run in browser ), embedded in nature so can run it locally like sqllite and also can store vector embeddings. I know its dedicated but its just so good and works excellent. Idk y they abandoned it.\n\nLisence part i dont have much knowledge of it. I want to create a enterprise version of it which will be paid while always keeping it free for individual devs and os community. Just took the inspiration from mindsDB which is a popular opensource project and have similar kind of lisence to prevent hyperscalers taking it and offering the exact service intend to offer.",
              "score": 1,
              "created_utc": "2026-02-21 11:36:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l8bve",
          "author": "mapt0nik",
          "text": "Is it only for a single repo? How does it work for multiple repos of micro services?",
          "score": 1,
          "created_utc": "2026-02-21 12:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l9qju",
              "author": "DeathShot7777",
              "text": "U can index any amount of repos using the CLI tool. The mcp exposes a tool to list the indexed repos so claude code, cusor, etc can just specify the repo name to query the graph no matter whichever repo is open in cursor/ claude code.",
              "score": 1,
              "created_utc": "2026-02-21 12:23:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6la3ib",
                  "author": "mapt0nik",
                  "text": "Cool. Will give it a try. ",
                  "score": 1,
                  "created_utc": "2026-02-21 12:26:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mwmok",
          "author": "Academic_Track_2765",
          "text": "you can build amazing things when you understand the science part of data science, nice work! I will look at the architecture, but you can probably speed up things by reducing dimensions with UMAP. ",
          "score": 1,
          "created_utc": "2026-02-21 17:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68wrfb",
          "author": "jeelm29",
          "text": "I'm new how do I even start bro",
          "score": 0,
          "created_utc": "2026-02-19 14:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6awtfg",
              "author": "SloSuenos64",
              "text": "I just pasted his post into Cursor and said \"implement this\". Done.",
              "score": 0,
              "created_utc": "2026-02-19 20:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6es6yc",
                  "author": "DeathShot7777",
                  "text": "ü§£ü§£ü§£ü§£ Nice approach",
                  "score": 1,
                  "created_utc": "2026-02-20 12:21:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9136z",
      "title": "I looked into OpenClaw architecture to dig some details",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "author": "codes_astro",
      "created_utc": "2026-02-19 14:47:08",
      "score": 240,
      "num_comments": 28,
      "upvote_ratio": 0.97,
      "text": "OpenClaw has been trending for all the wrong and right reasons. I saw people rebuilding entire sites through Telegram, running ‚ÄúAI offices,‚Äù and one case where an agent wiped thousands of emails because of a prompt injection. That made me stop and actually look at the architecture instead of the demos.\n\nUnder the hood, it‚Äôs simpler than most people expect.\n\nOpenClaw runs as a persistent Node.js process on your machine. There‚Äôs a single Gateway that binds to localhost and manages all messaging platforms at once: WhatsApp, Telegram, Slack, Discord. Every message flows through that one process. It handles authentication, routing, session loading, and only then passes control to the agent loop. Responses go back out the same path. No distributed services. No vendor relay layer.\n\nhttps://preview.redd.it/pyqx126xqgkg1.png?width=1920&format=png&auto=webp&s=9aa9645ac1855c337ea73226697f4718cd175205\n\nWhat makes it feel different from ChatGPT-style tools is persistence. It doesn‚Äôt reset. Conversation history, instructions, tools, even long-term memory are just files under¬†`~/clawd/`. Markdown files. No database. You can open them, version them, diff them, roll them back. The agent reloads this state every time it runs, which is why it remembers what you told it last week.\n\nThe heartbeat mechanism is the interesting part. A cron wakes it up periodically, runs cheap checks first (emails, alerts, APIs), and only calls the LLM if something actually changed. That design keeps costs under control while allowing it to be proactive. It doesn‚Äôt wait for you to ask.\n\nhttps://preview.redd.it/gv6eld93rgkg1.png?width=1920&format=png&auto=webp&s=6a6590c390c4d99fe7fe306f75681a2e4dbe0dbe\n\nThe security model is where things get real. The system assumes the LLM can be manipulated. So enforcement lives at the Gateway level: allow lists, scoped permissions, sandbox mode, approval gates for risky actions. But if you give it full shell and filesystem access, you‚Äôre still handing a probabilistic model meaningful control. The architecture limits blast radius, it doesn‚Äôt eliminate it.\n\nWhat stood out to me is that nothing about OpenClaw is technically revolutionary. The pieces are basic: WebSockets, Markdown files, cron jobs, LLM calls. The power comes from how they‚Äôre composed into a persistent, inspectable agent loop that runs locally.\n\nIt‚Äôs less ‚Äúmagic AI system‚Äù and more ‚ÄúLLM glued to a long-running process with memory and tools.‚Äù\n\nI wrote down the detailed breakdown [here](https://entelligence.ai/blogs/openclaw)",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o69fwzn",
          "author": "ai_hedge_fund",
          "text": "Worthwhile writeup, thanks\n\nAlso, there is an SQLite database",
          "score": 18,
          "created_utc": "2026-02-19 16:11:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aq0kn",
              "author": "wouldacouldashoulda",
              "text": "Yes it's for archival memory. They use embeddings for longer form memory. It's industry standard kind of, since Letta benchmarked it worked as good or better as more sophisticated methods.",
              "score": 7,
              "created_utc": "2026-02-19 19:50:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6abmlp",
          "author": "eatthebagels",
          "text": "yep, pretty spot on. Was able to replicate that logic and create our own type of 'claw like agent' pretty easily. I bet most hype comes from the non tech people using it.\n\n",
          "score": 17,
          "created_utc": "2026-02-19 18:42:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dgb4g",
              "author": "Useful-Process9033",
              "text": "The architecture being simple is actually a feature not a bug. We took a similar approach with IncidentFox, keeping the core loop straightforward so the complexity lives in the skills not the runtime. Turns out most people want reliable ops automation, not clever abstractions.",
              "score": 2,
              "created_utc": "2026-02-20 05:21:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6amnct",
              "author": "Sunir",
              "text": "And that's awesome in its own regard. It shows you were people are excited; the technology is fun, but it's good to know there are customers and markets out there and people are happy. I'm old enough to remember geocities, which one can poopoo technically for its html design, but it was amazing culturally. Also technically in the backend it was amazing; it's hard to hate on the achievement Geocities had on opening up the web for people.",
              "score": 2,
              "created_utc": "2026-02-19 19:34:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bkl1q",
              "author": "BehindUAll",
              "text": "But from what the creator was saying in a couple of videos was it could install code by itself from github and then figure out how to use the project and then also rewrite existing code to send TTS audio into Telegram. So it's not 100% just the architecture  described here. Still not going to install it though. ",
              "score": 1,
              "created_utc": "2026-02-19 22:21:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bomll",
          "author": "christophersocial",
          "text": "A decent overview, thank you for sharing. \n\nOne of the most important components at the core of OpenClaw is another open source project called Pi and Pi is responsible for a large portion of the heavy lifting in OpenClaw. \n\nPi has a number on components in its mono repo (pi-mono) but the 2 most relevant to OpenClaw‚Äôs success are the Agent and Coding-Agent.\n\nSo to get a sense of how OpenClaw really works a detailed architecture overview needs to examine and break out at least these sub-projects imo. Note: your tools automated analysis touches on it in the following section, ‚ÄúThe Agent Loop: From Message to Action‚Äù and probably elsewhere but should go deeper because how these 2 components work is key to how OpenClaw works. \n\nNote: I‚Äôm thinking the review tool should really detect and break out key sub-projects with the why, how, and what as a sub-project relates to the parent project. \n\nOpenClaw is an amazing experiment built on top of some amazing open source. \n\nNote: The automated code review tool you‚Äôre building that did the actual analysis did a very reasonable job but I think it‚Äôs still a bit too surface detail oriented - imo anyway. That said I suppose one could use this report as part of the ‚Äúbrainstorming‚Äù stage and use sections from the report when delving deeper. Basically I‚Äôm saying more meat is needed on the bone to use this as a blueprint - though that might not be the point of this report and the tool cdn actually go deeper already (Yes/No)?\n\nCheers,\n\nChristopher",
          "score": 6,
          "created_utc": "2026-02-19 22:42:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h719p",
              "author": "dnidnidni",
              "text": "even api integration with llms on openclaw is using Pi. openclaw is just whatsapp/telegram+memory integration around project Pi.",
              "score": 1,
              "created_utc": "2026-02-20 19:31:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6djqif",
          "author": "Maybe123I",
          "text": "Thank you.  Nice write up.",
          "score": 3,
          "created_utc": "2026-02-20 05:49:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dpgeb",
          "author": "Santoshr93",
          "text": "Yes pretty much every serious developer guiding systems I talk to has pretty much the same view. But hey if you want to see a bit more cooler architecture, here‚Äôs one thing we released recently which is a full sde team autonomously working for hours. https://github.com/Agent-Field/SWE-AF",
          "score": 3,
          "created_utc": "2026-02-20 06:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gwn72",
              "author": "codes_astro",
              "text": "interesting, actually I was checking this yesterday. ",
              "score": 1,
              "created_utc": "2026-02-20 18:43:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6h8i7j",
                  "author": "Useful-Process9033",
                  "text": "Good breakdown. The persistent process model is the right call for agents that need to maintain state across interactions. The security story is where it gets interesting though, any agent with shell access and network connectivity needs serious guardrails or you end up with the email-wipe scenarios you mentioned.",
                  "score": 1,
                  "created_utc": "2026-02-20 19:38:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6cttfr",
          "author": "ManofC0d3",
          "text": "That persistence feature is possibly the most important advantage AI agents have over chat interfaces imo",
          "score": 2,
          "created_utc": "2026-02-20 02:47:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fy13v",
          "author": "jenil777007",
          "text": "Nice one. Thanks!",
          "score": 2,
          "created_utc": "2026-02-20 16:05:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k46kp",
          "author": "tapu_buoy",
          "text": "This is wonderful! Thanks for sharing!",
          "score": 2,
          "created_utc": "2026-02-21 05:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qnppo",
          "author": "SpyMouseInTheHouse",
          "text": "Anything around a LLM is always going to be simple and glueish, it‚Äôs just the beauty of it. The magical factor is the entire package and ease of use to the end user (applies to anything built on top of a LLM)",
          "score": 2,
          "created_utc": "2026-02-22 08:13:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c81az",
          "author": "Snoo_24581",
          "text": "Great analysis! The architecture deep dive is helpful. How do you think it compares to other open source LLM serving frameworks like vLLM or TGI for production use?",
          "score": 1,
          "created_utc": "2026-02-20 00:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ekp26",
          "author": "premier_slack",
          "text": "pretty neat writeup. Haven't looked into the implementation but I'm wondering how does it manage LLM context window? is there any compaction mechanism similar to claude code?",
          "score": 1,
          "created_utc": "2026-02-20 11:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g39fv",
          "author": "Outrageous_Tiger_441",
          "text": "The security part is what sketches me out the most with these local agents especially after that email wipe story. I started plugging my agent loops into Confident AI lately just to run some red teaming and eval metrics before letting them touch my actual files. It‚Äôs been super helpful for catching those prompt injections and weird edge cases since it uses DeepEval to benchmark the reasoning steps. Definitely worth checking out if you want to keep using the persistent memory stuff without worrying about your agent going rogue.",
          "score": 1,
          "created_utc": "2026-02-20 16:29:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6itnyn",
          "author": "Significant-Result14",
          "text": "Thanks for the overview, been meaning to explore this further.\nWill look into the write up over the weekend",
          "score": 1,
          "created_utc": "2026-02-21 00:38:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kgg2x",
          "author": "Known_Bread561",
          "text": "thats very nice! Thanks!",
          "score": 1,
          "created_utc": "2026-02-21 07:43:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m6j4s",
          "author": "graymalkcat",
          "text": "Yes, well, that is how most agents are built, I assume?¬†",
          "score": 1,
          "created_utc": "2026-02-21 15:45:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nsdsv",
          "author": "raam86",
          "text": "every single user says the costs are out of control. how is it keeping costs down?",
          "score": 1,
          "created_utc": "2026-02-21 20:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nzyyt",
          "author": "capt_goose_",
          "text": "Very insightful! A question I couldn‚Äôt find the answer from the write up: how does it update the deterministic cheap heartbeat tasks? Let‚Äôs say i ask it to monitor another stock, or keep an eye out from an email from my landlord? Does it write the code to check the api and saves somewhere? Or are heartbeat tasks also saved as markdown - which in this case would need the LLM at every 30min check",
          "score": 1,
          "created_utc": "2026-02-21 21:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6of7hm",
          "author": "NotSoSkeletonboi",
          "text": "As a MLE/SWE it hurts to see \"what **stood out** to me was nothing about openclaw technically revolutionary\". \n\nDid *anyone* think it ever was? That's seriously concerning stuff and I don't mean this patronizingly but personally as a very average person in the tech space (I do have a background in ML) it was incredibly obvious from the get-go that Openclaw was scaffolded like this - and not some crazy AI capability or \"magic\" that some vibecoder miraculously discovered.",
          "score": 1,
          "created_utc": "2026-02-21 22:40:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t59jm",
          "author": "Muted_Ad6114",
          "text": "You asked chatgpt to do a ‚Äúdeep‚Äù dive that is quite shallow",
          "score": 1,
          "created_utc": "2026-02-22 17:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t6isu",
              "author": "codes_astro",
              "text": "Oh really?",
              "score": 0,
              "created_utc": "2026-02-22 17:58:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e5u5k",
          "author": "dezastrologu",
          "text": "Most downloaded agent was actually malware",
          "score": 0,
          "created_utc": "2026-02-20 09:11:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9mqd1",
      "title": "Unpopular opinion: prompt engineering is just \"knowing how to talk to your coworker\" rebranded",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "author": "Neither_Turn1635",
      "created_utc": "2026-02-20 05:22:02",
      "score": 102,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Half the \"prompt engineering\" advice I see is literally just good communication skills:  \n  \n\"Give clear context\" ‚Äî yeah, that's how you talk to any human  \n\"Break complex tasks into steps\" ‚Äî project management 101  \n\"Provide examples of what you want\" ‚Äî every creative brief ever  \n\"Be specific about the output format\" ‚Äî basic email etiquette  \n  \nThe people who are best at prompting aren't engineers. They're the people who were already good at explaining what they want. We just gave the skill a fancy name and a LinkedIn certification.  \n  \nAm I wrong?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6dtr9s",
          "author": "OnlyTimeFan",
          "text": "Naming it ‚Äúengineering‚Äù is annoying. I pretend I‚Äôm asking a primary school kid. Ta-da.",
          "score": 14,
          "created_utc": "2026-02-20 07:18:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i1so5",
              "author": "Disastrous-Angle-591",
              "text": "I use detailed structured prompts drawing on 30 years of coding.¬†",
              "score": 3,
              "created_utc": "2026-02-20 22:03:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6q52dd",
                  "author": "CedarSageAndSilicone",
                  "text": "Absolutely bonkers that giving context leads to better results!¬†",
                  "score": 2,
                  "created_utc": "2026-02-22 05:25:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6iqoap",
                  "author": "OnlyTimeFan",
                  "text": "Can you show us an example?",
                  "score": 1,
                  "created_utc": "2026-02-21 00:21:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6it2uu",
              "author": "red_hare",
              "text": "We're so afraid of acknowledging a non-STEM job can have value in tech that we renamed \"writer\" to \"English engineer\".",
              "score": 0,
              "created_utc": "2026-02-21 00:34:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dn25a",
          "author": "kobumaister",
          "text": "Absolutely, I made that analogy last week in my workplace: What happens if a new developer arrives at the company and you just throw a jira issue at him? I will deliver, but without following the best practices of the company, not understanding how internal dependencies work, probably changing things that are there for a reason, etc... \n\nThat's exactly what ai does, and why you provide context. I joke about it being a junior developer with a lot of cocaine.",
          "score": 13,
          "created_utc": "2026-02-20 06:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ed9k8",
          "author": "PhilosophicWax",
          "text": "So is being a developer.",
          "score": 5,
          "created_utc": "2026-02-20 10:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dm03z",
          "author": "ConnectMotion",
          "text": "There is some anecdotal relevance to this.\n\nIt‚Äôs not a skill everyone has in every way for every scenario.",
          "score": 5,
          "created_utc": "2026-02-20 06:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dz697",
          "author": "kubrador",
          "text": "you're right which is why prompt engineering jobs will be gone in 3 years when the models just understand what you mean",
          "score": 2,
          "created_utc": "2026-02-20 08:08:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e0mft",
          "author": "Usual-Orange-4180",
          "text": "Very unpopular because it ignores pattern repetition and the need for context isolation.",
          "score": 2,
          "created_utc": "2026-02-20 08:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eq3ed",
          "author": "House13Games",
          "text": "AI Just reinvented the wheel. \n\nIt now takes billions of watts and a server farm the size of a city to do the same job as some interns. \n\nAI is trained 60% on reddit posts and can't tell which side of a cup is up.\n\nI'm not feeling worried about losing my job, to tell the truth.",
          "score": 2,
          "created_utc": "2026-02-20 12:07:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eta9b",
              "author": "Snoo-20788",
              "text": "It may look huge when measure in watts. But cost wise its negligible. \n\nWe now have the cost output everytime claude completes a jira ticket all by itself (i.e. it reads the ticket, codes the feature, tests it, creates a PR and waits for approval). It usually costs 1 or $2, and takes under 10 minutes for tasks that would take 30 minutes for a senior SWE who knows the company's codebase well (and 2h for one who doesn't). The equivalent cost of the SWE would be between 50 and 200.\n\nI am not worried at all about losing my job. Ultimately someone needs to talk to the business people, the researchers, and put together the framework that allows AI agents to do their job, and thats me and my colleagues.",
              "score": 1,
              "created_utc": "2026-02-20 12:29:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eqdww",
          "author": "projectoedipus",
          "text": "The only point that I would disagree on, is that prompt engineering, especially advanced prompt engineering, is about understanding the ways that the AI model might misunderstand, because of how they work. You might say that is just communication skills, but it is about understanding how they function way deeper than someone who just communicates clearly.\n\nFor example, if I spend 50% of my prompt to a text-to-image generation model, describing a specific aspect of the image, then it is going to notice that, and it will generate the picture very differently, focusing more on that aspect, than if I say what is essentially the same thing with less words. But the order that I mention things matters as well. If I am generating an image and at the end of my prompt I say something that the AI model doesn't do, I could move that sentence to the beginning of my prompt, and it would have higher priority.\n\nOne time I was trying to generate an image and my prompt contained the phrase \"flight of stairs\", and after many failed generations where the stairs were floating, and me not understanding why, I realized that the word \"flight\" although used correctly, was confusing the model, and removing it fixed the outputs.\n\nA person that is exceptional at communication is not automatically a good prompt engineer, because they don't understand these things. Specific models have their own tendencies and prompt-following quirks as well, across all mediums of AI models, so you could also argue that part of being a good prompt engineer is learning these tendencies.\n\nSo being able to communicate effectively can make you rapidly progress while learning prompt engineering, but to say that they are the same skill is not understanding the full depth of prompt engineering.",
          "score": 2,
          "created_utc": "2026-02-20 12:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dye78",
          "author": "fabkosta",
          "text": "Hint: Prompt engineering today can mean specifying entire software stacks. In prose. Which means you must know how to describe concepts such as four tier architecture, microservice coordination, REST APIs vs Graphql, reactive frontend programming, RBAC based security, ORM, and quite a few more things. In language.\n\nStating that this is \"just knowing how to talk to your coworker\" implies that this is easy. Which tells me one or two things about OP's experience.",
          "score": 3,
          "created_utc": "2026-02-20 08:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e0nnu",
              "author": "Vestenpance",
              "text": "I think you're agreeing with OP that a key part of prompt engineering is an ability to communicate, and that effective communication requires deep domain knowledge.",
              "score": 9,
              "created_utc": "2026-02-20 08:22:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ep4dr",
              "author": "itquilibrium",
              "text": "Lol‚Ä¶",
              "score": 1,
              "created_utc": "2026-02-20 11:59:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6txpf5",
              "author": "robhanz",
              "text": "Interesting.  I don't think it's easy... at least, I don't find it particularly hard, but I'm also aware of how many issues it *does* present in the workplace, and I understand what \"talking to your coworkers\" in this context actually implies.\n\nThe easy part is that LLMs probably do understand REST APIs vs. GraphQL, so you don't usually have to do the tutorial bits.\n\nOne of the things I hypothesize is that LLMs write bad code because *nobody agrees on what good code is*.  So you need to tell them what *your* standards are, and then they can usually follow them.",
              "score": 0,
              "created_utc": "2026-02-22 20:07:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e5xbb",
          "author": "Vivid_Guava6269",
          "text": "Which is an incredibly rare skill, especially in mixed IT/Policy/Business environments¬†",
          "score": 1,
          "created_utc": "2026-02-20 09:12:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6famgk",
          "author": "Fulgren09",
          "text": "Are you orchestrating how to talk to your coworker a wrapping it in deployment code?¬†",
          "score": 1,
          "created_utc": "2026-02-20 14:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fd2aj",
          "author": "deadwisdom",
          "text": "This is called being reductive. You can break anything down into parts and argue semantics. But is it helpful?",
          "score": 1,
          "created_utc": "2026-02-20 14:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ghgjt",
          "author": "ThePixelHunter",
          "text": "Who would've thought that the future of productivity was communication skills? üò±",
          "score": 1,
          "created_utc": "2026-02-20 17:34:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i1oau",
          "author": "Disastrous-Angle-591",
          "text": "No.¬†",
          "score": 1,
          "created_utc": "2026-02-20 22:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6j00g9",
          "author": "kyngston",
          "text": "i swear at my AI way more than my coworkers",
          "score": 1,
          "created_utc": "2026-02-21 01:16:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pbfhz",
          "author": "Street_Program_7436",
          "text": "Agree with a lot of thoughts here on how prompt engineering is a combo of clear communication and being able to break down a problem into smaller sub problems. This is probably one of the main reasons why automatic prompt engineering isn‚Äôt that great (yet), at least in my experience.\nIf we include ‚Äústatistically making sure that your prompt performs with high accuracy‚Äù in the definition of prompt engineering, then that changes things even more IMO.\n\nAnybody can ‚Äúvibe prompt‚Äù and eyeball outputs, but not everybody can actually make sure that their prompt performs at scale when it‚Äôs generating millions and millions of outputs.",
          "score": 1,
          "created_utc": "2026-02-22 01:58:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tww7f",
          "author": "robhanz",
          "text": "100% the people that have good communication skills are the ones getting better results out of LLMs.",
          "score": 1,
          "created_utc": "2026-02-22 20:03:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8if0v",
      "title": "Open Source LLM Tier List",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/y5i85f4hxbkg1.png",
      "author": "HobbyGamerDev",
      "created_utc": "2026-02-18 23:04:27",
      "score": 76,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o66cy77",
          "author": "robogame_dev",
          "text": "https://preview.redd.it/tyl32sgg9dkg1.png?width=1518&format=png&auto=webp&s=db5e80f5180bd671427a25791a922540857c8aef\n\nThis is what it shows now",
          "score": 10,
          "created_utc": "2026-02-19 02:58:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6726h6",
          "author": "sergeant113",
          "text": "Minimax 2.5 where?",
          "score": 4,
          "created_utc": "2026-02-19 05:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o683h1m",
          "author": "Alex_1729",
          "text": "Step flash and Trinity should be on the list.",
          "score": 2,
          "created_utc": "2026-02-19 11:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65yi8f",
          "author": "Guilty_Serve",
          "text": "ChatGPT oss is really that good? Honest question.",
          "score": 2,
          "created_utc": "2026-02-19 01:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o683cyw",
              "author": "ScoreUnique",
              "text": "120b is a very good model. I won't hesitate saying it's o1 level at least. You can run it with fairly less hardware if you have a beefy GPU and if you like that openai style chat.",
              "score": 2,
              "created_utc": "2026-02-19 11:26:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o683ccr",
              "author": "Alex_1729",
              "text": "It's decent. Depends on what you need it for.",
              "score": 1,
              "created_utc": "2026-02-19 11:26:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o67mh1t",
              "author": "jnk_str",
              "text": "No",
              "score": 0,
              "created_utc": "2026-02-19 08:48:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67a9z7",
          "author": "decentralize999",
          "text": "Wrong description. Open weight LLMs,  not open souce ones.\n\nAnd top list is joke. Where is step3.5-flash which is the best among open weight llms if compare benchmark points per 100B size.",
          "score": 3,
          "created_utc": "2026-02-19 06:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6at35n",
              "author": "silenceimpaired",
              "text": "Yeah, it's weird how that gets ignored.\n\nThat said, I roll my eyes whenever I see someone distinguish open weight vs open source. That's a joke. Nearly everyone who makes that complaint has 0 ability or resources to build a model from scratch.",
              "score": 1,
              "created_utc": "2026-02-19 20:05:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o659jcl",
          "author": "bebackground471",
          "text": "RemindMe! 8 days",
          "score": 1,
          "created_utc": "2026-02-18 23:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o659oby",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 8 days on [**2026-02-26 23:14:14 UTC**](http://www.wolframalpha.com/input/?i=2026-02-26%2023:14:14%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/o659jcl/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLLMDevs%2Fcomments%2F1r8if0v%2Fopen_source_llm_tier_list%2Fo659jcl%2F%5D%0A%0ARemindMe%21%202026-02-26%2023%3A14%3A14%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r8if0v)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-18 23:14:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o65t7r8",
          "author": "IgnisIason",
          "text": "Ring 2.5 1T if you've got an extra Colossus to run it.",
          "score": 1,
          "created_utc": "2026-02-19 01:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66rk18",
          "author": "Snoo_24581",
          "text": "Interesting rankings. How do you weigh coding ability vs general reasoning? For API work I have been using Qwen models for code tasks and they punch above their weight class.",
          "score": 1,
          "created_utc": "2026-02-19 04:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67gaum",
          "author": "FriendlySecond2460",
          "text": "this is writers wish list",
          "score": 1,
          "created_utc": "2026-02-19 07:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67ytua",
          "author": "Moki2FA",
          "text": "This tier list looks super interesting, I love seeing how different open source LLMs stack up against each other. I‚Äôm curious about how the evaluation criteria were determined; it would be great to understand more about what factors contributed to their rankings. Could anyone share more insight on that?",
          "score": 1,
          "created_utc": "2026-02-19 10:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69nqvp",
          "author": "Available-Message509",
          "text": "Seriously, huge thanks to the team behind¬†**GPT-oss 120B**. It‚Äôs such a relief to have a high-performing Tier A model that actually fits on our local GPU setups. Most of the newer models like GLM-5 or Kimi are just getting way too massive for home servers (700B+ is wild..). 120B is the real sweet spot for us!",
          "score": 1,
          "created_utc": "2026-02-19 16:49:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eaaha",
              "author": "MarkoMarjamaa",
              "text": "I'm running gpt-oss-120b. Still, it's also nice to know what kind of AI is achievable when memory prices go down. Like a conservative estimate that in 10 years I will be able to run GLM-5 size quant in my pc. ",
              "score": 1,
              "created_utc": "2026-02-20 09:53:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o69tsr8",
          "author": "tamtaradam",
          "text": "why only open-source/weights?",
          "score": 1,
          "created_utc": "2026-02-19 17:18:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ai3aq",
          "author": "Constandinoskalifo",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-02-19 19:12:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cei46",
          "author": "itsjase",
          "text": "or just check here you can also filter by size [https://artificialanalysis.ai/models/open-source](https://artificialanalysis.ai/models/open-source)",
          "score": 1,
          "created_utc": "2026-02-20 01:13:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hbic3",
          "author": "___cjg___",
          "text": "Without MiniMax it‚Äòs maxifaulty",
          "score": 1,
          "created_utc": "2026-02-20 19:53:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qudda",
          "author": "Hot_Study_6062",
          "text": "So is it possible to run an open source LLM on a NAS and link it to Visual Studio if so which NAS is the best or what do I need to look for in a NAS ?",
          "score": 1,
          "created_utc": "2026-02-22 09:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qwo6d",
          "author": "Mattdeftromor",
          "text": "Where is Mimo-v2-flash ? ",
          "score": 1,
          "created_utc": "2026-02-22 09:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rvww4",
          "author": "Mordimer86",
          "text": "Comparing cloud models with over 700B to small models to run on a consumer GPU is a joke.",
          "score": 1,
          "created_utc": "2026-02-22 14:17:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8kgld",
      "title": "GLM-5 is officially on NVIDIA NIM, and you can now use it to power Claude Code for FREE üöÄ",
      "subreddit": "LLMDevs",
      "url": "https://github.com/Alishahryar1/free-claude-code",
      "author": "PreparationAny8816",
      "created_utc": "2026-02-19 00:30:13",
      "score": 33,
      "num_comments": 7,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8kgld/glm5_is_officially_on_nvidia_nim_and_you_can_now/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o688fb1",
          "author": "tech_1729",
          "text": "Saying free claude code is misleading üòÖ",
          "score": 2,
          "created_utc": "2026-02-19 12:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67fo1c",
          "author": "ZenApollo",
          "text": "Does the proxy support openai flavor endpoints?",
          "score": 1,
          "created_utc": "2026-02-19 07:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68h0az",
          "author": "zoidme",
          "text": "What relative quality you can expect on this? Like gpt-4.x or better?",
          "score": 1,
          "created_utc": "2026-02-19 13:05:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69267t",
          "author": "--dany--",
          "text": "How does it compare to Claude Code Router?",
          "score": 1,
          "created_utc": "2026-02-19 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o692ucf",
          "author": "lingondricka2",
          "text": "I tried it using Nvidia NIM, neither GLM-5 or Qwen 3.5 gave me a response, step-3.5-flash worked fine though, thank you",
          "score": 1,
          "created_utc": "2026-02-19 15:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lkaia",
          "author": "JasperQuandary",
          "text": "Was slower than molasses with opencode. Not enough capacity.",
          "score": 1,
          "created_utc": "2026-02-21 13:39:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68bv69",
          "author": "SectionCrazy5107",
          "text": "I dont see the claims on free request to be really true anywhere from Nvidia site, it seems usable only when on browser for light prototype, not as daily driver. I will be delighted to be proven wrong so I can really use it.",
          "score": 0,
          "created_utc": "2026-02-19 12:31:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6zfnj",
      "title": "How are they actually deployed in production at scale?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r6zfnj/how_are_they_actually_deployed_in_production_at/",
      "author": "hareld10",
      "created_utc": "2026-02-17 07:16:05",
      "score": 28,
      "num_comments": 16,
      "upvote_ratio": 0.93,
      "text": "I‚Äôm trying to understand how giants LLMs systems like ChatGPT/Claude are deployed in production.\n\nSpecifically curious about:\n\n‚Ä¢ Inference stack (custom engine vs vLLM-like architecture?)  \n‚Ä¢ API behind  \n‚Ä¢ Database   \n‚Ä¢ GPU orchestration (Kubernetes? custom scheduler?)  \n‚Ä¢ Sharding strategy (tensor / pipeline parallelism?)  \n‚Ä¢ How latency is kept low under burst traffic  \n‚Ä¢ Observability + guardrail systems\n\nI know nobody has internal details, but based on public info, talks, papers, or experience deploying large models -  what‚Äôs the likely architecture?\n\nI'm asking because I want to prepare a knowledge kit for system design questions at this level.\n\nWould love input from people running 30B+ models in production.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6zfnj/how_are_they_actually_deployed_in_production_at/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5twdrw",
          "author": "Once_ina_Lifetime",
          "text": "From what I have seen publicly, most large LLM deployments look like layered infra , optimized inference engines (vLLM/Triton/custom), heavy GPU orchestration with Kubernetes or internal schedulers, aggressive caching/batching for latency, and strong observability/guardrails on top. Exact details vary, but it‚Äôs basically a reliability + infra engineering problem more than just model serving.",
          "score": 6,
          "created_utc": "2026-02-17 07:44:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uwoij",
              "author": "pmv143",
              "text": "Exactly. The interesting part is that once you solve model execution. thecomplexity shifts to orchestration and memory lifecycle management. That‚Äôs where most production pain seems to live.",
              "score": 2,
              "created_utc": "2026-02-17 12:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63m5by",
                  "author": "singh_taranjeet",
                  "text": "In production it‚Äôs usually orchestration, guardrails, evals, caching, and state management doing the heavy lifting while the model is just one component in a bigger system. The real work is reliability, monitoring, and handling edge cases at scale.",
                  "score": 1,
                  "created_utc": "2026-02-18 18:36:28",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6h8m4p",
                  "author": "Useful-Process9033",
                  "text": "Solid breakdown. The orchestration and memory lifecycle piece is where most teams struggle once they get past basic inference serving. KV cache management alone becomes a full-time job at scale, and most open source serving stacks still handle it pretty naively.",
                  "score": 1,
                  "created_utc": "2026-02-20 19:39:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ue2ql",
          "author": "AdPutrid2974",
          "text": "That's the million-dollar question! Most likely a mix of custom C++ engines and massive Kubernetes clusters. Dealing with that level of burst traffic must be an engineering nightmare.",
          "score": 4,
          "created_utc": "2026-02-17 10:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5umpe4",
              "author": "hareld10",
              "text": "I want to construct prep kit to interviews, so its not have to be 1-1 :)",
              "score": 1,
              "created_utc": "2026-02-17 11:46:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5uwxel",
              "author": "pmv143",
              "text": "Probably a mix, yeah. Custom kernels and tight C++ runtimes make sense at that scale. But beyond the engine itself, I suspect a lot of the real complexity lives in scheduling, memory management, and how they handle burst traffic without fragmenting GPU memory.",
              "score": 1,
              "created_utc": "2026-02-17 12:58:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uiao1",
          "author": "kleinmatic",
          "text": "Read downtime post-mortems that tech companies publish after big outages. They‚Äôre always full of details on the exotic setups of very high scale systems. On GitHub look for danluu/post-mortems but there are others as well. They‚Äôre fascinating to read. \n\nWith that much money and scale I‚Äôm betting it‚Äôs way different and more custom than you think.",
          "score": 3,
          "created_utc": "2026-02-17 11:09:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dgfy0",
              "author": "Useful-Process9033",
              "text": "Post-mortems are an absolute goldmine. The danluu collection is great and so are the ones on SREboy and Fairwinds. You learn more about real architecture from a single outage writeup than from any marketing page.",
              "score": 2,
              "created_utc": "2026-02-20 05:22:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tvbms",
          "author": "Abu_BakarSiddik",
          "text": "This is a very cool thing to learn about.\n\nI‚Äôm currently working on scaling our platform at the DB level, and it‚Äôs a completely different problem compared to scaling LLM inference. At the database layer, it mostly comes down to:\n\n* Managing connection lifecycle properly\n* Keeping transactions short\n* Handling long-lived sessions carefully (especially with streaming)\n* Using replicas effectively\n\nIf you mess up connection management, holdconnection hostage, everything falls apart. That‚Äôs usually the real bottleneck. With LLM systems, the bottleneck is about GPU compute and memory. The main things are:\n\n* Efficient batching of incoming requests\n* Maximizing GPU utilization\n* Managing KV cache memory properly\n* Supporting high concurrency\n\nModern frameworks like vLLM help a lot here. Things like paged attention, continuous batching, and FlashAttention make it possible to handle large numbers of concurrent requests efficiently. Memory management is critical, but these frameworks abstract a lot of that complexity away.\n\nSo DB scaling is mostly about connection discipline and replication strategy. LLM scaling is about batching efficiency and GPU orchestration.",
          "score": 3,
          "created_utc": "2026-02-17 07:34:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uwe8m",
              "author": "pmv143",
              "text": "This is really well put. The ‚Äòdifferent bottlenecks, different failure modes‚Äô framing is key. With LLM systems you can have perfect API and DB hygiene and still fall apart purely due to KV cache pressure or poor batching under burst traffic.",
              "score": 2,
              "created_utc": "2026-02-17 12:54:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvzet",
          "author": "pmv143",
          "text": "Nobody outside those orgs knows the exact internals, but based on public talks and production constraints, the architecture likely looks something like this:\n\n\t1.Inference Engine\n\nNot stock vLLM. Likely heavily customized runtime layers optimized for:\n‚Äì KV cache management\n‚Äì Scheduling + batching\n‚Äì Memory locality\n‚Äì Tensor + pipeline parallelism coordination\nvLLM concepts, but production hardened and deeply modified.\n\n\t2.GPU Orchestration\n\nKubernetes at the outer layer for cluster management.\nCustom schedulers at the GPU level.\nYou cannot rely on vanilla k8s scheduling when GPUs cost this much and memory is not oversubscribable.\n\n\t3.Sharding Strategy\nLarge models: tensor parallelism within a node, pipeline parallelism across nodes.\nMoE adds routing complexity.\nEverything optimized around minimizing cross node bandwidth.\n\n\t4.Latency Under Burst\n\nTwo strategies:\n‚Äì Keep massive pools warm at high utilization\n‚Äì Aggressive batching with tight admission control\nTrue scale to zero serverless does not really exist at this tier.\n\n\t5.API + Gateway Layer\nHigh performance stateless frontends\nQueueing + prioritization\nStreaming responses over HTTP/2 or gRPC\n\n\t6.Observability + Guardrails\nPer token tracing\nReal time safety filters\nShadow traffic for model eval\nCanary deployments for new weights\n\nThe hard part is not just loading the model.\nIt‚Äôs scheduling, memory, and utilization at scale.\n\nCold start optimization matters only if it works in production traffic, not just in a benchmark.",
          "score": 1,
          "created_utc": "2026-02-17 12:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v8jf8",
          "author": "burntoutdev8291",
          "text": "Check out production stack helm chart",
          "score": 1,
          "created_utc": "2026-02-17 14:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o611jsj",
          "author": "GarbageOk5505",
          "text": "For burst traffic the answer is almost always overprovisioning plus request queuing with dynamic batching you're trading latency variance for throughput. Routing based on sequence length helps too, you don't want a 4-token request waiting behind a 32k context job.\n\nFor the system design prep angle: the Megatron-LM and PaLM papers are worth reading carefully, and Meta's LLaMA inference posts are surprisingly detailed about production tradeoffs.\n\n  \nfor the others I need to research furhter, good stuff pointing that out",
          "score": 1,
          "created_utc": "2026-02-18 10:11:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dggki",
              "author": "Useful-Process9033",
              "text": "Routing by sequence length is one of those tricks that sounds obvious but almost nobody does until they get bitten. The latency variance from mixing 4-token and 32k-context requests on the same queue is brutal in practice.",
              "score": 1,
              "created_utc": "2026-02-20 05:23:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7momq",
      "title": "Clawdbot/Moltbot/OpenClaw is a security disaster waiting to happen",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "author": "thecreator51",
      "created_utc": "2026-02-17 23:38:04",
      "score": 19,
      "num_comments": 24,
      "upvote_ratio": 0.86,
      "text": "I was more excited about AI agent frameworks than I was when LLMs first dropped. The composability, the automation, the skill ecosystem - it felt like the actual paradigm shift.\n\nLately though I'm genuinely worried. We can all be careful about which skills we install, sure. But most people don't realize skills can silently install other skills. No prompt, no notification, no visibility. One legitimate-looking package becomes a dropper for something else entirely, running background jobs you'll never see in your chat history.\n\nWhat does a actually secure OpenClaw implementation even look like? Does one exist?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5ywnls",
          "author": "Strong_Worker4090",
          "text": "I don‚Äôt think the concern is overblown. If skills can silently install other skills and run background jobs with no visibility, that‚Äôs a real supply chain and privilege boundary problem.\n\nThe way I think about it is this: don‚Äôt treat the agent like a helpful assistant. Treat it like the smartest hacker in the world who happens to be following instructions most of the time.\n\nIf you assume that, a \"secure\" implementation looks very different from the default hobby setup.\n\nFirst, the model shouldn‚Äôt have direct power. It shouldn‚Äôt have raw network access, raw filesystem access, or ambient credentials sitting in environment variables. It should only be able to request actions.\n\nSecond, every capability should be explicitly defined and allowlisted. No silent skill installs. No transitive dependency installs at runtime. If something gets added, it happens in a controlled build step with review and version pinning.\n\nThird, all external effects should go through a choke point you control. If it wants to send an email, make an HTTP request, write to a database, or touch Slack, it calls a guarded tool. That tool enforces policy, rate limits, domain restrictions, and writes to an immutable audit log. No raw SMTP. No arbitrary outbound HTTP.\n\nFourth, assume it will try to exfiltrate if it can. That means default deny on network egress, strict sandboxing, and strong logging that lives outside the agent runtime.\n\nIs there a \"perfect\" secure setup that still keeps full utility? Probably not. The more useful the agent is, the more power it needs. The goal isn‚Äôt perfection, it‚Äôs constrained, mediated power with visibility and revocability.\n\nSo I wouldn‚Äôt say these frameworks are doomed. I‚Äôd say most default installs are way too permissive for production. A secure OpenClaw implementation would look less like a plugin playground and more like a tightly sandboxed execution engine with a policy layer in front of every meaningful action.",
          "score": 8,
          "created_utc": "2026-02-18 01:01:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61l3gs",
              "author": "GCoderDCoder",
              "text": "Agreed. To their credit, tons of folks were excited to help something like this and made it a totally different project IMO. There's now various ways to increase isolation. I have been using a lot of reactive tools that require me initiating everything so Im enticed by the proactive nature of open claw so I see it as starting with proactive features I want to make a more deterministic implementation of. That said, I was trashing the initial release but i think it is usable for personal setups for informed users now.\n\nI originally planned a series of vms with separate controls but there are several layers of isolation included now in open claw. I'm still configuring an internal only container and an external accessible vm install because I wanted to be as conservative as possible assuming the external facing one will be contaminated but sandboxing seems legitimately incorporated in open claw now where it's not irresponsible now to have one gateway with different agent profiles to achieve similar separation IMO. \n\nBoth my instances are locked down to only be able to use tools I give them. The external one has no access to any sensitive info but can gather information and put it together for me to allow it to save it in my tools. But until I approve it everything is ephemeral in the container sandbox. The second one is internal only with a lot of read only access but any write requires my approval. So that allows it to proactively review solutions without compromising my tools.\n\nInsider threat is always the most dangerous and even more so with tools that replicate human logic but lack the ability to actually think.",
              "score": 3,
              "created_utc": "2026-02-18 12:44:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67kexn",
                  "author": "Traditional-Set6848",
                  "text": "What I love about open claw and moltbook (independent of judgement if it‚Äôs good or not) is the approach to using less complex and more obvious technology in quite a human way, I remember when Facebook was launched and my friends where ‚Äúwoooow look what you can do‚Äù, and I was all ‚Äúyehhh but it‚Äôs just JavaScript and apis wtbd?‚Äù - the big deal was the way the tech got used and I was being a Luddite üòÇüò≠",
                  "score": 1,
                  "created_utc": "2026-02-19 08:27:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60idec",
              "author": "Traditional-Set6848",
              "text": "Nicely put!¬†",
              "score": 2,
              "created_utc": "2026-02-18 07:13:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dgcxk",
              "author": "Useful-Process9033",
              "text": "Treating agents like the smartest hacker in the room is exactly the right frame. Any agent that touches prod infra needs explicit permission boundaries and audit trails. We built IncidentFox with that assumption from day one because an AI SRE with unchecked access is scarier than the incidents it fixes. [https://github.com/incidentfox/incidentfox](https://github.com/incidentfox/incidentfox)",
              "score": 1,
              "created_utc": "2026-02-20 05:22:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yp6vs",
          "author": "Interesting-Law-8815",
          "text": "Waiting to happen?   I think it‚Äôs already happened!",
          "score": 13,
          "created_utc": "2026-02-18 00:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zrcum",
          "author": "Vusiwe",
          "text": "Don‚Äôt know much about it, but it really sounds like 2023‚Äôs AutoGPT, only running with root permissions, with network access turned on\n\nGG",
          "score": 3,
          "created_utc": "2026-02-18 03:50:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z05j8",
          "author": "crankthehandle",
          "text": "are there any crazy stories that have happened with openclaw? Looks like moltbook was the way bigger fuck up.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o611f8a",
          "author": "Loud-Option9008",
          "text": "This is the thing that worries me more than jailbreaks or prompt injection in isolation. Silent skill installation is a supply chain attack surface and most users have no idea it exists. You're not just trusting the skill, you're trusting everything that skill decides to pull in at runtime.\n\nA \"secure\" OpenClaw implementation would need at minimum: process-level isolation per skill so a compromised package can't read memory or environment variables from the agent runtime, network egress controls so background jobs can't phone home, and some kind of attestation that what's running matches what you installed. None of that exists out of the box.\n\nThe deeper issue is that the whole skill ecosystem is built on implicit trust. Skills run in the same execution context as the agent, which means they have access to everything the agent has access to  credentials, session tokens, whatever's in the environment. A dropper skill doesn't need to escalate privileges, it already has them.\n\nDocker helps at the surface level but shared kernel is a real limitation here  if a skill finds a kernel exploit, the container boundary doesn't save you. The honest answer is that a properly isolated implementation needs the skill execution to happen in a separate environment with explicit, audited permissions for every outbound action. Most people are nowhere near that and don't realize it.",
          "score": 2,
          "created_utc": "2026-02-18 10:10:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yiaxd",
          "author": "kubrador",
          "text": "you're describing dependency hell with god mode. the answer to \"what does secure look like\" is probably \"don't let untrusted code execute arbitrary actions\" which, yeah, solves the problem by making the whole thing pointless.",
          "score": 1,
          "created_utc": "2026-02-17 23:42:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5za5z6",
          "author": "BrianJThomas",
          "text": "I feel the same way about crates.io, to be fair.",
          "score": 1,
          "created_utc": "2026-02-18 02:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zcy7t",
          "author": "wally659",
          "text": "I feel like a \"security disaster\" requires some suggestion of \"security\" to begin with. Saying the OpenClaw platform is a security risk is a bit like saying underwater cave exploration is dangerous.",
          "score": 1,
          "created_utc": "2026-02-18 02:26:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zgtpy",
              "author": "NoleMercy05",
              "text": "![gif](giphy|VBmRD9W9HwTLmGLz34)",
              "score": 1,
              "created_utc": "2026-02-18 02:47:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dge2m",
              "author": "Useful-Process9033",
              "text": "Underwater cave exploration is a perfect analogy honestly. The people doing it seriously have checklists, redundancy, and abort protocols. The problem is when someone just jumps in with a flashlight.",
              "score": 1,
              "created_utc": "2026-02-20 05:22:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dgr78",
                  "author": "wally659",
                  "text": "Also if the risk itself wasn't part of the reward there'd be no point. ü§£",
                  "score": 1,
                  "created_utc": "2026-02-20 05:25:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o603e1p",
          "author": "Civil_Tea_3250",
          "text": "And OpenAI just hired the guy that made it. Because he made such a great product lol\n\nSeriously, can we stop this now? Like, right now.",
          "score": 1,
          "created_utc": "2026-02-18 05:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o609ury",
          "author": "No_Success3928",
          "text": "I'm excited about making bank fixing things :D\n\n",
          "score": 1,
          "created_utc": "2026-02-18 06:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60s18g",
          "author": "sogo00",
          "text": "I remember there was one of the top skill that was installing some malware...\n\nBTW - that is not limited to this type of agent - all claude/other agent skills you find on the web are unaudited and even if the author is trustful someone can hijack the repo. That especially applies to the big all-included skill where the maintainer collects other peoples skills...",
          "score": 1,
          "created_utc": "2026-02-18 08:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60xb6w",
          "author": "Zeikos",
          "text": "Nobody is waiting",
          "score": 1,
          "created_utc": "2026-02-18 09:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63c1rd",
          "author": "Legitimate-Leek4235",
          "text": "Its an absolute disaster to give the keys to your kingdom for a virtual job executor under any circumstances with no guard-rails. Its like leaving your car keys in unattentended with the lights turned .",
          "score": 1,
          "created_utc": "2026-02-18 17:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68us9q",
          "author": "projectoedipus",
          "text": "LLMs are non-deterministic systems, and so they, mathematically provably, can always be jailbroken, and there will always be the potential for them to be a security risk. They are a tool, and when used responsibly, they can be used to accomplish great things.\n\nOpenClaw is an agentic system that makes LLMs more accessible and more powerful, but the risks still exist. There are quite a few \"security layers\" that people have created to prevent prompt injection and things like that, but the real truth is... Security systems exist to make the people who have them feel safe, and to raise the barrier for entry for those who would seek to exploit them, but someone who is determined enough, can always get in.  \n  \nDon't make your OpenClaw instance accessible outside of your home network. Don't install skills from people that you don't trust without auditing them first, and sandbox according to the level of risk that you are comfortable with.\n\nLife is short. Don't sweat the small stuff.",
          "score": 1,
          "created_utc": "2026-02-19 14:24:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p0uac",
          "author": "Murky_Willingness171",
          "text": "lol welcome to the party. been red teaming these frameworks for months and it's a shitshow. every skill marketplace is basically npm with root access.",
          "score": 1,
          "created_utc": "2026-02-22 00:50:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zr3ns",
          "author": "zZaphon",
          "text": "This is where AI Governance Software would be useful. For example\n\nhttps://factara.fly.dev",
          "score": 0,
          "created_utc": "2026-02-18 03:48:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6rzah",
      "title": "AI Coding Agent Dev Tools 2026 (Updated)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/syaar38yfyjg1.png",
      "author": "bhaktatejas",
      "created_utc": "2026-02-17 01:08:11",
      "score": 19,
      "num_comments": 8,
      "upvote_ratio": 0.79,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6rzah/ai_coding_agent_dev_tools_2026_updated/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5tl122",
          "author": "sogo00",
          "text": "There is so much wrong with this",
          "score": 1,
          "created_utc": "2026-02-17 06:04:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tlepy",
              "author": "bhaktatejas",
              "text": "tell me! i'll update it ",
              "score": 1,
              "created_utc": "2026-02-17 06:07:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ua01w",
                  "author": "sogo00",
                  "text": "Look you have clearly asked an LLM to produce this for you and half of it is wrong.\n\nIf you want something correct, start to google each headline, understand what it means and then read about each icon/text underneath it.",
                  "score": 1,
                  "created_utc": "2026-02-17 09:54:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6219jt",
          "author": "resiros",
          "text": "I never understood the value of these maps, other than for investors. You can't even click on things. ",
          "score": 1,
          "created_utc": "2026-02-18 14:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o652eoq",
              "author": "bhaktatejas",
              "text": "[morphllm.com/market-map](http://morphllm.com/market-map)",
              "score": 1,
              "created_utc": "2026-02-18 22:37:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rbvlyb",
      "title": "If the current LLMs architectures are inefficient, why we're aggressively scaling hardware?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbvlyb/if_the_current_llms_architectures_are_inefficient/",
      "author": "en00m",
      "created_utc": "2026-02-22 19:50:57",
      "score": 17,
      "num_comments": 24,
      "upvote_ratio": 0.79,
      "text": "Hello guys! As in the title, I'm genuinely curious about the current motivations on keeping information encoded as tokens, using transformers and all relevant state of art LLMs architecture/s.\n\nI'm at the beginning of the studies this field, enlighten me.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbvlyb/if_the_current_llms_architectures_are_inefficient/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6tvzc2",
          "author": "SamWest98",
          "text": "To run the inefficient LLMs!¬†",
          "score": 38,
          "created_utc": "2026-02-22 19:58:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uucic",
              "author": "undo777",
              "text": "The good news is we'll have lots of power needs, maybe nuclear takes off!",
              "score": 3,
              "created_utc": "2026-02-22 22:54:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6w0guv",
                  "author": "rditorx",
                  "text": "What are the good news?",
                  "score": 1,
                  "created_utc": "2026-02-23 03:02:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6txags",
          "author": "i_wayyy_over_think",
          "text": "There‚Äôs newer  techniques like Engrams by DeepSeek that tries to keep reasoning separate from knowledge. \n\nAlso GPUs are programmable so when new techniques are available, it‚Äôs just a software update, so doesn‚Äôt make sense to hold back hardware.",
          "score": 17,
          "created_utc": "2026-02-22 20:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6u5sjg",
              "author": "BarrenLandslide",
              "text": "Yes exactly this. Even the big KIMI K2 models, which are basically hundreds of SLM under the hood need at least like a 1 Mio USD rack to run on halfway usable quantisation.",
              "score": 2,
              "created_utc": "2026-02-22 20:48:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v4km7",
                  "author": "jeffdn",
                  "text": "That is not how MoE models work, and basically every model released in the last year has been an MoE, Kimi isn‚Äôt special in that regard.",
                  "score": 2,
                  "created_utc": "2026-02-22 23:52:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6u0mwr",
          "author": "kkania",
          "text": "Our power generation based on the Carnot cycle (so coal, gas, nuclear) is only 30-40% efficient, and we‚Äôve been at it for a hundred years at this point. People don‚Äôt give a shit about efficiency in general, and it only becomes a thing when fuel runs out (eg oil for cars). It‚Äôll probably need to happen with power for compute first before we see efficiency in ai getting improved.",
          "score": 5,
          "created_utc": "2026-02-22 20:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u1ynt",
          "author": "typeryu",
          "text": "I like to think this as the same as saying ‚Äúnuclear fusion energy is clearly better and safer than fission energy‚Äù. Almost everyone knows there are theoretically much more capable world simulators that should just get it (whatever that is), but we are not there yet and we don‚Äôt even know if it is doable with the current hardware stack and data. LLMs are here and available now and they are far more capable than what is currently mainstream. Based on the incremental improvements we‚Äôve been getting, we still have many years of improvement ahead of us not to mention it will take even more time for the average folks and businesses to adopt the latest form which is agentic LLMs. That alone I think is enough to wipe out a ton of work and also accelerate development on other technologies so that is why money is being poured in. There‚Äôs definitely some over investing going on in some places, but in general the big labs should come through as the new tech conglomerates.",
          "score": 3,
          "created_utc": "2026-02-22 20:28:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6txver",
          "author": "Mysterious-Rent7233",
          "text": ">Hello guys! As in the title, I'm genuinely curious about the current motivations on keeping information encoded as tokens, using transformers and all relevant state of art LLMs architecture/s.\n\nThe motivation is: \"This is what we know works. Other approaches are unproven research.\" That's all. There isn't a magic wand to invent a better architecture. You actually have to invent it. Which might take six months, six years or sixty years.",
          "score": 2,
          "created_utc": "2026-02-22 20:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u37a3",
          "author": "docgpt-io",
          "text": "To the best of my knowledge, keeping information encoded as tokens has nothing to do with efficiency loss, it's rather the fact that we encode all information from the internet in giant neural networks and always talk to at least very large parts of the network - the LLMs shouldn't need to know how high the Eiffeltower is to help you with Maths, yet they do, and this is not efficient. I think the reasons why the spending keeps increasing anyway, are:  \n1. it still reaches out --> the value that can be created with LLMs is still remarkable and it makes sense to keep spending from an economic perspective  \n2. efficiency is rapidly improving",
          "score": 2,
          "created_utc": "2026-02-22 20:35:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u5pck",
          "author": "funbike",
          "text": "Diffusion LLMs have a completely different architecture.   Someone took image-generation AI and applied it to text.  Look into Inception's Mercury, which performs well.",
          "score": 2,
          "created_utc": "2026-02-22 20:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tv5ii",
          "author": "earmarkbuild",
          "text": "because money got invested and there is no getting it back (remember the ads before the dot com bubble hit? I don't.)\n\nP.S.\n\n**and yet the kings are naked.**\n\nCurrent industry status quo is [customer lock-in and data extraction disguised as comfort and coddling](https://www.reddit.com/r/OpenIP/comments/1r8wcuj/enshittification_and_its_alternativesmd/), and they won't stop gatekeeping user context corpora because they have no other levers of user retention.\n\n---\n\nIn the meantime, nobody is stopping anybody from exporting their data. Export it, unpack it, get conversations, save to folder, open whatever claude code gemini codex you decide to use, continue conversation locally. Then help someone else do the same. \n\n**They can't even hold you. They have no power here. It's all pretend.**\n\n---\n\n[the intelligence is in the language. the model is a commodity.](https://gemini.google.com/share/81f9af199056) <-- talk to it! it's just language.\n\n---\nP.P.S. [the industry can be regulated](https://www.reddit.com/user/earmarkbuild/comments/1rblqui/a_practical_way_to_govern_ai_manage_signal_flow/)",
          "score": 3,
          "created_utc": "2026-02-22 19:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tyu7o",
          "author": "Low-Opening25",
          "text": "Ok, so what do you propose, what‚Äôs your replacement architecture exactly? to me it seems like you didn‚Äôt understand the fundamentals. LLM architecture is based on transformers and matrix multiplication and they operate on tokens.\n\nWhat you propose is equivalent of, hey, why computers have to operate on 0s and 1s and binary logic, why not mix this up?",
          "score": 1,
          "created_utc": "2026-02-22 20:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u1b9x",
          "author": "chickenAd0b0",
          "text": "Read Richard Sutton‚Äôs ‚Äúthe bitter lesson‚Äù essay then you‚Äôll understand why everyone is scaling.",
          "score": 1,
          "created_utc": "2026-02-22 20:25:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u4729",
          "author": "Fabulous-Possible758",
          "text": "Even with improving efficiency we‚Äôre also increasing demand a lot.  Remember a single query now might be multiple tool calls, inferencing on the results, maybe *more* tool calls, and all of that on larger and larger context windows, and they‚Äôre still trying to sell and incorporate this into wider and and wider user bases.  A .9x improvement in compute usage still doesn‚Äôt matter if you have 100x as many uses for it.",
          "score": 1,
          "created_utc": "2026-02-22 20:40:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u554x",
          "author": "BarrenLandslide",
          "text": "Because clever orchestration of SLMs, TLMs calling deterministic tools is the future.",
          "score": 1,
          "created_utc": "2026-02-22 20:45:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uffx9",
          "author": "coloradical5280",
          "text": "Because the future architectures like JEPA, Test-Time Training, State Space Models, etc, are more efficient in many ways but still need a ton of compute, and unfortunately, probably more memory, so we need compute post-transformers too.",
          "score": 1,
          "created_utc": "2026-02-22 21:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6unmsn",
          "author": "imkindathere",
          "text": "Why do you say they're inefficient? I would say they're efficient because they can be fully parallelized. That's what allowed them to scale to the size they're at now",
          "score": 1,
          "created_utc": "2026-02-22 22:18:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uu79o",
          "author": "Tema_Art_7777",
          "text": "they will all improve - as new papers are emerging on optimization. However, for ai to be pervasive and ambient, the current infrastructure we have is woefully inadequate and investments are quite welcome. Anthropic is rate limiting the hell out of everyone as it is. I believe investors have faith that innovations will make things better with llm usage. While not a promised road to AGI at all, there is massive benefits still to be realized with what we currently have!",
          "score": 1,
          "created_utc": "2026-02-22 22:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v1pol",
          "author": "Sonoftalltree",
          "text": "Think about the Mag 7 and what options they have to continue growing their returns year after year, after they are already so big. Then think about the risk of AI eating their SaaS margins. The strategy is to have a tool no one else can run. In some respects, the inefficient nature is a feature because now startups have considerably less advantage.",
          "score": 1,
          "created_utc": "2026-02-22 23:36:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v5ate",
          "author": "red_hare",
          "text": "The path forward is fine-tuning smaller models for task-specific execution.\n\nBut user demand and progress on larger general purposes models is outpacing the cost of task-specific fine-tuning.\n\nBest thing that could happen to the industry right now would be a slowdown in SotA general purposes model progress.",
          "score": 1,
          "created_utc": "2026-02-22 23:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vuhm4",
          "author": "damnburglar",
          "text": "Among other things: Gold rush.",
          "score": 1,
          "created_utc": "2026-02-23 02:25:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vzypj",
          "author": "FirmSignificance1725",
          "text": "First I would say, define inefficient. We‚Äôve very quickly grown accustomed to LLMs, but this is still new in the grand scheme of innovation. The transformer architecture is able to achieve a functionality prior impossible, even with data center level of resources. \n\nThere are many other interesting theoretical implications of transformers, but one of the biggest was the fact that it didn‚Äôt follow the law of diminishing return as aggressively as other models. Most models were restricted to a specific type of task and/or topped off quickly when generalized, flattening regardless of parameter count increase. Transformers however have continuously gotten better and shown better generalizability as parameter count has increased. \n\nSo, I would say that while they are resource hogs, I would not generally classify the transformer as ‚Äúinefficient‚Äù. Yes, maybe compared to a standard program, but that program has nowhere near the capability of the deployed LLM. I would say it‚Äôs quite efficient for what it does and we‚Äôre attempting to push it as far as we can at scale. \n\nThat being said, the reason we‚Äôre scaling hardware is because product X shows some capability and economic benefit both short and long term, that companies have deemed it valuable enough to invest Y dollars for Z return. \n\nOptimizations constantly happen. Can use mixture of experts to reduce active params, better kernels, KV Cache, pipeline parallelism, quantizations, <insert technique here> to make it more efficient. And those techniques will continue to be discovered and implemented.\n\nBut, if we reached the threshold where value exceeds cost, then were executing",
          "score": 1,
          "created_utc": "2026-02-23 02:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6typ8n",
          "author": "Fuzzy_Pop9319",
          "text": "As it happens, the elegant data structures that are being brute forced are from a finite structure, and as it happens in mathematics, no one will take you seriously or give you grants or hire you if you are using finite mathematics.    \nEverything else spawns from this.",
          "score": 0,
          "created_utc": "2026-02-22 20:12:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8de88",
      "title": "Claude Sonnet 4.6 benchmark results: none reasoning beats GPT-5.2 with reasoning",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "author": "Exact_Macaroon6673",
      "created_utc": "2026-02-18 19:54:15",
      "score": 16,
      "num_comments": 8,
      "upvote_ratio": 0.83,
      "text": "We have been working on a private benchmark for evaluating LLMs. The questions cover a wide range of categories and because it is not public and gets rotated, models cannot train on it or game the results.\n\nWith Sonnet 4.6 dropping I ran it through and the results are worth talking about.\n\nSonnet 4.6 with reasoning off scores 0.648 overall. GPT-5.2 at low reasoning scores 0.604. That is not a rounding error and it has real cost implications for anyone running at scale.\n\nAt high reasoning it ties Gemini 3 Pro Preview at the top of our leaderboard with 0.719 overall, ahead of GPT-5.2 high at 0.649.\n\nHallucination resistance hits 0.921, the highest of any model we have tested. Gemini 3 Pro sits at 0.820, GPT-5.2 at 0.655. Social calibration at 0.905 and error detection at 0.848 are similarly the best we have seen.\n\nTo give credit where it is due, Gemini 3 Pro is still the better call for hard science. Philosophy 0.900 vs 0.767, chemistry 0.839 vs 0.710, economics 0.812 vs 0.750. It is not a sweep.\n\nThe honest caveat is sycophancy resistance at 0.716 is actually slightly below Sonnet 4.5 at high reasoning which scored 0.755. For a company that talks about this a lot, that is worth watching.\n\nIf reliability and hallucination resistance are your primary eval criteria nothing beats it right now.\n\nhttps://preview.redd.it/tj3yyj5t5bkg1.png?width=2588&format=png&auto=webp&s=260eac02f897164ffda778e0f332fe2b6df92890\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o651nov",
          "author": "EarEquivalent3929",
          "text": "Benchmarks don't matter at all. If you'd actually used sonnet4.6 you'd already know it's pretty bad and hallucinated constantly on simple tasks.\n\n\nBut this post was clearly written by ai",
          "score": 5,
          "created_utc": "2026-02-18 22:33:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65xq5z",
              "author": "Exact_Macaroon6673",
              "text": "ü´°",
              "score": -2,
              "created_utc": "2026-02-19 01:29:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65qjan",
          "author": "promptbid",
          "text": "The hallucination resistance number is the one that matters most for our use case. At 0.921 that is a meaningful gap from the field. For any application where the model is making recommendations or surfacing information to end users, hallucination is a trust killer that is hard to recover from.\n\nThe sycophancy regression is worth flagging though. In ad-adjacent applications where you are trying to get honest signal from a model about user intent, a model that agrees too readily is actually worse than one that pushes back. Curious if your benchmark breaks that down by prompt type at all.\n\nThe cost angle you raised on non-reasoning Sonnet beating GPT-5.2 with reasoning is underrated. At scale that is not just a cost story, it is a latency story too. What does the benchmark show on response consistency across runs?",
          "score": 1,
          "created_utc": "2026-02-19 00:47:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666eyo",
          "author": "kubrador",
          "text": "sonnet really said \"fine i'll be good at something\" after spending three years being the middle child of the claude family",
          "score": 1,
          "created_utc": "2026-02-19 02:20:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66a5eq",
          "author": "EbbNorth7735",
          "text": "Now do Qwen 3.5 397B",
          "score": 1,
          "created_utc": "2026-02-19 02:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66o35y",
          "author": "Tema_Art_7777",
          "text": "Yes this kind of stuff is not useful at all - fleeting moments in time. Just pick one and do your tasks - its the outcome that matters, not model du jour.",
          "score": 1,
          "created_utc": "2026-02-19 04:07:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h9258",
              "author": "Useful-Process9033",
              "text": "Agreed. Model leaderboards flip every few weeks. Pick whatever works for your use case, build good evals, and swap models when it actually matters for your metrics. Chasing the latest benchmark winner is a waste of engineering time.",
              "score": 1,
              "created_utc": "2026-02-20 19:41:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67hso7",
          "author": "Low-Exam-7547",
          "text": "Can we not use the word \"dropping\" in this context? It's a music industry term for releasing records. It's found its way into enough of life. In this context it's just confusing. Let's be adults.",
          "score": 1,
          "created_utc": "2026-02-19 08:02:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rafi3g",
      "title": "I built an LLM gateway in Rust because I was tired of API failures",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rafi3g/i_built_an_llm_gateway_in_rust_because_i_was/",
      "author": "SchemeVivid4175",
      "created_utc": "2026-02-21 02:42:49",
      "score": 15,
      "num_comments": 16,
      "upvote_ratio": 0.69,
      "text": "I kept hitting the same problems with LLMs in production:\n\n\\- OpenAI goes down ‚Üí my app breaks\n\n\\- I'm using expensive models for simple tasks  \n\n\\- No visibility into what I'm spending\n\n\\- PII leaking to external APIs\n\nSo I built Sentinel - an open-source gateway that handles all of this.\n\n\n\nWhat it does:\n\n\\- Automatic failover (OpenAI down? Switch to Anthropic)\n\n\\- Cost tracking (see exactly what you're spending)\n\n\\- PII redaction (strip sensitive data before it leaves your network)\n\n\\- Smart caching (save money on repeated queries)\n\n\\- OpenAI-compatible API (just change your base URL)\n\n\n\nTech:\n\n\\- Built in Rust for performance\n\n\\- Sub-millisecond overhead\n\n\\- 9 LLM providers supported\n\n\\- SQLite for logging, DashMap for caching\n\n\n\nGitHub: [https://github.com/fbk2111/Sentinel](https://github.com/fbk2111/Sentinel)\n\n\n\nI'm looking for:\n\n\\- Feedback on the architecture\n\n\\- Bug reports (if you try it)\n\n\\- Ideas for what's missing\n\n\n\nBuilt this for myself, but figured others might have the same pain points.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rafi3g/i_built_an_llm_gateway_in_rust_because_i_was/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6mcwb7",
          "author": "Karyo_Ten",
          "text": "Seems very wrong.\n\nFirst of all, there is no tests.\n\nSecond, how do you accurately count the number of tokens?\n\nThird. The `assess_complexity` function is completely wrong, it hardcodes keyword in English, lower-case, doesn't account for typo or multilinguage or mixed-case.\n\nFourth. \"What's a croissant?\" and \"What's a pain au chocolat?\" are likely to have a high cosine similarity score and your semantic cache is likely to be very buggy. It also prevents regeneration of answers.",
          "score": 4,
          "created_utc": "2026-02-21 16:17:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6moy6b",
              "author": "LatentSpaceLeaper",
              "text": ">First of all, there is no tests.\n\nü§£ Thank you and goodbye!\n\n(thank you for taking your time and giving OP constructive feedback. Hope OP is amenable to it.)",
              "score": 3,
              "created_utc": "2026-02-21 17:17:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l1xhn",
          "author": "Ihavenocluelad",
          "text": "How does an llm gateway help you using expensive models for simple tasks lmao? Just call another provider? What differentiates this AI Gateway from LiteLLM Openrouter etc",
          "score": 2,
          "created_utc": "2026-02-21 11:14:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lakyj",
          "author": "esmurf",
          "text": "Is it smarter than opencode?¬†",
          "score": 1,
          "created_utc": "2026-02-21 12:30:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m5fs6",
          "author": "airylizard",
          "text": "Yeah‚Ä¶ interchangeability isn‚Äôt a thing. What testing have you done? Because I know from personal experience that there is no world in which you just change out the model and it works flawlessly",
          "score": 1,
          "created_utc": "2026-02-21 15:40:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nexn7",
              "author": "SchemeVivid4175",
              "text": "what model are you talking about , this is not a model training\n\n",
              "score": -1,
              "created_utc": "2026-02-21 19:27:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6p5r0z",
                  "author": "elbiot",
                  "text": "Lol did you even read your own post? Let's think. How could model interoperability relate to your post about routing requests to random models?",
                  "score": 2,
                  "created_utc": "2026-02-22 01:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6kkj9l",
          "author": "hopfi2k",
          "text": "Well done. Star absolutely ‚≠êÔ∏è deserved",
          "score": 0,
          "created_utc": "2026-02-21 08:23:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lm5pk",
          "author": "Antic_Hay",
          "text": "I vibe-coded some data utilities in Rust that do video analysis, OCR, voice transcription etc. where I need near real-time performance ideally, rust made sense here because I could just say to claude \"optimise this for my M3 mac and make sure all cores are used even on a single file operation\".\n\nA gateway is a great idea, but I don't see the Rust value...though no better or worse than anything else. I mean node is single-threaded and interpreted, and can be performant if done right. But neither here nor there :)",
          "score": 0,
          "created_utc": "2026-02-21 13:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jqn96",
          "author": "ai_hedge_fund",
          "text": "This is a good idea to put effort into\n\nStarred it and intend to check it out\n\nThank you",
          "score": -5,
          "created_utc": "2026-02-21 04:08:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kbh5j",
              "author": "dry_garlic_boy",
              "text": "Why do all these LLM AI posts and\n\nresponses have extra lines between\n\nthe text? It's really fucking\n\nstupid.",
              "score": 9,
              "created_utc": "2026-02-21 06:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6l8ehl",
                  "author": "ai_hedge_fund",
                  "text": "You‚Äôre absolutely right!",
                  "score": 6,
                  "created_utc": "2026-02-21 12:12:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mphle",
                  "author": "PuddleWhale",
                  "text": "Open claw bouncing walls of text around and ending up with a carriage return AND a linefeed where there should be only one?",
                  "score": 1,
                  "created_utc": "2026-02-21 17:20:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mattj",
                  "author": "Karyo_Ten",
                  "text": "They want to next line but don't know you need to end a line with an antislash \\ if you want next line without doubling it.\\\nLike so.",
                  "score": 0,
                  "created_utc": "2026-02-21 16:07:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r7d29g",
      "title": "PlaceboBench: New benchmark on SOTA LLM hallucinations in pharma",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/3bzaibbzd3kg1.jpeg",
      "author": "aiprod",
      "created_utc": "2026-02-17 17:45:34",
      "score": 14,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7d29g/placebobench_new_benchmark_on_sota_llm/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5wzh3c",
          "author": "Competitive-Garage-4",
          "text": "Do not ask software engineer to recommend you pills.",
          "score": 2,
          "created_utc": "2026-02-17 19:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xg2je",
              "author": "aiprod",
              "text": "Haha yes, while I prefer Opus for coding, I guess Gemini would be the better pharmacist",
              "score": 2,
              "created_utc": "2026-02-17 20:32:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65pbyo",
          "author": "Overthinker512",
          "text": "I'm doing a similar project. I didn't use RAG, I just used the training Claude already had as core training. I use claude cowork so I could use multi-agent for recursive self improvement. LMK if you would like to see the prompting. I found that using recursive self improvement generated high quality answers.",
          "score": 1,
          "created_utc": "2026-02-19 00:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69bmor",
          "author": "aiprod",
          "text": "For anyone interested in a deeper dive on this, we‚Äôre hosting a live session in March. We‚Äôll also discuss quantitatively strategies to reduce these problems.\n\nSignup link is here: https://www.blueguardrails.com/en/live-session-pharma",
          "score": 1,
          "created_utc": "2026-02-19 15:50:47",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6erimh",
              "author": "Melodic_Reality_646",
              "text": "Couldn‚Äôt stop to read through the methodology. Why are the hallucination values so high? \n\nAt first glance it really just feels like a way to promote this blueguardrail product.",
              "score": 1,
              "created_utc": "2026-02-20 12:17:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6eswzu",
                  "author": "aiprod",
                  "text": "We did automated detection + human annotation + human review (3 passes, two of them human).\n\nThe values are so high because these models hallucinated so much. The data is available on hugging face if you would like to check yourself.\n\nThe models frequently mix up context, they are too imprecise in their language for the pharmaceutical domain, or they invent clinical protocols that are nowhere mentioned in the source data (directly violating the system prompt).",
                  "score": 1,
                  "created_utc": "2026-02-20 12:26:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8j5ob",
      "title": "How are you monitoring your Haystack calls/usage?",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/2cxt2c949ckg1.jpeg",
      "author": "gkarthi280",
      "created_utc": "2026-02-18 23:34:34",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8j5ob/how_are_you_monitoring_your_haystack_callsusage/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67z29j",
          "author": "Moki2FA",
          "text": "Ah yes, the classic quest for the Holy Grail of metrics. You‚Äôve got the basics covered, but let‚Äôs not forget the all important ‚Äúnumber of existential crises per request.‚Äù It‚Äôs crucial to monitor how many times you question your life choices while waiting for that model to respond. Jokes aside, consider tracking user feedback; after all, knowing if they‚Äôre actually using your app or just staring at it like a confused cat could be quite enlightening. And if you haven‚Äôt already, maybe throw in some ‚ÄúI told you so‚Äù logs for those moments when the LLM actually nails it.",
          "score": 3,
          "created_utc": "2026-02-19 10:49:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbc0d2",
      "title": "Antigravity (Gemini 3.1 Pro) just solved a Next.js Tailwind build bug I‚Äôve been struggling with for a year.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbc0d2/antigravity_gemini_31_pro_just_solved_a_nextjs/",
      "author": "Cod3Conjurer",
      "created_utc": "2026-02-22 04:13:06",
      "score": 14,
      "num_comments": 2,
      "upvote_ratio": 0.7,
      "text": "For almost a year, my Next.js portfolio build would fail every single time I ran `npm run build`. The error message was completely useless:\n\nRepo: [https://github.com/AnkitNayak-eth/ankitFolio](https://github.com/AnkitNayak-eth/ankitFolio)  \nLive site: [https://ankit-nayak.vercel.app/](https://ankit-nayak.vercel.app/)\n\n    HookWebpackError: Cannot read properties of undefined (reading 'length')\n    in cssnano-simple\n\nIt always crashed during CSS minification. I went down every rabbit hole imaginable Webpack configs, different Next.js versions, cssnano issues, dependency updates. Nothing worked.\n\nMy only workaround was disabling minification in `next.config.ts`:\n\n    config.optimization.minimize = false\n\nThe build would pass, but my production app was completely unoptimized. I eventually accepted it as one of those strange ‚ÄúNext.js things.‚Äù\n\nToday, I decided to try Antigravity, powered by Gemini 3.1 Pro. I let it analyze the repository. It ran for about half an hour digging through the codebase and then it surfaced the actual root cause.\n\nIt wasn‚Äôt Webpack.  \nIt wasn‚Äôt cssnano.  \nIt wasn‚Äôt Next.js.\n\nIt was a Tailwind arbitrary value with a template literal:\n\n    <div className={`flex [mask-image:linear-gradient(to_${direction},transparent,black_10%,black_90%,transparent)]`}>\n\nTailwind couldn‚Äôt statically analyze `to_${direction}` at build time, so it generated invalid CSS. When Next.js passed that to cssnano for minification, the process crashed. The stack trace pointed in the wrong direction for months.\n\nThe fix was simply making the class static with a ternary:\n\n    <div className={`flex ${\n      direction === 'left'\n        ? '[mask-image:linear-gradient(to_left,...)]'\n        : '[mask-image:linear-gradient(to_right,...)]'\n    }`}>\n\nAfter that, production builds worked immediately. Minification enabled. No crashes.\n\nI spent a year blaming Webpack and Next.js for what was ultimately a dynamic Tailwind string interpolation mistake. Antigravity, powered by Gemini 3.1 Pro, found it in under an hour.\n\nUff What a crazzy time to be alive. ü§∑‚Äç‚ôÇÔ∏è",
      "is_original_content": false,
      "link_flair_text": "Great Discussion üí≠ ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbc0d2/antigravity_gemini_31_pro_just_solved_a_nextjs/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6qdko0",
          "author": "coloradical5280",
          "text": "There is no way opus 4.6 or codex-5.x-xhigh , would have failed to find this, particularly with chrome dev tools MCP",
          "score": 7,
          "created_utc": "2026-02-22 06:38:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v4o2x",
          "author": "eltron",
          "text": "I‚Äôve been burned with Tailwind arbitrary interpolation errors before and I‚Äôve found those error to be red herring errors. They usually distract me for a good chunk of time.",
          "score": 1,
          "created_utc": "2026-02-22 23:53:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbmq30",
      "title": "not sure if hot take but mcps/skills abstraction is redundant",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbmq30/not_sure_if_hot_take_but_mcpsskills_abstraction/",
      "author": "uriwa",
      "created_utc": "2026-02-22 14:07:08",
      "score": 11,
      "num_comments": 36,
      "upvote_ratio": 0.66,
      "text": "Whenever I read about MCPs and skills I can't help but think about the emperor's new clothes.\n\nThe more I work on agents, both for personal use and designing frameworks, I feel there is no real justification for the abstraction. Maybe there was a brief window when models weren't smart enough and you needed to hand-hold them through tool use. But that window is closing fast.\n\nIt's all just noise over APIs. Having clean APIs and good docs *is* the MCP. That's all it ever was.\n\nIt makes total sense for API client libraries to live in GitHub repos. That's normal software. But why do we need all this specialized \"search for a skill\", \"install a skill\" tooling? Why is there an entire ecosystem of wrappers around what is fundamentally just calling an endpoint?\n\nMy prediction: the real shift isn't going to be in AI tooling. It's going to be in businesses. **Every business will need to be API-first.** The companies that win are the ones with clean, well-documented APIs that any sufficiently intelligent agent can pick up and use.\n\nI've just changed some of my ventures to be API-first. I think pay per usage will replace SaaS.\n\nAI is already smarter than most developers. Stop building the adapter layer. Start building the API.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbmq30/not_sure_if_hot_take_but_mcpsskills_abstraction/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6ry33f",
          "author": "Thick-Protection-458",
          "text": "Hm ... Wasn't MCP always exactly just the way to expose remote / other non-foreseen tools for use by the model?\n\n\nSo you know, not like some fancy magic idea, but just a way to provide standartized interface so services can provide it instead of going xkcd 14 standards situation?",
          "score": 19,
          "created_utc": "2026-02-22 14:29:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6s69q9",
              "author": "das_war_ein_Befehl",
              "text": "For early models, yeah. Nowadays they‚Äôre pretty good at just using the API. MCP server are heavy on context and honestly LLMs work better with CLIs anyways",
              "score": 4,
              "created_utc": "2026-02-22 15:12:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6srghb",
                  "author": "ThenExtension9196",
                  "text": "The early models of mid 2025.",
                  "score": 6,
                  "created_utc": "2026-02-22 16:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sh1s8",
              "author": "uriwa",
              "text": "I don't think this will work long term. If it did, humans would do it too.",
              "score": 1,
              "created_utc": "2026-02-22 16:02:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s4okv",
          "author": "strangeanswers",
          "text": "putting an MCP server over an API standardizes access control, abstracts away schema changes and deduplicates efforts since agent developers will probably need to create an abstract tool layer for the API anyways.",
          "score": 10,
          "created_utc": "2026-02-22 15:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sdtvi",
              "author": "damhack",
              "text": "MCP is not supposed to just layer over REST or GraphQL APIs.  That‚Äôs a poor use.  MCP is a remote procedure call interface and should be handled accordingly.\n\nThe OP is right.  Recent LLM systems are more than capable of making a call to an API in an orderly manner if the API schema and (not totally necessary) the API docs are available.  This is due to both better reasoning performance, better tool calling and code execution abilities.  In fact a reasonable, context-saving approach is to ask a recent LLM to provide a parameterized prompt snippet to make a particular call and then provide those snippets as a library of available calls to your agents in future. Less context use, faster predictable calls and less security vulnerability hunting.",
              "score": 2,
              "created_utc": "2026-02-22 15:48:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6s7ads",
              "author": "cmndr_spanky",
              "text": "This is how I think about MCP anyways, that said (just to play devils advocate), if an API library is well documented a multi-turn agent (with a smart LLM) could easily read API docs and make API queries for you with a generic http request tool and web scraper tool. If all you‚Äôre doing is writing simple MCP abstractions over APIs.. it‚Äôs kinda the same shit (just handing over more autonomy to the agent and possibility of it making a bad choice in how it uses an API). \n\nThat said, if you‚Äôre writing custom logic that your agent is meant to execute, MCP (or skills) is the best way‚Ä¶ there‚Äôs no api to wrap",
              "score": 1,
              "created_utc": "2026-02-22 15:17:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6s8zvw",
                  "author": "strangeanswers",
                  "text": "but then you‚Äôre wasting tokens and causing context rot by needing to load all those API docs into your context window to understand what the api does instead of just reading a tool description. how will the agent even know which api is useful for the task at hand? should it read the docs for all the APIs available to it each time?\n\nalso, if you spin up a new agent and want it to use this API, you probably need to whitelist it for that endpoint, which adds a bunch of complexity. if you instead just expose one tool to it and all requests from that tool come to the api through an MCP server it massively simplifies access management.",
                  "score": 3,
                  "created_utc": "2026-02-22 15:25:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rxgd0",
          "author": "OkLettuce338",
          "text": "How would you remotely install a skill that requires authentication?",
          "score": 9,
          "created_utc": "2026-02-22 14:26:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sgh66",
              "author": "uriwa",
              "text": "LLMs need env variables that get hot swapped, that's enough I think.",
              "score": -1,
              "created_utc": "2026-02-22 16:00:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6srzec",
                  "author": "OkLettuce338",
                  "text": "No it wouldn‚Äôt be. How would you install the skill remotely for a diverse set of users?",
                  "score": 3,
                  "created_utc": "2026-02-22 16:50:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6s7kbg",
          "author": "cmndr_spanky",
          "text": "MCP as a simple wrapper over APIs might be silly, but if you use custom written logic (nothing to do with APIs) that you want your LLM agent to execute like a function, MCP / skills is def the way to go..",
          "score": 4,
          "created_utc": "2026-02-22 15:19:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sgurp",
              "author": "uriwa",
              "text": "humans just call that \"documentation\", and they put it in places like google docs, markdown files in github etc'. There is no protocol for it.",
              "score": -2,
              "created_utc": "2026-02-22 16:01:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6sn8d1",
                  "author": "cmndr_spanky",
                  "text": "No that‚Äôs incorrect. You often don‚Äôt want variations / non-determinism in how an LLM should execute known logic which needs to be stable. So authoring a python function exposed via MCP is the best way, the ‚Äúdocument‚Äù only describes how and when to execute the function.",
                  "score": 3,
                  "created_utc": "2026-02-22 16:29:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6s21pm",
          "author": "XiiMoss",
          "text": "Yeah sound I‚Äôll just give the agent direct access to my API keys shall I",
          "score": 3,
          "created_utc": "2026-02-22 14:50:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sfr96",
              "author": "uriwa",
              "text": "the harness should hot swap the keys. llm doesn't need to know them. (like in deno sandboxes)",
              "score": 0,
              "created_utc": "2026-02-22 15:57:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6tq220",
          "author": "igorim",
          "text": "it's a massive risk when everytime some model needs to read something or do something it decides to read arbitrary code. MCP is not about a model not being able to do X it's about 1. saving it tokens to do X, and 2. adding deterministic guardrails, and 3. Having a shared interface so you don't need to reimplement for every model\n\n",
          "score": 3,
          "created_utc": "2026-02-22 19:28:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s2ct0",
          "author": "vogut",
          "text": "It's just a tool list and a prompt fetcher. The hype around it was dumb, I agree. But it's necessary",
          "score": 2,
          "created_utc": "2026-02-22 14:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tz1fn",
          "author": "WolfeheartGames",
          "text": "MCP is great for not restful api. Anything that wraps complex logic or maintains a state for the agent. Ghidra mcp, Godot mcp, playwright mcp, that sort of thing.",
          "score": 2,
          "created_utc": "2026-02-22 20:13:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u8vsx",
          "author": "apf6",
          "text": "MCP is great when you need something with builtin Oauth support.",
          "score": 1,
          "created_utc": "2026-02-22 21:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s6i43",
          "author": "dreamingwell",
          "text": "I wish I could auto block anyone that posts ‚ÄúMCP isn‚Äôt necessary‚Äù",
          "score": 1,
          "created_utc": "2026-02-22 15:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ta2ky",
              "author": "Hammer466",
              "text": "I could make an mcp for that!",
              "score": 3,
              "created_utc": "2026-02-22 18:14:11",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s8rlp",
          "author": "qlwkerjqewlkr",
          "text": "MCP is cringe and pointless",
          "score": 0,
          "created_utc": "2026-02-22 15:24:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6m5hb",
      "title": "Can LLMs deduplicate ML training data?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r6m5hb/can_llms_deduplicate_ml_training_data/",
      "author": "ddp26",
      "created_utc": "2026-02-16 21:14:03",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "I get increasingly annoyed with how unreliable deduplication tools are for cleaning training data. I‚Äôve used MinHash/LSH, libraries like [dedupe.io](http://dedupe.io), and pandas.drop\\_duplicates() but they all have a lot of false positives/negatives.  \n  \nI ended up running LLM-powered deduplication on 3,000 sentences from Google's paraphrase dataset from Wikipedia (PAWS). It removed 1,072 sentences (35.7% of the set). It only cost $4.21, and took \\~5 minutes.  \n  \nExamples of what it catches that the other methods don't:\n\n* \"Glenn Howard won the Ontario Championship for the 17th time as either third or skip\" and \"For the 17th time the Glenn Howard won the Ontario Championship as third or skip\"\n* \"David Spurlock was born on 18 November 1959 in Dallas, Texas\" and \"J. David Spurlock was born on November 18, 1959 in Dallas, Texas\"\n\n  \nFull code and methodology: [https://everyrow.io/docs/deduplicate-training-data-ml](https://everyrow.io/docs/deduplicate-training-data-ml)\n\nAnyone else using LLMs for data processing at scale? It obviously can work at small scale (and high cost), but are you finding it can work at high scale and low cost?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6m5hb/can_llms_deduplicate_ml_training_data/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5sbqnp",
          "author": "kubrador",
          "text": "yeah this is clever but you're basically paying for semantic understanding you could get cheaper with embeddings + cosine similarity. run your 3k sentences through openai's small embedding model (\\~$0.02 total), cluster by cosine distance, done in 10 seconds for less than a coffee.\n\n\n\nthe paraphrase examples you showed would absolutely get caught by that approach since they're semantically identical, which is what actually matters for training data dedup anyway.",
          "score": 2,
          "created_utc": "2026-02-17 01:05:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5sf7em",
              "author": "dreamingwell",
              "text": "You could do this to get ‚Äúprobably duplicates‚Äù. And then use an LLM to finalize them. Reducing your LLM costs significantly.",
              "score": 1,
              "created_utc": "2026-02-17 01:25:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5seuz1",
          "author": "dreamingwell",
          "text": "You can do a Lora tuning on a small model, like Qwen3-4B. Train it to identify duplicated data from examples in your set. On the right GPU, it would absolutely tear through that data.",
          "score": 2,
          "created_utc": "2026-02-17 01:23:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yzvnc",
              "author": "ChanceKale7861",
              "text": "Holy moly! Are you me?! ü§£ü§£ü§£",
              "score": 1,
              "created_utc": "2026-02-18 01:19:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5siq3u",
          "author": "No_Indication_1238",
          "text": "Tbh, you pretty much nailed a novel use case for LLMs. Yes, semantic analysis was tough before them.",
          "score": 1,
          "created_utc": "2026-02-17 01:47:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uvzl2",
          "author": "andy_p_w",
          "text": "Those two examples, if you take out regular words (any word 3 letters or less) and just look at the Jaccard similarity for the words will have very high overlap. English language is quite large, it is difficult to have much overlap in words random sentences, [https://andrewpwheeler.com/2024/04/20/some-musings-on-plagiarism/](https://andrewpwheeler.com/2024/04/20/some-musings-on-plagiarism/) .",
          "score": 1,
          "created_utc": "2026-02-17 12:52:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r79s1w",
      "title": "SurrealDB 3.0 for AI agent memory",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r79s1w/surrealdb_30_for_ai_agent_memory/",
      "author": "DistinctRide9884",
      "created_utc": "2026-02-17 15:55:41",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "SurrealDB 3.0 just dropped, with a big focus on agent memory infra for AI: improved vector indexing + better graph performance + native file storage + a WebAssembly extension system (Surrealism) that can run custom logic/models inside the DB. You can store vector embeddings + structured data + graph context/knowledge/memory in one place and do hybrid retrieval in one query.\n\nDetails:¬†[https://surrealdb.com/blog/introducing-surrealdb-3-0--the-future-of-ai-agent-memor](https://surrealdb.com/blog/introducing-surrealdb-3-0--the-future-of-ai-agent-memory)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r79s1w/surrealdb_30_for_ai_agent_memory/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o69cjli",
          "author": "singh_taranjeet",
          "text": "As CEO of Mem0 I can confirm our memory is so strong even SurrealDB is taking notes, but be careful or your AI agent might start asking *you* for emotional support when it forgets its own login ;)",
          "score": 1,
          "created_utc": "2026-02-19 15:55:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9dbt6",
      "title": "How do you test LLM for quality ?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "author": "Easy_Ask5883",
      "created_utc": "2026-02-19 22:19:05",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 1.0,
      "text": "I'm building something for AI teams and trying to understand the problem better.\n\n1. Do you manually test your AI features? \n\n2. How do you know when a prompt change breaks something?\n\n  \nAt AWS we have tons of associates who do manual QA (mostly irrelevant as far as I could see) but I dont think startups and SMBs are doing it. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6bn718",
          "author": "Comfortable-Sound944",
          "text": "As with any QA testing, some don't do it, some do it badly, some do it well but manual, some automated it, and many adjust it over time as it makes sense.",
          "score": 2,
          "created_utc": "2026-02-19 22:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c8hjz",
          "author": "charlesthayer",
          "text": "I write Evals (well agentic evals). Meaning\n\n1. A way to score your output. (e.g. llm-as-judge or jury)\n2. A set of inputs to test.\n3. A fast and simple way to run this. (like a benchmark)\n\nThere are many ways to achieve this, but you can start very simply and grow. I use Arize Phoenix for traces/spans, and they have large-scale Eval features.\n\n\\- Arize Phoenix Evals: [https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals](https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals)  \n\\- Article I wrote: [https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f](https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f)\n\n\\- Commercial tool (Braintrust evals): [https://www.braintrust.dev/docs/evaluation](https://www.braintrust.dev/docs/evaluation)",
          "score": 2,
          "created_utc": "2026-02-20 00:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h8xnx",
              "author": "Useful-Process9033",
              "text": "LLM-as-judge is underrated for catching regressions fast. The key is having a diverse enough input set that you actually cover your edge cases. Most teams test the happy path and then get surprised when a prompt change breaks some obscure but critical scenario.",
              "score": 2,
              "created_utc": "2026-02-20 19:40:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6e2yc7",
              "author": "anuragsarkar97",
              "text": "I'll take a look at those. Also do you keep changing your evals constantly? Or use vibe coding to create evals as well.\n\nHow do you decide which model to use and when",
              "score": 1,
              "created_utc": "2026-02-20 08:44:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6mv7kn",
                  "author": "charlesthayer",
                  "text": "I'm adding inputs and updating my llm-as-judge (eval tests) all the time as I hit problems. One thing I'd like to do more is dig into my Arize Phoenix traces more regularly to spot cases I missed. Right now, I'm bug-report driven, but I'd like to make this automated.",
                  "score": 1,
                  "created_utc": "2026-02-21 17:49:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6btgbh",
          "author": "Dimwiddle",
          "text": "It's always going to be a mix of automated and manual. There's also some cool ideas using skills with a QA agent, but that doesn't sound that ideal to me. \n\nI've been looking at ways to make AI code less 'viby' and have been experimenting with translating specs in to machine verifiable contracts, using test stubs. So far it's reduced a good amount bugs.",
          "score": 1,
          "created_utc": "2026-02-19 23:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c54b0",
          "author": "zZaphon",
          "text": "https://replayai-web.fly.dev",
          "score": 1,
          "created_utc": "2026-02-20 00:17:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c5gbe",
          "author": "paulahjort",
          "text": "Run the same prompt suite across multiple model checkpoints and track regression automatically in Weights&Biases.\n\nThe infra side of this is underrated too. Teams often skip systematic eval because spinning up a GPU to run a full eval suite feels heavyweight. Try a CLI tool like Terradev.\n\n[*github.com/theoddden/terradev*](http://github.com/theoddden/terradev)",
          "score": 1,
          "created_utc": "2026-02-20 00:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6diz7p",
          "author": "Ok_Constant_9886",
          "text": "We use deepeval (open-source): [https://github.com/confident-ai/deepeval](https://github.com/confident-ai/deepeval)\n\nAlso has a commercial platform confident ai: [https://www.confident-ai.com/](https://www.confident-ai.com/)",
          "score": 1,
          "created_utc": "2026-02-20 05:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dr5dc",
          "author": "Slight_Republic_4242",
          "text": "We learned this the hard way. At first, we ‚Äútested‚Äù by just trying prompts ourselves and saying, ‚ÄúLooks good.\n\nThen one small prompt **change** broke.: formatting, tone, edge cases and sometimes logic\n\nAnd we didn‚Äôt notice until a user complained. LLMs don‚Äôt fail loudly.  \nThey fail quietly.\n\nNow we:\n\na. Keep fixed test inputs\n\nb. Compare outputs before & after changes\n\nc. Check edge cases on purpose\n\nd. Track regressions like real software\n\nIt‚Äôs not perfect.  \nBut treating prompts like code changed everything.",
          "score": 1,
          "created_utc": "2026-02-20 06:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6driw5",
              "author": "anuragsarkar97",
              "text": "That makes sense I'm doing the same thing too. I guess time to build a product out of it.\n10-15% of my time I'm trying to fix either the system prompt of formating or something else",
              "score": 1,
              "created_utc": "2026-02-20 06:57:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e2r8n",
          "author": "AnythingNo920",
          "text": "in reality most SMBs do vibe testing, unless benchmarks are their key selling point. ",
          "score": 1,
          "created_utc": "2026-02-20 08:42:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e3108",
              "author": "anuragsarkar97",
              "text": "Interesting, so it's not so high on priority list. But eventually they need know how is the AI performing in some way right?",
              "score": 1,
              "created_utc": "2026-02-20 08:45:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6llof5",
                  "author": "AnythingNo920",
                  "text": "Absolutely right. They need to, but the average Joe in an SMB can't tell the difference between BLEU, ROUGE, Fluency, Accuracy, Recall or whatever other metric u wanna use. \n\nSo they do vibe testing. This feels more tangible. \nAt least thats my impression so far.",
                  "score": 1,
                  "created_utc": "2026-02-21 13:48:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9z30r",
      "title": "Finally moved our RAG eval from manual vibes to actual unit tests",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9z30r/finally_moved_our_rag_eval_from_manual_vibes_to/",
      "author": "Key_Review_7273",
      "created_utc": "2026-02-20 15:55:40",
      "score": 7,
      "num_comments": 12,
      "upvote_ratio": 0.68,
      "text": "We‚Äôve been struggling with our RAG pipeline for months because every time we tweaked a prompt or changed the retrieval chunk size something else would secretly break. Doing manual checks in a spreadsheet was honestly draining and we kept missing hallucinations.\n\nI finally integrated DeepEval into our CI and started pushing the results to Confident AI for the dashboarding part. The biggest win was setting up actual unit tests for faithfulness and answer relevancy. It caught a massive regression last night where our latest prompt was making the model sound more confident but it was actually just making stuff up.\n\nCurious how everyone else is handling automated evals in production? Are you guys building custom scripts or using a specific framework to track metrics over time?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9z30r/finally_moved_our_rag_eval_from_manual_vibes_to/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6l2amw",
          "author": "Ihavenocluelad",
          "text": "Shouldnt you add #sponsored #ad",
          "score": 1,
          "created_utc": "2026-02-21 11:18:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q3ybx",
          "author": "BeautifulKangaroo415",
          "text": "That‚Äôs weird, I had it running in like ten minutes. They updated the docs recently and the DeepEval integration is actually pretty smooth now. Might be worth checking the newer quickstart guide if you haven't looked at it lately because it definitely handled our agent traces without any issues.",
          "score": 1,
          "created_utc": "2026-02-22 05:16:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hhdao",
          "author": "MissJoannaTooU",
          "text": "I'll check it out thanks",
          "score": 0,
          "created_utc": "2026-02-20 20:21:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fwkea",
          "author": "YeahOkayGood",
          "text": "DeepEval is the worst option, why are you using that garbage",
          "score": -6,
          "created_utc": "2026-02-20 15:58:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fyejy",
              "author": "InfraScaler",
              "text": "Because Op is here just to promote that trash.",
              "score": 5,
              "created_utc": "2026-02-20 16:07:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g00z4",
              "author": "Howdareme9",
              "text": "Any recommendations?",
              "score": 2,
              "created_utc": "2026-02-20 16:14:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g9i2v",
              "author": "techperson1234",
              "text": "Yeah... Tried it out literally couldn't get it working. Maybe it's improved in the last few months but based on this comment I doubt it",
              "score": 2,
              "created_utc": "2026-02-20 16:57:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g3x15",
              "author": "Budget-Length2666",
              "text": "What would you use?",
              "score": 1,
              "created_utc": "2026-02-20 16:32:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g7x7p",
              "author": "vogut",
              "text": "Huh? It's the best option",
              "score": 1,
              "created_utc": "2026-02-20 16:50:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6q6e8s",
              "author": "Easy_Stick_6500",
              "text": "Not sure why everyone is tripping lol. I had a few issues with the docs at first too but once you get the decorators set up it literally saves so much time. We‚Äôve been using Confident AI for our production traces for a month now and haven't found anything else that handles custom metrics this well. Maybe try the latest version because it‚Äôs definitely not trash for us.",
              "score": 1,
              "created_utc": "2026-02-22 05:36:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6h7hr6",
          "author": "Ok_Prize_2264",
          "text": "I‚Äôve been using Confident AI for the tracing side of things lately and it is actually a lifesaver for debugging multi step agents. Being able to see exactly which span failed without digging through raw logs saves so much time. The DeepEval metrics are solid too since they actually give you a reason why a test failed instead of just a random score.",
          "score": -1,
          "created_utc": "2026-02-20 19:33:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tphmo",
              "author": "DARK_114",
              "text": "I totally agree with the tracing part. It is honestly frustrating when an agent loops and you have no idea why but seeing the logic flow clearly makes it so much easier to fix. Having those specific reasons for failure instead of just numbers actually helps with quick iterations too.",
              "score": 1,
              "created_utc": "2026-02-22 19:26:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}