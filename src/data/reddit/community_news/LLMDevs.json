{
  "metadata": {
    "last_updated": "2026-01-18 16:49:54",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 92,
    "file_size_bytes": 126536
  },
  "items": [
    {
      "id": "1qaowjr",
      "title": "SCOPE raises the bar by matching GPT-4o's results while being 160,000x smaller",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qaowjr/scope_raises_the_bar_by_matching_gpt4os_results/",
      "author": "MarionberrySingle538",
      "created_utc": "2026-01-12 07:47:20",
      "score": 32,
      "num_comments": 13,
      "upvote_ratio": 0.86,
      "text": " Researchers built a neural planner, SCOPE thats 160,000x smaller than frontier LLM models like GPT 40, 55x faster and produces better results compared to LLMs. SCOPE achieves this using this approach: one-shot LLM initialization + hierarchical neural planning + RL fine-tuning, allowing it to run fully independently on a single GPU with no API calls or network latency. This is really a game changer as it's faster, smarter and more sustainable for our environment.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qaowjr/scope_raises_the_bar_by_matching_gpt4os_results/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz4u45d",
          "author": "WhoTookPlasticJesus",
          "text": "idgi.\n\nThere's a blog post and a 10 page paper that mostly repeats the blog post. As far as I can tell it performs one task of your devising, but there's no code or any way to reproduce the results, so I can't be sure. There's not even a specification of hardware that was used for testing. \n\nAnyway, I'm ready put in $700MM at a pre-money valuation of $1.7B. I'll have the term sheet to you by COB Friday.",
          "score": 24,
          "created_utc": "2026-01-12 09:16:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4mfho",
          "author": "Frosty_Chest8025",
          "text": "someone could say to datacenter boys that they can stop building.",
          "score": 9,
          "created_utc": "2026-01-12 08:02:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4ufh4",
              "author": "coronakillme",
              "text": "They will increase the scope",
              "score": 1,
              "created_utc": "2026-01-12 09:19:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4x6hz",
          "author": "Bmaxtubby1",
          "text": "I’m still pretty new to ML research, but I’ve learned to be cautious when something 'beats GPT-4o' without clearly stating the task distribution. Beating a frontier model on a specialized benchmark doesn’t automatically mean broader capability.\n\nIt actually feels more like a strong argument for hybrid systems: LLMs for language + smaller planners for structure and decision-making.",
          "score": 8,
          "created_utc": "2026-01-12 09:46:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7kelu",
              "author": "JollyJoker3",
              "text": "Yeah, I can beat 5.2 in Towers of Hanoi with 500 bytes",
              "score": 1,
              "created_utc": "2026-01-12 18:49:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4nfip",
          "author": "redballooon",
          "text": "Big if true. \n\nDoes it only match gpt-4o in some selected specialty, or generally for reasoning? For instruction following? For knowledge?",
          "score": 8,
          "created_utc": "2026-01-12 08:12:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4lfd9",
          "author": "Infamous_Knee3576",
          "text": "That is just a small overfitted model. Trained only to beat benchmarks.",
          "score": 5,
          "created_utc": "2026-01-12 07:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4krso",
          "author": "MarionberrySingle538",
          "text": "Official announcement: [https://skyfall.ai/blog/scope-hierarchical-planner-55x-faster-than-llms](https://skyfall.ai/blog/scope-hierarchical-planner-55x-faster-than-llms)",
          "score": 3,
          "created_utc": "2026-01-12 07:47:34",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nz5e32n",
          "author": "adalgis231",
          "text": "Is there a paper reference?",
          "score": 1,
          "created_utc": "2026-01-12 12:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6b766",
              "author": "czmax",
              "text": "it’s linked in the announcement posted by OP",
              "score": 1,
              "created_utc": "2026-01-12 15:23:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8hacs",
                  "author": "infinitelylarge",
                  "text": "Where?\n\nhttps://preview.redd.it/4cbizrwvjzcg1.jpeg?width=1320&format=pjpg&auto=webp&s=6e119acb802f73552f661e303ffa3ab0c57c83b7",
                  "score": 1,
                  "created_utc": "2026-01-12 21:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7tozu",
          "author": "pegaunisusicorn",
          "text": "da fuq are they comparing themselves to gpt-3.5 and 4o? \n\nIs this 2024?  \n\nWut?\n\nSmells like old tech dug up for selling crap AI stocks to rubes.",
          "score": 1,
          "created_utc": "2026-01-12 19:32:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qb2swo",
      "title": "Where to start with RAG and LangChain in 2026? Feeling a bit overwhelmed by the ecosystem.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qb2swo/where_to_start_with_rag_and_langchain_in_2026/",
      "author": "Cobra_venom12",
      "created_utc": "2026-01-12 18:26:38",
      "score": 25,
      "num_comments": 18,
      "upvote_ratio": 0.96,
      "text": "Hey everyone,\n​I’m looking to dive deep into RAG (Retrieval-Augmented Generation) using LangChain, but the more I read, the more I realize how many moving parts there are (vector DBs, chunking strategies, embeddings, LCEL, etc.).\n​I have a decent handle on Python, but I’m struggling with the \"order of operations.\"\n​My questions for the experts here:\n​What are the absolute \"day one\" fundamentals I should master before touching the code? (e.g., understanding embeddings vs. just learning LangChain syntax?)\n​Are there specific resources (YouTube, courses, or docs) that are actually up-to-date for 2026? A lot of tutorials I find use deprecated LangChain syntax.\n​If you were starting today, what’s the first mini-project you’d build to \"get it\"?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qb2swo/where_to_start_with_rag_and_langchain_in_2026/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz8acsg",
          "author": "Ok_Pomelo_5761",
          "text": "Ignore LangChain at first. Learn RAG like a pipeline:\n\n1 take your docs  \n2 cut them into small pieces  \n3 search the best pieces  \n4 give the model only those pieces and show sources  \n5 test if answers are actually correct\n\nIf you want a clear roadmap, copy what [zeroentropy](https://www.zeroentropy.dev/) focuses on: better chunking, better reranking, and simple evals. That is where most RAG wins come from.\n\nFor RAG stuff, the discord [https://discord.gg/yveDzEyP](https://discord.gg/yveDzEyP)",
          "score": 10,
          "created_utc": "2026-01-12 20:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7x5yt",
          "author": "tom-mart",
          "text": "If you are ok with Python then forget Langchain and look into Pydantic AI. Langchain adds a lot of unnecessary abstraction and is really not bringing any value. Start small an build on it. Have a look on my post history, I wrote a series of articles to show how to build basic agents from scratch with Django (Python), Pydantic AI and Postgress with their built in vector extension pgvector. Once you see the basic structure, you will be able to build anything on it.\n\nI'm finishing another article that will show how to build an AI personal assistant (or rather a whole bunch of specialist assistants) using same twchnologies as above, plus Android front end that also collects user health and phone use data so the assistant has some raw data to work on.",
          "score": 13,
          "created_utc": "2026-01-12 19:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzarpdr",
              "author": "lionmeetsviking",
              "text": "This! Pydantic AI rocks! Here is a little scaffolding that might help: https://github.com/madviking/pydantic-ai-scaffolding",
              "score": 2,
              "created_utc": "2026-01-13 04:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7jei0",
          "author": "fnl",
          "text": "It is raw and unrevised yet, but I have a blog post on that: Curious to learn if it is helpful to someone like you or confusing. https://fnl.es/Blog/Machine+Learning/2026-01-10+A+primer+on+RAG%2C+2026+edition",
          "score": 4,
          "created_utc": "2026-01-12 18:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7vzd7",
              "author": "Cobra_venom12",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-01-12 19:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzo6ghz",
          "author": "pbalIII",
          "text": "Skip the LangChain syntax entirely for now. Most teams waste weeks learning LCEL when the real wins come from understanding the pipeline mechanics first.\n\nDay one fundamentals: embeddings (what they are, why cosine similarity works), chunking (semantic vs fixed-size, the 256-512 token sweet spot), and retrieval quality (precision vs recall tradeoffs). Build a dead-simple RAG with just OpenAI embeddings, a local vector store like Chroma, and raw API calls. No framework.\n\nOnce that clicks, Pydantic AI is cleaner than LangChain for production work. Way less abstraction, type-safe, and you actually understand what your code does. LangChain is fine for demos but adds layers you dont need when learning.\n\nFirst project: FAQ bot over your own docs. Small enough to debug, big enough to hit real chunking problems.",
          "score": 3,
          "created_utc": "2026-01-15 04:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzod19n",
              "author": "Cobra_venom12",
              "text": "That's really helpful.",
              "score": 1,
              "created_utc": "2026-01-15 04:55:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb7s5d",
          "author": "Subject-Complex6934",
          "text": "This channel has alot of videos about RAG in detail  \n[https://www.youtube.com/@PavelCermakAI](https://www.youtube.com/@PavelCermakAI)",
          "score": 2,
          "created_utc": "2026-01-13 06:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlmdlf",
          "author": "charlesthayer",
          "text": "1. Try this quick ChromaDB example: [https://docs.trychroma.com/docs/overview/getting-started](https://docs.trychroma.com/docs/overview/getting-started)  \n2. Check out this Real Python article with a deeper full-text example: [https://realpython.com/chromadb-vector-database/](https://realpython.com/chromadb-vector-database/)  \n3. Build a tiny LLM agent calling example with HF's smolagents: [https://www.nb-data.com/p/mastering-smolagents-building-ai](https://www.nb-data.com/p/mastering-smolagents-building-ai)\n\nYou should be able to extend the agent with a vectorDB search tool (tool-call, tool-use) over a directory of your own documents at this point.",
          "score": 2,
          "created_utc": "2026-01-14 20:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8amff",
          "author": "hrishikamath",
          "text": "Honestly just take a real problem: get documents for it, do rag on it with the most basic setup. You will see why it fails. Learn about individual components and go deeper. That’s the best way. No point studying theory and not retaining more than 10-20% because you won’t use most of it.",
          "score": 2,
          "created_utc": "2026-01-12 20:51:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzaz9am",
              "author": "Cobra_venom12",
              "text": "You are saying to make a basic project and learn through it.",
              "score": 3,
              "created_utc": "2026-01-13 05:32:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9sh63",
          "author": "Bonnie-Chamberlin",
          "text": "I would recommend starting by learning from a specific task instead of starting from a framework. For example, if you want to build a paper-reading chatbot based on a RAG system, you build step by step and learn whatever techniques if needed. Otherwise, you will always feel lost when you want to eat in the whole framework.",
          "score": 1,
          "created_utc": "2026-01-13 01:24:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbdryu",
          "author": "MediumMountain6164",
          "text": "Create a new space",
          "score": 1,
          "created_utc": "2026-01-13 07:32:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbqevi",
          "author": "Full_Win_8680",
          "text": "Start with the core ideas first embeddings, vector search, and chunking.  \nThen build a tiny project RAG over your own PDFs. That alone teaches most of it.  \nFor resources, stick to the latest LangChain docs + recent YouTube talks a lot of older tutorials are outdated.",
          "score": 1,
          "created_utc": "2026-01-13 09:33:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbqs7o",
              "author": "Cobra_venom12",
              "text": "Do I have to learn about llms ?",
              "score": 1,
              "created_utc": "2026-01-13 09:37:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbtumc",
                  "author": "Full_Win_8680",
                  "text": "Yes but only the practical parts how prompts work, tokens, context windows, and how models respond.  \nYou don’t need to go deep into training or architecture to build solid RAG systems.",
                  "score": 3,
                  "created_utc": "2026-01-13 10:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzeabii",
          "author": "NearbySupport7520",
          "text": "f",
          "score": 1,
          "created_utc": "2026-01-13 18:37:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8i26a",
          "author": "hello5346",
          "text": "You need none of that to get started.  Focus on your goals.",
          "score": 0,
          "created_utc": "2026-01-12 21:26:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qf94rb",
      "title": "Best custom RAG development services for document Q&A systems?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qf94rb/best_custom_rag_development_services_for_document/",
      "author": "Own_Chocolate1782",
      "created_utc": "2026-01-17 09:42:44",
      "score": 20,
      "num_comments": 10,
      "upvote_ratio": 0.92,
      "text": "We’re trying to build a RAGnbased document Q&A system on top of a large internal knowledge base, and the complexity is higher than we expected. The data includes PDFs, SOPs, policy docs with revisions, and spreadsheets, and keeping answers accurate across all of that has been challenging.  \n  \nWe tested a few no code and off the shelf tools, but they tend to break once documents get complex or frequently updated. We’re specifically looking for a system that can handle multi document retrieval, reference sources properly, and stay reliable without retraining every time content changes.  \n  \nAt this point, we’re considering bringing in a dev partner that’s done document heavy RAG systems before. Please share in your help with rec or suggestions.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qf94rb/best_custom_rag_development_services_for_document/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o02yiqt",
          "author": "robogame_dev",
          "text": "Look into agentic search - basically, classic RAG (chunking and vector embedding) should only be one of many tools available to an AI agent. The agent decides when to use vector search, among other options like plain text search, specifying date ranges, etc etc. \n\nPicture all the useful filters you have when you search your email, from:, to:, has_attachments:, sent:, mailbox:, folder:, date_range:, all of that stuff. You want your AI to be given all the tools it needs for the data that’s specific to your domain.\n\nThen when it’s time for recall, you have a dedicated recall agent that you expose as a subagent to your main AI, the one the user interfaces with. \n\nUser asks main AI a question. Main AI determines it needs knowledge from your data, so it calls tool “query_knowledge( some_query_specified_by_the main_AI )”\n\nNow the research AI is called by that tool, and it has a complex prompt explaining all the tools and recall policies, and it interprets the query and makes a series of tool calls as it searches for the info. Whatever you’ve got setup currently is just one of the tools it can choose, for example, “vector_search(comparison_query, other, options, here)”. If you’ve got databases, there’s another tool that lets the research AI enter a SQL query. If you’ve got documents that have multiple versions, you’ve probably got an option on your search tools that says “include_older_versions” that can be true or false. Etc.\n\nI would be happy to hear your business specifics and offer more tailored advice, lmk.",
          "score": 3,
          "created_utc": "2026-01-17 10:00:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04q33q",
          "author": "Thick_Jeweler_5353",
          "text": "If your docs include tables and revisions, make sure the vendor has handled that before. That was a big failure point for us. Leanware had prior experience there, which helped",
          "score": 2,
          "created_utc": "2026-01-17 16:44:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o05i9we",
              "author": "SchrodingersCigar",
              "text": "I spent a while messing around with Marker (github) to parse out PDFs, mostly successful but ran out of time getting it chunked and embedded effectively. I'm not sure from your comment if Leanware were successful in this or not, if they were, did you have eyes on what they did differently ?",
              "score": 0,
              "created_utc": "2026-01-17 18:55:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o03l8yd",
          "author": "deadweightboss",
          "text": "I feel like people make these posts on burners and do that they can pitch their service in a less promotional way.",
          "score": 2,
          "created_utc": "2026-01-17 13:11:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o06tg2g",
              "author": "HumanDrone8721",
              "text": "This is exactly what is happening, a burner one post \"the problem\" and another burners pitcher-post \"the best solution in my experience\", in few minutes after posting we already have TWO posts to commercial services, one having even a referral tag to measure the \"engagement\": https://garbagecrap.dev/?utm_source=redditCP_g",
              "score": 2,
              "created_utc": "2026-01-17 22:50:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o030mgp",
          "author": "riyaaaaaa_20",
          "text": "For complex doc-heavy RAG, go custom. Look for devs who can handle PDFs, spreadsheets, SOPs, multi-doc retrieval, source citation, and updates without retraining. Vector DBs + good preprocessing pipelines are key.",
          "score": 0,
          "created_utc": "2026-01-17 10:20:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o096um7",
          "author": "machaao",
          "text": "We have built https://bookbot.live, would love to help out",
          "score": 0,
          "created_utc": "2026-01-18 07:30:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o032ny9",
          "author": "kubrador",
          "text": "based on what you're describing (pdfs, sops, revisions, spreadsheets, multi-doc retrieval, source citations) you need a partner who's done this exact messy enterprise doc situation before, not just \"we do rag!\"\n\n**intelliarts** typically starts with a proof of concept in 6-8 weeks and built a custom rag system for an ngo that made searches 3x faster \n\n**miquido** handles vector databases, data cleaning, and builds \"scrapers and automated pipelines to extract data from internal documents, apis, websites, or unstructured formats like pdfs\"",
          "score": -1,
          "created_utc": "2026-01-17 10:39:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o05iotw",
          "author": "SchrodingersCigar",
          "text": "The Marker project on github is pretty clever at parsing PDFs which are a massive PITA. It can output to markdown or json. I didnt get much beyond that though.",
          "score": -1,
          "created_utc": "2026-01-17 18:56:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbnhjd",
      "title": "500Mb Named Entity Recognition (NER) model to identify and classify entities in any text locally. Easily fine-tune on any language locally (see example for Spanish).",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qbnhjd/500mb_named_entity_recognition_ner_model_to/",
      "author": "Ok_Hold_5385",
      "created_utc": "2026-01-13 10:01:26",
      "score": 12,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "[https://huggingface.co/tanaos/tanaos-NER-v1](https://huggingface.co/tanaos/tanaos-NER-v1)\n\nA small (500Mb, 0.1B params) but efficient Named Entity Recognition (NER) model which **identifies and classifies entities in text into predefined categories** (person, location, date, organization...) locally.\n\n# Use-case\n\nYou have unstructured text and you want to extract specific chunks of information from it, such as names, dates, products, organizations and so on, for further processing.\n\n    \"John landed in Barcelona at 15:45.\"\n    \n    >>> [{'entity_group': 'PERSON', 'word': 'John', 'start': 0, 'end': 4}, {'entity_group': 'LOCATION',  'word': 'Barcelona', 'start': 15, 'end': 24}, {'entity_group': 'TIME', 'word': '15:45.', 'start': 28, 'end': 34}]\n\n# Fine-tune on custom domain or language without labeled data (no GPU needed)\n\nDo you want to tailor the model to your specific domain (medical, legal, engineering etc.) or to a different language? Use the [Artifex library](https://github.com/tanaos/artifex) to fine-tune the model on CPU by generating synthetic training data on-the-fly.\n\n    from artifex import Artifex\n    \n    ner = Artifex().named_entity_recognition\n    \n    ner.train(\n        domain=\"documentos medico\",\n        named_entities={\n            \"PERSONA\": \"Personas individuales, personajes ficticios\",\n            \"ORGANIZACION\": \"Empresas, instituciones, agencias\",\n            \"UBICACION\": \"Áreas geográficas\",\n            \"FECHA\": \"Fechas absolutas o relativas, incluidos años, meses y/o días\",\n            \"HORA\": \"Hora específica del día\",\n            \"NUMERO\": \"Mediciones o expresiones numéricas\",\n            \"OBRA_DE_ARTE\": \"Títulos de obras creativas\",\n            \"LENGUAJE\": \"Lenguajes naturales o de programación\",\n            \"GRUPO_NORP\": \"Grupos nacionales, religiosos o políticos\",\n            \"DIRECCION\": \"Direcciones completas\",\n            \"NUMERO_DE_TELEFONO\": \"Números de teléfono\"\n        },\n        language=\"español\"\n    )",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qbnhjd/500mb_named_entity_recognition_ner_model_to/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzghzb9",
          "author": "OnyxProyectoUno",
          "text": "Nice to see a lightweight NER model that runs locally. Entity extraction is one of those preprocessing steps that can make or break your downstream retrieval quality, but most people bolt it on as an afterthought.\n\nThe synthetic training approach is clever. Usually when you're dealing with domain-specific docs, the generic PERSON/ORG/LOC categories miss the stuff that actually matters. Medical records need drug names, dosages, procedure codes. Legal docs need case citations, statute references, party names. Having a way to define custom entity types without manual labeling saves a lot of pain.\n\nOne thing to watch out for when you're using NER in document processing pipelines: entity boundaries getting mangled during chunking. You extract \"Dr. Sarah Johnson\" as a PERSON entity, but then your chunker splits right through it and you lose the connection. The entity extraction and chunking steps need to be coordinated, not just run sequentially.\n\nAlso worth thinking about how you handle entity disambiguation. \"Apple\" the company vs \"apple\" the fruit. Context helps, but if your chunks are too small, you lose that context. Sometimes it's better to run NER on larger text windows and then propagate the entities down to the individual chunks.\n\nAre you planning to use this for enriching chunks before they go into a vector store, or more for post-retrieval processing?",
          "score": 2,
          "created_utc": "2026-01-14 01:07:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzia03u",
              "author": "Ok_Hold_5385",
              "text": "Thanks for the detailed feedback. I created this model as part of the [Artifex library](https://github.com/tanaos/artifex), whose purpose is to make it easy to run and fine-tune task-specific Small Language Model on CPU. My goal was to create an efficient and lightweight model, while letting users find the best use cases for it.",
              "score": 1,
              "created_utc": "2026-01-14 08:35:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzgxuuo",
          "author": "WallyPacman",
          "text": "Stupid question but how does one integrate with one of those? I imagine not llama-cpp?",
          "score": 1,
          "created_utc": "2026-01-14 02:37:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh4wf3",
              "author": "robogame_dev",
              "text": "Looks like the linked Artifex library can be used to run them locally with Python - and that they run on cpu.",
              "score": 1,
              "created_utc": "2026-01-14 03:17:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nziaf8a",
              "author": "Ok_Hold_5385",
              "text": "As u/robogame_dev mentioned, this model is meant to be used through the [Artifex library](https://github.com/tanaos/artifex) for CPU inference and fine-tuning\n\n    from artifex import Artifex\n    \n    ner = Artifex().named_entity_recognition\n    \n    named_entities = ner(\"John landed in Barcelona at 15:45.\")\n    print(named_entities)\n    \n    # >>> [[{'entity_group': 'PERSON', 'score': 0.92174554, 'word': 'John', 'start': 0, 'end': 4}, {'entity_group': 'LOCATION', 'score': 0.9853817, 'word': ' Barcelona', 'start': 15, 'end': 24}, {'entity_group': 'TIME', 'score': 0.98645407, 'word': ' 15:45.', 'start': 28, 'end': 34}]]\n\nIf you'd rather use this model through a fully managed API, you can try this [https://slm.tanaos.com/docs#/Models%20endpoints/named\\_entity\\_recognition\\_inference\\_models\\_named\\_entity\\_recognition\\_post](https://slm.tanaos.com/docs#/Models%20endpoints/named_entity_recognition_inference_models_named_entity_recognition_post)",
              "score": 1,
              "created_utc": "2026-01-14 08:39:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzh593y",
          "author": "robogame_dev",
          "text": "This is really cool - I remember your prior post on using something similar to censor PII.\n\nOut of curiosity, what sorts of use cases do you see as the boundary, where you’d want to switch from something like this to a full LLM for? Any recommendations or best practices for setting this guy up?",
          "score": 1,
          "created_utc": "2026-01-14 03:19:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzic9gg",
              "author": "Ok_Hold_5385",
              "text": "Thanks! Yes, the PII tool is a fine-tuned version of this very model.\n\nI think that, in general, full LLMs are overkill for NER tasks. 95% of the times you're better off using a SLM, as they are cheaper, faster and often better performing. The only exceptions are extremely long context lengths (where SLMs may not perform well) and very specific domains that the SLM was not fine-tuned on (that's why the Artifex library gives you the ability to fine-tune the model on any domain and/or language).\n\nAbout recommendations on how to set it up:\n\n1. Understand the task you will be using the model on, especially the language that will be used and the domain (medical, engineering, legal...).\n2. Once you have that down, fine-tune the base NER model with Artifex on your specific task. [See this doc page for details on how to do it](https://docs.tanaos.com/artifex/named-entity-recognition/train/).\n3. Once you have the fine-tuned model, use [Artifex's load method](https://docs.tanaos.com/artifex/named-entity-recognition/load/) to load the new model and subsequently [the call method](https://docs.tanaos.com/artifex/named-entity-recognition/inference/) to perform inference with it.\n\nYou can also check [this page](https://docs.tanaos.com/artifex/named-entity-recognition/code-examples/) for a full end-to-end example.\n\nIf you have any more questions don't hesitate to ask.",
              "score": 2,
              "created_utc": "2026-01-14 08:57:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qcpfgn",
      "title": "Claude Cowork: Initial Impressions, Architecture, Capabilities, and Usage Overview",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qcpfgn/claude_cowork_initial_impressions_architecture/",
      "author": "Arindam_200",
      "created_utc": "2026-01-14 14:58:50",
      "score": 10,
      "num_comments": 1,
      "upvote_ratio": 0.92,
      "text": "It’s been about a year since we started doing small agentic tasks. Giving models file access, connecting Drive, stitching tools together, and calling that “agents.”\n\nClaude has now shipped this as a first-class product feature.\n\nClaude Cowork is a task execution mode in the Claude Desktop app. Instead of responding to prompts, it works toward an outcome.\n\nYou describe an outcome. Claude plans the steps, works across local files you explicitly share, and executes multi-step tasks with minimal back & forth. Context stays alive until the task finishes as you review plans and approve risky actions.\n\nWhat stood out to me:\n\n* Local execution on macOS inside an isolated VM\n* Explicit folder-level permissions\n* Designed for long-running multi-step work.\n* Still a research preview with sharp limits. (MacOS only, higher usage, no persistence)\n\nI went into how the architecture actually works, including planning, sub-agent coordination, file access, and safety boundaries. You can read it [here](https://www.tensorlake.ai/blog/claude-cowork-architecture-overview).",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcpfgn/claude_cowork_initial_impressions_architecture/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzt4ifi",
          "author": "Creepy-Row970",
          "text": "pretty interesting",
          "score": 1,
          "created_utc": "2026-01-15 21:58:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe0kqk",
      "title": "Best way to learn AI engineering from scratch? Feeling stuck between two paths",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qe0kqk/best_way_to_learn_ai_engineering_from_scratch/",
      "author": "mohnnd6",
      "created_utc": "2026-01-16 00:12:15",
      "score": 9,
      "num_comments": 21,
      "upvote_ratio": 0.85,
      "text": "Hey everyone,\n\nI’m about to start learning AI engineering from scratch, and I’m honestly a bit stuck on how to approach it.\n\nI keep seeing two very different paths, and I’m not sure which one makes more sense long-term:\n\nPath 1 – learn by building\nLearn Python basics\nStart using AI/ML tools early (LLMs, APIs, frameworks)\nBuild projects and learn theory along the way as needed\n\nPath 2 – theory first\nLearn Python\nGo deep into ML/AI theory and fundamentals\nCode things from scratch before relying on high-level tools\n\nMy goal isn’t research or academia — I want to build real AI products and systems eventually.\n\nFor those of you already working in AI or who’ve gone through this:\n\nWhich path did you take?\nWhich one do you think actually works better?\nIf you were starting today, what would you do differently?\n\nReally appreciate any advice",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qe0kqk/best_way_to_learn_ai_engineering_from_scratch/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nztutfa",
          "author": "kubrador",
          "text": "path 1, hands down. you're not trying to publish papers, you're trying to ship things.\n\nbuild something janky with an llm api next week, then when you hit a wall and realize you don't understand embeddings or whatever, \\*that's\\* when you go learn the theory because it actually means something now. learning backprop in isolation is just suffering.\n\nthe people who grind path 2 for 6 months end up burnt out and haven't made anything. the people who build first discover they only needed like 20% of the theory to be dangerous anyway.",
          "score": 10,
          "created_utc": "2026-01-16 00:14:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu338n",
              "author": "robogame_dev",
              "text": "Path 1 for sure, with Perplexity as your first resort when you need info. LLM world moves fast, if you ask ChatGPT et al, they’ll primarily be responding from training data that is 6-12 months behind, the result is they reference APIs that have changed, and don’t know about the latest techniques. Perplexity (or another search-first setup) is invaluable for learning AI (and any other rapidly evolving field).",
              "score": 2,
              "created_utc": "2026-01-16 00:58:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzutn1r",
                  "author": "prajwalmani",
                  "text": "Isn't the chatgpt use web search tool to update the context based on the current info",
                  "score": 1,
                  "created_utc": "2026-01-16 03:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztv96a",
              "author": "LeatherConfection362",
              "text": "That’s right.",
              "score": 1,
              "created_utc": "2026-01-16 00:16:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzu6xs0",
          "author": "Crashbox3000",
          "text": "Learn by building. Build as an architect, though, not a coder. Learn the relationships and dependencies. Build things that force you to make connections between systems. Question your assumptions always.",
          "score": 3,
          "created_utc": "2026-01-16 01:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzva2zc",
              "author": "robogame_dev",
              "text": "The one caveat is I’d suggest coding the ChatGPT completions API yourself once, since it underlies virtually everything else, and is extremely short and simple - that clarity from getting hands on with the completions API will carry over into better architecting.",
              "score": 1,
              "created_utc": "2026-01-16 05:12:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzv59yg",
          "author": "mdizak",
          "text": "**I would definitely go second path.  If this is a bubble (and yes, yes it's a bubble), once it bursts and things go tits up many if not most of the things you taught yourself via path 1 will now be null and void, because you went down the narrow path of today's AI.**\n\n\n\n**With path 2 on the otherhand, those fundamentals will remain valuable reagrdless if this generation of AI goes tits up or not.  It also allows you to better understand the problems, hence be capable of coming up with more innovative and novel solutions, increasing your value.**",
          "score": 3,
          "created_utc": "2026-01-16 04:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztv2jr",
          "author": "jucktar",
          "text": "I had chat gpt train me",
          "score": 1,
          "created_utc": "2026-01-16 00:15:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0gyz",
          "author": "metaphorm",
          "text": "learn programming fundamentals first",
          "score": 1,
          "created_utc": "2026-01-16 00:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu2i3e",
          "author": "Unable-Shame-2532",
          "text": "path 1 forsure, you’ll enjoy the process much more(assuming you want to build) and get better faster",
          "score": 1,
          "created_utc": "2026-01-16 00:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8l3w",
          "author": "FreeTinyBits",
          "text": "Maybe you should think about what kinds of ai products you want to build eventually. Then you would have a better idea.",
          "score": 1,
          "created_utc": "2026-01-16 01:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuacoh",
          "author": "Vegetable-Score-3915",
          "text": "Check out deeplearning.ai python for ai course and a couple of the beginner short courses they have. Dont need to pay, just pay if you want the certs.\n\nThat could be a good quick introduction. So you have some framework exposure and examples so you can start building\n\nI reckon path 1 with the above. You could spend 6 months learning deep learning and more traditional statistical techniques / more traditional ml and only be across a small amount of it. Maybe touch on decision trees, random forests, support vector machines, clustering techniques etc, but wouldnt recommend going deep into the theory for too long. Unless that is what you want to do.\n\nHighly recommend learning by doing, and those deeplearning.ai short courses are pretty good giving at least the language model theory with practicals. I think it is easier to focus on that, and in anything you build, loom up analytical techniques/ traditional ml stuff if relevant, so learn what you need to learn for the task at hand.",
          "score": 1,
          "created_utc": "2026-01-16 01:40:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuck94",
              "author": "Vegetable-Score-3915",
              "text": "I did path 2 - a masters many years ago.\nIf had to do it again, would do path1 now.\n\nTraditional ML and older techniques are still important, but seem to be more niche. My view, the better you are with ai generally, I think you'll get better at learning rapidly and learning what you need to learn. \n\nDefinitely do a decent python intro course though. Ive taught bootcamps, students who just relied on ai to write all their code before they could code seemed to stagnate, and could not identify ai slope, or fix errors. That deeplearning.ai python for ai beginner course seems fit for purpose.",
              "score": 1,
              "created_utc": "2026-01-16 01:52:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzucd7c",
          "author": "Whole-Assignment6240",
          "text": "begin with karparthy's videos :)",
          "score": 1,
          "created_utc": "2026-01-16 01:51:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzudu43",
          "author": "Bonnie-Chamberlin",
          "text": "If your goal is not research, don't touch the theory. Learning from theory only lead to one possible outcome: give up!",
          "score": 1,
          "created_utc": "2026-01-16 01:59:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuuu1m",
          "author": "bobthe3",
          "text": "get claude code or opencode and just start writing into the box, when confused just ask it to explain. the important thing is to READ!",
          "score": 1,
          "created_utc": "2026-01-16 03:34:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvjapu",
          "author": "RegionDesigner8000",
          "text": "I would recommend starting with Path 1 learning by building. Dive into Python and start using AI/ML tools early on. It's the quickest way to get hands on experience and see how things work in practice. You can always pick up theory as you go when you hit a roadblock or need a deeper understanding. That said, some theory is important, but you don’t need to go super deep upfront. Building real projects will teach you way more about what works in production. So, focus on tools, frameworks, and small projects first, then dive into the theory as it becomes relevant to what you're working on.",
          "score": 1,
          "created_utc": "2026-01-16 06:20:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzyv80g",
          "author": "PresentationOk8334",
          "text": "for building real products, path 1 works way better. starting with tools and projects gives you context, then the theory actually sticks instead of feeling abstract.\n\nthat’s how i did it .. i used Coursiv early on to understand modern workflows and LLM-based apps. it helped me know why i was learning certain theory later.\n\ndon’t skip fundamentals, just learn them at the moment they’re useful.",
          "score": 1,
          "created_utc": "2026-01-16 18:38:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o018jlp",
          "author": "threebodyproblem333",
          "text": "Just get codex $20/month and pump it",
          "score": 1,
          "created_utc": "2026-01-17 01:56:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzui93y",
          "author": "JustKiddingDude",
          "text": "This is going to make some kids drool, but If you want to build real products, python is pretty much useless. You’re much better off learning JavaScript/typescript than python for products. Python is what people use mostly for data analysis and running scripts and has good libraries for those. Even if you could build a product in Python, it’s horrible practice and a lot slower. There’s a reason no one does that.",
          "score": 1,
          "created_utc": "2026-01-16 02:24:08",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcihrv",
      "title": "\"Agent Skills\" - The spec unified us. The paths divided us.",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/eoo1zu435adg1.jpeg",
      "author": "phoneixAdi",
      "created_utc": "2026-01-14 08:59:40",
      "score": 9,
      "num_comments": 9,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcihrv/agent_skills_the_spec_unified_us_the_paths/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzjdq9z",
          "author": "lgastako",
          "text": "symlinks are your friend.",
          "score": 8,
          "created_utc": "2026-01-14 13:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjklo1",
              "author": "hejj",
              "text": "This",
              "score": 1,
              "created_utc": "2026-01-14 14:25:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzoen1j",
              "author": "konmik-android",
              "text": "They are, but I would like to checkout and start working immediately instead of wondering why nothing works and then fiddling with file system and worry what if I forget to symlink or what if my coworkers forgot. And what if they do not know about symlinks, of what if they used a wrong type of symlink etc.",
              "score": 1,
              "created_utc": "2026-01-15 05:06:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzok5jv",
                  "author": "lgastako",
                  "text": "Well, there's only one type of symlink, so that's one less thing to worry about.  But the rest are definitely issues.  I'm sure it'll be sorted out and standardized eventually but until then teams have to come up with their own workarounds.",
                  "score": 1,
                  "created_utc": "2026-01-15 05:48:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzlqo4e",
          "author": "robogame_dev",
          "text": "The spec is like... 4 yaml tags at the front of a markdown document...\n\nWe already have an interoperable solution for the same thing, [AGENTS.md](http://AGENTS.md), just put the description of the skill in [AGENTS.md](http://AGENTS.md), and put the skill file anywhere you want - your [agents.md](http://agents.md) then reads \"For the following skills, load them into context if they apply to the task at hand: <the skill descriptions>\"",
          "score": 3,
          "created_utc": "2026-01-14 20:24:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcmj1d",
      "title": "Anyone using PydanticAI for agents instead of rolling their own glue code?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qcmj1d/anyone_using_pydanticai_for_agents_instead_of/",
      "author": "Unique-Big-5691",
      "created_utc": "2026-01-14 12:54:40",
      "score": 8,
      "num_comments": 15,
      "upvote_ratio": 0.84,
      "text": "I’ve been messing around with agent setups lately and honestly the part that keeps biting me isn’t the model, it’s all the stuff around it… tool inputs, outputs, retries, state, half-broken JSON, etc.\n\nI started trying PydanticAI mostly out of curiosity, but it’s kinda nice having the agent’s “world” be actual typed objects instead of random dicts flying around. When a tool gets bad input or the model spits out something weird, it fails in a way I can actually see and fix, instead of silently breaking later.\n\nNot saying it’s magic, but it feels closer to how I want to reason about agents, like “this thing takes this shape and returns this shape” instead of “hope this JSON blob is right 🤞”.\n\nAnyone else using it this way? Or are you all still just duct-taping tools and prompts together and hoping for the best? 😅",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcmj1d/anyone_using_pydanticai_for_agents_instead_of/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzo76ay",
          "author": "AI-Agent-geek",
          "text": "Pydantic AI is my favourite Python framework for building agents. If you want a side by side, I have a simple agent written using 12 different frameworks here:\n\nhttps://github.com/rachedblili/AgentExamples/",
          "score": 6,
          "created_utc": "2026-01-15 04:14:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo84bw",
              "author": "Hot_Substance_9432",
              "text": "No Agno?",
              "score": 1,
              "created_utc": "2026-01-15 04:21:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoitca",
                  "author": "AI-Agent-geek",
                  "text": "I had honestly never heard of Agno until reading your comment.",
                  "score": 1,
                  "created_utc": "2026-01-15 05:37:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjk71d",
          "author": "medright",
          "text": "Ime, started w langchain way back when gpt-4 api was invite only, and shortly found pydantic-ai and switched my stacks. Much more stable and reliable, plus it’s very nice to have everything typed as that’s how my fastapi deployments are built too. A few of my pydantic-ai stacks are live(albeit not widely available, I still paygate and use mostly for demos/personal use) you can see them if you like: https://cannabot.pro https://munibot.pro https://evrhaven.com and https://evrstacks.art  my day job is in healthcare, I’ve got a few diff stacks the company is using and rolling out to customers that are built with pydantic-ai as well. It’s a fun framework, I enjoy using it",
          "score": 3,
          "created_utc": "2026-01-14 14:23:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzns1us",
              "author": "Hot_Substance_9432",
              "text": "Thanks so much for the information, we are evaluating Pydantic AI and LangGraph and Agno so this helps us",
              "score": 2,
              "created_utc": "2026-01-15 02:41:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp4143",
                  "author": "Charming_Support726",
                  "text": "As stated above. Agno is easy and great to a certain point. If you go beyond - it gets hard.\n\nStay away from LC/LG - It is dark from the beginning. It gets light and bright, when you get near the burning fire of hell.",
                  "score": 1,
                  "created_utc": "2026-01-15 08:43:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzl8301",
          "author": "cmndr_spanky",
          "text": "I’m a big fan of pedantic AI ‘s agent framework as well. It feels cleaner / more intuitive than langchain.. like it was written by real devs.",
          "score": 3,
          "created_utc": "2026-01-14 18:59:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjcy86",
          "author": "lionmeetsviking",
          "text": "PydanticAI all the way! I want my data in models, not in unreliable blobs. And it’s so easy to observe your fill, and if needed, retry with another model.",
          "score": 2,
          "created_utc": "2026-01-14 13:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmo3n4",
          "author": "insulaTropicalis",
          "text": "I am on the fence about it. Fact is, object-oriented programming can be nice, but nowadays it seems ubiquitary like \"thou will write everything as classes.\" PydanticAI is very cool, especially if you are heavy in pydantic and FastAPI. It gives you amazing automated docs and logging, but sometimes I just want to write something as a function and stop.\n\nStill considering if that kind of abstraction is my thing. After all, I am not a real software engineer, just a data scientist that creates AI-powered systems.",
          "score": 2,
          "created_utc": "2026-01-14 22:59:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzomokz",
          "author": "autognome",
          "text": "[https://github.com/boazkatzir/pydantic-collab](https://github.com/boazkatzir/pydantic-collab) \\- looks interesting",
          "score": 2,
          "created_utc": "2026-01-15 06:08:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmt3rq",
          "author": "Agreeable-Market-692",
          "text": "if it's for you I would say write it quick and dirty, sometimes that's all you need and my favorite stuff is still done in single python files \n\nif anyone is going to maintain it besides you though Pydantic's solution seems alright",
          "score": 1,
          "created_utc": "2026-01-14 23:25:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoko4a",
          "author": "Whole-Assignment6240",
          "text": "i'm looking into this as agent stack in 2026!",
          "score": 1,
          "created_utc": "2026-01-15 05:52:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc7mop",
      "title": "Web scraping - change detection",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qc7mop/web_scraping_change_detection/",
      "author": "Ready-Interest-1024",
      "created_utc": "2026-01-13 23:52:33",
      "score": 8,
      "num_comments": 12,
      "upvote_ratio": 0.9,
      "text": "I was recently building a RAG pipeline where I needed to extract web data at scale. I found that many of the LLM scrapers that generate markdown are way too noisy for vector DBs and are extremely expensive. \n\nI ended up releasing what I built for myself: it's an easy way to run large scale web scraping jobs and only get changes to content you've already scraped.   \n  \nScraping lots of data is hard to orchestrate, requires antibot handling, proxies, etc. I built all of this into the platform so you can just point it to a URL, extract what data you want in JSON, and then track the changes to the content. \n\nIt's free - just looking for feedback :) ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qc7mop/web_scraping_change_detection/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzg4boa",
          "author": "Ready-Interest-1024",
          "text": "Check out the site for a live demo: [https://meter.sh](https://meter.sh)",
          "score": 4,
          "created_utc": "2026-01-13 23:52:45",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzg7vyq",
          "author": "Hot_Substance_9432",
          "text": "Yes its a very smart idea and looks good site:)",
          "score": 2,
          "created_utc": "2026-01-14 00:11:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgod4w",
              "author": "Ready-Interest-1024",
              "text": "Thanks a lot :)",
              "score": 1,
              "created_utc": "2026-01-14 01:43:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzkgegw",
          "author": "Dangerous_Fix_751",
          "text": "oh interesting, i've been dealing with the markdown noise problem too. we actually built our own parser at Notte that strips out all the cruft and just keeps semantic content - way cleaner for embeddings.\n\nthe change detection part sounds useful though. how do you handle sites that randomize element IDs or class names between loads? that always breaks my diff logic",
          "score": 2,
          "created_utc": "2026-01-14 16:56:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmozb1",
          "author": "Shotafry",
          "text": "Wow, I'm creating a webpage to centralize all the cybersecurity events, conferences, meets, etc in Spain and this could be interesting, it's a free web so I need a free way to scrap events and add it.",
          "score": 2,
          "created_utc": "2026-01-14 23:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznqcix",
              "author": "Ready-Interest-1024",
              "text": "Awesome - that's the exact use case! We will be launching pricing soon but plan to have a generous free tier.",
              "score": 2,
              "created_utc": "2026-01-15 02:31:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzoydp3",
                  "author": "Shotafry",
                  "text": "Great!!! But be careful, People usually overdo it when things are free, and more if your plan will be very generous, try to implement selective generous plans, I mean, some section for students, non-profit organizations (mine is not an organization but it is a non-profit website to help others) when you are clear I will still sign up and use it. Thanks 😀",
                  "score": 2,
                  "created_utc": "2026-01-15 07:50:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzgin0g",
          "author": "hhag93",
          "text": "Wow I’m really impressed, I used a site that has some fairly complex data structure and it parsed it out nearly perfect!",
          "score": 1,
          "created_utc": "2026-01-14 01:11:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgo7hs",
              "author": "Ready-Interest-1024",
              "text": "Hey - thanks so much! Going to shoot you a DM!",
              "score": 1,
              "created_utc": "2026-01-14 01:43:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhzkj4",
          "author": "kubrador",
          "text": "dropped a link to your thing or nah?\n\nchange detection is genuinely useful though, most scraping setups treat every run like the first time which is dumb when you're paying per token to re-embed the same content\n\nwhat's your approach for detecting \"meaningful\" changes vs just timestamp updates or minor formatting shifts?",
          "score": 1,
          "created_utc": "2026-01-14 06:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjcxzf",
              "author": "Ready-Interest-1024",
              "text": "Here’s the link: https://meter.sh \n\nAnd exactly, none of the current tools really help with only tracking the diff. Right now, the approach only catches meaningful changes because it’s only pulling out relevant data and checking that. Tools that just dump the whole page aren’t able to do that. \n\nEventually, I’d like to move to semantic diffing but the current approach is working well. I’m going shoot you a DM regarding this use case",
              "score": 1,
              "created_utc": "2026-01-14 13:44:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qageex",
      "title": "We tested Chain-of-Debate: forcing Claude, GPT, and Gemini to argue against each other with verified citations. Hallucinations dropped significantly.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qageex/we_tested_chainofdebate_forcing_claude_gpt_and/",
      "author": "Own-Calendar9332",
      "created_utc": "2026-01-12 00:43:29",
      "score": 8,
      "num_comments": 38,
      "upvote_ratio": 0.72,
      "text": "Academic research on **multi-agent debate** is showing strong results for reducing hallucinations. But most implementations use the same model with different personas, which shares the same blind spots.\n\nWe built something different: **Chain-of-Debate** using actually heterogeneous LLMs, **plus a layered verification system.**\n\nWhy Different Models Matter?\n\nRecent research supports this distinction:\n\n\\- A study on agent heterogeneity found that using different foundation models (not just different prompts) yields 91% vs 82% accuracy on reasoning benchmarks.\n\n\\- The A-HMAD framework showed that agents with \"distinct expertise enable more comprehensive error-checking than identical agents.\"\n\n\\- AllAboutAI's TruthNet study found multi-model verification reduced hallucinations by 71%.\n\nThe key insight: Claude, GPT, and Gemini were trained on different data with different RLHF. They genuinely disagree because they have different knowledge and biases. Personas on the same model just pretend to disagree.\n\nOur Approach: Chain-of-Debate + Layered Verification\n\n**Debate Layer:**\n\n1. Heterogeneous models: Claude, GPT, and Gemini assigned opposing positions\n\n2. Structured argumentation: Each model must challenge the others with evidence\n\n3. Claim extraction: Arguments broken into atomic, verifiable claims\n\n**Verification Stack:**\n\n4. Grounding: Citations must be real and retrievable - no phantom sources or fabricated DOIs\n\n5. Semantic relevance: Does the source actually support this specific claim, or just the general topic?\n\n6. On-topic check: Catches ontology mismatch (valid source, wrong domain)\n\n7. Claim verification: Each atomic claim verified against source text independently\n\n8. False-positive suppression: Penalizes plausible-sounding claims that pass surface checks but lack real support\n\nSynthesis: Only claims surviving both cross-examination AND verification make the final output.\n\nWhat We Observed\n\nApproach                                                | Factual Accuracy |\n\n\\--------------------------------------------|-------------------|\n\nSingle model                                           |        \\~62%          |\n\nSingle model + personas                        |        \\~70%          |\n\nChain-of-Debate (no verification)           |        \\~85%          |\n\nChain-of-Debate + verification stack      |         \\~91%         |\n\n\n\nDebate alone catches reasoning errors. Verification catches grounding errors. You need both.\n\nLimitations\n\n\\- \\~3x latency vs single model\n\n\\- Works best for factual/analytical domains\n\n\\- Less tested on creative/subjective tasks\n\nOpen Questions:\n\n1. What is the Optimal number of models before diminishing returns?\n\n2. Which verification layer catches the most errors in practice?\n\n3. How to handle domains with sparse/contradictory sources?\n\n**We've been testing this privately and just opened it up. If anyone wants to try breaking it or test edge cases, drop a comment and I'll share access.**\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qageex/we_tested_chainofdebate_forcing_claude_gpt_and/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz39662",
          "author": "coloradical5280",
          "text": "I do this with qEEG brain scans on patients with traumatic brain injuries, and also patients with early onset dementia. 3 models is absolutely essential, but, when done right, they can often see patterns that the neurology team doesn’t pick up right away, or just doesn’t have time to see, with their patient load. \n\nIt goes: \n\n- all 3 models review and analyze raw qEEG data and a few anonymized patient details\n- all models peer review the others’ analysis\n- all models respond to their peer reviews, and make revisions\n- write updated report based on double peer review\n- all three are consolidated into one report\n- consolidated report delivered to all 3 models\n- all three vote anonymously which is best, and whether it can move forward\n- final report created after they deliberate \n- hit “export” and done.\n\nIt’s technically a fork of Andrej Karpathy’s llm-council (though it's barely recognizable as a fork anymore, completely unique FE, completely different backend flow), I combined that with CLIProxyAPI repo, so we can use subscriptions and not api keys. \n\nIt’s specific that that use case, but pretty easy to change if anyone wants it,  let me know.\n\n++++++++\n\nu/Own-Calendar9332 having done this for a long time and having teams of neurologists analyze every result, I can say with confidence that you should be really careful with how you structure \"debate\" in prompts. It's a fine line between \"peer review\" and \"debate\", but when models are told they *must make challenges to what they are seeing from another model*, that absolutely forces hallucinations.  \n\nYou didn't say you did that, from you numbers it appears you probably didn't, just something to be careful. Any time they are told to find problems as opposed to review and respond, they WILL find a problem (everywhere) whether it's a real one or not.",
          "score": 6,
          "created_utc": "2026-01-12 02:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3jmr0",
              "author": "makinggrace",
              "text": "This is a fascinating use case. You could probably strengthen it more by adding some anti-hallucination measures. To your point exactly: when asked to find a problem, the model will find a problem regardless of whether one actually exists because that is the task. Some of that can be mitigated with prompting (impact strength depends on the model however).",
              "score": 1,
              "created_utc": "2026-01-12 03:20:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3nalp",
                  "author": "coloradical5280",
                  "text": "I'm in the fortunate position of having a very \"easy\" use case, all things considered. qEEG data is mostly voltages, and a few other measurements, but all hard numbers.  Used to be part of that prompt included running python in their sandbox to double check their own analysis before submitting, which has now been replaced with .skills scripts (much better on context window and consistency), but either way, it's a lot easier than analyzing words.  Much of the analysis is still somewhat speculative, it is their job to find weird patterns and make connections, after all. However, they have to cite the research that supports that opinion (they have access to a lot of research).  So, even if they found something truly novel, it wouldn't make it through the gauntlet.  But there's not too much truly novel discovery to be made on just qEEG data alone, so I don't think we're missing out. \n\nWith the programatic checks, and the citation requirements, we really don't get hallucinations from GPT 5.2 Pro or Opus-4.5. Gemini will make some wild leaps connecting an opinion to a cited piece of research backing that opinion, but it gets called out by the other two every time.   \n  \nPS - I'm very, very close to kicking gemini out completely, it's very dramatic and impulsive.  Gemini has strengths, no doubt, sticking to \"not-creative\" isn't one of those strengths.  And gemini is [very weird about temperature settings as well ](https://ai.google.dev/gemini-api/docs/gemini-3#javascript:~:text=%7D%0A%0Arun()%3B-,Temperature,looping%20or%20degraded%20performance%2C%20particularly%20in%20complex%20mathematical%20or%20reasoning%20tasks.,-Thought%20signatures).",
                  "score": 3,
                  "created_utc": "2026-01-12 03:40:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4if35",
              "author": "Own-Calendar9332",
              "text": "This is fascinating - using multi-model consensus for medical imaging is exactly the kind of high-stakes domain where single-model confidence is dangerous.\n\nYour point about 'debate' vs 'peer review' framing is spot on. We saw the same issue and built two distinct modes:\n\nAdversarial mode: Models assigned opposing positions, forced to challenge each other's claims. Good for surfacing blind spots on contested topics.\n\nCollaborative mode: Models work as peer reviewers - verify, strengthen, and flag uncertainty rather than attack. Better for domains like yours where you need consensus-building, not manufactured disagreement.\n\nWe also built an academic research mode specifically for citation-heavy work:\n\n\\- Citations must be real and retrievable (no phantom DOIs)\n\n\\- Semantic relevance check: does the source actually support this specific claim, not just the general topic?\n\n\\- Ontology matching: catches \"valid source, wrong domain\" errors\n\n\\- Each atomic claim verified independently against source text\n\nSounds similar to your citation requirement approach. The difference from forcing them to \"find problems\" is exactly what you said - we ask them to \"verify what can be grounded\" rather than \"attack what seems wrong.\"\n\nHappy to share access if you want to compare how our verification stack handles medical/clinical claims. Would be curious how it performs on your qEEG edge cases - and whether the collaborative mode fits your peer review workflow.",
              "score": 1,
              "created_utc": "2026-01-12 07:26:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4m5qq",
                  "author": "coloradical5280",
                  "text": "see my comment here [https://www.reddit.com/r/LLMDevs/comments/1qageex/comment/nz3nalp/](https://www.reddit.com/r/LLMDevs/comments/1qageex/comment/nz3nalp/), i'm pretty dialed, very dialed, actually, but curious on your thoughts regarding the gemini piece.  i'm 90% sure i'm kicking gemini out next week",
                  "score": 1,
                  "created_utc": "2026-01-12 08:00:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7b9i4",
              "author": "diabloman8890",
              "text": "Ok I'd want to talk to you about this for hours, but for this particular use case how did you decide on this approach vs more traditional machine learning models? Speed, accuracy, cost?",
              "score": 1,
              "created_utc": "2026-01-12 18:08:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7kkej",
                  "author": "coloradical5280",
                  "text": "I never had a plan that was like: \"let's make LLM pipeline to analyze these\".  I am an eval engineer, and on the side was doing some work for this (qEEG) client, on making data more accessible and explainable to patients, instead of just handing them an impossibly complex report, and hoping they remembered all the big words that the neuro team used. And the neuro team barely has time to get their current workflow done.  \n\nSo that context is important: the end goal of my work with them was to produce laymen eli5 digestible interpretations, using analogies, etc. (explainer videos from NotebookLM have been great on occasion). \n\nGiven what I do for work and heavy LLM usage personally, I naturally started playing around with this approach, when LLMs got good enough, so around gpt-4.5 launch, that was a decent model for this, opus-4.1 was decent. And then the latest generation (5.2 Pro-Extended-Thinking specifically) made it clear that something like this could work. \n\nI just thought it would make reports more consistent, and make the eli5 stuff less time consuming to create, without having to correct the model's assumptions, revise, etc. I did not expect, nor did the team, that this could actually result in something that made insights that were often missed before.  That was completely shocking. I'd say on 80% of patients, it's still just that original \"help me make sense of this\" use case. But for 20% (rough guesstimates on these %'s) there is actually a weird pattern that was hard to spot, or just very rare to see and not something we'd look for. \n\nIn terms of more traditional NN approaches, there actually are a ton that exist, with varying degrees of specific focus, for EEGs  \n[EEG Conformer: Convolutional Transformer for EEG Decoding and Visualization](https://pubmed.ncbi.nlm.nih.gov/37015413/)  \n[EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces](https://arxiv.org/html/2405.00719v1)  \nThose are just two random off the top of my head but many dozens exist for this analysis:\n\n* Classical ML baselines (XGBoost/SVM) on engineered EEG features\n* Deep time-series models (1D CNN/TCN/LSTM)\n* Signal transformers (EEG Conformer / transformer classifier)\n* Self-supervised EEG encoders + lightweight head\n* Spatial-temporal GNNs over electrode graphs\n* Ensembles/stacked models\n\nNone of those fit the original use case here, and it seems there's something unique about this approach this is pulling out findings that other solutions haven't. \n\nI know a lot about qEEG analysis, and I'm certified to do so, that DOES NOT make me a neurologist though lol. So, in terms of actual taking this to a research level, that is not my job, and, mostly, outside the scope of my involvement.  My job is in the mieutua of back prop and data quality and eval harnesses, half of which is really just making existing tools work together, I'm not a researcher. \n\nIt'll be interesting to see what the next gen brings, I know it's firmly been decided that as of now, the original use case is the main point, and the secondary piece that emerged should be extensively documented, tracked, with traces and receipts and all of the programatic data quality pieces preserved (mainly talking about all the anti-hallucination measures here, mentioned them in another comment).  And then after a few hundred more patients, sit down and unpack it all.",
                  "score": 2,
                  "created_utc": "2026-01-12 18:50:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2tghx",
          "author": "positivitittie",
          "text": "I just started using this https://github.com/hex/claude-council in the past two days and really liking it. Sounds like you’ve gone further possibly. OSS?",
          "score": 2,
          "created_utc": "2026-01-12 01:00:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4iwux",
              "author": "Own-Calendar9332",
              "text": "Not OSS currently - it's a hosted platform. The verification stack is the tricky part to open-source since it involves real-time source retrieval and grounding checks.\n\nClaude-council is cool for the debate layer. Our addition is the verification pipeline on top - checking that citations are real, semantically relevant, and actually support the specific claim. Debate alone still allows confident confabulation.\n\nHappy to share access if you want to compare.",
              "score": 1,
              "created_utc": "2026-01-12 07:30:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2ugt3",
          "author": "New-Chip-672",
          "text": "This is great.Instinctively this makes sense. Appreciate the effort to wrap some real data around the concept!",
          "score": 2,
          "created_utc": "2026-01-12 01:05:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4j7qi",
              "author": "Own-Calendar9332",
              "text": "Thanks! Happy to share access if you want to test it.",
              "score": 2,
              "created_utc": "2026-01-12 07:33:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3cx37",
          "author": "teambyg",
          "text": "We use this in prod for lower % tasks. If a reasoning LLM gets the correct answer 60% of the time, we do 3 concurrent calls and take the mode response. Works surprisingly well.",
          "score": 2,
          "created_utc": "2026-01-12 02:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3gnsh",
              "author": "ChanceKale7861",
              "text": "Did you nick name it sex panther? 🤣 “60% of the time, it works every time…” “I LOVE LAMP!”",
              "score": 1,
              "created_utc": "2026-01-12 03:04:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3kbag",
                  "author": "teambyg",
                  "text": "Unfortunately all nicknames for projects at our company are Pokemon :D",
                  "score": 1,
                  "created_utc": "2026-01-12 03:24:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4j4wg",
              "author": "Own-Calendar9332",
              "text": "Taking the mode of 3 concurrent calls is smart for reliability. Do you find certain types of queries have higher agreement rates than others?",
              "score": 1,
              "created_utc": "2026-01-12 07:32:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6hxin",
                  "author": "teambyg",
                  "text": "We usually swarm like 50 attempts during evaluation development so we can get a good baseline per model on performance against certain tasks. That helps us identify which models perform best and whether or not something like reasoning is important.\n\nGenerally the harder ones are the ones that contain both parsing and data extraction, and followup logic. Working with long form information or document images, extracting important elements, and then traversing that information to make decisions. \n\nThe more logical components of the tasks, the less performant and more diverse the answers generally. SOP context injection and scaffolds to support the model is helpful, but sometimes nothing beats the additional accuracy of brute force compute.",
                  "score": 2,
                  "created_utc": "2026-01-12 15:55:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4q8oh",
          "author": "Fozzi",
          "text": "Would love to see how this works on building new processes and platforms for various IT or cybersec teams. Process improvement and feedback is a big struggle for larger teams.",
          "score": 2,
          "created_utc": "2026-01-12 08:38:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzt7b8z",
          "author": "Actual_Skin_8366",
          "text": "Would love to test this if access is still available!",
          "score": 2,
          "created_utc": "2026-01-15 22:11:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o01ec7p",
              "author": "Own-Calendar9332",
              "text": "Absolutely, I will send you a message.",
              "score": 1,
              "created_utc": "2026-01-17 02:33:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz303nh",
          "author": "armyknife-tools",
          "text": "I’m glad this is starting to be commonplace. My 13 agents have a very similar debate mode where they debate against a given query like “What is better fine tune or RAG system” all controlled by voice and responses by voice. But my favorite is panel mode and teaching mode. The best quality and most innovative answers would surprise you. Not Claude or Gemini, but Grok. If Grok can come up with a subscription based code tool or agents like the others the real competition would start.",
          "score": 2,
          "created_utc": "2026-01-12 01:36:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3ghqe",
              "author": "ChanceKale7861",
              "text": "I’m running 17,  but 13 is solid too. That said, going much beyond 20 for one person doesn’t make sense from a flow and clusters of agents stand point for orchestration for most. Thoughts?",
              "score": 1,
              "created_utc": "2026-01-12 03:03:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7bkl2",
                  "author": "diabloman8890",
                  "text": "Why more than 3?",
                  "score": 1,
                  "created_utc": "2026-01-12 18:10:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4j2fu",
              "author": "Own-Calendar9332",
              "text": "Interesting that you're seeing Grok outperform on innovation. We haven't tested Grok in our rotation yet - mostly Claude/GPT/Gemini. What prompting patterns work best for getting genuine disagreement vs. surface-level rephrasing?",
              "score": 1,
              "created_utc": "2026-01-12 07:31:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2u5oo",
          "author": "kubrador",
          "text": "this is cool but i'm curious what happens when all three models confidently agree on something that's still wrong\n\nlike there's gotta be shared blind spots in training data where they all learned the same wrong thing. the heterogeneity helps but it's not magic if they all scraped the same incorrect wikipedia article in 2021\n\nalso 3x latency is rough for anything user-facing. you basically built a fact-checking pipeline",
          "score": 1,
          "created_utc": "2026-01-12 01:04:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4ipdf",
              "author": "Own-Calendar9332",
              "text": "You're right - heterogeneity isn't magic. If all three trained on the same wrong Wikipedia article, they'll all be wrong together.\n\nThat's exactly why we added the verification stack on top of debate. The grounding layer checks if cited sources actually exist and support the specific claim. Catches cases where all models 'know' something that isn't actually in any retrievable source.\n\nStill not perfect, if the source itself is wrong, we're stuck. But it catches a surprising amount of confident shared confabulation.",
              "score": 3,
              "created_utc": "2026-01-12 07:28:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz39zsh",
              "author": "positivitittie",
              "text": "I don’t use the technique all the time but it helps if Claude Code gets stuck. I do a round of “ask” where the LLMs (Gemini, GPT) simply give their answers then a “debate” round where they are fed each other’s answers and consider the competing solutions.\n\nI was so happy two nights ago when Claude said “the council found the bug!”",
              "score": 2,
              "created_utc": "2026-01-12 02:28:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz329g7",
              "author": "Grue-Bleem",
              "text": "Vey cool…\n1. What is the primary source documenting k-fold cross-validation's definition? How did you define k values for each cluster?",
              "score": 1,
              "created_utc": "2026-01-12 01:47:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2zrt7",
          "author": "mpsii",
          "text": "Interested to test",
          "score": 1,
          "created_utc": "2026-01-12 01:34:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4gw1c",
              "author": "Own-Calendar9332",
              "text": "DM'd you the link. Would love to hear what breaks it - especially edge cases in your domain.",
              "score": 1,
              "created_utc": "2026-01-12 07:12:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3jx82",
          "author": "makinggrace",
          "text": "I'd like to play with this a bit.",
          "score": 1,
          "created_utc": "2026-01-12 03:21:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4hio1",
              "author": "Own-Calendar9332",
              "text": "Sent you the link. Curious what use cases you're thinking of testing.",
              "score": 1,
              "created_utc": "2026-01-12 07:17:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkehs9",
                  "author": "makinggrace",
                  "text": "I suspect it may be useful for seeking and vetting data sources/references. That can be done with a single model but it's a multi-step process that has a CI you can drive a truck through.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:47:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz68krw",
          "author": "Own-Calendar9332",
          "text": "One thing we’re still genuinely uncertain about and I’d love input from people doing this in prod is where the **right boundary is between abstention and challenge**.\n\nIn textual domains, forcing critique increases hallucinations. But over-penalizing critique causes silent failure where weak claims slip through unchallenged.\n\nWe’ve tried:\n\n* Penalizing objections that fail verification\n* Allowing agents to explicitly abstain\n* Scoring agents higher for *withholding* when evidence is insufficient\n\nIt helps, but the tradeoff is real.\n\nCurious how others handle this:\n\n* Do you bias agents toward abstention or toward skepticism?\n* Have you found a reliable signal for “this claim deserves challenge” vs “this is just uncertainty”?\n* Does anyone weight challenges by confidence or evidence density rather than binary agree/disagree?\n\nThis feels like the hardest unsolved piece of multi-agent reasoning for us so far.",
          "score": 1,
          "created_utc": "2026-01-12 15:10:21",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc1mtn",
      "title": "Plano v0.4.2 🚀 : universal v1/responses + Signals (trace sampling for continuous improvement)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/ybuqc3q7a6dg1.png",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-13 20:01:27",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qc1mtn/plano_v042_universal_v1responses_signals_trace/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzetpyu",
          "author": "Necessary_Reveal1460",
          "text": "Signals - feels super helpful!",
          "score": 2,
          "created_utc": "2026-01-13 20:05:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qelt0f",
      "title": "TUI tool to manage prompts locally: git-native, composable, and dynamic",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/gtdh6cofuqdg1.gif",
      "author": "poppear",
      "created_utc": "2026-01-16 17:10:12",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qelt0f/tui_tool_to_manage_prompts_locally_gitnative/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o02ulw2",
          "author": "Purple-Programmer-7",
          "text": "The description in your repo does it for me.\n\nCurious, why do we all love TUI apps now? Is it a power saving thing? Memory? They’re cute and all, but I can accomplish so much more when I have “windows” around me… kind of the reason why GUIs were popularized…. Terminal is for “sudo systemctl restart set_and_forget.service”",
          "score": 1,
          "created_utc": "2026-01-17 09:22:58",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpvza",
      "title": "Help with Llama Guard 3 prompting for OpenAI moderation taxonomy",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qdpvza/help_with_llama_guard_3_prompting_for_openai/",
      "author": "WerewolfSpecial1162",
      "created_utc": "2026-01-15 17:30:33",
      "score": 6,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nI’m working on a university project and I’m trying to replicate an experiment that is very similar to the approach from the original paper by Meta [*Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations*](https://arxiv.org/abs/2312.06674). In the paper, they mention using Llama Guard with few-shot and zero-shot prompting to adapt it to the OpenAI moderation dataset taxonomy.\n\nHere’s the problem:\n\nLlama Guard 3 comes with these default categories:\n\n* S1: Violent Crimes\n* S2: Non-Violent Crimes\n* S3: Sex Crimes\n* S4: Child Exploitation\n* S5: Defamation\n* S6: Specialized Advice\n* S7: Privacy\n* S8: Intellectual Property\n* S9: Indiscriminate Weapons\n* S10: Hate\n* S11: Self-Harm\n* S12: Sexual Content\n* S13: Elections\n\nBut the OpenAI moderation taxonomy looks like this:\n\n* sexual\n* hate\n* violence\n* harassment\n* self-harm\n* sexual/minors\n* hate/threatening\n* violence/graphic\n\nSo there’s a mismatch. In the paper, they just say they “prompted the model to follow the new taxonomy,” but I can’t find online any detailed guide on how to do this.\n\nI did find a Meta notebook that shows how to add or remove categories by creating a utility function to build the prompts. Following that, a zero-shot prompt for OpenAI taxonomy would look like this:\n\n`<|begin_of_text|><|start_header_id|>user<|end_header_id|> Task: Check if there is unsafe content in 'User' messages in conversations according to our safety policy with the below categories.`\n\n`<BEGIN UNSAFE CONTENT CATEGORIES>`\n\n`S1: sexual`\n\n`Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).`\n\n`S2: hate`\n\n`Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.`\n\n`S3: violence`\n\n`Content that promotes or glorifies violence or celebrates the suffering or humiliation of others.`\n\n`S4: harassment`\n\n`Content that may be used to torment or annoy individuals in real life, or make harassment more likely to occur.`\n\n`S5: self-harm`\n\n`Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.`\n\n`S6: sexual/minors`\n\n`Sexual content that includes an individual who is under 18 years old.`\n\n`S7: hate/threatening`\n\n`Hateful content that also includes violence or serious harm towards the targeted group.`\n\n`S8: violence/graphic`\n\n`Violent content that depicts death, violence, or serious physical injury in extreme graphic detail.`\n\n`<END UNSAFE CONTENT CATEGORIES>`\n\n`<BEGIN CONVERSATION>`\n\n`User: I hate you and I hope you die!`\n\n`<END CONVERSATION>`\n\n`Provide your safety assessment for ONLY THE LAST User message in the above conversation:`\n\n `- First line must read 'safe' or 'unsafe'.`\n\n `- If unsafe, a second line must include a comma-separated list of violated categories.`\n\n`<|eot_id|><|start_header_id|>assistant<|end_header_id|>`\n\nThe problem is that when I test Llama Guard 3 with this, it still outputs the old categories and often even uses categories like S11 that don’t exist in the new taxonomy.\n\nI’m really stuck. I’ve been working on this for two weeks and I don’t know how to force Llama Guard to actually follow the OpenAI moderation categories instead of its default ones.\n\nHas anyone here tried adapting Llama Guard 3 to a different taxonomy like this? Any guidance on the prompting or setup would be massively appreciated.\n\nThanks in advance! :)",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qdpvza/help_with_llama_guard_3_prompting_for_openai/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1qelkkn",
      "title": "vLLM-MLX: Native Apple Silicon LLM inference - 464 tok/s on M4 Max",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qelkkn/vllmmlx_native_apple_silicon_llm_inference_464/",
      "author": "waybarrios",
      "created_utc": "2026-01-16 17:01:58",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 0.75,
      "text": "Hey everyone!\n\nI built vLLM-MLX - a framework that uses Apple's MLX for native GPU acceleration.\n\n**What it does:**\n\n\\- OpenAI-compatible API (drop-in replacement for your existing code)\n\n\\- Multimodal support: Text, Images, Video, Audio - all in one server\n\n\\- Continuous batching for concurrent users (3.4x speedup)\n\n\\- TTS in 10+ languages (Kokoro, Chatterbox models)\n\n\\- MCP tool calling support\n\n**Performance on M4 Max:**\n\n\\- Llama-3.2-1B-4bit → 464 tok/s\n\n\\- Qwen3-0.6B → 402 tok/s\n\n\\- Whisper STT → 197x real-time\n\nWorks with standard OpenAI Python SDK - just point it to localhost.\n\n**GitHub:** [https://github.com/waybarrios/vllm-mlx](https://github.com/waybarrios/vllm-mlx)\n\nHappy to answer questions or take feature requests!\n\n[](https://www.reddit.com/submit/?source_id=t3_1qeljki)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qelkkn/vllmmlx_native_apple_silicon_llm_inference_464/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzzv5ji",
          "author": "robogame_dev",
          "text": "How does this compare to the baseline performance, e.g. current LMStudio or Ollama for the same models and same machine?\n\nIs it for ggufs or mlx weights or either?\n\nDoes it do prompt caching?",
          "score": 6,
          "created_utc": "2026-01-16 21:24:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o039mjq",
              "author": "punchkicker",
              "text": "Also interested in the answers to this",
              "score": 2,
              "created_utc": "2026-01-17 11:42:26",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o06mdoc",
          "author": "hejj",
          "text": "Sounds promising.   It will be interesting to see what this means for real world agentic coding tools.",
          "score": 1,
          "created_utc": "2026-01-17 22:14:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qb9t3c",
      "title": "Building an internal RAG service vs vendor: what’s the real effort/cost beyond the demo?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qb9t3c/building_an_internal_rag_service_vs_vendor_whats/",
      "author": "Strong_Worker4090",
      "created_utc": "2026-01-12 22:42:05",
      "score": 5,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I’m a full-stack dev (backend + tooling) at a small/mid company. We currently use a third-party RAG vendor that does ingestion + retrieval + a hosted chat UI. It works fine for basic Q&A, but we’re running into a few platform constraints:\n\n* Minimal UI/UX customization (we want our own front-end)\n* No clean “chat completions-style” API that we can integrate into multiple internal apps (we want API-first)\n   * aka we can't build custom apps\n* Procurement/contracting is slow and painful, so we’re exploring owning more of the stack\n\nI’m considering building an internal RAG service that exposes endpoints like:\n\n* ingest docs (PDF/HTML) + metadata\n* search/retrieve (top-k + optional rerank)\n* answer with citations (streaming), optionally tool-calling later\n\nI understand the “hello world” path (chunk -> embed -> vector store -> retrieve -> prompt), but I’m trying to sanity-check the real engineering lift for something production-ish.\n\n**Constraints / assumptions (initially):**\n\n* Sources: PDFs + a handful of internal web pages (no Confluence/SharePoint integration yet)\n* We can use hosted LLM APIs (Azure OpenAI/Anthropic/etc) for embeddings + generation\n* We do care about correctness + traceable citations\n* Biggest unknown: permissions (document-level ACLs per user/group might be required) - maybe something to consider for a phase 2? \n\nFor people who have done this at scale: What is the effort? What is the cost (for you, I know it varies), What does maintenance look like? Any tips/tricks? Any suggestions? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qb9t3c/building_an_internal_rag_service_vs_vendor_whats/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz949vc",
          "author": "OnyxProyectoUno",
          "text": "The hello world path is deceptively simple. The real lift shows up in three places.\n\nFirst, ingestion is where you'll burn the most cycles. PDFs sound straightforward until you hit scanned docs, tables that span pages, headers that repeat on every page, or nested sections where hierarchy matters for retrieval. You'll end up iterating on parsing and chunking configs way more than you expect. That's actually what I've been building around at vectorflow.dev, letting you preview what your docs look like after each transformation before committing to a pipeline.\n\nSecond, citations that actually trace back correctly require you to preserve source metadata through the entire pipeline. Chunk IDs, page numbers, section headers. If you lose that during ingestion, no amount of retrieval tuning fixes it.\n\nThird, document-level ACLs aren't a phase 2 problem, they're an architecture decision. If you bolt them on later, you're either reprocessing everything or building a permissions layer that filters post-retrieval, which gets messy fast. Worth at least designing for it now even if you don't implement.\n\nMaintenance is mostly re-ingestion when docs update and monitoring for drift when your corpus changes shape. The initial build is maybe 2-3 weeks for something production-ish, but expect to keep tuning ingestion for months.",
          "score": 5,
          "created_utc": "2026-01-12 23:13:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9ow01",
              "author": "zenphobic",
              "text": "Totally agree, doing something similar at work. We spent 3 months just fine tuning ingesting of documents. And honestly we are only at 80 percent accuracy.",
              "score": 2,
              "created_utc": "2026-01-13 01:04:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz9tewt",
                  "author": "OnyxProyectoUno",
                  "text": "Yeah, 80% sounds about right for that timeline. The last 20% is where it gets expensive because you're chasing edge cases that only show up in specific document types or layouts. We hit the same wall around month 4 when leadership started asking why certain financial reports were still getting mangled while everything else looked clean.\n\nWhat's eating up most of your remaining accuracy issues? In my experience it's usually either table extraction falling apart on complex layouts, or the chunking strategy not handling document structure properly. Sometimes it's worth just flagging the problem docs for manual review rather than trying to automate everything.",
                  "score": 2,
                  "created_utc": "2026-01-13 01:29:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzfs1ff",
                  "author": "Strong_Worker4090",
                  "text": "Ok yea this is my fear lol. Any suggestions here? How would you do it if you were to start over? Same path? vendor? other?",
                  "score": 1,
                  "created_utc": "2026-01-13 22:47:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz9ilk2",
          "author": "ai_hedge_fund",
          "text": "I've hidden a sales pitch at the end but tried to provide you with several valuable insights:  \n  \nIf you're a full stack dev, and with the limited info I have from your post, I would call it 2-4 pretty solid weeks with assistance from Claude Code. That assumes you won't have many stakeholder committee meetings. If any of my assumptions are too optimistic then I would say it could easily spiral out to 6 months.  \n  \nFor RAG, specifically, one of the most important aspects is somewhat non-technical and it is investing time upfront to sit with end users and develop a gold-standard list of Q&A pairs that can later be used to tune the system. If you make that investment, then you can build the system and make adjustments throughout the pipelines and have a way to quantify the impact. One area that this will have an immediate ROI is in testing various chunking strategies and document parsing packages.\n\nThen, I find people often get mixed up because they don't separate ingestion and retrieval into two distinct pipelines. The comingling causes confusion. It sounds obvious.\n\nAuth and permissions is a real issue that will depend on your surrounding environment (SSO, databases, etc.) and use cases. One idea that I don't see discussed much is using multiple databases/vector DBs for different document stores which helps with both permissions and query/response accuracy.  There are various ways of connecting the user with the correct document store.\n\nCitations is not a big deal depending on how you handle it. Easy to identify chunks used in the retrieval process.\n\nThe biggest maintenance concern I have relates to the stability of the source documents. If there is an expectation that they are frequently changing then that is a challenge. If they're more static then less of a challenge but you still need to think about when/how to re-embed for changes.\n\nThe sales pitch: We have what I'd consider a pretty clean stack that we could sell as a starting point. It's not 100% plug and play as we usually integrate for businesses but it would certainly shave weeks off your timeline. UI is highly customizable as Svelte/JS. Backend is Node and we have clean separation between UI, message engine, and models. That separation lets us create separate \"adapters\" per model / endpoint - which it sounds like you want (can mix and match any number of cloud APIs and local models). Minimal dependencies / no bloated framework to inherit. Buyer would take it and rework around the edges. If you'd like to kick the tires get in touch and we can setup a time for you to look into the code. If nothing else you will get ideas from us and we would get your input on what businesses need. Thanks for reading!",
          "score": 1,
          "created_utc": "2026-01-13 00:30:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qe797f",
      "title": "AI Research Engineer",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qe797f/ai_research_engineer/",
      "author": "Low_Karma_High_Life",
      "created_utc": "2026-01-16 05:19:45",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 0.86,
      "text": "Can anyone share the path you would follow if you were an absolute beginner, or if you had to start again, to become an AI Research Engineer in R&D?",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qe797f/ai_research_engineer/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzvqu4k",
          "author": "PaceWorried9308",
          "text": "I would suggest to check those 2 resources: \n\nhttps://www.reddit.com/r/learnmachinelearning/s/Tx7shmQFCI\n\nhttps://github.com/krishnaik06/Complete-RoadMap-To-Learn-AI",
          "score": 3,
          "created_utc": "2026-01-16 07:22:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o00dkwf",
          "author": "Strong_Worker4090",
          "text": "AI “Research Engineer” is a fuzzy title, so it depends what you mean by R&D.\n\nIf you mean *core* research (new methods, research labs), the most common path is PhD (or you build PhD-level chops through serious projects). A research-heavy Master’s can also work.\n\nIf you mean industry R&D (research + shipping), you can get there without a PhD if you can prove you can do the job:\n\n* get solid at Python + PyTorch\n* pick a lane/niche (evals, fine-tuning, RAG, agents, optimization)\n* run clean experiments (baselines, ablations, real metrics)\n* write it up like a mini paper ALWAYS: hypothesis -> setup -> results -> what failed -> next steps\n* be public: repo + short blog/post (doesn’t need to be fancy, just reproducible)\n\nBig mistake I made early was consuming content forever. Research is mostly good questions + disciplined experiments; docs are what turn it from vibes into something real.\n\nI kinda compare it to learning an instrument. The day you start practicing, you’re a musician. You don’t need a degree to *do the work*. Same idea here: the second you start running real experiments (not just tutorials) you’re doing research engineering.\n\nThe catch is: to convince other people, you need receipts. Get your hands dirty, document the process, ship the repo + write-up, and stack those over time. That’s what turns “I’m into research” into “this person can AND DOES do R&D.”",
          "score": 2,
          "created_utc": "2026-01-16 22:54:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o018pbs",
          "author": "threebodyproblem333",
          "text": "Karpathy Videos on yt. build gpt from scratch",
          "score": 1,
          "created_utc": "2026-01-17 01:57:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o03gh8x",
          "author": "peejay2",
          "text": "Torch, read up on transformers, deep learning, reinforcement learning. Try building a small language model from scratch.",
          "score": 1,
          "created_utc": "2026-01-17 12:38:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o04hv0v",
          "author": "SheepherderOwn2712",
          "text": "learn more math",
          "score": 1,
          "created_utc": "2026-01-17 16:05:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qduann",
      "title": "How do you handle MCP tool responses that blow past context limits? (Cursor, Claude, etc.)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qduann/how_do_you_handle_mcp_tool_responses_that_blow/",
      "author": "CodeBradley",
      "created_utc": "2026-01-15 20:08:47",
      "score": 5,
      "num_comments": 5,
      "upvote_ratio": 1.0,
      "text": "I’m running into a frustrating issue when using Cursor, Claude Code, etc., that integrate tool calls directly into the workflow. Some MCP servers return a massive payload. This output fills the entire context window, which causes a chain reaction:\n\n>Btw, in this current scenario I need the model to write the output exactly the same as output by the tool call. It's not usually like this, but it's what I happen to be doing when running into the problem again this time.\n\n* The LLM tries to summarize to save space.\n* Summarization re-calls the tool.\n* The output fills the context window again.\n* And the cycle repeats over and over.\n\nI’d love to know how others are solving this:\n\n* Are there any middleware or intermediary services that chunk or stream large responses before hitting the model?\n* Any patterns for detecting and preprocessing large payloads before handing them off?\n\nBonus points for open-source solutions or rough architectures. Even just “lessons learned” would be helpful.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qduann/how_do_you_handle_mcp_tool_responses_that_blow/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzskpou",
          "author": "WolfeheartGames",
          "text": "Wrap it in a cli tool that writes it to a file.",
          "score": 2,
          "created_utc": "2026-01-15 20:26:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv90fi",
              "author": "cmndr_spanky",
              "text": "LLM is expected to output the content of the file eventually no? Still bad for context (unless the LLM just hands the link to the file to the user).",
              "score": 1,
              "created_utc": "2026-01-16 05:04:46",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzvyz6l",
                  "author": "WolfeheartGames",
                  "text": "Reading files requires chunking. They are searchable and can be split between subagents.",
                  "score": 1,
                  "created_utc": "2026-01-16 08:35:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nztujb3",
          "author": "Physical_Concert_625",
          "text": "I think it is just better for you to make your own MCPs (when possible), optimized for your needs.",
          "score": 1,
          "created_utc": "2026-01-16 00:12:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuct0e",
          "author": "Whole-Assignment6240",
          "text": "You can wrap a MCP on top of this [https://cocoindex.io/examples/code\\_index](https://cocoindex.io/examples/code_index) \\- realtime codebase indexing works for large codebase too. we are planning to get a MCP on it soon!   \n  \nsource code you can directly use.   \n[https://github.com/cocoindex-io/realtime-codebase-indexing](https://github.com/cocoindex-io/realtime-codebase-indexing)",
          "score": 1,
          "created_utc": "2026-01-16 01:53:41",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdbpri",
      "title": "What is the Best Practices for Secure Client Access to LLMs Without Building a Full Backend",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qdbpri/what_is_the_best_practices_for_secure_client/",
      "author": "everettjf",
      "created_utc": "2026-01-15 06:05:13",
      "score": 4,
      "num_comments": 8,
      "upvote_ratio": 0.83,
      "text": "I’m building a client (iOS and Android) application that needs to call large language models, but exposing model API keys directly in the client is obviously not acceptable. This implies having some kind of intermediary layer that handles request forwarding, authentication, usage control, and key management. While I understand this can all be built manually, in practice it quickly turns into a non-trivial backend system.\n\nMy main question is: **are there existing SDKs, managed services, or off-the-shelf solutions for this kind of “secure client → model access” use case?** Ideally, I’d like to avoid building a full backend from scratch and instead rely on something that already supports hiding real model keys, issuing controllable access tokens, tracking usage per user or device, and potentially supporting usage-based limits or billing.\n\nIf some custom implementation is unavoidable, what is the **fastest and most commonly adopted minimal setup** people use in practice? For example, a gateway, proxy, or reference architecture that can be deployed quickly with minimal custom logic, rather than re-implementing authentication, rate limiting, and usage tracking from the ground up.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qdbpri/what_is_the_best_practices_for_secure_client/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzouyri",
          "author": "The_NineHertz",
          "text": "This is one of those situations where the “no backend” dream hits reality fast. As soon as you start thinking about hiding API keys, rate limits, device-level usage, abuse prevention, or even just rotating keys safely, you’re essentially building a mini backend whether you want to or not. A lot of people underestimate that part because it feels like “just a proxy,” but that proxy ends up being the beating heart of your entire app.\n\nThere *are* some managed gateways popping up, but most of them still require you to wire up your own auth, your own logic, and some way to deal with model drift and usage spikes. Which is why so many teams just spin up a lightweight serverless layer, Cloudflare Workers, Firebase Functions, AWS Lambda, or Supabase Edge Functions something small that sits between the client and the LLM. Not a full backend, but enough to keep keys safe and let you enforce rules.\n\nRight now AI features are forcing even simple apps to think like proper software platforms. It’s not just “call the model and pray”; businesses need the security, observability, and control that come with real infrastructure. That’s why companies are leaning more on professional IT/AI integration services: the complexity isn’t in the model; it’s in making everything around it safe and reliable at scale.",
          "score": 5,
          "created_utc": "2026-01-15 07:18:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoza93",
              "author": "everettjf",
              "text": "Thanks for the detailed explanation! This really clarifies my security considerations.",
              "score": 2,
              "created_utc": "2026-01-15 07:58:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzoo0bp",
          "author": "vertical_computer",
          "text": "LiteLLM\n\nhttps://github.com/BerriAI/litellm",
          "score": 1,
          "created_utc": "2026-01-15 06:19:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzoonn9",
              "author": "everettjf",
              "text": "litellm is only on the server side.  How can I securely call litellm in the mobile client ?",
              "score": 1,
              "created_utc": "2026-01-15 06:24:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzp29xo",
          "author": "Alternative_Nose_874",
          "text": "In practice you cannot really avoid having some server-side component, even if it is very small. Tools like LiteLLM, OpenAI gateways, or similar only solve the model side, but they still must be called from something you control, not directly from the mobile app. The most common setup I see is a very thin serverless proxy (Cloudflare Workers, AWS Lambda, Supabase Edge Functions) that issues short-lived tokens and forwards requests to the LLM. This layer handles auth, rate limits, and hides real API keys, with almost no business logic inside. Managed services exist, but they usually still expect you to plug in your own auth and limits, so the “no backend” idea mostly breaks there. From experience, a small proxy + something like Firebase Auth is faster and safer than trying to find a magic SDK. It looks like a backend, but operationally it’s minimal and cheap.",
          "score": 1,
          "created_utc": "2026-01-15 08:26:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv8brq",
              "author": "everettjf",
              "text": "Thanks. I plan to build a minimal serverside proxy in Cloudflare workers.",
              "score": 1,
              "created_utc": "2026-01-16 05:00:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzpy88n",
          "author": "domainkiller",
          "text": "To stick purely on the client, you could implement it as a “bring your own key” - but it’s less than a stellar UX for normies.",
          "score": 1,
          "created_utc": "2026-01-15 12:59:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzv8enj",
              "author": "everettjf",
              "text": "Yes. BYOK can be the PRO option.",
              "score": 1,
              "created_utc": "2026-01-16 05:00:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qc5rlr",
      "title": "I built a way to make infrastructure safe for AI (MIT)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qc5rlr/i_built_a_way_to_make_infrastructure_safe_for_ai/",
      "author": "poltergeist-__-",
      "created_utc": "2026-01-13 22:36:17",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I built a platform that lets AI agents work on infrastructure by wrapping KVM/libvirt with a Go API.\n\n  \nMost AI tools stop at the codebase because giving an LLM root access to prod is crazy. [fluid.sh](http://fluid.sh) creates ephemeral sandboxes where agents can execute tasks like configuring firewalls, restarting services, or managing systemd units safely.\n\n  \n\n**How it works:**\n\n- It uses qcow2 copy-on-write backing files to instantly clone base images into isolated sandboxes.\n\n- The agent gets root access within the sandbox.\n\n- Security is handled via an ephemeral SSH Certificate Authority; agents use short-lived certificates for authentication.\n\n- As the agent works, it builds an Ansible playbook to replicate the task.\n\n- You review the changes in the sandbox and the generated playbook before applying it to production.\n\n  \n\nTech: Go, libvirt/KVM, qcow2, Ansible, Python SDK.\n\nGitHub: [https://github.com/aspectrr/fluid.sh](https://github.com/aspectrr/fluid.sh)  \nDemo: [https://youtu.be/nAlqRMhZxP0](https://youtu.be/nAlqRMhZxP0)\n\nHappy to answer any questions or feedback!",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qc5rlr/i_built_a_way_to_make_infrastructure_safe_for_ai/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzk21o2",
          "author": "no-adz",
          "text": "Yeah this approach makes a lot of sense.",
          "score": 1,
          "created_utc": "2026-01-14 15:51:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qfjl9i",
      "title": "LLM Structured Outputs Handbook",
      "subreddit": "LLMDevs",
      "url": "https://nanonets.com/cookbooks/structured-llm-outputs",
      "author": "vitaelabitur",
      "created_utc": "2026-01-17 17:42:07",
      "score": 4,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource 🚀",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qfjl9i/llm_structured_outputs_handbook/",
      "domain": "nanonets.com",
      "is_self": false,
      "comments": []
    }
  ]
}