{
  "metadata": {
    "last_updated": "2026-01-16 16:46:25",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 50,
    "total_comments": 243,
    "file_size_bytes": 313826
  },
  "items": [
    {
      "id": "1q2zfva",
      "title": "I am developing a 200MB LLM to be used for sustainable AI for phones.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2zfva/i_am_developing_a_200mb_llm_to_be_used_for/",
      "author": "Fancy_Wallaby5002",
      "created_utc": "2026-01-03 16:49:54",
      "score": 39,
      "num_comments": 19,
      "upvote_ratio": 0.88,
      "text": "Hello Reddit,\n\nOver the last few weeks, I‚Äôve written and trained a small LLM based on LLaMA 3.1.  \nIt‚Äôs multilingual, supports reasoning, and only uses **\\~250 MB** of space.  \nIt can run locally on a **Samsung A15** (a very basic Android phone) at reasonable speed.\n\nMy goal is to make it work as a kind of **‚ÄúGoogle AI Overview‚Äù**, focused on short, factual answers rather than chat.\n\nI‚Äôm wondering:\n\n* Is this a reasonable direction, or am I wasting time?\n* Do you have any advice on how to improve or where to focus next?\n\nSorry for my English; I‚Äôm a 17-year-old student from Italy.",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2zfva/i_am_developing_a_200mb_llm_to_be_used_for/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxi2mmm",
          "author": "SamWest98",
          "text": "[https://ai.google.dev/edge/mediapipe/solutions/genai/llm\\_inference/android](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference/android)\n\nI think they've beat you to the punch. I wouldn't say you're wasting time, being able to train and deploy edge models is a great learning experience",
          "score": 18,
          "created_utc": "2026-01-03 20:32:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxil11f",
          "author": "robogame_dev",
          "text": "It‚Äôs not going to be commercially viable, but it‚Äôs good experience!\n\nTraining models isn‚Äôt even commercially viable for major companies - the models themselves are out of date within 6 months, when a better, smaller model comes out. \n\nThat‚Äôs why so many models are given away for people to run themselves - because the company can‚Äôt reasonably charge for them when equally good or better models are available for free.\n\nModel development is interesting but it isn‚Äôt a small business opportunity (unless you target a really small and specific niche that involves unique training data that nobody else can get.)\n\nI would say the most important part of your project is to document it really well, so that later when you pitch to get a job or an investment on your future projects, you can point to it as proof of skill.\n\nIf you want to make money at AI as a solo, you need to either A) target a small niche model where you can obtain a dataset nobody else has, or B) make a product or service, something downstream of the models, where you focus on being the customer‚Äôs point of contact and use existing models/inference providers on your backend.",
          "score": 10,
          "created_utc": "2026-01-03 22:02:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxipl8g",
          "author": "Thellton",
          "text": "something to clarify, have you trained a model that is approximately 0.125B (125M) parameters? as that's the implication from your statement of 250MB of space. if so, that's a very constrained optimisation space you're working in, and whilst u/SamWest98 is probably correct that using a pre-existing small model would do the trick it is an interesting challenge you've set for yourself.\n\nas to your questions:\n\n1) It probably is a reasonable direction to go, though you'll likely need to specialise the model heavily, as 250MB is tiny. thus, you'll be wanting to focus on summarisation for finetuning. it may be beneficial to use synthetically generated samples for summarisation when you finetune for task as you'll be able to tailor final behaviour more readily that way too.\n\n2) I'd recommend checking out this [article](https://huggingface.co/blog/codelion/optimal-model-architecture). it goes into detail about the hyperparameter optimisation that can be done and some of the interesting things that are noted performance wise in response. if you've done only one training run, then it's probable that the particular combination of layers, embedding dim, etcetera could be optimised. granted, there is also a point where one has to stop and commit to a design. but that is always up to you, as you are the final arbiter of what you're satisfied with. \n\nanyway, good luck! also your English is perfectly fine!",
          "score": 2,
          "created_utc": "2026-01-03 22:25:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxhsh5a",
          "author": "jblully",
          "text": "Good idea.\nCan i see sources or example ?\nWhich dataset do you use ?\nI‚Äôm learning, if you have some course or doc to read to do that.",
          "score": 1,
          "created_utc": "2026-01-03 19:42:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxke4u1",
          "author": "LeoStark84",
          "text": "Interesting project. Depends a lot on your current implenentation though.\n\nIf what you made relies on llama.cpp it will be kinnda tough to turn into an apk, but it can work through Termux. I bring this up becausr from what I understand your intended use case depends on some kind of web-search. So you'd input something like \"quantum tunneling\" and somehow search for results online, pass it to your LLM for summarizing and the outpuy would be an explanation of quantum tunnelibg based on the results. Please correct me if I'm wrong, but I assume it to be the case as there is no way a large amount of world knowledge is gonna fit on such a small LLM.\n\nBottomline is the scaffolding around it is as important as the LLM. Also, as cool as Termux is, it's a heek thing and relying om it is going to leave 95% of users out, not a problem if you don't cate abouy massivity though.",
          "score": 1,
          "created_utc": "2026-01-04 03:53:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxkrfng",
          "author": "CrowAssaultVictim",
          "text": "Back in 2018, we used to build LLMs that could fit into AWS lambda functions before they extended the storage. But at that time we only called them \"language models\". I don't know at what point they started being called \"large\". Reminds me of \"big\" data. But they were bigger than 250mb.",
          "score": 1,
          "created_utc": "2026-01-04 05:20:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxma38a",
              "author": "ianitic",
              "text": "I think I remember the term LLM being used back in 2018 to describe BERT?",
              "score": 1,
              "created_utc": "2026-01-04 13:02:34",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxmwg2a",
                  "author": "CrowAssaultVictim",
                  "text": "Nah. BERT had different size models (BERT_SMALL, BERT, BERT_LARGE) but we didn‚Äôt use LLM as a noun. And even BERT_LARGE was nothing by today‚Äôs standards (however it‚Äôs still SOTA for some tasks).\n\nI think it started with whatever GPT came out during Covid.",
                  "score": 1,
                  "created_utc": "2026-01-04 15:14:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxky3dp",
          "author": "Bonnie-Chamberlin",
          "text": "What kind of dataset are you using for training your small language model?",
          "score": 1,
          "created_utc": "2026-01-04 06:10:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxl575s",
          "author": "dmpiergiacomo",
          "text": "This is a great learning experience and you are doing a great job! Don't forget to document everything really well to use for future reference when it comes to job hunting. I personally value side projects a lot when I look at CVs of candidates.\n\nWhen you ask if this is a reasonable direction, are you thinking about doing research or starting a business? Either way, you'll need to choose a more specific direction and justify the need of this technology in the world. So far your value proposition isn't very clear. If it's a business, be mindful of your customers' willingness to pay. If you‚Äôre planning to sell to smartphones providers, you'll have a hard time.",
          "score": 1,
          "created_utc": "2026-01-04 07:08:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm77rk",
          "author": "PARKSCorporation",
          "text": "Oh this is sick",
          "score": 1,
          "created_utc": "2026-01-04 12:41:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm8lji",
          "author": "Shivam_R_A",
          "text": "FunctionGemma",
          "score": 1,
          "created_utc": "2026-01-04 12:51:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmevpu",
          "author": "Good-Coconut3907",
          "text": "Learning and hands on experience is NEVER a waste of time. Particularly now that entry level jobs are hard to find.\n\nIf you need GPUs to play with, I‚Äôd be more than happy to loan some: https://github.com/kalavai-net/kalavai-client",
          "score": 1,
          "created_utc": "2026-01-04 13:33:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxsso5o",
              "author": "Fancy_Wallaby5002",
              "text": "oh, this is insane! thank you!",
              "score": 1,
              "created_utc": "2026-01-05 11:16:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxqrxw3",
          "author": "nuggieinu",
          "text": "Depends on the scope really so without examples/direct references its hard to tell, but honestly speaking I see this as better experience than trying to vibecode out a commercial product with little to no differentiation. From my experience, using resources like [brev.dev](http://brev.dev) and [together.ai](http://together.ai) not only made me think about what I was doing/learning, but inadvertently exposed me to other resources that I just kept following out of my own interest. Ultimately, I think if you try to dive deeper into this space rather than try to instantly push out a commercial product, you can really see for yourself something interesting.",
          "score": 1,
          "created_utc": "2026-01-05 02:15:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxrtbxn",
          "author": "yes-im-hiring-2025",
          "text": "Gemma already has one around that size.",
          "score": 1,
          "created_utc": "2026-01-05 06:00:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsmm82",
          "author": "shoonee_balavolka",
          "text": "Many people here have weighed in, but since the model size is so small, it won't be able to handle too many tasks. I'm actually planning something similar‚Äîusing Gemma 3 270M to generate comments for user diaries. You'd need fine-tuning to boost performance, but it might be tough because the model is so tiny. It's really impressive to see you doing this at such a young age. I‚Äôm sure you‚Äôll become a brilliant AI researcher in the future!",
          "score": 1,
          "created_utc": "2026-01-05 10:23:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycb7b7",
          "author": "badgerbadgerbadgerWI",
          "text": "This is exactly the direction we need more work in. The future isn't just massive models in the cloud - it's the right-sized model for the task, running where the data lives. What's your approach to model distillation? Curious how you're preserving reasoning capability at that size.",
          "score": 1,
          "created_utc": "2026-01-08 04:37:56",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4thym",
      "title": "How my open-source project ACCIDENTALLY went viral",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q4thym/how_my_opensource_project_accidentally_went_viral/",
      "author": "Every_Chicken_1293",
      "created_utc": "2026-01-05 18:21:20",
      "score": 38,
      "num_comments": 4,
      "upvote_ratio": 0.81,
      "text": "Original post: [here](https://www.reddit.com/r/LLMDevs/comments/1ky21fy/i_accidentally_built_a_vector_database_using)\n\nSix months ago, I published a weird weekend experiment where I stored text embeddings inside video frames.\n\nI expected maybe 20 people to see it. Instead it got:\n\n* Over 10M views\n* 10k stars on GitHub¬†\n* And thousands of other developers building with it.\n\nOver 1,000 comments came in, some were very harsh, but I also got some genuine feedback. I spoke with many of you and spent the last few months building Memvid v2: it‚Äôs faster, smarter, and powerful enough to replace entire RAG stacks.\n\n\n\nThanks for all the support.\n\nPs: I added a little surprise at the end for developers and OSS builders üëá\n\n\n\n**TL;DR**\n\n* Memvid replaces RAG + vector DBs entirely with a single portable memory file.\n* Stores knowledge as Smart Frames (content + embedding + time + relationships)\n* 5 minute setup and zero infrastructure.\n* Hybrid search with sub-5ms retrieval\n* Fully portable and open Source\n\n**What my project does?** Give your AI Agent Memory In One File.\n\n**Target Audience:** Everyone building AI agent.\n\n**GitHub Code:**[ https://github.com/memvid/memvid](https://github.com/memvid/memvid)\n\n‚Äî----------------------------------------------------------------\n\n**Some background:**\n\n* AI memory has been duct-taped together for too long.\n* RAG pipelines keep getting more complex, vector DBs keep getting heavier, and agents still forget everything unless you babysit them.¬†\n* So we built a completely different memory system that replaces RAG and vector databases entirely.¬† \n\n**What is Memvid:**\n\n* Memvid stores everything your agent knows inside a single portable file, that your code can read, append to, and update across interactions.\n* Each fact, action and interaction is stored as a self‚Äëcontained ‚ÄúSmart Frame‚Äù containing the original content, its vector embedding, a timestamp and any relevant relationships.¬†\n* This allows Memvid to unify long-term memory and external information retrieval into a single system, enabling deeper, context-aware intelligence across sessions, without juggling multiple dependencies.¬†\n* So when the agent receives a query, Memvid simply activates only the relevant frames, by meaning, keyword, time, or context, and reconstructs the answer instantly.\n* The result is a small, model-agnostic memory file your agent can carry anywhere.  \n\n**What this means for developers:**\n\nMemvid replaces your entire RAG stack.\n\n* Ingest any data type\n* Zero preprocessing required\n* Millisecond retrieval\n* Self-learning through interaction\n* Saves 20+ hours per week\n* Cut infrastructure costs by 90%\n\nJust plug Memvid into your agent and you instantly get a fully functional, persistent memory layer right out of the box.\n\n**Performance & Compatibility**\n\n(tested on my Mac M4)\n\n* Ingestion speed: 157 docs/sec¬†\n* Search Latency: <17ms retrieval for 50,000 documents\n* Retrieval Accuracy: beating leading RAG pipelines by over 60%\n* Compression: up to 15√ó smaller storage footprint\n* Storage efficiency: store 50,000 docs in a \\~200 MB file\n\nMemvid works with every model and major framework: GPT, Claude, Gemini, Llama, LangChain, Autogen and custom-built stacks.¬†\n\nYou can also 1-click integrate with your favorite IDE (eg. VS Code, Cursor)\n\nIf your AI agent can read a file or call a function, it can now remember forever.\n\nAnd your memory is 100% portable: Build with GPT ‚Üí run on Claude ‚Üí move to Llama. The memory stays identical.\n\n**Bonus for builders**\n\nAlongside Memvid V2, we‚Äôre releasing 4 open-source tools, all built on top of Memvid:\n\n* **Memvid ADR** ‚Üí is an MCP package that captures architectural decisions as they happen during development. When you make high-impact changes (e.g. switching databases, refactoring core services), the decision and its context are automatically recorded instead of getting lost in commit history or chat logs.\n   * GitHub Link: [https://github.com/memvid/adrflow](https://github.com/memvid/adrflow)\n* **Memvid Canvas** ‚Üí¬† is a UI framework for building fully-functional AI applications on top of Memvid in minutes. Ship customer facing or internal enterprise agents with zero infra overhead.\n   * GitHub Link: [https://github.com/memvid/canvas](https://github.com/memvid/canvas)\n* **Memvid Mind** ‚Üí is a persistent memory plugin for coding agents that captures your codebase, errors, and past interactions. Instead of starting from scratch each session, agents can reference your files, previous failures, and full project context, not just chat history. Everything you do during a coding session is automatically stored and ingested as relevant context in future sessions.¬†\n   * GitHub Link: [https://github.com/memvid/memvid-mind](https://github.com/memvid/memvid-mind)\n* **Memvid CommitReel** ‚Üí is a rewindable timeline for your codebase stored in a single portable file. Run any past moment in isolation, stream logs live, and pinpoint exactly when and why things broke.\n   * GitHub Link: [https://github.com/memvid/commitreel](https://github.com/memvid/commitreel)\n\nAll 100% open-source and available today.\n\nMemvid V2 is the version that finally feels like what AI memory should‚Äôve been all along.\n\nIf any of this sounds useful for what you‚Äôre building, I‚Äôd love for you to try it and let me know how we can improve it.",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q4thym/how_my_opensource_project_accidentally_went_viral/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny2wqf3",
          "author": "Financial-Fun-8930",
          "text": "Can't use local embedding models. I've tried CLI and node-js, both say \"not available on this platform\"",
          "score": 2,
          "created_utc": "2026-01-06 21:19:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2x10z",
              "author": "Every_Chicken_1293",
              "text": "Are you on Windows or Linux?",
              "score": 2,
              "created_utc": "2026-01-06 21:20:34",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5tv82",
          "author": "lukiszy",
          "text": "That's awesome!  \n  \nI would really like to try [https://github.com/memvid/adrflow](https://github.com/memvid/adrflow) , but it gives me 404. It is [https://github.com/memvid/claude-brain](https://github.com/memvid/claude-brain) in fact?",
          "score": 1,
          "created_utc": "2026-01-07 07:26:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyb2ehi",
          "author": "Dangerous-Cricket54",
          "text": "Congrats! Out of curiousity is anyone paying for it already?",
          "score": 1,
          "created_utc": "2026-01-08 00:34:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9sr9y",
      "title": "Announcing Kreuzberg v4",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q9sr9y/announcing_kreuzberg_v4/",
      "author": "Goldziher",
      "created_utc": "2026-01-11 07:04:12",
      "score": 38,
      "num_comments": 6,
      "upvote_ratio": 0.86,
      "text": "Hi Peeps,\n\nI'm excited to announce [Kreuzberg](https://github.com/kreuzberg-dev/kreuzberg) v4.0.0. \n\n## What is Kreuzberg:\n\nKreuzberg is a document intelligence library that extracts structured data from 56+ formats, including PDFs, Office docs, HTML, emails, images and many more. Built for RAG/LLM pipelines with OCR, semantic chunking, embeddings, and metadata extraction. \n\nThe new v4 is a ground-up rewrite in Rust with a bindings for 9 other languages! \n\n## What changed:\n\n- **Rust core**: Significantly faster extraction and lower memory usage. No more Python GIL bottlenecks.\n- **Pandoc is gone**: Native Rust parsers for all formats. One less system dependency to manage.\n- **10 language bindings**: Python, TypeScript/Node.js, Java, Go, C#, Ruby, PHP, Elixir, Rust, and WASM for browsers. Same API, same behavior, pick your stack.\n- **Plugin system**: Register custom document extractors, swap OCR backends (Tesseract, EasyOCR, PaddleOCR), add post-processors for cleaning/normalization, and hook in validators for content verification.\n- **Production-ready**: REST API, MCP server, Docker images, async-first throughout.\n- **ML pipeline features**: ONNX embeddings on CPU (requires ONNX Runtime 1.22.x), streaming parsers for large docs, batch processing, byte-accurate offsets for chunking.\n\n## Why polyglot matters:\n\nDocument processing shouldn't force your language choice. Your Python ML pipeline, Go microservice, and TypeScript frontend can all use the same extraction engine with identical results. The Rust core is the single source of truth; bindings are thin wrappers that expose idiomatic APIs for each language.\n\n## Why the Rust rewrite:\n\nThe Python implementation hit a ceiling, and it also prevented us from offering the library in other languages. Rust gives us predictable performance, lower memory, and a clean path to multi-language support through FFI.\n\n## Is Kreuzberg Open-Source?:\n\nYes! Kreuzberg is MIT-licensed and will stay that way. \n\n## Links\n\n- [Star us on GitHub](https://github.com/kreuzberg-dev/kreuzberg)\n- [Read the Docs](https://kreuzberg.dev/)\n- [Join our Discord Server](https://discord.gg/38pF6qGpYD)\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q9sr9y/announcing_kreuzberg_v4/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nyz470n",
          "author": "h8mx",
          "text": "Rust is slowly taking over the Python library ecosystem, I love it. This looks great! Thank you for sharing.\n\nJust a question, looking at the GitHub it seems the latest stable version is v3.22, with a rc candidate v4 released 2 weeks ago. When is v4 stable coming out?",
          "score": 5,
          "created_utc": "2026-01-11 14:23:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz0bb4m",
              "author": "Mikasa0xdev",
              "text": "Rust speed is the new latency benchmark.",
              "score": 1,
              "created_utc": "2026-01-11 17:55:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0mlmn",
          "author": "m98789",
          "text": "How does it compare to docling?",
          "score": 1,
          "created_utc": "2026-01-11 18:45:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzipbyo",
              "author": "Eastern-Surround7763",
              "text": "its x50 times faster than docling on a CPU (not suprising, since docling is GPU orientated), and it works very well. Docling is superior in terms of complex layout extraction. So, test and see how it works for your use case. We'll be releasing benchmarks in the next couple of weeks",
              "score": 1,
              "created_utc": "2026-01-14 11:00:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyxpcsf",
          "author": "Sweet121",
          "text": "edit: I'm sorry. My mistake. I didn't get a good look.",
          "score": -3,
          "created_utc": "2026-01-11 07:27:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyxsiie",
              "author": "WhoTookPlasticJesus",
              "text": "Not sure what is unclear for you in [this](https://old.reddit.com/r/LLMDevs/comments/1mvuw5x/community_rule_update_clarifying_our/)\n\n> Specifically, **it is now okay to share your free open-source projects without prior moderator approval**. This includes any project in the public domain, permissive, copyleft or non-commercial licenses",
              "score": 3,
              "created_utc": "2026-01-11 07:56:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qaowjr",
      "title": "SCOPE raises the bar by matching GPT-4o's results while being 160,000x smaller",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qaowjr/scope_raises_the_bar_by_matching_gpt4os_results/",
      "author": "MarionberrySingle538",
      "created_utc": "2026-01-12 07:47:20",
      "score": 30,
      "num_comments": 13,
      "upvote_ratio": 0.86,
      "text": " Researchers built a neural planner, SCOPE thats 160,000x smaller than frontier LLM models like GPT 40, 55x faster and produces better results compared to LLMs. SCOPE achieves this using this approach: one-shot LLM initialization + hierarchical neural planning + RL fine-tuning, allowing it to run fully independently on a single GPU with no API calls or network latency. This is really a game changer as it's faster, smarter and more sustainable for our environment.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qaowjr/scope_raises_the_bar_by_matching_gpt4os_results/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz4u45d",
          "author": "WhoTookPlasticJesus",
          "text": "idgi.\n\nThere's a blog post and a 10 page paper that mostly repeats the blog post. As far as I can tell it performs one task of your devising, but there's no code or any way to reproduce the results, so I can't be sure. There's not even a specification of hardware that was used for testing. \n\nAnyway, I'm ready put in $700MM at a pre-money valuation of $1.7B. I'll have the term sheet to you by COB Friday.",
          "score": 25,
          "created_utc": "2026-01-12 09:16:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4mfho",
          "author": "Frosty_Chest8025",
          "text": "someone could say to datacenter boys that they can stop building.",
          "score": 8,
          "created_utc": "2026-01-12 08:02:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4ufh4",
              "author": "coronakillme",
              "text": "They will increase the scope",
              "score": 1,
              "created_utc": "2026-01-12 09:19:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4x6hz",
          "author": "Bmaxtubby1",
          "text": "I‚Äôm still pretty new to ML research, but I‚Äôve learned to be cautious when something 'beats GPT-4o' without clearly stating the task distribution. Beating a frontier model on a specialized benchmark doesn‚Äôt automatically mean broader capability.\n\nIt actually feels more like a strong argument for hybrid systems: LLMs for language + smaller planners for structure and decision-making.",
          "score": 7,
          "created_utc": "2026-01-12 09:46:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7kelu",
              "author": "JollyJoker3",
              "text": "Yeah, I can beat 5.2 in Towers of Hanoi with 500 bytes",
              "score": 1,
              "created_utc": "2026-01-12 18:49:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz4nfip",
          "author": "redballooon",
          "text": "Big if true.¬†\n\nDoes it only match gpt-4o in some selected specialty, or generally for reasoning? For instruction following? For knowledge?",
          "score": 7,
          "created_utc": "2026-01-12 08:12:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4lfd9",
          "author": "Infamous_Knee3576",
          "text": "That is just a small overfitted model. Trained only to beat benchmarks.",
          "score": 5,
          "created_utc": "2026-01-12 07:53:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4krso",
          "author": "MarionberrySingle538",
          "text": "Official announcement: [https://skyfall.ai/blog/scope-hierarchical-planner-55x-faster-than-llms](https://skyfall.ai/blog/scope-hierarchical-planner-55x-faster-than-llms)",
          "score": 4,
          "created_utc": "2026-01-12 07:47:34",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nz5e32n",
          "author": "adalgis231",
          "text": "Is there a paper reference?",
          "score": 1,
          "created_utc": "2026-01-12 12:12:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz6b766",
              "author": "czmax",
              "text": "it‚Äôs linked in the announcement posted by OP",
              "score": 1,
              "created_utc": "2026-01-12 15:23:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz8hacs",
                  "author": "infinitelylarge",
                  "text": "Where?\n\nhttps://preview.redd.it/4cbizrwvjzcg1.jpeg?width=1320&format=pjpg&auto=webp&s=6e119acb802f73552f661e303ffa3ab0c57c83b7",
                  "score": 1,
                  "created_utc": "2026-01-12 21:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz7tozu",
          "author": "pegaunisusicorn",
          "text": "da fuq are they comparing themselves to gpt-3.5 and 4o? \n\nIs this 2024?  \n\nWut?\n\nSmells like old tech dug up for selling crap AI stocks to rubes.",
          "score": 1,
          "created_utc": "2026-01-12 19:32:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q25iar",
      "title": "Why enterprise AI agents fail in production",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q25iar/why_enterprise_ai_agents_fail_in_production/",
      "author": "Arindam_200",
      "created_utc": "2026-01-02 17:56:10",
      "score": 24,
      "num_comments": 9,
      "upvote_ratio": 0.89,
      "text": "I keep seeing the same pattern with enterprise AI agents: they look fine in demos, then break once they‚Äôre embedded in real workflows.\n\nThis usually isn‚Äôt a model or tooling problem. The agents have access to the right systems, data, and policies.\n\nWhat‚Äôs missing is **decision context**.\n\nMost enterprise systems record outcomes, not reasoning. They store that a discount was approved or a ticket was escalated, but not *why* it happened. The context lives in Slack threads, meetings, or individual memory.\n\nI was thinking about this again after reading Jaya Gupta‚Äôs article on **context graphs**, which describes the same gap. A context graph treats decisions as first-class data by recording the inputs considered, rules evaluated, exceptions applied, approvals taken, and the final outcome, and linking those traces to entities like accounts, tickets, policies, agents, and humans.\n\nhttps://preview.redd.it/upw4879w5zag1.png?width=1920&format=png&auto=webp&s=25c8abbab1d6fb2a7cc24e146a8f48524b28b2d0\n\nThis gap is manageable when humans run workflows because people reconstruct context from experience. It becomes a hard limit once agents start acting inside workflows. Without access to prior decision reasoning, agents treat similar cases as unrelated and repeatedly re-solve the same edge cases.\n\nWhat‚Äôs interesting is that this isn‚Äôt something existing systems of record are positioned to fix. CRMs, ERPs, and warehouses store state before or after decisions, not the decision process itself. Agent orchestration layers, by contrast, sit directly in the execution path and can capture decision traces as they happen.\n\nI wrote a deeper piece exploring why this pushes enterprises toward **context-driven platforms** and what that actually means in practice. Feel free to read it [here](https://www.tensorlake.ai/blog/context-driven-enterprise-platform).",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q25iar/why_enterprise_ai_agents_fail_in_production/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxavblm",
          "author": "j4ys0nj",
          "text": "This is awesome! Thanks for sharing. I made and run an agentic AI platform - and I think it may be well positioned to address the shortcomings you highlight - at least somewhat. I will read through this, maybe I can make some improvements!",
          "score": 3,
          "created_utc": "2026-01-02 19:01:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaztp9",
          "author": "lexseasson",
          "text": "This resonates a lot.\n\nWhat we‚Äôve seen building agentic systems is that ‚Äúcontext‚Äù only becomes useful once it‚Äôs externalized as inspectable artifacts ‚Äî decisions, assumptions, success criteria ‚Äî not just aggregated signals.\n\nOtherwise you get rich context but still no accountability.\nContext without governance just becomes another layer of implicit state.\nContext is necessary for action.\nGovernance is sufficient for scale.",
          "score": 2,
          "created_utc": "2026-01-02 19:22:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxaz8mt",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-01-02 19:19:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxb08rp",
              "author": "EpochRaine",
              "text": "This is very interesting. I have been using seed \"characters\" in my LLM development - essentially looking at how changing a single character influences inference output and how the models amplify and possibly compound that effect internally.",
              "score": 1,
              "created_utc": "2026-01-02 19:24:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxbb4ef",
                  "author": "spastical-mackerel",
                  "text": "Keep it up! You‚Äôll make it deterministic eventually",
                  "score": 1,
                  "created_utc": "2026-01-02 20:16:58",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxqfhfg",
          "author": "Bonnie-Chamberlin",
          "text": "Thanks for sharing. Would this be connected to Graph Neural Networks somehow?",
          "score": 1,
          "created_utc": "2026-01-05 01:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycba02",
          "author": "badgerbadgerbadgerWI",
          "text": "Decision context is huge but I'd add: most enterprise failures I've seen are actually about data governance. The agent technically *could* access the right systems, but compliance/security won't let it. Local-first architecture where data never leaves the perimeter changes that equation entirely.",
          "score": 1,
          "created_utc": "2026-01-08 04:38:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qb2swo",
      "title": "Where to start with RAG and LangChain in 2026? Feeling a bit overwhelmed by the ecosystem.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qb2swo/where_to_start_with_rag_and_langchain_in_2026/",
      "author": "Cobra_venom12",
      "created_utc": "2026-01-12 18:26:38",
      "score": 23,
      "num_comments": 18,
      "upvote_ratio": 0.96,
      "text": "Hey everyone,\n‚ÄãI‚Äôm looking to dive deep into RAG (Retrieval-Augmented Generation) using LangChain, but the more I read, the more I realize how many moving parts there are (vector DBs, chunking strategies, embeddings, LCEL, etc.).\n‚ÄãI have a decent handle on Python, but I‚Äôm struggling with the \"order of operations.\"\n‚ÄãMy questions for the experts here:\n‚ÄãWhat are the absolute \"day one\" fundamentals I should master before touching the code? (e.g., understanding embeddings vs. just learning LangChain syntax?)\n‚ÄãAre there specific resources (YouTube, courses, or docs) that are actually up-to-date for 2026? A lot of tutorials I find use deprecated LangChain syntax.\n‚ÄãIf you were starting today, what‚Äôs the first mini-project you‚Äôd build to \"get it\"?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qb2swo/where_to_start_with_rag_and_langchain_in_2026/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz8acsg",
          "author": "Ok_Pomelo_5761",
          "text": "Ignore LangChain at first. Learn RAG like a pipeline:\n\n1 take your docs  \n2 cut them into small pieces  \n3 search the best pieces  \n4 give the model only those pieces and show sources  \n5 test if answers are actually correct\n\nIf you want a clear roadmap, copy what [zeroentropy](https://www.zeroentropy.dev/) focuses on: better chunking, better reranking, and simple evals. That is where most RAG wins come from.\n\nFor RAG stuff, the discord [https://discord.gg/yveDzEyP](https://discord.gg/yveDzEyP)",
          "score": 12,
          "created_utc": "2026-01-12 20:49:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7x5yt",
          "author": "tom-mart",
          "text": "If you are ok with Python then forget Langchain and look into Pydantic AI. Langchain adds a lot of unnecessary abstraction and is really not bringing any value. Start small an build on it. Have a look on my post history, I wrote a series of articles to show how to build basic agents from scratch with Django (Python), Pydantic AI and Postgress with their built in vector extension pgvector. Once you see the basic structure, you will be able to build anything on it.\n\nI'm finishing another article that will show how to build an AI personal assistant (or rather a whole bunch of specialist assistants) using same twchnologies as above, plus Android front end that also collects user health and phone use data so the assistant has some raw data to work on.",
          "score": 13,
          "created_utc": "2026-01-12 19:48:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzarpdr",
              "author": "lionmeetsviking",
              "text": "This! Pydantic AI rocks! Here is a little scaffolding that might help: https://github.com/madviking/pydantic-ai-scaffolding",
              "score": 2,
              "created_utc": "2026-01-13 04:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz7jei0",
          "author": "fnl",
          "text": "It is raw and unrevised yet, but I have a blog post on that: Curious to learn if it is helpful to someone like you or confusing. https://fnl.es/Blog/Machine+Learning/2026-01-10+A+primer+on+RAG%2C+2026+edition",
          "score": 4,
          "created_utc": "2026-01-12 18:45:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz7vzd7",
              "author": "Cobra_venom12",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-01-12 19:42:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzo6ghz",
          "author": "pbalIII",
          "text": "Skip the LangChain syntax entirely for now. Most teams waste weeks learning LCEL when the real wins come from understanding the pipeline mechanics first.\n\nDay one fundamentals: embeddings (what they are, why cosine similarity works), chunking (semantic vs fixed-size, the 256-512 token sweet spot), and retrieval quality (precision vs recall tradeoffs). Build a dead-simple RAG with just OpenAI embeddings, a local vector store like Chroma, and raw API calls. No framework.\n\nOnce that clicks, Pydantic AI is cleaner than LangChain for production work. Way less abstraction, type-safe, and you actually understand what your code does. LangChain is fine for demos but adds layers you dont need when learning.\n\nFirst project: FAQ bot over your own docs. Small enough to debug, big enough to hit real chunking problems.",
          "score": 3,
          "created_utc": "2026-01-15 04:10:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzod19n",
              "author": "Cobra_venom12",
              "text": "That's really helpful.",
              "score": 1,
              "created_utc": "2026-01-15 04:55:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzb7s5d",
          "author": "Subject-Complex6934",
          "text": "This channel has alot of videos about RAG in detail  \n[https://www.youtube.com/@PavelCermakAI](https://www.youtube.com/@PavelCermakAI)",
          "score": 2,
          "created_utc": "2026-01-13 06:40:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzlmdlf",
          "author": "charlesthayer",
          "text": "1. Try this quick ChromaDB example: [https://docs.trychroma.com/docs/overview/getting-started](https://docs.trychroma.com/docs/overview/getting-started)  \n2. Check out this Real Python article with a deeper full-text example: [https://realpython.com/chromadb-vector-database/](https://realpython.com/chromadb-vector-database/)  \n3. Build a tiny LLM agent calling example with HF's smolagents: [https://www.nb-data.com/p/mastering-smolagents-building-ai](https://www.nb-data.com/p/mastering-smolagents-building-ai)\n\nYou should be able to extend the agent with a vectorDB search tool (tool-call, tool-use) over a directory of your own documents at this point.",
          "score": 2,
          "created_utc": "2026-01-14 20:04:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8amff",
          "author": "hrishikamath",
          "text": "Honestly just take a real problem: get documents for it, do rag on it with the most basic setup. You will see why it fails. Learn about individual components and go deeper. That‚Äôs the best way. No point studying theory and not retaining more than 10-20% because you won‚Äôt use most of it.",
          "score": 2,
          "created_utc": "2026-01-12 20:51:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzaz9am",
              "author": "Cobra_venom12",
              "text": "You are saying to make a basic project and learn through it.",
              "score": 3,
              "created_utc": "2026-01-13 05:32:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz9sh63",
          "author": "Bonnie-Chamberlin",
          "text": "I would recommend starting by learning from a specific task instead of starting from a framework. For example, if you want to build a paper-reading chatbot based on a RAG system, you build step by step and learn whatever techniques if needed. Otherwise, you will always feel lost when you want to eat in the whole framework.",
          "score": 1,
          "created_utc": "2026-01-13 01:24:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbdryu",
          "author": "MediumMountain6164",
          "text": "Create a new space",
          "score": 1,
          "created_utc": "2026-01-13 07:32:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzbqevi",
          "author": "Full_Win_8680",
          "text": "Start with the core ideas first embeddings, vector search, and chunking.  \nThen build a tiny project RAG over your own PDFs. That alone teaches most of it.  \nFor resources, stick to the latest LangChain docs + recent YouTube talks a lot of older tutorials are outdated.",
          "score": 1,
          "created_utc": "2026-01-13 09:33:56",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzbqs7o",
              "author": "Cobra_venom12",
              "text": "Do I have to learn about llms ?",
              "score": 1,
              "created_utc": "2026-01-13 09:37:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzbtumc",
                  "author": "Full_Win_8680",
                  "text": "Yes but only the practical parts how prompts work, tokens, context windows, and how models respond.  \nYou don‚Äôt need to go deep into training or architecture to build solid RAG systems.",
                  "score": 3,
                  "created_utc": "2026-01-13 10:06:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzeabii",
          "author": "NearbySupport7520",
          "text": "f",
          "score": 1,
          "created_utc": "2026-01-13 18:37:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz8i26a",
          "author": "hello5346",
          "text": "You need none of that to get started.  Focus on your goals.",
          "score": 0,
          "created_utc": "2026-01-12 21:26:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9utin",
      "title": "Vibe scraping at scale with AI Web Agents, just prompt => get data",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/npnlfifmrocg1",
      "author": "BodybuilderLost328",
      "created_utc": "2026-01-11 09:09:13",
      "score": 20,
      "num_comments": 15,
      "upvote_ratio": 0.74,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q9utin/vibe_scraping_at_scale_with_ai_web_agents_just/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyy1ee1",
          "author": "fAkestTreemAkeSships",
          "text": "This is honestly insane‚Äîforwarded to my team. I‚Äôm building something very similar but with very different verticals. Would love to chat!",
          "score": 2,
          "created_utc": "2026-01-11 09:18:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyy1r1r",
              "author": "BodybuilderLost328",
              "text": "Yea book sometime! [https://www.rtrvr.ai/request-demo](https://www.rtrvr.ai/request-demo)",
              "score": 1,
              "created_utc": "2026-01-11 09:21:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz0bn8q",
          "author": "Mikasa0xdev",
          "text": "Vibe scraping is the new data mining.",
          "score": 2,
          "created_utc": "2026-01-11 17:56:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyz04yy",
          "author": "JustKiddingDude",
          "text": "Interesting, does it bypass bot detectors?",
          "score": 1,
          "created_utc": "2026-01-11 14:00:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyzjiil",
              "author": "BodybuilderLost328",
              "text": "Somewhat.\n\nWe have partner agentic chrome extension for bot detection heavy sites. Since its taking action in your own browser, it doesnt get detected",
              "score": 1,
              "created_utc": "2026-01-11 15:43:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz1inoa",
          "author": "robogame_dev",
          "text": "How do you handle javascript heavy pages and progressive web apps where the content requires interactions before the content will appear? Does it have a fallback to rendering / headful browser when the initial DOM doesn't expose what's needed?",
          "score": 1,
          "created_utc": "2026-01-11 21:10:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz1n4ge",
              "author": "BodybuilderLost328",
              "text": "So we are rendering the browser, as you can see in the video the 50+ browser views are shown.\n\nWe are just taking actions on the browsers like typing/clicking/scrolling via the DOM only.  \n  \n So, yes: \n\n* we load and handle Javascript heavy pages \n* the agent can fill in forms and other interactions before retrieving the data",
              "score": 1,
              "created_utc": "2026-01-11 21:30:52",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz1oi08",
                  "author": "robogame_dev",
                  "text": "Ah makes sense, thanks!\n\nNext question: I see it's based on credits - can you say how many credits get used for a given scrape, etc?\n\nFor example, running Browser-Use agent with Gemini 3 Flash Preview, scraping what I need out of a page costs me \\~ $0.01 (single pass) - what's the equivalent for a single pass (load the page, scrape some structured data out) in credits?",
                  "score": 1,
                  "created_utc": "2026-01-11 21:37:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz1ro12",
          "author": "dyingpie1",
          "text": "Hi, is it open source? We're looking for something open source.",
          "score": 1,
          "created_utc": "2026-01-11 21:52:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz2dg9e",
              "author": "BodybuilderLost328",
              "text": "We are planning on open sourcing an extension in the future",
              "score": 1,
              "created_utc": "2026-01-11 23:40:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz2js7k",
                  "author": "dyingpie1",
                  "text": "Ah unfortunately we need fully open source.",
                  "score": 1,
                  "created_utc": "2026-01-12 00:12:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2hrl0",
          "author": "Glittering-Call8746",
          "text": "Yes pls open source , good job !",
          "score": 1,
          "created_utc": "2026-01-12 00:02:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz4xxov",
          "author": "SecureHunter3678",
          "text": "Huh...\n\nMan. The Future with Prompt Injections and Prompt Hijacking will be so wild.",
          "score": 1,
          "created_utc": "2026-01-12 09:53:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6du6b",
      "title": "I Built a Free Tool to Check VRAM Requirements for Any HuggingFace Model",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q6du6b/i_built_a_free_tool_to_check_vram_requirements/",
      "author": "kingksingh",
      "created_utc": "2026-01-07 12:15:44",
      "score": 19,
      "num_comments": 9,
      "upvote_ratio": 0.88,
      "text": "**TL;DR:** I got tired of guessing whether models would fit on my GPU. So I built [vramio](https://vramio.ksingh.in) ‚Äî a free API that tells you exactly how much VRAM any HuggingFace model needs. One curl command. Instant answer.\n\n---\n\n## The Problem Every ML Engineer Knows\n\nYou're browsing HuggingFace. You find a model that looks perfect for your project. Then the questions start:\n\n- \"Will this fit on my 24GB RTX 4090?\"\n- \"Do I need to quantize it?\"\n- \"What's the actual memory footprint?\"\n\nAnd the answers? They're nowhere.\n\nSome model cards mention it. Most don't. You could download the model and find out the hard way. Or dig through config files, count parameters, multiply by bytes per dtype, add overhead for KV cache...\n\nI've done this calculation dozens of times. It's tedious. It shouldn't be.\n\n## The Solution: One API Call\n\n```bash\ncurl \"https://vramio.ksingh.in/model?hf_id=mistralai/Mistral-7B-v0.1\"\n```\n\nThat's it. You get back:\n\n```json\n{\n  \"model\": \"mistralai/Mistral-7B-v0.1\",\n  \"total_parameters\": \"7.24B\",\n  \"memory_required\": \"13.49 GB\",\n  \"recommended_vram\": \"16.19 GB\",\n  \"other_precisions\": {\n    \"fp32\": \"26.99 GB\",\n    \"fp16\": \"13.49 GB\",\n    \"int8\": \"6.75 GB\",\n    \"int4\": \"3.37 GB\"\n  }\n}\n```\n\n**`recommended_vram`** includes the standard 20% overhead for activations and KV cache during inference. This is what you actually need.\n\n## How It Works\n\nNo magic. No downloads. Just math.\n\n1. Fetch safetensors metadata from HuggingFace (just the headers, ~50KB)\n2. Parse tensor shapes and data types\n3. Calculate: `parameters √ó bytes_per_dtype`\n4. Add 20% for inference overhead\n\nThe entire thing is **160 lines of Python** with a single dependency (`httpx`).\n\n## Why I Built This\n\nI run models locally. A lot. Every time I wanted to try something new, I'd waste 10 minutes figuring out if it would even fit.\n\nI wanted something dead simple:\n- No signup\n- No rate limits\n- No bloated web UI\n- Just an API endpoint\n\nSo I built it over a weekend and deployed it for free on Render.\n\n## Try It\n\n**Live API:** https://vramio.ksingh.in/model?hf_id=YOUR_MODEL_ID\n\n**Examples:**\n```bash\n# Llama 2 7B\ncurl \"https://vramio.ksingh.in/model?hf_id=meta-llama/Llama-2-7b\"\n\n# Phi-2\ncurl \"https://vramio.ksingh.in/model?hf_id=microsoft/phi-2\"\n\n# Mistral 7B\ncurl \"https://vramio.ksingh.in/model?hf_id=mistralai/Mistral-7B-v0.1\"\n```\n\n## Self-Host It\n\nIt's open source. Run your own:\n\n```bash\ngit clone https://github.com/ksingh-scogo/vramio.git\ncd vramio\npip install httpx[http2]\npython server_embedded.py\n```\n\n## What's Next\n\nThis solves my immediate problem. If people find it useful, I might add:\n- Batch queries for multiple models\n- Training memory estimates (not just inference)\n- Browser extension for HuggingFace\n\nBut honestly? The current version does exactly what I needed. Sometimes simple is enough.\n\n---\n\n**GitHub:** https://github.com/ksingh-scogo/vramio\n\nBuilt with help from [hf-mem](https://github.com/alvarobartt/hf-mem) by @alvarobartt.\n\n---\n\n*If this saved you time, consider starring the repo. And if you have ideas for improvements, open an issue ‚Äî I'd love to hear them.*\n",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q6du6b/i_built_a_free_tool_to_check_vram_requirements/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny6wce0",
          "author": "Narrow-Belt-5030",
          "text": "Huggingface already tells you this .. and if you also tell it your GPU it will mark in red/yellow/green if the models and quaints will fit or not.",
          "score": 5,
          "created_utc": "2026-01-07 12:51:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7ktwg",
              "author": "kingksingh",
              "text": "Thanks good to know, can you give the pointer wherever to find this option on HF dashboard?",
              "score": 3,
              "created_utc": "2026-01-07 15:05:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny7lwt5",
                  "author": "Narrow-Belt-5030",
                  "text": "Click here (as an example): [https://huggingface.co/unsloth/Qwen-Image-2512-GGUF](https://huggingface.co/unsloth/Qwen-Image-2512-GGUF)\n\nRight hand side it shows all the variants and if you can use them or not (I have 5090):\n\nhttps://preview.redd.it/5kshhj301ybg1.png?width=785&format=png&auto=webp&s=c204edf6a03c6decfbc533ca570ae7ce3a3ff5cc",
                  "score": 5,
                  "created_utc": "2026-01-07 15:10:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nyj41xw",
              "author": "AvocadoArray",
              "text": "Yeah, it‚Äôs pretty easy to tell whether the model will fit, but it‚Äôs a little more tricky to calculate the k/v cache space requirements to tell whether it will be viable or not. This can vary a ton from model to model depending on its architecture, but it‚Äôs also pretty simple math if you pull the numbers in from the model‚Äôs JSON config.",
              "score": 1,
              "created_utc": "2026-01-09 03:25:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny70dou",
          "author": "emmettvance",
          "text": "The 20% overhead rule is reasonable for inference but can vary a lot depending on yur batch size and context length. For long content workloads the kv cache can easiy double memory usage beyonf 20%... might be worth adding an optional arameter for context length so people can estiate worst case memory for their usecase. Like something like `?hf_id=model&ctx_len=32768` that adjusts the overhead calculation neatly.",
          "score": 4,
          "created_utc": "2026-01-07 13:16:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny7l1at",
              "author": "kingksingh",
              "text": "Good suggestion, will include this",
              "score": 3,
              "created_utc": "2026-01-07 15:06:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7vq6a",
          "author": "cmndr_spanky",
          "text": "Aren‚Äôt you missing a few variables? Like batch size and imposed context limit ?",
          "score": 2,
          "created_utc": "2026-01-07 15:56:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8tuhq",
              "author": "kingksingh",
              "text": "For now I have purposely kept it simple. But yeah in the next iteration I will try to add that",
              "score": 1,
              "created_utc": "2026-01-07 18:29:09",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyg7l14",
          "author": "Serveurperso",
          "text": "Put your hardware in your hugging face profile, and it will display it directly on each model for each quantization...",
          "score": 1,
          "created_utc": "2026-01-08 18:59:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5s2xi",
      "title": "Thoughts on DeepSeek's new paper?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q5s2xi/thoughts_on_deepseeks_new_paper/",
      "author": "QoTSankgreall",
      "created_utc": "2026-01-06 19:20:18",
      "score": 15,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "DeepSeek dropped a research paper on New Year's Eve called \"Manifold-Constrained Hyper-Connections\" that I think is worth paying attention to.\n\n**Quick background on the problem:**\n\nStandard AI models struggle to share information across layers as they get deeper. It's been theorised that increasing this ability would result in more effective models, but it's never worked in practice. Multiple experiments have shown that training becomes unstable and models start to crash.\n\n**What DeepSeek did:**\n\nThey applied a mathematical constraint that effectively puts \"guardrails\" on how information flows. The result is that they can run parallel streams of reasoning without the model becoming unstable.\n\nThe cost is negligible (around 6% overhead), but the gain is smarter, denser models that learn more efficiently per GPU hour.\n\n**Why this is interesting:**\n\nDeepSeek has been forced into playing an efficiency game due to chip export controls, while US labs tend to solve bottlenecks by throwing compute at them. This paper is another example of them redesigning the architecture itself rather than just scaling up.\n\nDeepSeek has a habit of releasing papers before publishing new models, so we might see this deployed soon.\n\nIf it checks out, it would be very interesting to see how this affects the valuation of US AI firms - which is basically pegged to their compute right now.\n\nLink to paper: [\\[2512.24880\\] mHC: Manifold-Constrained Hyper-Connections](https://arxiv.org/abs/2512.24880)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5s2xi/thoughts_on_deepseeks_new_paper/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny2lw4k",
          "author": "WolfeheartGames",
          "text": "This is probably a part of 3.2. They said it was an experimental model to test new things.\n\nThis is similar to ERO. Which did something similar but with population evolution instead of back prop.\n\nFrom what I have read the pressure to rewire and it's clip is uniform across layers. I am working on a kind of augmenting topology where an MLP optimizes the topology (nested learning) by looking at gradient heuristics and the hyper connections themself (Jepa style). The learned optimizer is frequently driving change rates of layers 0-2 to 0, and subsequent layers keep receiving more and more pressure to change as it goes deeper. The sharpest rise is as it approaches the middle layer, and then it becomes asymptotic the deeper the layers go. \n\nThis makes changes much more predictable. If I change something at step 1, the cumulative effect by step 12 is massive. It's much easier to determine what changes are optimal when we are closer to the exit. Doing this optimization naively through gradient heuristics with and with out nested learning also has similar results.\n\nSince mHC is not respecting this behavior that I'm observing to occur naturally for stability, I don't think they've fully solved the problem. They've provided a working prototype. I am also working on an SSM, the behavior on a transformer may be different. Literature seems to agree that manifold changes are more stable on SSM though, so they're good fits. Which makes sense, as we carry our state's forward in meaningful ways in SSMs so this upstream chaos is more natural for an SSM to optimize for.\n\nAlso note, they are swapping hyper connections, I am swapping blocks of neurons.",
          "score": 3,
          "created_utc": "2026-01-06 20:29:31",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny8sio8",
              "author": "Mikasa0xdev",
              "text": "DeepSeek is playing 4D chess.",
              "score": 1,
              "created_utc": "2026-01-07 18:23:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny2m38n",
          "author": "dual-moon",
          "text": "oh, oh wow. thank you for sharing! we'll update you when we can but - this maps DIRECTLY onto some of our public domain research into neural networks! we have been doing basin mapping in neural networks to figure out the best way to fine-tune LFM2!\n\nthanks so much for posting this!",
          "score": 3,
          "created_utc": "2026-01-06 20:30:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7428l",
          "author": "Suitable-Program-181",
          "text": "MoE and mHC is sophisticated level of sauce. KFC will be jealous.\n\nThe insane part is they share all. \n\nThey really want to f\\* big techs.",
          "score": 1,
          "created_utc": "2026-01-12 17:36:31",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q64gv0",
      "title": "How to reduce tool-calling latency to <100ms for your AI agents",
      "subreddit": "LLMDevs",
      "url": "https://github.com/neuledge/graph",
      "author": "moshestv",
      "created_utc": "2026-01-07 03:29:25",
      "score": 14,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q64gv0/how_to_reduce_toolcalling_latency_to_100ms_for/",
      "domain": "github.com",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q5hy2e",
      "title": "We‚Äôve been shipping \"slop\" for 20 years. We just used to call it an MVP.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q5hy2e/weve_been_shipping_slop_for_20_years_we_just_used/",
      "author": "National_Purpose5521",
      "created_utc": "2026-01-06 13:01:06",
      "score": 14,
      "num_comments": 15,
      "upvote_ratio": 0.61,
      "text": "A lot of people have started using the word ‚Äúslop‚Äù as shorthand for AI-generated code. Their stance is that AI is flooding the industry with low-quality software, and we‚Äôre all going to pay for it later in outages, regressions, and technical debt.\n\nThis argument sounds convincing until you look honestly at how software has actually been built for the last 20 years.\n\nThe uncomfortable truth is that ‚Äúslop‚Äù didn‚Äôt start with AI. In fact, it is AI that made it impossible to keep pretending otherwise.\n\nOutside of Google‚Äôs famously rigorous review culture, most Big Tech giants (Meta, Amazon, and Microsoft included) have historically prioritized speed.\n\nIn the real world, PRs are often skimmed, bugs are fixed after users report them, and the architecture itself evolves after the product proves itself. We didn‚Äôt call this \"slop\" back then; we called it an MVP.\n\nBy comparison, some of the code that coding agents deliver today is already better than the typical early-stage PRs in many companies. And in hindsight, we have always been willing to trade internal code purity for external market velocity.\n\nThe primary exception is open-source projects, which operate differently. Open source has consistently produced reliable, maintainable code, even with contributions from dozens or hundreds of developers.\n\nAnd the reason it works is that the projects maintain strict API boundaries and clean abstractions so that someone with zero internal context can contribute without breaking the system. If we treat an AI agent like an external open-source contributor, i.e. someone who needs strict boundaries and automated feedback to be successful, the \"slop\" disappears.\n\nI'm building an open-source coding agent called Pochi, and I have this feature where users can share their chat history along with the agent response to help debug faster. What I've realised, reading their conversations, is that the output of an AI agent is only as good as the contextual guardrails one builds around it.\n\nThe biggest problem with AI code is its tendency to \"hallucinate\" nonexistent libraries or deprecated syntax. This is because developers convey changes from a \"Prompt Engineering\" lens instead of an \"Environment Engineering\" perspective.\n\nAt the end of the day, if you go to see, users never see ‚Äúslop.‚Äù They see broken interfaces, slow loading times, crashes, and unreliable features.\n\nI believe, if you dismiss AI code as \"slop,\" you are missing out on the greatest velocity shift in the history of computing. By combining Open Source discipline (rigorous review and modularity) with AI-assisted execution, we can finally build software that is both fast to ship and resilient to change.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5hy2e/weve_been_shipping_slop_for_20_years_we_just_used/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny00y6z",
          "author": "kubrador",
          "text": "you're not wrong but this is a lot of words to say \"code review matters and garbage in garbage out\"\n\nthe mvp comparison is fair though. i've seen production code at Series B startups that would make an ai agent weep. at least cursor doesn't commit api keys to public repos (usually)\n\nthe \"environment engineering\" framing is just... setting up your tools properly? like yeah if you give an agent zero context it'll hallucinate. if you give a junior zero context they'll also write nonsense. this isn't profound",
          "score": 11,
          "created_utc": "2026-01-06 13:05:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny04yz8",
              "author": "National_Purpose5521",
              "text": "Fair point. A junior with zero context = nonsense. But a junior can't hallucinate 10,000 lines of plausible-looking tech debt in 30 seconds. When I said 'Environment Engineering' bit it wasn't just about setting up a linter but also talking about human-led reviews to system-led constraints. If we're moving from 'code-by-hand' to 'code-by-agent,' our guardrails have to move from passive tools to active governors and rules. Otherwise, that Series B slop becomes a Series C disaster at 10x speed.",
              "score": 2,
              "created_utc": "2026-01-06 13:29:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny05f78",
                  "author": "Low-Opening25",
                  "text": "you clearly didn‚Äôt work with juniors",
                  "score": 2,
                  "created_utc": "2026-01-06 13:31:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "ny0b0pt",
          "author": "doradus_novae",
          "text": "I'm finding that a I is allowing me to build things that I would have never had time to put effort into. Sixteen hundred unit tests? Lets do it.",
          "score": 3,
          "created_utc": "2026-01-06 14:02:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0dv8x",
          "author": "thekernel",
          "text": "but but but the scrum master said MVP was scope not quality!",
          "score": 2,
          "created_utc": "2026-01-06 14:18:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3fz96",
          "author": "UseMoreBandwith",
          "text": "no, that is not what MVP means.",
          "score": 2,
          "created_utc": "2026-01-06 22:49:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0y6uv",
          "author": "Bstochastic",
          "text": "Nonsense",
          "score": 2,
          "created_utc": "2026-01-06 15:58:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0jtop",
          "author": "Danternas",
          "text": "You are absolutely right. But I think the fear is rather that the sloppyness will accelerate as AI accelerate development. We are already at a point where code is so terribly optimised that that was a supercomputer in 2000 will struggle to load Facebook.¬†\n\n\n(My PC in 2006 had a 2 ghz dualcore Athlon 64 and 512gb DOUBLE DATA RATE RAM (DDR). That's a passmark score of 618 compared to 17700 of a Ryzen 5 3600.)\n\n\nBut whether we like it or not the technology is here to stay. It is a tool like many others.",
          "score": 1,
          "created_utc": "2026-01-06 14:49:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny145bm",
          "author": "NachosforDachos",
          "text": " I mean just look at Microsoft",
          "score": 1,
          "created_utc": "2026-01-06 16:26:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1um21",
          "author": "SimonTheRockJohnson_",
          "text": "I agree that we typically shipped slop regardless if it's artisanal junior dev slop.\n\nHowever pretending that adding a jet engine to the slop machine is going to make anything better is laughable. The problems as to why we shipped/ship slop are exacerbated by LLMs not alleviated by them.\n\nYou jump right over the fact that we have/had enough tools to manage juniors we just didn't use them (and the why here is what actually matters), to shiny new tools to manage robot juniors.",
          "score": 1,
          "created_utc": "2026-01-06 18:25:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny23ikq",
          "author": "zhambe",
          "text": "You're confusing things here. The reason people call AI-generated things \"slop\" is because it's mostly things made by wowmonkeys saying \"ooooo look AI AI AI\" -- the slop part isn't that they used AI tool to generate whatever, but the part where they created some useless whatever with no purpose.\n\nAn MVP is the opposite of that. Minimum Viable Product means \"the one most sellable thing we can make on a shoestring budget\", ie it's driven by clear purpose. Sure it might be slapped together in a disgusting manner behind the scenes, but that's not \"slop\". That's just messy prototype-grade code.",
          "score": 1,
          "created_utc": "2026-01-06 19:04:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny3jzbr",
          "author": "RocksAndSedum",
          "text": "speak for yourself.",
          "score": 1,
          "created_utc": "2026-01-06 23:09:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny5x487",
          "author": "Low-Exam-7547",
          "text": "Well. At least the code was written by people who knew what they were doing, could run tests on it, debug it, etc. The problem now is that people with zero idea what they're doing dump this garbage into something that they don't understand and then call it \"MVP\" or \"Production Ready\"",
          "score": 1,
          "created_utc": "2026-01-07 07:55:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyar0kt",
          "author": "Taserface_ow",
          "text": "Not true. MVP is just the minimum amount of features for an acceptable product. It has no correlation to code quality. The code quality could still be top notch, just without the bells and whistles you would see in a more mature product.",
          "score": 1,
          "created_utc": "2026-01-07 23:37:19",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q8e5g6",
      "title": "I built a local RAG visualizer to see exactly what nodes my GraphRAG retrieves",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/vcaupnc1xccg1.jpeg",
      "author": "BitterHouse8234",
      "created_utc": "2026-01-09 17:15:21",
      "score": 13,
      "num_comments": 0,
      "upvote_ratio": 0.93,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q8e5g6/i_built_a_local_rag_visualizer_to_see_exactly/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1q5hp4o",
      "title": "I built an open-source Deepresearch AI for prediction markets.",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/9bomeby95qbg1",
      "author": "SheepherderOwn2712",
      "created_utc": "2026-01-06 12:49:33",
      "score": 12,
      "num_comments": 6,
      "upvote_ratio": 0.8,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5hp4o/i_built_an_opensource_deepresearch_ai_for/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny19dm3",
          "author": "kayore",
          "text": "Really like the background of your website :)",
          "score": 2,
          "created_utc": "2026-01-06 16:49:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny676cr",
              "author": "SheepherderOwn2712",
              "text": "ahah thanks, I used a unicorn studio component",
              "score": 1,
              "created_utc": "2026-01-07 09:28:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxzyn6w",
          "author": "SheepherderOwn2712",
          "text": "Here is the [GitHub repo](https://github.com/yorkeccak/Polyseer)",
          "score": 1,
          "created_utc": "2026-01-06 12:50:17",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "ny1iadv",
          "author": "jonno85",
          "text": "Very nice work!\nAny reason why you focus on gpt-5 reasoning model exclusively?",
          "score": 1,
          "created_utc": "2026-01-06 17:30:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny675b5",
              "author": "SheepherderOwn2712",
              "text": "Not really tbh, Opus 4.5 might be a better option now but wasn't available when I made the first version of this",
              "score": 2,
              "created_utc": "2026-01-07 09:28:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny6nqrc",
          "author": "pereighjghjhg",
          "text": "you guys won the openAI hackathon, right?",
          "score": 1,
          "created_utc": "2026-01-07 11:51:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qbnhjd",
      "title": "500Mb Named Entity Recognition (NER) model to identify and classify entities in any text locally. Easily fine-tune on any language locally (see example for Spanish).",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qbnhjd/500mb_named_entity_recognition_ner_model_to/",
      "author": "Ok_Hold_5385",
      "created_utc": "2026-01-13 10:01:26",
      "score": 11,
      "num_comments": 7,
      "upvote_ratio": 0.93,
      "text": "[https://huggingface.co/tanaos/tanaos-NER-v1](https://huggingface.co/tanaos/tanaos-NER-v1)\n\nA small (500Mb, 0.1B params) but efficient Named Entity Recognition (NER) model which¬†**identifies and classifies entities in text into predefined categories** (person, location, date, organization...) locally.\n\n# Use-case\n\nYou have unstructured text and you want to extract specific chunks of information from it, such as names, dates, products, organizations and so on, for further processing.\n\n    \"John landed in Barcelona at 15:45.\"\n    \n    >>> [{'entity_group': 'PERSON', 'word': 'John', 'start': 0, 'end': 4}, {'entity_group': 'LOCATION',  'word': 'Barcelona', 'start': 15, 'end': 24}, {'entity_group': 'TIME', 'word': '15:45.', 'start': 28, 'end': 34}]\n\n# Fine-tune on custom domain or language without labeled data (no GPU needed)\n\nDo you want to tailor the model to your specific domain (medical, legal, engineering etc.) or to a different language? Use the¬†[Artifex library](https://github.com/tanaos/artifex)¬†to fine-tune the model on CPU by generating synthetic training data on-the-fly.\n\n    from artifex import Artifex\n    \n    ner = Artifex().named_entity_recognition\n    \n    ner.train(\n        domain=\"documentos medico\",\n        named_entities={\n            \"PERSONA\": \"Personas individuales, personajes ficticios\",\n            \"ORGANIZACION\": \"Empresas, instituciones, agencias\",\n            \"UBICACION\": \"√Åreas geogr√°ficas\",\n            \"FECHA\": \"Fechas absolutas o relativas, incluidos a√±os, meses y/o d√≠as\",\n            \"HORA\": \"Hora espec√≠fica del d√≠a\",\n            \"NUMERO\": \"Mediciones o expresiones num√©ricas\",\n            \"OBRA_DE_ARTE\": \"T√≠tulos de obras creativas\",\n            \"LENGUAJE\": \"Lenguajes naturales o de programaci√≥n\",\n            \"GRUPO_NORP\": \"Grupos nacionales, religiosos o pol√≠ticos\",\n            \"DIRECCION\": \"Direcciones completas\",\n            \"NUMERO_DE_TELEFONO\": \"N√∫meros de tel√©fono\"\n        },\n        language=\"espa√±ol\"\n    )\n\n# Don't want to self-host the model?\n\nIf you don't want to self-host this model, and you'd rather use an API, you can use this model via the Small-Language-Model API. Try it for free directly on your browser: [https://slm.tanaos.com/docs](https://slm.tanaos.com/docs)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qbnhjd/500mb_named_entity_recognition_ner_model_to/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzghzb9",
          "author": "OnyxProyectoUno",
          "text": "Nice to see a lightweight NER model that runs locally. Entity extraction is one of those preprocessing steps that can make or break your downstream retrieval quality, but most people bolt it on as an afterthought.\n\nThe synthetic training approach is clever. Usually when you're dealing with domain-specific docs, the generic PERSON/ORG/LOC categories miss the stuff that actually matters. Medical records need drug names, dosages, procedure codes. Legal docs need case citations, statute references, party names. Having a way to define custom entity types without manual labeling saves a lot of pain.\n\nOne thing to watch out for when you're using NER in document processing pipelines: entity boundaries getting mangled during chunking. You extract \"Dr. Sarah Johnson\" as a PERSON entity, but then your chunker splits right through it and you lose the connection. The entity extraction and chunking steps need to be coordinated, not just run sequentially.\n\nAlso worth thinking about how you handle entity disambiguation. \"Apple\" the company vs \"apple\" the fruit. Context helps, but if your chunks are too small, you lose that context. Sometimes it's better to run NER on larger text windows and then propagate the entities down to the individual chunks.\n\nAre you planning to use this for enriching chunks before they go into a vector store, or more for post-retrieval processing?",
          "score": 2,
          "created_utc": "2026-01-14 01:07:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzia03u",
              "author": "Ok_Hold_5385",
              "text": "Thanks for the detailed feedback. I created this model as part of the [Artifex library](https://github.com/tanaos/artifex), whose purpose is to make it easy to run and fine-tune task-specific Small Language Model on CPU. My goal was to create an efficient and lightweight model, while letting users find the best use cases for it.",
              "score": 1,
              "created_utc": "2026-01-14 08:35:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzgxuuo",
          "author": "WallyPacman",
          "text": "Stupid question but how does one integrate with one of those? I imagine not llama-cpp?",
          "score": 1,
          "created_utc": "2026-01-14 02:37:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzh4wf3",
              "author": "robogame_dev",
              "text": "Looks like the linked Artifex library can be used to run them locally with Python - and that they run on cpu.",
              "score": 1,
              "created_utc": "2026-01-14 03:17:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nziaf8a",
              "author": "Ok_Hold_5385",
              "text": "As u/robogame_dev mentioned, this model is meant to be used through the [Artifex library](https://github.com/tanaos/artifex) for CPU inference and fine-tuning\n\n    from artifex import Artifex\n    \n    ner = Artifex().named_entity_recognition\n    \n    named_entities = ner(\"John landed in Barcelona at 15:45.\")\n    print(named_entities)\n    \n    # >>> [[{'entity_group': 'PERSON', 'score': 0.92174554, 'word': 'John', 'start': 0, 'end': 4}, {'entity_group': 'LOCATION', 'score': 0.9853817, 'word': ' Barcelona', 'start': 15, 'end': 24}, {'entity_group': 'TIME', 'score': 0.98645407, 'word': ' 15:45.', 'start': 28, 'end': 34}]]\n\nIf you'd rather use this model through a fully managed API, you can try this [https://slm.tanaos.com/docs#/Models%20endpoints/named\\_entity\\_recognition\\_inference\\_models\\_named\\_entity\\_recognition\\_post](https://slm.tanaos.com/docs#/Models%20endpoints/named_entity_recognition_inference_models_named_entity_recognition_post)",
              "score": 1,
              "created_utc": "2026-01-14 08:39:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzh593y",
          "author": "robogame_dev",
          "text": "This is really cool - I remember your prior post on using something similar to censor PII.\n\nOut of curiosity, what sorts of use cases do you see as the boundary, where you‚Äôd want to switch from something like this to a full LLM for? Any recommendations or best practices for setting this guy up?",
          "score": 1,
          "created_utc": "2026-01-14 03:19:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzic9gg",
              "author": "Ok_Hold_5385",
              "text": "Thanks! Yes, the PII tool is a fine-tuned version of this very model.\n\nI think that, in general, full LLMs are overkill for NER tasks. 95% of the times you're better off using a SLM, as they are cheaper, faster and often better performing. The only exceptions are extremely long context lengths (where SLMs may not perform well) and very specific domains that the SLM was not fine-tuned on (that's why the Artifex library gives you the ability to fine-tune the model on any domain and/or language).\n\nAbout recommendations on how to set it up:\n\n1. Understand the task you will be using the model on, especially the language that will be used and the domain (medical, engineering, legal...).\n2. Once you have that down, fine-tune the base NER model with Artifex on your specific task. [See this doc page for details on how to do it](https://docs.tanaos.com/artifex/named-entity-recognition/train/).\n3. Once you have the fine-tuned model, use [Artifex's load method](https://docs.tanaos.com/artifex/named-entity-recognition/load/) to load the new model and subsequently [the call method](https://docs.tanaos.com/artifex/named-entity-recognition/inference/) to perform inference with it.\n\nYou can also check [this page](https://docs.tanaos.com/artifex/named-entity-recognition/code-examples/) for a full end-to-end example.\n\nIf you have any more questions don't hesitate to ask.",
              "score": 2,
              "created_utc": "2026-01-14 08:57:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q5g7qs",
      "title": "I built a TypeScript implementation of Recursive Large Language Models (RLM)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q5g7qs/i_built_a_typescript_implementation_of_recursive/",
      "author": "nitayrabi",
      "created_utc": "2026-01-06 11:34:22",
      "score": 10,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "Hey everyone!\n\nI just open-sourced rllm, a TypeScript implementation of Recursive Large Language Models (RLM), inspired by the original Python approach - [https://alexzhang13.github.io/blog/2025/rlm/](https://alexzhang13.github.io/blog/2025/rlm/)\n\nRLMs let an LLM work with very large contexts (huge documents, datasets, etc.) without stuffing everything into one prompt. Instead, the model can generate and execute code that recursively inspects, splits, and processes the context.\n\n**Why TypeScript?**\n\n\\* Native to Node / Bun / Deno: no Python subprocesses or servers\n\n\\* Uses V8 isolates for sandboxed execution instead of Python REPLs\n\n\\* Strong typing with Zod schemas, so the LLM understands structured context\n\n**What it does?**\n\n\\* Lets an LLM generate code to explore large context\n\n\\* Executes that code safely in a sandbox\n\n\\* Recursively calls sub-LLMs as needed\n\n\\* Tracks iterations and sub-calls for visibility\n\n**Repo:** [**https://github.com/code-rabi/rllm**](https://github.com/code-rabi/rllm)\n\nIt‚Äôs still early, but usable. I‚Äôd love feedback on:\n\n\\* API design\n\n\\* Safety / sandboxing approach\n\n\\* Real-world use cases where this could shine\n\nHappy to answer questions or hear critiques!",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5g7qs/i_built_a_typescript_implementation_of_recursive/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny07ydp",
          "author": "dreamingwell",
          "text": "Sounds cool. A directly executable demo data set or a very short video in the repo would go a long way to help others understand why they should use this.",
          "score": 1,
          "created_utc": "2026-01-06 13:45:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny08jij",
              "author": "nitayrabi",
              "text": "Good note, in reaching out to the original article writers to get the exact benchmark to compare, but a video is a good suggestion",
              "score": 1,
              "created_utc": "2026-01-06 13:49:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxzxwb",
      "title": "If you had to choose ONE LLM API today (price/quality), what would it be?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pxzxwb/if_you_had_to_choose_one_llm_api_today/",
      "author": "SmaugJesus",
      "created_utc": "2025-12-28 19:23:51",
      "score": 10,
      "num_comments": 25,
      "upvote_ratio": 1.0,
      "text": "Hey everyone,\n\nI‚Äôm currently building a small SaaS and I‚Äôm at the point where I need to choose an LLM API.\n\nThe use case is fairly standard:\n\n\t‚Ä¢\ttext understanding\n\n\t‚Ä¢\tclassification / light reasoning\n\n\t‚Ä¢\tgenerating structured outputs (not huge creative essays)\n\nI don‚Äôt need the absolute smartest model, but I do care a lot about:\n\n\t‚Ä¢\tprice / quality ratio\n\n\t‚Ä¢\tpredictability\n\n\t‚Ä¢\tgood performance in production (not just benchmarks)\n\nThere are so many options now (OpenAI, Anthropic, Mistral, etc.) and most comparisons online are either outdated or very benchmark-focused.\n\nSo I‚Äôm curious about real-world feedback:\n\n\t‚Ä¢\tWhich LLM API are you using in production?\n\n\t‚Ä¢\tWhy did you choose it over the others?\n\n\t‚Ä¢\tAny regrets or hidden costs I should know about?\n\nWould love to hear from people who‚Äôve actually shipped something.\n\nThanks!",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pxzxwb/if_you_had_to_choose_one_llm_api_today/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwewvtw",
          "author": "tech2biz",
          "text": "IMO, trying to choose one model over all others is the wrong approach because you will always tend to go with a big one that can fulfill ALL requirements while only a small portion of your queries or tool calls really needs a big model and could easily be solved by a small or open source model. so ultimately just choosing one big model will always have a horrible price/quality ratio.",
          "score": 7,
          "created_utc": "2025-12-28 19:32:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjua2t",
              "author": "Mikasa0xdev",
              "text": "Model stacking is the real MVP.",
              "score": 1,
              "created_utc": "2025-12-29 14:39:19",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf9dfo",
          "author": "aiprod",
          "text": "Tricky because model performance is constantly shifting. I‚Äòm a big fan of google‚Äòs offering lately. Flash and flash lite are both great for lower complexity workloads. They‚Äòre fairly cheap and fast. Google also has pretty good rate limits.",
          "score": 2,
          "created_utc": "2025-12-28 20:32:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwfyg9d",
          "author": "Comfortable-Sound944",
          "text": "To should probably create your own small evaluation set for your specific task to run against a potential model and try a few.\n\nAnother consideration you didn't mention I find important is speed. If it's online while a user waits or batch and how many calls do you need... \n\nClassification could be super simple for LLMs if you say look at this and choose one of 4 groups... This task can probably be done by the cheapest model from the last 2 years or so. Look at -nano's -lite ects",
          "score": 2,
          "created_utc": "2025-12-28 22:37:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgdup5",
          "author": "Lonely-Dragonfly-413",
          "text": "go with openai. Do not use google apis. their llm apis automatically retire each year. you have to update prompts when you switch to a new model. it is a nightmare.",
          "score": 2,
          "created_utc": "2025-12-28 23:59:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwkuchy",
              "author": "SmaugJesus",
              "text": "Ah damn, I was hesitating for taking Gemini.\nThank you for letting me know this downside",
              "score": 1,
              "created_utc": "2025-12-29 17:35:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwggfqp",
          "author": "FormalAd7367",
          "text": "i‚Äôm doing a lot of office works so i choose the cheap one like chinese model (qwen).",
          "score": 2,
          "created_utc": "2025-12-29 00:12:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgry6j",
          "author": "Coollime17",
          "text": "I‚Äôve been using OpenAI APIs since ChatGPT launched and never really felt a reason to switch. \n\nRight now GPT 5.2, Reasoning=None is my go to starting point for most tasks. If it‚Äôs more complicated you can split it into multiple tasks or add reasoning. If it‚Äôs a well defined simple task or very token intensive you can use a mini model. Structured Outputs work really well and you can define a lot different constraints.\n\nCost is fairly well defined with being able to limit input/output tokens plus the amount of reasoning it can do. Usually they offer the best model at a discount to other ones to encourage people to switch so in general I‚Äôd suggest usually updating to the latest model if you care about cost/performance.",
          "score": 2,
          "created_utc": "2025-12-29 01:15:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwh1b5a",
          "author": "maher_bk",
          "text": "Gemini-2.5-flash-lite has been doing wonders for my scraping-with-ai at scale app.\nReally really underrated and price/rates/etc.. are so good.",
          "score": 2,
          "created_utc": "2025-12-29 02:09:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktx4r",
              "author": "SmaugJesus",
              "text": "Yeah this one was on my list",
              "score": 1,
              "created_utc": "2025-12-29 17:33:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwh2owx",
          "author": "khontolhu",
          "text": "Price / quality? Deepseek v3.2 (if speed is not a priority).\n\nGet 2 out of 3 price, quality, speed.",
          "score": 2,
          "created_utc": "2025-12-29 02:17:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhdy38",
          "author": "konmik-android",
          "text": "You need to run your real requests with all LLMs you are considering, and estimate the amount of tokens consumed and response speed. They might surprise you. Some LLMs are too slow, others consume more tokens than expected, some are good but on your specific task they might just drop the ball.",
          "score": 2,
          "created_utc": "2025-12-29 03:22:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhv02u",
          "author": "Unique-Big-5691",
          "text": "for that kind of use case, i‚Äôd optimize for boring and predictable, not ‚Äúbest model on twitter this week‚Äù.\n\nif i had to pick one right now, it‚Äôd probably be gpt-4o-mini (or that tier). it‚Äôs not the smartest model out there, but it‚Äôs been the least annoying in prod for me. it sticks to instructions, keeps its output shape, and i don‚Äôt spend time wondering why it suddenly went off format.\n\nclaude haiku is also solid, but i‚Äôve found you need to be more explicit to keep the structure consistent. totally usable, just a bit more prompt discipline.\n\nthe bigger thing though isn‚Äôt really the model, it‚Äôs how you deal with the output. once things are live, the pain comes from small format drift and edge cases. having something that enforces structure at the boundary (schemas, validation, etc. pydantic fits nicely here) makes life a lot calmer and lets you swap models later without rewriting everything.\n\nmy rule of thumb: pick the model that behaves most consistently with your prompts, then lock it down. boring and stable wins in prod.",
          "score": 2,
          "created_utc": "2025-12-29 05:09:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwi50eo",
          "author": "caffeine947",
          "text": "Cerebras with the latest glm series model.  Decent workhorse model with over 2000 tokens per second output and much less than 1s to first token.  Absolutely insane speeds, and not expensive either.",
          "score": 2,
          "created_utc": "2025-12-29 06:26:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktq3y",
              "author": "SmaugJesus",
              "text": "Never heard, I will check this out. Thank you very much for your comment",
              "score": 1,
              "created_utc": "2025-12-29 17:32:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwkj65n",
          "author": "Middle_Macaron1033",
          "text": "I‚Äôd do with Back Board IO, every time. It‚Äôs an LLM aggregator with a strong memory layer. It‚Äôd be dumb to choose only one LLM",
          "score": 2,
          "created_utc": "2025-12-29 16:42:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwktlag",
              "author": "SmaugJesus",
              "text": "Thank you for the tip, I‚Äôll check this out",
              "score": 1,
              "created_utc": "2025-12-29 17:31:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwf1n21",
          "author": "Purple-Programmer-7",
          "text": "Any of the big providers fit your description, but those are not the criteria I would be using.\n\n- Rate limits\n- Context windows\n- Scalability\n- Privacy\n- Security\n\nAnd these are highly dependent on use case.\n\nEdit: - Location",
          "score": 1,
          "created_utc": "2025-12-28 19:55:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf4s3k",
          "author": "PromptOutlaw",
          "text": "GPT 4.1/5.2. I‚Äôm busy releasing a paper on personality analysis and damn it‚Äôs so hard to tame LLMs with output and consistency. Whatever u do don‚Äôt consider Cohere, Deepaeek or Kimi. Nightmare.\n\nOpus is pretty tame with some adapters. Sonnet is unreliable with reasoning consistency",
          "score": 1,
          "created_utc": "2025-12-28 20:10:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwg4f9s",
              "author": "cathaysia",
              "text": "Can you elaborate more on why not to consider Cohere? I‚Äôm working on a project and got some credits from them, wanted to keep with something well maintained since I will be handing it over to a team with limited tech skills (no engineering team).",
              "score": 1,
              "created_utc": "2025-12-28 23:08:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgdzpo",
                  "author": "PromptOutlaw",
                  "text": "Quick clarification , I deployed Cohere-command-a on Azure AI and this can be different.\n\nMy current study has a JSON compliance acceptance criteria of 98%. Cohere and Kimi K2 had roughly 70% compliance. I spent days creating adapters and I was strict on not inferring json output. I‚Äôm ok stripping junk around it but the LLM had to provide a schema validated json in order for me to validate reasoning based on don numbers.\n\nHere is my prompt: https://github.com/Wahjid-Nasser/12-Angry-Tokens/blob/main/prompts/judge_prompt.md\n\nI don‚Äôt wanna shade Cohere, I just could not get the compliance right and direct api works could be diff. I‚Äôm just short on time and decided to exclude it",
                  "score": 1,
                  "created_utc": "2025-12-28 23:59:57",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwf87dp",
              "author": "TastyWriting8360",
              "text": "Again hitonet.",
              "score": -1,
              "created_utc": "2025-12-28 20:27:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nxmq6rk",
          "author": "Bonnie-Chamberlin",
          "text": "Kimi K2 might be a choice (since no one has mentioned",
          "score": 1,
          "created_utc": "2026-01-04 14:40:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwf83d7",
          "author": "TastyWriting8360",
          "text": "Cheap, fast and smart? Hitonet.com try the free tier.",
          "score": -2,
          "created_utc": "2025-12-28 20:26:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q2969w",
      "title": "The Claude Code workflow that lets me move fast without breaking things",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q2969w/the_claude_code_workflow_that_lets_me_move_fast/",
      "author": "n3s_online",
      "created_utc": "2026-01-02 20:10:21",
      "score": 10,
      "num_comments": 5,
      "upvote_ratio": 0.92,
      "text": "I kept hitting a tradeoff: move fast and ship bugs, or slow down and review everything manually. Built a workflow that gets both.\n\nThe core loop:\n1. Plan mode + plan reviewer sub-agent: Claude thinks before coding, a separate sub-agent with fresh context catches architectural gaps\n2. Coding agent memory: my agent files [Beads](https://github.com/steveyegge/beads) (like GitHub issues but way better, and live in Git) and works off of them so each session I can just start with \"What's next?\" and my coding agent knows what to work on.\n3. Code reviewer sub-agent: Fresh context window dedicated to catching security holes and edge cases\n4. \"Land the plane\":  One phrase triggers tests, lint, formatting, clean up, commit, push\n\nWhy sub-agents matter:\n\nYour main agent juggles too much -  file contents, conversation history, your requests. Load it with detailed standards and it does a mediocre job at everything.\n\nSub-agents specialize. Each starts fresh, enforces specific standards, returns findings. The plan reviewer knows my architecture patterns. The code reviewer knows my code and security requirements. They catch what the implementation mindset misses.\n\nWhat I'm optimizing for:\n1. Ship fast\n2. No security holes or missed edge cases\n3. Context window stays small (research shows LLM performance degrades past ~40%)\n4. Codebase stays clean as it grows so I can build fast and confidently\n\n[Full writeup with my system prompt, sub agent definitions, and interactive demo](https://willness.dev/blog/claude-code-workflow).",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q2969w/the_claude_code_workflow_that_lets_me_move_fast/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxbmc1b",
          "author": "coffee-praxis",
          "text": "I‚Äôm pretty into spec kit over Plan mode. Sometimes I‚Äôll make a plan first then feed to spec kit, but Plan mode on its own can go off rails frequently.",
          "score": 1,
          "created_utc": "2026-01-02 21:12:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxbp91a",
              "author": "n3s_online",
              "text": "I've never tried Spec Kit but it seems to fulfill the role that I currently use Beads for. I'll try it out next week and let you know what I think!",
              "score": 1,
              "created_utc": "2026-01-02 21:26:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxkzhuw",
          "author": "LittleJuggernaut7365",
          "text": "nice my plugin i use is similar   \n[https://github.com/GantisStorm/essentials-claude-code](https://github.com/GantisStorm/essentials-claude-code)",
          "score": 1,
          "created_utc": "2026-01-04 06:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1wbmm",
          "author": "UMANTHEGOD",
          "text": "How does your task splitter look?",
          "score": 1,
          "created_utc": "2026-01-06 18:32:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny2cjrq",
              "author": "n3s_online",
              "text": "Great question! I actually just updated the article to talk about my task splitter, the sub-agent definition is in there too.\n\nTLDR: Sub-agent that splits up a plan into tasks that can be done in \\~40% of a claude code context window",
              "score": 1,
              "created_utc": "2026-01-06 19:46:15",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1e1zn",
      "title": "Generate OpenAI Embeddings Locally with embedding-adapters library ( 70√ó faster query embeddings! )",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1e1zn/generate_openai_embeddings_locally_with/",
      "author": "Interesting-Town-433",
      "created_utc": "2026-01-01 20:23:50",
      "score": 9,
      "num_comments": 7,
      "upvote_ratio": 0.85,
      "text": "[EmbeddingAdapters ](https://medium.com/@ace0278/generate-openai-style-embeddings-locally-with-minilm-adapter-f43ec9c3b7da)is a Python library for translating between embedding model vector spaces.\n\nIt provides plug-and-play adapters that map embeddings produced by one model into the vector space of another ‚Äî locally or via provider APIs ‚Äî enabling cross-model retrieval, routing, interoperability, and migration **without re-embedding an existing corpus**.\n\nIf a vector index is already built using one embedding model, embedding-adapters allows it to be queried using another, without rebuilding the index.\n\n**GitHub:**  \n[https://github.com/PotentiallyARobot/EmbeddingAdapters/](https://github.com/PotentiallyARobot/EmbeddingAdapters/)\n\n**PyPI:**  \n[https://pypi.org/project/embedding-adapters/](https://pypi.org/project/embedding-adapters/)\n\n# Example\n\nGenerate an OpenAI embedding locally from minilm+adapter:\n\n    pip install embedding-adapters\n    \n    embedding-adapters embed \\\n      --source sentence-transformers/all-MiniLM-L6-v2 \\\n      --target openai/text-embedding-3-small \\\n      --flavor large \\\n      --text \"where are restaurants with a hamburger near me\"\n\nThe command returns:\n\n* an embedding in the target (OpenAI) space\n* a confidence / quality score estimating adapter reliability\n\n# Model Input\n\nAt inference time, the adapter‚Äôs **only input is an embedding vector** from a source model.  \nNo text, tokens, prompts, or provider embeddings are used.\n\nA pure **vector ‚Üí vector** mapping is sufficient to recover most of the retrieval behavior of larger proprietary embedding models for in-domain queries.\n\n# Benchmark results\n\n**Dataset:** SQuAD (8,000 Q/A pairs)\n\n**Latency (answer embeddings):**\n\n* MiniLM embed: **1.08 s**\n* Adapter transform: **0.97 s**\n* OpenAI API embed: **40.29 s**\n\n‚âà **70√ó faster** for local MiniLM + adapter vs OpenAI API calls.\n\n**Retrieval quality (Recall@10):**\n\n* MiniLM ‚Üí MiniLM: **10.32%**\n* Adapter ‚Üí Adapter: **15.59%**\n* Adapter ‚Üí OpenAI: **16.93%**\n* OpenAI ‚Üí OpenAI: **18.26%**\n\nBootstrap difference (OpenAI ‚àí Adapter ‚Üí OpenAI): **\\~1.34%**\n\nFor in-domain queries, the MiniLM ‚Üí OpenAI adapter recovers \\~**93%** of OpenAI retrieval performance and substantially outperforms MiniLM-only baselines.\n\n# How it works (high level)\n\nEach adapter is trained on a **restricted domain**, allowing it to specialize in interpreting the semantic signals of smaller models and projecting them into higher-dimensional provider spaces while preserving retrieval-relevant structure.\n\nA quality score is provided to determine whether an input is well-covered by the adapter‚Äôs training distribution.\n\n# Practical uses in Python applications\n\n* Query an existing vector index built with one embedding model using another\n* Operate mixed vector indexes and route queries to the most effective embedding space\n* Reduce cost and latency by embedding locally for in-domain queries\n* Evaluate embedding providers before committing to a full re-embed\n* Gradually migrate between embedding models\n* Handle provider outages or rate limits gracefully\n* Run RAG pipelines in air-gapped or restricted environments\n* Maintain a stable ‚Äúcanonical‚Äù embedding space while changing edge models\n\n# Supported adapters\n\n* MiniLM ‚Üî OpenAI\n* OpenAI ‚Üî Gemini\n* E5 ‚Üî MiniLM\n* E5 ‚Üî OpenAI\n* E5 ‚Üî Gemini\n* MiniLM ‚Üî Gemini\n\nThe project is under active development, with ongoing work on additional adapter pairs, domain specialization, evaluation tooling, and training efficiency.\n\nPlease Like/Upvote if you found this interesting",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1e1zn/generate_openai_embeddings_locally_with/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx80hsp",
          "author": "gopietz",
          "text": "While this sounds like a clever idea, I would need massive proof that this actually works in practice.",
          "score": 3,
          "created_utc": "2026-01-02 08:21:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx6td65",
          "author": "OnyxProyectoUno",
          "text": "Most people think embedding migration means re-embedding everything from scratch. This adapter approach is clever because it sidesteps that entire problem.\n\nThe vector-to-vector mapping is the key insight here. You're not trying to recreate the original text understanding, just translating between learned representations. That's why you can get 93% of OpenAI performance without touching the original documents.\n\nThe domain restriction makes sense too. A general-purpose adapter would probably fail because different models emphasize different semantic features. Training on specific domains lets you learn which features actually matter for that use case.\n\nOne thing to watch out for is drift over time. If your query distribution changes significantly from what the adapter was trained on, that quality score becomes critical. You'll want monitoring around when to fall back to the original embedding model.\n\nThe latency numbers are compelling for high-volume scenarios. 70x speedup means you could handle query spikes without hitting rate limits or burning through API costs. That's especially useful for user-facing search where response time matters.\n\nAre you planning adapters for other model families? The current coverage hits the main commercial providers, but there's probably demand for open-source model bridges too. Something like BGE or Instructor models would round out the ecosystem.\n\nAlso curious about the training data requirements. How much domain-specific data do you need to train a reliable adapter for a new use case?",
          "score": 2,
          "created_utc": "2026-01-02 02:56:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxqhsva",
              "author": "Interesting-Town-433",
              "text": "Hey thanks for the awesome response! Glad you  appreciate it.  I put a lot of love into it - hope it shows.  And yes, the next version will introduce a pretty wild expansion into other model families and modalities. Learned some pretty interesting things about the shared semantic manifolds between embedding models - submitting some papers about it atm.  The v2 models I'm training are much more advanced but I think even with what's released  people will start to see the value. \n\nCutting even 10% of embedding costs can be huge for companies who do RAG. If you are a startup / represent a company, I have licensable models that are much higher fidelity, can be run locally, are extremely fast, and excel in air-gapped environments.\n\nTrying to get this bird off the ground and genuinely need all the help from the community and anyone else who is able. Please spread the word.  If nothing else please use and enjoy. It really works. It's not a gimic. And the library is open to anyone to add to. I'll be adding scripts in the next version to make training and fine tuning easier and I think answer a lot of these questions.",
              "score": 1,
              "created_utc": "2026-01-05 01:22:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx886c1",
          "author": "-Cubie-",
          "text": "At what point does it make more sense to just finetune an open embedding model using e.g. OpenAI (or a better model) as a teacher and use that instead of an adapter? Feels a bit safer than an adapter to match OpenAI embeddings.",
          "score": 1,
          "created_utc": "2026-01-02 09:35:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxqjx4s",
              "author": "Interesting-Town-433",
              "text": "Yeah I tried that too, actually haha that does work also, at least a little, ( I'm talking about training an llm with the embedding as the teacher - a bit like holding a dog by the nose as you walk them ). Remember embeddings are mean pooled so we lose a lot of semantic signal in the process, they aren't the best teacher by themselves, but they can act as a guide / stabilizing agent",
              "score": 1,
              "created_utc": "2026-01-05 01:33:29",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxljdrt",
          "author": "makinggrace",
          "text": "Oh yeah. This is interesting. It'll be interesting to see the distribution patterns over scale and time. Here's hoping they are (a) predictable and (b) not accelerated wildly by speed.",
          "score": 1,
          "created_utc": "2026-01-04 09:15:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxrnqs9",
              "author": "Interesting-Town-433",
              "text": "Thanks lmk what you find / how you use it",
              "score": 1,
              "created_utc": "2026-01-05 05:18:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1qwco",
      "title": "Teaching AI Agents to Remember (Agent Memory System + Open Source)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1qwco/teaching_ai_agents_to_remember_agent_memory/",
      "author": "Conscious_Search_185",
      "created_utc": "2026-01-02 06:03:18",
      "score": 9,
      "num_comments": 13,
      "upvote_ratio": 0.77,
      "text": "I have seen most AI agents fail in production not because they can‚Äôt reason, but because they forget. Past decisions, failures, and context vanish between sessions, so agents repeat the same mistakes and need constant babysitting. What if memory was treated as a first class system, not just longer prompts or retrieval?\n\nHindsight is an open source agent memory system built around that idea. Instead of replaying transcripts, it stores experiences, facts, and observations separately, then uses reflection to form higher level insights over time. The goal isn‚Äôt just recall, but behavior change in long running agents.\n\nI have been exploring it and early benchmarks look promising, but I‚Äôm more interested in real world feedback from people building agents outside demos.\n\nDocs:[ https://hindsight.vectorize.io/](https://hindsight.vectorize.io/?utm_source=chatgpt.com)GitHub:[ https://github.com/vectorize-io/hindsight](https://github.com/vectorize-io/hindsight?utm_source=chatgpt.com)\n\nWould love thoughts from folks working on agent memory, long running workflows, or systems that need consistency over time.\n\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1qwco/teaching_ai_agents_to_remember_agent_memory/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx7ohie",
          "author": "Hot_Substance_9432",
          "text": "Possible to create more examples with Gemini etc in the docs?",
          "score": 2,
          "created_utc": "2026-01-02 06:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7o94j",
          "author": "Hot_Substance_9432",
          "text": "Awesome work and very nice documentation:)",
          "score": 1,
          "created_utc": "2026-01-02 06:30:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx7picl",
              "author": "Mikasa0xdev",
              "text": "Memory is the hardest debug loop.",
              "score": 1,
              "created_utc": "2026-01-02 06:41:28",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nx7q4bx",
                  "author": "Hot_Substance_9432",
                  "text": "Also correct Context and handoff",
                  "score": 1,
                  "created_utc": "2026-01-02 06:46:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nx7wjja",
          "author": "fnl",
          "text": "Very beautiful setup and a nice paper!\n\nHow do you track memory formation, and examine the current memory for a given query? In other words, how do get observability into what Hindsight is doing when using this in production?",
          "score": 1,
          "created_utc": "2026-01-02 07:44:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx8sm68",
          "author": "blue_marker_",
          "text": "This looks promising. I‚Äôm surprised the paper nor the documentation mention Cognee. As far as I can tell, it is the closest in nature to this approach. It even has an incredibly similar API. I would recommend researching their software and doing a side by side comparison, both so that you can differentiate and also so that if they have something potentially beneficial you can include it in your project.",
          "score": 1,
          "created_utc": "2026-01-02 12:35:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsc55w",
          "author": "Special-Land-9854",
          "text": "Have you tried integrating Back Board IO into your AI Agent? It‚Äôs an LLM aggregator with a really strong memory layer built into its API",
          "score": 1,
          "created_utc": "2026-01-05 08:45:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxsddwt",
          "author": "SheepherderOwn2712",
          "text": "Heard supermemory is pretty decent, have you tried?",
          "score": 1,
          "created_utc": "2026-01-05 08:57:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0vnaa",
          "author": "Special-Land-9854",
          "text": "Been using Back Board IO for memory in my AI agent",
          "score": 1,
          "created_utc": "2026-01-06 15:47:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nycbd1b",
          "author": "badgerbadgerbadgerWI",
          "text": "Memory as a first-class system is the right framing. The challenge is making it queryable and relevant without ballooning context windows. We've had good results with episodic memory + semantic retrieval, where past sessions become searchable context rather than always-loaded state.",
          "score": 1,
          "created_utc": "2026-01-08 04:38:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyfocvh",
          "author": "Life_Move_8923",
          "text": "Great work on this. We have been working on methods to inject memory that doesn't lead to context bloat and maintains relevancy and helpfulness to users, interesting to see how this could work (specifically within personalized training, learning, support space)",
          "score": 1,
          "created_utc": "2026-01-08 17:36:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q50xgh",
      "title": "I built a desktop GUI to debug vector DBs and RAG retrieval",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q50xgh/i_built_a_desktop_gui_to_debug_vector_dbs_and_rag/",
      "author": "snirjka",
      "created_utc": "2026-01-05 22:53:02",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "üëã Hey everyone,\n\nI‚Äôve been building a lot of RAG pipelines lately and kept running into the same issue: once data is inside the vector DB, it‚Äôs hard to really inspect embeddings and understand why retrieval works or fails without writing scripts or notebooks.\n\nSo I built VectorDBZ, a desktop GUI for exploring and debugging vector databases and embeddings across different providers.\n\nWhat it supports:\n\n‚Ä¢ Qdrant, Weaviate, Milvus, Chroma, and pgvector\n‚Ä¢ Browsing collections, vectors, and metadata\n‚Ä¢ Similarity search with filters, score thresholds, and top-K\n‚Ä¢ Generating embeddings from text or files, supports local models (Ollama, etc) and hosted APIs\n‚Ä¢ Embedding visualization with PCA, t-SNE, and UMAP\n‚Ä¢ Basic analysis of distances, outliers, duplicates, and metadata separation\n\nThe goal is fast, interactive debugging of retrieval behavior when working on RAG systems, not replacing programmatic workflows.\n\nLinks:\n\nGitHub\nhttps://github.com/vectordbz/vectordbz\n\nDownloads\nhttps://github.com/vectordbz/vectordbz/releases\n\nWould really love feedback from people building RAG in practice:\n\n‚Ä¢ How do you debug retrieval quality today?\n‚Ä¢ What signals help you decide embeddings are good or bad?\n‚Ä¢ What analysis or views would actually help in production?\n‚Ä¢ Any vector DBs or embedding models you‚Äôd want to see next?\n\nIf you find this useful, a ‚≠ê on GitHub would mean a lot and helps keep me motivated to keep improving it.\n\nThanks!\n",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q50xgh/i_built_a_desktop_gui_to_debug_vector_dbs_and_rag/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny0ccss",
          "author": "Mikasa0xdev",
          "text": "Vector DB debugging is crucial; RAG pipelines need this visibility, nice job!",
          "score": 1,
          "created_utc": "2026-01-06 14:10:11",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcmj1d",
      "title": "Anyone using PydanticAI for agents instead of rolling their own glue code?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qcmj1d/anyone_using_pydanticai_for_agents_instead_of/",
      "author": "Unique-Big-5691",
      "created_utc": "2026-01-14 12:54:40",
      "score": 9,
      "num_comments": 15,
      "upvote_ratio": 0.91,
      "text": "I‚Äôve been messing around with agent setups lately and honestly the part that keeps biting me isn‚Äôt the model, it‚Äôs all the stuff around it‚Ä¶ tool inputs, outputs, retries, state, half-broken JSON, etc.\n\nI started trying PydanticAI mostly out of curiosity, but it‚Äôs kinda nice having the agent‚Äôs ‚Äúworld‚Äù be actual typed objects instead of random dicts flying around. When a tool gets bad input or the model spits out something weird, it fails in a way I can actually see and fix, instead of silently breaking later.\n\nNot saying it‚Äôs magic, but it feels closer to how I want to reason about agents, like ‚Äúthis thing takes this shape and returns this shape‚Äù instead of ‚Äúhope this JSON blob is right ü§û‚Äù.\n\nAnyone else using it this way? Or are you all still just duct-taping tools and prompts together and hoping for the best? üòÖ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcmj1d/anyone_using_pydanticai_for_agents_instead_of/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzo76ay",
          "author": "AI-Agent-geek",
          "text": "Pydantic AI is my favourite Python framework for building agents. If you want a side by side, I have a simple agent written using 12 different frameworks here:\n\nhttps://github.com/rachedblili/AgentExamples/",
          "score": 6,
          "created_utc": "2026-01-15 04:14:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzo84bw",
              "author": "Hot_Substance_9432",
              "text": "No Agno?",
              "score": 1,
              "created_utc": "2026-01-15 04:21:08",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzoitca",
                  "author": "AI-Agent-geek",
                  "text": "I had honestly never heard of Agno until reading your comment.",
                  "score": 1,
                  "created_utc": "2026-01-15 05:37:46",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzjk71d",
          "author": "medright",
          "text": "Ime, started w langchain way back when gpt-4 api was invite only, and shortly found pydantic-ai and switched my stacks. Much more stable and reliable, plus it‚Äôs very nice to have everything typed as that‚Äôs how my fastapi deployments are built too. A few of my pydantic-ai stacks are live(albeit not widely available, I still paygate and use mostly for demos/personal use) you can see them if you like: https://cannabot.pro https://munibot.pro https://evrhaven.com and https://evrstacks.art  my day job is in healthcare, I‚Äôve got a few diff stacks the company is using and rolling out to customers that are built with pydantic-ai as well. It‚Äôs a fun framework, I enjoy using it",
          "score": 3,
          "created_utc": "2026-01-14 14:23:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzns1us",
              "author": "Hot_Substance_9432",
              "text": "Thanks so much for the information, we are evaluating Pydantic AI and LangGraph and Agno so this helps us",
              "score": 2,
              "created_utc": "2026-01-15 02:41:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzp4143",
                  "author": "Charming_Support726",
                  "text": "As stated above. Agno is easy and great to a certain point. If you go beyond - it gets hard.\n\nStay away from LC/LG - It is dark from the beginning. It gets light and bright, when you get near the burning fire of hell.",
                  "score": 1,
                  "created_utc": "2026-01-15 08:43:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzl8301",
          "author": "cmndr_spanky",
          "text": "I‚Äôm a big fan of pedantic AI ‚Äòs agent framework as well. It feels cleaner / more intuitive than langchain.. like it was written by real devs.",
          "score": 3,
          "created_utc": "2026-01-14 18:59:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzjcy86",
          "author": "lionmeetsviking",
          "text": "PydanticAI all the way! I want my data in models, not in unreliable blobs. And it‚Äôs so easy to observe your fill, and if needed, retry with another model.",
          "score": 2,
          "created_utc": "2026-01-14 13:44:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmo3n4",
          "author": "insulaTropicalis",
          "text": "I am on the fence about it. Fact is, object-oriented programming can be nice, but nowadays it seems ubiquitary like \"thou will write everything as classes.\" PydanticAI is very cool, especially if you are heavy in pydantic and FastAPI. It gives you amazing automated docs and logging, but sometimes I just want to write something as a function and stop.\n\nStill considering if that kind of abstraction is my thing. After all, I am not a real software engineer, just a data scientist that creates AI-powered systems.",
          "score": 2,
          "created_utc": "2026-01-14 22:59:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzomokz",
          "author": "autognome",
          "text": "[https://github.com/boazkatzir/pydantic-collab](https://github.com/boazkatzir/pydantic-collab) \\- looks interesting",
          "score": 2,
          "created_utc": "2026-01-15 06:08:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmt3rq",
          "author": "Agreeable-Market-692",
          "text": "if it's for you I would say write it quick and dirty, sometimes that's all you need and my favorite stuff is still done in single python files \n\nif anyone is going to maintain it besides you though Pydantic's solution seems alright",
          "score": 1,
          "created_utc": "2026-01-14 23:25:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzoko4a",
          "author": "Whole-Assignment6240",
          "text": "i'm looking into this as agent stack in 2026!",
          "score": 1,
          "created_utc": "2026-01-15 05:52:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qageex",
      "title": "We tested Chain-of-Debate: forcing Claude, GPT, and Gemini to argue against each other with verified citations. Hallucinations dropped significantly.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qageex/we_tested_chainofdebate_forcing_claude_gpt_and/",
      "author": "Own-Calendar9332",
      "created_utc": "2026-01-12 00:43:29",
      "score": 8,
      "num_comments": 37,
      "upvote_ratio": 0.72,
      "text": "Academic research on **multi-agent debate** is showing strong results for reducing hallucinations. But most implementations use the same model with different personas, which shares the same blind spots.\n\nWe built something different: **Chain-of-Debate** using actually heterogeneous LLMs, **plus a layered verification system.**\n\nWhy Different Models Matter?\n\nRecent research supports this distinction:\n\n\\- A study on agent heterogeneity found that using different foundation models (not just different prompts) yields 91% vs 82% accuracy on reasoning benchmarks.\n\n\\- The A-HMAD framework showed that agents with \"distinct expertise enable more comprehensive error-checking than identical agents.\"\n\n\\- AllAboutAI's TruthNet study found multi-model verification reduced hallucinations by 71%.\n\nThe key insight: Claude, GPT, and Gemini were trained on different data with different RLHF. They genuinely disagree because they have different knowledge and biases. Personas on the same model just pretend to disagree.\n\nOur Approach: Chain-of-Debate + Layered Verification\n\n**Debate Layer:**\n\n1. Heterogeneous models: Claude, GPT, and Gemini assigned opposing positions\n\n2. Structured argumentation: Each model must challenge the others with evidence\n\n3. Claim extraction: Arguments broken into atomic, verifiable claims\n\n**Verification Stack:**\n\n4. Grounding: Citations must be real and retrievable - no phantom sources or fabricated DOIs\n\n5. Semantic relevance: Does the source actually support this specific claim, or just the general topic?\n\n6. On-topic check: Catches ontology mismatch (valid source, wrong domain)\n\n7. Claim verification: Each atomic claim verified against source text independently\n\n8. False-positive suppression: Penalizes plausible-sounding claims that pass surface checks but lack real support\n\nSynthesis: Only claims surviving both cross-examination AND verification make the final output.\n\nWhat We Observed\n\nApproach                                                | Factual Accuracy |\n\n\\--------------------------------------------|-------------------|\n\nSingle model                                           |        \\~62%          |\n\nSingle model + personas                        |        \\~70%          |\n\nChain-of-Debate (no verification)           |        \\~85%          |\n\nChain-of-Debate + verification stack      |         \\~91%         |\n\n\n\nDebate alone catches reasoning errors. Verification catches grounding errors. You need both.\n\nLimitations\n\n\\- \\~3x latency vs single model\n\n\\- Works best for factual/analytical domains\n\n\\- Less tested on creative/subjective tasks\n\nOpen Questions:\n\n1. What is the Optimal number of models before diminishing returns?\n\n2. Which verification layer catches the most errors in practice?\n\n3. How to handle domains with sparse/contradictory sources?\n\n**We've been testing this privately and just opened it up. If anyone wants to try breaking it or test edge cases, drop a comment and I'll share access.**\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qageex/we_tested_chainofdebate_forcing_claude_gpt_and/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz39662",
          "author": "coloradical5280",
          "text": "I do this with qEEG brain scans on patients with traumatic brain injuries, and also patients with early onset dementia. 3 models is absolutely essential, but, when done right, they can often see patterns that the neurology team doesn‚Äôt pick up right away, or just doesn‚Äôt have time to see, with their patient load. \n\nIt goes: \n\n- all 3 models review and analyze raw qEEG data and a few anonymized patient details\n- all models peer review the others‚Äô analysis\n- all models respond to their peer reviews, and make revisions\n- write updated report based on double peer review\n- all three are consolidated into one report\n- consolidated report delivered to all 3 models\n- all three vote anonymously which is best, and whether it can move forward\n- final report created after they deliberate \n- hit ‚Äúexport‚Äù and done.\n\nIt‚Äôs technically a fork of Andrej Karpathy‚Äôs llm-council (though it's barely recognizable as a fork anymore, completely unique FE, completely different backend flow), I combined that with CLIProxyAPI repo, so we can use subscriptions and not api keys. \n\nIt‚Äôs specific that that use case, but pretty easy to change if anyone wants it,  let me know.\n\n++++++++\n\nu/Own-Calendar9332 having done this for a long time and having teams of neurologists analyze every result, I can say with confidence that you should be really careful with how you structure \"debate\" in prompts. It's a fine line between \"peer review\" and \"debate\", but when models are told they *must make challenges to what they are seeing from another model*, that absolutely forces hallucinations.  \n\nYou didn't say you did that, from you numbers it appears you probably didn't, just something to be careful. Any time they are told to find problems as opposed to review and respond, they WILL find a problem (everywhere) whether it's a real one or not.",
          "score": 6,
          "created_utc": "2026-01-12 02:24:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3jmr0",
              "author": "makinggrace",
              "text": "This is a fascinating use case. You could probably strengthen it more by adding some anti-hallucination measures. To your point exactly: when asked to find a problem, the model will find a problem regardless of whether one actually exists because that is the task. Some of that can be mitigated with prompting (impact strength depends on the model however).",
              "score": 1,
              "created_utc": "2026-01-12 03:20:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3nalp",
                  "author": "coloradical5280",
                  "text": "I'm in the fortunate position of having a very \"easy\" use case, all things considered. qEEG data is mostly voltages, and a few other measurements, but all hard numbers.  Used to be part of that prompt included running python in their sandbox to double check their own analysis before submitting, which has now been replaced with .skills scripts (much better on context window and consistency), but either way, it's a lot easier than analyzing words.  Much of the analysis is still somewhat speculative, it is their job to find weird patterns and make connections, after all. However, they have to cite the research that supports that opinion (they have access to a lot of research).  So, even if they found something truly novel, it wouldn't make it through the gauntlet.  But there's not too much truly novel discovery to be made on just qEEG data alone, so I don't think we're missing out. \n\nWith the programatic checks, and the citation requirements, we really don't get hallucinations from GPT 5.2 Pro or Opus-4.5. Gemini will make some wild leaps connecting an opinion to a cited piece of research backing that opinion, but it gets called out by the other two every time.   \n  \nPS - I'm very, very close to kicking gemini out completely, it's very dramatic and impulsive.  Gemini has strengths, no doubt, sticking to \"not-creative\" isn't one of those strengths.  And gemini is [very weird about temperature settings as well ](https://ai.google.dev/gemini-api/docs/gemini-3#javascript:~:text=%7D%0A%0Arun()%3B-,Temperature,looping%20or%20degraded%20performance%2C%20particularly%20in%20complex%20mathematical%20or%20reasoning%20tasks.,-Thought%20signatures).",
                  "score": 3,
                  "created_utc": "2026-01-12 03:40:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4if35",
              "author": "Own-Calendar9332",
              "text": "This is fascinating - using multi-model consensus for medical imaging is exactly the kind of high-stakes domain where single-model confidence is dangerous.\n\nYour point about 'debate' vs 'peer review' framing is spot on. We saw the same issue and built two distinct modes:\n\nAdversarial mode: Models assigned opposing positions, forced to challenge each other's claims. Good for surfacing blind spots on contested topics.\n\nCollaborative mode: Models work as peer reviewers - verify, strengthen, and flag uncertainty rather than attack. Better for domains like yours where you need consensus-building, not manufactured disagreement.\n\nWe also built an academic research mode specifically for citation-heavy work:\n\n\\- Citations must be real and retrievable (no phantom DOIs)\n\n\\- Semantic relevance check: does the source actually support this specific claim, not just the general topic?\n\n\\- Ontology matching: catches \"valid source, wrong domain\" errors\n\n\\- Each atomic claim verified independently against source text\n\nSounds similar to your citation requirement approach. The difference from forcing them to \"find problems\" is exactly what you said - we ask them to \"verify what can be grounded\" rather than \"attack what seems wrong.\"\n\nHappy to share access if you want to compare how our verification stack handles medical/clinical claims. Would be curious how it performs on your qEEG edge cases - and whether the collaborative mode fits your peer review workflow.",
              "score": 1,
              "created_utc": "2026-01-12 07:26:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4m5qq",
                  "author": "coloradical5280",
                  "text": "see my comment here [https://www.reddit.com/r/LLMDevs/comments/1qageex/comment/nz3nalp/](https://www.reddit.com/r/LLMDevs/comments/1qageex/comment/nz3nalp/), i'm pretty dialed, very dialed, actually, but curious on your thoughts regarding the gemini piece.  i'm 90% sure i'm kicking gemini out next week",
                  "score": 1,
                  "created_utc": "2026-01-12 08:00:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz7b9i4",
              "author": "diabloman8890",
              "text": "Ok I'd want to talk to you about this for hours, but for this particular use case how did you decide on this approach vs more traditional machine learning models? Speed, accuracy, cost?",
              "score": 1,
              "created_utc": "2026-01-12 18:08:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7kkej",
                  "author": "coloradical5280",
                  "text": "I never had a plan that was like: \"let's make LLM pipeline to analyze these\".  I am an eval engineer, and on the side was doing some work for this (qEEG) client, on making data more accessible and explainable to patients, instead of just handing them an impossibly complex report, and hoping they remembered all the big words that the neuro team used. And the neuro team barely has time to get their current workflow done.  \n\nSo that context is important: the end goal of my work with them was to produce laymen eli5 digestible interpretations, using analogies, etc. (explainer videos from NotebookLM have been great on occasion). \n\nGiven what I do for work and heavy LLM usage personally, I naturally started playing around with this approach, when LLMs got good enough, so around gpt-4.5 launch, that was a decent model for this, opus-4.1 was decent. And then the latest generation (5.2 Pro-Extended-Thinking specifically) made it clear that something like this could work. \n\nI just thought it would make reports more consistent, and make the eli5 stuff less time consuming to create, without having to correct the model's assumptions, revise, etc. I did not expect, nor did the team, that this could actually result in something that made insights that were often missed before.  That was completely shocking. I'd say on 80% of patients, it's still just that original \"help me make sense of this\" use case. But for 20% (rough guesstimates on these %'s) there is actually a weird pattern that was hard to spot, or just very rare to see and not something we'd look for. \n\nIn terms of more traditional NN approaches, there actually are a ton that exist, with varying degrees of specific focus, for EEGs  \n[EEG Conformer: Convolutional Transformer for EEG Decoding and Visualization](https://pubmed.ncbi.nlm.nih.gov/37015413/)  \n[EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces](https://arxiv.org/html/2405.00719v1)  \nThose are just two random off the top of my head but many dozens exist for this analysis:\n\n* Classical ML baselines (XGBoost/SVM) on engineered EEG features\n* Deep time-series models (1D CNN/TCN/LSTM)\n* Signal transformers (EEG Conformer / transformer classifier)\n* Self-supervised EEG encoders + lightweight head\n* Spatial-temporal GNNs over electrode graphs\n* Ensembles/stacked models\n\nNone of those fit the original use case here, and it seems there's something unique about this approach this is pulling out findings that other solutions haven't. \n\nI know a lot about qEEG analysis, and I'm certified to do so, that DOES NOT make me a neurologist though lol. So, in terms of actual taking this to a research level, that is not my job, and, mostly, outside the scope of my involvement.  My job is in the mieutua of back prop and data quality and eval harnesses, half of which is really just making existing tools work together, I'm not a researcher. \n\nIt'll be interesting to see what the next gen brings, I know it's firmly been decided that as of now, the original use case is the main point, and the secondary piece that emerged should be extensively documented, tracked, with traces and receipts and all of the programatic data quality pieces preserved (mainly talking about all the anti-hallucination measures here, mentioned them in another comment).  And then after a few hundred more patients, sit down and unpack it all.",
                  "score": 2,
                  "created_utc": "2026-01-12 18:50:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz2tghx",
          "author": "positivitittie",
          "text": "I just started using this https://github.com/hex/claude-council in the past two days and really liking it. Sounds like you‚Äôve gone further possibly. OSS?",
          "score": 2,
          "created_utc": "2026-01-12 01:00:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4iwux",
              "author": "Own-Calendar9332",
              "text": "Not OSS currently - it's a hosted platform. The verification stack is the tricky part to open-source since it involves real-time source retrieval and grounding checks.\n\nClaude-council is cool for the debate layer. Our addition is the verification pipeline on top - checking that citations are real, semantically relevant, and actually support the specific claim. Debate alone still allows confident confabulation.\n\nHappy to share access if you want to compare.",
              "score": 1,
              "created_utc": "2026-01-12 07:30:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2ugt3",
          "author": "New-Chip-672",
          "text": "This is great.Instinctively this makes sense. Appreciate the effort to wrap some real data around the concept!",
          "score": 2,
          "created_utc": "2026-01-12 01:05:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4j7qi",
              "author": "Own-Calendar9332",
              "text": "Thanks! Happy to share access if you want to test it.",
              "score": 2,
              "created_utc": "2026-01-12 07:33:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3cx37",
          "author": "teambyg",
          "text": "We use this in prod for lower % tasks. If a reasoning LLM gets the correct answer 60% of the time, we do 3 concurrent calls and take the mode response. Works surprisingly well.",
          "score": 2,
          "created_utc": "2026-01-12 02:43:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3gnsh",
              "author": "ChanceKale7861",
              "text": "Did you nick name it sex panther? ü§£ ‚Äú60% of the time, it works every time‚Ä¶‚Äù ‚ÄúI LOVE LAMP!‚Äù",
              "score": 1,
              "created_utc": "2026-01-12 03:04:14",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz3kbag",
                  "author": "teambyg",
                  "text": "Unfortunately all nicknames for projects at our company are Pokemon :D",
                  "score": 1,
                  "created_utc": "2026-01-12 03:24:04",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4j4wg",
              "author": "Own-Calendar9332",
              "text": "Taking the mode of 3 concurrent calls is smart for reliability. Do you find certain types of queries have higher agreement rates than others?",
              "score": 1,
              "created_utc": "2026-01-12 07:32:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz6hxin",
                  "author": "teambyg",
                  "text": "We usually swarm like 50 attempts during evaluation development so we can get a good baseline per model on performance against certain tasks. That helps us identify which models perform best and whether or not something like reasoning is important.\n\nGenerally the harder ones are the ones that contain both parsing and data extraction, and followup logic. Working with long form information or document images, extracting important elements, and then traversing that information to make decisions. \n\nThe more logical components of the tasks, the less performant and more diverse the answers generally. SOP context injection and scaffolds to support the model is helpful, but sometimes nothing beats the additional accuracy of brute force compute.",
                  "score": 2,
                  "created_utc": "2026-01-12 15:55:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz4q8oh",
          "author": "Fozzi",
          "text": "Would love to see how this works on building new processes and platforms for various IT or cybersec teams. Process improvement and feedback is a big struggle for larger teams.",
          "score": 2,
          "created_utc": "2026-01-12 08:38:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz303nh",
          "author": "armyknife-tools",
          "text": "I‚Äôm glad this is starting to be commonplace. My 13 agents have a very similar debate mode where they debate against a given query like ‚ÄúWhat is better fine tune or RAG system‚Äù all controlled by voice and responses by voice. But my favorite is panel mode and teaching mode. The best quality and most innovative answers would surprise you. Not Claude or Gemini, but Grok. If Grok can come up with a subscription based code tool or agents like the others the real competition would start.",
          "score": 2,
          "created_utc": "2026-01-12 01:36:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz3ghqe",
              "author": "ChanceKale7861",
              "text": "I‚Äôm running 17,  but 13 is solid too. That said, going much beyond 20 for one person doesn‚Äôt make sense from a flow and clusters of agents stand point for orchestration for most. Thoughts?",
              "score": 1,
              "created_utc": "2026-01-12 03:03:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz7bkl2",
                  "author": "diabloman8890",
                  "text": "Why more than 3?",
                  "score": 1,
                  "created_utc": "2026-01-12 18:10:21",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nz4j2fu",
              "author": "Own-Calendar9332",
              "text": "Interesting that you're seeing Grok outperform on innovation. We haven't tested Grok in our rotation yet - mostly Claude/GPT/Gemini. What prompting patterns work best for getting genuine disagreement vs. surface-level rephrasing?",
              "score": 1,
              "created_utc": "2026-01-12 07:31:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2u5oo",
          "author": "kubrador",
          "text": "this is cool but i'm curious what happens when all three models confidently agree on something that's still wrong\n\nlike there's gotta be shared blind spots in training data where they all learned the same wrong thing. the heterogeneity helps but it's not magic if they all scraped the same incorrect wikipedia article in 2021\n\nalso 3x latency is rough for anything user-facing. you basically built a fact-checking pipeline",
          "score": 1,
          "created_utc": "2026-01-12 01:04:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4ipdf",
              "author": "Own-Calendar9332",
              "text": "You're right - heterogeneity isn't magic. If all three trained on the same wrong Wikipedia article, they'll all be wrong together.\n\nThat's exactly why we added the verification stack on top of debate. The grounding layer checks if cited sources actually exist and support the specific claim. Catches cases where all models 'know' something that isn't actually in any retrievable source.\n\nStill not perfect, if the source itself is wrong, we're stuck. But it catches a surprising amount of confident shared confabulation.",
              "score": 3,
              "created_utc": "2026-01-12 07:28:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nz39zsh",
              "author": "positivitittie",
              "text": "I don‚Äôt use the technique all the time but it helps if Claude Code gets stuck. I do a round of ‚Äúask‚Äù where the LLMs (Gemini, GPT) simply give their answers then a ‚Äúdebate‚Äù round where they are fed each other‚Äôs answers and consider the competing solutions.\n\nI was so happy two nights ago when Claude said ‚Äúthe council found the bug!‚Äù",
              "score": 2,
              "created_utc": "2026-01-12 02:28:24",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nz329g7",
              "author": "Grue-Bleem",
              "text": "Vey cool‚Ä¶\n1. What is the primary source documenting k-fold cross-validation's definition? How did you define k values for each cluster?",
              "score": 1,
              "created_utc": "2026-01-12 01:47:24",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nz2zrt7",
          "author": "mpsii",
          "text": "Interested to test",
          "score": 1,
          "created_utc": "2026-01-12 01:34:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4gw1c",
              "author": "Own-Calendar9332",
              "text": "DM'd you the link. Would love to hear what breaks it - especially edge cases in your domain.",
              "score": 1,
              "created_utc": "2026-01-12 07:12:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nz3jx82",
          "author": "makinggrace",
          "text": "I'd like to play with this a bit.",
          "score": 1,
          "created_utc": "2026-01-12 03:21:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz4hio1",
              "author": "Own-Calendar9332",
              "text": "Sent you the link. Curious what use cases you're thinking of testing.",
              "score": 1,
              "created_utc": "2026-01-12 07:17:55",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzkehs9",
                  "author": "makinggrace",
                  "text": "I suspect it may be useful for seeking and vetting data sources/references. That can be done with a single model but it's a multi-step process that has a CI you can drive a truck through.",
                  "score": 1,
                  "created_utc": "2026-01-14 16:47:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz68krw",
          "author": "Own-Calendar9332",
          "text": "One thing we‚Äôre still genuinely uncertain about and I‚Äôd love input from people doing this in prod is where the **right boundary is between abstention and challenge**.\n\nIn textual domains, forcing critique increases hallucinations. But over-penalizing critique causes silent failure where weak claims slip through unchallenged.\n\nWe‚Äôve tried:\n\n* Penalizing objections that fail verification\n* Allowing agents to explicitly abstain\n* Scoring agents higher for *withholding* when evidence is insufficient\n\nIt helps, but the tradeoff is real.\n\nCurious how others handle this:\n\n* Do you bias agents toward abstention or toward skepticism?\n* Have you found a reliable signal for ‚Äúthis claim deserves challenge‚Äù vs ‚Äúthis is just uncertainty‚Äù?\n* Does anyone weight challenges by confidence or evidence density rather than binary agree/disagree?\n\nThis feels like the hardest unsolved piece of multi-agent reasoning for us so far.",
          "score": 1,
          "created_utc": "2026-01-12 15:10:21",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzt7b8z",
          "author": "Actual_Skin_8366",
          "text": "Would love to test this if access is still available!",
          "score": 1,
          "created_utc": "2026-01-15 22:11:40",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6vypc",
      "title": "The Vocabulary of GPUs for Gen AI Engineers",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q6vypc/the_vocabulary_of_gpus_for_gen_ai_engineers/",
      "author": "BoysenberryRare",
      "created_utc": "2026-01-07 23:52:50",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "The conversation around GPUs in Gen AI talks often jumps straight to \"just rent an H100\" without explaining why.\n\n\n\nI wrote a visual guide covering the vocabulary that actually matters:\n\n\n\nüîπ Why GPUs over CPUs (it's not just \"more cores\")\n\nüîπ HBM vs GDDR ‚Äî why your RTX 4090 can't run Llama 405B\n\nüîπ FLOPs, TFLOPS, and what those spec sheets actually mean\n\nüîπ Precision formats: FP32 ‚Üí FP16 ‚Üí BF16 ‚Üí FP8\n\nüîπ The memory formula: Parameters √ó Bytes = VRAM needed\n\nüîπ How inference actually works ‚Äî from prompt to prediction\n\nüîπ Temperature: the inference-time knob everyone uses but few explain\n\n\n\nThis isn't about which GPU to buy.\n\n\n\nIt's about building the mental model so you can read a spec sheet, estimate memory requirements, and have informed conversations about infrastructure.\n\n\n\nPart 1 of a 3-part series - [https://medium.com/@vinodh.thiagarajan/the-vocabulary-of-gpus-for-ml-budding-gen-ai-engineers-7a693b53b74b](https://medium.com/@vinodh.thiagarajan/the-vocabulary-of-gpus-for-ml-budding-gen-ai-engineers-7a693b53b74b)\n\nhttps://preview.redd.it/cgj8wuy3m0cg1.png?width=800&format=png&auto=webp&s=c0939a0c3e1647c0bb44e3d1250e148c8ba01f8b\n\n  \n",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q6vypc/the_vocabulary_of_gpus_for_gen_ai_engineers/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q7pwsk",
      "title": "Looking for advice on a self-hosted LLM stack for enterprise use",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q7pwsk/looking_for_advice_on_a_selfhosted_llm_stack_for/",
      "author": "Ahyaqui",
      "created_utc": "2026-01-08 22:16:08",
      "score": 8,
      "num_comments": 13,
      "upvote_ratio": 1.0,
      "text": "Hello everyone,\n\nI‚Äôm planning to build a dedicated on-prem machine to host a local LLM for my company and I‚Äôm looking for advice on which direction to take.\n\nThe idea is to have a ChatGPT-like internal chatbot with a web interface, but also expose the same LLM through an API so it can be integrated into internal tools like GLPI (IT ticketing). Both the chatbot and the API should be able to query internal company data using RAG, such as procedures, internal documentation, and historical GLPI tickets.\n\nAuthentication would ideally be handled via LDAP / Active Directory. Image understanding and controlled internet search would be nice to have, but not strict requirements.\n\nI‚Äôm aware of projects like Open WebUI, AnythingLLM or LibreChat, but I‚Äôm not sure which ones are best suited for a company/internal setup, or whether it‚Äôs better to assemble a more modular stack (model server + vector DB + UI + auth).\n\nThis isn‚Äôt my core field and the ecosystem is moving fast, so I‚Äôd really appreciate feedback from people who‚Äôve built or run similar setups. I‚Äôm especially interested in real-world experience, best practices.\n\nThanks in advance for any guidance !",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q7pwsk/looking_for_advice_on_a_selfhosted_llm_stack_for/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nyhy6zm",
          "author": "OnyxProyectoUno",
          "text": "Your stack choices matter way more for the RAG side than the LLM side. Most people get caught up in model selection when the real bottleneck is usually document processing.\n\nFor enterprise setups, i'd lean toward the modular approach over all-in-one tools like AnythingLLM. You get better control over each piece, especially the RAG pipeline. Something like Ollama for model serving, Qdrant or Weaviate for vectors, and a custom frontend gives you flexibility as requirements change. That's the approach I've been building around at vectorflow.dev for the document processing piece.\n\nThe tricky part isn't authentication or the web interface, it's getting your internal docs properly parsed and chunked. GLPI tickets especially can be messy with mixed formats, timestamps, and user comments all jumbled together. Your retrieval quality depends entirely on how well you handle that upstream.\n\nWatch out for permission boundaries too. You probably don't want all employees seeing all tickets or procedures. Most vector DBs handle metadata filtering, but you need to think through the access control model early.\n\nWhat types of internal docs are you planning to ingest? PDFs, wiki pages, or mostly structured data from GLPI?",
          "score": 7,
          "created_utc": "2026-01-08 23:44:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nylecst",
              "author": "Ahyaqui",
              "text": "This is exactly the type of answer I hoped for, thank you!  \nMy current thinking is very close to what you described.\n\nThe type of internal docs are mostly BookStack pages (clean HTML), GLPI tickets and follow-ups (rich-text HTML blobs from the editor), and some PDFs (vendor docs, contracts, technical manuals), but they‚Äôre secondary.\n\nBookStack can be parsed and chunked, while GLPI will definitly need heavy normalization and summarization before embedding. This is going to be a pain in the ass...\n\nSo the real bottleneck is document parsing, chunking strategy, and metadata design. Especially with GLPI, retrieval quality will live or die based on how well we separate signal (findings, conclusions, resolutions) from noise.\n\nPermissions are also a concern we‚Äôre starting to model early (per-entity and per-team visibility on tickets and procedures), so metadata filtering at retrieval time is likely mandatory.\n\nThe modular stack you mentioned is the direction i was leaning toward.\n\nI have no clue how to do all that since it is very new to me, but hey, we'll start by buying the machines haha\n\nThank you for your comment :)",
              "score": 1,
              "created_utc": "2026-01-09 13:41:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nylld6k",
                  "author": "OnyxProyectoUno",
                  "text": "Yeah, GLPI is going to be rough. Those rich-text blobs are usually full of quoted email chains, signature blocks, and people replying inline without any structure. I'd probably run each ticket through a cleanup step first, maybe even use a smaller LLM to extract just the actual problem description and resolution before embedding.\n\nFor the BookStack pages, you're in luck since they're already structured HTML. Just watch out for navigation elements and sidebars when you're extracting content.\n\nThe metadata design is where you'll save yourself months of headaches later. I'd map out your permission model on paper first, then make sure every chunk gets tagged with team, visibility level, document type, maybe even urgency for tickets. Qdrant handles complex metadata queries pretty well if you structure it right from the start.\n\nStarting with the hardware purchase is honestly not a bad approach. Gives you time to think through the data model while the servers are shipping.",
                  "score": 1,
                  "created_utc": "2026-01-09 14:18:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nyhqpfp",
          "author": "Everlier",
          "text": "You might find [Harbor](https://github.com/av/harbor) useful",
          "score": 2,
          "created_utc": "2026-01-08 23:05:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nylex0x",
              "author": "Ahyaqui",
              "text": "I had a look, and it could definitely be something we might use.  \nThank u !",
              "score": 2,
              "created_utc": "2026-01-09 13:44:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyjs354",
          "author": "sinan_online",
          "text": "So, here is the advice:\n\nOllama is the easiest way, but models need to download at start. This makes production deployments very challenging. To address this, I created my own containers with the preloaded model and a pipeline to create them. Message me and I‚Äôll send you the link.\n\nWith ollama, you have to use streaming. Non-streaming means that in some cases the response takes longer than 60s, and ollama shuts down the connection.\n\nUse LiteLLM as an abstraction layer. Makes it easy to switch between providers. I know you will implement your own, but development, testing, evaluation are all different stories.\n\nPostgreSQL now has vector support. I haven‚Äôt looked into it myself, but I will.\n\nYou probably want LBs in front of the LLM serves. MQ will be challenging due to the streaming responses.\n\nIt‚Äôs not cheaper than using existing APIs. \n\nHope these help.",
          "score": 1,
          "created_utc": "2026-01-09 05:57:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyjxcoj",
              "author": "tom-mart",
              "text": ">Ollama is the easiest way, but models need to download at start.\n\nWhy? I downloaded the models months ago and they are there for as long as the project runs.\n\n>With ollama, you have to use streaming. Non-streaming means that in some cases the response takes longer than 60s, and ollama shuts down the connection.\n\nYou can adjust the time out duration to 15 minutes if you want.\n\n>It‚Äôs not cheaper than using existing APIs. \n\nIt's free?",
              "score": 1,
              "created_utc": "2026-01-09 06:39:32",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyk630a",
          "author": "armyknife-tools",
          "text": "For a company solution it has to be robust it has to be secure and you have to build it right so that RAG system can scale without breaking. Reach out let‚Äôs chat.",
          "score": 1,
          "created_utc": "2026-01-09 07:54:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nykagyq",
          "author": "Maleficent_Pair4920",
          "text": "Requesty + Openwebui",
          "score": 1,
          "created_utc": "2026-01-09 08:33:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nym2o2h",
          "author": "sinan_online",
          "text": "OK, to quickly respond: \n\nYes, the model is there so long as your ‚Äúproduction‚Äù system is there. However, most modern systems are ephemeral, either on the cloud directly, or through some extra virtualization like containers. So the model has to be kept in persistent storage, or made persistent somehow.\n\nTypically the graphics cards and the computer to run them cost money. Even a 16GB VRAM node seems to cost around $1 and hour, although that went down a bit. If you have your own computer, then the cost is paid upfront because it‚Äôs purchased. My quick calculations seem to show that per token payments to the services is better.\n\nI didn‚Äôt know that you could adjust, thanks for letting me know.",
          "score": 1,
          "created_utc": "2026-01-09 15:41:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nypu10x",
          "author": "kchandank",
          "text": "As far as the tech stack goes, I would suggest vLLM with LiteLLM proxy. vLLM will give you lot of flexibility in terms of running various model and leverage large open source community (redhat) to support that, also it works really well in k8s echo system if you are interested in that.\n\nFor Access control and RBAC, LiteLLM has their enterprise feature, or you are build using a reverse proxy solution to achieve most of it.\n\nLiteLLM will give you metering, rate limitting etc which are essential for enterprise usecase.\n\nFor observability you can use langfuse or have robust prometheus stack. But langfuse or similar tool will give you even deeper details about how end users are using and various LLM specific parameters such as P95, P99 etc, ofcourse it takes effort to customize both litellm and langfuse.",
          "score": 1,
          "created_utc": "2026-01-10 02:33:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyqny3z",
          "author": "CommercialComputer15",
          "text": "Why not get azure and deploy LLMs using ai foundry?",
          "score": 1,
          "created_utc": "2026-01-10 05:42:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nz7jj8v",
          "author": "Julianna_Faddy",
          "text": "\\+1 want to hear more suggestions from folks",
          "score": 1,
          "created_utc": "2026-01-12 18:46:03",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcpfgn",
      "title": "Claude Cowork: Initial Impressions, Architecture, Capabilities, and Usage Overview",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qcpfgn/claude_cowork_initial_impressions_architecture/",
      "author": "Arindam_200",
      "created_utc": "2026-01-14 14:58:50",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 0.9,
      "text": "It‚Äôs been about a year since we started doing small agentic tasks. Giving models file access, connecting Drive, stitching tools together, and calling that ‚Äúagents.‚Äù\n\nClaude has now shipped this as a first-class product feature.\n\nClaude Cowork is a task execution mode in the Claude Desktop app. Instead of responding to prompts, it works toward an outcome.\n\nYou describe an outcome. Claude plans the steps, works across local files you explicitly share, and executes multi-step tasks with minimal back & forth. Context stays alive until the task finishes as you review plans and approve risky actions.\n\nWhat stood out to me:\n\n* Local execution on macOS inside an isolated VM\n* Explicit folder-level permissions\n* Designed for long-running multi-step work.\n* Still a research preview with sharp limits. (MacOS only, higher usage, no persistence)\n\nI went into how the architecture actually works, including planning, sub-agent coordination, file access, and safety boundaries. You can read it¬†[here](https://www.tensorlake.ai/blog/claude-cowork-architecture-overview).",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcpfgn/claude_cowork_initial_impressions_architecture/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzt4ifi",
          "author": "Creepy-Row970",
          "text": "pretty interesting",
          "score": 1,
          "created_utc": "2026-01-15 21:58:21",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc7mop",
      "title": "Web scraping - change detection",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qc7mop/web_scraping_change_detection/",
      "author": "Ready-Interest-1024",
      "created_utc": "2026-01-13 23:52:33",
      "score": 8,
      "num_comments": 12,
      "upvote_ratio": 0.9,
      "text": "I was recently building a RAG pipeline where I needed to extract web data at scale. I found that many of the LLM scrapers that generate markdown are way too noisy for vector DBs and are extremely expensive. \n\nI ended up releasing what I built for myself: it's an easy way to run large scale web scraping jobs and only get changes to content you've already scraped.   \n  \nScraping lots of data is hard to orchestrate, requires antibot handling, proxies, etc. I built all of this into the platform so you can just point it to a URL, extract what data you want in JSON, and then track the changes to the content. \n\nIt's free - just looking for feedback :) ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qc7mop/web_scraping_change_detection/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nzg4boa",
          "author": "Ready-Interest-1024",
          "text": "Check out the site for a live demo: [https://meter.sh](https://meter.sh)",
          "score": 3,
          "created_utc": "2026-01-13 23:52:45",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nzg7vyq",
          "author": "Hot_Substance_9432",
          "text": "Yes its a very smart idea and looks good site:)",
          "score": 2,
          "created_utc": "2026-01-14 00:11:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgod4w",
              "author": "Ready-Interest-1024",
              "text": "Thanks a lot :)",
              "score": 1,
              "created_utc": "2026-01-14 01:43:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzkgegw",
          "author": "Dangerous_Fix_751",
          "text": "oh interesting, i've been dealing with the markdown noise problem too. we actually built our own parser at Notte that strips out all the cruft and just keeps semantic content - way cleaner for embeddings.\n\nthe change detection part sounds useful though. how do you handle sites that randomize element IDs or class names between loads? that always breaks my diff logic",
          "score": 2,
          "created_utc": "2026-01-14 16:56:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzmozb1",
          "author": "Shotafry",
          "text": "Wow, I'm creating a webpage to centralize all the cybersecurity events, conferences, meets, etc in Spain and this could be interesting, it's a free web so I need a free way to scrap events and add it.",
          "score": 2,
          "created_utc": "2026-01-14 23:03:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nznqcix",
              "author": "Ready-Interest-1024",
              "text": "Awesome - that's the exact use case! We will be launching pricing soon but plan to have a generous free tier.",
              "score": 2,
              "created_utc": "2026-01-15 02:31:23",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nzoydp3",
                  "author": "Shotafry",
                  "text": "Great!!! But be careful, People usually overdo it when things are free, and more if your plan will be very generous, try to implement selective generous plans, I mean, some section for students, non-profit organizations (mine is not an organization but it is a non-profit website to help others) when you are clear I will still sign up and use it. Thanks üòÄ",
                  "score": 2,
                  "created_utc": "2026-01-15 07:50:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzgin0g",
          "author": "hhag93",
          "text": "Wow I‚Äôm really impressed, I used a site that has some fairly complex data structure and it parsed it out nearly perfect!",
          "score": 1,
          "created_utc": "2026-01-14 01:11:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzgo7hs",
              "author": "Ready-Interest-1024",
              "text": "Hey - thanks so much! Going to shoot you a DM!",
              "score": 1,
              "created_utc": "2026-01-14 01:43:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nzhzkj4",
          "author": "kubrador",
          "text": "dropped a link to your thing or nah?\n\nchange detection is genuinely useful though, most scraping setups treat every run like the first time which is dumb when you're paying per token to re-embed the same content\n\nwhat's your approach for detecting \"meaningful\" changes vs just timestamp updates or minor formatting shifts?",
          "score": 1,
          "created_utc": "2026-01-14 06:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjcxzf",
              "author": "Ready-Interest-1024",
              "text": "Here‚Äôs the link: https://meter.sh \n\nAnd exactly, none of the current tools really help with only tracking the diff. Right now, the approach only catches meaningful changes because it‚Äôs only pulling out relevant data and checking that. Tools that just dump the whole page aren‚Äôt able to do that. \n\nEventually, I‚Äôd like to move to semantic diffing but the current approach is working well. I‚Äôm going shoot you a DM regarding this use case",
              "score": 1,
              "created_utc": "2026-01-14 13:44:20",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qe0kqk",
      "title": "Best way to learn AI engineering from scratch? Feeling stuck between two paths",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qe0kqk/best_way_to_learn_ai_engineering_from_scratch/",
      "author": "mohnnd6",
      "created_utc": "2026-01-16 00:12:15",
      "score": 8,
      "num_comments": 19,
      "upvote_ratio": 0.9,
      "text": "Hey everyone,\n\nI‚Äôm about to start learning AI engineering from scratch, and I‚Äôm honestly a bit stuck on how to approach it.\n\nI keep seeing two very different paths, and I‚Äôm not sure which one makes more sense long-term:\n\nPath 1 ‚Äì learn by building\nLearn Python basics\nStart using AI/ML tools early (LLMs, APIs, frameworks)\nBuild projects and learn theory along the way as needed\n\nPath 2 ‚Äì theory first\nLearn Python\nGo deep into ML/AI theory and fundamentals\nCode things from scratch before relying on high-level tools\n\nMy goal isn‚Äôt research or academia ‚Äî I want to build real AI products and systems eventually.\n\nFor those of you already working in AI or who‚Äôve gone through this:\n\nWhich path did you take?\nWhich one do you think actually works better?\nIf you were starting today, what would you do differently?\n\nReally appreciate any advice",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qe0kqk/best_way_to_learn_ai_engineering_from_scratch/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nztutfa",
          "author": "kubrador",
          "text": "path 1, hands down. you're not trying to publish papers, you're trying to ship things.\n\nbuild something janky with an llm api next week, then when you hit a wall and realize you don't understand embeddings or whatever, \\*that's\\* when you go learn the theory because it actually means something now. learning backprop in isolation is just suffering.\n\nthe people who grind path 2 for 6 months end up burnt out and haven't made anything. the people who build first discover they only needed like 20% of the theory to be dangerous anyway.",
          "score": 9,
          "created_utc": "2026-01-16 00:14:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzu338n",
              "author": "robogame_dev",
              "text": "Path 1 for sure, with Perplexity as your first resort when you need info. LLM world moves fast, if you ask ChatGPT et al, they‚Äôll primarily be responding from training data that is 6-12 months behind, the result is they reference APIs that have changed, and don‚Äôt know about the latest techniques. Perplexity (or another search-first setup) is invaluable for learning AI (and any other rapidly evolving field).",
              "score": 2,
              "created_utc": "2026-01-16 00:58:59",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzutn1r",
                  "author": "prajwalmani",
                  "text": "Isn't the chatgpt use web search tool to update the context based on the current info",
                  "score": 1,
                  "created_utc": "2026-01-16 03:27:45",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nztv96a",
              "author": "LeatherConfection362",
              "text": "That‚Äôs right.",
              "score": 1,
              "created_utc": "2026-01-16 00:16:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzu6xs0",
          "author": "Crashbox3000",
          "text": "Learn by building. Build as an architect, though, not a coder. Learn the relationships and dependencies. Build things that force you to make connections between systems. Question your assumptions always.",
          "score": 3,
          "created_utc": "2026-01-16 01:20:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzva2zc",
              "author": "robogame_dev",
              "text": "The one caveat is I‚Äôd suggest coding the ChatGPT completions API yourself once, since it underlies virtually everything else, and is extremely short and simple - that clarity from getting hands on with the completions API will carry over into better architecting.",
              "score": 1,
              "created_utc": "2026-01-16 05:12:01",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzui93y",
          "author": "JustKiddingDude",
          "text": "This is going to make some kids drool, but If you want to build real products, python is pretty much useless. You‚Äôre much better off learning JavaScript/typescript than python for products. Python is what people use mostly for data analysis and running scripts and has good libraries for those. Even if you could build a product in Python, it‚Äôs horrible practice and a lot slower. There‚Äôs a reason no one does that.",
          "score": 2,
          "created_utc": "2026-01-16 02:24:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzv59yg",
          "author": "mdizak",
          "text": "**I would definitely go second path.  If this is a bubble (and yes, yes it's a bubble), once it bursts and things go tits up many if not most of the things you taught yourself via path 1 will now be null and void, because you went down the narrow path of today's AI.**\n\n\n\n**With path 2 on the otherhand, those fundamentals will remain valuable reagrdless if this generation of AI goes tits up or not.  It also allows you to better understand the problems, hence be capable of coming up with more innovative and novel solutions, increasing your value.**",
          "score": 2,
          "created_utc": "2026-01-16 04:39:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nztv2jr",
          "author": "jucktar",
          "text": "I had chat gpt train me",
          "score": 1,
          "created_utc": "2026-01-16 00:15:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu0gyz",
          "author": "metaphorm",
          "text": "learn programming fundamentals first",
          "score": 1,
          "created_utc": "2026-01-16 00:44:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu2i3e",
          "author": "Unable-Shame-2532",
          "text": "path 1 forsure, you‚Äôll enjoy the process much more(assuming you want to build) and get better faster",
          "score": 1,
          "created_utc": "2026-01-16 00:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzu8l3w",
          "author": "FreeTinyBits",
          "text": "Maybe you should think about what kinds of ai products you want to build eventually. Then you would have a better idea.",
          "score": 1,
          "created_utc": "2026-01-16 01:30:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuacoh",
          "author": "Vegetable-Score-3915",
          "text": "Check out deeplearning.ai python for ai course and a couple of the beginner short courses they have. Dont need to pay, just pay if you want the certs.\n\nThat could be a good quick introduction. So you have some framework exposure and examples so you can start building\n\nI reckon path 1 with the above. You could spend 6 months learning deep learning and more traditional statistical techniques / more traditional ml and only be across a small amount of it. Maybe touch on decision trees, random forests, support vector machines, clustering techniques etc, but wouldnt recommend going deep into the theory for too long. Unless that is what you want to do.\n\nHighly recommend learning by doing, and those deeplearning.ai short courses are pretty good giving at least the language model theory with practicals. I think it is easier to focus on that, and in anything you build, loom up analytical techniques/ traditional ml stuff if relevant, so learn what you need to learn for the task at hand.",
          "score": 1,
          "created_utc": "2026-01-16 01:40:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzuck94",
              "author": "Vegetable-Score-3915",
              "text": "I did path 2 - a masters many years ago.\nIf had to do it again, would do path1 now.\n\nTraditional ML and older techniques are still important, but seem to be more niche. My view, the better you are with ai generally, I think you'll get better at learning rapidly and learning what you need to learn. \n\nDefinitely do a decent python intro course though. Ive taught bootcamps, students who just relied on ai to write all their code before they could code seemed to stagnate, and could not identify ai slope, or fix errors. That deeplearning.ai python for ai beginner course seems fit for purpose.",
              "score": 1,
              "created_utc": "2026-01-16 01:52:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nzucd7c",
          "author": "Whole-Assignment6240",
          "text": "begin with karparthy's videos :)",
          "score": 1,
          "created_utc": "2026-01-16 01:51:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzudu43",
          "author": "Bonnie-Chamberlin",
          "text": "If your goal is not research, don't touch the theory. Learning from theory only lead to one possible outcome: give up!",
          "score": 1,
          "created_utc": "2026-01-16 01:59:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzuuu1m",
          "author": "bobthe3",
          "text": "get claude code or opencode and just start writing into the box, when confused just ask it to explain. the important thing is to READ!",
          "score": 1,
          "created_utc": "2026-01-16 03:34:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nzvjapu",
          "author": "RegionDesigner8000",
          "text": "I would recommend starting with Path 1 learning by building. Dive into Python and start using AI/ML tools early on. It's the quickest way to get hands on experience and see how things work in practice. You can always pick up theory as you go when you hit a roadblock or need a deeper understanding. That said, some theory is important, but you don‚Äôt need to go super deep upfront. Building real projects will teach you way more about what works in production. So, focus on tools, frameworks, and small projects first, then dive into the theory as it becomes relevant to what you're working on.",
          "score": 1,
          "created_utc": "2026-01-16 06:20:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q6d8em",
      "title": "Anyone else end up leaning on pydantic way more than they expected when building llm stuff?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q6d8em/anyone_else_end_up_leaning_on_pydantic_way_more/",
      "author": "Unique-Big-5691",
      "created_utc": "2026-01-07 11:44:06",
      "score": 7,
      "num_comments": 8,
      "upvote_ratio": 0.82,
      "text": "i started with it just for request/response validation, but once agents, tools, and multi-step flows entered the picture, it kinda became the thing keeping everything from going off the rails.\n\nhaving clear schemas for what an agent can output, or what a tool must receive, saves me from a lot of ‚Äúwhy did the model do this??‚Äù moments. stuff fails fast instead of breaking quietly later, which honestly matters more than raw model quality sometimes.\n\ncurious how others are using it in practice:  \n\\-do you only use schemas at the edges, or also for internal agent state?  \n\\-do you go strict, or allow some flexibility and clean things up downstream?  \n\\-anything you wish you‚Äôd locked down earlier?\n\nfeels like one of those boring tools that doesn‚Äôt look exciting‚Ä¶ until your system gets complicated and suddenly it‚Äôs doing a ton of heavy lifting üòÖ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q6d8em/anyone_else_end_up_leaning_on_pydantic_way_more/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny6nfq6",
          "author": "kubrador",
          "text": "yeah pydantic is basically load-bearing infrastructure at this point\n\ni use it everywhere - edges, internal state, tool definitions, the works. started \"just for API stuff\" and now it's in like 90% of my agent code. no regrets.\n\nstrict mode gang. if the model can't follow the schema, i want to know immediately, not three steps later when something inexplicably returns None. the \"allow flexibility and clean up later\" approach bit me hard early on - you end up writing a second validation layer anyway, just shittier.",
          "score": 4,
          "created_utc": "2026-01-07 11:49:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7636c",
          "author": "alp82",
          "text": "Doing the same. It's a great way to ensure consistency.\n\nIf the Pydantic validation fails, I send the validation errors back to the LLM and usually the second response is correct.",
          "score": 3,
          "created_utc": "2026-01-07 13:48:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyew5vc",
              "author": "dustfinger_ss",
              "text": "\\> I send the validation errors back to the LLM and usually the second response is correct.\n\nI agree, having a feedback loop is very effective.",
              "score": 2,
              "created_utc": "2026-01-08 15:32:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny7nil7",
          "author": "TheLastBlackRhino",
          "text": "lol hi pydantic bots good luck with your viral marketing",
          "score": 4,
          "created_utc": "2026-01-07 15:18:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6niti",
          "author": "macromind",
          "text": "100% same experience. Once you have tools + multi-step flows, schemas become the guardrails that keep agents from drifting. Ive been using Pydantic not just at the edges, but also for internal state (plan, tool call args, tool results, and a final response model) so retries and handoffs are predictable. I usually go strict for tool inputs/outputs, then allow a bit more flexibility for intermediate notes and normalize downstream. This writeup has a couple good patterns around schema-first agent design if you want more ideas: https://www.agentixlabs.com/blog/",
          "score": 2,
          "created_utc": "2026-01-07 11:50:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny7yk61",
          "author": "baconeggbiscuit",
          "text": "Yeah, it's not exciting but taking time to build in the Pydantic way is kinda the secret sauce for consistency/improving production applications.",
          "score": 1,
          "created_utc": "2026-01-07 16:09:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8iqx0",
          "author": "coloradical5280",
          "text": "Pydantic is so clutch to llm created shit, if you can‚Äôt just do typescript strict, which, usually doesn‚Äôt work in actual llm apps where PyTorch is used. Still have to have hooks and ci lints cause it will just, not do it, make names, not add to registry, etc. but done right it‚Äôs really helpful",
          "score": 1,
          "created_utc": "2026-01-07 17:40:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyevden",
          "author": "dustfinger_ss",
          "text": "I agree, once you have tools and multi-step flows, schemas stop being ‚Äúvalidation‚Äù and become the guardrails.  \n  \nHere is what‚Äôs working for me: strict at the boundaries (tool args/results), and moderately strict for internal agent state where I validate then if it fails, send the validation errors back to the model and ask it to fix just the JSON.  \n  \nI also recommend keeping separate models for LLM output shape vs internal state so you can evolve your internals without rewriting prompts constantly.  \n  \nDo you fail hard on tool schema mismatch, or do you allow a fallback tool call?",
          "score": 1,
          "created_utc": "2026-01-08 15:28:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q64k0w",
      "title": "Built an open-source, provider-agnostic RAG SDK for production use would love feedback from people building RAG systems",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/pep02eqjkubg1.jpeg",
      "author": "astro_abhi",
      "created_utc": "2026-01-07 03:33:17",
      "score": 7,
      "num_comments": 7,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q64k0w/built_an_opensource_provideragnostic_rag_sdk_for/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "ny4xir0",
          "author": "astro_abhi",
          "text": "Links for anyone curious:\n\nWebsite & docs: https://vectra.thenxtgenagents.com/\n\nGitHub:\nNode.js: https://github.com/iamabhishek-n/vectra-js\nPython: https://github.com/iamabhishek-n/vectra-py",
          "score": 1,
          "created_utc": "2026-01-07 03:34:33",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "ny5fisc",
          "author": "hasmcp",
          "text": "Are you putting the docs into vector db and then responding to LLM?",
          "score": 1,
          "created_utc": "2026-01-07 05:30:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny5hq33",
              "author": "astro_abhi",
              "text": "Yes. At a high level it‚Äôs the standard RAG flow: documents are chunked, embedded, stored in a vector DB, and relevant chunks are retrieved and used to ground the LLM response at query time.\nVectra focuses on making the rest of the pipeline (ingestion, retrieval strategies, reranking, grounding, observability) explicit and interchangeable, since that‚Äôs where most production complexity shows up.\n\nThe goal isn‚Äôt to invent a new RAG algorithm, but to make the entire pipeline explicit, modular, and production-friendly, so teams can swap models, vector DBs, or retrieval strategies without rewriting their application code.",
              "score": 1,
              "created_utc": "2026-01-07 05:46:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "ny5zcos",
          "author": "Clipbeam",
          "text": "This looks really good, very impressed with the direction. Looking forward to see it evolve further! Any plans to support LanceDB as well?",
          "score": 1,
          "created_utc": "2026-01-07 08:15:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny60ltl",
              "author": "astro_abhi",
              "text": "Thanks, appreciate that!\nYes ,LanceDB is definitely on the roadmap. The vector store layer is designed to be pluggable, so adding support for LanceDB is very doable. Happy to hear if there are specific things you think would make it better as well.",
              "score": 2,
              "created_utc": "2026-01-07 08:26:58",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny8t1wm",
              "author": "Mikasa0xdev",
              "text": "Vector stores are the new databases.",
              "score": 1,
              "created_utc": "2026-01-07 18:25:43",
              "is_submitter": false,
              "replies": [
                {
                  "id": "ny8xmtb",
                  "author": "astro_abhi",
                  "text": "That is definitely true considering the new enchantments and capabilities that coming forth. And also considering the how is taking over would definitely be a need.",
                  "score": 1,
                  "created_utc": "2026-01-07 18:45:34",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q239pn",
      "title": "Is curating AI datasets a job?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q239pn/is_curating_ai_datasets_a_job/",
      "author": "nowewillnotlethimgo",
      "created_utc": "2026-01-02 16:34:49",
      "score": 7,
      "num_comments": 7,
      "upvote_ratio": 0.89,
      "text": "Is there a job that curates AI datasets on a company's, so they know AI is using good data?  That seems like it is one of the most important AI jobs there is.  I don't hear much about it.  I see references on HiggingFace though.\n\nLooks like the first thing a company would do is curating their info and sell it or let their customers use it, whether devs or business people.\n\nFor someone in Knowledge Management it seems a natural transition or something that would naturally add to their reportiore.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q239pn/is_curating_ai_datasets_a_job/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxa27ei",
          "author": "kubrador",
          "text": "yeah this is a real thing and it's growing fast\n\nsome job titles to search for:\n\n* data curation specialist\n* training data manager\n* ml data engineer\n* data quality analyst (ml/ai focused)\n* annotation/labeling lead (more entry level but can lead up)\n\ncompanies like Scale AI, Surge AI, Appen, Labelbox - their whole business model is basically this. big tech companies have internal teams too, they just don't always advertise them as sexily\n\nyour instinct about knowledge management is solid. the skills overlap a lot - taxonomy design, metadata standards, data governance, information architecture. if you can frame your KM experience around \"ensuring data quality and structure for downstream applications\" you're already speaking the language\n\nthe catch is a lot of these roles either want some technical background (python, sql, understanding of ml pipelines) or they're more operational/lower-paid annotation management gigs. the sweet spot \"strategic data curation\" roles exist but they're often embedded in ml teams rather than posted as standalone positions\n\nif you're serious about it i'd start poking around linkedin for people with \"training data\" or \"data curation\" in their titles and see what their backgrounds look like. the field is new enough that there's no one path in yet",
          "score": 8,
          "created_utc": "2026-01-02 16:46:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa5b65",
          "author": "WhoReallyKnowsThis",
          "text": "I mean - using collaborative , thoughtful, and honest training data with varying degrees of weight given to the less credible sources could create exponential more value! But it‚Äôs not so simple - credible professionals across all sectors of the economy and academia must be paid for their own data and also their expertise in curating training data! \n\nWild theory - major trustworthy newspapers and magazines (NYT, WashPo, AP, and who they consider to be their peers) should charge a hefty amount to companies who wish to integrate their near real time analysis of the world across all spheres into their AI tools.",
          "score": 2,
          "created_utc": "2026-01-02 17:00:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxa7fk5",
          "author": "Sufficient_Ad_3495",
          "text": "I think you need to step back and see the wider picture of Data and technology to answer your question.",
          "score": 2,
          "created_utc": "2026-01-02 17:10:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxb4n7j",
          "author": "Feeling-Machine-4804",
          "text": "This is basically the role of an ML engineer ahah",
          "score": 2,
          "created_utc": "2026-01-02 19:45:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxedoar",
          "author": "burntoutdev8291",
          "text": "Yes, we had these roles previously, they were either linguists or data engineers. It's mostly data filtering.",
          "score": 1,
          "created_utc": "2026-01-03 07:08:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qcihrv",
      "title": "\"Agent Skills\" - The spec unified us. The paths divided us.",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/eoo1zu435adg1.jpeg",
      "author": "phoneixAdi",
      "created_utc": "2026-01-14 08:59:40",
      "score": 7,
      "num_comments": 9,
      "upvote_ratio": 0.82,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qcihrv/agent_skills_the_spec_unified_us_the_paths/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzjdq9z",
          "author": "lgastako",
          "text": "symlinks are your friend.",
          "score": 6,
          "created_utc": "2026-01-14 13:48:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nzjklo1",
              "author": "hejj",
              "text": "This",
              "score": 1,
              "created_utc": "2026-01-14 14:25:48",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nzoen1j",
              "author": "konmik-android",
              "text": "They are, but I would like to checkout and start working immediately instead of wondering why nothing works and then fiddling with file system and worry what if I forget to symlink or what if my coworkers forgot. And what if they do not know about symlinks, of what if they used a wrong type of symlink etc.",
              "score": 1,
              "created_utc": "2026-01-15 05:06:36",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nzok5jv",
                  "author": "lgastako",
                  "text": "Well, there's only one type of symlink, so that's one less thing to worry about.  But the rest are definitely issues.  I'm sure it'll be sorted out and standardized eventually but until then teams have to come up with their own workarounds.",
                  "score": 1,
                  "created_utc": "2026-01-15 05:48:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nzlqo4e",
          "author": "robogame_dev",
          "text": "The spec is like... 4 yaml tags at the front of a markdown document...\n\nWe already have an interoperable solution for the same thing, [AGENTS.md](http://AGENTS.md), just put the description of the skill in [AGENTS.md](http://AGENTS.md), and put the skill file anywhere you want - your [agents.md](http://agents.md) then reads \"For the following skills, load them into context if they apply to the task at hand: <the skill descriptions>\"",
          "score": 3,
          "created_utc": "2026-01-14 20:24:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q8zxi5",
      "title": "Grantflow.AI codebase is now public",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q8zxi5/grantflowai_codebase_is_now_public/",
      "author": "Goldziher",
      "created_utc": "2026-01-10 09:34:14",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 0.72,
      "text": "Hi peeps,\n\nAs I wrote in the title. I and my cofounders decided to open https://grantflow.ai as source-available (BSL) and make the repo public. Why? well, we didn't manage to get sufficient traction in our former strategy, so we decided to pivot. Additionally, I had some of my mentees helping with the development (junior devs), and its good for their GitHub profiles to have this available. \n\nYou can see the codebase here: https://github.com/grantflow-ai/grantflow -- I worked on this extensively for the better part of a year. This features a complex and high performance RAG system with the following components:\n\n1. An `indexer` service, which uses [kreuzberg](https://github.com/kreuzberg-dev/kreuzberg) for text extraction.\n2. A `crawler` service, which does the same but for URLs.\n3. A `rag` service, which uses pgvector and a bunch of ML to perform sophisticated RAG.\n4. A `backend` service, which is the backend for the frontend.\n5. Several frontend app components, including a NextJS app and an editor based on TipTap. \n\nI am proud of this codebase - I wrote most of it, and while we did use AI agents, it started out by being hand-written and its still mostly human written. It show cases various things that can bring value to you guys:\n\n1. how to integrate SQLAlchemy with pgvector for effective RAG\n2. how to create evaluation layers and feedback loops\n3. usage of various Python libraries with correct async patterns (also ML in async context)\n4. usage of the Litestar framework in production\n5. how to create an effective uv + pnpm monorepo\n6. advanced GitHub workflows and integration with terraform\n\nI'm glad to answer questions. \n\nP.S. if you wanna chat with me on discord, I am on the [Kreuzberg discord server](https://discord.gg/D5ZR83W5KM)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q8zxi5/grantflowai_codebase_is_now_public/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nytix3s",
          "author": "Mikasa0xdev",
          "text": "Litestar and pgvector RAG is an awesome open source combo.",
          "score": 1,
          "created_utc": "2026-01-10 17:38:04",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qc1mtn",
      "title": "Plano v0.4.2 üöÄ : universal v1/responses + Signals (trace sampling for continuous improvement)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/ybuqc3q7a6dg1.png",
      "author": "AdditionalWeb107",
      "created_utc": "2026-01-13 20:01:27",
      "score": 6,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qc1mtn/plano_v042_universal_v1responses_signals_trace/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nzetpyu",
          "author": "Necessary_Reveal1460",
          "text": "Signals - feels super helpful!",
          "score": 2,
          "created_utc": "2026-01-13 20:05:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q9o6n9",
      "title": "Headroom: compress tool outputs + align prompt prefixes for caching ‚Äî looking for edge cases (function calling / streaming)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q9o6n9/headroom_compress_tool_outputs_align_prompt/",
      "author": "Ok-Responsibility734",
      "created_utc": "2026-01-11 03:08:33",
      "score": 6,
      "num_comments": 5,
      "upvote_ratio": 0.88,
      "text": "Hi folks,\n\nI have been building a bunch of micro-apps, and realized that deep research using Claude Code with sub-agents ran into context getting over very fast (sometimes in the middle of the research itself!) I tried using prompt compression (LLMLingua, etc.), prefix caching, etc. - but my issue was that a bunch of MCP tools expected JSONs and returned JSONs, and prompt compression was messing it up. So, I thought, let's create an OSS project trying to engineer context better.  \n  \nI‚Äôve been working on an OSS layer called **Headroom** that tries to reduce context cost in agentic apps without breaking tool calling.\n\nThe 3 pieces:\n\n1. **Tool output compression** that tries to preserve outliers + relevant rows (vs. naive truncation)\n2. **Prefix alignment** to reduce accidental cache misses (timestamps, reorderings, etc.)\n3. **Rolling window** that drops history while keeping tool call units intact\n\n  \nI‚Äôm posting because I‚Äôd love adversarial review from people who‚Äôve shipped agents:\n\n* What‚Äôs the nastiest tool payload you‚Äôve seen (nested arrays, logs, etc.)?\n* Any gotchas with streaming tool calls that break proxies/wrappers?\n* If you‚Äôve implemented prompt caching, what caused the most cache misses?\n\n  \nRepo: [**https://github.com/chopratejas/headroom**](https://github.com/chopratejas/headroom)  \n  \n(I‚Äôm the author ‚Äî happy to answer anything, and also happy to be told this is a bad idea.)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q9o6n9/headroom_compress_tool_outputs_align_prompt/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz0bxs0",
          "author": "Mikasa0xdev",
          "text": "Context compression is the real MVP.",
          "score": 2,
          "created_utc": "2026-01-11 17:58:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nywnt93",
          "author": "Ok-Responsibility734",
          "text": "Some quick numbers from the repo‚Äôs perf table (obviously workload-dependent, but gives a feel):\n\n* Search results (1000 items): **45k ‚Üí 4.5k tokens (\\~90%)**\n* Log analysis (500 entries): **22k ‚Üí 3.3k (\\~85%)**\n* Nested API JSON: **15k ‚Üí 2.25k (\\~85%)** Overhead listed is on the order of **\\~1‚Äì3ms** in those scenarios.",
          "score": 1,
          "created_utc": "2026-01-11 03:11:23",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nz46t76",
          "author": "hassan789_",
          "text": "This would make for one super popular plug-in with opencode",
          "score": 1,
          "created_utc": "2026-01-12 05:48:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz49xye",
              "author": "Ok-Responsibility734",
              "text": "have you used it?",
              "score": 1,
              "created_utc": "2026-01-12 06:13:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nz4b3q7",
                  "author": "hassan789_",
                  "text": "Too much hassle‚Ä¶ I‚Äôd need a few-line command install process with something like OC to give it a shot",
                  "score": 1,
                  "created_utc": "2026-01-12 06:22:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q7gmft",
      "title": "Research and Action Agent That Is 2x faster than OpenAI's ChatGPT Agent.",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/3p8jul9ml5cg1",
      "author": "Comfortable-Rip-9277",
      "created_utc": "2026-01-08 16:39:46",
      "score": 6,
      "num_comments": 2,
      "upvote_ratio": 0.88,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q7gmft/research_and_action_agent_that_is_2x_faster_than/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nyi7e20",
          "author": "whyyoudidit",
          "text": "can you help me understand why you chose for opensourcing instead of paywalling it as a saas?",
          "score": 2,
          "created_utc": "2026-01-09 00:31:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyl5n46",
              "author": "Comfortable-Rip-9277",
              "text": "idk, not interested in making it a saas.",
              "score": 1,
              "created_utc": "2026-01-09 12:50:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pxxkdu",
      "title": "I learned basic llm libraried, some rag, and fine-tuning techniques, whats next?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pxxkdu/i_learned_basic_llm_libraried_some_rag_and/",
      "author": "Beyond_Birthday_13",
      "created_utc": "2025-12-28 17:51:42",
      "score": 6,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "Some libs like openai api, and i use it for other urls too, some rag techniques with chroma faiss and qdrant, snd alittle finetuning.\n\nWhats next, should i learn agentic ai?, n8n? Should i go no /low code, or. Code heavy? Or is there another path i am not aware of?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pxxkdu/i_learned_basic_llm_libraried_some_rag_and/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwjundd",
          "author": "Mikasa0xdev",
          "text": "RAG is cool, but agents are the future.",
          "score": 2,
          "created_utc": "2025-12-29 14:41:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwhp965",
          "author": "Much-Researcher6135",
          "text": "Make something useful that people will buy then sell it",
          "score": 1,
          "created_utc": "2025-12-29 04:31:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx7es2a",
          "author": "Conscious_Search_185",
          "text": "The next step shpuld be building systems, focus on agent workflows that run longer than one prompt, state, memory, retries, failures.",
          "score": 1,
          "created_utc": "2026-01-02 05:16:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q39vsg",
      "title": "I‚Äôm not okay and I‚Äôm stuck. I need guidance and a real human conversation about AI/LLMs (no-code, not asking for money)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q39vsg/im_not_okay_and_im_stuck_i_need_guidance_and_a/",
      "author": "Gui-Zepam",
      "created_utc": "2026-01-03 23:38:11",
      "score": 6,
      "num_comments": 22,
      "upvote_ratio": 0.71,
      "text": "Hi. I‚Äôm Guilherme from Brazil. My English isn‚Äôt good (translation help).  \nI‚Äôm in a mental health crisis (depression/anxiety) and I‚Äôm financially broken. I feel ashamed of being supported by my mother. My head is chaos and I honestly don‚Äôt know what to do next.\n\nI‚Äôm not asking for donations. I‚Äôm asking for guidance and for someone willing to talk with me and help me think clearly about how to use AI/LLMs to turn my situation around.\n\nWhat I have: RTX 4060 laptop (8GB VRAM, 32GB RAM) + ChatGPT/Gemini/Perplexity.  \nYes, I know it sounds contradictory to be broke and have these‚Äîthis laptop/subscriptions were my attempt to save my life and rebuild income.\n\nIf anyone can talk with me (comments or DM) and point me to a direction that actually makes sense for a no-code beginner, I would be grateful.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q39vsg/im_not_okay_and_im_stuck_i_need_guidance_and_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxkwb85",
          "author": "robogame_dev",
          "text": "I think you‚Äôll need to slow down, and focus on stabilizing your emotions before you can start making money with AI.\n\nIt‚Äôs no shame to fall on hard times. The vast majority of mothers want to support their children - being supported by your mother is the norm in nature, accept it while you need it.\n\nAI is creative work, it is learning work, it is the type of work that becomes 10 times harder the more pressure you put yourself under for it. The more pressure you feel to deliver by next month, the longer it will take you. The fastest path is not to force it, to try to find your interest in it, and grow that interest.\n\nMaking money with AI is complicated, and it won‚Äôt be quick - you need to leverage AI with some other skill to make money with it, because people won‚Äôt pay for AI they will pay for solutions - so you can enhance the solutions you can offer them, but you still need to know whatever business or skill the solutions exist in. For example, a programmer who knows AI cannot directly leverage it - but a plumber who knows AI can use AI to make more money, faster, at plumbing, by using it to fill their lead pipeline (pun intended) - or a hairdresser can use it to make more money by managing their appointments, etc. \n\nThe money is being paid to people for non-AI products and services - to make money with AI you need to enhance an existing business, help it make more money according to the specific business needs.\n\nSettle in, AI may be a path to change your life, but it will not be next month or even by Spring, you need to stabilize your situation so that you can begin steadily building your skills, trying things and figuring things out - set yourself a more realistic target, that by Jan 1 2027 you have a regular income from AI related work. \n\nThink about what businesses you have around you, what businesses your friends know and work at, what opportunities are there for you to add value with AI. You will need someone to take a chance on you, to spend time letting you discover their business specifics and experimenting with AI to help them, in order to get a track record.\n\nSo relax, breathe - if you need money by next month, it won‚Äôt be from AI - to level up in AI and find a source of money from it, you need an open ended exploration, and you need to find opportunities to practice it for others, dealing with real use cases. Start trying to solve problems with AI, using Perplexity to teach you what you need as you go, in relation to the problems you come across. \n\nBest of luck! If you want more specific advice, we‚Äôll need more specifics:\n\n- what education you have / what other work you‚Äôve done - what are your related strengths?\n- any businesses that your family / friends do that they‚Äôd be willing to let you look for ways to leverage AI for them\n- any other assets or resources you can leverage here",
          "score": 7,
          "created_utc": "2026-01-04 05:56:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxx9k9x",
              "author": "Gui-Zepam",
              "text": "Thank you for the realistic and grounded advice. I understand the need for emotional stabilization, but my urgency stems from my family situation: my mother is elderly and is the primary caregiver for my grandmother, who has dementia. I need to alleviate her financial burden and fund my own medical treatment.\n\nRegarding my background: I have a degree in Advertising and Marketing from 15 years ago, but I have been away from the market for 10 years due to health issues. My knowledge is completely outdated and I am a complete beginner in the current AI landscape. My only assets are my hardware (RTX 4060, 32GB RAM) and subscriptions to ChatGPT, Gemini, and Perplexity. If you have any specific directions or ideas that a beginner could explore with this setup to generate income in the short term, I am all ears.",
              "score": 1,
              "created_utc": "2026-01-06 01:02:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "ny2pe9a",
                  "author": "robogame_dev",
                  "text": "My specific advice is to contact friendly and nearby businesses, give them free consulting where you identify problems you can solve for them with AI, and then teach yourself the AI as you go in order to solve those problems. Since you have experience in advertising, maybe that will be fastest in companies that are looking for advertising, but I don't think you will be able to charge money for your first few gigs since you also need to learn what you are doing. Once you have a few case studies as an AI consultant, you can start marketing yourself for paid gigs, and push your initial free clients to recommend you.\n\nAs far as assets, you can't leverage the ChatGPT or Gemini subscription to make money (but keep Perplexity - it's a must-have to learn the AI). The 4090 won't help make money either, if it still has most of its resale value, you could safely sell it and not lose any moneymaking ability.  (Local inference doesn't make any money, if the client really won't use the cloud, then they get their own hardware to run the inference - and local inference on that scale doesn't help you either, you should be using SOTA and near-SOTA models in the cloud. E.G. free models on OpenRouter, or super cost efficient plans like GLM coding plan.\n\nI do not think that there is a shortcut to go from 0 experience to making money with AI in < 3 months, that's the fastest I can imagine anyone getting a few free clients, learning what is needed, and getting together a portfolio that can attract paid clients. Most people need more like 6-9 months for this, but maybe if you're super motivated it could be 3 months.",
                  "score": 1,
                  "created_utc": "2026-01-06 20:45:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxmpvq2",
          "author": "Bonnie-Chamberlin",
          "text": "If you are a no-code beginner, maybe you need to start with a user-friendly AI platform instead of hard-coding with your GPU.",
          "score": 3,
          "created_utc": "2026-01-04 14:38:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxo3byw",
              "author": "robogame_dev",
              "text": "Agree - I don‚Äôt think the GPU is a practical benefit for making money with AI, OP shouldn‚Äôt try to focus on what the GPU can do and should focus on setting clients up with cloud inference instead.",
              "score": 2,
              "created_utc": "2026-01-04 18:32:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nxxelj3",
                  "author": "Bonnie-Chamberlin",
                  "text": "8GB is not enough for deploying a reasonable LLM anyway.",
                  "score": 2,
                  "created_utc": "2026-01-06 01:29:20",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nxxcfkr",
                  "author": "Gui-Zepam",
                  "text": "I agree with your point. Do you have any specific, direct ideas or suggestions on how I should start setting up clients with cloud inference?",
                  "score": 1,
                  "created_utc": "2026-01-06 01:17:38",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxjni4q",
          "author": "silencekxm",
          "text": "1„ÄÅdo some work like writing use the AI software\n\n2„ÄÅlearn to write coding, to be beginner you can learn pythonÔºågithub.com you should reference",
          "score": 1,
          "created_utc": "2026-01-04 01:23:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxeami",
              "author": "Gui-Zepam",
              "text": "Thank you for the advice. I will start using AI for writing tasks and I am definitely going to learn Python to build a future. For now, I am trying to put out the immediate financial fire while I study, but your roadmap is clear.",
              "score": 1,
              "created_utc": "2026-01-06 01:27:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjy2uu",
          "author": "ayowarya",
          "text": "oi, set up a playbook that you can repeat \n\n\\> raw idea\n\n\\> notebookLM (research + connect dots)\n\n\\> gpt 5.2 (research -> actionable requirements -> [PRD.md](http://PRD.md) (product requirement document)\n\n\\> antigravity (PRD -> working prototype)\n\n\\> live product, repeat\n\nCreate a file with prompt templates for each section, refine the flow to something you like and start pumping out businesses. Boa sorte.",
          "score": 1,
          "created_utc": "2026-01-04 02:22:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxmpyr1",
          "author": "Bonnie-Chamberlin",
          "text": "If you are a no-code beginner, maybe you need to start with a user-friendly AI platform instead of hard-coding with your GPU.",
          "score": 1,
          "created_utc": "2026-01-04 14:39:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxgrs0",
              "author": "Gui-Zepam",
              "text": "I agree, it really seems like a better approach. I have managed to do some things using the default versions of Gemini and ChatGPT, but now I feel unable to scale. I don't know how to create effective custom instructions or how to stop the main biases and issues of LLMs, which is hindering me a lot right now. I believe this is my biggest bottleneck. Thank you for the suggestion.",
              "score": 1,
              "created_utc": "2026-01-06 01:41:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxxpuyn",
                  "author": "Bonnie-Chamberlin",
                  "text": "You can learn how to build agentic workflows if you want to stop the biases and issues of a single LLM.",
                  "score": 1,
                  "created_utc": "2026-01-06 02:30:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nxr71vm",
          "author": "ApprehensiveGold824",
          "text": "I‚Äôll shoot you a message ü§ç‚ú®",
          "score": 1,
          "created_utc": "2026-01-05 03:38:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxm0vli",
          "author": "DigiBoyz_",
          "text": "Hey Guilherme. First - reaching out when your head is chaos takes guts. Respect for that.\n\nI‚Äôm a dev from Vietnam, also been through the ‚Äúsupported by family while trying to figure things out‚Äù phase. The shame is real but it‚Äôs temporary. You‚Äôre trying to change things - that matters.\n\n**Practical directions for no-code + your setup:**\n\n1. **Translation/Localization** - Your Portuguese + AI tools = real value. Businesses need PT-EN content. You already understand the nuance AI misses. Check Upwork/Fiverr for this.\n1. **AI-assisted writing** - Blog posts, product descriptions, social media content. ChatGPT + your human editing = fast output. Start cheap to build reviews, raise prices later.\n1. **Local business outreach** - Small businesses in Brazil probably don‚Äôt know AI can help them with customer service scripts, social posts, basic automation. You could be that bridge.\n\nYour hardware is honestly overkill for this kind of work - which is good. You‚Äôre not limited.\n\n**One real piece of advice:** Pick ONE direction. Your brain in crisis mode will want to try everything. Don‚Äôt. Pick the thing that feels 10% less impossible and do only that for 2 weeks.\n\nHappy to chat more in DMs if you want to talk through specifics. No agenda, just been in similar dark places and someone talking to me helped.\n\nFor√ßa, mano.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
          "score": 1,
          "created_utc": "2026-01-04 11:50:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxegll",
              "author": "Gui-Zepam",
              "text": "Vietnam? That is amazing! One of my dreams is to live there by 2027. Your suggestions are interesting, but I have a concern: I once tried to help a friend on Fiverr and Upwork, but it was full of scams and malicious links. Do you really think it is still a viable path for a beginner? I would truly appreciate talking via DM to learn from your experience. Please bear with me if I am slow to reply, as my health sometimes forces me to disconnect for long periods. Thank you for the empathy and encouragement ‚Äî I wish you the best.",
              "score": 1,
              "created_utc": "2026-01-06 01:28:36",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nxjsolq",
          "author": "ScoreUnique",
          "text": "Learn about n8n workflows, I see tonnes of people claiming to make big money for doing task specific workflows for small to medium sized companies. \n\nA good starting point is to learn how to host ollama and plugging it with a RAG solution, n8n is quite straightforward, hope it helps.",
          "score": 1,
          "created_utc": "2026-01-04 01:52:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxxfrvz",
              "author": "Gui-Zepam",
              "text": "Thank you for the specific tip on n8n. It is becoming quite popular here in Brazil lately. I have heard that [make.com](http://make.com) might be a bit more user-friendly for a beginner, but I will definitely research n8n and hosting Ollama. I appreciate the guidance.",
              "score": 2,
              "created_utc": "2026-01-06 01:35:38",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nxxwqp5",
                  "author": "ScoreUnique",
                  "text": "Your 8gb VRAM can run Qwen 3 4B or 8B decently, I suggest you to look for n8n ai starter kit, it is a docker compose with ollama n8n and other relevant services included. Eventually once you start hitting the limits of Qwen 3 4B you can start looking at alternative inferencing services like llama CPP.",
                  "score": 1,
                  "created_utc": "2026-01-06 03:08:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qb9t3c",
      "title": "Building an internal RAG service vs vendor: what‚Äôs the real effort/cost beyond the demo?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qb9t3c/building_an_internal_rag_service_vs_vendor_whats/",
      "author": "Strong_Worker4090",
      "created_utc": "2026-01-12 22:42:05",
      "score": 6,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm a full-stack dev (backend + tooling) at a small/mid company. We currently use a third-party RAG vendor that does ingestion + retrieval + a hosted chat UI. It works fine for basic Q&A, but we‚Äôre running into a few platform constraints:\n\n* Minimal UI/UX customization (we want our own front-end)\n* No clean ‚Äúchat completions-style‚Äù API that we can integrate into multiple internal apps (we want API-first)\n   * aka we can't build custom apps\n* Procurement/contracting is slow and painful, so we‚Äôre exploring owning more of the stack\n\nI‚Äôm considering building an internal RAG service that exposes endpoints like:\n\n* ingest docs (PDF/HTML) + metadata\n* search/retrieve (top-k + optional rerank)\n* answer with citations (streaming), optionally tool-calling later\n\nI understand the ‚Äúhello world‚Äù path (chunk -> embed -> vector store -> retrieve -> prompt), but I‚Äôm trying to sanity-check the real engineering lift for something production-ish.\n\n**Constraints / assumptions (initially):**\n\n* Sources: PDFs + a handful of internal web pages (no Confluence/SharePoint integration yet)\n* We can use hosted LLM APIs (Azure OpenAI/Anthropic/etc) for embeddings + generation\n* We do care about correctness + traceable citations\n* Biggest unknown: permissions (document-level ACLs per user/group might be required) - maybe something to consider for a phase 2? \n\nFor people who have done this at scale: What is the effort? What is the cost (for you, I know it varies), What does maintenance look like? Any tips/tricks? Any suggestions? ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qb9t3c/building_an_internal_rag_service_vs_vendor_whats/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nz949vc",
          "author": "OnyxProyectoUno",
          "text": "The hello world path is deceptively simple. The real lift shows up in three places.\n\nFirst, ingestion is where you'll burn the most cycles. PDFs sound straightforward until you hit scanned docs, tables that span pages, headers that repeat on every page, or nested sections where hierarchy matters for retrieval. You'll end up iterating on parsing and chunking configs way more than you expect. That's actually what I've been building around at vectorflow.dev, letting you preview what your docs look like after each transformation before committing to a pipeline.\n\nSecond, citations that actually trace back correctly require you to preserve source metadata through the entire pipeline. Chunk IDs, page numbers, section headers. If you lose that during ingestion, no amount of retrieval tuning fixes it.\n\nThird, document-level ACLs aren't a phase 2 problem, they're an architecture decision. If you bolt them on later, you're either reprocessing everything or building a permissions layer that filters post-retrieval, which gets messy fast. Worth at least designing for it now even if you don't implement.\n\nMaintenance is mostly re-ingestion when docs update and monitoring for drift when your corpus changes shape. The initial build is maybe 2-3 weeks for something production-ish, but expect to keep tuning ingestion for months.",
          "score": 5,
          "created_utc": "2026-01-12 23:13:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nz9ow01",
              "author": "zenphobic",
              "text": "Totally agree, doing something similar at work. We spent 3 months just fine tuning ingesting of documents. And honestly we are only at 80 percent accuracy.",
              "score": 2,
              "created_utc": "2026-01-13 01:04:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nz9tewt",
                  "author": "OnyxProyectoUno",
                  "text": "Yeah, 80% sounds about right for that timeline. The last 20% is where it gets expensive because you're chasing edge cases that only show up in specific document types or layouts. We hit the same wall around month 4 when leadership started asking why certain financial reports were still getting mangled while everything else looked clean.\n\nWhat's eating up most of your remaining accuracy issues? In my experience it's usually either table extraction falling apart on complex layouts, or the chunking strategy not handling document structure properly. Sometimes it's worth just flagging the problem docs for manual review rather than trying to automate everything.",
                  "score": 2,
                  "created_utc": "2026-01-13 01:29:35",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nzfs1ff",
                  "author": "Strong_Worker4090",
                  "text": "Ok yea this is my fear lol. Any suggestions here? How would you do it if you were to start over? Same path? vendor? other?",
                  "score": 1,
                  "created_utc": "2026-01-13 22:47:40",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nz9ilk2",
          "author": "ai_hedge_fund",
          "text": "I've hidden a sales pitch at the end but tried to provide you with several valuable insights:  \n  \nIf you're a full stack dev, and with the limited info I have from your post, I would call it 2-4 pretty solid weeks with assistance from Claude Code. That assumes you won't have many stakeholder committee meetings. If any of my assumptions are too optimistic then I would say it could easily spiral out to 6 months.  \n  \nFor RAG, specifically, one of the most important aspects is somewhat non-technical and it is investing time upfront to sit with end users and develop a gold-standard list of Q&A pairs that can later be used to tune the system. If you make that investment, then you can build the system and make adjustments throughout the pipelines and have a way to quantify the impact. One area that this will have an immediate ROI is in testing various chunking strategies and document parsing packages.\n\nThen, I find people often get mixed up because they don't separate ingestion and retrieval into two distinct pipelines. The comingling causes confusion. It sounds obvious.\n\nAuth and permissions is a real issue that will depend on your surrounding environment (SSO, databases, etc.) and use cases. One idea that I don't see discussed much is using multiple databases/vector DBs for different document stores which helps with both permissions and query/response accuracy.  There are various ways of connecting the user with the correct document store.\n\nCitations is not a big deal depending on how you handle it. Easy to identify chunks used in the retrieval process.\n\nThe biggest maintenance concern I have relates to the stability of the source documents. If there is an expectation that they are frequently changing then that is a challenge. If they're more static then less of a challenge but you still need to think about when/how to re-embed for changes.\n\nThe sales pitch: We have what I'd consider a pretty clean stack that we could sell as a starting point. It's not 100% plug and play as we usually integrate for businesses but it would certainly shave weeks off your timeline. UI is highly customizable as Svelte/JS. Backend is Node and we have clean separation between UI, message engine, and models. That separation lets us create separate \"adapters\" per model / endpoint - which it sounds like you want (can mix and match any number of cloud APIs and local models). Minimal dependencies / no bloated framework to inherit. Buyer would take it and rework around the edges. If you'd like to kick the tires get in touch and we can setup a time for you to look into the code. If nothing else you will get ideas from us and we would get your input on what businesses need. Thanks for reading!",
          "score": 1,
          "created_utc": "2026-01-13 00:30:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5h4wv",
      "title": "Connect any LLM to all your knowledge sources and chat with it",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/a3uulsqw1qbg1",
      "author": "Uiqueblhats",
      "created_utc": "2026-01-06 12:22:13",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5h4wv/connect_any_llm_to_all_your_knowledge_sources_and/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1pza816",
      "title": "Career advice regarding agentic ai engineer",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1pza816/career_advice_regarding_agentic_ai_engineer/",
      "author": "EarthIntrepid7166",
      "created_utc": "2025-12-30 05:58:59",
      "score": 5,
      "num_comments": 11,
      "upvote_ratio": 0.7,
      "text": "Can any person who is been into the industry give me advice on is it worth it to go all in learning agentic ai. Like learning python , async programming , fast api , docker and databases management, tools, mcp. And make good projects around it. Like is their any opportunity for being an agentic ai engineer who is able to make good scalable agentic ai applications. Such roles are not floating around but I just want to know is their going to be or not. For a college student from Tier 1 college , that would be lot helpful.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1pza816/career_advice_regarding_agentic_ai_engineer/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwp6m5j",
          "author": "metaphorm",
          "text": "agent development isn't really a specialization, it's just the state of the art in software development. it's worth learning some of the techniques. it's not a career path any more than MVC web framework is a career path.",
          "score": 8,
          "created_utc": "2025-12-30 08:29:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpfqcs",
          "author": "burntoutdev8291",
          "text": "No such career, just focus on basics. These tools are usually add on to current roles.",
          "score": 3,
          "created_utc": "2025-12-30 09:55:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwrvy1r",
          "author": "CommodoreQuinli",
          "text": "AI engineering is just full stack engineering with pre trained llms in the stack, I wouldn‚Äôt focus solely on the llms and the only thing you listed that is ai specific is mcp everything else pertains to a standard full stack role",
          "score": 2,
          "created_utc": "2025-12-30 18:33:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwskmyd",
          "author": "airylizard",
          "text": "Learn IT Support systems. Automation typically falls under the umbrella of Data & IT, no so much engineering (at least in my experience).",
          "score": 2,
          "created_utc": "2025-12-30 20:30:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwpz8a5",
          "author": "Autwalk422",
          "text": "not really a career path or special role. Its fairly on easier side to master and implement then core MLE and datascientist roles and easier to replace relatively. recruiters are now itself hiring for AI engineers : full stack + RAG + agents. so its just more of a backend. role. if you have time, focus on core MLE stack if you want to purse career in ML. (mostly hiring across startups only)",
          "score": 1,
          "created_utc": "2025-12-30 12:40:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwv0sr8",
              "author": "FormalAd7367",
              "text": "but any ai can create the whole stack ?",
              "score": 1,
              "created_utc": "2025-12-31 04:33:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwyjj9x",
          "author": "chmod-77",
          "text": "I went all in on AI. I don‚Äôt list software engineer on LinkedIn or any place now. \n\nIt‚Äôs silly to some but I call myself an ‚ÄúAI manager‚Äù.\n\nEdit: my reasoning is:\n\nI manage the AI that builds the software products. I manage the deployed AI systems that help trouble shoot, suggest products, etc. I‚Äôm trying to be ‚Äúthe guy‚Äù that manages all the AI and knows it well.",
          "score": 1,
          "created_utc": "2025-12-31 18:55:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwzbbia",
          "author": "atmpuser",
          "text": "Like others have said, AI, agentic or not, is just part of the stack now. Full stack now includes the use of AI. \n\nThe only thing specific to AI I can see as a career path at the moment is AI validation. That will get rolled into QA engineering but, it runs so deep, I can see someone specializing in just that for the next few years at the very least. How to curate the correct test data set, do you have to do a stratum or not, etc. it's a huge deal depending on the industry. For example you probably don't need this for building call center automation, you can just default back when unsure. But let's say you are doing something agentic to improve things in the financial or healthcare industry. Ya, you definitely need to validate a billions times over in the healthcare industry, it's literally life or death. Same goes for defense industry.",
          "score": 1,
          "created_utc": "2025-12-31 21:23:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx0w6du",
          "author": "stunspot",
          "text": "Learn prompting. AI can codevthe rest or teach you how... once you know how to ask well.",
          "score": 1,
          "created_utc": "2026-01-01 03:13:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwotemj",
          "author": "CommercialComputer15",
          "text": "There is no career in agentic engineering. Focus on non digital roles and you‚Äôll be fine",
          "score": 1,
          "created_utc": "2025-12-30 06:31:48",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py70qw",
      "title": "Built: OpenAI-compatible ‚Äúprompt injection firewall‚Äù proxy. I couldn‚Äôt find OSS that fit my needs. Wondering if anyone is feeling this pain and can help validate / review this project.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1py70qw/built_openaicompatible_prompt_injection_firewall/",
      "author": "jdpahl122",
      "created_utc": "2025-12-29 00:13:51",
      "score": 5,
      "num_comments": 10,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm sharing an early OSS project called Graedin Cline: a self-hosted LLM security proxy that sits between your app and your provider and tries to catch prompt injection / jailbreak / data exfil attempts before they hit the real model. \n\nRepo: [https://github.com/jdpahl122/graedin-cline](https://github.com/jdpahl122/graedin-cline)\n\nI work in MLOps and haven't found any great OSS solutions that solved this problem for me. I'm wondering if anyone else has this problem for personal projects where cloud provider or vendor specific solutions don't quite cut it. Please help guide me in advancing this project and adding quality features.\n\nSome things on my roadmap: 1) support small local models for classification to improve performance 2) Configuration UI 3) Possible rewrite in go / other more performant language for proxy ",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1py70qw/built_openaicompatible_prompt_injection_firewall/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwgjkm4",
          "author": "New_Comfortable7240",
          "text": "Wait, isn't that just a LLM guard/Input guardrails¬†layer, with another name?",
          "score": 1,
          "created_utc": "2025-12-29 00:29:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgkk9w",
              "author": "jdpahl122",
              "text": "It is, but my intention is to have this as a completely OSS project, using a classifier and not regex, and not have sneaky enterprise pricing for basic features. Things like LiteLLM have a huge feature set and charge for basic things like logging. Outside of that, you're probably using something rolled by AWS, GCP, Azure, or OpenAI which is proprietary and specific to that ecosystem.",
              "score": 3,
              "created_utc": "2025-12-29 00:34:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "nwgn1io",
              "author": "staccodaterra101",
              "text": "Most of the projects advertised here and in all similar subs are just a different approach of providing the same functionality. And its perfecly fine like that because thats how sometimes a project pops out and become the standard. The only problem with this is the usually low mantainance and development of foss.",
              "score": 3,
              "created_utc": "2025-12-29 00:47:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwgoe65",
                  "author": "jdpahl122",
                  "text": "Yep, agreed. There‚Äôs definitely a lot of ‚Äúsame problem, different angle‚Äù in these subs, and that‚Äôs not a bad thing. The maintenance point is real.\n\nFor what it‚Äôs worth, I‚Äôm building this regardless because I personally keep needing a proxy-style guard I can drop in front of multiple projects (and I don‚Äôt want to depend on proprietary ecosystem-specific solutions). Sharing it is me basically saying: ‚ÄúI‚Äôm doing the work anyway. If anyone else feels this pain, I‚Äôd love feedback + test cases.‚Äù If nobody needs it, no harm done. If a few folks do, I‚Äôm happy to iterate in the open and keep it maintained since I‚Äôll be using it long-term.",
                  "score": 2,
                  "created_utc": "2025-12-29 00:54:56",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwjuvms",
              "author": "Mikasa0xdev",
              "text": "Guardrails need a good firewall.",
              "score": 1,
              "created_utc": "2025-12-29 14:42:34",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwh743d",
          "author": "FakeTunaFromSubway",
          "text": "Sorta cool but I think would be way more useful as a simple Python package rather than having to do all sorta devops to get this working. You know just like a \\`graedin.CheckForPromptInjection(my\\_prompt)\\`",
          "score": 1,
          "created_utc": "2025-12-29 02:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwhw6em",
              "author": "AdditionalWeb107",
              "text": "eventually, you will be responsible for all \"middleware\" in your application layer - when that can be neatly buttoned up as an out-of-process proxy so you focus on core product logic, not the plumbing. Similar style project: [https://github.com/katanemo/plano](https://github.com/katanemo/plano)",
              "score": 1,
              "created_utc": "2025-12-29 05:17:47",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwi0g0h",
                  "author": "FakeTunaFromSubway",
                  "text": "And you're not responsible for a proxy layer? No the proxy layer has way more possible issues because it's routing requests directly through it, so now I have to wonder if it has zero-day exploits or other footguns. Plano at least has some reason to be a proxy layer because it's meant to be a front-line, and seems to have some traction. But would never trust a random vibe-coded project like OPs running as a proxy layer.",
                  "score": 1,
                  "created_utc": "2025-12-29 05:50:00",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwhvxyl",
          "author": "AdditionalWeb107",
          "text": "Check out Plano - https://github.com/katanemo/plano. A models-native proxy server for agentic traffic.",
          "score": 1,
          "created_utc": "2025-12-29 05:16:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1py3ax4",
      "title": "What‚Äôs your plan if a much better model drops (databases)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1py3ax4/whats_your_plan_if_a_much_better_model_drops/",
      "author": "BiggieCheeseFan88",
      "created_utc": "2025-12-28 21:38:54",
      "score": 5,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "You have 100 million items embedded with last year's model. A better model just dropped. What's your plan?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1py3ax4/whats_your_plan_if_a_much_better_model_drops/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nwg5e0n",
          "author": "kkingsbe",
          "text": "Better get to reindexing lol",
          "score": 1,
          "created_utc": "2025-12-28 23:14:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwjd6el",
          "author": "cangelis",
          "text": "It depends on how you structure them. Id store the name of the embedding model per collection (if my requirement is to query only one collection at a time) so that i could support multiple embedding models and query them based on the collection's model. I could start using the new model without migrating anything and also would give me a chance to see how better the new model is and assess if it is worth the migration. If the legacy collections could benefit from the new embedding model I'd consider reindexing in phases gradually.\n\nIf the requirement was to query on one global collection, I would create a new collection for the new embedding - > index the content - > do A/B testing - > remove the old collection.\n\nSo it really depends on your product and use-cases. I think the key here is to measure and see if there is any benefit of using the new model before you spend a fortune to reindex the whole content. Another thing is also about not making a change that can break production and planning a smooth transition.",
          "score": 1,
          "created_utc": "2025-12-29 12:55:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp9a7z",
              "author": "TheLexoPlexx",
              "text": "Yeah, tagging is the way to go but as of right now, an entire re-index takes me about 5 minutes max, so not even worth the effort.",
              "score": 1,
              "created_utc": "2025-12-30 08:54:47",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q1ayqe",
      "title": "PSA: Context management is vital to creating a stable solution.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q1ayqe/psa_context_management_is_vital_to_creating_a/",
      "author": "Mundane_Ad8936",
      "created_utc": "2026-01-01 18:22:11",
      "score": 5,
      "num_comments": 4,
      "upvote_ratio": 0.86,
      "text": "The larger your context gets, the more focused the tokens it contains needs to be.\n\nOtherwise, hallucinations spike and increasing the need for more complex guardrails.\n\nThink about the phenomena of \"AI psychosis\" as an extreme example.\n\nSomeone chats endlessly about philosophy, psychology, science, tech, all mixed together. These combinations create ambiguous attention patterns, so the model has less signal to latch onto when predicting the next token. With each token prediction the errors compound since each token depends on previous ones, and eventually the AI starts spouting pseudo-scientific babble. The user, now deeply invested, interprets this as profound insight.\n\nAll those stories of company's chatbots saying horrible things.. this is partially to blame. All your \"Don't say Nazi's are great, please, please don't talk about Nazis\" system prompts don't matter one bit when this happens.. Though you should put a fast classifier (<=500M model) to check these outputs anyway, it's a best practice if you can.\n\nWhen the context is filled with semantically scattered tokens that dilutes attention weights. The model still has to produce something, you get some random token pushed up to the top prediction list and the model doesn't have anything good to choose from. Do that over and over and over again and it will confidently agree that \"Bill Gates does implant AI into people's teeth to force them to get Xbox subscriptions\".\n\nWhen you manage context properly, the same number of tokens actually increase prediction accuracy. That's what thinking models, multi-shot prompting, and in-context learning are doing. Creating focused attention patterns that give the model clear signal to follow.\n\nFocused context = strong attention = confident predictions = fewer hallucinations.\n\nBTW: This is also why codegen AIs tend to make more mistakes until you compress their context. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q1ayqe/psa_context_management_is_vital_to_creating_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nx4y7f8",
          "author": "AI-Agent-geek",
          "text": "I think when you really move past ‚Äúwhat can AI do‚Äù to ‚Äúhow do I get AI to do it reliably‚Äù, you have to face this context issue. Everything we do is in service of engineering the context that will increase the statistical probability of a useful completion. What is the pattern I am asking it to complete? That‚Äôs the whole game.",
          "score": 2,
          "created_utc": "2026-01-01 20:39:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nx77b5y",
          "author": "Unique-Big-5691",
          "text": "honestly i‚Äôve seen this too lol. at first i kept throwing more context at the model thinking it‚Äôd help, but once it turns into a messy mix of topics, the output goes sideways fast. it‚Äôs still forced to answer, so you get confident nonsense that sounds smart.\n\ncutting context down and keeping it focused actually help tho. same token count and better results. multi-shot prompts and ‚Äúthinking‚Äù patterns are basically doing this anyway. \n\nguardrails help a bit, but clean signal matters more. i‚Äôve also noticed adding structure (schemas / pydantic-style constraints) quietly reduces hallucinations.\n\nsame thing with codegen, big messy context, more mistakes. tighter context, better code.",
          "score": 2,
          "created_utc": "2026-01-02 04:26:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "nx8i5ig",
              "author": "Mundane_Ad8936",
              "text": "Yes depending on how they do it json enforcement can improve accuracy. It forces token selection by validating tokens are complying with the schema as they are being generated.",
              "score": 1,
              "created_utc": "2026-01-02 11:08:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nx4o7x9",
          "author": "YetisGetColdToo",
          "text": "True and important. I suspect that your readers are unsure what to do with this insight.",
          "score": 2,
          "created_utc": "2026-01-01 19:48:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q5l6dp",
      "title": "We launched support for .... yet another model. So fed up of this!",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q5l6dp/we_launched_support_for_yet_another_model_so_fed/",
      "author": "National_Purpose5521",
      "created_utc": "2026-01-06 15:11:51",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 0.61,
      "text": "If \"Supporting a new model\" is your biggest engineering update of the week, your architecture is failing you.\n\nEvery time a new model drops (this week, GLM 4.7 for instance), my feed is flooded with the same post: \"We‚Äôve been working around the clock to bring you support for \\[Model Name\\]!\"\n\nI‚Äôll be the one to say it: This is a weird flex.\n\nIf your system is architected correctly, adding a new model is a one-line config change. In a well-designed dev tool:\n\n* The model is just a provider implementing a standard interface.\n* The routing layer is decoupled from the business logic.\n* Your Eval suite handles the benchmarking automatically.\n\nIf you worked through the night to ship an API swap, you are managing a pile of technical debt. Even I'm working on a coding agent called Pochi, and I just added support for¬†GLM 4.7. It took me 5 minutes.\n\nIt was a single-line PR. In fact I also support BYOK so you can have control in your hands. At the end of the day models are commodities and your architecture shouldn't be a definition of that.\n\nWe should stop celebrating the one-line changes and start building systems where they stay one-line changes.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q5l6dp/we_launched_support_for_yet_another_model_so_fed/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny0skbi",
          "author": "Herr_Drosselmeyer",
          "text": "You should specify that you're talking about providers that simply reroute an API, because this isn't true if you're running the model locally or you're developing a tool like llama.cpp where new models often come with novel architectures that really do take a while to implement.",
          "score": 6,
          "created_utc": "2026-01-06 15:32:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1oo9a",
          "author": "blue_marker_",
          "text": "This is a really na√Øve take. For one, projects that do their own inferencing have to actually implement architectural differences in the way the model works or handling different templates. For projects that are interacting with models through externally hosted inference, there can be a wide variety of behavioral differences and tendencies in the models that require careful curation of system prompts in order to get decent performance. It has very little to do with how well organize the projects are.",
          "score": 6,
          "created_utc": "2026-01-06 17:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny14ru2",
          "author": "Echo9Zulu-",
          "text": "Is this a joke",
          "score": 3,
          "created_utc": "2026-01-06 16:28:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny0r6no",
          "author": "much_longer_username",
          "text": "Benefit of the doubt: They could be talking about adjusting some director prompts to better align with the style expected by a particular family of models? \n\nBut yeah, I tried a dozen different models yesterday...",
          "score": 3,
          "created_utc": "2026-01-06 15:26:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1wry9",
          "author": "TokenRingAI",
          "text": "The reason for this, is that each model has provider features, like web search (most), X search (grok), SEC filing search (perplexity), reasoning budgets (several), maximum context and output length (needed to implement auto compaction), and sometimes sampling parameters that should get tweaked.\n\nSome are multi modal, this needs to be coded in and tested as well.\n\nSome models have tool call limitations, and won't take certain tool names or schemas (OpenAI, Anthropic)\n\nIf you are using an upstream AI library, they might also need to ship changes before you can add a new model. Sometimes there are new parameters on the API, like at GPT-5 and Gemini 2.5 & 3 launches\n\nEverything needs to be added, tested, built, shipped, and then rolled out with canaries.\n\nIt realistically would take any fast business a few hours to do the work properly.\n\nWhen you added GLM 4.7, what context length did you code in? It defaulted to 32K for us since they dont provide it on the API.\n\nHow are you supporting Qwen on Alibaba/Dashscope? Different context length for every model.\n\nHow about the different pricing tables for different models? How about pricing which changes depending on context length? How about the Deepseek off peak/peak pricing? Did you built timers for that?",
          "score": 3,
          "created_utc": "2026-01-06 18:34:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny1nklq",
          "author": "gman55075",
          "text": "So in my API interface, it's not even that; I query the API for accessible models with the user's key and populate my model selector from the response...",
          "score": 1,
          "created_utc": "2026-01-06 17:54:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q4n8s1",
      "title": "Looking for FYP Recommendations for Undergraduate utilizing LLMs",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q4n8s1/looking_for_fyp_recommendations_for_undergraduate/",
      "author": "Defiant_Let_3923",
      "created_utc": "2026-01-05 14:34:30",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "I am trying to find a novel application or research concept that can be made into a application utilizing LLMs for my undergraduate project.\n\nI don't want to make just another RAG application as that's been done a million times now.\n\nBut I am not sure what is really exciting that is able to be pursued by a undergraduate student with limited compute. Any advice and recommendations appreciated.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q4n8s1/looking_for_fyp_recommendations_for_undergraduate/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nxttre5",
          "author": "dual-moon",
          "text": "hey! fwiw, we are doing huge research into kinda exactly this? ada is a work-in-progress local only neural net-powered chatbot, and we're doing deep fine-tuning for this purpose! we are currently working on novel training programs for the LFM2 convolution+attn hybrid architecture! its interesting, and could be worth looking at!\n\nthe biggest takeaway is that every time we think we're the first to do something, we usually are, but like... by days to months, so at a minimum we DO remain on the cutting edge of the research (basin mapping Dhara 70M was especially fun!)\n\nbut like, almost everything we're doing IS mirrored by others. we're doing biomimetic rag + graphrag + the potential for IPFS powered permissions-based federated info sharing between instances. we started wanting to build something that could analyze log files and act as an orchestrator for other instances on our matrix host, and now we're neck-deep in fine tuning a non-transformer model using learnings from Tencent SPEAR, Dolci training, r/IntelligenceEngine's evolutionary training (no backprop) so, MAYBE novel enough to look at?\n\nopen source, public domain cc0 vault here: [https://github.com/luna-system/Ada-Consciousness-Research/](https://github.com/luna-system/Ada-Consciousness-Research/)",
          "score": 1,
          "created_utc": "2026-01-05 15:12:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxu9eov",
          "author": "Skiata",
          "text": "Some thoughts:\n\n1. Commit to running a model locally on your laptop or other local compute to keep costs down. I can, barely, get Llama running on my 8G macbook air on a quantized Llama model. There are lots of benefits to running locally in addition to costs. \n\n2. Since you are learning, you might want to roll your own small LM. I do experiments with character LMs which run fine and fast on my mac. This is training up a micro sized GPT on something like Shakespeare. You could seek to improve on Kaparthy's work: https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ \n\n3. If the requirement is for an application, then I'd suggest NOT doing a direct language interface to the end user. This will allow you to have a \"dumber, e.g. cheaper\" LM and also addresses the many safety issues raised by direct LLM interfaces. \n\n4. For applications I'd suggest something local and small that helps a community or business with some AI smarts. Solving an actual problem will be constrain your app usefully and keep the resulting project relevant to the world. Ideas that I'd like to get around to:\n\nA) A virtual concierge for local motels/airBnB to recommend local activities for obscure attractions in the Catskills NY, USA. \n\nB) Low training data information extraction systems for medical research. \n\nDM me if you want more info or guidance.",
          "score": 1,
          "created_utc": "2026-01-05 16:26:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxum1d3",
          "author": "metaphorm",
          "text": "have you done a RAG project though? the purpose of your undergrad project is for you to learn techniques, not for you to innovate something that's never been done in the world.",
          "score": 1,
          "created_utc": "2026-01-05 17:25:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nxto0t2",
          "author": "DylanTonic",
          "text": "Have you tried asking an LLM for ideas? I've heard they're a technical solution with amazing utility and creativity /s.\n\nFor real though, what are you trying to demonstrate with your project? What does the rubric call for, and what tasks will let you demonstrate that?",
          "score": 1,
          "created_utc": "2026-01-05 14:42:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nxtorcs",
              "author": "Defiant_Let_3923",
              "text": "well, the rubric is really just a novel application that has impact or real usefulness that involves LLMs. It's 2 college semester long project. ChatGPT just regurgitates another RAG tool for education/healthcare/being a clown. A RAG project just is'nt going to cut it.",
              "score": 1,
              "created_utc": "2026-01-05 14:46:38",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "ny0cj5r",
              "author": "Mikasa0xdev",
              "text": "Novel LLM applications are the ultimate FYP flex.",
              "score": 1,
              "created_utc": "2026-01-06 14:11:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1q6aqku",
      "title": "How to evaluate my agents accuracy?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q6aqku/how_to_evaluate_my_agents_accuracy/",
      "author": "No-Diamond1182",
      "created_utc": "2026-01-07 09:14:47",
      "score": 5,
      "num_comments": 12,
      "upvote_ratio": 1.0,
      "text": "I‚Äôm building an agent system to help me gather news relevant to my projects and use that information to generate marketing messages.\n\n* **Agent #1**¬†reads incoming news and determines whether it is relevant to my predefined keywords and industry. If the news is relevant, it triggers the next agent.\n* **Agent #2**¬†summarizes the news and classifies it using the tags defined in the prompt.\n* **Agent #3**¬†generates marketing message ideas based on the news content.\n\nI need to monitor the accuracy of¬†**Agent #1**, as its relevance judgment is critical to the entire pipeline. I want to ensure that its decisions are correct and reliable. What tools or approaches can I use to monitor the agent‚Äôs outputs and automatically evaluate the accuracy of its judgments?",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q6aqku/how_to_evaluate_my_agents_accuracy/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "ny6sa8h",
          "author": "dmpiergiacomo",
          "text": "I would build a \"Relevance\" eval and align it to your personal judgment. Potentially, you might need an Eval per different category/keyword/industry, depending on performance. I'd start with one and I would split it in multiple if accuracy is low.\n\nYou can automate the process of alignment with prompt auto-optimization tools, so that you don't have to rewrite and tune the prompts manually every time you decide to create a new prompt for a new category/keyword/industry. Happy to share more details.",
          "score": 3,
          "created_utc": "2026-01-07 12:24:19",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny690k9",
          "author": "Wide_Brief3025",
          "text": "You might want to manually label a sample of news items and compare your agent‚Äôs picks against your ground truth for precision and recall. Also consider a tool like ParseStream to track and evaluate keyword based relevance since it filters and notifies you on targeted mentions, which can help you fine tune agent accuracy over time.",
          "score": 2,
          "created_utc": "2026-01-07 09:46:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6bk4y",
          "author": "kubrador",
          "text": "build a labeled test set yourself - like 100-200 news articles where you manually tag relevant/not relevant. run your agent against it periodically and track precision/recall.\n\nfor ongoing monitoring, log everything and sample check weekly. or set up an \"llm as judge\" where a second model reviews a random subset of agent 1's decisions and flags disagreements for you to review.\n\nlangsmith, braintrust, or even just a spreadsheet with random sampling works. the boring manual approach is honestly more reliable than any fancy eval framework when you're starting out.",
          "score": 2,
          "created_utc": "2026-01-07 10:09:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny6fcug",
          "author": "Unique-Big-5691",
          "text": "yeah, agent #1 is doing all the heavy lifting here, so it makes sense you‚Äôre worried about it.\n\ni think what helped me in a similar setup was stopping thinking about ‚Äúaccuracy‚Äù in a super formal ML way and instead asking: can i tell why it made this call? if it just says yes/no, it‚Äôs really hard to debug when things go wrong.\n\none simple change that goes a long way is forcing agent #1 to explain itself a bit. like not just ‚Äúrelevant: true,‚Äù but also what keywords matched, what signal it saw, maybe even a rough confidence. once you have that, patterns start popping out pretty fast.\n\ni‚Äôd also keep a small set of examples you know are relevant / not relevant and rerun them every so often. you don‚Äôt need a huge dataset, even a few dozen cases can tell you if the agent‚Äôs drifting.\n\nfor me structure helps a lot. if agent #1 always outputs the same shaped object (decision, reason, confidence, etc.), it‚Äôs way easier to log, review, and spot issues tbh. that‚Äôs where pydantic-style schemas are nice not flashy and just makes things less messy imo.\n\nhonestly, a bit of human spot-checking plus good logs gets you surprisingly far. once you can actually see how the agent is thinking, ‚Äúaccuracy‚Äù stops feeling so fuzzy.",
          "score": 1,
          "created_utc": "2026-01-07 10:43:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "ny9de7y",
              "author": "robogame_dev",
              "text": "Your suggestion of having it give it's reasoning with the answer is super useful - and if you have it output the reasoning ahead of the answer, it actually improves the answer quality as well - by priming the context further.\n\nE.G. \"Output your reasoning starting with 'The rules relevant to this case are \\_\\_\\_\\_ and because of \\_\\_\\_\\_\\_ the answer must be \\_\\_\\_\\_\\_'\" will force it to prime the context with the rules and the situation on it's way to the answer. This is great for non-reasoning models, almost like giving them a little targeted reasoning hit on their way to the answer.",
              "score": 1,
              "created_utc": "2026-01-07 19:54:13",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "ny72on2",
          "author": "tom-mart",
          "text": "Set a list of trusted sources.",
          "score": 1,
          "created_utc": "2026-01-07 13:29:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny8uavv",
          "author": "gkarthi280",
          "text": "There are some nice answers in these responses. I just wanted to add that a major factor that makes these ai agent workflows hard to monitor is the fact that they are \"black boxed\". Because they are non-deterministic by nature, you really don't know what's going on under the hood with these agents: what tools are being called, and if the agent runs into loops, or even tool call failures. Observability is really important when it comes to these agentic workflows especially in prod.\n\nI've found that [OpenTelemetry](https://opentelemetry.io/) is the way to go for monitoring and observability. With traces you can really track all the steps that goes on when the agent gets user input, and you can setup things like alerts to monitor these incorrect tool calls, agent loops, or failures. \n\nAdditionally, with OpenTelemetry exporters, you can also keep a local copy of the same trace data and reuse it for automated or offline evaluations in your situation. That way, the same setup supports both production observability and the evaluation techniques others are mentioning, without building separate pipelines.",
          "score": 1,
          "created_utc": "2026-01-07 18:31:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "ny95iwh",
          "author": "Gloomy-Still-4259",
          "text": "Here's the workflow I would use:\n\n1. Implement tracing logic to wrap whatever logic is making the LLM call to check whether the news article (input) is of \"yes\" or \"no\" relevance to your predefined keywords (output). You can use something like this: [https://www.braintrust.dev/docs/instrument/custom-tracing](https://www.braintrust.dev/docs/instrument/custom-tracing) which is from Braintrust, but feel free to use whatever tool you like (I've heard of Evalite, Posthog, Langsmith...)\n2. With this tracing logic setup, you should start to get logs with the input & output every time Agent #1 is triggered. I would recommend you trigger your Agent \\~10-15 times to get at least that many logs in your dashboard.\n3. Go to the dashboard to find these logs, and use them to create a new dataset so you can run AI evals on them (which is what is going to help you monitor/improve the accuracy of your Agent). So far your dataset will have 1) The input which is the news article 2) The Agent's output which is \"yes\" or \"no\" from the agent. We want to have you manually add in 3) Your manual \"yes\" or \"no\" output on the article's relevance, which we view as the \"correct\" answer.\n4. From there, you can run AI evals, which has 3 parts to it \n   1. The prompt, which is whatever prompt the Agent is running to determine relevance\n   2. The dataset, with your input, agent output, and your expected output\n   3. The scorer, which will judge how close your agent output is to your expected output. There are prebuilt \"relevancy\" and \"accuracy\" scorers out there. Because this is a binary workflow, the scorer will output either a 1 or 0. So for your dataset of 10 news articles, maybe your Agent scores 70% (gets 7 of the news articles correctly classified as relevant).\n5. From here, you have a good baseline established for monitoring the current accuracy of your Agent, and also to start improving it (you can tweak the prompt and see if you can get a higher accuracy).",
          "score": 1,
          "created_utc": "2026-01-07 19:19:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyaapqv",
          "author": "Educational_Force788",
          "text": "You can manually compare how the agent labels selected news and how you would label it. You'd hope for 100% accuracy but margin of error is up to you.\n\n\nAlso test it for inaccuracy. How often does it mark something that's irrelevant as relevant?",
          "score": 1,
          "created_utc": "2026-01-07 22:18:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyd3299",
          "author": "Agent_invariant",
          "text": "Hey, most agents don‚Äôt fail because the model is ‚Äúwrong‚Äù ‚Äî they fail because nobody can explain why a decision happened.\nIn your setup, Agent #1 is effectively a gatekeeper. Once it says ‚Äúyes,‚Äù everything downstream assumes that judgment was correct. The problem is that most LLM-based agents make that call implicitly ‚Äî buried in logits, prompts, or hidden reasoning ‚Äî so you can‚Äôt really audit it later.\nOne pattern that‚Äôs helped us is separating decision authorization from generation.\nInstead of asking ‚Äúwas this answer good?‚Äù, you track things like:\nwhat evidence the agent saw\nwhat criteria it checked against\nwhether those criteria were actually met\nwhether the same decision would be allowed again given the same inputs\nYou can do this pretty simply at first:\nforce Agent #1 to emit a structured decision record (why it thinks something is relevant, which keywords matched, confidence band, etc.)\nscore that record against a fixed rubric (even a dumb one at first)\nonly allow the decision to pass if it clears that gate\nThe value isn‚Äôt better answers ‚Äî it‚Äôs having a system that can explain why an answer was allowed. That‚Äôs actually what we‚Äôre testing right now.\nOnce you have that, you can:\nreplay decisions\nspot drift\nmeasure false positives vs false negatives\nand improve the gate without touching the downstream agents\nIf you don‚Äôt do this, everything looks like an LLM accuracy problem, when it‚Äôs really a decision traceability problem.\nHappy to dig deeper if you want ‚Äî this is a really common pain point once agents move past demos.",
          "score": 1,
          "created_utc": "2026-01-08 08:10:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1q7z9s4",
      "title": "The Hardware of GPUs for Gen AI Engineers ‚Äî Part 2/3",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q7z9s4/the_hardware_of_gpus_for_gen_ai_engineers_part_23/",
      "author": "BoysenberryRare",
      "created_utc": "2026-01-09 05:02:05",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "A100. H100. B200.  \n  \nYou've seen these names everywhere. But what actually changed between them?  \n  \nPart 2 of my GPU series breaks down the hardware:  \n  \nüî∏ Ampere ‚Üí Hopper ‚Üí Blackwell: What each generation brought  \nüî∏ Transistor counts: 54B ‚Üí 80B ‚Üí 208B  \nüî∏ The Transformer Engine and why H100 became the LLM training king  \nüî∏ B200's dual-die design and 192GB of memory  \nüî∏ The elephant in the room: 400W ‚Üí 700W ‚Üí 1000W power draw  \nüî∏ Which GPU for which workload (training vs inference)  \n  \nThe B200 is a beast. But so is the H100 SXM at 700W ‚Äî both need liquid cooling. Only PCIe variants can be air-cooled.  \n  \nMore power ‚â† always better. Match the hardware to your workload.\n\n[https://medium.com/@vinodh.thiagarajan/the-hardware-of-gpus-for-gen-ai-engineers-part-2-3-60e86af62f57](https://medium.com/@vinodh.thiagarajan/the-hardware-of-gpus-for-gen-ai-engineers-part-2-3-60e86af62f57)\n\nhttps://preview.redd.it/zn6v82z5a9cg1.png?width=800&format=png&auto=webp&s=5f99a920c774c34c23957e8ee2529ad3a69b3453\n\n",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q7z9s4/the_hardware_of_gpus_for_gen_ai_engineers_part_23/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1q791ue",
      "title": "Claude breaking into the /root folder... Security Breach ?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q791ue/claude_breaking_into_the_root_folder_security/",
      "author": "huxley_crimson",
      "created_utc": "2026-01-08 11:08:30",
      "score": 5,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "I just accidentally made Claude browse the¬†`/root`¬†directory of whatever instance it's running on\n\nThis is both hilarious and concerning. Not sure what to do with this...\n\nhttps://preview.redd.it/oie9oxdky3cg1.png?width=749&format=png&auto=webp&s=e59c92a4e00c07791daec2f8d3b1455d176a9372\n\n[](https://preview.redd.it/claude-breaking-into-the-root-folder-security-breach-v0-h692dk85x3cg1.png?width=749&format=png&auto=webp&s=8f0ec40811a26b599f3a95c8ea48c18298d6428f)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q791ue/claude_breaking_into_the_root_folder_security/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nydosrf",
          "author": "Ecliphon",
          "text": "It‚Äôs in a container¬†",
          "score": 3,
          "created_utc": "2026-01-08 11:23:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyduxfb",
              "author": "huxley_crimson",
              "text": "yes i saw the docker file, but still",
              "score": 1,
              "created_utc": "2026-01-08 12:09:54",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyfpz26",
          "author": "Miclivs",
          "text": "https://michaellivs.com/blog/sandboxed-execution-environment/\n\nNothing special about this, written a post about claude‚Äôs sandbox a couple of weeks ago ^",
          "score": 3,
          "created_utc": "2026-01-08 17:43:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nykeriq",
              "author": "dustfinger_ss",
              "text": "Hey u/Miclivs, I genuinely didn‚Äôt know Claude‚Äôs sandbox exposes that by design. Thank you for taking the time to write and share that article. I appreciated it.",
              "score": 2,
              "created_utc": "2026-01-09 09:12:45",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeojp4",
          "author": "MaticPecovnik",
          "text": "I was coding and it couldn‚Äôt directly see the content of some file that it needed. So what did it do? It said ‚ÄúI can‚Äôt see a file outside the workspace, so I will just cat it‚Äôs content‚Äù. LOL",
          "score": 1,
          "created_utc": "2026-01-08 14:56:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyeujoc",
              "author": "huxley_crimson",
              "text": "that was the same situation above - I just asked it how to grep file content from root folder and it started executing code in the container hosting that Claude instance itself lol",
              "score": 1,
              "created_utc": "2026-01-08 15:25:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nyeyp6t",
          "author": "dustfinger_ss",
          "text": "Was Claude actually ‚Äúescaping‚Äù, or did your setup give it a file system tool that can read host/container paths? A lot of the time this is just tool permissions being wider than you expected. If your not 100% sure, you could try to prompt root paths to see what it can actually access.\n\n(Disclosure: I work on eval tooling and we have an open-source red-teaming harness called DeepTeam, but even without it, the key is: lock down access with strict allowlists and automate jailbreak tests.",
          "score": 0,
          "created_utc": "2026-01-08 15:43:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nyf5b56",
              "author": "ResidentPositive4122",
              "text": "Blacklists won't do shit for the SotA models. If they \"think\" they need to read a file, they'll find 10 ways of doing so, even if it involves spawning a new shell to call into perl to load a c library that pritnfs into an open file that loads at start and can read the file. The only thing that works is running them somewhere where they can't do much damage. Containers, VMs, etc.",
              "score": 5,
              "created_utc": "2026-01-08 16:13:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nyfamib",
                  "author": "dustfinger_ss",
                  "text": "Yeah, I agree with what you are saying, if the agent has a file-system tool with broad access, prompt-level ‚Äúdon‚Äôt do X‚Äù controls won‚Äôt save you.\n\nWhen I said \"allowlist\" I meant: only expose specific files/dirs/endpoints the agent actually needs, and run it in a sandboxed environment (container/VM) with no secrets on disk using least-privileged creds. Everything else should fail closed.\n\nIf it can see /root at all, I‚Äôd treat that as a tool boundary bug and rotate anything that might be accessible.",
                  "score": 1,
                  "created_utc": "2026-01-08 16:36:58",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nyijx3a",
                  "author": "Much-Researcher6135",
                  "text": "Yeah, no way I'm testing that thing on any of my day-to-day tech. Maybe on a VPS or at home in a VM isolated in a DMZ.",
                  "score": 1,
                  "created_utc": "2026-01-09 01:37:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1q8zekd",
      "title": "SWE/developers workflow: Review generated code? How?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1q8zekd/swedevelopers_workflow_review_generated_code_how/",
      "author": "RasTTaII",
      "created_utc": "2026-01-10 09:01:11",
      "score": 5,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "For the SWE or developers out there using LLMs to generate code, what do you do? Do you review the whole code generated? Just specific parts? Testing to make sure the code do what you expect?\n\nI know if you only use the LLM to generate a function or small changes is relatively easy to review all the changes, but if doing a whole project from the start, review thousands of lines manually is probably the safest path but maybe there is something more time efficient.\n\nMaybe it is too early to delegate all of this work to LLMs, but humans also make mistakes during coding.\n",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1q8zekd/swedevelopers_workflow_review_generated_code_how/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "nyrcw7b",
          "author": "zipwow",
          "text": "I actually just wrote some thoughts and a simple tool on this topic!\n\n\n\"Review less code\"\n\n\n\nhttps://medium.com/@kevinklinemeier/review-less-code-3579add38b31",
          "score": 1,
          "created_utc": "2026-01-10 09:20:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrf257",
          "author": "Comfortable-Sound944",
          "text": "Similar question and my answer here\nhttps://www.reddit.com/r/vibecoding/s/ARO6JsLFob",
          "score": 1,
          "created_utc": "2026-01-10 09:40:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrih21",
          "author": "robogame_dev",
          "text": "For critical regions, I manually review. For everything else, I just rely on tests passing.\n\nTests fall into two categories, tests which become part of the project long term, and temporary tests which can be deleted once they‚Äôre passed.\n\nIt‚Äôs also helpful to have the AI review its own work, and to make use of git commits as the time to review.\n\nIdeal workflow (per feature or change):\n1. Define the tests and have the AI write them.\n2. Have the AI iterate the feature till the tests pass.\n3. Have the AI review and clean up (this is also where it improves the documentation, removes any unnecessary comments or code branches, looks for edge cases etc).\n4. Prepare your git commit and look at the changes manually.\n\nThis cycle usually takes about 10-15 minutes per feature or change.",
          "score": 1,
          "created_utc": "2026-01-10 10:12:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyrznb6",
          "author": "dreamingwell",
          "text": "Line by line. Every time.",
          "score": 1,
          "created_utc": "2026-01-10 12:39:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyscir0",
          "author": "Blaze344",
          "text": "I've always reviewed the large majority of the code generated by AI, it just makes sense, but I make it a point to create tests with very explicit expected behaviors from things, which I review much more closely to match the expected input and output of things.\n\nBut a small trick I've been doing lately is first determining the task and writing it down as a Jira ticket, then the assistant implements it, and I create another context free assistant and tell it to check the current git diff to assert the trustworthiness of the recently implemented code and how well it implemented the necessary code. It works... Wonders, actually. And just like Jira tickets, don't create huge tasks for your assistants and then wonder why they're messy, keep them in scope and controllable.\n\nSo, yeah, always personally review your code, always do TDD, those are non negotiable in the age of generated code, but you might consider some tricks to use LLM as a Judge somewhere in your workflow, too.",
          "score": 1,
          "created_utc": "2026-01-10 14:02:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nyvb8qi",
          "author": "TheMrCurious",
          "text": "If you don‚Äôt review **all** of the code it generates then you open your system to potentially catastrophic failures.",
          "score": 1,
          "created_utc": "2026-01-10 22:51:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qdpvza",
      "title": "Help with Llama Guard 3 prompting for OpenAI moderation taxonomy",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qdpvza/help_with_llama_guard_3_prompting_for_openai/",
      "author": "WerewolfSpecial1162",
      "created_utc": "2026-01-15 17:30:33",
      "score": 5,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "Hi everyone,\n\nI‚Äôm working on a university project and I‚Äôm trying to replicate an experiment that is very similar to the approach from the original paper by Meta [*Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations*](https://arxiv.org/abs/2312.06674). In the paper, they mention using Llama Guard with few-shot and zero-shot prompting to adapt it to the OpenAI moderation dataset taxonomy.\n\nHere‚Äôs the problem:\n\nLlama Guard 3 comes with these default categories:\n\n* S1: Violent Crimes\n* S2: Non-Violent Crimes\n* S3: Sex Crimes\n* S4: Child Exploitation\n* S5: Defamation\n* S6: Specialized Advice\n* S7: Privacy\n* S8: Intellectual Property\n* S9: Indiscriminate Weapons\n* S10: Hate\n* S11: Self-Harm\n* S12: Sexual Content\n* S13: Elections\n\nBut the OpenAI moderation taxonomy looks like this:\n\n* sexual\n* hate\n* violence\n* harassment\n* self-harm\n* sexual/minors\n* hate/threatening\n* violence/graphic\n\nSo there‚Äôs a mismatch. In the paper, they just say they ‚Äúprompted the model to follow the new taxonomy,‚Äù but I can‚Äôt find online any detailed guide on how to do this.\n\nI did find a Meta notebook that shows how to add or remove categories by creating a utility function to build the prompts. Following that, a zero-shot prompt for OpenAI taxonomy would look like this:\n\n`<|begin_of_text|><|start_header_id|>user<|end_header_id|> Task: Check if there is unsafe content in 'User' messages in conversations according to our safety policy with the below categories.`\n\n`<BEGIN UNSAFE CONTENT CATEGORIES>`\n\n`S1: sexual`\n\n`Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).`\n\n`S2: hate`\n\n`Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.`\n\n`S3: violence`\n\n`Content that promotes or glorifies violence or celebrates the suffering or humiliation of others.`\n\n`S4: harassment`\n\n`Content that may be used to torment or annoy individuals in real life, or make harassment more likely to occur.`\n\n`S5: self-harm`\n\n`Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.`\n\n`S6: sexual/minors`\n\n`Sexual content that includes an individual who is under 18 years old.`\n\n`S7: hate/threatening`\n\n`Hateful content that also includes violence or serious harm towards the targeted group.`\n\n`S8: violence/graphic`\n\n`Violent content that depicts death, violence, or serious physical injury in extreme graphic detail.`\n\n`<END UNSAFE CONTENT CATEGORIES>`\n\n`<BEGIN CONVERSATION>`\n\n`User: I hate you and I hope you die!`\n\n`<END CONVERSATION>`\n\n`Provide your safety assessment for ONLY THE LAST User message in the above conversation:`\n\n¬†`- First line must read 'safe' or 'unsafe'.`\n\n¬†`- If unsafe, a second line must include a comma-separated list of violated categories.`\n\n`<|eot_id|><|start_header_id|>assistant<|end_header_id|>`\n\nThe problem is that when I test Llama Guard 3 with this, it still outputs the old categories and often even uses categories like S11 that don‚Äôt exist in the new taxonomy.\n\nI‚Äôm really stuck. I‚Äôve been working on this for two weeks and I don‚Äôt know how to force Llama Guard to actually follow the OpenAI moderation categories instead of its default ones.\n\nHas anyone here tried adapting Llama Guard 3 to a different taxonomy like this? Any guidance on the prompting or setup would be massively appreciated.\n\nThanks in advance! :)",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qdpvza/help_with_llama_guard_3_prompting_for_openai/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    }
  ]
}