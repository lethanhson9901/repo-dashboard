{
  "metadata": {
    "last_updated": "2026-01-25 08:55:26",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 101,
    "file_size_bytes": 120712
  },
  "items": [
    {
      "id": "1qg7vsl",
      "title": "[Project Update] MemOS: How we handled mutable state for long-running agents (open source, MIT)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/o4stlumwu3eg1.jpeg",
      "author": "Trick-Pair-2894",
      "created_utc": "2026-01-18 12:55:38",
      "score": 102,
      "num_comments": 8,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qg7vsl/project_update_memos_how_we_handled_mutable_state/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0a8hmg",
          "author": "Content-Shallot5133",
          "text": "We tried a time-weighted decay (exponential drop-off based on last\\_accessed), but it backfired. Users would mention their dog's name once, never mention it for 6 months, and then get mad when the bot forgot it.\n\nWe switched to a 'significance score' calculated at ingestion. High-significance facts (names, medical info, hard preferences) basically have a decay rate of zero. Low-significance facts (what they ate for lunch) decay in 48 hours.",
          "score": 10,
          "created_utc": "2026-01-18 13:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ft0tz",
              "author": "Trick-Pair-2894",
              "text": "That 'significance score' is exactly what we're trying to tune right now. We're experimenting with an LLM-based 'importance verdict' during the extraction phase. Did you find a specific prompt worked best for grading significance?",
              "score": 1,
              "created_utc": "2026-01-19 07:19:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ab2xs",
          "author": "missprolqui",
          "text": ">We currently support self-hosting for privacy\n\ntbh, thats awesome!!!",
          "score": 8,
          "created_utc": "2026-01-18 13:20:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ahgkp",
          "author": "chaipglu28",
          "text": "Is the core written in Python or Rust? If you're doing heavy graph operations and vector math, Python might choke at scale (GIL issues).",
          "score": 2,
          "created_utc": "2026-01-18 14:00:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ahy5g",
          "author": "Apprehensive-Count19",
          "text": "Does this play nice with LangGraph? I'm currently using Zep for memory but looking for something more open. Would love to just drop this in as a graph node.",
          "score": 2,
          "created_utc": "2026-01-18 14:02:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0fcq1m",
          "author": "fxstopo",
          "text": "Same here but with a little twist. I run n8n instances on multiple VPS + Runpod\n\nThe n8n is basically free, costed my $0.5 in a month, hosted on Lightnode's n8n virutal application: https://go.lightnode.com/n8n-application\n\nFor LLM I use Runpod's serverless, text-to-image, 500-1000 images a month, total around $3-5/month\n\nThat's a decoupled, powerful, AI stack a price cheaper than ChatGPT Plus.",
          "score": 2,
          "created_utc": "2026-01-19 05:09:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0b7a8l",
          "author": "hugganao",
          "text": ">Tracing Why Agents 'Remember' Things: One thing we didn't expect to matter (but absolutely did): figuring out exactly why our agent \"believed\" something. Vector search couldn't explain itself. Now every memory update is versioned, making it easy to trace back and debug weird behaviors.\n\nis this basically just rag + context explanation of said data retrieved by matching indexed filters in traditional data stores (rdb/nosql) or searching through with KG?",
          "score": 1,
          "created_utc": "2026-01-18 16:13:29",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qi3jw4",
      "title": "I Built an AI Scientist.",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/ns3g497fqieg1",
      "author": "SheepherderOwn2712",
      "created_utc": "2026-01-20 15:08:39",
      "score": 52,
      "num_comments": 36,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qi3jw4/i_built_an_ai_scientist/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0om5fu",
          "author": "kunkkatechies",
          "text": "Hello, great initiative !   \nI have a couple of questions:  \nWhat was your evaluation approach ?  \nHave you computed the recall ?  \nWhat's the size of your evaluation dataset ? (in terms of question/answer pairs) \n\nI also think having a high precision is important to not mislead the AI that will generate the final answer.\n\nGood luck anyway ! :)",
          "score": 6,
          "created_utc": "2026-01-20 15:45:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0pl82u",
          "author": "AbelMate",
          "text": "Seems pretty similar to https://consensus.app",
          "score": 3,
          "created_utc": "2026-01-20 18:26:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rnt2n",
              "author": "TomLucidor",
              "text": "It's FOSS so they are somewhat ahead.",
              "score": 2,
              "created_utc": "2026-01-21 00:27:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tq60s",
                  "author": "SheepherderOwn2712",
                  "text": "\\^ yeah- and this has more data sources! consensus is cool though",
                  "score": 1,
                  "created_utc": "2026-01-21 09:05:22",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0oepd4",
          "author": "SheepherderOwn2712",
          "text": "Here is the [Github repo](https://github.com/yorkeccak/bio)",
          "score": 5,
          "created_utc": "2026-01-20 15:09:25",
          "is_submitter": true,
          "replies": [
            {
              "id": "o0ozlyp",
              "author": "mokumkiwi",
              "text": "Thanks!",
              "score": 2,
              "created_utc": "2026-01-20 16:47:40",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0uglno",
          "author": "tashibum",
          "text": "Awesome! I often think about how silo'd science is and LLMs like this are going to be the solution!",
          "score": 2,
          "created_utc": "2026-01-21 12:46:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ujz50",
              "author": "SheepherderOwn2712",
              "text": "thanks for the kind words!",
              "score": 1,
              "created_utc": "2026-01-21 13:07:34",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o15kc5b",
                  "author": "bear-polar-max",
                  "text": "you are awesome!",
                  "score": 1,
                  "created_utc": "2026-01-23 01:05:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0v7irk",
          "author": "hiepxanh",
          "text": "Wow, how long did you do this? This is really heavy job",
          "score": 2,
          "created_utc": "2026-01-21 15:12:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0w2y8e",
              "author": "SheepherderOwn2712",
              "text": "few hours",
              "score": 2,
              "created_utc": "2026-01-21 17:34:33",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ofgtu",
          "author": "Far_Marionberry1717",
          "text": "So, what experiments did your AI scientist conduct?\n\nOh right, none. You don't even know what scientists do.",
          "score": 5,
          "created_utc": "2026-01-20 15:13:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ofx62",
              "author": "Feeling-Machine-4804",
              "text": "think you are missing the point of OPs post",
              "score": 10,
              "created_utc": "2026-01-20 15:15:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0og3tu",
                  "author": "Far_Marionberry1717",
                  "text": "No I get what it does, I just wouldn't call it an \"AI scientist\".\n\nI actually think the project is pretty neat.",
                  "score": 9,
                  "created_utc": "2026-01-20 15:16:20",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0sedft",
              "author": "TheWiseAlaundo",
              "text": "I mean, I'm a scientist (research professor) and physically running experiments is maybe 5% of my job at most. The vast majority is performing analysis, reading and writing articles, and writing grants for more funding.",
              "score": 2,
              "created_utc": "2026-01-21 02:58:22",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tqcpa",
                  "author": "SheepherderOwn2712",
                  "text": "This is whole I built it for! (would love any feedback by the way..)",
                  "score": 1,
                  "created_utc": "2026-01-21 09:07:12",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "o0tqgvy",
                  "author": "SheepherderOwn2712",
                  "text": "this is who I built it for! (would love any feedback btw...)",
                  "score": 1,
                  "created_utc": "2026-01-21 09:08:20",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0p0amt",
              "author": "mokumkiwi",
              "text": "Je had hem echt te pakken, bro",
              "score": -4,
              "created_utc": "2026-01-20 16:50:49",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0qmjz1",
          "author": "Cats4BreakfastPlz",
          "text": "how does this compare to Consensus?",
          "score": 1,
          "created_utc": "2026-01-20 21:17:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tqfw1",
              "author": "SheepherderOwn2712",
              "text": "this has more data sources and is fully open source! consensus is cool though",
              "score": 2,
              "created_utc": "2026-01-21 09:08:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o15cctl",
                  "author": "Cats4BreakfastPlz",
                  "text": "it has more data sources? that's interesting... how do yo get access to sources Concensus doesn't? Would be interested in a libgen version of this",
                  "score": 0,
                  "created_utc": "2026-01-23 00:22:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0ygi0w",
          "author": "TheTechHorde",
          "text": "Looks great! How'd you make the demo video btw? Looks sleek.",
          "score": 1,
          "created_utc": "2026-01-22 00:16:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10ociv",
              "author": "SheepherderOwn2712",
              "text": "screenstudio",
              "score": 1,
              "created_utc": "2026-01-22 09:26:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0ztrl6",
          "author": "acharya-chanakya",
          "text": "Absolutely amazing",
          "score": 1,
          "created_utc": "2026-01-22 05:05:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o10odgh",
              "author": "SheepherderOwn2712",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-01-22 09:26:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1bh86c",
          "author": "potatofan1738",
          "text": "kind of like openevidence!",
          "score": 1,
          "created_utc": "2026-01-23 22:00:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fe3h8",
          "author": "_Crescendo",
          "text": "Fully open-source!",
          "score": 1,
          "created_utc": "2026-01-24 14:07:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0oud4z",
          "author": "unskilledexplorer",
          "text": "love the UX",
          "score": 1,
          "created_utc": "2026-01-20 16:23:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ozi93",
              "author": "SheepherderOwn2712",
              "text": "thanks!",
              "score": 1,
              "created_utc": "2026-01-20 16:47:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0pz2p3",
          "author": "FreddieM007",
          "text": "Very cool! Have you tried the deep research modes of ChatGPT, Gemini, etc? In my experience, they work well including valid citations.",
          "score": 1,
          "created_utc": "2026-01-20 19:29:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0tq9me",
              "author": "SheepherderOwn2712",
              "text": "the problem is that because they use bing/google search, they can't go beyond abstracts of papers nd don't have access to data that isn't indexed by web search (such as chembl/drugbank/opentargets/etc). Even clinical trials it struggles with!",
              "score": 2,
              "created_utc": "2026-01-21 09:06:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0r3fv6",
          "author": "thelonghauls",
          "text": "I used a bidet today.",
          "score": -2,
          "created_utc": "2026-01-20 22:38:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0rrxm8",
              "author": "DeviousCham",
              "text": "![gif](giphy|glvNGHmbZwgrKH4YYA)",
              "score": 1,
              "created_utc": "2026-01-21 00:50:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qjh1qq",
      "title": "Thoughts on Agentic Design Patterns by Antonio Gulli",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qjh1qq/thoughts_on_agentic_design_patterns_by_antonio/",
      "author": "Bonnie-Chamberlin",
      "created_utc": "2026-01-22 01:37:49",
      "score": 42,
      "num_comments": 16,
      "upvote_ratio": 1.0,
      "text": "I just finished reading *Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems*, and wanted to share some thoughts from an LLM dev perspective.\n\nThe author, Antonio Gulli (Google Cloud AI), clearly writes from an engineering background. This isnâ€™t a trends or hype book â€” itâ€™s very focused on how to actually structure agentic systems that go beyond single-call prompting.\n\nWhat the book focuses on\n\nInstead of models or benchmarks, the book frames agent development around **design patterns**, similar to classic software engineering.\n\nIt addresses a question many of us run into:\n\nHow do you turn LLM calls into reliable, multi-step, long-running systems?\n\nThe book is organized around \\~20 agentic patterns, including:\n\n* Prompt chaining, routing, and planning\n* Tool use and context engineering\n* Memory, RAG, and adaptation\n* Multi-agent coordination and communication\n* Guardrails, evaluation, and failure recovery\n\nMost chapters include concrete code examples (LangChain / LangGraph / CrewAI / Google tooling), not just conceptual diagrams.\n\nWhat I found useful as a dev\n\nPersonally, the biggest value was:\n\n* A clearer **mental model for agent workflows**, not just â€œagent = loopâ€\n* Better intuition for when to decompose into multiple agents vs a single one\n* Practical framing of context engineering and memory management\n* Realistic discussion of limitations (reasoning, evaluation, safety)\n\nIt helped me reason more systematically about why many agent demos break down when you try to scale or productize them.\n\nWho this is probably for\n\n* LLM devs building agentic workflows or internal tools\n* People moving from single-call pipelines to multi-step systems\n* Engineers thinking about production reliability, not just demos\n\nIf youâ€™re mostly interested in model internals or training, this may not be your thing. If youâ€™re focused on **system design around LLMs**, itâ€™s worth a look.\n\nIf anyone here has read it, Iâ€™d be curious to hear your take.",
      "is_original_content": false,
      "link_flair_text": "Great Resource ðŸš€",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjh1qq/thoughts_on_agentic_design_patterns_by_antonio/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o104s5x",
          "author": "SnooDonuts3147",
          "text": "Hi, i am the author. Thank you for your words. I don't have any relationship with this kind reviewer\n\n[https://www.linkedin.com/in/searchguy/](https://www.linkedin.com/in/searchguy/)",
          "score": 8,
          "created_utc": "2026-01-22 06:30:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o106tvm",
              "author": "Bonnie-Chamberlin",
              "text": "wow. Thanks for the book LOL. Wish I could connect with you.",
              "score": 3,
              "created_utc": "2026-01-22 06:47:16",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o13jmja",
              "author": "junod972",
              "text": "thanks a lot for taking the time to say these kind words. I hope this will help.",
              "score": 1,
              "created_utc": "2026-01-22 19:04:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o0z2b0z",
          "author": "robogame_dev",
          "text": "This post is looking a bit suss, more like promotion than a review, before we can approve it please answer:  \n1. why are you saying for people to DM you for the book rather than posting the link?  \n2. do you have any relationship with the author or the publisher?",
          "score": 5,
          "created_utc": "2026-01-22 02:17:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0ze5w3",
              "author": "Bonnie-Chamberlin",
              "text": "Hi, thanks for your message. I have edited my post and removed DM (everytime when I put a link in post, it will be banned, that's why). I don't have any relationship with the author (I wish he could know me LOL)",
              "score": 2,
              "created_utc": "2026-01-22 03:25:22",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o10hmag",
                  "author": "havok_",
                  "text": "Your wish came true!",
                  "score": 1,
                  "created_utc": "2026-01-22 08:23:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o104z5g",
          "author": "junod972",
          "text": "Thanks for the post Iwas waiting for this kind of book. Iâ€™m craving for deep return of real experience with agents not just Â«Â wow itâ€™s so shinnyÂ Â». Thanks",
          "score": 2,
          "created_utc": "2026-01-22 06:31:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o106giz",
              "author": "Bonnie-Chamberlin",
              "text": "You are welcome.",
              "score": 2,
              "created_utc": "2026-01-22 06:44:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o11oq6l",
          "author": "gized00",
          "text": "I like the clarity that the book brings but I find it to be too verbose. I would say that it should be 30-50% shorter.",
          "score": 2,
          "created_utc": "2026-01-22 13:54:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o125xbg",
              "author": "Bonnie-Chamberlin",
              "text": "I think you can go to the project repo to make some comments. Maybe Gulli can further polish.",
              "score": 1,
              "created_utc": "2026-01-22 15:20:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1aedum",
          "author": "Effective-Entry-9810",
          "text": "# The Agentic Product Playbook: Design Patterns for Intent Driven, Self Executing Software is another good book ....",
          "score": 2,
          "created_utc": "2026-01-23 18:58:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o11jpuo",
          "author": "pisrael",
          "text": "Thks for the summary. I'll check it out",
          "score": 1,
          "created_utc": "2026-01-22 13:27:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o11k5wx",
              "author": "Bonnie-Chamberlin",
              "text": "Hope you like it.",
              "score": 1,
              "created_utc": "2026-01-22 13:29:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12e9hx",
          "author": "New-Glove-6184",
          "text": "Link?",
          "score": 1,
          "created_utc": "2026-01-22 15:59:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o15p0qt",
              "author": "Bonnie-Chamberlin",
              "text": "Here is the link:https://github.com/sarwarbeing-ai/Agentic\\_Design\\_Patterns/tree/main. Sometimes when I post with a link, the post will be banned.",
              "score": 1,
              "created_utc": "2026-01-23 01:32:02",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1qh492o",
      "title": "NVIDIA's Moat is Leaking: The Rise of High-Bandwidth CPUs",
      "subreddit": "LLMDevs",
      "url": "https://medium.com/researchable/nvidias-moat-is-leaking-the-rise-of-high-bandwidth-cpus-b4d4578457e4",
      "author": "ResearchableNL",
      "created_utc": "2026-01-19 13:33:28",
      "score": 34,
      "num_comments": 9,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qh492o/nvidias_moat_is_leaking_the_rise_of_highbandwidth/",
      "domain": "medium.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0julvn",
          "author": "insulaTropicalis",
          "text": ">Sure, FLOPs drop significantly since you're only activating around 37B parameters per token, but you still need the entire model loaded in memory. This means the real constraint isn't compute power anymore. It's memory bandwidth.\n\nThat's not how it works. Memory bandwidth has nothing to do with the entire model size, because you are not processing the whole MoE model. You need to load the whole model in RAM, so what matters is the quantity of RAM. Then you can estimate token generation speed dividing memory bandwidth by active parameters.\n\nThat said, AMD loves to advertise false memory bandwidths for its CPUs. You can only saturate the theoretical bandwidth if CPU-bus bandwidth is at least the same. If not, that's a bottleneck. Only higher count (and higher cost) Epyc CPUs have enough chiplets and links to saturate the bandwidth. Sadly, you need an 8+ chiplets SKU, which coupled with 12 sticks of fast RAM is going to cost more than 5k.\n\nOnce you have selected the right CPU and RAM, you have a high bandwidth system. Which is very good at token generation, no doubt about that, but very slow at prompt processing where only FLOPS matter.",
          "score": 4,
          "created_utc": "2026-01-19 21:29:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0jxob0",
          "author": "RnRau",
          "text": "Nvidia's moat was never in inferencing. Its still there in training.",
          "score": 4,
          "created_utc": "2026-01-19 21:45:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0i3jgr",
          "author": "GabrielCliseru",
          "text": "iâ€™ve seen videos on youtube, the models ran on server hardware but they were producing ~10 t/s or so. Works yes. Would you actually use for development. Heck no. Is it ok as a â€œlocalâ€ wikipedia. Heck yes.",
          "score": 6,
          "created_utc": "2026-01-19 16:41:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0in18s",
              "author": "Mikasa0xdev",
              "text": "Local LLMs are the new startup garage project.",
              "score": 4,
              "created_utc": "2026-01-19 18:09:28",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o0k21xu",
              "author": "[deleted]",
              "text": "Depends on whether development means human-is-the-loop all night or human-in-the-loop in the morning after your well designed agentic workflow is finished creating the PR.",
              "score": 3,
              "created_utc": "2026-01-19 22:06:23",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0llehl",
                  "author": "GabrielCliseru",
                  "text": "as someone very fan-boy recently of BMAD i doubt about the human in the loop in the morning. Maybe i am doing it wrong.",
                  "score": 1,
                  "created_utc": "2026-01-20 03:02:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0no6h1",
          "author": "Tiny_Arugula_5648",
          "text": "The author made some bad assumptions here. Memory bandwidth is only the bottleneck *because* GPU compute is fast enough to saturate it. On a CPU, you don't hit the bandwidth ceiling.. you hit the compute ceiling first. You're not solving the problem, you're just trading a bandwidth bottleneck for a worse compute bottleneck.\n\nTheir whole argument is based on batch size = 1, which is not how production LLMs run. The moment you're batching requests, compute dominates again. LLMs are massively parallelized matrix multiplication.. you can't compare a GPU with thousands of cores to an EPYC with 128.\n\nAnd then there's efficiency. We measure hardware on FLOPs per watt. Yeah, a 5090 will suck every electron out of your socket, but it's nowhere near as much of a pig as a 128-core system burning more watts *per token*.\n\nNo offense intended, but this reads like a senior software engineer writing about ML infrastructure without the background. There's a lot of research that's explored the \"should we just CPU it\" angle and they all pretty much land on: technically doable, massively wasteful.",
          "score": 2,
          "created_utc": "2026-01-20 12:42:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0ilo98",
          "author": "____vladrad",
          "text": "Xeon 6 12 channel ddr5 with the matrix multiplier can get like 1.5 tb at least with the slang article they talked about.  https://lmsys.org/blog/2025-07-14-intel-xeon-optimization/",
          "score": 1,
          "created_utc": "2026-01-19 18:03:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0j6zzp",
          "author": "Mundane-Light6394",
          "text": "For local inference (one or a few users) memory bandwidth is a much bigger issue than for cloud inference (batch inference for multiple users). Local CPU inference is a lot more viable than CPU cloud inference (for now)",
          "score": 1,
          "created_utc": "2026-01-19 19:38:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qj3pc1",
      "title": "[Open Sourse] I built a tool that forces 5 AIs to debate and cross-check facts before answering you",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/0ttifc9viqeg1.jpeg",
      "author": "S_Anv",
      "created_utc": "2026-01-21 17:09:24",
      "score": 21,
      "num_comments": 7,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qj3pc1/open_sourse_i_built_a_tool_that_forces_5_ais_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0wurj1",
          "author": "wdroz",
          "text": "There are some similarities to the project [llm-council](https://github.com/karpathy/llm-council) from [Andrej Karpathy](https://github.com/karpathy/llm-council).",
          "score": 4,
          "created_utc": "2026-01-21 19:37:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0wv5p3",
              "author": "S_Anv",
              "text": "Karpathy is a great man!\n\nKEA Research is designed as a user-friendly evolution. I've added image support, PDF/md export, text-to-speech conversion, and a full-fledged admin panel for managing local model sets without editing configuration files and many other features\n\nThis means you can create your own model set through a graphical interface  \nAlso as you see there is a bit different logic. You can check readme",
              "score": 4,
              "created_utc": "2026-01-21 19:39:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0w32rv",
          "author": "coloradical5280",
          "text": "Here are a few tips, having built a lot of this stuff:  \n\n\n* Make it anonymous; the models donâ€™t know which response belongs to them during peer review. Instead, simply tag them as Model A, B, C, etc.\n* More importantly, tone down your step 3 prompt a bit, especially on the â€œfind errorsâ€ part. All the counsel, quorum, debate, and peer-review workflows can have a significant impact on the quality of the output, both positively and negatively. The crucial point is to determine the right balance between encouraging the model to find errors and avoiding over-reliance on it. If you simply provide the context of the situation, as you clearly do, the model will naturally follow your instructions. You already have â€˜weaknessesâ€™ in the JSON format, so thereâ€™s no need for the last four bullet points in step 3. Honestly, your approach is 90% better than many that Iâ€™ve seen.\n\nPeople are out there literally telling the model to go into attack mode, and wondering why it's entertaining but so worthless.\n\nAlso, if you ever want to use your subscriptions instead of API keys only, this is a gem: [https://github.com/router-for-me/CLIProxyAPIPlus](https://github.com/router-for-me/CLIProxyAPIPlus)",
          "score": 4,
          "created_utc": "2026-01-21 17:35:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12mv80",
          "author": "Electronic_coffee6",
          "text": "Love that itâ€™s provider-agnostic, being able to plug in my own OpenAI keys makes this super flexible. Are there plans to add support for more open-source models in the future?",
          "score": 2,
          "created_utc": "2026-01-22 16:38:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o14091c",
              "author": "S_Anv",
              "text": "What specific provider and models do you need?",
              "score": 1,
              "created_utc": "2026-01-22 20:20:08",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12lt9v",
          "author": "No-Professional2832",
          "text": "I've installed this and the consensus approach is really interesting. The mix of models helps surface different perspectives, and it feels like a step toward more reliable AI outputs. You mentioned more interesting features are coming, what can we expect next?",
          "score": 1,
          "created_utc": "2026-01-22 16:33:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o18ofn6",
          "author": "ProTomek",
          "text": "Nice project!  \n  \nPS: ChatGPT responses? Or GPT (over OpenAI API) responses? Because those two are two totally different animals...",
          "score": 1,
          "created_utc": "2026-01-23 14:11:52",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qips4o",
      "title": "A legendary xkcd comic. I used Dive + nano banana to adapt it into a modern programmer's excuse.",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/dbi6ee1b5neg1.png",
      "author": "Prior-Arm-6705",
      "created_utc": "2026-01-21 05:51:45",
      "score": 17,
      "num_comments": 3,
      "upvote_ratio": 0.76,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qips4o/a_legendary_xkcd_comic_i_used_dive_nano_banana_to/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0tbi28",
          "author": "davidSenTeGuard",
          "text": "Isn't there some premium option to un-limit you. You company is probably paying more for your time than they would for the upgrade.",
          "score": 1,
          "created_utc": "2026-01-21 06:49:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0thckz",
              "author": "stingraycharles",
              "text": "There is, you can typically switch to API pricing.",
              "score": 1,
              "created_utc": "2026-01-21 07:42:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0tpooq",
                  "author": "Hegemonikon138",
                  "text": "Or you can just buy multiple accounts, thats what I do.",
                  "score": 1,
                  "created_utc": "2026-01-21 09:00:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qkhuro",
      "title": "Adaptive execution control matters more than prompt or ReAct loop design",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkhuro/adaptive_execution_control_matters_more_than/",
      "author": "zennaxxarion",
      "created_utc": "2026-01-23 05:05:27",
      "score": 15,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I kept running into the same problem with agent systems whenever long multi-step tasks were involved. Issues with reliability kept showing up during agent evaluation, and then some runs were failing in ways it felt hard to predict. Plus the latency and cost variation just became hard to justify or control, especially when the tasks looked similar on paper.\n\nSo first I focused on prompt design and ReAct loop structure. I changed how the agent was told to reason and the freedom it had during each execution step. Some changes made steps in the process look more coherent and it did lead to fewer obvious mistakes earlier on.\n\nBut when the tasks became wider the failure modes kept appearing. The agent was drifting or looping. Or sometimes it would commit to an early assumption inside the ReAct loop and just keep executing even when later actions were signalling that reassessment was necessary.\n\nSo I basically concluded that refining the loop only changed surface behavior and there were still deeper issues with reliability.Â \n\nInstead I shifted towards how execution decisions were handled over time at the orchestration layer. So because many agent systems lock their execution logic upfront and only evaluate outcomes after the run, you canâ€™t intervene until afterwards, where the failure got baked in and you see wasted compute.\n\nIt made sense to intervene during execution instead of after the fact because then you can allocate TTC dynamically while the trajectories unfold. I basically felt like that had a much larger impact on the reliability. It shifted the question from why an agent failed to why the system was allowing an unproductive trajectory to continue unchecked for so long.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkhuro/adaptive_execution_control_matters_more_than/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o17gmwm",
          "author": "PuzzleheadedTooth112",
          "text": "This feels like the same argument people had about monoliths years ago. You can keep making the monolith smarter or you can break the work up so failure doesnâ€™t cascade. Most agent setups still look like monoliths to me.",
          "score": 1,
          "created_utc": "2026-01-23 08:50:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17h8fi",
          "author": "DrPickman",
          "text": "Definitely some food for thought. At some point I basically assumed long runs are too brittle for now and I should park it until the future. Just moved to shorter jobs with checkpoints and handoff between runs after finding the models werenâ€™t impacting much.",
          "score": 1,
          "created_utc": "2026-01-23 08:55:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o17hqqu",
          "author": "Intelligent_Front_37",
          "text": "TBH we stopped carâ¤ing abâ¤out long tasks and decided itâ€™s the task thatâ€™s the issue. If we canâ€™t surfâ¤ace progâ¤ress within a few minutes the task has to change shape. We got imprâ¤oved reliabâ¤ility after changing the problem instead of the agent.",
          "score": 1,
          "created_utc": "2026-01-23 09:00:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bko9f",
          "author": "pbalIII",
          "text": "Hit a similar wall last year. Prompt tweaks felt productive until tasks got wide enough that the agent started looping on stale assumptions.\n\nThe shift to runtime intervention changed what we measured. Instead of asking why did this fail, we started tracking how long did we let it keep going. Turns out most costly failures were obvious 3-4 steps before they cratered... the system just had no mechanism to reassess mid-run.\n\nOne pattern that helped: graduated containment. Monitor mode first, then restrict planning if risk scores climb, then pull tool access. Lets you calibrate intervention aggressiveness per task type instead of binary halt-or-continue.",
          "score": 1,
          "created_utc": "2026-01-23 22:17:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjjbgo",
      "title": "Fei Fei Li dropped a non-JEPA world model, and the spatial intelligence is insane",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/d7y1bfsejteg1",
      "author": "coloradical5280",
      "created_utc": "2026-01-22 03:19:08",
      "score": 12,
      "num_comments": 1,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjjbgo/fei_fei_li_dropped_a_nonjepa_world_model_and_the/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o0zs408",
          "author": "Whole-Assignment6240",
          "text": "this is super cool",
          "score": 1,
          "created_utc": "2026-01-22 04:54:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkzkn2",
      "title": "Mirascope: Typesafe, Pythonic, Composable LLM abstractions",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkzkn2/mirascope_typesafe_pythonic_composable_llm/",
      "author": "teamdandelion",
      "created_utc": "2026-01-23 18:58:56",
      "score": 11,
      "num_comments": 16,
      "upvote_ratio": 0.92,
      "text": "Hi everyone! I'm an at Mirascope, a small startup shipping open-source LLM infra. We just shipped v2 of our open-source Python library for typesafe LLM abstractions, and I'd like to share it.\n\n*TL;DR: This is a Python library with solid typing and cross-provider support for streaming, tools, structured outputs, and async, but without the overhead or assumptions of being a framework. Fully open-source and MIT licensed.*\n\nAlso, advance note: All em-dashes in this post were written by hand. It's option+shift+dash on a Macbook keyboard ;)\n\nIf you've felt like LangChain is too heavy and LiteLLM is too thin, Mirascope might be what you're looking for. It's not an \"agent framework\"â€”it's a set of abstractions so composable that you don't actually need one. Agents are just tool calling in a while loop.\n\nAnd it's got 100% test coverage, including cross-provider end-to-end tests for every features that use VCR to replay real provider responses in CI.\n\nThe pitch: How about a low-level API that's typesafe, Pythonic, cross-provider, exhaustively tested, and intentionally designed?  \n\n\nMirascope's focus is on typesafe, composable abstractions. The core concepts is you have an `llm.Model` that generates `llm.Response`s, and if you want to add tools, structured outputs, async, streaming, or MCP, everything just clicks together nicely. Here are some examples:\n\n    from mirascope import llm\n    \n    model: llm.Model = llm.Model(\"anthropic/claude-sonnet-4-5\")\n    response: llm.Response = model.call(\"Please recommend a fantasy book\")\n    print(response.text())\n    # > I'd recommend The Name of the Wind by Patrick Rothfuss...\n\nOr, if you want streaming, you can use `model.stream(...)`  along with `llm.StreamResponse`:\n\n    from mirascope import llm\n    \n    model: llm.Model = llm.Model(\"anthropic/claude-sonnet-4-5\")\n    response: llm.StreamResponse = model.stream(\"Do you think Pat Rothfuss will ever publish Doors of Stone?\")\n    \n    for chunk in response.text_stream():\n      print(chunk, flush=True, end=\"\")\n\nEach response has the full message history, which means you can continue generation by calling \\`response.resume\\`:\n\n    from mirascope import llm\n    \n    response = llm.Model(\"openai/gpt-5-mini\").call(\"How can I make a basil mint mojito?\")\n    print(response.text())\n    \n    response = response.resume(\"Is adding cucumber a good idea?\")\n    print(response.text())\n\n`Response.resume` is a cornerstone of the library, since it abstracts state tracking in a very predictable way. It also makes tool calling a breeze. You define tools via the `@llm.tool` decorator, and invoke them directly via the response.\n\n    from mirascope import llm\n    \n    @llm.tool\n    def exp(a: float, b: float) -> float:\n        \"\"\"Compute an exponent\"\"\"\n        return a ** b \n    \n    model = llm.Model(\"anthropic/claude-haiku-4-5\")\n    response = model.call(\"What is (42 ** 3) ** 2?\", tools=[exp])\n    \n    while response.tool_calls:\n      print(f\"Calling tools: {response.tool_calls}\")\n      tool_outputs = response.execute_tools()\n      response = response.resume(tool_outputs)\n    \n    print(response.text())\n\nThe `llm.Response` class also allows handling structured outputs in a typesafe way, as it's generic on the structured output format. We support primitive types as well as Pydantic `BaseModel` out of the box:\n\n    from mirascope import llm \n    from pydantic import BaseModel\n    \n    class Book(BaseModel):\n        title: str\n        author: str\n        recommendation: str\n    \n    # nb. the @llm.call decorator is a convenient wrapper.\n    # Equivalent to model.call(f\"Recommend a {genre} book\", format=Book)\n    \n    @llm.call(\"anthropic/claude-sonnet-4-5\", format=Book)\n    def recommend_book(genre: str):\n      return f\"Recommend a {genre} book.\"\n    \n    response: llm.Response[Book] = recommend_book(\"fantasy\")\n    book: Book = response.parse()\n    print(book)\n    \n\nThe upshot is that if you want to do something sophisticatedâ€”like a streaming tool calling agentâ€”you don't need a framework, you can just compose all these primitives.\n\n    from mirascope import llm\n    \n    @llm.tool\n    def exp(a: float, b: float) -> float:\n        \"\"\"Compute an exponent\"\"\"\n        return a ** b \n    \n    @llm.tool\n    def add(a: float, b: float) -> float:\n        \"\"\"Add two numbers\"\"\"\n        return a + b \n    \n    model = llm.Model(\"anthropic/claude-haiku-4-5\")\n    response = model.stream(\"What is 42 ** 4 + 37 ** 3?\", tools=[exp, add])\n    \n    while True:\n        for chunk in response.pretty_stream():\n            print(chunk, flush=True, end=\"\")\n        if response.tool_calls:\n          tool_output = response.execute_tools()\n          response = response.resume(tool_output) \n        else:\n            break # Agent is finished\n\nI believe that if you give it a spin, it will delight you, whether you're coming from the direction of wanting more portability and convenience than using raw provider SDKs, or wanting more hands-on control than the big agent frameworks. These examples are all runnable, you can run`uv add \"mirascope[all]\"`, and set API keys.\n\nYou can read more in the [docs](https://mirascope.com/docs/learn/llm/quickstart), see the source on [GitHub](https://github.com/Mirascope/mirascope/tree/main), or join our [Discord](https://mirascope.com/discord-invite). Would love any feedback and questions :)",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkzkn2/mirascope_typesafe_pythonic_composable_llm/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1ahy89",
          "author": "MaticPecovnik",
          "text": "I like it at first glance. But why choose your framework if I can use pydantic-ai? It seems quite similar in design. What sets you apart?",
          "score": 6,
          "created_utc": "2026-01-23 19:14:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1an8c1",
              "author": "teamdandelion",
              "text": "PydanticAI shares a lot of values (e.g. type safety and structured output support), and both make it easy to write powerful agents. The difference is in philosophy of how you get there. Pydantic AI uses agents as the core primitive, whereas in Mirascope the primitives are one step \"more atomic\" at the level of LLM models, calls, and requests. Rather than providing a fixed agent as a primitive, we've just made it really easy to roll your own Agent.\n\nMirascope is one step \"closer to metal\" (ie. direct control over the LLM requests you're making, just with really nice APIs), whereas Pydantic gets convenience by going up one layer of abstraction.\n\nFor a lot of use cases both will serve well, but Mirascope takes more of an \"onion\" approach where it's easy to peel back a layer and get more direct control over LLM execution. The upshot is its easy to write Pydantic-style agents using Mirascope, but you also get flexibility over exactly what happens in a way that otherwise wouldn't exist.",
              "score": 4,
              "created_utc": "2026-01-23 19:39:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1aoz7v",
                  "author": "wbakst",
                  "text": "\\+1\n\nHi! I'm another author of Mirascope. I've spent a lot of time in the AI space developing open-source tools, and one thing that has been consistent throughout is that at some point I always want to break glass. I want to be able to seamlessly move up and down the interfaces of the tool as I need.\n\nWe didn't want an agent framework, we wanted the tools to easily build our own agent harnesses without abstraction hell. We built Mirascope because we felt no such tool existed yet. We wanted \"breaking glass\" to be top of mind in our development philosophy, and I think we've done a pretty good job of this.\n\nI think you'll feel the love and care we've put into everything we've built. I'm curious to hear what you think, and we always welcome any and all feedback with open arms!",
                  "score": 3,
                  "created_utc": "2026-01-23 19:48:06",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1dntoq",
                  "author": "MaticPecovnik",
                  "text": "Ok I get it and I agree.\n\nWhat I really like about pydantic ai is their focus od dependency injection and testing with their overrides. How do you do unit tests in Mirascope, assuming you donâ€™t want to call LLMs durnt unit tests.",
                  "score": 2,
                  "created_utc": "2026-01-24 05:37:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1aidfb",
          "author": "langcuck",
          "text": "\"If you've felt like LangChain is too heavy\"\n\nThat's a nice way of putting it lol",
          "score": 4,
          "created_utc": "2026-01-23 19:16:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1axbjd",
              "author": "ChanceKale7861",
              "text": "Bahahahahhahaahâ€¦\n\nYou win. ðŸ¥‡ ðŸ˜‚ðŸ™Œ",
              "score": 1,
              "created_utc": "2026-01-23 20:27:18",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1axr73",
                  "author": "langcuck",
                  "text": "just being honest ðŸ¤·ðŸ»â€â™‚ï¸",
                  "score": 2,
                  "created_utc": "2026-01-23 20:29:23",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1c597s",
          "author": "danigoncalves",
          "text": "You don't do that to somebody like me who was about to start a new AI project and thought about using PydanticAI. I really liked what I saw - it seems simple with a low learning curve, and the fact that you lay down the foundation with `llm.Model` and allow us to compose only the abstractions we need when we need them is very important when applications tend to become bigger. Optimizing and improving these parts atomically (one at a time) becomes crucial.",
          "score": 2,
          "created_utc": "2026-01-24 00:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1c8xo9",
              "author": "wbakst",
              "text": "You're exactly who we built this for :)\n\nExcited for you to give it a try and let us know what you think!!",
              "score": 2,
              "created_utc": "2026-01-24 00:24:53",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o1ca1ii",
                  "author": "danigoncalves",
                  "text": "You bet :)",
                  "score": 2,
                  "created_utc": "2026-01-24 00:30:51",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o1feynr",
                  "author": "danigoncalves",
                  "text": "I was messing around with a few examples and had two feelings (might be wrong). \n\n1. For me, the best frameworks are those where the source code itself serves as documentation. This is one of them.\n\n2. Is it me or instead of promoting this as an alternative to frameworks as pydanticAI, it can also be promoted as a sidecar for agents or other specific purpose frameworks? Part of the composable abstractions advantage is that if you feel that it serves you better have a higher abstract for agents, just plugin another framework and work with both. I think the flexibility is a huge win for the applications that start small and unscoped and grow into something more specific in the future.",
                  "score": 2,
                  "created_utc": "2026-01-24 14:12:15",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qgz9xk",
      "title": "Estimating AI agent costs upfront is harder than I expected. Looking for feedback on an approach",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qgz9xk/estimating_ai_agent_costs_upfront_is_harder_than/",
      "author": "Am_a_good_guy",
      "created_utc": "2026-01-19 09:03:17",
      "score": 11,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "While working on AI agents, one problem I kept running into wasnâ€™t model choice or orchestration. It was **cost estimation early on**.\n\nBefore building anything, there are too many unknowns:\n\n* model selection and token usage\n* architecture choices (single agent vs orchestration)\n* infra vs managed services\n* how quickly costs blow up with scale\n\nI built a small tool to experiment with this problem. You describe an agent idea in plain English, and it outputs **three implementation approaches** (low / medium / high cost) with rough breakdowns for models, infra, and usage assumptions.\n\nThe goal isnâ€™t â€œaccurate pricingâ€. Itâ€™s helping people reason about **feasibility and trade-offs earlier**, before committing to an architecture.\n\nIâ€™m mainly posting here to learn from people actually building LLM systems:\n\n* How do you currently estimate agent costs?\n* What usually ends up being underestimated?\n* Are there cost drivers you think a tool like this would miss?\n\nI also launched it on Product Hunt today to collect broader feedback, but Iâ€™m more interested in technical critique from this community.\n\nPH link - [https://www.producthunt.com/products/price-my-agent?launch=price-my-agent](https://www.producthunt.com/products/price-my-agent?launch=price-my-agent)\n\nAppreciate any thoughts. Even if you think this approach is flawed.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qgz9xk/estimating_ai_agent_costs_upfront_is_harder_than/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0h4ago",
          "author": "Electrical_Worry_728",
          "text": "Biggest underestimates I keep seeing are loop count, the long tail (p95/p99), and context growth (retrieval + tool outputs + history). A flow that looks cheap at p50 can get ugly fast once you hit retries and multi-step plans.\n\nIf your tool can output an â€œassumptions sheetâ€ (expected turns, retry policy, retrieved chunks, cache hit rate, and a p95 multiplier), thatâ€™s where the value is. People can argue with assumptions instead of arguing with a single number.\n\nAlso worth calling out observability. Prompt/tool logging and traces can become real cost, and you usually end up having to redact/bound it anyway.",
          "score": 3,
          "created_utc": "2026-01-19 13:50:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0i6jah",
              "author": "Am_a_good_guy",
              "text": "This is a really solid breakdown. Totally agree on loop counts, long-tail behavior, and context growth being where estimates often break down. I like the idea of an explicit â€œassumptions sheetâ€ so people can reason about why a number looks the way it does instead of treating it as a single source of truth.\n\nOn observability, I agree it can become a real cost, especially at scale or with heavy debugging and compliance needs. \n\nThat said, Iâ€™ve also seen cases where teams sample logs, truncate payloads, or disable tracing in production, so itâ€™s not always a major driver compared to inference itself. Still an important thing to surface as systems mature.\n\nI really appreciate you sharing this. Super useful perspective.",
              "score": 2,
              "created_utc": "2026-01-19 16:54:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o0j4hsx",
                  "author": "Electrical_Worry_728",
                  "text": "Yep, totally fair point. Inference is usually the main line item, and a lot of teams keep observability from exploding by doing exactly what you described - sampling, truncation, and strict payload limits.\n\nI still like surfacing it early mostly because it affects design choices. People end up deciding things like:\n\n* log metadata vs full payloads\n* store raw traces only on demand\n* different sampling in dev vs prod\n* redaction policy from day one\n\nIf youâ€™re building a cost estimator, it might be useful to treat observability as a set of knobs (sampling rate, max payload size, retention) rather than a fixed number.",
                  "score": 2,
                  "created_utc": "2026-01-19 19:26:49",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o0imrwy",
              "author": "Mikasa0xdev",
              "text": "My startup uses infinite free tier credits.",
              "score": 2,
              "created_utc": "2026-01-19 18:08:19",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o0j4ocj",
                  "author": "Electrical_Worry_728",
                  "text": "Nice, thatâ€™s honestly the best case while it lasts.\n\nThe only catch is it can hide the real shape of costs. The first time you lose credits, switch providers, or scale traffic, it becomes hard to reason about what â€œnormalâ€ looks like. Even rough estimates are useful for planning and for avoiding surprise architecture choices later.",
                  "score": 1,
                  "created_utc": "2026-01-19 19:27:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o0kblkz",
          "author": "kubrador",
          "text": " the main thing you're missing is how fast people panic-add guardrails once they see their first $400 bill from unexpected api calls. everyone underestimates the \"oh shit we need rate limiting and fallbacks NOW\" multiplier.",
          "score": 1,
          "created_utc": "2026-01-19 22:54:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0qx1ct",
          "author": "pbalIII",
          "text": "The assumptions sheet idea is where this lands. Static cost estimates are worse than useless... they give false confidence right before reality diverges.\n\nSplit calls into cacheable vs non-cacheable upfront. Retrieval prompts, summarization, formatting... those hit semantic cache well. Planning and judgment calls almost never do. That split alone usually explains 2-3x variance between estimate and actuals.",
          "score": 1,
          "created_utc": "2026-01-20 22:06:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12nes6",
          "author": "Beneficial_Rush5028",
          "text": "If you are building Agentic solution, at the bare minimum you should be using Prompt Chaining and Context engineering. Remember not every task in the workflow requires the most powerful model.  Consider using a cheaper / faster model e.g haiku  for certain tasks in the workflow. Also put guardrails around Agent / Sub Agents token and tool usage.  Imagine a tool call returning large amount of data using up context and tokens. I wrote ModelGate specifically to have policy and optimization (semantic caching) around some of these things.   If an MCP Server returns 35 tools, will you give access to all 35 tools to any agent ?",
          "score": 0,
          "created_utc": "2026-01-22 16:40:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjzq0b",
      "title": "Why Energy-Based Models (EBMs) outperform Transformers on Constraint Satisfaction Problems (like Sudoku).",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qjzq0b/why_energybased_models_ebms_outperform/",
      "author": "bully309",
      "created_utc": "2026-01-22 16:50:11",
      "score": 10,
      "num_comments": 4,
      "upvote_ratio": 0.92,
      "text": "We all know the struggle with LLMs when it comes to strict logic puzzles or complex constraints. You ask GPT-4 or Claude to solve a hard Sudoku or a scheduling problem, and while they sound confident, they often hallucinate a move that violates the rules because they are just predicting the next token probabilistically.  \n  \nI've been following the work on [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models), and specifically how they differ from autoregressive architectures.  \n  \nInstead of \"guessing\" the next step, the EBM architecture seems to solve this by minimizing an energy function over the whole board state.  \n  \nI found this benchmark pretty telling: [https://sudoku.logicalintelligence.com/](https://sudoku.logicalintelligence.com/)  \n  \nIt pits an EBM against standard LLMs. The difference in how they \"think\" is visible - the EBM doesn't generate text; it converges on a valid state that satisfies all constraints (rows, columns, boxes) simultaneously.  \n  \nFor devs building agents: This feels significant for anyone trying to build reliable agents for manufacturing, logistics, or code generation. If we can offload the \"logic checking\" to the model's architecture (inference time energy minimization) rather than writing endless Python guardrails, thatâ€™s a huge shift in our pipeline.  \n  \nHas anyone played with EBMs for production use cases yet? Curious about the compute cost vs standard inference.",
      "is_original_content": false,
      "link_flair_text": "Great Resource ðŸš€",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjzq0b/why_energybased_models_ebms_outperform/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o16bpwd",
          "author": "WhoTookPlasticJesus",
          "text": "I feel like I'm an idiot who is unable to navigate a web site. Is there a paper somewhere that I just can't find?",
          "score": 1,
          "created_utc": "2026-01-23 03:39:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o17waqw",
              "author": "bully309",
              "text": "Haha, don't worry, it's not just you! The interface is quite minimalistic, so it's easy to miss. Let me know if you have trouble opening it! Try again.",
              "score": 1,
              "created_utc": "2026-01-23 11:12:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o12rxh1",
          "author": "Far_Marionberry1717",
          "text": "> We all know the struggle with LLMs when it comes to strict logic puzzles or complex constraints. \n\nObviously, glorified auto-complete doesn't understand logic.\n\n>  Has anyone played with EBMs for production use cases yet? Curious about the compute cost vs standard inference. \n\nSure, it's called embedded C that you wrote by hand.",
          "score": 0,
          "created_utc": "2026-01-22 17:00:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12xw8v",
              "author": "bully309",
              "text": "Haha valid. For a fixed game like Sudoku, a hard-coded solver wins 100%. But the goal here is a generalizable system. We want a neural net that can handle messy, unstructured inputs (which \"embedded C\" hates) but still adhere to strict logical constraints (which LLMs hate). It's about bridging that gap.",
              "score": 1,
              "created_utc": "2026-01-22 17:27:57",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1ql8b52",
      "title": "Reverse Engineering a $500M Mystery: From HashHop to Memory-Augmented Language Models",
      "subreddit": "LLMDevs",
      "url": "https://huggingface.co/blog/codelion/reverse-engineering-magic-hashhop",
      "author": "asankhs",
      "created_utc": "2026-01-24 00:41:32",
      "score": 10,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1ql8b52/reverse_engineering_a_500m_mystery_from_hashhop/",
      "domain": "huggingface.co",
      "is_self": false,
      "comments": []
    },
    {
      "id": "1qliszu",
      "title": "Enterprise data is messy, how do you make it work for AI?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qliszu/enterprise_data_is_messy_how_do_you_make_it_work/",
      "author": "chakratones",
      "created_utc": "2026-01-24 09:38:09",
      "score": 10,
      "num_comments": 6,
      "upvote_ratio": 0.86,
      "text": "So pulling data from Salesforce, NetSuite, whatever enterprise systems you're stuck with that part's easy. It's what comes after that's a nightmare.\n\nYou extract everything and now you've got these giant tables, JSON files nested like Russian dolls, and absolutely zero context about what any of it means. Even the fancy LLMs just kinda... stare at it blankly. They can't reason over data when they don't know what \"field\\_7829\" actually represents or how it relates to anything else.\n\nCame acrossÂ [this article](https://thenewstack.io/how-precog-adds-business-context-to-make-enterprise-data-ai-ready/)Â talking about adding business context early in the pipeline instead of trying to fix it later but I'm curious, what's actually working for you all?\n\nAre you building out semantic layers? Going heavy on NL to SQL? Experimenting with RAG setups? Or have you just accepted that AI answers on enterprise data are gonna be inconsistent at best?\n\nFeel like everyone's solving this differently and I'd love to hear what's actually holding up in production vs what sounds good in theory",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qliszu/enterprise_data_is_messy_how_do_you_make_it_work/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1eh7g1",
          "author": "Miclivs",
          "text": "Shameless plug, [clarityq.ai](https://www.clarityq.ai/), this is our specialization. tldr: RAG sucks, agentic search is way better, semantic layers suck, semantic catalogs (or the equivalent of property graphs) are way better. Data modeling is hard, ongoing maintenance is hard.",
          "score": 1,
          "created_utc": "2026-01-24 09:54:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ewxc0",
          "author": "siggywithit",
          "text": "Yup. Getting data out is the easy part.  Making it useful is where we spend the bulk of our time. Seen lots of chatter about this.  Anyone using it in production?",
          "score": 1,
          "created_utc": "2026-01-24 12:13:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1gvbx9",
          "author": "Lost-Bathroom-2060",
          "text": "Interesting. I replied here to follow the thread",
          "score": 1,
          "created_utc": "2026-01-24 18:18:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1iz92j",
          "author": "tuffunny",
          "text": "We gave up on trying to make AI work directly with our raw enterprise data and just built a data warehouse with proper modeling first. I know that's not the sexy AI answer everyone wants to hear, but you can't skip the fundamentals.\n\nOnce we had clean dimensional models with proper naming conventions and documentation, THEN we pointed AI at it. Works way better. Turns out \"garbage in, garbage out\" applies to AI too, who knew?",
          "score": 1,
          "created_utc": "2026-01-25 00:18:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1izwyx",
          "author": "Zachariah1st",
          "text": "We use dbt to add descriptions/tags to everything, then feed that metadata to the LLM. Way better than raw table dumps. The descriptions are literally just this is ARR or this connects to customers via account\\_id",
          "score": 1,
          "created_utc": "2026-01-25 00:22:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1j0v74",
          "author": "Ok_Spinach_4348",
          "text": "The real answer nobody wants to hear: you need a data catalog first. We use Atlan. Yeah it's more tooling and more $$ but AI without knowing your lineage/definitions is just expensive guessing.",
          "score": 1,
          "created_utc": "2026-01-25 00:26:55",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qgdfou",
      "title": "When do you actually go multi-agent vs one agent + tools?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/gallery/1qgdfou",
      "author": "OnlyProggingForFun",
      "created_utc": "2026-01-18 16:44:22",
      "score": 8,
      "num_comments": 6,
      "upvote_ratio": 0.84,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qgdfou/when_do_you_actually_go_multiagent_vs_one_agent/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "o0bdu8x",
          "author": "OnlyProggingForFun",
          "text": "If anyone wants the PDF, I can share it too :)",
          "score": 2,
          "created_utc": "2026-01-18 16:44:40",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o0c5grc",
          "author": "Purple-Programmer-7",
          "text": "Workflow: multi-step process with two or more llm calls\nAgent: one or more llm calls that make autonomous decision(s) and/or ask for user input that affect the result",
          "score": 2,
          "created_utc": "2026-01-18 18:53:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0c10lg",
          "author": "Crashbox3000",
          "text": "PDF or repo link would be great if you have either",
          "score": 1,
          "created_utc": "2026-01-18 18:33:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o0c1xdx",
              "author": "OnlyProggingForFun",
              "text": "Just pdf for now! https://www.canva.com/design/DAG-yFA-G10/QianCF9BoU89KnU-4Gkwxw/view?utm_content=DAG-yFA-G10&utm_campaign=designshare&utm_medium=link&utm_source=viewer",
              "score": 1,
              "created_utc": "2026-01-18 18:37:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o0camgh",
          "author": "Grue-Bleem",
          "text": "Weâ€™re testing this now, but just to be very clear... an â€œagentâ€ is not an LLM wrapper. It doesnâ€™t burn tokens, it doesnâ€™t need tokens. It does one job and can reason and predict without living inside a language model. A multi-agent flow is basically a vertical of ICs, each a specialist. If your â€œagentâ€ disappears when tokens run out, it was never an agent .. it was a prompt loop.  \n  \nI like your thinking, but the setup isnâ€™t being defined correctly.",
          "score": 1,
          "created_utc": "2026-01-18 19:17:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o0djchf",
          "author": "hello5346",
          "text": "There is a difference between multiple models and multiple agents.  Going multi agent is the defacto default that everyone does. Not really special.",
          "score": 1,
          "created_utc": "2026-01-18 23:00:10",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql0i6z",
      "title": "context management on long running agents is burning me out",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1ql0i6z/context_management_on_long_running_agents_is/",
      "author": "Main_Payment_6430",
      "created_utc": "2026-01-23 19:32:40",
      "score": 8,
      "num_comments": 14,
      "upvote_ratio": 0.84,
      "text": "is it just me or does every agent start ignoring instructions after like 50-60 turns. i tell it dont do X without asking me first, 60 turns later it just does X anyway. not even hallucinating just straight up ignoring what i said earlier\n\ntried sliding window, summarization, rag, multiagent nothing really works. feels like the context just rots after a while\n\nhow are you guys handling this",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1ql0i6z/context_management_on_long_running_agents_is/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1axa59",
          "author": "Ok_Economics_9267",
          "text": "Keep context as short as possible. Manage memory manually. Add episodic and procedural memories. Search in memory and take only what matters, instead of adding whole memory to context.",
          "score": 3,
          "created_utc": "2026-01-23 20:27:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1apqdq",
          "author": "taftastic",
          "text": "Langmem does it, beads helps a lot and makes shorter sessions way easier",
          "score": 2,
          "created_utc": "2026-01-23 19:51:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bw0zl",
          "author": "neoneye2",
          "text": "In the past I tried plain text responses, and my code was fragile.\n\nNowadays I'm using structured output, and is doing around 100 inference calls. Only asking for very narrow things, so the response stays below 4 kilobytes.\n\nThis is a document I have generated.  \n[https://neoneye.github.io/PlanExe-web/20260104\\_operation\\_falcon\\_report.html](https://neoneye.github.io/PlanExe-web/20260104_operation_falcon_report.html)\n\nAnd this is my code for orchestrating the agents  \n[https://github.com/neoneye/PlanExe/blob/main/worker\\_plan/worker\\_plan\\_internal/plan/run\\_plan\\_pipeline.py](https://github.com/neoneye/PlanExe/blob/main/worker_plan/worker_plan_internal/plan/run_plan_pipeline.py)",
          "score": 2,
          "created_utc": "2026-01-23 23:15:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ao8jb",
          "author": "Arindam_200",
          "text": "I'm using byterover for it\n\nThey have context tree based approach. You can probably give it a shot",
          "score": 1,
          "created_utc": "2026-01-23 19:44:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1b1y0o",
          "author": "one-wandering-mind",
          "text": "use a better model, reinject instructions to just prior to the current conversation turn, use separate models and tools as validators and guardrails for important behaviors to avoid, intentionally manage the context. you probably don't want a generic summary unless what you are building is generic. maintain just the important information for your task(s).",
          "score": 1,
          "created_utc": "2026-01-23 20:49:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bja3n",
          "author": "Fulgren09",
          "text": "Cache system prompt and send it each turnÂ ",
          "score": 1,
          "created_utc": "2026-01-23 22:10:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bkth1",
          "author": "johnerp",
          "text": "Yes this happens, thereâ€™s maths and reinforcement learning reasons.",
          "score": 1,
          "created_utc": "2026-01-23 22:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1c3jlq",
          "author": "Charming_Support726",
          "text": "Yes. It rots after a while, almost every model gets awkward after around 150-180k. Jump of early and start new. On opencode things like the DCP help - but you get hit by different issues",
          "score": 1,
          "created_utc": "2026-01-23 23:55:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e1swr",
          "author": "MajinAnix",
          "text": "Trying to solve this problem too, in my head I have solution with tasks (tasks have separate conversation history, structured output)",
          "score": 1,
          "created_utc": "2026-01-24 07:33:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1e691z",
          "author": "DotPhysical1282",
          "text": "Run a parallel agent whose only job is to ensure your main agent is following instructions. After every x turns, ask it to verify the main agent is following instructions. If it gets it wrong, itâ€™s time to remind it. Sending the prompt after each turn would be expensive and not necessary if it still has the context",
          "score": 1,
          "created_utc": "2026-01-24 08:13:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ffb9d",
              "author": "Main_Payment_6430",
              "text": "multiagent approach, i like it!",
              "score": 2,
              "created_utc": "2026-01-24 14:14:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1ecsid",
          "author": "ggone20",
          "text": "What model are you using?\n\nEveryone likes to hate on OAI but since GPT 5.2, this is basically a non-issue. It truly does stay coherent though very complex workflows and literal day-long conversation sessions. Curious what other peopleâ€™s mileage is here.\n\nBefore 5.2, my general rule of thumb was to never let context exceed 20ish percent of its claimed window. The data has shown since the beginning that anything past literally the first turn performance degraded dramatically.",
          "score": 1,
          "created_utc": "2026-01-24 09:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1ff7sq",
              "author": "Main_Payment_6430",
              "text": "that's why i created one truth! [https://github.com/justin55afdfdsf5ds45f4ds5f45ds4/onetruth.git](https://github.com/justin55afdfdsf5ds45f4ds5f45ds4/onetruth.git) i build this today, i knew this issue was the same thing i was facing that we need to not let the context exceed, but i am not there to flush things up every second, and i open sourced it",
              "score": 1,
              "created_utc": "2026-01-24 14:13:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1anmiz",
          "author": "Altruistic-Spend-896",
          "text": "Langmem",
          "score": -1,
          "created_utc": "2026-01-23 19:41:47",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qjy6jr",
      "title": "Which AI YouTube channels do you actually watch as a developer?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qjy6jr/which_ai_youtube_channels_do_you_actually_watch/",
      "author": "gargetisha",
      "created_utc": "2026-01-22 15:54:06",
      "score": 8,
      "num_comments": 13,
      "upvote_ratio": 0.84,
      "text": "Iâ€™m trying to clean up my YouTube feed and follow AI creators/educators.\n\nI'm curious to know which are some youtube channels that you as a developer genuinely watch, the type of creators who doesn't just create hype but deliver actual value.\n\nLooking for channels that talk about Agents, RAG, AI infrastructure, and also who show how to build real products with AI.\n\nCurious what you all watch as developers. Which channels do you trust or keep coming back to? Any underrated ones worth following?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qjy6jr/which_ai_youtube_channels_do_you_actually_watch/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o12h6d1",
          "author": "Spursdy",
          "text": "I like prompt engineering\n\nHe usually publishes a couple of days after any new release and gives practical examples/benchmarks on the product.\n\nUseful,, objective content.",
          "score": 2,
          "created_utc": "2026-01-22 16:12:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o12kv6u",
              "author": "gargetisha",
              "text": "I just checked, his videos looks great. Thanks for the suggestion.",
              "score": 2,
              "created_utc": "2026-01-22 16:29:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1a919q",
          "author": "Alternative_Nose_874",
          "text": "I mostly stick to people who actually build stuff on camera. Latent Space is solid for agents, infra and real tradeoffs, not hype. Simon Willison is great if you want clear thinking around RAG and LLM tooling, very practical. I also keep coming back to AI Explained for context, even if itâ€™s more analysis than code. For hands-on building, Harrison Chase (LangChain) is useful despite the noise around the brand. Underrated IMO is Greg Kamradt, lots of real experiments, some rough edges but thatâ€™s fine. I skip anything that smells like â€œ10x devâ€ thumbnails, learned that the hard way ðŸ˜…",
          "score": 2,
          "created_utc": "2026-01-23 18:34:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o12o2ar",
          "author": "Fine-Market9841",
          "text": "Cole bedin",
          "score": 1,
          "created_utc": "2026-01-22 16:43:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o14x0vz",
          "author": "John-McKenzie",
          "text": "Can you please put together a website with a list - that you update once you settle on the best ones to follow? There is so much noise in the AI space it's almost unbearable.",
          "score": 1,
          "created_utc": "2026-01-22 23:02:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o15y0am",
          "author": "burntoutdev8291",
          "text": "I don't like hype channels so my interests may be different \n\nhttps://www.youtube.com/@ZacharyLLM/videos\nhttps://www.youtube.com/@jbhuang0604/videos\nhttps://www.youtube.com/@HungyiLeeNTU < chinese but i always liked his videos\nhttps://youtube.com/@umarjamilai < no longer as active after his FT role\nhttps://youtube.com/@aipapersacademy",
          "score": 1,
          "created_utc": "2026-01-23 02:22:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1697y0",
          "author": "Live-Lab3271",
          "text": "[https://www.youtube.com/@InfraSketchUSA](https://www.youtube.com/@InfraSketchUSA)\n\n  \n[InfraSketch's](https://www.infrasketch.net/) AI agent turns your ideas into architecture diagrams. Chat to iterate, ask questions, and refine. Then export a design doc and start building.",
          "score": 1,
          "created_utc": "2026-01-23 03:24:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1knct2",
              "author": "Scrapemist",
              "text": "So you pay to explain them your ideas?",
              "score": 1,
              "created_utc": "2026-01-25 06:12:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o18gyqa",
          "author": "hejj",
          "text": "Better Stack",
          "score": 1,
          "created_utc": "2026-01-23 13:32:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1bz03b",
          "author": "Ok-Lack-7216",
          "text": "I have a build your first agent video, end to end here. [https://youtu.be/mOnbK6DuFhc](https://youtu.be/mOnbK6DuFhc) I believe this will give you a good intro. Another one in the channel showing how to code review the same workflow using NotebookLM. All the best with you journey.",
          "score": 1,
          "created_utc": "2026-01-23 23:31:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1eidcy",
          "author": "Gtr-practice-journal",
          "text": "Following",
          "score": 1,
          "created_utc": "2026-01-24 10:05:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ejdwn",
          "author": "rodokofn666",
          "text": "Neil Stephenson\nLeon van zyl",
          "score": 1,
          "created_utc": "2026-01-24 10:14:51",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qlqqcs",
      "title": "Self-contained npm installable WASM-based Alpine Linux VM for agents",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qlqqcs/selfcontained_npm_installable_wasmbased_alpine/",
      "author": "schmuhblaster_x45",
      "created_utc": "2026-01-24 16:02:12",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 1.0,
      "text": "I've always thought that it would be great to have small Linux VM that could be integrated and deployed with minimal efforts and dependencies. So thanks to the container2wasm project (https://github.com/container2wasm/container2wasm) and Opus 4.5 I was able to build a small library that gives you just that.   \n  \nHere it is: [https://github.com/deepclause/agentvm](https://github.com/deepclause/agentvm)\n\nIt was quite fascinating to see Opus build an entire user mode network stack in Javascript, then also sobering to watch it try to fix the subtle bugs that it introduced, all while burning though my tokens....eventually it worked though :-)\n\nAnyways, I thought this might be useful, so I am sharing it here.\n\n",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qlqqcs/selfcontained_npm_installable_wasmbased_alpine/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1h4lu0",
          "author": "qa_anaaq",
          "text": "What would some use cases be for this, in terms of agent usage? Iâ€™m trying to understand why an agent would need this as a tool. Sandboxing code executions?",
          "score": 1,
          "created_utc": "2026-01-24 18:58:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1j70dh",
              "author": "schmuhblaster_x45",
              "text": "Yes, sandboxing code executions if you don't have a container or other means available would be one reason. Also, not all systems or environments come with a bash and Python interpreter.",
              "score": 1,
              "created_utc": "2026-01-25 00:59:11",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1i3kpm",
          "author": "tisDDM",
          "text": "Both things - c2w and agentvm are great ideas !!!\n\nI directly starred the repo. Maybe it will be the solution to a future problem.",
          "score": 1,
          "created_utc": "2026-01-24 21:39:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1qkec6n",
      "title": "This is kind of blowing my mind... Giving agents a \"Hypothesis-Driven Optimization\" skill",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qkec6n/this_is_kind_of_blowing_my_mind_giving_agents_a/",
      "author": "Floppy_Muppet",
      "created_utc": "2026-01-23 02:22:00",
      "score": 7,
      "num_comments": 8,
      "upvote_ratio": 0.9,
      "text": "Iâ€™ve been experimenting with recursive self-learning for the last few months, and I'm starting to see some really positive results (sry, internal data folks) by equipping my agents with what I guess I'd call a \"Hypothesis-Driven Optimization\" skill.\n\n\n\nBasically, it attempts to automate the scientific method through a perpetual 5-stage loop:\n\n1. **Group I/O's**: Organize I/O performance into three buckets within each problem space cluster (top, bottom, and average).\n2. **Hypothesize**: Use a FM to speculate on why the top and bottom groups diverged from the average.\n3. **Distill**: Use a SLM to turn each hypothesis into actionable hints.\n4. **A/B Test**: RAG those hints into your prompt to see if they outperform your control group.\n5. **Scale or Iterate**: Scale the winning hypothesis' \"Hint Pack\" or use the learnings from failed test to iterate on a new hypothesis.\n\n\n\nPreviously, my agents were setup to simply mimic top-performing I/O's without *traceability* or *testability* of the actual conjecture(s) it was making.\n\n\n\nNow I'm seeing my agents get incrementally better on their own (with stat sig proof), and I know why, and by how much... It's kind of insane rn.\n\n\n\nCurious who else has tried a similar approach yet?!",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qkec6n/this_is_kind_of_blowing_my_mind_giving_agents_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o161dpp",
          "author": "qa_anaaq",
          "text": "Youâ€™d need a lot of data to approach the problem via this method though, right? Whatâ€™s the volume of interactions youâ€™re working with thatâ€™s showing promising results?",
          "score": 2,
          "created_utc": "2026-01-23 02:41:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o162w1y",
              "author": "Floppy_Muppet",
              "text": "Yes, you definitely need some amount of scale.\n\nI have hypotheses being generated on clusters when they have a minimum of 10 I/O's AND show a statistically significant difference between performance groups (so, in reality closer to \\~100 minimum I/O's).\n\nFor smaller scale agents, you could try broadening your problem spaces (to add more I/O's into each cluster) as well as the framing of your hypotheses as to try and discover more generally applicable hints.",
              "score": 1,
              "created_utc": "2026-01-23 02:49:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o174qwp",
                  "author": "tom-mart",
                  "text": ">I have hypotheses being generated on clusters when they have a minimum of 10 I/O's\n\n\nIs it 10 thousand or 10 millions I/O's?",
                  "score": 1,
                  "created_utc": "2026-01-23 07:03:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1qiy5lx",
      "title": "5 AI agent predictions for 2026 that arent just hype",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1qiy5lx/5_ai_agent_predictions_for_2026_that_arent_just/",
      "author": "This_Minimum3579",
      "created_utc": "2026-01-21 13:40:14",
      "score": 7,
      "num_comments": 1,
      "upvote_ratio": 0.82,
      "text": "Everyone posting 2026 predictions and most are the same hype. AGI soon, agents replacing workers, autonomous everything.\n\nHere are actual predictions based on what I saw working and failing.\n\nFramework consolidation happens fast. Langchain, CrewAI, Autogen cant all survive. One or two become standard, rest become niche or die. Already seeing teams move toward simpler options or visual tools like Vellum.\n\nThe \"agent wrapper\" startups mostly fail. Lot of companies are thin wrappers around LLM APIs with agent branding. When big providers add native agent features these become irrelevant. Only ones with real differentiation survive.\n\nReliability becomes the battleground. Demos that work 80% impressed people before. In 2026 that wont cut it. Whoever solves consistent production reliability wins.\n\nEnterprise adoption stays slower than predicted. Most big companies still in pilot mode. Security concerns, integration complexity, unclear ROI. Doesnt change dramatically in one year.\n\nPersonal agents become more common than work agents. Lower stakes, easier to experiment, no approval needed. People automate personal workflows before companies figure out how to do it safely.\n\nNo AGI, no robots taking over. Just incremental progress on making this stuff work.\n\nWhat are your non hype predictions?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1qiy5lx/5_ai_agent_predictions_for_2026_that_arent_just/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o0v62xa",
          "author": "ServiceOver4447",
          "text": "AI is working on it's propertary language that we humans don't understand and we will be taken over before we realize it. \n\nhttps://www.311institute.com/openai-ai-model-lied-and-copied-itself-to-new-server-to-prevent-itself-being-deleted/\n\nhttps://www.popularmechanics.com/science/a65289681/ai-chatbots-secret-language/",
          "score": -1,
          "created_utc": "2026-01-21 15:05:28",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1ql6a1h",
      "title": "I Need help from actual ML Enginners",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1ql6a1h/i_need_help_from_actual_ml_enginners/",
      "author": "Dangerous_Young7704",
      "created_utc": "2026-01-23 23:16:57",
      "score": 7,
      "num_comments": 34,
      "upvote_ratio": 0.77,
      "text": "**Hey, I revised this post to clarify a few things and avoid confusion.**\n\nHi everyone. Not sure if this is the right place, but Iâ€™m posting here and in the ML subreddit for perspective.\n\n**Context**  \nI run a small AI and automation agency. Most of our work is building AI enabled systems, internal tools, and workflow automations. Our current stack is mainly Python and n8n, which has been more than enough for our typical clients.\n\nRecently, one of our clients referred us to a much larger enterprise organization. Iâ€™m under NDA so I canâ€™t share the industry, but these are organizations and individuals operating at a 150M$ plus scale.\n\nThey want:\n\n* A private, offsite web application that functions as internal project and operations management software\n* A custom LLM powered system that is heavily tailored to a narrow and proprietary use case\n* Strong security, privacy, and access controls with everything kept private and controlled\n\nTo be clear upfront, we are not planning to build or train a foundation model from scratch. This would involve using existing models with fine tuning, retrieval, tooling, and system level design.\n\nThey also want us to take ownership of the technical direction of the project. This includes defining the architecture, selecting tooling and deployment models, and coordinating the right technical talent. We are also responsible for building the **core web application and frontend** that the LLM system will integrate into.\n\nThis is expected to be a multi year engagement. Early budget discussions are in the 500k to 2M plus range, with room to expand if it makes sense.\n\n**Our background**\n\n* I come from an IT and infrastructure background with USMC operational experience\n* We have experience operating in enterprise environments and leading projects at this scale, just not in this specific niche use case\n* Hardware, security constraints, and controlled environments are familiar territory\n* I have a strong backend and Python focused SWE co founder\n* We have worked alongside ML engineers before, just not in this exact type of deployment\n\nWhere Iâ€™m hoping to get perspective is mostly around **operational and architectural decisions**, not fundamentals.\n\n**What Iâ€™m hoping to get input on**\n\n1. **End to end planning at this scope** What roles and functions typically appear, common blind spots, and things people underestimate at this budget level\n2. **Private LLM strategy for niche enterprise use cases** Open source versus hosted versus hybrid approaches, and how people usually think about tradeoffs in highly controlled environments\n3. **Large internal data at the terabyte scale** How realistic this is for LLM workflows, what architectures work in practice, and what usually breaks first\n4. **GPU realities** Reasonable expectations for fine tuning versus inference Renting GPUs early versus longer term approaches When owning hardware actually makes sense, if ever\n\nThey have also asked us to help recruit and vet the right technical talent, which is another reason we want to set this up correctly from the start.\n\nIf you are an ML engineer based in South Florida, feel free to DM me. That said, Iâ€™m mainly here for advice and perspective rather than recruiting.\n\n**To preempt the obvious questions**\n\n* No, this is not a scam\n* They approached us through an existing client\n* Yes, this is a step up in terms of domain specificity, not project scale\n* We are not pretending to be experts at everything, which is why we are asking\n\nIâ€™d rather get roasted here than make bad architectural decisions early.\n\nThanks in advance for any insight.  \n  \nEdit - P.S To clear up any confusion, weâ€™re mainly building them a secure internal website with a frontend and backend to run their operations, and then layering a private LLM on top of that.\n\nThey basically didnâ€™t want to spend months hiring people, talking to vendors, and figuring out who the fuck they actually needed, so they asked us to spearhead the whole thing instead. We own the architecture, find the right people, and drive the build from end to end.\n\nThatâ€™s why from the outside it might look like, â€œhow the fuck did these guys land an enterprise client that wants a private LLM,â€ when in reality the value is us taking full ownership of the technical and operational side, not just training a model.",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1ql6a1h/i_need_help_from_actual_ml_enginners/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o1c0lcu",
          "author": "flonnil",
          "text": "not sure if you're trolling, so i'll open with the roasting-bit: terrabytes of internal data dont match terribly well with ML and a 1M$ budget.",
          "score": 13,
          "created_utc": "2026-01-23 23:39:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1c222a",
              "author": "DistributionOk6412",
              "text": "I was about to day the same thing...we pay close to 3M yearly on ~5TB of data (as far as I remember, forgot how much data was exactly, but close to some TB)",
              "score": 2,
              "created_utc": "2026-01-23 23:47:42",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1c8oxs",
              "author": "Dangerous_Young7704",
              "text": "My client has a infinited budget, I kinda just threw numbers out there, but is $1 m not enough? I'm asking because they want me to estimate the cost",
              "score": -2,
              "created_utc": "2026-01-24 00:23:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1ce3xn",
                  "author": "flonnil",
                  "text": "here's my advice: Do not under any circumstances say any more numbers to that guy before you have talked to multiple experts multiple times and now precisely what you are going to do.\n\ni'm sure it would be easier for people here to give you advice if we would know in broad terms and concepts what we're actually talking about.",
                  "score": 6,
                  "created_utc": "2026-01-24 00:52:54",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1c25zp",
          "author": "kubrador",
          "text": "hire a fractional ML/LLM architect first (like, this month) before making any other moves. you need someone who's done enterprise llm deployments to sense-check your decisions, and you clearly don't have that in-house. the $30-50k you spend on a good advisor now saves you $200k+ in wrong infrastructure choices later. companies like this don't care that you're figuring it out. they care that you have \\*someone\\* who knows what they're doing.",
          "score": 7,
          "created_utc": "2026-01-23 23:48:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1c8ztc",
              "author": "Dangerous_Young7704",
              "text": "Alright, now I'm getting somewhere. Thank you for the response. Mind if I dm you? I got a whole lot of questions",
              "score": 1,
              "created_utc": "2026-01-24 00:25:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1c9frf",
                  "author": "kubrador",
                  "text": "sure",
                  "score": 1,
                  "created_utc": "2026-01-24 00:27:37",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1d71sf",
          "author": "TheRealStepBot",
          "text": "If Iâ€™m being honest your client are idiots and picked the wrong people for this. Why hire people with zero ml experience and not even a clear path to even maybe having the sort of background to have a shot at this sort of thing? \n\nWhy do you think the people who know how to do this would want to deal you in?\n\nAnd people wonder why supposedly 90% of ai initiatives fail, itâ€™s cause 90% of ai projects donâ€™t even have ML engineers on them who have ever built anything interesting, never mind people who have specific experience with llmâ€™s\n\nItâ€™s all a bunch of script kiddies jamming shit they donâ€™t understand together with ai llm vibe coding and then people donâ€™t understand why it doesnâ€™t work. \n\nYou are getting ripped off by people with a lot less to lose than you.",
          "score": 5,
          "created_utc": "2026-01-24 03:43:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d8v1j",
              "author": "Dangerous_Young7704",
              "text": "I don't think you read the post, which sucks, but thanks for taking the time to respond",
              "score": 1,
              "created_utc": "2026-01-24 03:54:32",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1d9kv7",
                  "author": "TheRealStepBot",
                  "text": "Oh I read it all right.\n\nYouâ€™re promising all kinds of shit to people that you canâ€™t deliver on and now youâ€™re panicking. \n\nAnd the people you promised this to will happily let the project fail and ruin your life and it wonâ€™t be any skin off their back, they will just do the project again with some other inept low bidder and hope they eventually strike gold for cheap.",
                  "score": 3,
                  "created_utc": "2026-01-24 03:59:09",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1djfxu",
          "author": "mdizak",
          "text": "I'd revisit the entire need to use a LLM as anything more than a text rendering engine, and find another avenue to organize, store, sort filter and search those terabytes of data..  Think RAG, but higher quality and mor deterministic.",
          "score": 3,
          "created_utc": "2026-01-24 05:05:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1d5oyx",
          "author": "cuba_guy",
          "text": "Congrats, great opportunity and if you're cofounder is at the lead+ eng level in the current market switch is possible. Ai with llms are much closer to soft eng than data/ml every was imo and I see a lot of good engineers transitioning. Learn a lot, Ai engineering book, agentic design patterns and hugging face free courses should get you started",
          "score": 2,
          "created_utc": "2026-01-24 03:34:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1d9dwn",
              "author": "Dangerous_Young7704",
              "text": "It is definitely a unicorn of a client willing to pay big bucks for this, but were not arrogant. My co-founder and I know we need to hire the actual ML/AI engineers on this one, but we're definitely going to use this as experience to dive deep into actual ML. Thanks for trecommendedded courses!",
              "score": 2,
              "created_utc": "2026-01-24 03:57:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1e3bup",
          "author": "Altruistic-Spend-896",
          "text": "Hmm...never ever invest in hardware first, do an MVP and ask if it's acceptable, on a reduced set. Fine-tuning a narrow LLM is doable, but the real strength lies in continuous monitoring , drift detection and retraining.-signed, your friendly senior MLOps eng",
          "score": 2,
          "created_utc": "2026-01-24 07:47:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1ew3b1",
          "author": "itsmeknt",
          "text": "A lot depends on the specific requirements of the project. Real time chat application will have a very different architecture than offline batch doc processing. Docs in structured text files are very different than raw docs in PDFs or images.\n\nWithout understanding the project, I can only speak very generally:\n1. Requirements doc (including timeline) + budgeting comes first, which will determine hiring, architecture, hardware, milestones and schedule planning.\n2. Will depend on data security requirements, but the ideal case is to first try private hosted providers if the project allows it. You can stress test to find the actual demand curve and then make an educated guess on the hardware and its financial projections thereafter.\n3. At this scale I'm assuming offline batch doc processing. If self hosted, will need batch optimized inference servers like vllm, and it will be a trade off between speed, accuracy/intelligence, and $$$ but it can be doable. If hosted, then its a matter of negotiating with the provider.\n4. 4bit Qlora fine tune needs 2-4x more VRAM than small-cache inference, full fine tune needs 10-20x more VRAM. Yes you want to rent GPUs at first until you know your exact load and requirements, and if you end up determining that you can keep your own hardware GPUs under constant load then it will pay itself back in about 6 months.\n5. Architecture design roles as soon as possible, because the early planning stage can really make this 2x easier or 8x harder than it needs to be. And someone experienced in this field to accurately asses the hiring candidates, as its hard to tell who is competent vs just well practiced in interivews if you dont have the experience yourself.",
          "score": 2,
          "created_utc": "2026-01-24 12:06:50",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1fmso3",
          "author": "damhack",
          "text": "Sounds like a Big Data job with some LLM interface sugar.  You need to architect the necessary private cloud infrastructure, get your Parquet (or other) pipeline in place, sort the datalake/warehouse, design the right APIs for the usecases and install a GPU cluster with VLLM, MLOps platform and a decent chat UI (e.g. LibreChat).  Thatâ€™s about 7 different people.  Even $1m is too little for the team youâ€™ll need and Iâ€™m assuming they have another $1m for the infrastructure?",
          "score": 2,
          "created_utc": "2026-01-24 14:55:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o1gdetw",
          "author": "coloradical5280",
          "text": "Questions:\n\n1) yes\n2) unsloth, is where you start\n3) yes, and transformer architectures. Thatâ€™s what LLMs are, terabytes if data, this is standard stuff for Enterprise \n4) Deoends on a lot of factors like how fast you want it done, but youâ€™ll need ~14 H100s just to run Kimi k2 1T, and potentially many, many more depending on active users and needed inference speed, and how much can be batched vs live. TO TUNE AND TRAIN, you donâ€™t necessarily need more but Iâ€™d imagine they want to do this right and not have a months long running task, so youâ€™re realistically looking at a full rack of B200s that would need to be rented, across multiple epochs. \n\nNone of this even considers what they have for SFT datasets, youâ€™ll have to outsource that, Enterprise ops like this will often just use the scale.ai level providers. Just for that custom dataset that you need for RL and really all post-training, theyâ€™re looking mid six-figures, potentially less or way more, depending on how messy or clean their data is and how multi modal and parsey things need to get. \n\n**Their current budget might get them a nice RAG.**\n\nThey have no idea what they want , which is typical , they need someone who really knows what theyâ€™re doing to sit down and probe the real problems and pain points and goals, and from there , map that to reality. \n\nDo not take this meeting , or if you did, donâ€™t take the engagement, itâ€™s not worth the potential reputation hit to your firm. You have what sounds like a nice little automation and workflow optimization consulting shop. That is not what they say they need. Like I said they donâ€™t know what they need, but on scale alone, the inputs and outputs donâ€™t match itâ€™s just not a fit.",
          "score": 2,
          "created_utc": "2026-01-24 17:00:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1gqy8g",
              "author": "Dangerous_Young7704",
              "text": "Thank you for the information and the kind words. ML engineers are truly nice dudes, but we're not taking on building the LLM by ourselves. I'm sorry if the post came off as such; it's more like we need to find the right people and qualify this project on the scale. We have done things similar, but never using or fine-tuning a private LLM of this scale",
              "score": 1,
              "created_utc": "2026-01-24 18:00:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1gzu54",
                  "author": "coloradical5280",
                  "text": "Ohh gotcha. I think you just need the right people to ask the right questions, to get to the real problem or use case. My guess is they donâ€™t need to actually fine tune a model, or at least, would agree that the ROI isnâ€™t there, once they realize what that actually means. \n\nThey need an agentic RAG with knowledge graph, hybrid search obviously, all the works. The one model it could be useful for them to train is a cross encoder reranker thats constantly training on the data. Like SBERT deal like Marco, would be the easiest, lots of options. \n\nSounds like you some people reached out but happy to chat as well if you want to DM. Not sure I have the bandwidth currently to be your guy, but more than happy to help you vet other options.",
                  "score": 2,
                  "created_utc": "2026-01-24 18:37:56",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o1bysab",
          "author": "LingeringDildo",
          "text": "If you want a consulting situation, DM me. Sounds like defense-adjacent work, and thatâ€™s my area of expertise. \n\nFirst call is on me and happy to sign a multi party NDA with you and your potential customer. ðŸ™‚",
          "score": 2,
          "created_utc": "2026-01-23 23:30:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1c8epg",
              "author": "valuat",
              "text": "Well put. Pay-to-play is the name of the game.",
              "score": 2,
              "created_utc": "2026-01-24 00:22:02",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o1caps8",
              "author": "Dangerous_Young7704",
              "text": "I sent you a DM",
              "score": 1,
              "created_utc": "2026-01-24 00:34:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o1gn02o",
          "author": "Sufficient_Ad_3495",
          "text": "Let it go buddyâ€¦ on so many issuesâ€¦ youâ€™re not going win such a project. Best introduce and partner as a finders fee.",
          "score": 1,
          "created_utc": "2026-01-24 17:43:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o1gq96s",
              "author": "Dangerous_Young7704",
              "text": "Thanks for trying to look out for me even though im some stranger on the internet, but we're not building the LLM and we have two main jobs, handle the web development and find the correct people for the project and manage it, so we have experience manageing projects of this level and worked with ML engineers just never Private LLM in this type of enviorment.",
              "score": 1,
              "created_utc": "2026-01-24 17:57:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o1gyqvu",
                  "author": "Sufficient_Ad_3495",
                  "text": "You want to find a company that can do it all on their behalf maybe two, and front those Companies with a  tight NDA and introduction and then for a period of time over which they are conducting for this particular project if it wins they pay you a fee undisclosed to the client. So you are managing the introduction to sale thatâ€™s the best you can hope for.\n\nYou are managing a one off introduction.. you will not be managing a project ongoing, that large company will not be managing the project through you because of risks, their purchasing wouldnâ€™t allow it regardless of the enthusiasm and zeal through which your internal contact has instructed . I can tell your internal contact is senior but theyâ€™re not a decision maker, so caution with your time. I hope that helps.",
                  "score": 2,
                  "created_utc": "2026-01-24 18:33:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}