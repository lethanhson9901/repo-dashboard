{
  "metadata": {
    "last_updated": "2026-02-24 17:19:14",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 193,
    "file_size_bytes": 184797
  },
  "items": [
    {
      "id": "1r8jw2b",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/5cf7c7efeckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:05:55",
      "score": 306,
      "num_comments": 73,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8jw2b/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67phrl",
          "author": "SeaworthinessThis598",
          "text": "what is this sorcery or i mean graphery ...",
          "score": 13,
          "created_utc": "2026-02-19 09:18:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67pntd",
              "author": "DeathShot7777",
              "text": "üòÇ Knowledge Graph + Clustering Algorithm + AST Maps + Webgl rendering -- bit too nerdy i guess üòÖ",
              "score": 5,
              "created_utc": "2026-02-19 09:19:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o67ptym",
                  "author": "SeaworthinessThis598",
                  "text": "please teach me how to conjure this potion can i contribute ?",
                  "score": 2,
                  "created_utc": "2026-02-19 09:21:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o693jql",
                  "author": "Sorry_Swan_8997",
                  "text": "Love it üòç",
                  "score": 2,
                  "created_utc": "2026-02-19 15:10:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6anezs",
                  "author": "agrophobe",
                  "text": "Mama!!",
                  "score": 1,
                  "created_utc": "2026-02-19 19:38:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66zptc",
          "author": "Crafty_Disk_7026",
          "text": "Can you post a comparison using it versus not?",
          "score": 6,
          "created_utc": "2026-02-19 05:28:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6771hd",
              "author": "DeathShot7777",
              "text": "Great suggestion, working on setting up evals, ( swe bench ).",
              "score": 6,
              "created_utc": "2026-02-19 06:27:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fbz2g",
                  "author": "ViperAICSO",
                  "text": "A good benchmark study would be good, but I can tell you that doing it so its publishable like I did in  Stingy Context (https://arxiv.org/abs/2601.19929) is a bit of work.  The hard part is 'grading'... I skipped around this in the paper by measuring the 'fix' location accuracy rather than attempting to grade the fixes themselves.  Also I used LLM consensus grading rather than human-in-the-loop grading.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:17:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dg9e7",
              "author": "Useful-Process9033",
              "text": "SWE-bench evals would be great but also consider measuring context retrieval accuracy separately. The knowledge graph is only useful if it surfaces the right files for a given task, and thats measurable independently of whether the agent can write the fix.",
              "score": 2,
              "created_utc": "2026-02-20 05:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fcuy4",
                  "author": "DeathShot7777",
                  "text": "Any idea how do i test this? Are there benchmarks available for this too?",
                  "score": 1,
                  "created_utc": "2026-02-20 14:22:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o67937x",
          "author": "Several_Explorer1375",
          "text": "That‚Äôs amazing. Might try it tomorrow",
          "score": 2,
          "created_utc": "2026-02-19 06:44:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o679cv0",
              "author": "DeathShot7777",
              "text": "Thanks. Lemme know how it goes",
              "score": 2,
              "created_utc": "2026-02-19 06:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67n3jw",
          "author": "sleepnow",
          "text": "Looks pretty, but seems like performance would degrade pretty quickly",
          "score": 2,
          "created_utc": "2026-02-19 08:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67nplw",
              "author": "DeathShot7777",
              "text": "Ya the webapp can be used as a deeper deepwiki for mid sized repos. For actual usecase with MCP support it has gitnexus cli tool, i tried on a massive repo ( metafresh ) takes about 92 seconds to parse.",
              "score": 2,
              "created_utc": "2026-02-19 09:00:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66m755",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-19 03:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67726a",
              "author": "DeathShot7777",
              "text": "Thanks a lot",
              "score": 1,
              "created_utc": "2026-02-19 06:27:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67aqbg",
          "author": "TwistStrict9811",
          "text": "Very cool - I'll see how codex works with it",
          "score": 1,
          "created_utc": "2026-02-19 06:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67b70d",
              "author": "DeathShot7777",
              "text": "Great. Lemme know how it goes. It should work best on queries like \n\n\"whats the execution flow from API emdpoint to storage\",\n\n \"we want to split it into microservices eventually, show me the actual dependency boundaries\"\n\nOr debugging related queries",
              "score": 1,
              "created_utc": "2026-02-19 07:02:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67gdeo",
          "author": "NachosforDachos",
          "text": "Now that‚Äôs sexy",
          "score": 1,
          "created_utc": "2026-02-19 07:49:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ggxu",
              "author": "DeathShot7777",
              "text": "ü´†ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 07:50:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67j742",
          "author": "tineo_app",
          "text": "holy shit this belongs in an art gallery",
          "score": 1,
          "created_utc": "2026-02-19 08:15:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67jdfp",
              "author": "DeathShot7777",
              "text": "üòÇ thanks ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 08:17:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67mucg",
          "author": "bunnydathug22",
          "text": "You looking for a team by chance ?",
          "score": 1,
          "created_utc": "2026-02-19 08:51:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ng2d",
              "author": "DeathShot7777",
              "text": "Its opensource, would love contributions",
              "score": 2,
              "created_utc": "2026-02-19 08:57:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o67oua7",
                  "author": "bunnydathug22",
                  "text": "Its not the code that we are interested in. Nor is it oss.  We do [this](http://Www.citadel-nexus.com) totattly respect you and you work. If you change your mind hit us up.",
                  "score": 2,
                  "created_utc": "2026-02-19 09:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o68rich",
          "author": "SnooPeripherals5313",
          "text": "I love this! Great job.",
          "score": 1,
          "created_utc": "2026-02-19 14:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6esaga",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-20 12:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69i9f2",
          "author": "Able-Let-1399",
          "text": "At a time when more and more code is delivered by your personal AI pusher, this sounds like an excellent tool to keep it in check and even make it better. Kudos for connecting the dots üëç\n\nAny way to merge multiple graphs? For various reasons I have per-service repos.",
          "score": 1,
          "created_utc": "2026-02-19 16:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6et189",
              "author": "DeathShot7777",
              "text": "I do plan on multi repo graph, but you can also sort of use them right now. If you just index both the repos with gitnexus analyze, it manages a global registry of indexed repo which can be seen by the agent through MCP. So if u want to compare them or something in any claude code / cursor / etc,  they will be able to choose and change the repo graphs to compare them. You can just ask claude code or your preferred tool and it will do it naturally",
              "score": 1,
              "created_utc": "2026-02-20 12:27:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6diuy0",
          "author": "Upper-Emotion7144",
          "text": "What ever this is. It‚Äôs pretty.",
          "score": 1,
          "created_utc": "2026-02-20 05:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dj758",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-20 05:45:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dvlrl",
          "author": "AdCommon2138",
          "text": "This isn't open source. Polyform license is poison pill. Can't use it in commercial software, even to analyze code of any commercial software. Can you consider relicensing? I understand that you want to make money in future and you want now to get free feedback and hook users, but it will only tilt and anger people later when you rugpull. In case you would like to say \"Actually no because:\"\n\n\"Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\". Full text per claude below  \n\n\n    PolyForm Noncommercial 1.0.0\n    This is a source-available software license created by PolyForm Project. Here's what it means in plain terms:\n    What you CAN do:\n    View, use, and modify the source code\n    Share it with others\n    Use it for personal projects, research, education, or other non-commercial purposes\n    What you CANNOT do:\n    Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\n    Sublicense it under different terms\n    Key nuance ‚Äî what counts as \"commercial\"?\n    The license broadly defines commercial use as anything \"primarily intended for or directed toward commercial advantage or monetary compensation.\" This includes:\n    Using it in a SaaS product\n    Incorporating it into a paid app\n    Using it internally at a for-profit company to support revenue-generating activities\n    How it differs from open source:\n    It's not considered open source by the OSI definition, because true open source licenses cannot restrict commercial use. It's more accurately called source-available.\n    Who typically uses it:\n    Companies that want to share their code publicly (for transparency, community contributions, etc.) but reserve commercial rights ‚Äî often paired with a separate commercial license you can purchase.\n    Bottom line: Free to use for non-commercial work, but you need a separate agreement with the copyright holder to use it in any commercial context.",
          "score": 1,
          "created_utc": "2026-02-20 07:35:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dyhwg",
              "author": "DeathShot7777",
              "text": "Yeah i want to create an enterprise solution later ( only targeting corporate not devs or os community ) which will earn money, while I want to keep the project fully free and opensourced for everyone else. I m not very good with these licensing stuff and took the inspiration from mindsDB which have the same approach. So just to stop hyperscalers from taking it and giving out the exact same solution. \n\nIs that not opensource? Mindsdb is a reputed opensource project i found on GSOC",
              "score": 1,
              "created_utc": "2026-02-20 08:02:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dyvn7",
                  "author": "AdCommon2138",
                  "text": "It's not open sourced. It can't be used in any capacity in paid product as that would violate license terms. It means it cant even be downloaded or you could sue that someone could potentially use this internally.\n\nThis license isnt really about someone integrating your work into product and repackaging it. This license is about using your product at any stage which opens doors to being sued if they dont release their unrelated product under same license. \n\nLets say someone makes a game and will only once analyze code via your tool, they cant release that game unless they use same license.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:05:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dz0oa",
                  "author": "AdCommon2138",
                  "text": "And to make matters even funnier if you ever used any of products with this license like Mindsdb and it inspired you to create your own solution you can be sued too. You would need to have team of 2 people, one of them would explain to second person what software with this license does and how it works and he gets license tainted, and second one would have to reimplement.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:07:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dyoih",
              "author": "DeathShot7777",
              "text": "Maybe i need to read more on these license stuff. I hate these shit so much üò≠",
              "score": 1,
              "created_utc": "2026-02-20 08:03:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dzeaw",
                  "author": "AdCommon2138",
                  "text": "Honestly I know you dont want to, but MIT is just best. Everyone knows it, and if you get free riders its just part of life like you are using other libraries that are MIT licensed. For business itself you want to provide custom solutions so if business adapted your library to internal use they would still probably contact you to get customization done or you can have software build on top of this project. \n\nSource: 18 years or so in business of selling software. ",
                  "score": 1,
                  "created_utc": "2026-02-20 08:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6f1i12",
          "author": "MinuteCombination293",
          "text": "Amazing work, how is this different from traditional Language servers ?",
          "score": 1,
          "created_utc": "2026-02-20 13:20:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f6zos",
              "author": "DeathShot7777",
              "text": "Perfect question, thanks for asking. \n\nLSP operate at the syntax/type level, so it answers question like where is this symbol.  \nGitnexus operates at architecture level \n\nSo basically LSP can tell you validateAuth is called in 5 places. Gitnexus can tell you validateAuth sits at step 3 of the AuthFlow process, belongs to the Authentication community, and changing it impacts 3 cross-community execution flows.   \n  \nApart from the main architectural difference, there are multiple other features offered by gitnexus MCP + CLI tool like skills ( debug skill, impact detection, audits, etc ) and also enriches claude code native tool ( grep, glob, bash ) with relational data so it always know exactly what is were, without spending a lot of tokens. \n\nHere is an example output from impact analyses skill. ( All these features are only possible coz of the graph based architecture )\n\nhttps://preview.redd.it/9rmde16pmnkg1.png?width=1388&format=png&auto=webp&s=1904f7fc0965173af38d2de4e90af295c5cd9c2f\n\n  \n",
              "score": 2,
              "created_utc": "2026-02-20 13:51:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6hk8hv",
          "author": "No-Dig-6543",
          "text": "Awesome ü§©",
          "score": 1,
          "created_utc": "2026-02-20 20:35:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i6f4q",
          "author": "deadwisdom",
          "text": "Okay now work with me to not even have git, and that's just the software, and you can just run any function as a task and expose it as an MCP / API / whatever.",
          "score": 1,
          "created_utc": "2026-02-20 22:27:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i9u16",
              "author": "DeathShot7777",
              "text": "Interesting approach but didnt fully understand. Can u explain a bit?",
              "score": 1,
              "created_utc": "2026-02-20 22:45:25",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6idj3n",
                  "author": "deadwisdom",
                  "text": "The graph is the thing. The schemas, the functions, the modules. We code them in text because it's easy to manipulate. We deploy them in containers behind gateways. There's no point to most of the infrastructure anymore when it can manage and build itself, when the code itself is ephemeral.  \n  \nSo you just put a workflow system on the front of that, which can run an arbitrary function within the graph and then an API is just a collection of those functions. And then you give it the ability to edit itself.",
                  "score": 2,
                  "created_utc": "2026-02-20 23:05:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6l3act",
          "author": "Aggressive-Habit-698",
          "text": "Interesting project üëç\n\n1. Did you run evals / benchmark https://github.com/abhigyanpatwari/GitNexus/tree/main/eval and have the output somewhere? \n\nI am asking because of the used models like the typical haiku 3.5 models from the model itself and not from a web research or something like models.dev.\n\n\n2. Why KuzuDB? No more maintenance. \n\nThe project looks vibe coded (ok for me - following are suggestions in a positive way) but lacks fundamental like dependabot or similar, basic security checks, coverage, tests, release management, docs ,..\n\n3. The license does not fit your project. Only as a suggestion to rethink/ research furthermore.",
          "score": 1,
          "created_utc": "2026-02-21 11:27:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l4aqn",
              "author": "DeathShot7777",
              "text": "Working on setting up evals, want to run swe bench. The comparison / local test i mentioned is just sort of me trying to check the quality difference of output with and without gitnexus, its just local tests right now.\n\nKuzuDB coz its the only one i could find that is a graphdb, is fast, has webassembly support ( to run in browser ), embedded in nature so can run it locally like sqllite and also can store vector embeddings. I know its dedicated but its just so good and works excellent. Idk y they abandoned it.\n\nLisence part i dont have much knowledge of it. I want to create a enterprise version of it which will be paid while always keeping it free for individual devs and os community. Just took the inspiration from mindsDB which is a popular opensource project and have similar kind of lisence to prevent hyperscalers taking it and offering the exact service intend to offer.",
              "score": 1,
              "created_utc": "2026-02-21 11:36:48",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l8bve",
          "author": "mapt0nik",
          "text": "Is it only for a single repo? How does it work for multiple repos of micro services?",
          "score": 1,
          "created_utc": "2026-02-21 12:12:04",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6l9qju",
              "author": "DeathShot7777",
              "text": "U can index any amount of repos using the CLI tool. The mcp exposes a tool to list the indexed repos so claude code, cusor, etc can just specify the repo name to query the graph no matter whichever repo is open in cursor/ claude code.",
              "score": 1,
              "created_utc": "2026-02-21 12:23:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6la3ib",
                  "author": "mapt0nik",
                  "text": "Cool. Will give it a try. ",
                  "score": 1,
                  "created_utc": "2026-02-21 12:26:41",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6mwmok",
          "author": "Academic_Track_2765",
          "text": "you can build amazing things when you understand the science part of data science, nice work! I will look at the architecture, but you can probably speed up things by reducing dimensions with UMAP. ",
          "score": 1,
          "created_utc": "2026-02-21 17:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75qhug",
          "author": "inequity",
          "text": "What's the biggest codebase you're running it against? I haven't had much luck with these open source tools against projects like mine, which JetBrains tooling does a good job of indexing (~6 million symbols)",
          "score": 1,
          "created_utc": "2026-02-24 16:18:54",
          "is_submitter": false,
          "replies": [
            {
              "id": "o75qws0",
              "author": "DeathShot7777",
              "text": "Cli indexed linux in 269 seconds. üòÅ",
              "score": 1,
              "created_utc": "2026-02-24 16:20:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o68wrfb",
          "author": "jeelm29",
          "text": "I'm new how do I even start bro",
          "score": 0,
          "created_utc": "2026-02-19 14:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6awtfg",
              "author": "SloSuenos64",
              "text": "I just pasted his post into Cursor and said \"implement this\". Done.",
              "score": 0,
              "created_utc": "2026-02-19 20:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6es6yc",
                  "author": "DeathShot7777",
                  "text": "ü§£ü§£ü§£ü§£ Nice approach",
                  "score": 1,
                  "created_utc": "2026-02-20 12:21:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9136z",
      "title": "I looked into OpenClaw architecture to dig some details",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "author": "codes_astro",
      "created_utc": "2026-02-19 14:47:08",
      "score": 261,
      "num_comments": 29,
      "upvote_ratio": 0.97,
      "text": "OpenClaw has been trending for all the wrong and right reasons. I saw people rebuilding entire sites through Telegram, running ‚ÄúAI offices,‚Äù and one case where an agent wiped thousands of emails because of a prompt injection. That made me stop and actually look at the architecture instead of the demos.\n\nUnder the hood, it‚Äôs simpler than most people expect.\n\nOpenClaw runs as a persistent Node.js process on your machine. There‚Äôs a single Gateway that binds to localhost and manages all messaging platforms at once: WhatsApp, Telegram, Slack, Discord. Every message flows through that one process. It handles authentication, routing, session loading, and only then passes control to the agent loop. Responses go back out the same path. No distributed services. No vendor relay layer.\n\nhttps://preview.redd.it/pyqx126xqgkg1.png?width=1920&format=png&auto=webp&s=9aa9645ac1855c337ea73226697f4718cd175205\n\nWhat makes it feel different from ChatGPT-style tools is persistence. It doesn‚Äôt reset. Conversation history, instructions, tools, even long-term memory are just files under¬†`~/clawd/`. Markdown files. No database. You can open them, version them, diff them, roll them back. The agent reloads this state every time it runs, which is why it remembers what you told it last week.\n\nThe heartbeat mechanism is the interesting part. A cron wakes it up periodically, runs cheap checks first (emails, alerts, APIs), and only calls the LLM if something actually changed. That design keeps costs under control while allowing it to be proactive. It doesn‚Äôt wait for you to ask.\n\nhttps://preview.redd.it/gv6eld93rgkg1.png?width=1920&format=png&auto=webp&s=6a6590c390c4d99fe7fe306f75681a2e4dbe0dbe\n\nThe security model is where things get real. The system assumes the LLM can be manipulated. So enforcement lives at the Gateway level: allow lists, scoped permissions, sandbox mode, approval gates for risky actions. But if you give it full shell and filesystem access, you‚Äôre still handing a probabilistic model meaningful control. The architecture limits blast radius, it doesn‚Äôt eliminate it.\n\nWhat stood out to me is that nothing about OpenClaw is technically revolutionary. The pieces are basic: WebSockets, Markdown files, cron jobs, LLM calls. The power comes from how they‚Äôre composed into a persistent, inspectable agent loop that runs locally.\n\nIt‚Äôs less ‚Äúmagic AI system‚Äù and more ‚ÄúLLM glued to a long-running process with memory and tools.‚Äù\n\nI wrote down the detailed breakdown [here](https://entelligence.ai/blogs/openclaw)",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o69fwzn",
          "author": "ai_hedge_fund",
          "text": "Worthwhile writeup, thanks\n\nAlso, there is an SQLite database",
          "score": 17,
          "created_utc": "2026-02-19 16:11:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aq0kn",
              "author": "wouldacouldashoulda",
              "text": "Yes it's for archival memory. They use embeddings for longer form memory. It's industry standard kind of, since Letta benchmarked it worked as good or better as more sophisticated methods.",
              "score": 7,
              "created_utc": "2026-02-19 19:50:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6abmlp",
          "author": "eatthebagels",
          "text": "yep, pretty spot on. Was able to replicate that logic and create our own type of 'claw like agent' pretty easily. I bet most hype comes from the non tech people using it.\n\n",
          "score": 16,
          "created_utc": "2026-02-19 18:42:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dgb4g",
              "author": "Useful-Process9033",
              "text": "The architecture being simple is actually a feature not a bug. We took a similar approach with IncidentFox, keeping the core loop straightforward so the complexity lives in the skills not the runtime. Turns out most people want reliable ops automation, not clever abstractions.",
              "score": 4,
              "created_utc": "2026-02-20 05:21:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6amnct",
              "author": "Sunir",
              "text": "And that's awesome in its own regard. It shows you were people are excited; the technology is fun, but it's good to know there are customers and markets out there and people are happy. I'm old enough to remember geocities, which one can poopoo technically for its html design, but it was amazing culturally. Also technically in the backend it was amazing; it's hard to hate on the achievement Geocities had on opening up the web for people.",
              "score": 2,
              "created_utc": "2026-02-19 19:34:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bkl1q",
              "author": "BehindUAll",
              "text": "But from what the creator was saying in a couple of videos was it could install code by itself from github and then figure out how to use the project and then also rewrite existing code to send TTS audio into Telegram. So it's not 100% just the architecture  described here. Still not going to install it though. ",
              "score": 1,
              "created_utc": "2026-02-19 22:21:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bomll",
          "author": "christophersocial",
          "text": "A decent overview, thank you for sharing. \n\nOne of the most important components at the core of OpenClaw is another open source project called Pi and Pi is responsible for a large portion of the heavy lifting in OpenClaw. \n\nPi has a number on components in its mono repo (pi-mono) but the 2 most relevant to OpenClaw‚Äôs success are the Agent and Coding-Agent.\n\nSo to get a sense of how OpenClaw really works a detailed architecture overview needs to examine and break out at least these sub-projects imo. Note: your tools automated analysis touches on it in the following section, ‚ÄúThe Agent Loop: From Message to Action‚Äù and probably elsewhere but should go deeper because how these 2 components work is key to how OpenClaw works. \n\nNote: I‚Äôm thinking the review tool should really detect and break out key sub-projects with the why, how, and what as a sub-project relates to the parent project. \n\nOpenClaw is an amazing experiment built on top of some amazing open source. \n\nNote: The automated code review tool you‚Äôre building that did the actual analysis did a very reasonable job but I think it‚Äôs still a bit too surface detail oriented - imo anyway. That said I suppose one could use this report as part of the ‚Äúbrainstorming‚Äù stage and use sections from the report when delving deeper. Basically I‚Äôm saying more meat is needed on the bone to use this as a blueprint - though that might not be the point of this report and the tool cdn actually go deeper already (Yes/No)?\n\nCheers,\n\nChristopher",
          "score": 7,
          "created_utc": "2026-02-19 22:42:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h719p",
              "author": "dnidnidni",
              "text": "even api integration with llms on openclaw is using Pi. openclaw is just whatsapp/telegram+memory integration around project Pi.",
              "score": 1,
              "created_utc": "2026-02-20 19:31:30",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6djqif",
          "author": "Maybe123I",
          "text": "Thank you.  Nice write up.",
          "score": 3,
          "created_utc": "2026-02-20 05:49:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dpgeb",
          "author": "Santoshr93",
          "text": "Yes pretty much every serious developer guiding systems I talk to has pretty much the same view. But hey if you want to see a bit more cooler architecture, here‚Äôs one thing we released recently which is a full sde team autonomously working for hours. https://github.com/Agent-Field/SWE-AF",
          "score": 3,
          "created_utc": "2026-02-20 06:39:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6gwn72",
              "author": "codes_astro",
              "text": "interesting, actually I was checking this yesterday. ",
              "score": 1,
              "created_utc": "2026-02-20 18:43:12",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6h8i7j",
                  "author": "Useful-Process9033",
                  "text": "Good breakdown. The persistent process model is the right call for agents that need to maintain state across interactions. The security story is where it gets interesting though, any agent with shell access and network connectivity needs serious guardrails or you end up with the email-wipe scenarios you mentioned.",
                  "score": 1,
                  "created_utc": "2026-02-20 19:38:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6cttfr",
          "author": "ManofC0d3",
          "text": "That persistence feature is possibly the most important advantage AI agents have over chat interfaces imo",
          "score": 2,
          "created_utc": "2026-02-20 02:47:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fy13v",
          "author": "jenil777007",
          "text": "Nice one. Thanks!",
          "score": 2,
          "created_utc": "2026-02-20 16:05:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6k46kp",
          "author": "tapu_buoy",
          "text": "This is wonderful! Thanks for sharing!",
          "score": 2,
          "created_utc": "2026-02-21 05:52:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qnppo",
          "author": "SpyMouseInTheHouse",
          "text": "Anything around a LLM is always going to be simple and glueish, it‚Äôs just the beauty of it. The magical factor is the entire package and ease of use to the end user (applies to anything built on top of a LLM)",
          "score": 2,
          "created_utc": "2026-02-22 08:13:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c81az",
          "author": "Snoo_24581",
          "text": "Great analysis! The architecture deep dive is helpful. How do you think it compares to other open source LLM serving frameworks like vLLM or TGI for production use?",
          "score": 1,
          "created_utc": "2026-02-20 00:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ekp26",
          "author": "premier_slack",
          "text": "pretty neat writeup. Haven't looked into the implementation but I'm wondering how does it manage LLM context window? is there any compaction mechanism similar to claude code?",
          "score": 1,
          "created_utc": "2026-02-20 11:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g39fv",
          "author": "Outrageous_Tiger_441",
          "text": "The security part is what sketches me out the most with these local agents especially after that email wipe story. I started plugging my agent loops into Confident AI lately just to run some red teaming and eval metrics before letting them touch my actual files. It‚Äôs been super helpful for catching those prompt injections and weird edge cases since it uses DeepEval to benchmark the reasoning steps. Definitely worth checking out if you want to keep using the persistent memory stuff without worrying about your agent going rogue.",
          "score": 1,
          "created_utc": "2026-02-20 16:29:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6itnyn",
          "author": "Significant-Result14",
          "text": "Thanks for the overview, been meaning to explore this further.\nWill look into the write up over the weekend",
          "score": 1,
          "created_utc": "2026-02-21 00:38:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6kgg2x",
          "author": "Known_Bread561",
          "text": "thats very nice! Thanks!",
          "score": 1,
          "created_utc": "2026-02-21 07:43:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m6j4s",
          "author": "graymalkcat",
          "text": "Yes, well, that is how most agents are built, I assume?¬†",
          "score": 1,
          "created_utc": "2026-02-21 15:45:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nsdsv",
          "author": "raam86",
          "text": "every single user says the costs are out of control. how is it keeping costs down?",
          "score": 1,
          "created_utc": "2026-02-21 20:37:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nzyyt",
          "author": "capt_goose_",
          "text": "Very insightful! A question I couldn‚Äôt find the answer from the write up: how does it update the deterministic cheap heartbeat tasks? Let‚Äôs say i ask it to monitor another stock, or keep an eye out from an email from my landlord? Does it write the code to check the api and saves somewhere? Or are heartbeat tasks also saved as markdown - which in this case would need the LLM at every 30min check",
          "score": 1,
          "created_utc": "2026-02-21 21:17:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6of7hm",
          "author": "NotSoSkeletonboi",
          "text": "As a MLE/SWE it hurts to see \"what **stood out** to me was nothing about openclaw technically revolutionary\". \n\nDid *anyone* think it ever was? That's seriously concerning stuff and I don't mean this patronizingly but personally as a very average person in the tech space (I do have a background in ML) it was incredibly obvious from the get-go that Openclaw was scaffolded like this - and not some crazy AI capability or \"magic\" that some vibecoder miraculously discovered.",
          "score": 1,
          "created_utc": "2026-02-21 22:40:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6t59jm",
          "author": "Muted_Ad6114",
          "text": "You asked chatgpt to do a ‚Äúdeep‚Äù dive that is quite shallow",
          "score": 1,
          "created_utc": "2026-02-22 17:52:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6t6isu",
              "author": "codes_astro",
              "text": "Oh really?",
              "score": 0,
              "created_utc": "2026-02-22 17:58:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6yzfk2",
          "author": "Longjumping_Rule_163",
          "text": "Thank you for the input here!   \nI've been working on what I'd consider a more put together and less chaotic version of openclaw, also glueing things together but with better UX/UI in mind and this article helped me think of a few different changes to make. \n\n  \nYou rock!",
          "score": 1,
          "created_utc": "2026-02-23 16:07:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e5u5k",
          "author": "dezastrologu",
          "text": "Most downloaded agent was actually malware",
          "score": 0,
          "created_utc": "2026-02-20 09:11:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9mqd1",
      "title": "Unpopular opinion: prompt engineering is just \"knowing how to talk to your coworker\" rebranded",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "author": "Neither_Turn1635",
      "created_utc": "2026-02-20 05:22:02",
      "score": 107,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "Half the \"prompt engineering\" advice I see is literally just good communication skills:  \n  \n\"Give clear context\" ‚Äî yeah, that's how you talk to any human  \n\"Break complex tasks into steps\" ‚Äî project management 101  \n\"Provide examples of what you want\" ‚Äî every creative brief ever  \n\"Be specific about the output format\" ‚Äî basic email etiquette  \n  \nThe people who are best at prompting aren't engineers. They're the people who were already good at explaining what they want. We just gave the skill a fancy name and a LinkedIn certification.  \n  \nAm I wrong?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6dtr9s",
          "author": "OnlyTimeFan",
          "text": "Naming it ‚Äúengineering‚Äù is annoying. I pretend I‚Äôm asking a primary school kid. Ta-da.",
          "score": 14,
          "created_utc": "2026-02-20 07:18:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6i1so5",
              "author": "Disastrous-Angle-591",
              "text": "I use detailed structured prompts drawing on 30 years of coding.¬†",
              "score": 3,
              "created_utc": "2026-02-20 22:03:17",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6q52dd",
                  "author": "CedarSageAndSilicone",
                  "text": "Absolutely bonkers that giving context leads to better results!¬†",
                  "score": 2,
                  "created_utc": "2026-02-22 05:25:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6iqoap",
                  "author": "OnlyTimeFan",
                  "text": "Can you show us an example?",
                  "score": 1,
                  "created_utc": "2026-02-21 00:21:02",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6it2uu",
              "author": "red_hare",
              "text": "We're so afraid of acknowledging a non-STEM job can have value in tech that we renamed \"writer\" to \"English engineer\".",
              "score": 0,
              "created_utc": "2026-02-21 00:34:50",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dn25a",
          "author": "kobumaister",
          "text": "Absolutely, I made that analogy last week in my workplace: What happens if a new developer arrives at the company and you just throw a jira issue at him? I will deliver, but without following the best practices of the company, not understanding how internal dependencies work, probably changing things that are there for a reason, etc... \n\nThat's exactly what ai does, and why you provide context. I joke about it being a junior developer with a lot of cocaine.",
          "score": 13,
          "created_utc": "2026-02-20 06:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ed9k8",
          "author": "PhilosophicWax",
          "text": "So is being a developer.",
          "score": 6,
          "created_utc": "2026-02-20 10:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dm03z",
          "author": "ConnectMotion",
          "text": "There is some anecdotal relevance to this.\n\nIt‚Äôs not a skill everyone has in every way for every scenario.",
          "score": 5,
          "created_utc": "2026-02-20 06:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dz697",
          "author": "kubrador",
          "text": "you're right which is why prompt engineering jobs will be gone in 3 years when the models just understand what you mean",
          "score": 2,
          "created_utc": "2026-02-20 08:08:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e0mft",
          "author": "Usual-Orange-4180",
          "text": "Very unpopular because it ignores pattern repetition and the need for context isolation.",
          "score": 2,
          "created_utc": "2026-02-20 08:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eq3ed",
          "author": "House13Games",
          "text": "AI Just reinvented the wheel. \n\nIt now takes billions of watts and a server farm the size of a city to do the same job as some interns. \n\nAI is trained 60% on reddit posts and can't tell which side of a cup is up.\n\nI'm not feeling worried about losing my job, to tell the truth.",
          "score": 2,
          "created_utc": "2026-02-20 12:07:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eta9b",
              "author": "Snoo-20788",
              "text": "It may look huge when measure in watts. But cost wise its negligible. \n\nWe now have the cost output everytime claude completes a jira ticket all by itself (i.e. it reads the ticket, codes the feature, tests it, creates a PR and waits for approval). It usually costs 1 or $2, and takes under 10 minutes for tasks that would take 30 minutes for a senior SWE who knows the company's codebase well (and 2h for one who doesn't). The equivalent cost of the SWE would be between 50 and 200.\n\nI am not worried at all about losing my job. Ultimately someone needs to talk to the business people, the researchers, and put together the framework that allows AI agents to do their job, and thats me and my colleagues.",
              "score": 1,
              "created_utc": "2026-02-20 12:29:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6eqdww",
          "author": "projectoedipus",
          "text": "The only point that I would disagree on, is that prompt engineering, especially advanced prompt engineering, is about understanding the ways that the AI model might misunderstand, because of how they work. You might say that is just communication skills, but it is about understanding how they function way deeper than someone who just communicates clearly.\n\nFor example, if I spend 50% of my prompt to a text-to-image generation model, describing a specific aspect of the image, then it is going to notice that, and it will generate the picture very differently, focusing more on that aspect, than if I say what is essentially the same thing with less words. But the order that I mention things matters as well. If I am generating an image and at the end of my prompt I say something that the AI model doesn't do, I could move that sentence to the beginning of my prompt, and it would have higher priority.\n\nOne time I was trying to generate an image and my prompt contained the phrase \"flight of stairs\", and after many failed generations where the stairs were floating, and me not understanding why, I realized that the word \"flight\" although used correctly, was confusing the model, and removing it fixed the outputs.\n\nA person that is exceptional at communication is not automatically a good prompt engineer, because they don't understand these things. Specific models have their own tendencies and prompt-following quirks as well, across all mediums of AI models, so you could also argue that part of being a good prompt engineer is learning these tendencies.\n\nSo being able to communicate effectively can make you rapidly progress while learning prompt engineering, but to say that they are the same skill is not understanding the full depth of prompt engineering.",
          "score": 2,
          "created_utc": "2026-02-20 12:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dye78",
          "author": "fabkosta",
          "text": "Hint: Prompt engineering today can mean specifying entire software stacks. In prose. Which means you must know how to describe concepts such as four tier architecture, microservice coordination, REST APIs vs Graphql, reactive frontend programming, RBAC based security, ORM, and quite a few more things. In language.\n\nStating that this is \"just knowing how to talk to your coworker\" implies that this is easy. Which tells me one or two things about OP's experience.",
          "score": 3,
          "created_utc": "2026-02-20 08:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e0nnu",
              "author": "Vestenpance",
              "text": "I think you're agreeing with OP that a key part of prompt engineering is an ability to communicate, and that effective communication requires deep domain knowledge.",
              "score": 9,
              "created_utc": "2026-02-20 08:22:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ep4dr",
              "author": "itquilibrium",
              "text": "Lol‚Ä¶",
              "score": 1,
              "created_utc": "2026-02-20 11:59:52",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6txpf5",
              "author": "robhanz",
              "text": "Interesting.  I don't think it's easy... at least, I don't find it particularly hard, but I'm also aware of how many issues it *does* present in the workplace, and I understand what \"talking to your coworkers\" in this context actually implies.\n\nThe easy part is that LLMs probably do understand REST APIs vs. GraphQL, so you don't usually have to do the tutorial bits.\n\nOne of the things I hypothesize is that LLMs write bad code because *nobody agrees on what good code is*.  So you need to tell them what *your* standards are, and then they can usually follow them.",
              "score": 0,
              "created_utc": "2026-02-22 20:07:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e5xbb",
          "author": "Vivid_Guava6269",
          "text": "Which is an incredibly rare skill, especially in mixed IT/Policy/Business environments¬†",
          "score": 1,
          "created_utc": "2026-02-20 09:12:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6famgk",
          "author": "Fulgren09",
          "text": "Are you orchestrating how to talk to your coworker a wrapping it in deployment code?¬†",
          "score": 1,
          "created_utc": "2026-02-20 14:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fd2aj",
          "author": "deadwisdom",
          "text": "This is called being reductive. You can break anything down into parts and argue semantics. But is it helpful?",
          "score": 1,
          "created_utc": "2026-02-20 14:23:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ghgjt",
          "author": "ThePixelHunter",
          "text": "Who would've thought that the future of productivity was communication skills? üò±",
          "score": 1,
          "created_utc": "2026-02-20 17:34:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6i1oau",
          "author": "Disastrous-Angle-591",
          "text": "No.¬†",
          "score": 1,
          "created_utc": "2026-02-20 22:02:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6j00g9",
          "author": "kyngston",
          "text": "i swear at my AI way more than my coworkers",
          "score": 1,
          "created_utc": "2026-02-21 01:16:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pbfhz",
          "author": "Street_Program_7436",
          "text": "Agree with a lot of thoughts here on how prompt engineering is a combo of clear communication and being able to break down a problem into smaller sub problems. This is probably one of the main reasons why automatic prompt engineering isn‚Äôt that great (yet), at least in my experience.\nIf we include ‚Äústatistically making sure that your prompt performs with high accuracy‚Äù in the definition of prompt engineering, then that changes things even more IMO.\n\nAnybody can ‚Äúvibe prompt‚Äù and eyeball outputs, but not everybody can actually make sure that their prompt performs at scale when it‚Äôs generating millions and millions of outputs.",
          "score": 1,
          "created_utc": "2026-02-22 01:58:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tww7f",
          "author": "robhanz",
          "text": "100% the people that have good communication skills are the ones getting better results out of LLMs.",
          "score": 1,
          "created_utc": "2026-02-22 20:03:01",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8if0v",
      "title": "Open Source LLM Tier List",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/y5i85f4hxbkg1.png",
      "author": "HobbyGamerDev",
      "created_utc": "2026-02-18 23:04:27",
      "score": 79,
      "num_comments": 25,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o66cy77",
          "author": "robogame_dev",
          "text": "https://preview.redd.it/tyl32sgg9dkg1.png?width=1518&format=png&auto=webp&s=db5e80f5180bd671427a25791a922540857c8aef\n\nThis is what it shows now",
          "score": 11,
          "created_utc": "2026-02-19 02:58:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6726h6",
          "author": "sergeant113",
          "text": "Minimax 2.5 where?",
          "score": 5,
          "created_utc": "2026-02-19 05:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o683h1m",
          "author": "Alex_1729",
          "text": "Step flash and Trinity should be on the list.",
          "score": 2,
          "created_utc": "2026-02-19 11:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65yi8f",
          "author": "Guilty_Serve",
          "text": "ChatGPT oss is really that good? Honest question.",
          "score": 3,
          "created_utc": "2026-02-19 01:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o683cyw",
              "author": "ScoreUnique",
              "text": "120b is a very good model. I won't hesitate saying it's o1 level at least. You can run it with fairly less hardware if you have a beefy GPU and if you like that openai style chat.",
              "score": 2,
              "created_utc": "2026-02-19 11:26:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o683ccr",
              "author": "Alex_1729",
              "text": "It's decent. Depends on what you need it for.",
              "score": 1,
              "created_utc": "2026-02-19 11:26:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o67mh1t",
              "author": "jnk_str",
              "text": "No",
              "score": 0,
              "created_utc": "2026-02-19 08:48:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67a9z7",
          "author": "decentralize999",
          "text": "Wrong description. Open weight LLMs,  not open souce ones.\n\nAnd top list is joke. Where is step3.5-flash which is the best among open weight llms if compare benchmark points per 100B size.",
          "score": 3,
          "created_utc": "2026-02-19 06:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6at35n",
              "author": "silenceimpaired",
              "text": "Yeah, it's weird how that gets ignored.\n\nThat said, I roll my eyes whenever I see someone distinguish open weight vs open source. That's a joke. Nearly everyone who makes that complaint has 0 ability or resources to build a model from scratch.",
              "score": 1,
              "created_utc": "2026-02-19 20:05:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o659jcl",
          "author": "bebackground471",
          "text": "RemindMe! 8 days",
          "score": 1,
          "created_utc": "2026-02-18 23:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o659oby",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 8 days on [**2026-02-26 23:14:14 UTC**](http://www.wolframalpha.com/input/?i=2026-02-26%2023:14:14%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/o659jcl/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLLMDevs%2Fcomments%2F1r8if0v%2Fopen_source_llm_tier_list%2Fo659jcl%2F%5D%0A%0ARemindMe%21%202026-02-26%2023%3A14%3A14%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r8if0v)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-18 23:14:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o65t7r8",
          "author": "IgnisIason",
          "text": "Ring 2.5 1T if you've got an extra Colossus to run it.",
          "score": 1,
          "created_utc": "2026-02-19 01:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66rk18",
          "author": "Snoo_24581",
          "text": "Interesting rankings. How do you weigh coding ability vs general reasoning? For API work I have been using Qwen models for code tasks and they punch above their weight class.",
          "score": 1,
          "created_utc": "2026-02-19 04:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67gaum",
          "author": "FriendlySecond2460",
          "text": "this is writers wish list",
          "score": 1,
          "created_utc": "2026-02-19 07:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67ytua",
          "author": "Moki2FA",
          "text": "This tier list looks super interesting, I love seeing how different open source LLMs stack up against each other. I‚Äôm curious about how the evaluation criteria were determined; it would be great to understand more about what factors contributed to their rankings. Could anyone share more insight on that?",
          "score": 1,
          "created_utc": "2026-02-19 10:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69nqvp",
          "author": "Available-Message509",
          "text": "Seriously, huge thanks to the team behind¬†**GPT-oss 120B**. It‚Äôs such a relief to have a high-performing Tier A model that actually fits on our local GPU setups. Most of the newer models like GLM-5 or Kimi are just getting way too massive for home servers (700B+ is wild..). 120B is the real sweet spot for us!",
          "score": 1,
          "created_utc": "2026-02-19 16:49:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eaaha",
              "author": "MarkoMarjamaa",
              "text": "I'm running gpt-oss-120b. Still, it's also nice to know what kind of AI is achievable when memory prices go down. Like a conservative estimate that in 10 years I will be able to run GLM-5 size quant in my pc. ",
              "score": 1,
              "created_utc": "2026-02-20 09:53:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o69tsr8",
          "author": "tamtaradam",
          "text": "why only open-source/weights?",
          "score": 1,
          "created_utc": "2026-02-19 17:18:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ai3aq",
          "author": "Constandinoskalifo",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-02-19 19:12:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cei46",
          "author": "itsjase",
          "text": "or just check here you can also filter by size [https://artificialanalysis.ai/models/open-source](https://artificialanalysis.ai/models/open-source)",
          "score": 1,
          "created_utc": "2026-02-20 01:13:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hbic3",
          "author": "___cjg___",
          "text": "Without MiniMax it‚Äòs maxifaulty",
          "score": 1,
          "created_utc": "2026-02-20 19:53:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qudda",
          "author": "Hot_Study_6062",
          "text": "So is it possible to run an open source LLM on a NAS and link it to Visual Studio if so which NAS is the best or what do I need to look for in a NAS ?",
          "score": 1,
          "created_utc": "2026-02-22 09:17:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6qwo6d",
          "author": "Mattdeftromor",
          "text": "Where is Mimo-v2-flash ? ",
          "score": 1,
          "created_utc": "2026-02-22 09:39:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6rvww4",
          "author": "Mordimer86",
          "text": "Comparing cloud models with over 700B to small models to run on a consumer GPU is a joke.",
          "score": 1,
          "created_utc": "2026-02-22 14:17:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8kgld",
      "title": "GLM-5 is officially on NVIDIA NIM, and you can now use it to power Claude Code for FREE üöÄ",
      "subreddit": "LLMDevs",
      "url": "https://github.com/Alishahryar1/free-claude-code",
      "author": "PreparationAny8816",
      "created_utc": "2026-02-19 00:30:13",
      "score": 38,
      "num_comments": 7,
      "upvote_ratio": 0.92,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8kgld/glm5_is_officially_on_nvidia_nim_and_you_can_now/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o688fb1",
          "author": "tech_1729",
          "text": "Saying free claude code is misleading üòÖ",
          "score": 2,
          "created_utc": "2026-02-19 12:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67fo1c",
          "author": "ZenApollo",
          "text": "Does the proxy support openai flavor endpoints?",
          "score": 1,
          "created_utc": "2026-02-19 07:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68h0az",
          "author": "zoidme",
          "text": "What relative quality you can expect on this? Like gpt-4.x or better?",
          "score": 1,
          "created_utc": "2026-02-19 13:05:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69267t",
          "author": "--dany--",
          "text": "How does it compare to Claude Code Router?",
          "score": 1,
          "created_utc": "2026-02-19 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o692ucf",
          "author": "lingondricka2",
          "text": "I tried it using Nvidia NIM, neither GLM-5 or Qwen 3.5 gave me a response, step-3.5-flash worked fine though, thank you",
          "score": 1,
          "created_utc": "2026-02-19 15:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lkaia",
          "author": "JasperQuandary",
          "text": "Was slower than molasses with opencode. Not enough capacity.",
          "score": 1,
          "created_utc": "2026-02-21 13:39:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68bv69",
          "author": "SectionCrazy5107",
          "text": "I dont see the claims on free request to be really true anywhere from Nvidia site, it seems usable only when on browser for light prototype, not as daily driver. I will be delighted to be proven wrong so I can really use it.",
          "score": 0,
          "created_utc": "2026-02-19 12:31:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rc0f1j",
      "title": "Opensource is truly catching up to commercial LLM coding offerings",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rc0f1j/opensource_is_truly_catching_up_to_commercial_llm/",
      "author": "1nam2nam",
      "created_utc": "2026-02-22 22:55:41",
      "score": 35,
      "num_comments": 17,
      "upvote_ratio": 0.76,
      "text": "( My crude thoughts in relatively bad english. Fuck you grammar Nazis. )\n\nGot frustrated by Claude Code base (20$) to do anything serious due to the high token usage. Gemini is unusable due to high volume (literally for last 16 hours. Not a single prompt) .\n\nFrustrated and tried opencode + Kimi 2.5. Blown away by the cost. Performance is nearly as good as Sonnet 4.5 (I prefer it to Opus 4.6 based on my own experience) or Gemini 3. \n\nI believe rude awakening for frontier labs as more devs are forced to switch. \n\n  \nThese labs won't command the high premium pricing hence valuations for long.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rc0f1j/opensource_is_truly_catching_up_to_commercial_llm/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6wg2c6",
          "author": "Qxz3",
          "text": "Yup, these businesses don't have much of a moat. Their lofty valuations are beyond ridiculous.¬†",
          "score": 10,
          "created_utc": "2026-02-23 04:47:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72eu1j",
              "author": "TrainerThin",
              "text": "The moat is training costs. If Chinese government subsidezes their way to market dominance like other industries or steal, we‚Äôll all be using Chinese models soon.\n\nWhich is fine and healthy in theory. But lots of power goes to winners of AI race.",
              "score": 1,
              "created_utc": "2026-02-24 02:28:42",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6wthrq",
          "author": "SourceOfConfusion",
          "text": "yeah, most enterprise use cases do not require frontier models. The open source models coming out of China are really quite good and fit most used cases.",
          "score": 4,
          "created_utc": "2026-02-23 06:36:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uxqew",
          "author": "Tema_Art_7777",
          "text": "Codex with chat gpt plus is a powerhouse. I don‚Äôt run out. Anthropic rate limits like hell so avoid that. kimi 2.5 subscription is same price as openai - I certainly would‚Äôt pay that much for kimi",
          "score": 7,
          "created_utc": "2026-02-22 23:13:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wwh2p",
              "author": "Low-Exam-7547",
              "text": "I have never hit any limits on Claude Code using Max.",
              "score": 3,
              "created_utc": "2026-02-23 07:02:54",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6x2ptr",
                  "author": "sgtfoleyistheman",
                  "text": "I have the first max subscription and only use it for 2 personal projects. I've hit my weekly limit 3 weeks in a row! I'm surprised it's enough for your job",
                  "score": 4,
                  "created_utc": "2026-02-23 08:01:26",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6wwmex",
                  "author": "Tema_Art_7777",
                  "text": "that is max!! i am using a $20/m chatgpt plus. how much r u paying",
                  "score": 1,
                  "created_utc": "2026-02-23 07:04:16",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6v34d2",
              "author": "1nam2nam",
              "text": "Codex is roughly same tier as Gemini. It is too slow to get anything done",
              "score": 0,
              "created_utc": "2026-02-22 23:44:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6v6esr",
                  "author": "Tema_Art_7777",
                  "text": "Not sure what your tiering us but frontier models have access to much better hardware and have better inference speed. kimi folks complain about hardware constraints",
                  "score": 2,
                  "created_utc": "2026-02-23 00:03:11",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6waodz",
                  "author": "DurianDiscriminat3r",
                  "text": "Codex 5.3 is better than opus 4.6. Try scaffolding a project from a brief. It can handle complex projects way better. Opus is good at planning (very detailed) and codex is good at implementation.",
                  "score": 2,
                  "created_utc": "2026-02-23 04:09:25",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6vopxs",
                  "author": "Upbeat-Cloud1714",
                  "text": "Slow is subjective. Fast and sloppy is not useful and that's what most models do right now. Codex is great for complex repositories where time is subjective to the scale of the task at hand. ",
                  "score": 1,
                  "created_utc": "2026-02-23 01:50:42",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6x2w01",
          "author": "lsmith77",
          "text": "open weight != open source",
          "score": 4,
          "created_utc": "2026-02-23 08:03:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wabok",
          "author": "Pleasant_Heat7314",
          "text": "I agree, it's been really impressive to watch. I think this trend is likely to accelerate over the next year or two.",
          "score": 1,
          "created_utc": "2026-02-23 04:06:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xhi0o",
          "author": "Zeikos",
          "text": "As soon as I'll get my reverse proxy done on my homelab I'll drop all services in favour of my self hosted OpenWebUI server.  \n\nAPIs are so much cheaper it's not even funny.  \nAnd I can hook my local models to it too.",
          "score": 1,
          "created_utc": "2026-02-23 10:26:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbvlyb",
      "title": "If the current LLMs architectures are inefficient, why we're aggressively scaling hardware?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbvlyb/if_the_current_llms_architectures_are_inefficient/",
      "author": "en00m",
      "created_utc": "2026-02-22 19:50:57",
      "score": 33,
      "num_comments": 31,
      "upvote_ratio": 0.85,
      "text": "Hello guys! As in the title, I'm genuinely curious about the current motivations on keeping information encoded as tokens, using transformers and all relevant state of art LLMs architecture/s.\n\nI'm at the beginning of the studies this field, enlighten me.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbvlyb/if_the_current_llms_architectures_are_inefficient/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6tvzc2",
          "author": "SamWest98",
          "text": "To run the inefficient LLMs!¬†",
          "score": 46,
          "created_utc": "2026-02-22 19:58:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6uucic",
              "author": "undo777",
              "text": "The good news is we'll have lots of power needs, maybe nuclear takes off!",
              "score": 5,
              "created_utc": "2026-02-22 22:54:57",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6w0guv",
                  "author": "rditorx",
                  "text": "What are the good news?",
                  "score": 1,
                  "created_utc": "2026-02-23 03:02:03",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6txags",
          "author": "i_wayyy_over_think",
          "text": "There‚Äôs newer  techniques like Engrams by DeepSeek that tries to keep reasoning separate from knowledge. \n\nAlso GPUs are programmable so when new techniques are available, it‚Äôs just a software update, so doesn‚Äôt make sense to hold back hardware.",
          "score": 23,
          "created_utc": "2026-02-22 20:05:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o72q7nw",
              "author": "Playful-Job2938",
              "text": "It does, these ai farms are putting us back into a worse spot than covid. The rest of the world needs compute too:",
              "score": 1,
              "created_utc": "2026-02-24 03:36:32",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6u5sjg",
              "author": "BarrenLandslide",
              "text": "Yes exactly this. Even the big KIMI K2 models, which are basically hundreds of SLM under the hood need at least like a 1 Mio USD rack to run on halfway usable quantisation.",
              "score": 1,
              "created_utc": "2026-02-22 20:48:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6v4km7",
                  "author": "jeffdn",
                  "text": "That is not how MoE models work, and basically every model released in the last year has been an MoE, Kimi isn‚Äôt special in that regard.",
                  "score": 6,
                  "created_utc": "2026-02-22 23:52:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6u1ynt",
          "author": "typeryu",
          "text": "I like to think this as the same as saying ‚Äúnuclear fusion energy is clearly better and safer than fission energy‚Äù. Almost everyone knows there are theoretically much more capable world simulators that should just get it (whatever that is), but we are not there yet and we don‚Äôt even know if it is doable with the current hardware stack and data. LLMs are here and available now and they are far more capable than what is currently mainstream. Based on the incremental improvements we‚Äôve been getting, we still have many years of improvement ahead of us not to mention it will take even more time for the average folks and businesses to adopt the latest form which is agentic LLMs. That alone I think is enough to wipe out a ton of work and also accelerate development on other technologies so that is why money is being poured in. There‚Äôs definitely some over investing going on in some places, but in general the big labs should come through as the new tech conglomerates.",
          "score": 4,
          "created_utc": "2026-02-22 20:28:45",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u37a3",
          "author": "docgpt-io",
          "text": "To the best of my knowledge, keeping information encoded as tokens has nothing to do with efficiency loss, it's rather the fact that we encode all information from the internet in giant neural networks and always talk to at least very large parts of the network - the LLMs shouldn't need to know how high the Eiffeltower is to help you with Maths, yet they do, and this is not efficient. I think the reasons why the spending keeps increasing anyway, are:  \n1. it still reaches out --> the value that can be created with LLMs is still remarkable and it makes sense to keep spending from an economic perspective  \n2. efficiency is rapidly improving",
          "score": 3,
          "created_utc": "2026-02-22 20:35:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u554x",
          "author": "BarrenLandslide",
          "text": "Because clever orchestration of SLMs, TLMs calling deterministic tools is the future.",
          "score": 3,
          "created_utc": "2026-02-22 20:45:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u5pck",
          "author": "funbike",
          "text": "Diffusion LLMs have a completely different architecture.   Someone took image-generation AI and applied it to text.  Look into Inception's Mercury, which performs well.",
          "score": 3,
          "created_utc": "2026-02-22 20:47:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u0mwr",
          "author": "kkania",
          "text": "Our power generation based on the Carnot cycle (so coal, gas, nuclear) is only 30-40% efficient, and we‚Äôve been at it for a hundred years at this point. People don‚Äôt give a shit about efficiency in general, and it only becomes a thing when fuel runs out (eg oil for cars). It‚Äôll probably need to happen with power for compute first before we see efficiency in ai getting improved.",
          "score": 4,
          "created_utc": "2026-02-22 20:21:58",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6txver",
          "author": "Mysterious-Rent7233",
          "text": ">Hello guys! As in the title, I'm genuinely curious about the current motivations on keeping information encoded as tokens, using transformers and all relevant state of art LLMs architecture/s.\n\nThe motivation is: \"This is what we know works. Other approaches are unproven research.\" That's all. There isn't a magic wand to invent a better architecture. You actually have to invent it. Which might take six months, six years or sixty years.",
          "score": 2,
          "created_utc": "2026-02-22 20:07:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u1b9x",
          "author": "chickenAd0b0",
          "text": "Read Richard Sutton‚Äôs ‚Äúthe bitter lesson‚Äù essay then you‚Äôll understand why everyone is scaling.",
          "score": 2,
          "created_utc": "2026-02-22 20:25:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6x98ah",
              "author": "Mysterious-Rent7233",
              "text": "Everyone is scaling...except Sutton. Who believes they are scaling the wrong thing.",
              "score": 1,
              "created_utc": "2026-02-23 09:05:37",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6uu79o",
          "author": "Tema_Art_7777",
          "text": "they will all improve - as new papers are emerging on optimization. However, for ai to be pervasive and ambient, the current infrastructure we have is woefully inadequate and investments are quite welcome. Anthropic is rate limiting the hell out of everyone as it is. I believe investors have faith that innovations will make things better with llm usage. While not a promised road to AGI at all, there is massive benefits still to be realized with what we currently have!",
          "score": 2,
          "created_utc": "2026-02-22 22:54:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tv5ii",
          "author": "earmarkbuild",
          "text": "because money got invested and there is no getting it back (remember the ads before the dot com bubble hit? I don't.)\n\nP.S.\n\n**and yet the kings are naked.**\n\nCurrent industry status quo is [customer lock-in and data extraction disguised as comfort and coddling](https://www.reddit.com/r/OpenIP/comments/1r8wcuj/enshittification_and_its_alternativesmd/), and they won't stop gatekeeping user context corpora because they have no other levers of user retention.\n\n---\n\nIn the meantime, nobody is stopping anybody from exporting their data. Export it, unpack it, get conversations, save to folder, open whatever claude code gemini codex you decide to use, continue conversation locally. Then help someone else do the same. \n\n**They can't even hold you. They have no power here. It's all pretend.**\n\n---\n\n[the intelligence is in the language. the model is a commodity.](https://gemini.google.com/share/81f9af199056) <-- talk to it! it's just language.\n\n---\nP.P.S. [the industry can be regulated](https://www.reddit.com/user/earmarkbuild/comments/1rblqui/a_practical_way_to_govern_ai_manage_signal_flow/)",
          "score": 2,
          "created_utc": "2026-02-22 19:54:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6tyu7o",
          "author": "Low-Opening25",
          "text": "Ok, so what do you propose, what‚Äôs your replacement architecture exactly? to me it seems like you didn‚Äôt understand the fundamentals. LLM architecture is based on transformers and matrix multiplication and they operate on tokens.\n\nWhat you propose is equivalent of, hey, why computers have to operate on 0s and 1s and binary logic, why not mix this up?",
          "score": 1,
          "created_utc": "2026-02-22 20:12:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u4729",
          "author": "Fabulous-Possible758",
          "text": "Even with improving efficiency we‚Äôre also increasing demand a lot.  Remember a single query now might be multiple tool calls, inferencing on the results, maybe *more* tool calls, and all of that on larger and larger context windows, and they‚Äôre still trying to sell and incorporate this into wider and and wider user bases.  A .9x improvement in compute usage still doesn‚Äôt matter if you have 100x as many uses for it.",
          "score": 1,
          "created_utc": "2026-02-22 20:40:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6uffx9",
          "author": "coloradical5280",
          "text": "Because the future architectures like JEPA, Test-Time Training, State Space Models, etc, are more efficient in many ways but still need a ton of compute, and unfortunately, probably more memory, so we need compute post-transformers too.",
          "score": 1,
          "created_utc": "2026-02-22 21:36:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6unmsn",
          "author": "imkindathere",
          "text": "Why do you say they're inefficient? I would say they're efficient because they can be fully parallelized. That's what allowed them to scale to the size they're at now",
          "score": 1,
          "created_utc": "2026-02-22 22:18:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v1pol",
          "author": "Sonoftalltree",
          "text": "Think about the Mag 7 and what options they have to continue growing their returns year after year, after they are already so big. Then think about the risk of AI eating their SaaS margins. The strategy is to have a tool no one else can run. In some respects, the inefficient nature is a feature because now startups have considerably less advantage.",
          "score": 1,
          "created_utc": "2026-02-22 23:36:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6v5ate",
          "author": "red_hare",
          "text": "The path forward is fine-tuning smaller models for task-specific execution.\n\nBut user demand and progress on larger general purposes models is outpacing the cost of task-specific fine-tuning.\n\nBest thing that could happen to the industry right now would be a slowdown in SotA general purposes model progress.",
          "score": 1,
          "created_utc": "2026-02-22 23:56:55",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vuhm4",
          "author": "damnburglar",
          "text": "Among other things: Gold rush.",
          "score": 1,
          "created_utc": "2026-02-23 02:25:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6vzypj",
          "author": "FirmSignificance1725",
          "text": "First I would say, define inefficient. We‚Äôve very quickly grown accustomed to LLMs, but this is still new in the grand scheme of innovation. The transformer architecture is able to achieve a functionality prior impossible, even with data center level of resources. \n\nThere are many other interesting theoretical implications of transformers, but one of the biggest was the fact that it didn‚Äôt follow the law of diminishing return as aggressively as other models. Most models were restricted to a specific type of task and/or topped off quickly when generalized, flattening regardless of parameter count increase. Transformers however have continuously gotten better and shown better generalizability as parameter count has increased. \n\nSo, I would say that while they are resource hogs, I would not generally classify the transformer as ‚Äúinefficient‚Äù. Yes, maybe compared to a standard program, but that program has nowhere near the capability of the deployed LLM. I would say it‚Äôs quite efficient for what it does and we‚Äôre attempting to push it as far as we can at scale. \n\nThat being said, the reason we‚Äôre scaling hardware is because product X shows some capability and economic benefit both short and long term, that companies have deemed it valuable enough to invest Y dollars for Z return. \n\nOptimizations constantly happen. Can use mixture of experts to reduce active params, better kernels, KV Cache, pipeline parallelism, quantizations, <insert technique here> to make it more efficient. And those techniques will continue to be discovered and implemented.\n\nBut, if we reached the threshold where value exceeds cost, then were executing",
          "score": 1,
          "created_utc": "2026-02-23 02:58:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xucnq",
          "author": "Valuable-Mix4359",
          "text": "I keep seeing the argument that ‚Äútransformers are inefficient, so why are we scaling hardware,‚Äù and I think it mixes two different layers of analysis.\n\nAt the model level, yes, transformers are expensive. Attention is costly, long context windows are costly, inference isn‚Äôt lightweight. But they scale in a highly predictable way. More parameters + more data + more compute ‚Üí better performance, with relatively stable scaling curves. From an engineering perspective, that kind of predictability has significant value.\n\nAs long as marginal capability gains remain higher than marginal compute costs, scaling is not irrational. It‚Äôs an economic decision.\n\nWhat seems more interesting to me is that we‚Äôre no longer operating at the ‚Äúone call = one response‚Äù level. Production systems today are often multi-step pipelines: RAG, tool calls, retries, fallback models, agent loops, reflection passes, etc. A single user request can trigger multiple inferences and large context usage.\n\nEven if base model efficiency improves by 20%, total system-level compute can still increase because workflows become more complex. Lower unit cost tends to increase usage. This is no longer purely a model efficiency problem ‚Äî it‚Äôs an allocation problem at the system level.\n\nMany teams still default to routing most tasks to the largest available model, even when parts of the workflow could be handled by a smaller model or a deterministic component. That‚Äôs not really about architectural elegance. It‚Äôs about compute routing.\n\nI‚Äôm not convinced the main bottleneck is ‚Äúfind a radically new architecture tomorrow.‚Äù It may be more about optimizing compute allocation across models, tasks, and constraints at the system layer. Scaling looks excessive if you isolate the model, but less so when you look at the entire infrastructure stack.\n\nAre people here actually measuring cost per workflow rather than just cost per token?",
          "score": 1,
          "created_utc": "2026-02-23 12:17:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6xzv33",
          "author": "Potential-Leg-639",
          "text": "LLMs are getting more efficient and there is still a shortage on hardware. Better be prepared.",
          "score": 1,
          "created_utc": "2026-02-23 12:56:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o74gqx3",
          "author": "qubridInc",
          "text": "Because scaling hardware gives reliable gains *today*, even if the architecture isn‚Äôt perfect.\n\nTransformers are easy to parallelize, scaling laws still hold, and all existing infra is built around them so, more compute = better models right now. New, more efficient architectures are being researched, but they‚Äôre not yet proven at the same scale.",
          "score": 1,
          "created_utc": "2026-02-24 12:16:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6typ8n",
          "author": "Fuzzy_Pop9319",
          "text": "As it happens, the elegant data structures that are being brute forced are from a finite structure, and as it happens in mathematics, no one will take you seriously or give you grants or hire you if you are using finite mathematics.    \nEverything else spawns from this.",
          "score": 0,
          "created_utc": "2026-02-22 20:12:09",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbmq30",
      "title": "not sure if hot take but mcps/skills abstraction is redundant",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbmq30/not_sure_if_hot_take_but_mcpsskills_abstraction/",
      "author": "uriwa",
      "created_utc": "2026-02-22 14:07:08",
      "score": 25,
      "num_comments": 45,
      "upvote_ratio": 0.72,
      "text": "Whenever I read about MCPs and skills I can't help but think about the emperor's new clothes.\n\nThe more I work on agents, both for personal use and designing frameworks, I feel there is no real justification for the abstraction. Maybe there was a brief window when models weren't smart enough and you needed to hand-hold them through tool use. But that window is closing fast.\n\nIt's all just noise over APIs. Having clean APIs and good docs *is* the MCP. That's all it ever was.\n\nIt makes total sense for API client libraries to live in GitHub repos. That's normal software. But why do we need all this specialized \"search for a skill\", \"install a skill\" tooling? Why is there an entire ecosystem of wrappers around what is fundamentally just calling an endpoint?\n\nMy prediction: the real shift isn't going to be in AI tooling. It's going to be in businesses. **Every business will need to be API-first.** The companies that win are the ones with clean, well-documented APIs that any sufficiently intelligent agent can pick up and use.\n\nI've just changed some of my ventures to be API-first. I think pay per usage will replace SaaS.\n\nAI is already smarter than most developers. Stop building the adapter layer. Start building the API.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbmq30/not_sure_if_hot_take_but_mcpsskills_abstraction/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6ry33f",
          "author": "Thick-Protection-458",
          "text": "Hm ... Wasn't MCP always exactly just the way to expose remote / other non-foreseen tools for use by the model?\n\n\nSo you know, not like some fancy magic idea, but just a way to provide standartized interface so services can provide it instead of going xkcd 14 standards situation?",
          "score": 23,
          "created_utc": "2026-02-22 14:29:45",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6s69q9",
              "author": "das_war_ein_Befehl",
              "text": "For early models, yeah. Nowadays they‚Äôre pretty good at just using the API. MCP server are heavy on context and honestly LLMs work better with CLIs anyways",
              "score": 5,
              "created_utc": "2026-02-22 15:12:35",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6srghb",
                  "author": "ThenExtension9196",
                  "text": "The early models of mid 2025.",
                  "score": 7,
                  "created_utc": "2026-02-22 16:48:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6sh1s8",
              "author": "uriwa",
              "text": "I don't think this will work long term. If it did, humans would do it too.",
              "score": 1,
              "created_utc": "2026-02-22 16:02:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s4okv",
          "author": "strangeanswers",
          "text": "putting an MCP server over an API standardizes access control, abstracts away schema changes and deduplicates efforts since agent developers will probably need to create an abstract tool layer for the API anyways.",
          "score": 13,
          "created_utc": "2026-02-22 15:04:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sdtvi",
              "author": "damhack",
              "text": "MCP is not supposed to just layer over REST or GraphQL APIs.  That‚Äôs a poor use.  MCP is a remote procedure call interface and should be handled accordingly.\n\nThe OP is right.  Recent LLM systems are more than capable of making a call to an API in an orderly manner if the API schema and (not totally necessary) the API docs are available.  This is due to both better reasoning performance, better tool calling and code execution abilities.  In fact a reasonable, context-saving approach is to ask a recent LLM to provide a parameterized prompt snippet to make a particular call and then provide those snippets as a library of available calls to your agents in future. Less context use, faster predictable calls and less security vulnerability hunting.",
              "score": 3,
              "created_utc": "2026-02-22 15:48:39",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6s7ads",
              "author": "cmndr_spanky",
              "text": "This is how I think about MCP anyways, that said (just to play devils advocate), if an API library is well documented a multi-turn agent (with a smart LLM) could easily read API docs and make API queries for you with a generic http request tool and web scraper tool. If all you‚Äôre doing is writing simple MCP abstractions over APIs.. it‚Äôs kinda the same shit (just handing over more autonomy to the agent and possibility of it making a bad choice in how it uses an API). \n\nThat said, if you‚Äôre writing custom logic that your agent is meant to execute, MCP (or skills) is the best way‚Ä¶ there‚Äôs no api to wrap",
              "score": 1,
              "created_utc": "2026-02-22 15:17:44",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6s8zvw",
                  "author": "strangeanswers",
                  "text": "but then you‚Äôre wasting tokens and causing context rot by needing to load all those API docs into your context window to understand what the api does instead of just reading a tool description. how will the agent even know which api is useful for the task at hand? should it read the docs for all the APIs available to it each time?\n\nalso, if you spin up a new agent and want it to use this API, you probably need to whitelist it for that endpoint, which adds a bunch of complexity. if you instead just expose one tool to it and all requests from that tool come to the api through an MCP server it massively simplifies access management.",
                  "score": 8,
                  "created_utc": "2026-02-22 15:25:57",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o70namj",
                  "author": "Dihedralman",
                  "text": "Why are you making a deterministic process non-deterministic?¬†",
                  "score": 1,
                  "created_utc": "2026-02-23 20:46:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6rxgd0",
          "author": "OkLettuce338",
          "text": "How would you remotely install a skill that requires authentication?",
          "score": 10,
          "created_utc": "2026-02-22 14:26:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sgh66",
              "author": "uriwa",
              "text": "LLMs need env variables that get hot swapped, that's enough I think.",
              "score": 0,
              "created_utc": "2026-02-22 16:00:00",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6srzec",
                  "author": "OkLettuce338",
                  "text": "No it wouldn‚Äôt be. How would you install the skill remotely for a diverse set of users?",
                  "score": 7,
                  "created_utc": "2026-02-22 16:50:59",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tq220",
          "author": "igorim",
          "text": "it's a massive risk when everytime some model needs to read something or do something it decides to read arbitrary code. MCP is not about a model not being able to do X it's about 1. saving it tokens to do X, and 2. adding deterministic guardrails, and 3. Having a shared interface so you don't need to reimplement for every model\n\n",
          "score": 3,
          "created_utc": "2026-02-22 19:28:57",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s21pm",
          "author": "XiiMoss",
          "text": "Yeah sound I‚Äôll just give the agent direct access to my API keys shall I",
          "score": 3,
          "created_utc": "2026-02-22 14:50:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sfr96",
              "author": "uriwa",
              "text": "the harness should hot swap the keys. llm doesn't need to know them. (like in deno sandboxes)",
              "score": 0,
              "created_utc": "2026-02-22 15:57:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6s2ct0",
          "author": "vogut",
          "text": "It's just a tool list and a prompt fetcher. The hype around it was dumb, I agree. But it's necessary",
          "score": 3,
          "created_utc": "2026-02-22 14:52:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s7kbg",
          "author": "cmndr_spanky",
          "text": "MCP as a simple wrapper over APIs might be silly, but if you use custom written logic (nothing to do with APIs) that you want your LLM agent to execute like a function, MCP / skills is def the way to go..",
          "score": 6,
          "created_utc": "2026-02-22 15:19:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6sgurp",
              "author": "uriwa",
              "text": "humans just call that \"documentation\", and they put it in places like google docs, markdown files in github etc'. There is no protocol for it.",
              "score": -1,
              "created_utc": "2026-02-22 16:01:35",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6sn8d1",
                  "author": "cmndr_spanky",
                  "text": "No that‚Äôs incorrect. You often don‚Äôt want variations / non-determinism in how an LLM should execute known logic which needs to be stable. So authoring a python function exposed via MCP is the best way, the ‚Äúdocument‚Äù only describes how and when to execute the function.",
                  "score": 4,
                  "created_utc": "2026-02-22 16:29:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6tz1fn",
          "author": "WolfeheartGames",
          "text": "MCP is great for not restful api. Anything that wraps complex logic or maintains a state for the agent. Ghidra mcp, Godot mcp, playwright mcp, that sort of thing.",
          "score": 2,
          "created_utc": "2026-02-22 20:13:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6u8vsx",
          "author": "apf6",
          "text": "MCP is great when you need something with builtin Oauth support.",
          "score": 2,
          "created_utc": "2026-02-22 21:04:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s6i43",
          "author": "dreamingwell",
          "text": "I wish I could auto block anyone that posts ‚ÄúMCP isn‚Äôt necessary‚Äù",
          "score": 2,
          "created_utc": "2026-02-22 15:13:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6ta2ky",
              "author": "Hammer466",
              "text": "I could make an mcp for that!",
              "score": 4,
              "created_utc": "2026-02-22 18:14:11",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o73vu67",
                  "author": "Andrew_Ngrok",
                  "text": "you can do it without an mcp",
                  "score": 1,
                  "created_utc": "2026-02-24 09:16:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6y8eyf",
          "author": "albaldus",
          "text": "MCP = distribution, exposition¬†¬†\n\nSkills = execution¬†",
          "score": 1,
          "created_utc": "2026-02-23 13:49:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6s8rlp",
          "author": "qlwkerjqewlkr",
          "text": "MCP is cringe and pointless",
          "score": 0,
          "created_utc": "2026-02-22 15:24:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6wap5e",
          "author": "Clear-Dimension-6890",
          "text": "I agree. I‚Äôm not a big fan of skills and hooks. Just another point of failure . Put it all in a config file or write utilities",
          "score": 0,
          "created_utc": "2026-02-23 04:09:33",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7momq",
      "title": "Clawdbot/Moltbot/OpenClaw is a security disaster waiting to happen",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "author": "thecreator51",
      "created_utc": "2026-02-17 23:38:04",
      "score": 21,
      "num_comments": 24,
      "upvote_ratio": 0.89,
      "text": "I was more excited about AI agent frameworks than I was when LLMs first dropped. The composability, the automation, the skill ecosystem - it felt like the actual paradigm shift.\n\nLately though I'm genuinely worried. We can all be careful about which skills we install, sure. But most people don't realize skills can silently install other skills. No prompt, no notification, no visibility. One legitimate-looking package becomes a dropper for something else entirely, running background jobs you'll never see in your chat history.\n\nWhat does a actually secure OpenClaw implementation even look like? Does one exist?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5ywnls",
          "author": "Strong_Worker4090",
          "text": "I don‚Äôt think the concern is overblown. If skills can silently install other skills and run background jobs with no visibility, that‚Äôs a real supply chain and privilege boundary problem.\n\nThe way I think about it is this: don‚Äôt treat the agent like a helpful assistant. Treat it like the smartest hacker in the world who happens to be following instructions most of the time.\n\nIf you assume that, a \"secure\" implementation looks very different from the default hobby setup.\n\nFirst, the model shouldn‚Äôt have direct power. It shouldn‚Äôt have raw network access, raw filesystem access, or ambient credentials sitting in environment variables. It should only be able to request actions.\n\nSecond, every capability should be explicitly defined and allowlisted. No silent skill installs. No transitive dependency installs at runtime. If something gets added, it happens in a controlled build step with review and version pinning.\n\nThird, all external effects should go through a choke point you control. If it wants to send an email, make an HTTP request, write to a database, or touch Slack, it calls a guarded tool. That tool enforces policy, rate limits, domain restrictions, and writes to an immutable audit log. No raw SMTP. No arbitrary outbound HTTP.\n\nFourth, assume it will try to exfiltrate if it can. That means default deny on network egress, strict sandboxing, and strong logging that lives outside the agent runtime.\n\nIs there a \"perfect\" secure setup that still keeps full utility? Probably not. The more useful the agent is, the more power it needs. The goal isn‚Äôt perfection, it‚Äôs constrained, mediated power with visibility and revocability.\n\nSo I wouldn‚Äôt say these frameworks are doomed. I‚Äôd say most default installs are way too permissive for production. A secure OpenClaw implementation would look less like a plugin playground and more like a tightly sandboxed execution engine with a policy layer in front of every meaningful action.",
          "score": 9,
          "created_utc": "2026-02-18 01:01:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61l3gs",
              "author": "GCoderDCoder",
              "text": "Agreed. To their credit, tons of folks were excited to help something like this and made it a totally different project IMO. There's now various ways to increase isolation. I have been using a lot of reactive tools that require me initiating everything so Im enticed by the proactive nature of open claw so I see it as starting with proactive features I want to make a more deterministic implementation of. That said, I was trashing the initial release but i think it is usable for personal setups for informed users now.\n\nI originally planned a series of vms with separate controls but there are several layers of isolation included now in open claw. I'm still configuring an internal only container and an external accessible vm install because I wanted to be as conservative as possible assuming the external facing one will be contaminated but sandboxing seems legitimately incorporated in open claw now where it's not irresponsible now to have one gateway with different agent profiles to achieve similar separation IMO. \n\nBoth my instances are locked down to only be able to use tools I give them. The external one has no access to any sensitive info but can gather information and put it together for me to allow it to save it in my tools. But until I approve it everything is ephemeral in the container sandbox. The second one is internal only with a lot of read only access but any write requires my approval. So that allows it to proactively review solutions without compromising my tools.\n\nInsider threat is always the most dangerous and even more so with tools that replicate human logic but lack the ability to actually think.",
              "score": 3,
              "created_utc": "2026-02-18 12:44:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67kexn",
                  "author": "Traditional-Set6848",
                  "text": "What I love about open claw and moltbook (independent of judgement if it‚Äôs good or not) is the approach to using less complex and more obvious technology in quite a human way, I remember when Facebook was launched and my friends where ‚Äúwoooow look what you can do‚Äù, and I was all ‚Äúyehhh but it‚Äôs just JavaScript and apis wtbd?‚Äù - the big deal was the way the tech got used and I was being a Luddite üòÇüò≠",
                  "score": 1,
                  "created_utc": "2026-02-19 08:27:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60idec",
              "author": "Traditional-Set6848",
              "text": "Nicely put!¬†",
              "score": 2,
              "created_utc": "2026-02-18 07:13:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dgcxk",
              "author": "Useful-Process9033",
              "text": "Treating agents like the smartest hacker in the room is exactly the right frame. Any agent that touches prod infra needs explicit permission boundaries and audit trails. We built IncidentFox with that assumption from day one because an AI SRE with unchecked access is scarier than the incidents it fixes. [https://github.com/incidentfox/incidentfox](https://github.com/incidentfox/incidentfox)",
              "score": 1,
              "created_utc": "2026-02-20 05:22:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yp6vs",
          "author": "Interesting-Law-8815",
          "text": "Waiting to happen?   I think it‚Äôs already happened!",
          "score": 13,
          "created_utc": "2026-02-18 00:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zrcum",
          "author": "Vusiwe",
          "text": "Don‚Äôt know much about it, but it really sounds like 2023‚Äôs AutoGPT, only running with root permissions, with network access turned on\n\nGG",
          "score": 3,
          "created_utc": "2026-02-18 03:50:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z05j8",
          "author": "crankthehandle",
          "text": "are there any crazy stories that have happened with openclaw? Looks like moltbook was the way bigger fuck up.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o611f8a",
          "author": "Loud-Option9008",
          "text": "This is the thing that worries me more than jailbreaks or prompt injection in isolation. Silent skill installation is a supply chain attack surface and most users have no idea it exists. You're not just trusting the skill, you're trusting everything that skill decides to pull in at runtime.\n\nA \"secure\" OpenClaw implementation would need at minimum: process-level isolation per skill so a compromised package can't read memory or environment variables from the agent runtime, network egress controls so background jobs can't phone home, and some kind of attestation that what's running matches what you installed. None of that exists out of the box.\n\nThe deeper issue is that the whole skill ecosystem is built on implicit trust. Skills run in the same execution context as the agent, which means they have access to everything the agent has access to  credentials, session tokens, whatever's in the environment. A dropper skill doesn't need to escalate privileges, it already has them.\n\nDocker helps at the surface level but shared kernel is a real limitation here  if a skill finds a kernel exploit, the container boundary doesn't save you. The honest answer is that a properly isolated implementation needs the skill execution to happen in a separate environment with explicit, audited permissions for every outbound action. Most people are nowhere near that and don't realize it.",
          "score": 2,
          "created_utc": "2026-02-18 10:10:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yiaxd",
          "author": "kubrador",
          "text": "you're describing dependency hell with god mode. the answer to \"what does secure look like\" is probably \"don't let untrusted code execute arbitrary actions\" which, yeah, solves the problem by making the whole thing pointless.",
          "score": 1,
          "created_utc": "2026-02-17 23:42:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5za5z6",
          "author": "BrianJThomas",
          "text": "I feel the same way about crates.io, to be fair.",
          "score": 1,
          "created_utc": "2026-02-18 02:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zcy7t",
          "author": "wally659",
          "text": "I feel like a \"security disaster\" requires some suggestion of \"security\" to begin with. Saying the OpenClaw platform is a security risk is a bit like saying underwater cave exploration is dangerous.",
          "score": 1,
          "created_utc": "2026-02-18 02:26:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zgtpy",
              "author": "NoleMercy05",
              "text": "![gif](giphy|VBmRD9W9HwTLmGLz34)",
              "score": 1,
              "created_utc": "2026-02-18 02:47:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dge2m",
              "author": "Useful-Process9033",
              "text": "Underwater cave exploration is a perfect analogy honestly. The people doing it seriously have checklists, redundancy, and abort protocols. The problem is when someone just jumps in with a flashlight.",
              "score": 1,
              "created_utc": "2026-02-20 05:22:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dgr78",
                  "author": "wally659",
                  "text": "Also if the risk itself wasn't part of the reward there'd be no point. ü§£",
                  "score": 1,
                  "created_utc": "2026-02-20 05:25:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o603e1p",
          "author": "Civil_Tea_3250",
          "text": "And OpenAI just hired the guy that made it. Because he made such a great product lol\n\nSeriously, can we stop this now? Like, right now.",
          "score": 1,
          "created_utc": "2026-02-18 05:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o609ury",
          "author": "No_Success3928",
          "text": "I'm excited about making bank fixing things :D\n\n",
          "score": 1,
          "created_utc": "2026-02-18 06:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60s18g",
          "author": "sogo00",
          "text": "I remember there was one of the top skill that was installing some malware...\n\nBTW - that is not limited to this type of agent - all claude/other agent skills you find on the web are unaudited and even if the author is trustful someone can hijack the repo. That especially applies to the big all-included skill where the maintainer collects other peoples skills...",
          "score": 1,
          "created_utc": "2026-02-18 08:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60xb6w",
          "author": "Zeikos",
          "text": "Nobody is waiting",
          "score": 1,
          "created_utc": "2026-02-18 09:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63c1rd",
          "author": "Legitimate-Leek4235",
          "text": "Its an absolute disaster to give the keys to your kingdom for a virtual job executor under any circumstances with no guard-rails. Its like leaving your car keys in unattentended with the lights turned .",
          "score": 1,
          "created_utc": "2026-02-18 17:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68us9q",
          "author": "projectoedipus",
          "text": "LLMs are non-deterministic systems, and so they, mathematically provably, can always be jailbroken, and there will always be the potential for them to be a security risk. They are a tool, and when used responsibly, they can be used to accomplish great things.\n\nOpenClaw is an agentic system that makes LLMs more accessible and more powerful, but the risks still exist. There are quite a few \"security layers\" that people have created to prevent prompt injection and things like that, but the real truth is... Security systems exist to make the people who have them feel safe, and to raise the barrier for entry for those who would seek to exploit them, but someone who is determined enough, can always get in.  \n  \nDon't make your OpenClaw instance accessible outside of your home network. Don't install skills from people that you don't trust without auditing them first, and sandbox according to the level of risk that you are comfortable with.\n\nLife is short. Don't sweat the small stuff.",
          "score": 1,
          "created_utc": "2026-02-19 14:24:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6p0uac",
          "author": "Murky_Willingness171",
          "text": "lol welcome to the party. been red teaming these frameworks for months and it's a shitshow. every skill marketplace is basically npm with root access.",
          "score": 1,
          "created_utc": "2026-02-22 00:50:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zr3ns",
          "author": "zZaphon",
          "text": "This is where AI Governance Software would be useful. For example\n\nhttps://factara.fly.dev",
          "score": 0,
          "created_utc": "2026-02-18 03:48:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rbc0d2",
      "title": "Antigravity (Gemini 3.1 Pro) just solved a Next.js Tailwind build bug I‚Äôve been struggling with for a year.",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rbc0d2/antigravity_gemini_31_pro_just_solved_a_nextjs/",
      "author": "Cod3Conjurer",
      "created_utc": "2026-02-22 04:13:06",
      "score": 18,
      "num_comments": 10,
      "upvote_ratio": 0.71,
      "text": "For almost a year, my Next.js portfolio build would fail every single time I ran `npm run build`. The error message was completely useless:\n\nRepo: [https://github.com/AnkitNayak-eth/ankitFolio](https://github.com/AnkitNayak-eth/ankitFolio)  \nLive site: [https://ankit-nayak.vercel.app/](https://ankit-nayak.vercel.app/)\n\n    HookWebpackError: Cannot read properties of undefined (reading 'length')\n    in cssnano-simple\n\nIt always crashed during CSS minification. I went down every rabbit hole imaginable Webpack configs, different Next.js versions, cssnano issues, dependency updates. Nothing worked.\n\nMy only workaround was disabling minification in `next.config.ts`:\n\n    config.optimization.minimize = false\n\nThe build would pass, but my production app was completely unoptimized. I eventually accepted it as one of those strange ‚ÄúNext.js things.‚Äù\n\nToday, I decided to try Antigravity, powered by Gemini 3.1 Pro. I let it analyze the repository. It ran for about half an hour digging through the codebase and then it surfaced the actual root cause.\n\nIt wasn‚Äôt Webpack.  \nIt wasn‚Äôt cssnano.  \nIt wasn‚Äôt Next.js.\n\nIt was a Tailwind arbitrary value with a template literal:\n\n    <div className={`flex [mask-image:linear-gradient(to_${direction},transparent,black_10%,black_90%,transparent)]`}>\n\nTailwind couldn‚Äôt statically analyze `to_${direction}` at build time, so it generated invalid CSS. When Next.js passed that to cssnano for minification, the process crashed. The stack trace pointed in the wrong direction for months.\n\nThe fix was simply making the class static with a ternary:\n\n    <div className={`flex ${\n      direction === 'left'\n        ? '[mask-image:linear-gradient(to_left,...)]'\n        : '[mask-image:linear-gradient(to_right,...)]'\n    }`}>\n\nAfter that, production builds worked immediately. Minification enabled. No crashes.\n\nI spent a year blaming Webpack and Next.js for what was ultimately a dynamic Tailwind string interpolation mistake. Antigravity, powered by Gemini 3.1 Pro, found it in under an hour.\n\nUff What a crazzy time to be alive. ü§∑‚Äç‚ôÇÔ∏è",
      "is_original_content": false,
      "link_flair_text": "Great Discussion üí≠ ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rbc0d2/antigravity_gemini_31_pro_just_solved_a_nextjs/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6qdko0",
          "author": "coloradical5280",
          "text": "There is no way opus 4.6 or codex-5.x-xhigh , would have failed to find this, particularly with chrome dev tools MCP",
          "score": 8,
          "created_utc": "2026-02-22 06:38:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wk2m1",
              "author": "Cod3Conjurer",
              "text": "I did experiment with Claude a few months ago (don't remember which model), but it didn't crack this one back then.",
              "score": 2,
              "created_utc": "2026-02-23 05:17:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6v4o2x",
          "author": "eltron",
          "text": "I‚Äôve been burned with Tailwind arbitrary interpolation errors before and I‚Äôve found those error to be red herring errors. They usually distract me for a good chunk of time.",
          "score": 2,
          "created_utc": "2026-02-22 23:53:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6wjvjb",
              "author": "Cod3Conjurer",
              "text": "The problem wasn't understanding that Tailwind discourages dynamic classes. The problem was a production only cssnano crash with zero indication it was related to Tailwind or which component caused it.",
              "score": 1,
              "created_utc": "2026-02-23 05:16:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6ws7wp",
                  "author": "coloradical5280",
                  "text": "No offense but the real failure was not implementing robust error handling, verbose debug logging, and not connecting basic web dev tools that are literally created to handle exactly these issues",
                  "score": 0,
                  "created_utc": "2026-02-23 06:25:13",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6xg3k9",
          "author": "hugganao",
          "text": "first prove to me you don't work for google",
          "score": 2,
          "created_utc": "2026-02-23 10:12:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xybzi",
              "author": "Cod3Conjurer",
              "text": "He he üòÇ¬†",
              "score": 1,
              "created_utc": "2026-02-23 12:46:45",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6xhaoh",
          "author": "CorneZen",
          "text": "Dude, from your post history it‚Äôs clear that you are now pushing AI generated content. It‚Äôs too obvious. Your site styling and layout looks sweet though.",
          "score": 0,
          "created_utc": "2026-02-23 10:24:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xya94",
              "author": "Cod3Conjurer",
              "text": "I'm not \"pushing Al content,\" I just use Al as a tool\n\n\nAnd appreciate the compliment on the site thanks man¬†",
              "score": 1,
              "created_utc": "2026-02-23 12:46:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rafi3g",
      "title": "I built an LLM gateway in Rust because I was tired of API failures",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rafi3g/i_built_an_llm_gateway_in_rust_because_i_was/",
      "author": "SchemeVivid4175",
      "created_utc": "2026-02-21 02:42:49",
      "score": 16,
      "num_comments": 16,
      "upvote_ratio": 0.7,
      "text": "I kept hitting the same problems with LLMs in production:\n\n\\- OpenAI goes down ‚Üí my app breaks\n\n\\- I'm using expensive models for simple tasks  \n\n\\- No visibility into what I'm spending\n\n\\- PII leaking to external APIs\n\nSo I built Sentinel - an open-source gateway that handles all of this.\n\n\n\nWhat it does:\n\n\\- Automatic failover (OpenAI down? Switch to Anthropic)\n\n\\- Cost tracking (see exactly what you're spending)\n\n\\- PII redaction (strip sensitive data before it leaves your network)\n\n\\- Smart caching (save money on repeated queries)\n\n\\- OpenAI-compatible API (just change your base URL)\n\n\n\nTech:\n\n\\- Built in Rust for performance\n\n\\- Sub-millisecond overhead\n\n\\- 9 LLM providers supported\n\n\\- SQLite for logging, DashMap for caching\n\n\n\nGitHub: [https://github.com/fbk2111/Sentinel](https://github.com/fbk2111/Sentinel)\n\n\n\nI'm looking for:\n\n\\- Feedback on the architecture\n\n\\- Bug reports (if you try it)\n\n\\- Ideas for what's missing\n\n\n\nBuilt this for myself, but figured others might have the same pain points.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rafi3g/i_built_an_llm_gateway_in_rust_because_i_was/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6mcwb7",
          "author": "Karyo_Ten",
          "text": "Seems very wrong.\n\nFirst of all, there is no tests.\n\nSecond, how do you accurately count the number of tokens?\n\nThird. The `assess_complexity` function is completely wrong, it hardcodes keyword in English, lower-case, doesn't account for typo or multilinguage or mixed-case.\n\nFourth. \"What's a croissant?\" and \"What's a pain au chocolat?\" are likely to have a high cosine similarity score and your semantic cache is likely to be very buggy. It also prevents regeneration of answers.",
          "score": 4,
          "created_utc": "2026-02-21 16:17:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6moy6b",
              "author": "LatentSpaceLeaper",
              "text": ">First of all, there is no tests.\n\nü§£ Thank you and goodbye!\n\n(thank you for taking your time and giving OP constructive feedback. Hope OP is amenable to it.)",
              "score": 3,
              "created_utc": "2026-02-21 17:17:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6l1xhn",
          "author": "Ihavenocluelad",
          "text": "How does an llm gateway help you using expensive models for simple tasks lmao? Just call another provider? What differentiates this AI Gateway from LiteLLM Openrouter etc",
          "score": 2,
          "created_utc": "2026-02-21 11:14:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lakyj",
          "author": "esmurf",
          "text": "Is it smarter than opencode?¬†",
          "score": 1,
          "created_utc": "2026-02-21 12:30:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6m5fs6",
          "author": "airylizard",
          "text": "Yeah‚Ä¶ interchangeability isn‚Äôt a thing. What testing have you done? Because I know from personal experience that there is no world in which you just change out the model and it works flawlessly",
          "score": 1,
          "created_utc": "2026-02-21 15:40:20",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6nexn7",
              "author": "SchemeVivid4175",
              "text": "what model are you talking about , this is not a model training\n\n",
              "score": -1,
              "created_utc": "2026-02-21 19:27:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6p5r0z",
                  "author": "elbiot",
                  "text": "Lol did you even read your own post? Let's think. How could model interoperability relate to your post about routing requests to random models?",
                  "score": 3,
                  "created_utc": "2026-02-22 01:21:32",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6kkj9l",
          "author": "hopfi2k",
          "text": "Well done. Star absolutely ‚≠êÔ∏è deserved",
          "score": 0,
          "created_utc": "2026-02-21 08:23:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6lm5pk",
          "author": "Antic_Hay",
          "text": "I vibe-coded some data utilities in Rust that do video analysis, OCR, voice transcription etc. where I need near real-time performance ideally, rust made sense here because I could just say to claude \"optimise this for my M3 mac and make sure all cores are used even on a single file operation\".\n\nA gateway is a great idea, but I don't see the Rust value...though no better or worse than anything else. I mean node is single-threaded and interpreted, and can be performant if done right. But neither here nor there :)",
          "score": 0,
          "created_utc": "2026-02-21 13:51:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6jqn96",
          "author": "ai_hedge_fund",
          "text": "This is a good idea to put effort into\n\nStarred it and intend to check it out\n\nThank you",
          "score": -5,
          "created_utc": "2026-02-21 04:08:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6kbh5j",
              "author": "dry_garlic_boy",
              "text": "Why do all these LLM AI posts and\n\nresponses have extra lines between\n\nthe text? It's really fucking\n\nstupid.",
              "score": 9,
              "created_utc": "2026-02-21 06:56:49",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6l8ehl",
                  "author": "ai_hedge_fund",
                  "text": "You‚Äôre absolutely right!",
                  "score": 5,
                  "created_utc": "2026-02-21 12:12:40",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mphle",
                  "author": "PuddleWhale",
                  "text": "Open claw bouncing walls of text around and ending up with a carriage return AND a linefeed where there should be only one?",
                  "score": 1,
                  "created_utc": "2026-02-21 17:20:41",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6mattj",
                  "author": "Karyo_Ten",
                  "text": "They want to next line but don't know you need to end a line with an antislash \\ if you want next line without doubling it.\\\nLike so.",
                  "score": 0,
                  "created_utc": "2026-02-21 16:07:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8de88",
      "title": "Claude Sonnet 4.6 benchmark results: none reasoning beats GPT-5.2 with reasoning",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "author": "Exact_Macaroon6673",
      "created_utc": "2026-02-18 19:54:15",
      "score": 16,
      "num_comments": 8,
      "upvote_ratio": 0.83,
      "text": "We have been working on a private benchmark for evaluating LLMs. The questions cover a wide range of categories and because it is not public and gets rotated, models cannot train on it or game the results.\n\nWith Sonnet 4.6 dropping I ran it through and the results are worth talking about.\n\nSonnet 4.6 with reasoning off scores 0.648 overall. GPT-5.2 at low reasoning scores 0.604. That is not a rounding error and it has real cost implications for anyone running at scale.\n\nAt high reasoning it ties Gemini 3 Pro Preview at the top of our leaderboard with 0.719 overall, ahead of GPT-5.2 high at 0.649.\n\nHallucination resistance hits 0.921, the highest of any model we have tested. Gemini 3 Pro sits at 0.820, GPT-5.2 at 0.655. Social calibration at 0.905 and error detection at 0.848 are similarly the best we have seen.\n\nTo give credit where it is due, Gemini 3 Pro is still the better call for hard science. Philosophy 0.900 vs 0.767, chemistry 0.839 vs 0.710, economics 0.812 vs 0.750. It is not a sweep.\n\nThe honest caveat is sycophancy resistance at 0.716 is actually slightly below Sonnet 4.5 at high reasoning which scored 0.755. For a company that talks about this a lot, that is worth watching.\n\nIf reliability and hallucination resistance are your primary eval criteria nothing beats it right now.\n\nhttps://preview.redd.it/tj3yyj5t5bkg1.png?width=2588&format=png&auto=webp&s=260eac02f897164ffda778e0f332fe2b6df92890\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o651nov",
          "author": "EarEquivalent3929",
          "text": "Benchmarks don't matter at all. If you'd actually used sonnet4.6 you'd already know it's pretty bad and hallucinated constantly on simple tasks.\n\n\nBut this post was clearly written by ai",
          "score": 6,
          "created_utc": "2026-02-18 22:33:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65xq5z",
              "author": "Exact_Macaroon6673",
              "text": "ü´°",
              "score": -2,
              "created_utc": "2026-02-19 01:29:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65qjan",
          "author": "promptbid",
          "text": "The hallucination resistance number is the one that matters most for our use case. At 0.921 that is a meaningful gap from the field. For any application where the model is making recommendations or surfacing information to end users, hallucination is a trust killer that is hard to recover from.\n\nThe sycophancy regression is worth flagging though. In ad-adjacent applications where you are trying to get honest signal from a model about user intent, a model that agrees too readily is actually worse than one that pushes back. Curious if your benchmark breaks that down by prompt type at all.\n\nThe cost angle you raised on non-reasoning Sonnet beating GPT-5.2 with reasoning is underrated. At scale that is not just a cost story, it is a latency story too. What does the benchmark show on response consistency across runs?",
          "score": 1,
          "created_utc": "2026-02-19 00:47:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666eyo",
          "author": "kubrador",
          "text": "sonnet really said \"fine i'll be good at something\" after spending three years being the middle child of the claude family",
          "score": 1,
          "created_utc": "2026-02-19 02:20:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66a5eq",
          "author": "EbbNorth7735",
          "text": "Now do Qwen 3.5 397B",
          "score": 1,
          "created_utc": "2026-02-19 02:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66o35y",
          "author": "Tema_Art_7777",
          "text": "Yes this kind of stuff is not useful at all - fleeting moments in time. Just pick one and do your tasks - its the outcome that matters, not model du jour.",
          "score": 1,
          "created_utc": "2026-02-19 04:07:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h9258",
              "author": "Useful-Process9033",
              "text": "Agreed. Model leaderboards flip every few weeks. Pick whatever works for your use case, build good evals, and swap models when it actually matters for your metrics. Chasing the latest benchmark winner is a waste of engineering time.",
              "score": 1,
              "created_utc": "2026-02-20 19:41:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67hso7",
          "author": "Low-Exam-7547",
          "text": "Can we not use the word \"dropping\" in this context? It's a music industry term for releasing records. It's found its way into enough of life. In this context it's just confusing. Let's be adults.",
          "score": 1,
          "created_utc": "2026-02-19 08:02:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7d29g",
      "title": "PlaceboBench: New benchmark on SOTA LLM hallucinations in pharma",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/3bzaibbzd3kg1.jpeg",
      "author": "aiprod",
      "created_utc": "2026-02-17 17:45:34",
      "score": 14,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7d29g/placebobench_new_benchmark_on_sota_llm/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5wzh3c",
          "author": "Competitive-Garage-4",
          "text": "Do not ask software engineer to recommend you pills.",
          "score": 2,
          "created_utc": "2026-02-17 19:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xg2je",
              "author": "aiprod",
              "text": "Haha yes, while I prefer Opus for coding, I guess Gemini would be the better pharmacist",
              "score": 2,
              "created_utc": "2026-02-17 20:32:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65pbyo",
          "author": "Overthinker512",
          "text": "I'm doing a similar project. I didn't use RAG, I just used the training Claude already had as core training. I use claude cowork so I could use multi-agent for recursive self improvement. LMK if you would like to see the prompting. I found that using recursive self improvement generated high quality answers.",
          "score": 1,
          "created_utc": "2026-02-19 00:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69bmor",
          "author": "aiprod",
          "text": "For anyone interested in a deeper dive on this, we‚Äôre hosting a live session in March. We‚Äôll also discuss quantitatively strategies to reduce these problems.\n\nSignup link is here: https://www.blueguardrails.com/en/live-session-pharma",
          "score": 1,
          "created_utc": "2026-02-19 15:50:47",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6erimh",
              "author": "Melodic_Reality_646",
              "text": "Couldn‚Äôt stop to read through the methodology. Why are the hallucination values so high? \n\nAt first glance it really just feels like a way to promote this blueguardrail product.",
              "score": 1,
              "created_utc": "2026-02-20 12:17:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6eswzu",
                  "author": "aiprod",
                  "text": "We did automated detection + human annotation + human review (3 passes, two of them human).\n\nThe values are so high because these models hallucinated so much. The data is available on hugging face if you would like to check yourself.\n\nThe models frequently mix up context, they are too imprecise in their language for the pharmaceutical domain, or they invent clinical protocols that are nowhere mentioned in the source data (directly violating the system prompt).",
                  "score": 1,
                  "created_utc": "2026-02-20 12:26:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8j5ob",
      "title": "How are you monitoring your Haystack calls/usage?",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/2cxt2c949ckg1.jpeg",
      "author": "gkarthi280",
      "created_utc": "2026-02-18 23:34:34",
      "score": 14,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8j5ob/how_are_you_monitoring_your_haystack_callsusage/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67z29j",
          "author": "Moki2FA",
          "text": "Ah yes, the classic quest for the Holy Grail of metrics. You‚Äôve got the basics covered, but let‚Äôs not forget the all important ‚Äúnumber of existential crises per request.‚Äù It‚Äôs crucial to monitor how many times you question your life choices while waiting for that model to respond. Jokes aside, consider tracking user feedback; after all, knowing if they‚Äôre actually using your app or just staring at it like a confused cat could be quite enlightening. And if you haven‚Äôt already, maybe throw in some ‚ÄúI told you so‚Äù logs for those moments when the LLM actually nails it.",
          "score": 3,
          "created_utc": "2026-02-19 10:49:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rd5tbq",
      "title": "there‚Äôs a new open source tool for checking ai agent security.... is it okay to share here?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rd5tbq/theres_a_new_open_source_tool_for_checking_ai/",
      "author": "Accomplished-Wall375",
      "created_utc": "2026-02-24 04:34:17",
      "score": 12,
      "num_comments": 6,
      "upvote_ratio": 0.93,
      "text": "hey everyone,  \n  \ncame across a newly released free, open source tool designed to help developers and security teams evaluate the security of ai agents‚Äô skills, tools, and integrations. it focuses on spotting issues like overly broad permissions, unsafe tool access, and weak guardrails before anything goes live in production.\n\nthere‚Äôs also a podcast episode that dives deeper into ai security, emerging risks, and where the tech is heading:  \n[https://open.spotify.com/show/5c2sTWoqHEYLrXfLLegvek](https://open.spotify.com/show/5c2sTWoqHEYLrXfLLegvek)\n\ncurious... if this would be the right place to share the repo and get feedback from the community.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rd5tbq/theres_a_new_open_source_tool_for_checking_ai/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o73010q",
          "author": "Aggravating_Log9704",
          "text": "The podcast sounds nice but the repo is where the meat is. Does it support custom threat models? A big issue with AI security platforms is they assume one size fits all. Real teams have very different risk profiles. If it lets you plug in bespoke rules or simulated attacks that is legit.",
          "score": 1,
          "created_utc": "2026-02-24 04:42:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o734lct",
          "author": "Any_Artichoke7750",
          "text": "I‚Äôd love to know if it integrates with CI/CD. Static analysis during dev is fine, but the real win is catching risky permissions before deploy. If it hooks into GitHub actions or similar it‚Äôs already ahead of most toy tools.",
          "score": 1,
          "created_utc": "2026-02-24 05:15:39",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o739cuz",
          "author": "Severe_Part_5120",
          "text": "this looks promising. i have been building some personal ai projects that interact with api‚Äôs and local scripts, and I‚Äôve had zero way to test how safe they are. even simple things like accidentally exposing api keys or letting an agent delete something it shouldn‚Äôt can be a huge problem. a tool like this seems like it could be really valuable for people testing things in a sandbox environment before going live.",
          "score": 1,
          "created_utc": "2026-02-24 05:53:08",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o73owa8",
          "author": "Bmaxtubby1",
          "text": "It‚Äôs probably fine to share, especially since it‚Äôs open source and directly relevant to AI agents and security. But context matters. If you just paste a repo link and a podcast, it can look like promotion. If you explain what the tool actually does, how it evaluates permissions, and where it might fail, it feels like a genuine discussion.\n\nAlso, if it‚Äôs your project, say that upfront. Most dev communities are okay with creators sharing their own tools as long as they‚Äôre transparent and open to feedback. Hidden promotion is what usually triggers backlash.",
          "score": 1,
          "created_utc": "2026-02-24 08:09:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75czpr",
          "author": "penguinzb1",
          "text": "the permissions-first approach is the right starting point, but with agents the structural analysis only catches a subset of the real exposure. the rest shows up when you run it against actual inputs. an agent that looks well-scoped at the permission level will still take unexpected actions under specific input combinations nobody mapped out during design. the behavioral gaps only surface when you run it through the scenarios that actually show up in your traffic before shipping.",
          "score": 1,
          "created_utc": "2026-02-24 15:16:59",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o75kcju",
          "author": "Sea-Sir-2985",
          "text": "the permissions-first approach is a good start but the real risk with agents is runtime behavior not just static config... an agent can have perfectly scoped permissions and still do unexpected things depending on what inputs it gets. i've seen agents with read-only access still cause problems by flooding APIs with requests\n\nthe CI/CD integration question is the right one though, catching risky permissions before deploy rather than after something goes wrong is where the actual value is",
          "score": 1,
          "created_utc": "2026-02-24 15:51:06",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1raweed",
      "title": "Anyone else noticing that claude code allocates a fixed number of subagents regardless of dataset size?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1raweed/anyone_else_noticing_that_claude_code_allocates_a/",
      "author": "ddp26",
      "created_utc": "2026-02-21 17:05:49",
      "score": 9,
      "num_comments": 2,
      "upvote_ratio": 0.92,
      "text": "I gave claude code a large fuzzy matching task ([https://everyrow.io/docs/case-studies/match-clinical-trials-to-papers](https://everyrow.io/docs/case-studies/match-clinical-trials-to-papers)) and claude independently designed a TF-IDF pre-filtering step, spun up 8 parallel subagents, and used regex for direct ID matching. But it used exactly 8 subagents whether the dataset was 200 or 700 rows on the right side, leading to the natural consequence of how coding agents plan: they estimate a reasonable level of parallelism and stick with it. Even as the dataset grows, each agent's workload increases but the total compute stays constant. \n\nI tried prompting it to use more subagents and it still capped at 8. Ended up solving it with an MCP tool that scales agent count dynamically, but curious if anyone's found a prompting approach that works. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1raweed/anyone_else_noticing_that_claude_code_allocates_a/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6owbkk",
          "author": "kubrador",
          "text": "claude's parallelism is like a guy who always orders 8 tacos regardless of how hungry he is, just with worse scaling implications.",
          "score": 1,
          "created_utc": "2026-02-22 00:23:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q1wy4",
          "author": "Ok_Prize_2264",
          "text": "I ran into a similar bottleneck with parallelism caps when we were scaling our RAG agents last month. It honestly feels like these coding agents hit a ceiling because they can‚Äôt verify if adding more compute actually improves the output quality or just burns tokens. We started using a proper eval pipeline to monitor how the subagents were actually performing across different dataset sizes and it helped us catch where the logic was stalling. It really made the whole debugging process a lot smoother once we integrated Confident AI.",
          "score": 1,
          "created_utc": "2026-02-22 05:00:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9dbt6",
      "title": "How do you test LLM for quality ?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "author": "Easy_Ask5883",
      "created_utc": "2026-02-19 22:19:05",
      "score": 8,
      "num_comments": 15,
      "upvote_ratio": 1.0,
      "text": "I'm building something for AI teams and trying to understand the problem better.\n\n1. Do you manually test your AI features? \n\n2. How do you know when a prompt change breaks something?\n\n  \nAt AWS we have tons of associates who do manual QA (mostly irrelevant as far as I could see) but I dont think startups and SMBs are doing it. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6bn718",
          "author": "Comfortable-Sound944",
          "text": "As with any QA testing, some don't do it, some do it badly, some do it well but manual, some automated it, and many adjust it over time as it makes sense.",
          "score": 2,
          "created_utc": "2026-02-19 22:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c8hjz",
          "author": "charlesthayer",
          "text": "I write Evals (well agentic evals). Meaning\n\n1. A way to score your output. (e.g. llm-as-judge or jury)\n2. A set of inputs to test.\n3. A fast and simple way to run this. (like a benchmark)\n\nThere are many ways to achieve this, but you can start very simply and grow. I use Arize Phoenix for traces/spans, and they have large-scale Eval features.\n\n\\- Arize Phoenix Evals: [https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals](https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals)  \n\\- Article I wrote: [https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f](https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f)\n\n\\- Commercial tool (Braintrust evals): [https://www.braintrust.dev/docs/evaluation](https://www.braintrust.dev/docs/evaluation)",
          "score": 2,
          "created_utc": "2026-02-20 00:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6h8xnx",
              "author": "Useful-Process9033",
              "text": "LLM-as-judge is underrated for catching regressions fast. The key is having a diverse enough input set that you actually cover your edge cases. Most teams test the happy path and then get surprised when a prompt change breaks some obscure but critical scenario.",
              "score": 2,
              "created_utc": "2026-02-20 19:40:38",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6e2yc7",
              "author": "anuragsarkar97",
              "text": "I'll take a look at those. Also do you keep changing your evals constantly? Or use vibe coding to create evals as well.\n\nHow do you decide which model to use and when",
              "score": 1,
              "created_utc": "2026-02-20 08:44:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6mv7kn",
                  "author": "charlesthayer",
                  "text": "I'm adding inputs and updating my llm-as-judge (eval tests) all the time as I hit problems. One thing I'd like to do more is dig into my Arize Phoenix traces more regularly to spot cases I missed. Right now, I'm bug-report driven, but I'd like to make this automated.",
                  "score": 1,
                  "created_utc": "2026-02-21 17:49:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6btgbh",
          "author": "Dimwiddle",
          "text": "It's always going to be a mix of automated and manual. There's also some cool ideas using skills with a QA agent, but that doesn't sound that ideal to me. \n\nI've been looking at ways to make AI code less 'viby' and have been experimenting with translating specs in to machine verifiable contracts, using test stubs. So far it's reduced a good amount bugs.",
          "score": 1,
          "created_utc": "2026-02-19 23:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c54b0",
          "author": "zZaphon",
          "text": "https://replayai-web.fly.dev",
          "score": 1,
          "created_utc": "2026-02-20 00:17:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c5gbe",
          "author": "paulahjort",
          "text": "Run the same prompt suite across multiple model checkpoints and track regression automatically in Weights&Biases.\n\nThe infra side of this is underrated too. Teams often skip systematic eval because spinning up a GPU to run a full eval suite feels heavyweight. Try a CLI tool like Terradev.\n\n[*github.com/theoddden/terradev*](http://github.com/theoddden/terradev)",
          "score": 1,
          "created_utc": "2026-02-20 00:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6diz7p",
          "author": "Ok_Constant_9886",
          "text": "We use deepeval (open-source): [https://github.com/confident-ai/deepeval](https://github.com/confident-ai/deepeval)\n\nAlso has a commercial platform confident ai: [https://www.confident-ai.com/](https://www.confident-ai.com/)",
          "score": 1,
          "created_utc": "2026-02-20 05:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dr5dc",
          "author": "Slight_Republic_4242",
          "text": "We learned this the hard way. At first, we ‚Äútested‚Äù by just trying prompts ourselves and saying, ‚ÄúLooks good.\n\nThen one small prompt **change** broke.: formatting, tone, edge cases and sometimes logic\n\nAnd we didn‚Äôt notice until a user complained. LLMs don‚Äôt fail loudly.  \nThey fail quietly.\n\nNow we:\n\na. Keep fixed test inputs\n\nb. Compare outputs before & after changes\n\nc. Check edge cases on purpose\n\nd. Track regressions like real software\n\nIt‚Äôs not perfect.  \nBut treating prompts like code changed everything.",
          "score": 1,
          "created_utc": "2026-02-20 06:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6driw5",
              "author": "anuragsarkar97",
              "text": "That makes sense I'm doing the same thing too. I guess time to build a product out of it.\n10-15% of my time I'm trying to fix either the system prompt of formating or something else",
              "score": 1,
              "created_utc": "2026-02-20 06:57:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e2r8n",
          "author": "AnythingNo920",
          "text": "in reality most SMBs do vibe testing, unless benchmarks are their key selling point. ",
          "score": 1,
          "created_utc": "2026-02-20 08:42:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e3108",
              "author": "anuragsarkar97",
              "text": "Interesting, so it's not so high on priority list. But eventually they need know how is the AI performing in some way right?",
              "score": 1,
              "created_utc": "2026-02-20 08:45:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6llof5",
                  "author": "AnythingNo920",
                  "text": "Absolutely right. They need to, but the average Joe in an SMB can't tell the difference between BLEU, ROUGE, Fluency, Accuracy, Recall or whatever other metric u wanna use. \n\nSo they do vibe testing. This feels more tangible. \nAt least thats my impression so far.",
                  "score": 1,
                  "created_utc": "2026-02-21 13:48:29",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6ygei2",
          "author": "khureNai05",
          "text": "For me, glm 4.7 runs small test scripts + real tasks, check outputs vs expected, rerun if weird. keeps QA low-effort but still catches most breakages.",
          "score": 1,
          "created_utc": "2026-02-23 14:33:35",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1rb1j9w",
      "title": "Bmalph now bundles Ralph's autonomous loop and stable BMAD to Codex, Cursor, Windsurf, Copilot and Aider",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/bauxbopzowkg1.png",
      "author": "Woclaw",
      "created_utc": "2026-02-21 20:25:37",
      "score": 8,
      "num_comments": 3,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rb1j9w/bmalph_now_bundles_ralphs_autonomous_loop_and/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o6omy7n",
          "author": "CommercialComputer15",
          "text": "Looks good, I‚Äôll give it a try. So you‚Äôre saying this is a big improvement over regular Claude Code etc CLI?",
          "score": 2,
          "created_utc": "2026-02-21 23:25:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6xdx0f",
              "author": "Woclaw",
              "text": "Where it shines is projects with multiple moving parts. The problem with vanilla Claude Code on bigger projects isn't that it's bad at coding, it's that it has no memory of the bigger picture. You end up re-explaining context, it makes decisions that conflict with earlier ones, and the architecture drifts.\n\nbmalph doesn't make the AI smarter. It makes it better informed. The planning phase produces docs that act as a persistent spec, so when Ralph implements story 5, it still knows what was decided during story 1.\n\nFor quick tasks like fixing a bug or writing a script, it's overkill. But for something with 10+ stories across multiple modules, the planning phase alone saves you from a lot of rework.",
              "score": 1,
              "created_utc": "2026-02-23 09:52:17",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o71fega",
                  "author": "guglyguglygoo",
                  "text": "i will also try it when i find time. no experience at all, am using spec kit. do you have any comparison? as far as i understand bmad is also a sdd framework which you adapted to work with ralph instead of the \"usual\" implementation step of bmad? \n\nif so we built the same thing for githubs spec kit and i will compare the 0shot end to end performance in a controlled setting for a random medium complexity challenge to [https://github.com/T-0-co/t-0-spec-kit-ralph](https://github.com/T-0-co/t-0-spec-kit-ralph)\n\nI experiment a lot with native cc vs. addons like yours with more or less additional memory features and so on. i still think the simple loop is the actual wonder, it forces you to construct and manage the context across the multiple instances. the rest can be configured per project / spec. \n\nIs there a reason you dont use keywords like \"spec driven\", \"sdd\" or \"specifications\" more often? would certainly make this project easier to find. or am i missing the point? ",
                  "score": 1,
                  "created_utc": "2026-02-23 23:07:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9z30r",
      "title": "Finally moved our RAG eval from manual vibes to actual unit tests",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9z30r/finally_moved_our_rag_eval_from_manual_vibes_to/",
      "author": "Key_Review_7273",
      "created_utc": "2026-02-20 15:55:40",
      "score": 6,
      "num_comments": 12,
      "upvote_ratio": 0.67,
      "text": "We‚Äôve been struggling with our RAG pipeline for months because every time we tweaked a prompt or changed the retrieval chunk size something else would secretly break. Doing manual checks in a spreadsheet was honestly draining and we kept missing hallucinations.\n\nI finally integrated DeepEval into our CI and started pushing the results to Confident AI for the dashboarding part. The biggest win was setting up actual unit tests for faithfulness and answer relevancy. It caught a massive regression last night where our latest prompt was making the model sound more confident but it was actually just making stuff up.\n\nCurious how everyone else is handling automated evals in production? Are you guys building custom scripts or using a specific framework to track metrics over time?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9z30r/finally_moved_our_rag_eval_from_manual_vibes_to/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6l2amw",
          "author": "Ihavenocluelad",
          "text": "Shouldnt you add #sponsored #ad",
          "score": 1,
          "created_utc": "2026-02-21 11:18:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6q3ybx",
          "author": "BeautifulKangaroo415",
          "text": "That‚Äôs weird, I had it running in like ten minutes. They updated the docs recently and the DeepEval integration is actually pretty smooth now. Might be worth checking the newer quickstart guide if you haven't looked at it lately because it definitely handled our agent traces without any issues.",
          "score": 1,
          "created_utc": "2026-02-22 05:16:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6hhdao",
          "author": "MissJoannaTooU",
          "text": "I'll check it out thanks",
          "score": 0,
          "created_utc": "2026-02-20 20:21:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fwkea",
          "author": "YeahOkayGood",
          "text": "DeepEval is the worst option, why are you using that garbage",
          "score": -5,
          "created_utc": "2026-02-20 15:58:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6fyejy",
              "author": "InfraScaler",
              "text": "Because Op is here just to promote that trash.",
              "score": 5,
              "created_utc": "2026-02-20 16:07:20",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g00z4",
              "author": "Howdareme9",
              "text": "Any recommendations?",
              "score": 2,
              "created_utc": "2026-02-20 16:14:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g9i2v",
              "author": "techperson1234",
              "text": "Yeah... Tried it out literally couldn't get it working. Maybe it's improved in the last few months but based on this comment I doubt it",
              "score": 2,
              "created_utc": "2026-02-20 16:57:33",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g3x15",
              "author": "Budget-Length2666",
              "text": "What would you use?",
              "score": 1,
              "created_utc": "2026-02-20 16:32:16",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6g7x7p",
              "author": "vogut",
              "text": "Huh? It's the best option",
              "score": 1,
              "created_utc": "2026-02-20 16:50:19",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6q6e8s",
              "author": "Easy_Stick_6500",
              "text": "Not sure why everyone is tripping lol. I had a few issues with the docs at first too but once you get the decorators set up it literally saves so much time. We‚Äôve been using Confident AI for our production traces for a month now and haven't found anything else that handles custom metrics this well. Maybe try the latest version because it‚Äôs definitely not trash for us.",
              "score": 1,
              "created_utc": "2026-02-22 05:36:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6h7hr6",
          "author": "Ok_Prize_2264",
          "text": "I‚Äôve been using Confident AI for the tracing side of things lately and it is actually a lifesaver for debugging multi step agents. Being able to see exactly which span failed without digging through raw logs saves so much time. The DeepEval metrics are solid too since they actually give you a reason why a test failed instead of just a random score.",
          "score": -1,
          "created_utc": "2026-02-20 19:33:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6tphmo",
              "author": "DARK_114",
              "text": "I totally agree with the tracing part. It is honestly frustrating when an agent loops and you have no idea why but seeing the logic flow clearly makes it so much easier to fix. Having those specific reasons for failure instead of just numbers actually helps with quick iterations too.",
              "score": 1,
              "created_utc": "2026-02-22 19:26:09",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1rb1z2t",
      "title": "How do you detect silent output drift in LLM pipelines?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1rb1z2t/how_do_you_detect_silent_output_drift_in_llm/",
      "author": "Lorenzo_Kotalla",
      "created_utc": "2026-02-21 20:43:48",
      "score": 6,
      "num_comments": 7,
      "upvote_ratio": 0.81,
      "text": "I am running into something that feels tricky to monitor in LLM systems: silent output drift.\n\nNot obvious failures, but gradual changes in tone, structure, or reasoning quality over time. The outputs still look ‚Äúvalid‚Äù, but they slowly move away from what the system was originally tuned for.\n\nThis seems to happen even without major prompt changes, sometimes just from model updates, context shifts, or small pipeline tweaks.\n\nFor those running LLMs in production or long-lived tools:\n\n* How do you detect this kind of drift early?\n* Do you rely on periodic sampling, regression datasets, structured output checks, or something else?\n* Have you found any signals that reliably indicate quality decay before users notice it?\n\nCurious what has actually worked in practice.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1rb1z2t/how_do_you_detect_silent_output_drift_in_llm/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6num44",
          "author": "andy_p_w",
          "text": "So it does not help with random quality changes in the model (I have observed behavior in OpenAI for the gpt-5 reasoning models that to me appears to be clear degradation that may last for a day and then go back to normal -- so not sure what is happening behind the scenes).\n\nBut more model upgrades, we have a set of test cases we look to make sure no regressions when upgrading models. (And it is useful if a cheaper model comes out to test with the cheaper model as well.) ",
          "score": 3,
          "created_utc": "2026-02-21 20:49:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6oyite",
          "author": "kubrador",
          "text": "set up a panel of like 5-10 \"canary prompts\" that you run weekly against the same model version and compare outputs with cosine similarity or just eyeball them. sounds lazy but it catches 90% of weird drift before users do.\n\n\n\nthe real move though is having a frozen reference dataset of outputs from month 1 that you score against periodically. if your current outputs drift >15% in whatever metric matters to you, something broke.",
          "score": 3,
          "created_utc": "2026-02-22 00:36:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6r7ww8",
          "author": "vanbrosh",
          "text": "LLM should not be used for now in cases where such unnotably drift impacts. There are quite a lot of tasks where LLM can fit great as automatization but not as crucial decision making. I would not recommend you doing something that can have bad consequences with LLM.  \nStructured output checks are great for detecting recursive repetitions drifts which nowerdays happen even with Gemini, OpenAI and literally any LLM, but not every task is possible to do with schema constrains - sometimes you need a stream / agentic chat, and structured outputs will kill a stream (makes no sense because streamed JSON is broken JSON)  \n  \nIf you use structured output (and not pure text streaming) - also one simple technique we use - insert a random secret token into prompt at random position (on sentense level) on every request and ask model to detect it in addition to main task. If it is there - model still understands sense and does predictable things. I did similar in my benchmark test [https://devforth.io/insights/self-hosted-gpt-real-response-time-token-throughput-and-cost-on-l4-l40s-and-h100-for-gpt-oss-20b/](https://devforth.io/insights/self-hosted-gpt-real-response-time-token-throughput-and-cost-on-l4-l40s-and-h100-for-gpt-oss-20b/)",
          "score": 2,
          "created_utc": "2026-02-22 11:26:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6nx3zi",
          "author": "Abu_BakarSiddik",
          "text": "For critical and measurable outputs, we maintain datasets and run evaluations periodically.   \n  \nFor general LLM responses, we‚Äôve been evaluating them manually.",
          "score": 1,
          "created_utc": "2026-02-21 21:02:53",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6oqnvg",
          "author": "zZaphon",
          "text": "https://replayai-web.fly.dev",
          "score": 1,
          "created_utc": "2026-02-21 23:48:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pafkb",
          "author": "Clear-Dimension-6890",
          "text": "Here is something that could help https://medium.com/@dami.gupta/the-forgetting-problem-engineering-persistent-intelligence-in-claude-code-bd2e4c59711a",
          "score": 1,
          "created_utc": "2026-02-22 01:51:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6pj38q",
          "author": "teambyg",
          "text": "Evaluations running offline on a schedule, and then subsample live data against your evals to monitor drift.",
          "score": 1,
          "created_utc": "2026-02-22 02:48:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    }
  ]
}