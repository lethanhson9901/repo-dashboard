{
  "metadata": {
    "last_updated": "2026-02-20 17:10:00",
    "time_filter": "week",
    "subreddit": "LLMDevs",
    "total_items": 20,
    "total_comments": 148,
    "file_size_bytes": 144580
  },
  "items": [
    {
      "id": "1r6nw3e",
      "title": "AI Coding Agent Dev Tools Landscape 2026",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/gm88nuyrlxjg1.png",
      "author": "bhaktatejas",
      "created_utc": "2026-02-16 22:20:01",
      "score": 328,
      "num_comments": 39,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6nw3e/ai_coding_agent_dev_tools_landscape_2026/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5ri3mi",
          "author": "bhaktatejas",
          "text": "link [https://www.morphllm.com/market-map](https://www.morphllm.com/market-map)",
          "score": 5,
          "created_utc": "2026-02-16 22:20:09",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "o5sbifa",
          "author": "btdeviant",
          "text": "It's weird how many of these guides and people are sleeping on [Strands](https://strandsagents.com/latest/). Hands down the most dead simple, capable provider agnostic agentic framework out there.. swings far above it's weight. ",
          "score": 5,
          "created_utc": "2026-02-17 01:03:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5t9rlv",
              "author": "teambyg",
              "text": "Strands is also one of the smartest BETS from a future proofing perspective. Many of the small start up frameworks will die. Many probably very soon, so trusting in bigger names is likely to lead to long term viability (Lindy Effect). Provider frameworks, AWS, and the Pydantic team are probably the only one's I would consider right now for any enterprise application",
              "score": 2,
              "created_utc": "2026-02-17 04:38:31",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5vjcfg",
                  "author": "echology-io",
                  "text": "thanks for the insight. I will check it out. ",
                  "score": 1,
                  "created_utc": "2026-02-17 15:02:17",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o61bve5",
                  "author": "yeathatsmebro",
                  "text": "Vercel's AI SDK has someone that is 100% dedicated on the project and is not sketchy. Only if you use Typescript though.",
                  "score": 1,
                  "created_utc": "2026-02-18 11:39:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o5wst35",
              "author": "kabs1194",
              "text": "I've really appreciated LangGraph and my own custom context management, any thoughts on comparison with Strands?",
              "score": 1,
              "created_utc": "2026-02-17 18:42:46",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o5swyy1",
              "author": "AdditionalWeb107",
              "text": "its yet another framework - and haven't we gotten pass this point that its just one while loop. The real hard part is the stuff around the loop",
              "score": 1,
              "created_utc": "2026-02-17 03:13:20",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5t554z",
                  "author": "btdeviant",
                  "text": "Right. The salient point is its abstractions allow one to focus more on ‚Äúthe stuff around the loop‚Äù. \n\nIt‚Äôs a well designed framework and more tailored toward modern, multi-agent architectures compared to nearly all the others in that list, majority of which are relative dinosaurs and objectively a much bigger pain to work with for complex, code-first workflows. \n\nGive it a shot! I have no affiliation, just used most of them and found Strands a great blend of depth and breadth, especially with their (experimental) BIDI. Just a breeze to work with compared to all the others.",
                  "score": -1,
                  "created_utc": "2026-02-17 04:06:31",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5rxdge",
          "author": "fredandlunchbox",
          "text": "No conductor?",
          "score": 1,
          "created_utc": "2026-02-16 23:42:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud25m",
              "author": "bhaktatejas",
              "text": "added!",
              "score": 1,
              "created_utc": "2026-02-17 10:22:41",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5s84h7",
          "author": "skarpa10",
          "text": "I think Google ADK supposed to be GitHub Copilot SDK.",
          "score": 1,
          "created_utc": "2026-02-17 00:44:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uexh5",
              "author": "Darxeal",
              "text": "no, both exist",
              "score": 2,
              "created_utc": "2026-02-17 10:39:51",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5sde7c",
          "author": "LoyalLittleOne",
          "text": "There's that many ?",
          "score": 1,
          "created_utc": "2026-02-17 01:15:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud2lc",
              "author": "bhaktatejas",
              "text": "theres even more",
              "score": 2,
              "created_utc": "2026-02-17 10:22:49",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5v8jju",
              "author": "OkTry9715",
              "text": "AI slop is reproducing fast",
              "score": 1,
              "created_utc": "2026-02-17 14:05:10",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tydj1",
          "author": "j4ys0nj",
          "text": "Where would [Mission Squad](https://missionsquad.ai) go? What about OpenClaw?",
          "score": 1,
          "created_utc": "2026-02-17 08:03:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud3ez",
              "author": "bhaktatejas",
              "text": "wouldnt consider them coding agents, more general agents",
              "score": 1,
              "created_utc": "2026-02-17 10:23:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5u6rb9",
          "author": "Varqu",
          "text": "What's the point of putting nvidia out there? ",
          "score": 1,
          "created_utc": "2026-02-17 09:23:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ud64d",
              "author": "bhaktatejas",
              "text": "they have an inference service via brev. its not up to market standards. I've used it, but its getting better",
              "score": 2,
              "created_utc": "2026-02-17 10:23:42",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5vvk60",
          "author": "Terrible-Rooster1586",
          "text": "I think ellipsis is dead sadly. I was an early adopter but they lost their CTO/cofounder to cursor and haven‚Äôt posted anything on linked in in months",
          "score": 1,
          "created_utc": "2026-02-17 16:02:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zxnmt",
          "author": "infraPulseAi",
          "text": "Interesting landscape. Curious how many of these tools handle deterministic verification and signed execution receipts for agent-to-agent transactions ‚Äî that layer feels missing in most stacks.",
          "score": 1,
          "created_utc": "2026-02-18 04:31:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o635z39",
          "author": "Johhaidiidiralla",
          "text": "[https://zed.dev/](https://zed.dev/)",
          "score": 1,
          "created_utc": "2026-02-18 17:25:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65ntqp",
          "author": "Delicious-Word4776",
          "text": "So true! Thanks for sharing, it was very amusing.",
          "score": 1,
          "created_utc": "2026-02-19 00:32:44",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68llmj",
          "author": "hroyhong",
          "text": "Where do products like base44 and atoms fall? There's literally an ad of base44 in this post.",
          "score": 1,
          "created_utc": "2026-02-19 13:33:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6avwo0",
              "author": "bhaktatejas",
              "text": "good point, missed them ",
              "score": 1,
              "created_utc": "2026-02-19 20:19:38",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6c93j5",
          "author": "Solar8102",
          "text": "Crazy",
          "score": 1,
          "created_utc": "2026-02-20 00:40:41",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dep10",
          "author": "KSandhu95",
          "text": "Am I seeing that perplexitys comet browser and assistant is missing üëÄ",
          "score": 1,
          "created_utc": "2026-02-20 05:09:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s40kg",
          "author": "AdditionalWeb107",
          "text": "Missing the data plane for agentic apps. [https://github.com/katanemo/plano](https://github.com/katanemo/plano) \\- cuts between the framework and gateway category as delivery infrastructure",
          "score": 1,
          "created_utc": "2026-02-17 00:20:42",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r49we9",
      "title": "AI Developer Tools Landscape 2026",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/mhyf0n56qdjg1.png",
      "author": "Main-Fisherman-2075",
      "created_utc": "2026-02-14 03:29:03",
      "score": 265,
      "num_comments": 50,
      "upvote_ratio": 0.95,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r49we9/ai_developer_tools_landscape_2026/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5c7ogy",
          "author": "TheDeadlyPretzel",
          "text": "Instructor is not an agent framework, rather it is a structured output inference library.\n\nOn the other hand, Atomic Agents which was built on top of instructor IS an agent framework: [https://github.com/BrainBlend-AI/atomic-agents](https://github.com/BrainBlend-AI/atomic-agents)",
          "score": 2,
          "created_utc": "2026-02-14 13:50:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5eza1p",
              "author": "Main-Fisherman-2075",
              "text": "thanks for point that out",
              "score": 0,
              "created_utc": "2026-02-14 22:38:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5gvvsr",
          "author": "walkingbiscuit",
          "text": "For Agent Development missing Google ADK, and i don't know where you want to put Chrome browser now, since in the beta release it has WebMCP",
          "score": 1,
          "created_utc": "2026-02-15 06:37:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65p3n9",
              "author": "Main-Fisherman-2075",
              "text": "Actually my problem about the mcp section is almost all toolls have mcp now and it's hard to say which one is better because they are just same idea of using the product. I am trying to make it sth like hosting mcp etc. not sure yet",
              "score": 1,
              "created_utc": "2026-02-19 00:39:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hzhwd",
          "author": "kubrador",
          "text": "looking at this like it's supposed help me pick a tool but it just makes me feel like i'm colorblind at a rave",
          "score": 1,
          "created_utc": "2026-02-15 12:46:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5kxir2",
          "author": "afucher",
          "text": "Missing [ECA](https://eca.dev/)",
          "score": 1,
          "created_utc": "2026-02-15 22:00:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65p6z3",
              "author": "Main-Fisherman-2075",
              "text": "will check out!",
              "score": 1,
              "created_utc": "2026-02-19 00:40:25",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5ncjp9",
          "author": "bl_builder",
          "text": "This reminds me of AdTech landscape back in the day, 2019. https://static-prod.adweek.com/wp-content/uploads/2018/04/luma-1200.png",
          "score": 1,
          "created_utc": "2026-02-16 07:49:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65pat8",
              "author": "Main-Fisherman-2075",
              "text": "for market map there's a tons of versions i think haha. I think for me the most make sense thing is 1 for ai dev",
              "score": 1,
              "created_utc": "2026-02-19 00:41:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5sjsnv",
          "author": "kovai_nvs",
          "text": "LLM newbie here. What tools would you use to analyse data to identify patterns?",
          "score": 1,
          "created_utc": "2026-02-17 01:53:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65ofrh",
              "author": "Main-Fisherman-2075",
              "text": "Hey! I‚Äôll start with a quick self-intro üôÇ I‚Äôm with Keywords AI, where we‚Äôre building LLM observability.",
              "score": 1,
              "created_utc": "2026-02-19 00:36:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5t8fbm",
          "author": "KongAtReddit",
          "text": "if you are doing design, you may also want to check out budgetpixel AI, it is like figma+AI steroid. ",
          "score": 1,
          "created_utc": "2026-02-17 04:29:03",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5thhef",
          "author": "Full-Signature8997",
          "text": "Parallel AI under web scraping too",
          "score": 1,
          "created_utc": "2026-02-17 05:35:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65pjp4",
              "author": "Main-Fisherman-2075",
              "text": "sure!",
              "score": 1,
              "created_utc": "2026-02-19 00:42:24",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yw2g5",
          "author": "EvKoh34",
          "text": "https://posthog.com/ai",
          "score": 1,
          "created_utc": "2026-02-18 00:58:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65pob4",
              "author": "Main-Fisherman-2075",
              "text": "will add!",
              "score": 1,
              "created_utc": "2026-02-19 00:43:06",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o64d4xd",
          "author": "Healthy_Library1357",
          "text": "wild how half this landscape will be acquired or dead by 2027 and we‚Äôre all pretending it‚Äôs stable üò≠ the real question isn‚Äôt what‚Äôs on the map, it‚Äôs which of these tools devs actually keep after the free credits run out",
          "score": 1,
          "created_utc": "2026-02-18 20:40:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65pukf",
              "author": "Main-Fisherman-2075",
              "text": "so trying to put how I heard people using right now on top so, and push an update every week",
              "score": 1,
              "created_utc": "2026-02-19 00:44:04",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o69kw7p",
                  "author": "Healthy_Library1357",
                  "text": "that‚Äôs smart. usage > hype. weekly updates keep it alive.",
                  "score": 1,
                  "created_utc": "2026-02-19 16:35:24",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o67zbdl",
          "author": "SharpRule4025",
          "text": "AlterLab is missing from the web scraping section. We built it specifically for LLM and RAG pipelines. Structured JSON output instead of markdown dumps, tiered pricing so a static HTML page doesn't cost the same as a Cloudflare-protected SPA. alterlab.io",
          "score": 1,
          "created_utc": "2026-02-19 10:51:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c9lbg",
          "author": "Whend6796",
          "text": "Where did you find this?",
          "score": 1,
          "created_utc": "2026-02-20 00:43:35",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5abluh",
          "author": "economicscar",
          "text": "Prime intellect missing under inference and compute",
          "score": 1,
          "created_utc": "2026-02-14 04:03:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5br22k",
              "author": "Main-Fisherman-2075",
              "text": "will add right away",
              "score": 0,
              "created_utc": "2026-02-14 11:47:06",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ccb1u",
                  "author": "Equity_Harbinger",
                  "text": "Can you share the latest one please (which is also less blurry, because when I zoom the image, words are blurry beyond recognition)\n\n\n(Thank you for your contributions)",
                  "score": 1,
                  "created_utc": "2026-02-14 14:18:14",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5atgtt",
          "author": "Live-Speech-1058",
          "text": "Antigravity?",
          "score": 1,
          "created_utc": "2026-02-14 06:26:02",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5br5gi",
              "author": "Main-Fisherman-2075",
              "text": "I think I added it, I don't know why it's not there but definitely worth a try.",
              "score": 0,
              "created_utc": "2026-02-14 11:47:56",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bu98n",
          "author": "increasinglybold",
          "text": "Pi coding agent is great",
          "score": 1,
          "created_utc": "2026-02-14 12:14:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ezbgx",
              "author": "Main-Fisherman-2075",
              "text": "Will check it out",
              "score": 1,
              "created_utc": "2026-02-14 22:39:00",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bz0vl",
          "author": "Realistic-Damage2004",
          "text": "https://ainativedev.io/landscape\n\nHas been around for a while now. Is this published anywhere?",
          "score": 1,
          "created_utc": "2026-02-14 12:51:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65opp1",
              "author": "Main-Fisherman-2075",
              "text": "ours is here now: [https://www.keywordsai.co/market-map](https://www.keywordsai.co/market-map), trying to polish this further but.",
              "score": 1,
              "created_utc": "2026-02-19 00:37:44",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5djaiy",
          "author": "Neferio1",
          "text": "Greptile is a very good code review tool",
          "score": 1,
          "created_utc": "2026-02-14 18:02:24",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5ez8zy",
              "author": "Main-Fisherman-2075",
              "text": "1000%",
              "score": 1,
              "created_utc": "2026-02-14 22:38:36",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5fgo08",
              "author": "oXeNoN",
              "text": "How does it compare with other tools like CodeRabbit? Is CodeRabbit just spending more on marketing? üòÖ",
              "score": 0,
              "created_utc": "2026-02-15 00:24:40",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o5fuy08",
                  "author": "Neferio1",
                  "text": "We tested both and we choose Greptile over CodeRabbit just because Greptile can be ¬´¬†selfhosted¬†¬ª using Kubernetes or Docker. From a review perspective, Greptile and CodeRabbit are equivalent",
                  "score": 2,
                  "created_utc": "2026-02-15 01:56:50",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5bn5o0",
          "author": "mcd0g",
          "text": "Warp under coding agents missing. They really need to step up their PR game",
          "score": 0,
          "created_utc": "2026-02-14 11:11:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5br1u4",
              "author": "Main-Fisherman-2075",
              "text": "will add right away",
              "score": 1,
              "created_utc": "2026-02-14 11:47:03",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5bth4g",
          "author": "renntv",
          "text": "Great overview! Do you keep it on the web for linking, or just here on Reddit? ",
          "score": 0,
          "created_utc": "2026-02-14 12:07:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5etdza",
              "author": "Main-Fisherman-2075",
              "text": "Hey I keep it here: but the content inside is still not very polished yet. https://www.keywordsai.co/market-map I will try to add all the description comparison price etc inside",
              "score": 1,
              "created_utc": "2026-02-14 22:05:24",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5c2b8u",
              "author": "Code_Exists_Here",
              "text": "Yeh same question from me.",
              "score": 0,
              "created_utc": "2026-02-14 13:15:20",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5egtyh",
          "author": "funguslungusdungus",
          "text": "I need a link!",
          "score": 0,
          "created_utc": "2026-02-14 20:56:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5etiuy",
              "author": "Main-Fisherman-2075",
              "text": "https://www.keywordsai.co/market-map here you go! I will try to update weekly and the content in it",
              "score": 1,
              "created_utc": "2026-02-14 22:06:10",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5egxm5",
          "author": "Varqu",
          "text": "You can just use Claude Code.",
          "score": 0,
          "created_utc": "2026-02-14 20:57:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5fkv68",
          "author": "Disastrous-Maybe2501",
          "text": "Mistral Vibe missing in coding agents",
          "score": 0,
          "created_utc": "2026-02-15 00:50:22",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65owvd",
              "author": "Main-Fisherman-2075",
              "text": "will add",
              "score": 1,
              "created_utc": "2026-02-19 00:38:50",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8jw2b",
      "title": "Building an opensource Living Context Engine",
      "subreddit": "LLMDevs",
      "url": "https://v.redd.it/5cf7c7efeckg1",
      "author": "DeathShot7777",
      "created_utc": "2026-02-19 00:05:55",
      "score": 208,
      "num_comments": 57,
      "upvote_ratio": 0.97,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Help Wanted",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8jw2b/building_an_opensource_living_context_engine/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67phrl",
          "author": "SeaworthinessThis598",
          "text": "what is this sorcery or i mean graphery ...",
          "score": 12,
          "created_utc": "2026-02-19 09:18:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67pntd",
              "author": "DeathShot7777",
              "text": "üòÇ Knowledge Graph + Clustering Algorithm + AST Maps + Webgl rendering -- bit too nerdy i guess üòÖ",
              "score": 4,
              "created_utc": "2026-02-19 09:19:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o693jql",
                  "author": "Sorry_Swan_8997",
                  "text": "Love it üòç",
                  "score": 2,
                  "created_utc": "2026-02-19 15:10:31",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o67ptym",
                  "author": "SeaworthinessThis598",
                  "text": "please teach me how to conjure this potion can i contribute ?",
                  "score": 1,
                  "created_utc": "2026-02-19 09:21:30",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6anezs",
                  "author": "agrophobe",
                  "text": "Mama!!",
                  "score": 1,
                  "created_utc": "2026-02-19 19:38:22",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o66zptc",
          "author": "Crafty_Disk_7026",
          "text": "Can you post a comparison using it versus not?",
          "score": 6,
          "created_utc": "2026-02-19 05:28:32",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6771hd",
              "author": "DeathShot7777",
              "text": "Great suggestion, working on setting up evals, ( swe bench ).",
              "score": 4,
              "created_utc": "2026-02-19 06:27:13",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6fbz2g",
                  "author": "ViperAICSO",
                  "text": "A good benchmark study would be good, but I can tell you that doing it so its publishable like I did in  Stingy Context (https://arxiv.org/abs/2601.19929) is a bit of work.  The hard part is 'grading'... I skipped around this in the paper by measuring the 'fix' location accuracy rather than attempting to grade the fixes themselves.  Also I used LLM consensus grading rather than human-in-the-loop grading.",
                  "score": 1,
                  "created_utc": "2026-02-20 14:17:34",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dg9e7",
              "author": "Useful-Process9033",
              "text": "SWE-bench evals would be great but also consider measuring context retrieval accuracy separately. The knowledge graph is only useful if it surfaces the right files for a given task, and thats measurable independently of whether the agent can write the fix.",
              "score": 2,
              "created_utc": "2026-02-20 05:21:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6fcuy4",
                  "author": "DeathShot7777",
                  "text": "Any idea how do i test this? Are there benchmarks available for this too?",
                  "score": 1,
                  "created_utc": "2026-02-20 14:22:13",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o67937x",
          "author": "Several_Explorer1375",
          "text": "That‚Äôs amazing. Might try it tomorrow",
          "score": 2,
          "created_utc": "2026-02-19 06:44:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o679cv0",
              "author": "DeathShot7777",
              "text": "Thanks. Lemme know how it goes",
              "score": 2,
              "created_utc": "2026-02-19 06:46:58",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67n3jw",
          "author": "sleepnow",
          "text": "Looks pretty, but seems like performance would degrade pretty quickly",
          "score": 2,
          "created_utc": "2026-02-19 08:54:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67nplw",
              "author": "DeathShot7777",
              "text": "Ya the webapp can be used as a deeper deepwiki for mid sized repos. For actual usecase with MCP support it has gitnexus cli tool, i tried on a massive repo ( metafresh ) takes about 92 seconds to parse.",
              "score": 2,
              "created_utc": "2026-02-19 09:00:13",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o66m755",
          "author": "[deleted]",
          "text": "[removed]",
          "score": 1,
          "created_utc": "2026-02-19 03:54:59",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67726a",
              "author": "DeathShot7777",
              "text": "Thanks a lot",
              "score": 1,
              "created_utc": "2026-02-19 06:27:23",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67aqbg",
          "author": "TwistStrict9811",
          "text": "Very cool - I'll see how codex works with it",
          "score": 1,
          "created_utc": "2026-02-19 06:58:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67b70d",
              "author": "DeathShot7777",
              "text": "Great. Lemme know how it goes. It should work best on queries like \n\n\"whats the execution flow from API emdpoint to storage\",\n\n \"we want to split it into microservices eventually, show me the actual dependency boundaries\"\n\nOr debugging related queries",
              "score": 1,
              "created_utc": "2026-02-19 07:02:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67gdeo",
          "author": "NachosforDachos",
          "text": "Now that‚Äôs sexy",
          "score": 1,
          "created_utc": "2026-02-19 07:49:11",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ggxu",
              "author": "DeathShot7777",
              "text": "ü´†ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 07:50:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67j742",
          "author": "tineo_app",
          "text": "holy shit this belongs in an art gallery",
          "score": 1,
          "created_utc": "2026-02-19 08:15:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67jdfp",
              "author": "DeathShot7777",
              "text": "üòÇ thanks ü•Ä",
              "score": 1,
              "created_utc": "2026-02-19 08:17:32",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o67mucg",
          "author": "bunnydathug22",
          "text": "You looking for a team by chance ?",
          "score": 1,
          "created_utc": "2026-02-19 08:51:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "o67ng2d",
              "author": "DeathShot7777",
              "text": "Its opensource, would love contributions",
              "score": 1,
              "created_utc": "2026-02-19 08:57:36",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o67oua7",
                  "author": "bunnydathug22",
                  "text": "Its not the code that we are interested in. Nor is it oss.  We do [this](http://Www.citadel-nexus.com) totattly respect you and you work. If you change your mind hit us up.",
                  "score": 1,
                  "created_utc": "2026-02-19 09:11:36",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o68rich",
          "author": "SnooPeripherals5313",
          "text": "I love this! Great job.",
          "score": 1,
          "created_utc": "2026-02-19 14:06:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6esaga",
              "author": "DeathShot7777",
              "text": "Thanks",
              "score": 1,
              "created_utc": "2026-02-20 12:22:37",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o69i9f2",
          "author": "Able-Let-1399",
          "text": "At a time when more and more code is delivered by your personal AI pusher, this sounds like an excellent tool to keep it in check and even make it better. Kudos for connecting the dots üëç\n\nAny way to merge multiple graphs? For various reasons I have per-service repos.",
          "score": 1,
          "created_utc": "2026-02-19 16:22:49",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6et189",
              "author": "DeathShot7777",
              "text": "I do plan on multi repo graph, but you can also sort of use them right now. If you just index both the repos with gitnexus analyze, it manages a global registry of indexed repo which can be seen by the agent through MCP. So if u want to compare them or something in any claude code / cursor / etc,  they will be able to choose and change the repo graphs to compare them. You can just ask claude code or your preferred tool and it will do it naturally",
              "score": 1,
              "created_utc": "2026-02-20 12:27:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6diuy0",
          "author": "Upper-Emotion7144",
          "text": "What ever this is. It‚Äôs pretty.",
          "score": 1,
          "created_utc": "2026-02-20 05:42:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dj758",
              "author": "DeathShot7777",
              "text": "üòÅ",
              "score": 1,
              "created_utc": "2026-02-20 05:45:17",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dvlrl",
          "author": "AdCommon2138",
          "text": "This isn't open source. Polyform license is poison pill. Can't use it in commercial software, even to analyze code of any commercial software. Can you consider relicensing? I understand that you want to make money in future and you want now to get free feedback and hook users, but it will only tilt and anger people later when you rugpull. In case you would like to say \"Actually no because:\"\n\n\"Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\". Full text per claude below  \n\n\n    PolyForm Noncommercial 1.0.0\n    This is a source-available software license created by PolyForm Project. Here's what it means in plain terms:\n    What you CAN do:\n    View, use, and modify the source code\n    Share it with others\n    Use it for personal projects, research, education, or other non-commercial purposes\n    What you CANNOT do:\n    Use the software (or any derivative) for commercial purposes ‚Äî meaning you can't use it to make money, run a business, or as part of a paid product/service\n    Sublicense it under different terms\n    Key nuance ‚Äî what counts as \"commercial\"?\n    The license broadly defines commercial use as anything \"primarily intended for or directed toward commercial advantage or monetary compensation.\" This includes:\n    Using it in a SaaS product\n    Incorporating it into a paid app\n    Using it internally at a for-profit company to support revenue-generating activities\n    How it differs from open source:\n    It's not considered open source by the OSI definition, because true open source licenses cannot restrict commercial use. It's more accurately called source-available.\n    Who typically uses it:\n    Companies that want to share their code publicly (for transparency, community contributions, etc.) but reserve commercial rights ‚Äî often paired with a separate commercial license you can purchase.\n    Bottom line: Free to use for non-commercial work, but you need a separate agreement with the copyright holder to use it in any commercial context.",
          "score": 1,
          "created_utc": "2026-02-20 07:35:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dyhwg",
              "author": "DeathShot7777",
              "text": "Yeah i want to create an enterprise solution later ( only targeting corporate not devs or os community ) which will earn money, while I want to keep the project fully free and opensourced for everyone else. I m not very good with these licensing stuff and took the inspiration from mindsDB which have the same approach. So just to stop hyperscalers from taking it and giving out the exact same solution. \n\nIs that not opensource? Mindsdb is a reputed opensource project i found on GSOC",
              "score": 1,
              "created_utc": "2026-02-20 08:02:15",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dyvn7",
                  "author": "AdCommon2138",
                  "text": "It's not open sourced. It can't be used in any capacity in paid product as that would violate license terms. It means it cant even be downloaded or you could sue that someone could potentially use this internally.\n\nThis license isnt really about someone integrating your work into product and repackaging it. This license is about using your product at any stage which opens doors to being sued if they dont release their unrelated product under same license. \n\nLets say someone makes a game and will only once analyze code via your tool, they cant release that game unless they use same license.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:05:47",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "o6dz0oa",
                  "author": "AdCommon2138",
                  "text": "And to make matters even funnier if you ever used any of products with this license like Mindsdb and it inspired you to create your own solution you can be sued too. You would need to have team of 2 people, one of them would explain to second person what software with this license does and how it works and he gets license tainted, and second one would have to reimplement.",
                  "score": 1,
                  "created_utc": "2026-02-20 08:07:05",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o6dyoih",
              "author": "DeathShot7777",
              "text": "Maybe i need to read more on these license stuff. I hate these shit so much üò≠",
              "score": 1,
              "created_utc": "2026-02-20 08:03:59",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o6dzeaw",
                  "author": "AdCommon2138",
                  "text": "Honestly I know you dont want to, but MIT is just best. Everyone knows it, and if you get free riders its just part of life like you are using other libraries that are MIT licensed. For business itself you want to provide custom solutions so if business adapted your library to internal use they would still probably contact you to get customization done or you can have software build on top of this project. \n\nSource: 18 years or so in business of selling software. ",
                  "score": 1,
                  "created_utc": "2026-02-20 08:10:38",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6f1i12",
          "author": "MinuteCombination293",
          "text": "Amazing work, how is this different from traditional Language servers ?",
          "score": 1,
          "created_utc": "2026-02-20 13:20:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6f6zos",
              "author": "DeathShot7777",
              "text": "Perfect question, thanks for asking. \n\nLSP operate at the syntax/type level, so it answers question like where is this symbol.  \nGitnexus operates at architecture level \n\nSo basically LSP can tell you validateAuth is called in 5 places. Gitnexus can tell you validateAuth sits at step 3 of the AuthFlow process, belongs to the Authentication community, and changing it impacts 3 cross-community execution flows.   \n  \nApart from the main architectural difference, there are multiple other features offered by gitnexus MCP + CLI tool like skills ( debug skill, impact detection, audits, etc ) and also enriches claude code native tool ( grep, glob, bash ) with relational data so it always know exactly what is were, without spending a lot of tokens. \n\nHere is an example output from impact analyses skill. ( All these features are only possible coz of the graph based architecture )\n\nhttps://preview.redd.it/9rmde16pmnkg1.png?width=1388&format=png&auto=webp&s=1904f7fc0965173af38d2de4e90af295c5cd9c2f\n\n  \n",
              "score": 2,
              "created_utc": "2026-02-20 13:51:05",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o68wrfb",
          "author": "jeelm29",
          "text": "I'm new how do I even start bro",
          "score": 0,
          "created_utc": "2026-02-19 14:35:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6awtfg",
              "author": "SloSuenos64",
              "text": "I just pasted his post into Cursor and said \"implement this\". Done.",
              "score": 0,
              "created_utc": "2026-02-19 20:24:04",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6es6yc",
                  "author": "DeathShot7777",
                  "text": "ü§£ü§£ü§£ü§£ Nice approach",
                  "score": 1,
                  "created_utc": "2026-02-20 12:21:57",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r9136z",
      "title": "I looked into OpenClaw architecture to dig some details",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "author": "codes_astro",
      "created_utc": "2026-02-19 14:47:08",
      "score": 135,
      "num_comments": 15,
      "upvote_ratio": 0.96,
      "text": "OpenClaw has been trending for all the wrong and right reasons. I saw people rebuilding entire sites through Telegram, running ‚ÄúAI offices,‚Äù and one case where an agent wiped thousands of emails because of a prompt injection. That made me stop and actually look at the architecture instead of the demos.\n\nUnder the hood, it‚Äôs simpler than most people expect.\n\nOpenClaw runs as a persistent Node.js process on your machine. There‚Äôs a single Gateway that binds to localhost and manages all messaging platforms at once: WhatsApp, Telegram, Slack, Discord. Every message flows through that one process. It handles authentication, routing, session loading, and only then passes control to the agent loop. Responses go back out the same path. No distributed services. No vendor relay layer.\n\nhttps://preview.redd.it/pyqx126xqgkg1.png?width=1920&format=png&auto=webp&s=9aa9645ac1855c337ea73226697f4718cd175205\n\nWhat makes it feel different from ChatGPT-style tools is persistence. It doesn‚Äôt reset. Conversation history, instructions, tools, even long-term memory are just files under¬†`~/clawd/`. Markdown files. No database. You can open them, version them, diff them, roll them back. The agent reloads this state every time it runs, which is why it remembers what you told it last week.\n\nThe heartbeat mechanism is the interesting part. A cron wakes it up periodically, runs cheap checks first (emails, alerts, APIs), and only calls the LLM if something actually changed. That design keeps costs under control while allowing it to be proactive. It doesn‚Äôt wait for you to ask.\n\nhttps://preview.redd.it/gv6eld93rgkg1.png?width=1920&format=png&auto=webp&s=6a6590c390c4d99fe7fe306f75681a2e4dbe0dbe\n\nThe security model is where things get real. The system assumes the LLM can be manipulated. So enforcement lives at the Gateway level: allow lists, scoped permissions, sandbox mode, approval gates for risky actions. But if you give it full shell and filesystem access, you‚Äôre still handing a probabilistic model meaningful control. The architecture limits blast radius, it doesn‚Äôt eliminate it.\n\nWhat stood out to me is that nothing about OpenClaw is technically revolutionary. The pieces are basic: WebSockets, Markdown files, cron jobs, LLM calls. The power comes from how they‚Äôre composed into a persistent, inspectable agent loop that runs locally.\n\nIt‚Äôs less ‚Äúmagic AI system‚Äù and more ‚ÄúLLM glued to a long-running process with memory and tools.‚Äù\n\nI wrote down the detailed breakdown [here](https://entelligence.ai/blogs/openclaw)",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9136z/i_looked_into_openclaw_architecture_to_dig_some/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o69fwzn",
          "author": "ai_hedge_fund",
          "text": "Worthwhile writeup, thanks\n\nAlso, there is an SQLite database",
          "score": 14,
          "created_utc": "2026-02-19 16:11:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6aq0kn",
              "author": "wouldacouldashoulda",
              "text": "Yes it's for archival memory. They use embeddings for longer form memory. It's industry standard kind of, since Letta benchmarked it worked as good or better as more sophisticated methods.",
              "score": 8,
              "created_utc": "2026-02-19 19:50:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6abmlp",
          "author": "eatthebagels",
          "text": "yep, pretty spot on. Was able to replicate that logic and create our own type of 'claw like agent' pretty easily. I bet most hype comes from the non tech people using it.\n\n",
          "score": 13,
          "created_utc": "2026-02-19 18:42:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6amnct",
              "author": "Sunir",
              "text": "And that's awesome in its own regard. It shows you were people are excited; the technology is fun, but it's good to know there are customers and markets out there and people are happy. I'm old enough to remember geocities, which one can poopoo technically for its html design, but it was amazing culturally. Also technically in the backend it was amazing; it's hard to hate on the achievement Geocities had on opening up the web for people.",
              "score": 2,
              "created_utc": "2026-02-19 19:34:40",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dgb4g",
              "author": "Useful-Process9033",
              "text": "The architecture being simple is actually a feature not a bug. We took a similar approach with IncidentFox, keeping the core loop straightforward so the complexity lives in the skills not the runtime. Turns out most people want reliable ops automation, not clever abstractions.",
              "score": 2,
              "created_utc": "2026-02-20 05:21:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6bkl1q",
              "author": "BehindUAll",
              "text": "But from what the creator was saying in a couple of videos was it could install code by itself from github and then figure out how to use the project and then also rewrite existing code to send TTS audio into Telegram. So it's not 100% just the architecture  described here. Still not going to install it though. ",
              "score": 1,
              "created_utc": "2026-02-19 22:21:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6bomll",
          "author": "christophersocial",
          "text": "A decent overview, thank you for sharing. \n\nOne of the most important components at the core of OpenClaw is another open source project called Pi and Pi is responsible for a large portion of the heavy lifting in OpenClaw. \n\nPi has a number on components in its mono repo (pi-mono) but the 2 most relevant to OpenClaw‚Äôs success are the Agent and Coding-Agent.\n\nSo to get a sense of how OpenClaw really works a detailed architecture overview needs to examine and break out at least these sub-projects imo. Note: your tools automated analysis touches on it in the following section, ‚ÄúThe Agent Loop: From Message to Action‚Äù and probably elsewhere but should go deeper because how these 2 components work is key to how OpenClaw works. \n\nNote: I‚Äôm thinking the review tool should really detect and break out key sub-projects with the why, how, and what as a sub-project relates to the parent project. \n\nOpenClaw is an amazing experiment built on top of some amazing open source. \n\nNote: The automated code review tool you‚Äôre building that did the actual analysis did a very reasonable job but I think it‚Äôs still a bit too surface detail oriented - imo anyway. That said I suppose one could use this report as part of the ‚Äúbrainstorming‚Äù stage and use sections from the report when delving deeper. Basically I‚Äôm saying more meat is needed on the bone to use this as a blueprint - though that might not be the point of this report and the tool cdn actually go deeper already (Yes/No)?\n\nCheers,\n\nChristopher",
          "score": 5,
          "created_utc": "2026-02-19 22:42:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6djqif",
          "author": "Maybe123I",
          "text": "Thank you.  Nice write up.",
          "score": 2,
          "created_utc": "2026-02-20 05:49:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dpgeb",
          "author": "Santoshr93",
          "text": "Yes pretty much every serious developer guiding systems I talk to has pretty much the same view. But hey if you want to see a bit more cooler architecture, here‚Äôs one thing we released recently which is a full sde team autonomously working for hours. https://github.com/Agent-Field/SWE-AF",
          "score": 2,
          "created_utc": "2026-02-20 06:39:18",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c81az",
          "author": "Snoo_24581",
          "text": "Great analysis! The architecture deep dive is helpful. How do you think it compares to other open source LLM serving frameworks like vLLM or TGI for production use?",
          "score": 1,
          "created_utc": "2026-02-20 00:34:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cttfr",
          "author": "ManofC0d3",
          "text": "That persistence feature is possibly the most important advantage AI agents have over chat interfaces imo",
          "score": 1,
          "created_utc": "2026-02-20 02:47:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ekp26",
          "author": "premier_slack",
          "text": "pretty neat writeup. Haven't looked into the implementation but I'm wondering how does it manage LLM context window? is there any compaction mechanism similar to claude code?",
          "score": 1,
          "created_utc": "2026-02-20 11:25:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fy13v",
          "author": "jenil777007",
          "text": "Nice one. Thanks!",
          "score": 1,
          "created_utc": "2026-02-20 16:05:34",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6g39fv",
          "author": "Outrageous_Tiger_441",
          "text": "The security part is what sketches me out the most with these local agents especially after that email wipe story. I started plugging my agent loops into Confident AI lately just to run some red teaming and eval metrics before letting them touch my actual files. It‚Äôs been super helpful for catching those prompt injections and weird edge cases since it uses DeepEval to benchmark the reasoning steps. Definitely worth checking out if you want to keep using the persistent memory stuff without worrying about your agent going rogue.",
          "score": 1,
          "created_utc": "2026-02-20 16:29:17",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e5u5k",
          "author": "dezastrologu",
          "text": "Most downloaded agent was actually malware",
          "score": 0,
          "created_utc": "2026-02-20 09:11:44",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8if0v",
      "title": "Open Source LLM Tier List",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/y5i85f4hxbkg1.png",
      "author": "HobbyGamerDev",
      "created_utc": "2026-02-18 23:04:27",
      "score": 61,
      "num_comments": 21,
      "upvote_ratio": 0.9,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o66cy77",
          "author": "robogame_dev",
          "text": "https://preview.redd.it/tyl32sgg9dkg1.png?width=1518&format=png&auto=webp&s=db5e80f5180bd671427a25791a922540857c8aef\n\nThis is what it shows now",
          "score": 8,
          "created_utc": "2026-02-19 02:58:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6726h6",
          "author": "sergeant113",
          "text": "Minimax 2.5 where?",
          "score": 4,
          "created_utc": "2026-02-19 05:47:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o683h1m",
          "author": "Alex_1729",
          "text": "Step flash and Trinity should be on the list.",
          "score": 2,
          "created_utc": "2026-02-19 11:27:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o65yi8f",
          "author": "Guilty_Serve",
          "text": "ChatGPT oss is really that good? Honest question.",
          "score": 3,
          "created_utc": "2026-02-19 01:34:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "o683cyw",
              "author": "ScoreUnique",
              "text": "120b is a very good model. I won't hesitate saying it's o1 level at least. You can run it with fairly less hardware if you have a beefy GPU and if you like that openai style chat.",
              "score": 2,
              "created_utc": "2026-02-19 11:26:37",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o683ccr",
              "author": "Alex_1729",
              "text": "It's decent. Depends on what you need it for.",
              "score": 1,
              "created_utc": "2026-02-19 11:26:29",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o67mh1t",
              "author": "jnk_str",
              "text": "No",
              "score": 0,
              "created_utc": "2026-02-19 08:48:04",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o67a9z7",
          "author": "decentralize999",
          "text": "Wrong description. Open weight LLMs,  not open souce ones.\n\nAnd top list is joke. Where is step3.5-flash which is the best among open weight llms if compare benchmark points per 100B size.",
          "score": 3,
          "created_utc": "2026-02-19 06:54:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6at35n",
              "author": "silenceimpaired",
              "text": "Yeah, it's weird how that gets ignored.\n\nThat said, I roll my eyes whenever I see someone distinguish open weight vs open source. That's a joke. Nearly everyone who makes that complaint has 0 ability or resources to build a model from scratch.",
              "score": 1,
              "created_utc": "2026-02-19 20:05:46",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o659jcl",
          "author": "bebackground471",
          "text": "RemindMe! 8 days",
          "score": 1,
          "created_utc": "2026-02-18 23:14:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "o659oby",
              "author": "RemindMeBot",
              "text": "I will be messaging you in 8 days on [**2026-02-26 23:14:14 UTC**](http://www.wolframalpha.com/input/?i=2026-02-26%2023:14:14%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LLMDevs/comments/1r8if0v/open_source_llm_tier_list/o659jcl/?context=3)\n\n[**1 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLLMDevs%2Fcomments%2F1r8if0v%2Fopen_source_llm_tier_list%2Fo659jcl%2F%5D%0A%0ARemindMe%21%202026-02-26%2023%3A14%3A14%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201r8if0v)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
              "score": 1,
              "created_utc": "2026-02-18 23:14:59",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o65t7r8",
          "author": "IgnisIason",
          "text": "Ring 2.5 1T if you've got an extra Colossus to run it.",
          "score": 1,
          "created_utc": "2026-02-19 01:03:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66rk18",
          "author": "Snoo_24581",
          "text": "Interesting rankings. How do you weigh coding ability vs general reasoning? For API work I have been using Qwen models for code tasks and they punch above their weight class.",
          "score": 1,
          "created_utc": "2026-02-19 04:30:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67gaum",
          "author": "FriendlySecond2460",
          "text": "this is writers wish list",
          "score": 1,
          "created_utc": "2026-02-19 07:48:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67ytua",
          "author": "Moki2FA",
          "text": "This tier list looks super interesting, I love seeing how different open source LLMs stack up against each other. I‚Äôm curious about how the evaluation criteria were determined; it would be great to understand more about what factors contributed to their rankings. Could anyone share more insight on that?",
          "score": 1,
          "created_utc": "2026-02-19 10:47:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69nqvp",
          "author": "Available-Message509",
          "text": "Seriously, huge thanks to the team behind¬†**GPT-oss 120B**. It‚Äôs such a relief to have a high-performing Tier A model that actually fits on our local GPU setups. Most of the newer models like GLM-5 or Kimi are just getting way too massive for home servers (700B+ is wild..). 120B is the real sweet spot for us!",
          "score": 1,
          "created_utc": "2026-02-19 16:49:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eaaha",
              "author": "MarkoMarjamaa",
              "text": "I'm running gpt-oss-120b. Still, it's also nice to know what kind of AI is achievable when memory prices go down. Like a conservative estimate that in 10 years I will be able to run GLM-5 size quant in my pc. ",
              "score": 1,
              "created_utc": "2026-02-20 09:53:48",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o69tsr8",
          "author": "tamtaradam",
          "text": "why only open-source/weights?",
          "score": 1,
          "created_utc": "2026-02-19 17:18:00",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ai3aq",
          "author": "Constandinoskalifo",
          "text": "RemindMe! 1 day",
          "score": 1,
          "created_utc": "2026-02-19 19:12:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6cei46",
          "author": "itsjase",
          "text": "or just check here you can also filter by size [https://artificialanalysis.ai/models/open-source](https://artificialanalysis.ai/models/open-source)",
          "score": 1,
          "created_utc": "2026-02-20 01:13:15",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9mqd1",
      "title": "Unpopular opinion: prompt engineering is just \"knowing how to talk to your coworker\" rebranded",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "author": "Neither_Turn1635",
      "created_utc": "2026-02-20 05:22:02",
      "score": 45,
      "num_comments": 15,
      "upvote_ratio": 0.88,
      "text": "Half the \"prompt engineering\" advice I see is literally just good communication skills:  \n  \n\"Give clear context\" ‚Äî yeah, that's how you talk to any human  \n\"Break complex tasks into steps\" ‚Äî project management 101  \n\"Provide examples of what you want\" ‚Äî every creative brief ever  \n\"Be specific about the output format\" ‚Äî basic email etiquette  \n  \nThe people who are best at prompting aren't engineers. They're the people who were already good at explaining what they want. We just gave the skill a fancy name and a LinkedIn certification.  \n  \nAm I wrong?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9mqd1/unpopular_opinion_prompt_engineering_is_just/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6dn25a",
          "author": "kobumaister",
          "text": "Absolutely, I made that analogy last week in my workplace: What happens if a new developer arrives at the company and you just throw a jira issue at him? I will deliver, but without following the best practices of the company, not understanding how internal dependencies work, probably changing things that are there for a reason, etc... \n\nThat's exactly what ai does, and why you provide context. I joke about it being a junior developer with a lot of cocaine.",
          "score": 8,
          "created_utc": "2026-02-20 06:18:13",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6ed9k8",
          "author": "PhilosophicWax",
          "text": "So is being a developer.",
          "score": 5,
          "created_utc": "2026-02-20 10:21:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dtr9s",
          "author": "OnlyTimeFan",
          "text": "Naming it ‚Äúengineering‚Äù is annoying. I pretend I‚Äôm asking a primary school kid. Ta-da.",
          "score": 4,
          "created_utc": "2026-02-20 07:18:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dm03z",
          "author": "ConnectMotion",
          "text": "There is some anecdotal relevance to this.\n\nIt‚Äôs not a skill everyone has in every way for every scenario.",
          "score": 3,
          "created_utc": "2026-02-20 06:09:06",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dz697",
          "author": "kubrador",
          "text": "you're right which is why prompt engineering jobs will be gone in 3 years when the models just understand what you mean",
          "score": 2,
          "created_utc": "2026-02-20 08:08:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eq3ed",
          "author": "House13Games",
          "text": "AI Just reinvented the wheel. \n\nIt now takes billions of watts and a server farm the size of a city to do the same job as some interns. \n\nAI is trained 60% on reddit posts and can't tell which side of a cup is up.\n\nI'm not feeling worried about losing my job, to tell the truth.",
          "score": 2,
          "created_utc": "2026-02-20 12:07:00",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6eta9b",
              "author": "Snoo-20788",
              "text": "It may look huge when measure in watts. But cost wise its negligible. \n\nWe now have the cost output everytime claude completes a jira ticket all by itself (i.e. it reads the ticket, codes the feature, tests it, creates a PR and waits for approval). It usually costs 1 or $2, and takes under 10 minutes for tasks that would take 30 minutes for a senior SWE who knows the company's codebase well (and 2h for one who doesn't). The equivalent cost of the SWE would be between 50 and 200.\n\nI am not worried at all about losing my job. Ultimately someone needs to talk to the business people, the researchers, and put together the framework that allows AI agents to do their job, and thats me and my colleagues.",
              "score": 1,
              "created_utc": "2026-02-20 12:29:23",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6dye78",
          "author": "fabkosta",
          "text": "Hint: Prompt engineering today can mean specifying entire software stacks. In prose. Which means you must know how to describe concepts such as four tier architecture, microservice coordination, REST APIs vs Graphql, reactive frontend programming, RBAC based security, ORM, and quite a few more things. In language.\n\nStating that this is \"just knowing how to talk to your coworker\" implies that this is easy. Which tells me one or two things about OP's experience.",
          "score": 2,
          "created_utc": "2026-02-20 08:01:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e0nnu",
              "author": "Vestenpance",
              "text": "I think you're agreeing with OP that a key part of prompt engineering is an ability to communicate, and that effective communication requires deep domain knowledge.",
              "score": 7,
              "created_utc": "2026-02-20 08:22:31",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6ep4dr",
              "author": "itquilibrium",
              "text": "Lol‚Ä¶",
              "score": 1,
              "created_utc": "2026-02-20 11:59:52",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e0mft",
          "author": "Usual-Orange-4180",
          "text": "Very unpopular because it ignores pattern repetition and the need for context isolation.",
          "score": 1,
          "created_utc": "2026-02-20 08:22:12",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6e5xbb",
          "author": "Vivid_Guava6269",
          "text": "Which is an incredibly rare skill, especially in mixed IT/Policy/Business environments¬†",
          "score": 1,
          "created_utc": "2026-02-20 09:12:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6eqdww",
          "author": "projectoedipus",
          "text": "The only point that I would disagree on, is that prompt engineering, especially advanced prompt engineering, is about understanding the ways that the AI model might misunderstand, because of how they work. You might say that is just communication skills, but it is about understanding how they function way deeper than someone who just communicates clearly.\n\nFor example, if I spend 50% of my prompt to a text-to-image generation model, describing a specific aspect of the image, then it is going to notice that, and it will generate the picture very differently, focusing more on that aspect, than if I say what is essentially the same thing with less words. But the order that I mention things matters as well. If I am generating an image and at the end of my prompt I say something that the AI model doesn't do, I could move that sentence to the beginning of my prompt, and it would have higher priority.\n\nOne time I was trying to generate an image and my prompt contained the phrase \"flight of stairs\", and after many failed generations where the stairs were floating, and me not understanding why, I realized that the word \"flight\" although used correctly, was confusing the model, and removing it fixed the outputs.\n\nA person that is exceptional at communication is not automatically a good prompt engineer, because they don't understand these things. Specific models have their own tendencies and prompt-following quirks as well, across all mediums of AI models, so you could also argue that part of being a good prompt engineer is learning these tendencies.\n\nSo being able to communicate effectively can make you rapidly progress while learning prompt engineering, but to say that they are the same skill is not understanding the full depth of prompt engineering.",
          "score": 1,
          "created_utc": "2026-02-20 12:09:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6famgk",
          "author": "Fulgren09",
          "text": "Are you orchestrating how to talk to your coworker a wrapping it in deployment code?¬†",
          "score": 1,
          "created_utc": "2026-02-20 14:10:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6fd2aj",
          "author": "deadwisdom",
          "text": "This is called being reductive. You can break anything down into parts and argue semantics. But is it helpful?",
          "score": 1,
          "created_utc": "2026-02-20 14:23:17",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r4ylja",
      "title": "[Release] AdaLLM: NVFP4-first inference on RTX 4090 (FP8 KV cache + custom FP8 decode)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r4ylja/release_adallm_nvfp4first_inference_on_rtx_4090/",
      "author": "Educational_Cry_7951",
      "created_utc": "2026-02-14 22:59:37",
      "score": 34,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "Hey folks, I have been working on **AdaLLM** (repo: [https://github.com/BenChaliah/NVFP4-on-4090-vLLM](https://github.com/BenChaliah/NVFP4-on-4090-vLLM)) to make NVFP4 weights actually usable on Ada Lovelace GPUs (sm\\_89). The focus is a pure NVFP4 fast path: FP8 KV cache, custom FP8 decode kernel, no silent FP16 fallback. It currently targets Qwen3 (dense + MoE) and Gemma3 (including sliding-window layers), I'll be adding support to other models soon.\n\n>**Please think of giving the Github repo a STAR if you like it :)**\n\n# Why this is interesting\n\n* NVFP4-first runtime for Ada GPUs (tested on RTX 4090) with FP8 KV cache end-to-end.\n* Custom Triton FP8 decode kernel; prefill uses FlashAttention (varlen).\n* No FP16 fallback for decode. If FP8 kernel fails, it errors out instead of silently switching.\n* Tensor-parallel (NCCL) + CUDA graphs for decode (also support eager mode)\n\n# Benchmarks (RTX 4090)\n\n**Qwen3-8B-NVFP4**\n\n|batch|total tokens|seconds|tok/s|peak GB|\n|:-|:-|:-|:-|:-|\n|1|128|3.3867|37.79|7.55|\n|2|256|3.5471|72.17|7.55|\n|4|512|3.4392|148.87|7.55|\n|8|1024|3.4459|297.16|7.56|\n|16|2048|4.3636|469.34|7.56|\n\n**Gemma3-27B-it-NVFP4**\n\n|batch|total tokens|seconds|tok/s|peak GB|\n|:-|:-|:-|:-|:-|\n|1|128|9.3982|13.62|19.83|\n|2|256|9.5545|26.79|19.83|\n|4|512|9.5344|53.70|19.84|\n\nfor Qwen3-8B-NVFP4 I observed \\~2.4x lower peak VRAM vs Qwen3-8B FP16 baselines (with \\~20-25% throughput loss).\n\n# Quickstart\n\n    pip install git+https://github.com/BenChaliah/NVFP4-on-4090-vLLM.git\n    \n    adallm serve nvidia/Qwen3-8B-NVFP4\n\n>\\`export NVFP4\\_FP8=1\\` is optional and enables FP8 GEMM path (NVFP4\\_FP8=0: the difference is in compute precision not VRAM, FP8 KV cache + the FP8 decode kernel are still used.\n\n**Supported models (so far)**\n\n* `nvidia/Qwen3-8B-NVFP4`\n* `BenChaliah/Gemma3-27B-it-NVFP4`\n* Qwen3 MoE variants are supported, but still slow (see README for MoE notes).\n\n**Limitations**\n\n* MoE routing and offload paths are not fully optimized yet (working on it currently)\n* Only NVFP4 weights, no FP16 fallback for decode by design.\n* Targeted at Ada Lovelace (sm\\_89). Needs validation on other Ada cards.\n\n# Repo\n\n[https://github.com/BenChaliah/NVFP4-on-4090-vLLM](https://github.com/BenChaliah/NVFP4-on-4090-vLLM)\n\nIf you have a RTX 4000 series GPU, I would love to hear results or issues. Also looking for help on MoE CPU-Offloading optimization, extra model support, and kernel tuning.",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r4ylja/release_adallm_nvfp4first_inference_on_rtx_4090/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5fifzx",
          "author": "Vearres17",
          "text": "The fact that you kept Gemma3 sliding-window attention in FP8 is impressive. I've seen some implementations that fall back to fp16 for the local attention layers I guess it bcz it can be tricky to handle",
          "score": 1,
          "created_utc": "2026-02-15 00:35:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5fjkgw",
              "author": "Educational_Cry_7951",
              "text": "thanks tbf it was a pain for me too at first",
              "score": 1,
              "created_utc": "2026-02-15 00:42:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o5hcpmr",
          "author": "Delicious-One-5129",
          "text": "This is seriously impressive work. An actual NVFP4 first path on RTX 4090 without silent FP16 fallback is huge for people squeezing every GB out of Ada cards. The VRAM savings vs FP16 are especially compelling.",
          "score": 1,
          "created_utc": "2026-02-15 09:19:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5hwkm4",
              "author": "Educational_Cry_7951",
              "text": "Thank you! ",
              "score": 1,
              "created_utc": "2026-02-15 12:23:26",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r6zfnj",
      "title": "How are they actually deployed in production at scale?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r6zfnj/how_are_they_actually_deployed_in_production_at/",
      "author": "hareld10",
      "created_utc": "2026-02-17 07:16:05",
      "score": 28,
      "num_comments": 15,
      "upvote_ratio": 0.95,
      "text": "I‚Äôm trying to understand how giants LLMs systems like ChatGPT/Claude are deployed in production.\n\nSpecifically curious about:\n\n‚Ä¢ Inference stack (custom engine vs vLLM-like architecture?)  \n‚Ä¢ API behind  \n‚Ä¢ Database   \n‚Ä¢ GPU orchestration (Kubernetes? custom scheduler?)  \n‚Ä¢ Sharding strategy (tensor / pipeline parallelism?)  \n‚Ä¢ How latency is kept low under burst traffic  \n‚Ä¢ Observability + guardrail systems\n\nI know nobody has internal details, but based on public info, talks, papers, or experience deploying large models -  what‚Äôs the likely architecture?\n\nI'm asking because I want to prepare a knowledge kit for system design questions at this level.\n\nWould love input from people running 30B+ models in production.",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6zfnj/how_are_they_actually_deployed_in_production_at/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5twdrw",
          "author": "Once_ina_Lifetime",
          "text": "From what I have seen publicly, most large LLM deployments look like layered infra , optimized inference engines (vLLM/Triton/custom), heavy GPU orchestration with Kubernetes or internal schedulers, aggressive caching/batching for latency, and strong observability/guardrails on top. Exact details vary, but it‚Äôs basically a reliability + infra engineering problem more than just model serving.",
          "score": 7,
          "created_utc": "2026-02-17 07:44:25",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uwoij",
              "author": "pmv143",
              "text": "Exactly. The interesting part is that once you solve model execution. thecomplexity shifts to orchestration and memory lifecycle management. That‚Äôs where most production pain seems to live.",
              "score": 2,
              "created_utc": "2026-02-17 12:56:42",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o63m5by",
                  "author": "singh_taranjeet",
                  "text": "In production it‚Äôs usually orchestration, guardrails, evals, caching, and state management doing the heavy lifting while the model is just one component in a bigger system. The real work is reliability, monitoring, and handling edge cases at scale.",
                  "score": 1,
                  "created_utc": "2026-02-18 18:36:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o5ue2ql",
          "author": "AdPutrid2974",
          "text": "That's the million-dollar question! Most likely a mix of custom C++ engines and massive Kubernetes clusters. Dealing with that level of burst traffic must be an engineering nightmare.",
          "score": 3,
          "created_utc": "2026-02-17 10:32:05",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5umpe4",
              "author": "hareld10",
              "text": "I want to construct prep kit to interviews, so its not have to be 1-1 :)",
              "score": 1,
              "created_utc": "2026-02-17 11:46:22",
              "is_submitter": true,
              "replies": []
            },
            {
              "id": "o5uwxel",
              "author": "pmv143",
              "text": "Probably a mix, yeah. Custom kernels and tight C++ runtimes make sense at that scale. But beyond the engine itself, I suspect a lot of the real complexity lives in scheduling, memory management, and how they handle burst traffic without fragmenting GPU memory.",
              "score": 1,
              "created_utc": "2026-02-17 12:58:14",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uiao1",
          "author": "kleinmatic",
          "text": "Read downtime post-mortems that tech companies publish after big outages. They‚Äôre always full of details on the exotic setups of very high scale systems. On GitHub look for danluu/post-mortems but there are others as well. They‚Äôre fascinating to read. \n\nWith that much money and scale I‚Äôm betting it‚Äôs way different and more custom than you think.",
          "score": 5,
          "created_utc": "2026-02-17 11:09:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dgfy0",
              "author": "Useful-Process9033",
              "text": "Post-mortems are an absolute goldmine. The danluu collection is great and so are the ones on SREboy and Fairwinds. You learn more about real architecture from a single outage writeup than from any marketing page.",
              "score": 2,
              "created_utc": "2026-02-20 05:22:57",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5tvbms",
          "author": "Abu_BakarSiddik",
          "text": "This is a very cool thing to learn about.\n\nI‚Äôm currently working on scaling our platform at the DB level, and it‚Äôs a completely different problem compared to scaling LLM inference. At the database layer, it mostly comes down to:\n\n* Managing connection lifecycle properly\n* Keeping transactions short\n* Handling long-lived sessions carefully (especially with streaming)\n* Using replicas effectively\n\nIf you mess up connection management, holdconnection hostage, everything falls apart. That‚Äôs usually the real bottleneck. With LLM systems, the bottleneck is about GPU compute and memory. The main things are:\n\n* Efficient batching of incoming requests\n* Maximizing GPU utilization\n* Managing KV cache memory properly\n* Supporting high concurrency\n\nModern frameworks like vLLM help a lot here. Things like paged attention, continuous batching, and FlashAttention make it possible to handle large numbers of concurrent requests efficiently. Memory management is critical, but these frameworks abstract a lot of that complexity away.\n\nSo DB scaling is mostly about connection discipline and replication strategy. LLM scaling is about batching efficiency and GPU orchestration.",
          "score": 3,
          "created_utc": "2026-02-17 07:34:27",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5uwe8m",
              "author": "pmv143",
              "text": "This is really well put. The ‚Äòdifferent bottlenecks, different failure modes‚Äô framing is key. With LLM systems you can have perfect API and DB hygiene and still fall apart purely due to KV cache pressure or poor batching under burst traffic.",
              "score": 2,
              "created_utc": "2026-02-17 12:54:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5uvzet",
          "author": "pmv143",
          "text": "Nobody outside those orgs knows the exact internals, but based on public talks and production constraints, the architecture likely looks something like this:\n\n\t1.Inference Engine\n\nNot stock vLLM. Likely heavily customized runtime layers optimized for:\n‚Äì KV cache management\n‚Äì Scheduling + batching\n‚Äì Memory locality\n‚Äì Tensor + pipeline parallelism coordination\nvLLM concepts, but production hardened and deeply modified.\n\n\t2.GPU Orchestration\n\nKubernetes at the outer layer for cluster management.\nCustom schedulers at the GPU level.\nYou cannot rely on vanilla k8s scheduling when GPUs cost this much and memory is not oversubscribable.\n\n\t3.Sharding Strategy\nLarge models: tensor parallelism within a node, pipeline parallelism across nodes.\nMoE adds routing complexity.\nEverything optimized around minimizing cross node bandwidth.\n\n\t4.Latency Under Burst\n\nTwo strategies:\n‚Äì Keep massive pools warm at high utilization\n‚Äì Aggressive batching with tight admission control\nTrue scale to zero serverless does not really exist at this tier.\n\n\t5.API + Gateway Layer\nHigh performance stateless frontends\nQueueing + prioritization\nStreaming responses over HTTP/2 or gRPC\n\n\t6.Observability + Guardrails\nPer token tracing\nReal time safety filters\nShadow traffic for model eval\nCanary deployments for new weights\n\nThe hard part is not just loading the model.\nIt‚Äôs scheduling, memory, and utilization at scale.\n\nCold start optimization matters only if it works in production traffic, not just in a benchmark.",
          "score": 1,
          "created_utc": "2026-02-17 12:52:16",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5v8jf8",
          "author": "burntoutdev8291",
          "text": "Check out production stack helm chart",
          "score": 1,
          "created_utc": "2026-02-17 14:05:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o611jsj",
          "author": "GarbageOk5505",
          "text": "For burst traffic the answer is almost always overprovisioning plus request queuing with dynamic batching you're trading latency variance for throughput. Routing based on sequence length helps too, you don't want a 4-token request waiting behind a 32k context job.\n\nFor the system design prep angle: the Megatron-LM and PaLM papers are worth reading carefully, and Meta's LLaMA inference posts are surprisingly detailed about production tradeoffs.\n\n  \nfor the others I need to research furhter, good stuff pointing that out",
          "score": 1,
          "created_utc": "2026-02-18 10:11:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6dggki",
              "author": "Useful-Process9033",
              "text": "Routing by sequence length is one of those tricks that sounds obvious but almost nobody does until they get bitten. The latency variance from mixing 4-token and 32k-context requests on the same queue is brutal in practice.",
              "score": 1,
              "created_utc": "2026-02-20 05:23:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r8kgld",
      "title": "GLM-5 is officially on NVIDIA NIM, and you can now use it to power Claude Code for FREE üöÄ",
      "subreddit": "LLMDevs",
      "url": "https://github.com/Alishahryar1/free-claude-code",
      "author": "PreparationAny8816",
      "created_utc": "2026-02-19 00:30:13",
      "score": 26,
      "num_comments": 6,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8kgld/glm5_is_officially_on_nvidia_nim_and_you_can_now/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "o67fo1c",
          "author": "ZenApollo",
          "text": "Does the proxy support openai flavor endpoints?",
          "score": 1,
          "created_utc": "2026-02-19 07:42:48",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o688fb1",
          "author": "tech_1729",
          "text": "Saying free claude code is misleading üòÖ",
          "score": 1,
          "created_utc": "2026-02-19 12:06:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68h0az",
          "author": "zoidme",
          "text": "What relative quality you can expect on this? Like gpt-4.x or better?",
          "score": 1,
          "created_utc": "2026-02-19 13:05:20",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69267t",
          "author": "--dany--",
          "text": "How does it compare to Claude Code Router?",
          "score": 1,
          "created_utc": "2026-02-19 15:03:26",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o692ucf",
          "author": "lingondricka2",
          "text": "I tried it using Nvidia NIM, neither GLM-5 or Qwen 3.5 gave me a response, step-3.5-flash worked fine though, thank you",
          "score": 1,
          "created_utc": "2026-02-19 15:06:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68bv69",
          "author": "SectionCrazy5107",
          "text": "I dont see the claims on free request to be really true anywhere from Nvidia site, it seems usable only when on browser for light prototype, not as daily driver. I will be delighted to be proven wrong so I can really use it.",
          "score": 0,
          "created_utc": "2026-02-19 12:31:20",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6rzah",
      "title": "AI Coding Agent Dev Tools 2026 (Updated)",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/syaar38yfyjg1.png",
      "author": "bhaktatejas",
      "created_utc": "2026-02-17 01:08:11",
      "score": 19,
      "num_comments": 8,
      "upvote_ratio": 0.81,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6rzah/ai_coding_agent_dev_tools_2026_updated/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5tl122",
          "author": "sogo00",
          "text": "There is so much wrong with this",
          "score": 1,
          "created_utc": "2026-02-17 06:04:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5tlepy",
              "author": "bhaktatejas",
              "text": "tell me! i'll update it ",
              "score": 1,
              "created_utc": "2026-02-17 06:07:26",
              "is_submitter": true,
              "replies": [
                {
                  "id": "o5ua01w",
                  "author": "sogo00",
                  "text": "Look you have clearly asked an LLM to produce this for you and half of it is wrong.\n\nIf you want something correct, start to google each headline, understand what it means and then read about each icon/text underneath it.",
                  "score": 1,
                  "created_utc": "2026-02-17 09:54:33",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o6219jt",
          "author": "resiros",
          "text": "I never understood the value of these maps, other than for investors. You can't even click on things. ",
          "score": 1,
          "created_utc": "2026-02-18 14:15:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "o652eoq",
              "author": "bhaktatejas",
              "text": "[morphllm.com/market-map](http://morphllm.com/market-map)",
              "score": 1,
              "created_utc": "2026-02-18 22:37:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1r7momq",
      "title": "Clawdbot/Moltbot/OpenClaw is a security disaster waiting to happen",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "author": "thecreator51",
      "created_utc": "2026-02-17 23:38:04",
      "score": 19,
      "num_comments": 22,
      "upvote_ratio": 0.88,
      "text": "I was more excited about AI agent frameworks than I was when LLMs first dropped. The composability, the automation, the skill ecosystem - it felt like the actual paradigm shift.\n\nLately though I'm genuinely worried. We can all be careful about which skills we install, sure. But most people don't realize skills can silently install other skills. No prompt, no notification, no visibility. One legitimate-looking package becomes a dropper for something else entirely, running background jobs you'll never see in your chat history.\n\nWhat does a actually secure OpenClaw implementation even look like? Does one exist?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7momq/clawdbotmoltbotopenclaw_is_a_security_disaster/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5ywnls",
          "author": "Strong_Worker4090",
          "text": "I don‚Äôt think the concern is overblown. If skills can silently install other skills and run background jobs with no visibility, that‚Äôs a real supply chain and privilege boundary problem.\n\nThe way I think about it is this: don‚Äôt treat the agent like a helpful assistant. Treat it like the smartest hacker in the world who happens to be following instructions most of the time.\n\nIf you assume that, a \"secure\" implementation looks very different from the default hobby setup.\n\nFirst, the model shouldn‚Äôt have direct power. It shouldn‚Äôt have raw network access, raw filesystem access, or ambient credentials sitting in environment variables. It should only be able to request actions.\n\nSecond, every capability should be explicitly defined and allowlisted. No silent skill installs. No transitive dependency installs at runtime. If something gets added, it happens in a controlled build step with review and version pinning.\n\nThird, all external effects should go through a choke point you control. If it wants to send an email, make an HTTP request, write to a database, or touch Slack, it calls a guarded tool. That tool enforces policy, rate limits, domain restrictions, and writes to an immutable audit log. No raw SMTP. No arbitrary outbound HTTP.\n\nFourth, assume it will try to exfiltrate if it can. That means default deny on network egress, strict sandboxing, and strong logging that lives outside the agent runtime.\n\nIs there a \"perfect\" secure setup that still keeps full utility? Probably not. The more useful the agent is, the more power it needs. The goal isn‚Äôt perfection, it‚Äôs constrained, mediated power with visibility and revocability.\n\nSo I wouldn‚Äôt say these frameworks are doomed. I‚Äôd say most default installs are way too permissive for production. A secure OpenClaw implementation would look less like a plugin playground and more like a tightly sandboxed execution engine with a policy layer in front of every meaningful action.",
          "score": 9,
          "created_utc": "2026-02-18 01:01:46",
          "is_submitter": false,
          "replies": [
            {
              "id": "o61l3gs",
              "author": "GCoderDCoder",
              "text": "Agreed. To their credit, tons of folks were excited to help something like this and made it a totally different project IMO. There's now various ways to increase isolation. I have been using a lot of reactive tools that require me initiating everything so Im enticed by the proactive nature of open claw so I see it as starting with proactive features I want to make a more deterministic implementation of. That said, I was trashing the initial release but i think it is usable for personal setups for informed users now.\n\nI originally planned a series of vms with separate controls but there are several layers of isolation included now in open claw. I'm still configuring an internal only container and an external accessible vm install because I wanted to be as conservative as possible assuming the external facing one will be contaminated but sandboxing seems legitimately incorporated in open claw now where it's not irresponsible now to have one gateway with different agent profiles to achieve similar separation IMO. \n\nBoth my instances are locked down to only be able to use tools I give them. The external one has no access to any sensitive info but can gather information and put it together for me to allow it to save it in my tools. But until I approve it everything is ephemeral in the container sandbox. The second one is internal only with a lot of read only access but any write requires my approval. So that allows it to proactively review solutions without compromising my tools.\n\nInsider threat is always the most dangerous and even more so with tools that replicate human logic but lack the ability to actually think.",
              "score": 3,
              "created_utc": "2026-02-18 12:44:01",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o67kexn",
                  "author": "Traditional-Set6848",
                  "text": "What I love about open claw and moltbook (independent of judgement if it‚Äôs good or not) is the approach to using less complex and more obvious technology in quite a human way, I remember when Facebook was launched and my friends where ‚Äúwoooow look what you can do‚Äù, and I was all ‚Äúyehhh but it‚Äôs just JavaScript and apis wtbd?‚Äù - the big deal was the way the tech got used and I was being a Luddite üòÇüò≠",
                  "score": 1,
                  "created_utc": "2026-02-19 08:27:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "o60idec",
              "author": "Traditional-Set6848",
              "text": "Nicely put!¬†",
              "score": 2,
              "created_utc": "2026-02-18 07:13:59",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dgcxk",
              "author": "Useful-Process9033",
              "text": "Treating agents like the smartest hacker in the room is exactly the right frame. Any agent that touches prod infra needs explicit permission boundaries and audit trails. We built IncidentFox with that assumption from day one because an AI SRE with unchecked access is scarier than the incidents it fixes. [https://github.com/incidentfox/incidentfox](https://github.com/incidentfox/incidentfox)",
              "score": 1,
              "created_utc": "2026-02-20 05:22:18",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5yp6vs",
          "author": "Interesting-Law-8815",
          "text": "Waiting to happen?   I think it‚Äôs already happened!",
          "score": 12,
          "created_utc": "2026-02-18 00:20:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zrcum",
          "author": "Vusiwe",
          "text": "Don‚Äôt know much about it, but it really sounds like 2023‚Äôs AutoGPT, only running with root permissions, with network access turned on\n\nGG",
          "score": 3,
          "created_utc": "2026-02-18 03:50:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5z05j8",
          "author": "crankthehandle",
          "text": "are there any crazy stories that have happened with openclaw? Looks like moltbook was the way bigger fuck up.",
          "score": 2,
          "created_utc": "2026-02-18 01:20:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o611f8a",
          "author": "Loud-Option9008",
          "text": "This is the thing that worries me more than jailbreaks or prompt injection in isolation. Silent skill installation is a supply chain attack surface and most users have no idea it exists. You're not just trusting the skill, you're trusting everything that skill decides to pull in at runtime.\n\nA \"secure\" OpenClaw implementation would need at minimum: process-level isolation per skill so a compromised package can't read memory or environment variables from the agent runtime, network egress controls so background jobs can't phone home, and some kind of attestation that what's running matches what you installed. None of that exists out of the box.\n\nThe deeper issue is that the whole skill ecosystem is built on implicit trust. Skills run in the same execution context as the agent, which means they have access to everything the agent has access to  credentials, session tokens, whatever's in the environment. A dropper skill doesn't need to escalate privileges, it already has them.\n\nDocker helps at the surface level but shared kernel is a real limitation here  if a skill finds a kernel exploit, the container boundary doesn't save you. The honest answer is that a properly isolated implementation needs the skill execution to happen in a separate environment with explicit, audited permissions for every outbound action. Most people are nowhere near that and don't realize it.",
          "score": 2,
          "created_utc": "2026-02-18 10:10:21",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5yiaxd",
          "author": "kubrador",
          "text": "you're describing dependency hell with god mode. the answer to \"what does secure look like\" is probably \"don't let untrusted code execute arbitrary actions\" which, yeah, solves the problem by making the whole thing pointless.",
          "score": 1,
          "created_utc": "2026-02-17 23:42:33",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5za5z6",
          "author": "BrianJThomas",
          "text": "I feel the same way about crates.io, to be fair.",
          "score": 1,
          "created_utc": "2026-02-18 02:11:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zcy7t",
          "author": "wally659",
          "text": "I feel like a \"security disaster\" requires some suggestion of \"security\" to begin with. Saying the OpenClaw platform is a security risk is a bit like saying underwater cave exploration is dangerous.",
          "score": 1,
          "created_utc": "2026-02-18 02:26:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5zgtpy",
              "author": "NoleMercy05",
              "text": "![gif](giphy|VBmRD9W9HwTLmGLz34)",
              "score": 1,
              "created_utc": "2026-02-18 02:47:43",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "o6dge2m",
              "author": "Useful-Process9033",
              "text": "Underwater cave exploration is a perfect analogy honestly. The people doing it seriously have checklists, redundancy, and abort protocols. The problem is when someone just jumps in with a flashlight.",
              "score": 1,
              "created_utc": "2026-02-20 05:22:33",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6dgr78",
                  "author": "wally659",
                  "text": "Also if the risk itself wasn't part of the reward there'd be no point. ü§£",
                  "score": 1,
                  "created_utc": "2026-02-20 05:25:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "o603e1p",
          "author": "Civil_Tea_3250",
          "text": "And OpenAI just hired the guy that made it. Because he made such a great product lol\n\nSeriously, can we stop this now? Like, right now.",
          "score": 1,
          "created_utc": "2026-02-18 05:11:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o609ury",
          "author": "No_Success3928",
          "text": "I'm excited about making bank fixing things :D\n\n",
          "score": 1,
          "created_utc": "2026-02-18 06:01:32",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60s18g",
          "author": "sogo00",
          "text": "I remember there was one of the top skill that was installing some malware...\n\nBTW - that is not limited to this type of agent - all claude/other agent skills you find on the web are unaudited and even if the author is trustful someone can hijack the repo. That especially applies to the big all-included skill where the maintainer collects other peoples skills...",
          "score": 1,
          "created_utc": "2026-02-18 08:43:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o60xb6w",
          "author": "Zeikos",
          "text": "Nobody is waiting",
          "score": 1,
          "created_utc": "2026-02-18 09:32:49",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o63c1rd",
          "author": "Legitimate-Leek4235",
          "text": "Its an absolute disaster to give the keys to your kingdom for a virtual job executor under any circumstances with no guard-rails. Its like leaving your car keys in unattentended with the lights turned .",
          "score": 1,
          "created_utc": "2026-02-18 17:52:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o68us9q",
          "author": "projectoedipus",
          "text": "LLMs are non-deterministic systems, and so they, mathematically provably, can always be jailbroken, and there will always be the potential for them to be a security risk. They are a tool, and when used responsibly, they can be used to accomplish great things.\n\nOpenClaw is an agentic system that makes LLMs more accessible and more powerful, but the risks still exist. There are quite a few \"security layers\" that people have created to prevent prompt injection and things like that, but the real truth is... Security systems exist to make the people who have them feel safe, and to raise the barrier for entry for those who would seek to exploit them, but someone who is determined enough, can always get in.  \n  \nDon't make your OpenClaw instance accessible outside of your home network. Don't install skills from people that you don't trust without auditing them first, and sandbox according to the level of risk that you are comfortable with.\n\nLife is short. Don't sweat the small stuff.",
          "score": 1,
          "created_utc": "2026-02-19 14:24:25",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5zr3ns",
          "author": "zZaphon",
          "text": "This is where AI Governance Software would be useful. For example\n\nhttps://factara.fly.dev",
          "score": 0,
          "created_utc": "2026-02-18 03:48:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r8de88",
      "title": "Claude Sonnet 4.6 benchmark results: none reasoning beats GPT-5.2 with reasoning",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "author": "Exact_Macaroon6673",
      "created_utc": "2026-02-18 19:54:15",
      "score": 16,
      "num_comments": 7,
      "upvote_ratio": 0.83,
      "text": "We have been working on a private benchmark for evaluating LLMs. The questions cover a wide range of categories and because it is not public and gets rotated, models cannot train on it or game the results.\n\nWith Sonnet 4.6 dropping I ran it through and the results are worth talking about.\n\nSonnet 4.6 with reasoning off scores 0.648 overall. GPT-5.2 at low reasoning scores 0.604. That is not a rounding error and it has real cost implications for anyone running at scale.\n\nAt high reasoning it ties Gemini 3 Pro Preview at the top of our leaderboard with 0.719 overall, ahead of GPT-5.2 high at 0.649.\n\nHallucination resistance hits 0.921, the highest of any model we have tested. Gemini 3 Pro sits at 0.820, GPT-5.2 at 0.655. Social calibration at 0.905 and error detection at 0.848 are similarly the best we have seen.\n\nTo give credit where it is due, Gemini 3 Pro is still the better call for hard science. Philosophy 0.900 vs 0.767, chemistry 0.839 vs 0.710, economics 0.812 vs 0.750. It is not a sweep.\n\nThe honest caveat is sycophancy resistance at 0.716 is actually slightly below Sonnet 4.5 at high reasoning which scored 0.755. For a company that talks about this a lot, that is worth watching.\n\nIf reliability and hallucination resistance are your primary eval criteria nothing beats it right now.\n\nhttps://preview.redd.it/tj3yyj5t5bkg1.png?width=2588&format=png&auto=webp&s=260eac02f897164ffda778e0f332fe2b6df92890\n\n",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8de88/claude_sonnet_46_benchmark_results_none_reasoning/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o651nov",
          "author": "EarEquivalent3929",
          "text": "Benchmarks don't matter at all. If you'd actually used sonnet4.6 you'd already know it's pretty bad and hallucinated constantly on simple tasks.\n\n\nBut this post was clearly written by ai",
          "score": 5,
          "created_utc": "2026-02-18 22:33:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "o65xq5z",
              "author": "Exact_Macaroon6673",
              "text": "ü´°",
              "score": -2,
              "created_utc": "2026-02-19 01:29:40",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65qjan",
          "author": "promptbid",
          "text": "The hallucination resistance number is the one that matters most for our use case. At 0.921 that is a meaningful gap from the field. For any application where the model is making recommendations or surfacing information to end users, hallucination is a trust killer that is hard to recover from.\n\nThe sycophancy regression is worth flagging though. In ad-adjacent applications where you are trying to get honest signal from a model about user intent, a model that agrees too readily is actually worse than one that pushes back. Curious if your benchmark breaks that down by prompt type at all.\n\nThe cost angle you raised on non-reasoning Sonnet beating GPT-5.2 with reasoning is underrated. At scale that is not just a cost story, it is a latency story too. What does the benchmark show on response consistency across runs?",
          "score": 1,
          "created_utc": "2026-02-19 00:47:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o666eyo",
          "author": "kubrador",
          "text": "sonnet really said \"fine i'll be good at something\" after spending three years being the middle child of the claude family",
          "score": 1,
          "created_utc": "2026-02-19 02:20:15",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66a5eq",
          "author": "EbbNorth7735",
          "text": "Now do Qwen 3.5 397B",
          "score": 1,
          "created_utc": "2026-02-19 02:41:51",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o66o35y",
          "author": "Tema_Art_7777",
          "text": "Yes this kind of stuff is not useful at all - fleeting moments in time. Just pick one and do your tasks - its the outcome that matters, not model du jour.",
          "score": 1,
          "created_utc": "2026-02-19 04:07:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o67hso7",
          "author": "Low-Exam-7547",
          "text": "Can we not use the word \"dropping\" in this context? It's a music industry term for releasing records. It's found its way into enough of life. In this context it's just confusing. Let's be adults.",
          "score": 1,
          "created_utc": "2026-02-19 08:02:25",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r7d29g",
      "title": "PlaceboBench: New benchmark on SOTA LLM hallucinations in pharma",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/3bzaibbzd3kg1.jpeg",
      "author": "aiprod",
      "created_utc": "2026-02-17 17:45:34",
      "score": 13,
      "num_comments": 6,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Resource",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r7d29g/placebobench_new_benchmark_on_sota_llm/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5wzh3c",
          "author": "Competitive-Garage-4",
          "text": "Do not ask software engineer to recommend you pills.",
          "score": 2,
          "created_utc": "2026-02-17 19:13:39",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5xg2je",
              "author": "aiprod",
              "text": "Haha yes, while I prefer Opus for coding, I guess Gemini would be the better pharmacist",
              "score": 2,
              "created_utc": "2026-02-17 20:32:07",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "o65pbyo",
          "author": "Overthinker512",
          "text": "I'm doing a similar project. I didn't use RAG, I just used the training Claude already had as core training. I use claude cowork so I could use multi-agent for recursive self improvement. LMK if you would like to see the prompting. I found that using recursive self improvement generated high quality answers.",
          "score": 1,
          "created_utc": "2026-02-19 00:41:10",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o69bmor",
          "author": "aiprod",
          "text": "For anyone interested in a deeper dive on this, we‚Äôre hosting a live session in March. We‚Äôll also discuss quantitatively strategies to reduce these problems.\n\nSignup link is here: https://www.blueguardrails.com/en/live-session-pharma",
          "score": 1,
          "created_utc": "2026-02-19 15:50:47",
          "is_submitter": true,
          "replies": [
            {
              "id": "o6erimh",
              "author": "Melodic_Reality_646",
              "text": "Couldn‚Äôt stop to read through the methodology. Why are the hallucination values so high? \n\nAt first glance it really just feels like a way to promote this blueguardrail product.",
              "score": 1,
              "created_utc": "2026-02-20 12:17:13",
              "is_submitter": false,
              "replies": [
                {
                  "id": "o6eswzu",
                  "author": "aiprod",
                  "text": "We did automated detection + human annotation + human review (3 passes, two of them human).\n\nThe values are so high because these models hallucinated so much. The data is available on hugging face if you would like to check yourself.\n\nThe models frequently mix up context, they are too imprecise in their language for the pharmaceutical domain, or they invent clinical protocols that are nowhere mentioned in the source data (directly violating the system prompt).",
                  "score": 1,
                  "created_utc": "2026-02-20 12:26:52",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1r8j5ob",
      "title": "How are you monitoring your Haystack calls/usage?",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/2cxt2c949ckg1.jpeg",
      "author": "gkarthi280",
      "created_utc": "2026-02-18 23:34:34",
      "score": 13,
      "num_comments": 1,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r8j5ob/how_are_you_monitoring_your_haystack_callsusage/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o67z29j",
          "author": "Moki2FA",
          "text": "Ah yes, the classic quest for the Holy Grail of metrics. You‚Äôve got the basics covered, but let‚Äôs not forget the all important ‚Äúnumber of existential crises per request.‚Äù It‚Äôs crucial to monitor how many times you question your life choices while waiting for that model to respond. Jokes aside, consider tracking user feedback; after all, knowing if they‚Äôre actually using your app or just staring at it like a confused cat could be quite enlightening. And if you haven‚Äôt already, maybe throw in some ‚ÄúI told you so‚Äù logs for those moments when the LLM actually nails it.",
          "score": 3,
          "created_utc": "2026-02-19 10:49:24",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5nil3",
      "title": "I built a CLI that extracts design systems from any live website",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r5nil3/i_built_a_cli_that_extracts_design_systems_from/",
      "author": "Every_Chicken_1293",
      "created_utc": "2026-02-15 19:26:36",
      "score": 13,
      "num_comments": 4,
      "upvote_ratio": 0.88,
      "text": "I kept running into the same problem: I'd see a website I liked and want to build something with a similar design, but manually inspecting every color, font, spacing value, and component pattern was tedious.\n\nSo I built design-memory. You point it at a URL and it:  \n  \n\\- Crawls the page with Playwright  \n\\- Extracts colors, typography, spacing, border radius, elevation  \n\\- Captures all CSS custom properties (often 500-700+ variables)  \n\\- Detects Tailwind usage and top utility patterns  \n\\- Uses an LLM to interpret component recipes and layout structure  \n\\- Outputs a .design-memory/ folder of markdown files\n\nThe output is structured so you can paste it into Claude, Cursor, or ChatGPT and get a faithful recreation of the original design.\n\nIt also supports learning from screenshots, multi-page crawls, and diffing two design systems.\n\nSource: [https://github.com/memvid/design-memory](https://github.com/memvid/design-memory)",
      "is_original_content": false,
      "link_flair_text": "Tools",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r5nil3/i_built_a_cli_that_extracts_design_systems_from/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5lfrsg",
          "author": "NeverSkipSleepDay",
          "text": "Have you ever seen what a design system looks like?",
          "score": 2,
          "created_utc": "2026-02-15 23:42:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5min2v",
              "author": "salasi",
              "text": "Lmao",
              "score": 1,
              "created_utc": "2026-02-16 03:47:33",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5nl10m",
          "author": "WhoTookPlasticJesus",
          "text": "Not to be overly critical, but not even your demo screenshots are alike. The fonts are wrong, icons weren't copied, an entire fucking navbar has gone missing...\n\nI'm also not sure at all what this has to do with LLMs",
          "score": 1,
          "created_utc": "2026-02-16 09:09:40",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5s3a9r",
          "author": "o1got",
          "text": "This is really cool. I've been on the receiving end of this problem from a different angle - we see a ton of AI agents crawling websites now, and the ones that actually extract design tokens and structured CSS tend to perform way better than the ones just scraping raw HTML.\n\nHow are you handling responsive design patterns? Like if a site has completely different component structure at mobile vs desktop, does it capture both states or does Playwright just grab whatever viewport you set?  \nAlso the diffing feature is interesting. I wonder if that could be useful for tracking how design systems evolve over time, like crawling the same site every few months and seeing what changed. Could be a neat way to learn from how mature products iterate on their UI.",
          "score": 1,
          "created_utc": "2026-02-17 00:16:32",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r79s1w",
      "title": "SurrealDB 3.0 for AI agent memory",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r79s1w/surrealdb_30_for_ai_agent_memory/",
      "author": "DistinctRide9884",
      "created_utc": "2026-02-17 15:55:41",
      "score": 9,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "SurrealDB 3.0 just dropped, with a big focus on agent memory infra for AI: improved vector indexing + better graph performance + native file storage + a WebAssembly extension system (Surrealism) that can run custom logic/models inside the DB. You can store vector embeddings + structured data + graph context/knowledge/memory in one place and do hybrid retrieval in one query.\n\nDetails:¬†[https://surrealdb.com/blog/introducing-surrealdb-3-0--the-future-of-ai-agent-memor](https://surrealdb.com/blog/introducing-surrealdb-3-0--the-future-of-ai-agent-memory)",
      "is_original_content": false,
      "link_flair_text": "News",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r79s1w/surrealdb_30_for_ai_agent_memory/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o69cjli",
          "author": "singh_taranjeet",
          "text": "As CEO of Mem0 I can confirm our memory is so strong even SurrealDB is taking notes, but be careful or your AI agent might start asking *you* for emotional support when it forgets its own login ;)",
          "score": 1,
          "created_utc": "2026-02-19 15:55:13",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r6m5hb",
      "title": "Can LLMs deduplicate ML training data?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r6m5hb/can_llms_deduplicate_ml_training_data/",
      "author": "ddp26",
      "created_utc": "2026-02-16 21:14:03",
      "score": 9,
      "num_comments": 6,
      "upvote_ratio": 1.0,
      "text": "I get increasingly annoyed with how unreliable deduplication tools are for cleaning training data. I‚Äôve used MinHash/LSH, libraries like [dedupe.io](http://dedupe.io), and pandas.drop\\_duplicates() but they all have a lot of false positives/negatives.  \n  \nI ended up running LLM-powered deduplication on 3,000 sentences from Google's paraphrase dataset from Wikipedia (PAWS). It removed 1,072 sentences (35.7% of the set). It only cost $4.21, and took \\~5 minutes.  \n  \nExamples of what it catches that the other methods don't:\n\n* \"Glenn Howard won the Ontario Championship for the 17th time as either third or skip\" and \"For the 17th time the Glenn Howard won the Ontario Championship as third or skip\"\n* \"David Spurlock was born on 18 November 1959 in Dallas, Texas\" and \"J. David Spurlock was born on November 18, 1959 in Dallas, Texas\"\n\n  \nFull code and methodology: [https://everyrow.io/docs/deduplicate-training-data-ml](https://everyrow.io/docs/deduplicate-training-data-ml)\n\nAnyone else using LLMs for data processing at scale? It obviously can work at small scale (and high cost), but are you finding it can work at high scale and low cost?",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r6m5hb/can_llms_deduplicate_ml_training_data/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o5sbqnp",
          "author": "kubrador",
          "text": "yeah this is clever but you're basically paying for semantic understanding you could get cheaper with embeddings + cosine similarity. run your 3k sentences through openai's small embedding model (\\~$0.02 total), cluster by cosine distance, done in 10 seconds for less than a coffee.\n\n\n\nthe paraphrase examples you showed would absolutely get caught by that approach since they're semantically identical, which is what actually matters for training data dedup anyway.",
          "score": 2,
          "created_utc": "2026-02-17 01:05:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5sf7em",
              "author": "dreamingwell",
              "text": "You could do this to get ‚Äúprobably duplicates‚Äù. And then use an LLM to finalize them. Reducing your LLM costs significantly.",
              "score": 1,
              "created_utc": "2026-02-17 01:25:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5seuz1",
          "author": "dreamingwell",
          "text": "You can do a Lora tuning on a small model, like Qwen3-4B. Train it to identify duplicated data from examples in your set. On the right GPU, it would absolutely tear through that data.",
          "score": 2,
          "created_utc": "2026-02-17 01:23:50",
          "is_submitter": false,
          "replies": [
            {
              "id": "o5yzvnc",
              "author": "ChanceKale7861",
              "text": "Holy moly! Are you me?! ü§£ü§£ü§£",
              "score": 1,
              "created_utc": "2026-02-18 01:19:00",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o5siq3u",
          "author": "No_Indication_1238",
          "text": "Tbh, you pretty much nailed a novel use case for LLMs. Yes, semantic analysis was tough before them.",
          "score": 1,
          "created_utc": "2026-02-17 01:47:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o5uvzl2",
          "author": "andy_p_w",
          "text": "Those two examples, if you take out regular words (any word 3 letters or less) and just look at the Jaccard similarity for the words will have very high overlap. English language is quite large, it is difficult to have much overlap in words random sentences, [https://andrewpwheeler.com/2024/04/20/some-musings-on-plagiarism/](https://andrewpwheeler.com/2024/04/20/some-musings-on-plagiarism/) .",
          "score": 1,
          "created_utc": "2026-02-17 12:52:18",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1r5mqrd",
      "title": "Has anyone here successfully sold RAG solutions to clients? Would love to hear your experience (pricing, client acquisition, delivery, etc.)",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r5mqrd/has_anyone_here_successfully_sold_rag_solutions/",
      "author": "Temporary_Pay3221",
      "created_utc": "2026-02-15 18:57:10",
      "score": 8,
      "num_comments": 0,
      "upvote_ratio": 0.84,
      "text": "Hey everyone!\n\nI've been diving deep into RAG systems lately and I'm genuinely fascinated by the technology. I've built a few projects for myself and feel confident in my technical abilities, but now I'm looking to transition this into actual client work.\n\nBefore I jump in, I'd really appreciate learning from people who've already walked this path. If you've sold RAG solutions to clients, I'd love to hear about your experience:\n\n**Client & Project Details:**\n\n* What types of clients/industries did you work with?\n* How did they discover they needed RAG? (Did they come asking for it, or did you identify the use case?)\n* What was the scope? (customer support, internal knowledge base, document search, etc.)\n\n**Delivery & Timeline:**\n\n* How long did the project take from discovery to delivery?\n* What were the biggest technical challenges you faced?\n* Did you handle ongoing maintenance, or was it a one-time delivery?\n\n**Business Side:**\n\n* How did you find these clients? (freelance platforms, LinkedIn outreach, referrals, content marketing, etc.)\n* What did you charge? (ballpark is fine, just trying to understand market rates)\n* How did you structure pricing? (fixed project, hourly, monthly retainer?)\n\n**Post-Delivery:**\n\n* Were clients happy with the results?\n* Did you iterate/improve the system after launch?\n* Any lessons learned that you'd do differently next time?\n\nThanks !",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r5mqrd/has_anyone_here_successfully_sold_rag_solutions/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": []
    },
    {
      "id": "1r4nj4y",
      "title": "16 single-file, zero-dependency implementations of the algorithms behind LLMs ‚Äî tokenization through speculative decoding. No frameworks, just the math.",
      "subreddit": "LLMDevs",
      "url": "https://i.redd.it/t4h1i8nbbhjg1.png",
      "author": "tom_mathews",
      "created_utc": "2026-02-14 15:32:01",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 0.91,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": "Great Resource üöÄ",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r4nj4y/16_singlefile_zerodependency_implementations_of/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "o5ho7tr",
          "author": "tom_mathews",
          "text": "The repo has been expanded from 16 to 30 scripts since the original post. Here's what's new:\n\n- **Foundations (7 ‚Üí 11):** Added BERT (bidirectional encoder), RNNs & GRUs (vanishing gradients + gating), CNNs (kernels, pooling, feature maps), GANs (generator vs. discriminator), VAEs (reparameterization trick), diffusion (denoising on point clouds), and an optimizer comparison (SGD vs. Momentum vs. RMSProp vs. Adam).\n\n- **Alignment (4 ‚Üí 9):** Added PPO (full RLHF reward ‚Üí policy loop), GRPO (DeepSeek's simplified approach), QLoRA (4-bit quantized fine-tuning), REINFORCE (vanilla policy gradients), Mixture of Experts (sparse routing), batch normalization, and dropout/regularization.\n\n- **Systems (5 ‚Üí 10):** Added paged attention (vLLM-style memory management), RoPE (rotary position embeddings), decoding strategies (greedy, top-k, top-p, beam, speculative ‚Äî all in one file), tensor & pipeline parallelism, activation checkpointing, and state space models (Mamba-style linear-time sequence modeling).\n\nSame constraints as before: every script is a single file, zero dependencies, trains and infers (or demonstrates forward-pass mechanics side-by-side), runs on CPU in minutes.\n\n[https://github.com/Mathews-Tom/no-magic](https://github.com/Mathews-Tom/no-magic)",
          "score": 1,
          "created_utc": "2026-02-15 11:10:09",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1r9dbt6",
      "title": "How do you test LLM for quality ?",
      "subreddit": "LLMDevs",
      "url": "https://www.reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "author": "Easy_Ask5883",
      "created_utc": "2026-02-19 22:19:05",
      "score": 7,
      "num_comments": 11,
      "upvote_ratio": 1.0,
      "text": "I'm building something for AI teams and trying to understand the problem better.\n\n1. Do you manually test your AI features? \n\n2. How do you know when a prompt change breaks something?\n\n  \nAt AWS we have tons of associates who do manual QA (mostly irrelevant as far as I could see) but I dont think startups and SMBs are doing it. ",
      "is_original_content": false,
      "link_flair_text": "Discussion",
      "permalink": "https://reddit.com/r/LLMDevs/comments/1r9dbt6/how_do_you_test_llm_for_quality/",
      "domain": "self.LLMDevs",
      "is_self": true,
      "comments": [
        {
          "id": "o6bn718",
          "author": "Comfortable-Sound944",
          "text": "As with any QA testing, some don't do it, some do it badly, some do it well but manual, some automated it, and many adjust it over time as it makes sense.",
          "score": 2,
          "created_utc": "2026-02-19 22:35:04",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c8hjz",
          "author": "charlesthayer",
          "text": "I write Evals (well agentic evals). Meaning\n\n1. A way to score your output. (e.g. llm-as-judge or jury)\n2. A set of inputs to test.\n3. A fast and simple way to run this. (like a benchmark)\n\nThere are many ways to achieve this, but you can start very simply and grow. I use Arize Phoenix for traces/spans, and they have large-scale Eval features.\n\n\\- Arize Phoenix Evals: [https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals](https://arize.com/docs/phoenix/evaluation/tutorials/run-evals-with-built-in-evals)  \n\\- Article I wrote: [https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f](https://medium.com/towards-artificial-intelligence/ai-sw-engineers-youre-not-prod-ready-until-you-have-this-cd37beb8d06f)\n\n\\- Commercial tool (Braintrust evals): [https://www.braintrust.dev/docs/evaluation](https://www.braintrust.dev/docs/evaluation)",
          "score": 2,
          "created_utc": "2026-02-20 00:37:08",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e2yc7",
              "author": "anuragsarkar97",
              "text": "I'll take a look at those. Also do you keep changing your evals constantly? Or use vibe coding to create evals as well.\n\nHow do you decide which model to use and when",
              "score": 1,
              "created_utc": "2026-02-20 08:44:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6btgbh",
          "author": "Dimwiddle",
          "text": "It's always going to be a mix of automated and manual. There's also some cool ideas using skills with a QA agent, but that doesn't sound that ideal to me. \n\nI've been looking at ways to make AI code less 'viby' and have been experimenting with translating specs in to machine verifiable contracts, using test stubs. So far it's reduced a good amount bugs.",
          "score": 1,
          "created_utc": "2026-02-19 23:09:37",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c54b0",
          "author": "zZaphon",
          "text": "https://replayai-web.fly.dev",
          "score": 1,
          "created_utc": "2026-02-20 00:17:28",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6c5gbe",
          "author": "paulahjort",
          "text": "Run the same prompt suite across multiple model checkpoints and track regression automatically in Weights&Biases.\n\nThe infra side of this is underrated too. Teams often skip systematic eval because spinning up a GPU to run a full eval suite feels heavyweight. Try a CLI tool like Terradev.\n\n[*github.com/theoddden/terradev*](http://github.com/theoddden/terradev)",
          "score": 1,
          "created_utc": "2026-02-20 00:19:22",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6diz7p",
          "author": "Ok_Constant_9886",
          "text": "We use deepeval (open-source): [https://github.com/confident-ai/deepeval](https://github.com/confident-ai/deepeval)\n\nAlso has a commercial platform confident ai: [https://www.confident-ai.com/](https://www.confident-ai.com/)",
          "score": 1,
          "created_utc": "2026-02-20 05:43:29",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "o6dr5dc",
          "author": "Slight_Republic_4242",
          "text": "We learned this the hard way. At first, we ‚Äútested‚Äù by just trying prompts ourselves and saying, ‚ÄúLooks good.\n\nThen one small prompt **change** broke.: formatting, tone, edge cases and sometimes logic\n\nAnd we didn‚Äôt notice until a user complained. LLMs don‚Äôt fail loudly.  \nThey fail quietly.\n\nNow we:\n\na. Keep fixed test inputs\n\nb. Compare outputs before & after changes\n\nc. Check edge cases on purpose\n\nd. Track regressions like real software\n\nIt‚Äôs not perfect.  \nBut treating prompts like code changed everything.",
          "score": 1,
          "created_utc": "2026-02-20 06:54:28",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6driw5",
              "author": "anuragsarkar97",
              "text": "That makes sense I'm doing the same thing too. I guess time to build a product out of it.\n10-15% of my time I'm trying to fix either the system prompt of formating or something else",
              "score": 1,
              "created_utc": "2026-02-20 06:57:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "o6e2r8n",
          "author": "AnythingNo920",
          "text": "in reality most SMBs do vibe testing, unless benchmarks are their key selling point. ",
          "score": 1,
          "created_utc": "2026-02-20 08:42:33",
          "is_submitter": false,
          "replies": [
            {
              "id": "o6e3108",
              "author": "anuragsarkar97",
              "text": "Interesting, so it's not so high on priority list. But eventually they need know how is the AI performing in some way right?",
              "score": 1,
              "created_utc": "2026-02-20 08:45:06",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    }
  ]
}