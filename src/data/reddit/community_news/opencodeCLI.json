{
  "metadata": {
    "last_updated": "2025-12-31 10:27:10",
    "time_filter": "week",
    "subreddit": "opencodeCLI",
    "total_items": 21,
    "total_comments": 82,
    "file_size_bytes": 89466
  },
  "items": [
    {
      "id": "1pv2foa",
      "title": "Tokscale - Finally a token tracker for OpenCode and Claude Code",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1pv2foa",
      "author": "junhoyeo",
      "created_utc": "2025-12-25 01:39:33",
      "score": 48,
      "num_comments": 7,
      "upvote_ratio": 0.98,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pv2foa/tokscale_finally_a_token_tracker_for_opencode_and/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nw78yqi",
          "author": "Mr-Zero-000",
          "text": "I think I found what I was looking for . Thanks üòä",
          "score": 1,
          "created_utc": "2025-12-27 15:17:58",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvqkpo",
              "author": "junhoyeo",
              "text": "So glad I could help! We now support AmpCode and Factory Droid too. Also rolled out a bunch of improvements and bug fixes, along with more precise token pricing.",
              "score": 1,
              "created_utc": "2025-12-31 07:58:19",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwlx2a7",
          "author": "New_Leaf_07_12",
          "text": "This is great. I'm trying to tighten up my AI spending. I'm not trying to spend *no money*, I'm trying to save *a little money* and use AI judiciously. I also don't want to forget how to code, so it is good to have a reality check on the economic side as well.",
          "score": 1,
          "created_utc": "2025-12-29 20:38:07",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvqmx0",
              "author": "junhoyeo",
              "text": "Thanks. More tokens... or smart tokens are always good,",
              "score": 1,
              "created_utc": "2025-12-31 07:58:53",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwp7b9v",
          "author": "cynuxtar",
          "text": "This is amazing! really great!",
          "score": 1,
          "created_utc": "2025-12-30 08:36:29",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwvqc3b",
              "author": "junhoyeo",
              "text": "Thanks! Happy to hear you liked my project",
              "score": 1,
              "created_utc": "2025-12-31 07:56:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pvzb24",
      "title": "Three years of experimenting with AI agents. Here's what I learned.",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pvzb24/three_years_of_experimenting_with_ai_agents_heres/",
      "author": "madolu2",
      "created_utc": "2025-12-26 08:19:30",
      "score": 48,
      "num_comments": 24,
      "upvote_ratio": 0.91,
      "text": "I've been using OpenCode since the early betas and GLM since version 4. During that time I've tried countless prompt patterns and agent designs. Most didn't quite deliver, but a few approaches seemed to work consistently.\n\nA bit about me: I'm a Clojure developer with 5+ years of experience and a Solution Architect for 2+ years. My daily driver is Emacs/Doom. I spend a lot of time doing vibe coding‚Äîrapid PoCs to verify architectural concepts and run calculations. When I'm writing production code, I work in tandem with Grok Code and the coder agent.\n\nThese agents are tuned around GLM4.6/4.7 and Grok Code, and I use them every day in my work.\n\n# The Agents\n\n# _arch ‚Äî Architecture Planning\n\nThis agent focuses on breaking down problems rather than writing code. It uses complexity frameworks and applies a \"bare minimum\" filter to help identify what's actually needed for an MVP.\n\nHow it works in practice: if you don't know System Design at all, it sets a good direction with atomic tasks. If you do know it well, it helps you find blind spots in your solution. Don't treat it as a source of truth, but it's been useful for generating JIRA-formatted tasks with deployment considerations.\n\n# _coder ‚Äî Code Implementation\n\nAn autonomous coding agent that reads the existing codebase before making changes. It follows the ReAct pattern‚Äîreasoning, planning, acting, observing, reflecting.\n\nThis is the most unstable agent. It depends heavily on whether the model actually listens to instructions. There's some copium involved here, but sometimes it does remember about DRY, SOLID, and proper error handling. When it works, it catches more edge cases because it understands the context first.\n\n# _writer ‚Äî Content Creation\n\nHigher temperature agent designed for narrative work. It goes through multiple thinking phases before writing, which tends to produce more natural prose.\n\nThis is the best creative agent I've built. I use it regularly to edit articles and releases, summarize meetings, and write documentation. It's become my go-to for anything that needs to read like it was written by a person, not an LLM.\n\n# _beagle ‚Äî Research Assistant\n\nStarts with a query and follows information trails, building connection maps between related concepts. Every fact gets a source citation, and it provides a confidence rating.\n\nThis is my magnum opus. I finally managed to build an agent that does iterative hierarchical web search, properly understanding terms along the way. It's especially valuable for unpopular domains where you need papers from arXiv or Medium posts written by actual researchers working on the problem.\n\n# How I Use Them\n\nI run these agents both as primary assistants and as sub-agents for specific tasks. I also actively use [OpenSpec](https://github.com/Fission-AI/OpenSpec) in my workflow ‚Äî *big* *shoutout to the Fission-AI team*. I even opened an issue to let `openspec-apply/proposal` use the current active agent instead of being limited to just Build.\n\n# MCP Tools I Use\n\n|Tool|Purpose|\n|:-|:-|\n|**Context7**|Library documentation with semantic search|\n|**zread**|GitHub repository search and file reading|\n|**zai-mcp-server**|Image analysis, OCR, error screenshot diagnosis|\n|**web-search-prime**|Web search with time-based filters|\n|**web-reader**|Converting web pages to markdown|\n|**playwright**|Browser automation|\n\n# Some Observations\n\nSpecialization seems to work better than trying to have one agent do everything. Different temperatures and permission sets for different tasks have been more reliable than a general-purpose assistant.\n\nI've set thinking to English across all agents while keeping responses in the language I'm using‚Äîthis seems to improve reasoning quality.\n\nThese prompts are tuned around GLM4.7 with unlimited tokens, so your mileage may vary with different models.\n\nRepository: [https://github.com/veschin/opencode-agents](https://github.com/veschin/opencode-agents)",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pvzb24/three_years_of_experimenting_with_ai_agents_heres/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nw03w4y",
          "author": "yookibooki_",
          "text": "Awesome. Can you share your full setup?",
          "score": 3,
          "created_utc": "2025-12-26 09:56:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0bvbi",
              "author": "madolu2",
              "text": "my setup\n\neditor - emacs (nibelung theme, agave font)  \nos - arch linux  \nllm ide - sst/opencode  \nllm vendors - openrouter (grok/claude), [z.ai](http://z.ai) glm  \nbrowser - zen  \nremarkable opencode settings\n\nhttps://preview.redd.it/vowuy2188j9g1.png?width=652&format=png&auto=webp&s=a33187f2b6a5ec5a9edf26dd840ec7297ae0fa98",
              "score": 5,
              "created_utc": "2025-12-26 11:17:01",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw0edm6",
                  "author": "yookibooki_",
                  "text": "Much appreciated. Already using your agents",
                  "score": 1,
                  "created_utc": "2025-12-26 11:41:27",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nw1qr2q",
                  "author": "SynapticStreamer",
                  "text": "How is z.ai GLM? Been looking at it. First year is cheap because of the Christmas deal. Thinking about trying it.",
                  "score": 1,
                  "created_utc": "2025-12-26 16:56:40",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw09p88",
          "author": "Punkstersky",
          "text": "You should check out playwriter instead of playwright mcp. Its a uinque mcp server combined with a chrome extension that adds minimum context and guve u access to manipulate current open tabs on ur normal chrome window",
          "score": 2,
          "created_utc": "2025-12-26 10:55:14",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5tv6z",
          "author": "Narrow-Breakfast126",
          "text": "Maker of OpenSpec here, thanks for the shoutout and the support! \n\nWe‚Äôre always looking to improve the project, if theres any feedback, drop it here or in the discord :)",
          "score": 2,
          "created_utc": "2025-12-27 08:26:38",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw0ddvo",
          "author": "Aaku1789",
          "text": "how exactly do you use openspec on a completely new project? and how do you use it if you are using it in a team?",
          "score": 1,
          "created_utc": "2025-12-26 11:31:57",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw0z8r0",
              "author": "madolu2",
              "text": "i like to work through all the scenarios in BDD format. this works for both new and old projects, and can be shared with the team. init -> proposal -> apply -> archive -> proposal ...",
              "score": 3,
              "created_utc": "2025-12-26 14:21:30",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw0dqdf",
          "author": "klocus",
          "text": "So you're saying you've been using AI agents to write code for three years, even before they existed, right?",
          "score": 1,
          "created_utc": "2025-12-26 11:35:21",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw10aw5",
              "author": "madolu2",
              "text": "just a loud post title; but I explore neural networks may be for 8 years, from perceptron and for nowadays, wrote and trained my own, and as soon as the first commercial powerful llm appeared, I began to use them. Agent - just a network of weights that can use tools, or all past experience should be cancelled because the word \"agent\" was not used back then?",
              "score": 1,
              "created_utc": "2025-12-26 14:28:18",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw1tplp",
          "author": "FunnyRocker",
          "text": "Thanks these are good.\nHave you thought about eval-ing your agents and testing against multiple possible models to develop a baseline to iterate against?",
          "score": 1,
          "created_utc": "2025-12-26 17:12:23",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw46y1s",
          "author": "aeroumbria",
          "text": "Do you use subagents / orchestrators? I tried a few times and I feel they just suck compared to simple plan->build or variants of it. Subagents always miss out on important information it is not provided, and will occasionally undo previously completed steps because it keeps forgetting what is just edited and what is not. Letting OpenCode naturally reach context limit and auto-compact seems to be more reliable, even when it happens at places I might consider unfortunate.",
          "score": 1,
          "created_utc": "2025-12-27 01:05:13",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw5pzyk",
              "author": "madolu2",
              "text": "no more. the problem is that if you delegate a task to an agent, he loses \\~20% of the details of the task, and if he then delegates it to someone else, he loses even more. With the current llm architecture, which are rigidly tied to the context window, there is no way to build codependent autonomous systems. i use primary agents for general tasks, may be subagents for research only tasks.",
              "score": 1,
              "created_utc": "2025-12-27 07:49:24",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw61ujf",
                  "author": "djudji",
                  "text": "I like this take. Skills instead of Agents.\nBut you can pass the context to a separate agent (a separate context window), right?",
                  "score": 1,
                  "created_utc": "2025-12-27 09:44:51",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw65muk",
          "author": "koderkashif",
          "text": "You can do this setup in an easy one click way with oh my opencode",
          "score": 1,
          "created_utc": "2025-12-27 10:22:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwimysm",
          "author": "korino11",
          "text": "How it can work with codebase + concepts descriptions of the projects that not fill in a context? All pain with GLm only in that, i do not not how, but gpt5.2 have a better context windows and when he ,aking a compact of context, he doesnt forget all thigs..",
          "score": 1,
          "created_utc": "2025-12-29 09:09:03",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwjb8cc",
              "author": "madolu2",
              "text": "Different models have different context window sizes and techniques for working with them. If I'm not mistaken, gpt5 has 400K and glm4.7 has 200K. The context difference is already at least 2 times. and to work, you don‚Äôt need to immerse the entire code base in the LLM context, you need to find relevant files, and modern LLMs can search by code quite effectively",
              "score": 1,
              "created_utc": "2025-12-29 12:41:28",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nvzz7w6",
          "author": "cybercorey",
          "text": "This may be exactly what I'm looking for cheers",
          "score": 1,
          "created_utc": "2025-12-26 09:06:43",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvzwk9z",
          "author": "rtfm_pls",
          "text": "so all this text just to promo glm?",
          "score": -2,
          "created_utc": "2025-12-26 08:38:38",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzyf9e",
              "author": "madolu2",
              "text": "no promo except my repo. don't give a shit about vendors or big capital; what works, works.\n\nused claude sonnet/opus in parallel the whole time. too many hallucinations for what it costs. that's why it never got mentioned.\n\njust choosing models that actually deliver. sharing these configs because when i started, nothing like this existed and i had to build it all from scratch.",
              "score": 4,
              "created_utc": "2025-12-26 08:58:16",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pyzzak",
      "title": "goodbye windsurf codex and cursor opencode is evolving too fast",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/gallery/1pyzzak",
      "author": "ZookeepergameFit4082",
      "created_utc": "2025-12-29 22:16:38",
      "score": 43,
      "num_comments": 10,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pyzzak/goodbye_windsurf_codex_and_cursor_opencode_is/",
      "domain": "reddit.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwmkchp",
          "author": "Doovester",
          "text": "I am watching the GitHub repo since some few days they closed 400 issues in matter of days. Maybe many duplicates but still.",
          "score": 6,
          "created_utc": "2025-12-29 22:32:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwmose7",
          "author": "hyperschlauer",
          "text": "Opencode is lovely",
          "score": 5,
          "created_utc": "2025-12-29 22:55:40",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwpg54y",
              "author": "whspb",
              "text": "Is it support windows? üôè",
              "score": 1,
              "created_utc": "2025-12-30 09:58:53",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwnlay9",
          "author": "SynapticStreamer",
          "text": "The CLI is significantly better than the GUI. I sincerely love the very simple \"plan\" and \"build\" modes. I find his functionality superior to any other platform I've used yet.\n\nStill has some pretty serious bugs on Windows though. Once they're sorted, it'll be my full time without question.",
          "score": 3,
          "created_utc": "2025-12-30 01:54:09",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwoibgc",
              "author": "Ang_Drew",
              "text": "mention also the code it produces is lot better (compared to all other agentic)\n\nthe plan mode isnt just plan, it asked you for confirmations too, and we can chat until the plan perfect. also multi model mindset is perfect. plan with gpt 5.2 high. build with frontend subagent using gemini 3 pro. backend subagent using gpt 5.2 medium.\n\nit's just perfect combo! one shot everything 90% of the times)",
              "score": 2,
              "created_utc": "2025-12-30 05:07:28",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwoqqi0",
          "author": "Erebea01",
          "text": "Just want to add at how awesome it is that I can scroll while using tmux without having to enter scrollmode",
          "score": 3,
          "created_utc": "2025-12-30 06:09:52",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwponln",
          "author": "Bob5k",
          "text": "If you need gui to do technical stuff then id say work on your skills. You'll thank me at some point as servers don't have gui-so being familiar with terminal, json, XML, Linux will be highly beneficial especially if you either don't want to spend a lot on hosting or you're working on a profit margin where you even more don't want to overspend.",
          "score": 1,
          "created_utc": "2025-12-30 11:16:11",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwo8ifw",
          "author": "zhambe",
          "text": "> the devs are absolute madmen. they are pushing 2-3 updates per day\n\nOf course they are, it's not like they're writing the code by hand",
          "score": 0,
          "created_utc": "2025-12-30 04:04:34",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwojzg7",
              "author": "dimonchoo",
              "text": "Sounds not friendly)",
              "score": -1,
              "created_utc": "2025-12-30 05:19:08",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pur0n5",
      "title": "SURVEY: Which free model do you prefer and what do you usually use it for?",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/4h4qwk5pf69g1.jpeg",
      "author": "Wrong_Daikon3202",
      "created_utc": "2025-12-24 16:17:10",
      "score": 31,
      "num_comments": 19,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pur0n5/survey_which_free_model_do_you_prefer_and_what_do/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvr7jjq",
          "author": "abeecrombie",
          "text": "Glm 4.7. Its a nice step up from 4.6. Big pickle.",
          "score": 14,
          "created_utc": "2025-12-24 18:28:51",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtbe6l",
              "author": "Mysterious_Ad_2326",
              "text": "Im all-win with GLM 4.6/4.7. Works Luke a charm. Qwen coder not bad as well.",
              "score": 3,
              "created_utc": "2025-12-25 02:38:15",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvrwvyo",
          "author": "armindvd2018",
          "text": "Grok Just for subagent",
          "score": 5,
          "created_utc": "2025-12-24 20:53:23",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvtbjoe",
              "author": "Mysterious_Ad_2326",
              "text": "How to get a free API for Grok? Tell us more about please.",
              "score": 2,
              "created_utc": "2025-12-25 02:39:25",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvu10ik",
                  "author": "LaughterOnWater",
                  "text": "https://preview.redd.it/tlbdt7l6ka9g1.png?width=491&format=png&auto=webp&s=9d62e54f16df2aa1dcb429943c0704480a016e34\n\n\\`/models\\`  \nThen do a search on \\`Grok\\`  \nYou'll see a list of them come up.  \nChoose the free Grok Code Fast 1 OpenCode Zen (Free).  \nBob's your uncle.",
                  "score": 4,
                  "created_utc": "2025-12-25 06:07:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvsn8od",
          "author": "CC_NHS",
          "text": "Game Dev - GLM-4.7 (Mostly as a backup for Opus) previously used Big Pickle",
          "score": 5,
          "created_utc": "2025-12-24 23:41:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqt3ls",
          "author": "Extension-Pen-109",
          "text": "Grok, cool output on terminal",
          "score": 4,
          "created_utc": "2025-12-24 17:10:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvsg74e",
              "author": "Artagious",
              "text": "Is it free? What‚Äôs the limit usage like?",
              "score": 2,
              "created_utc": "2025-12-24 22:52:24",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvsjkh1",
                  "author": "Extension-Pen-109",
                  "text": "I got free using github copilot plan (10$/month)",
                  "score": 5,
                  "created_utc": "2025-12-24 23:15:18",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvu0ied",
          "author": "LaughterOnWater",
          "text": "I use OpenCode for web dev. To be clear, their best free options are their own natively available models. Big Pickle and Grok Code Fast 1 are not too bad for straightforward tasks. Their GLM 4.7 is a standout. It‚Äôs nearly on par with something like Sonnet 4.5, but for a fraction of the cost.\n\nI‚Äôve tried using OpenRouter‚Äôs free models through OpenCode, but they‚Äôre almost always hampered or virtually unusable. So my go-to is either OpenCode‚Äôs own free models or, for more demanding work, I switch to one of OpenRouter‚Äôs paid models. Occasionally, when I need more reasoning power, I‚Äôll use the Claude API through OpenRouter. I try to use the most cost-efficient model for the task at hand. \n\nWhile it's available, I'll probably continue to rely quite a bit on OpenCode's free GLM 4.7.",
          "score": 3,
          "created_utc": "2025-12-25 06:02:27",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvts60b",
          "author": "gh0st777",
          "text": "Free is good for practicing and learning.\n\nFor hobbies look for a cheap subscription.\n\nFor serious projects and work that you rely on for income, you need the best, get a claude max subscription.",
          "score": 3,
          "created_utc": "2025-12-25 04:49:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbqy4u",
              "author": "t4a8945",
              "text": "Best summary as of now.",
              "score": 1,
              "created_utc": "2025-12-28 06:49:16",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nvtj4jo",
          "author": "Few-Mycologist-8192",
          "text": "My experience: the free ones are wasting your time , if you are trying to build some thing , use claude sonnet. if it is tool expensive for you, try to make some money and use claude sonnet , be laser focus and not waste your time , time is , very valueable. If you want to save money, learn how to prompt/ask AI in a more efficient way.",
          "score": 0,
          "created_utc": "2025-12-25 03:37:55",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvutc5b",
              "author": "[deleted]",
              "text": "i make the top 1% of tech salary for my level in my country and I still choose to use free as much as I can. for work, we have unlimited cursor use allowed by company (there is a limit but its so high its virtually impossible to get there), but I don't use that for my own projects. i still get a lot of great work done (better quality than my office work, because at home I build with passion and love) solely by using free models from OpenCode Zen. Long story short, you got skill issues mate, free is good enough! My side project work already earned me 1700$ for last week of work and will end with about 8000$ more by mid jan.",
              "score": 2,
              "created_utc": "2025-12-25 11:05:38",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nvutf6o",
                  "author": "[deleted]",
                  "text": "of course, it could be \"easier\" to just pay 200 for claude or 150 for gemini maximum tier subscriptions and forget about it. but I'd rather use my brain a bit more than fund the techbro bubble cult, no thanks :)",
                  "score": 2,
                  "created_utc": "2025-12-25 11:06:34",
                  "is_submitter": false,
                  "replies": []
                },
                {
                  "id": "nvvpzcp",
                  "author": "Few-Mycologist-8192",
                  "text": "I accept this , that is also the point: pro developers will earn more by leaveraging AI , I believe you enjoying coding like a hobby right? coding is your passion , not just get the job done;  and I also believe , these model will be better and better , espeically for GLM 4.7 , they say it work as smothly as Claude sonnet. But still ,It is really about the skill; also  , good work for you side project , that is a very good earning , what project you are doing for this money? I really want to know.",
                  "score": 1,
                  "created_utc": "2025-12-25 15:31:11",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nvtjfoy",
              "author": "Few-Mycologist-8192",
              "text": "sorry to say this, but it is the truth right now , also , GLM and Minimax models looks promissing, try it after few months , give it some time to make it happen.",
              "score": -1,
              "created_utc": "2025-12-25 03:40:21",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pz8ts9",
      "title": "Devs @ Opencode..... What's the sauce in that insane speed",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pz8ts9/devs_opencode_whats_the_sauce_in_that_insane_speed/",
      "author": "Top-Chain001",
      "created_utc": "2025-12-30 04:46:42",
      "score": 28,
      "num_comments": 15,
      "upvote_ratio": 0.89,
      "text": "The speed is not normal , it's like you guys cracked AGI.\n\nWhat's the sauce here? any workflows, tips, anything for us mortals would be the best new years gift a SWE can plead for except maybe opus 5",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pz8ts9/devs_opencode_whats_the_sauce_in_that_insane_speed/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nwpcrwi",
          "author": "mohadel1990",
          "text": "Because at this point it is more PRs from the community than the devs themselves, their Github workflows for detecting duplicate issues (best I've seen), code reviews, etc. makes it very encouraging to contribute. Also their codebase is well structured and AI agents really don't have that much of a hard time navigating it. I am so sold on OpenCode that I made a plugin to bring Claude Code skills within less than 24 hours of Anthropic releasing it. When the plugin got popular enough the devs let me do the core feature PR.\n\n You simply can't beat thousands of developers working on one project! Practically for free! Pure genius.",
          "score": 19,
          "created_utc": "2025-12-30 09:27:35",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwptckl",
              "author": "HunterNoo",
              "text": "I‚Äôve tried opencode but I fell back to Claude code. Maybe worth giving it a shot, but why do you think it‚Äôs a lot better ?",
              "score": 3,
              "created_utc": "2025-12-30 11:55:55",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwq4po7",
                  "author": "anfelipegris",
                  "text": "Look for \"Oh My OpenCode\", you'll have fun",
                  "score": 4,
                  "created_utc": "2025-12-30 13:17:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwoohj7",
          "author": "Any_Lavishness5419",
          "text": "I just looked at their commit velocity on their repo, its crazy",
          "score": 5,
          "created_utc": "2025-12-30 05:52:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp0k11",
              "author": "UnbeliebteMeinung",
              "text": "Because such projects are 100% ai code. They dont even bother with the hate but instead work on the software.",
              "score": 5,
              "created_utc": "2025-12-30 07:33:56",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwp8n95",
                  "author": "Top-Chain001",
                  "text": "[https://x.com/beginbot/status/2005809608598900816?s=20](https://x.com/beginbot/status/2005809608598900816?s=20)\n\nSomebody asked the same question haha",
                  "score": 0,
                  "created_utc": "2025-12-30 08:48:53",
                  "is_submitter": true,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwp6zv1",
          "author": "verkavo",
          "text": "Maybe they're just... using opencode?",
          "score": 3,
          "created_utc": "2025-12-30 08:33:30",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwp8mz4",
              "author": "Top-Chain001",
              "text": "[https://x.com/beginbot/status/2005809608598900816?s=20](https://x.com/beginbot/status/2005809608598900816?s=20)\n\nSomebody asked the same question haha",
              "score": 1,
              "created_utc": "2025-12-30 08:48:49",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwpwxa6",
          "author": "Fearless-Elephant-81",
          "text": "They also have a very generous free model which helps use their product and basically their product works with virtually all other subscriptions (and the APIs too)",
          "score": 3,
          "created_utc": "2025-12-30 12:23:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr9ub5",
              "author": "Erebea01",
              "text": "It is kinda neat that I can just enter an api key and don't have to worry about setting up the specific models",
              "score": 1,
              "created_utc": "2025-12-30 16:51:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwqb3ar",
          "author": "Otherwise-Pass9556",
          "text": "A lot of the insane speed usually comes down to how much they‚Äôve optimized their build + test flow and how much they parallelize things. Once teams start treating build time as a first-class problem, the gains add up fast. Tools like Incredibuild exist for that kind of acceleration but a lot of it is just solid infra + workflow decisions.",
          "score": 2,
          "created_utc": "2025-12-30 13:55:50",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pwkpvw",
      "title": "Why OpenCode instead of Antigravity?",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/063flc75en9g1.jpeg",
      "author": "Puzzleheaded_Leek258",
      "created_utc": "2025-12-27 01:16:39",
      "score": 19,
      "num_comments": 15,
      "upvote_ratio": 0.87,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pwkpvw/why_opencode_instead_of_antigravity/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw4t0y4",
          "author": "theGnartist",
          "text": "I use OpenCode so I can easily use more than just Claude all in one place. I use sub agents with grok, Gemini, and qwen coder to write code and review each others code and the output of my ai code has become orders of magnitude more reliable since doing so. Way better than just using Claude in cc alone. \n\nClaude is my main orchestration because I enjoy interacting with it the most. I just copied the Claude code system prompt and customized it to make the prompt for my Claude agent.",
          "score": 9,
          "created_utc": "2025-12-27 03:27:47",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw8r7kt",
              "author": "Impossible_Comment49",
              "text": "How did you setup your subagents? Can each subagent use different llm provider?",
              "score": 1,
              "created_utc": "2025-12-27 19:55:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nw8rubw",
                  "author": "theGnartist",
                  "text": "I configure mine using markdown [https://opencode.ai/docs/agents/#markdown](https://opencode.ai/docs/agents/#markdown) You an set any provider/model you access to for any subagent. \n\nI actually just provided this doc link to the default Build agent with claude as the model and asked it to help me configure a subagent for a specific task using a specific model.",
                  "score": 3,
                  "created_utc": "2025-12-27 19:58:28",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nw4uhxh",
          "author": "AriyaSavaka",
          "text": "Just experiment and build shit with each one and feel them out. No need to seek validation for your choice.",
          "score": 6,
          "created_utc": "2025-12-27 03:37:42",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw551v2",
          "author": "Mysterious_Ad_2326",
          "text": "I will share with you my perspective : opencode is open source and no one need red-tape a company to implemented changes or make it compatible with ant other private feature. Fork it and go free. For instance, we can make it compatible with Anthropic Skills. So we can easily take advantage of any technology if we want and know how to code it. \nFuture: you will be skilled using a tool that will receive constant updates from all sort of people around the world. Long life on edge or near edge technology. \nSo you will spend the most precious asset you have in life on a tool which you have full control, long lifetime, and very likely will adapt to all new trends of the future compared to all competitors.",
          "score": 4,
          "created_utc": "2025-12-27 04:51:36",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5ay51",
          "author": "Ok_Road_8710",
          "text": "There is  no top 1 coding agent. You are the coding agent",
          "score": 3,
          "created_utc": "2025-12-27 05:36:02",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw5inp4",
          "author": "pythonr",
          "text": "To be confident you need to try it out.\n\nThe premise of the post you quoted here is wrong. There are many reasons to use open code such as good UX, frequent updates, no vendor login, pay as you go, a/b testing of models, integration of own tools or plugins, custom command creation, open source, ‚Ä¶",
          "score": 3,
          "created_utc": "2025-12-27 06:41:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6dwsv",
          "author": "noiserr",
          "text": "I followed this rule my entire carrier. Always use vendor agnostic open source tools. Because the issue is time investment. Because if you're going to spend time learning about all the intricacies of a tool, you don't want that to be some tool a vendor can pull the rug under you.\n\nThere is no telling which model will be best tomorrow. And OpenCode being designed from ground up to work with all of them will have the best chance at staying the single agent I use.\n\nAlso I use local models and OpenCode supports those out of the box. And finally OpenCode is great.",
          "score": 3,
          "created_utc": "2025-12-27 11:42:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw6lgsf",
          "author": "Worldwidegoatski",
          "text": "Using Opencode with Ohmyopencode and antigravity auth, this shit is unbelievable, given the amount of IDEs, terminal and whatever agents exists I've basically tried them all the multi agent, with LSP, combined with Opus 4.5, gemini 3 pro and gpt 5.2 makes opencode really a tool in a league of its own",
          "score": 3,
          "created_utc": "2025-12-27 12:46:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwarndf",
              "author": "sams8com",
              "text": "The only problem is when you are using are testing the app you cant send a screenshot to explain clearly",
              "score": 1,
              "created_utc": "2025-12-28 02:42:07",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw6b65j",
          "author": "pilkafa",
          "text": "Simple, antigravity expects you to pay for Gemini sub. With open code you can pretty much anything what you have. You can even set your agents to different ai suppliers, for example I am thinking using ChatGPT for planning Claude for building¬†",
          "score": 1,
          "created_utc": "2025-12-27 11:16:05",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwcxc1q",
          "author": "puglife420blazeit",
          "text": "I haven‚Äôt used opencode in a while but I‚Äôve been blown away by factory.ai droid. It‚Äôs closed sourced and has a subscription model but you can bring your own apis",
          "score": 1,
          "created_utc": "2025-12-28 13:16:42",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwdm7z1",
              "author": "Puzzleheaded_Leek258",
              "text": "Why u prefer it?",
              "score": 1,
              "created_utc": "2025-12-28 15:46:01",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1px8nbz",
      "title": "Add voice input to OpenCode ‚Äî Ottex is a free voice-to-text app for OpenRouter users (native macOS, BYOK)",
      "subreddit": "opencodeCLI",
      "url": "https://v.redd.it/wc8n27lv5t9g1",
      "author": "ksanderer",
      "created_utc": "2025-12-27 21:08:20",
      "score": 17,
      "num_comments": 21,
      "upvote_ratio": 0.85,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1px8nbz/add_voice_input_to_opencode_ottex_is_a_free/",
      "domain": "v.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw9rs1s",
          "author": "noctrex",
          "text": "Or just use Handy:\n\n[https://github.com/cjpais/Handy](https://github.com/cjpais/Handy)\n\nFree, open source, uses local Whisper and Parakeet, and is very accurate, been using it for quite a while now.",
          "score": 3,
          "created_utc": "2025-12-27 23:14:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwa8yz9",
              "author": "rmoriz",
              "text": "Armin Ronacher (of flask fame) uses https://tryvoiceink.com/ on MacOS. He's regularly publishing videos about his workflow e.g. https://www.youtube.com/watch?v=X8M6U3QiC8Q",
              "score": 1,
              "created_utc": "2025-12-28 00:51:06",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwc1sil",
                  "author": "ksanderer",
                  "text": "Thanks, I‚Äôll check it out and see how it stacks up.",
                  "score": 1,
                  "created_utc": "2025-12-28 08:30:55",
                  "is_submitter": true,
                  "replies": []
                },
                {
                  "id": "nwcp98u",
                  "author": "SatoshiNotMe",
                  "text": "Tried them all, and settled on VoiceInk as well. Local , open source, one time payment,\nResponsive developer. Very flexible keyboard shortcuts to toggle record mode.",
                  "score": 1,
                  "created_utc": "2025-12-28 12:13:12",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwc1pyk",
              "author": "ksanderer",
              "text": "Thanks, I‚Äôll check it out and see how it stacks up.",
              "score": 1,
              "created_utc": "2025-12-28 08:30:14",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw97usi",
          "author": "rm-rf-rm",
          "text": "Fuck cloud for STT. Dont send your voice to some untrustworthy endpoint. Install Spokenly or the dozen other local STT apps that are free (as they should be) using local OSS models like Parakeet, Whisper.",
          "score": 3,
          "created_utc": "2025-12-27 21:26:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9a3h5",
              "author": "ksanderer",
              "text": "Local models aren‚Äôt quite there yet in terms of quality, compared to top tier models like gemini. I actually plan to add local model support as well.\n\nThe cloud part is more about what happens after transcription - removing all the ums and uhs, formatting text properly, etc.",
              "score": 1,
              "created_utc": "2025-12-27 21:38:07",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nw9peq2",
                  "author": "rm-rf-rm",
                  "text": "They definitely are good enough already. I'm using them.",
                  "score": 3,
                  "created_utc": "2025-12-27 23:00:48",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwcos4u",
              "author": "DemonicPotatox",
              "text": "i wonder why you think literally calling the gemini endpoint is untrustworthy lol",
              "score": 0,
              "created_utc": "2025-12-28 12:09:07",
              "is_submitter": false,
              "replies": [
                {
                  "id": "nwcwyx8",
                  "author": "rm-rf-rm",
                  "text": "You think Google is trustworthy?",
                  "score": 1,
                  "created_utc": "2025-12-28 13:14:08",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwaf7a9",
          "author": "c0nfluks",
          "text": "Shows a voice app, strips the audio. What a way to market your product‚Ä¶",
          "score": 2,
          "created_utc": "2025-12-28 01:28:16",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc0a20",
              "author": "ksanderer",
              "text": "It's a 30 min coding session, I thought no one would want to hear me for 30 minutes while I‚Äôm talking to AI .‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã\n\nBut, good point! Next time I‚Äôll choose a better format with voice. Thanks.",
              "score": 2,
              "created_utc": "2025-12-28 08:16:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwdwrfh",
          "author": "roiseeker",
          "text": "Wow really cool man! Works perfectly, Wispr is cooked",
          "score": 2,
          "created_utc": "2025-12-28 16:39:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwe0yep",
              "author": "ksanderer",
              "text": "üòÇ‚ù§Ô∏è",
              "score": 1,
              "created_utc": "2025-12-28 17:00:04",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw9euzp",
          "author": "960be6dde311",
          "text": "Why not just use MacOS built-in dictation? That's what I do with OpenCode.",
          "score": 1,
          "created_utc": "2025-12-27 22:03:12",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc1fnk",
              "author": "ksanderer",
              "text": "I will compare and get back to you. I would suspect that the quality of transcription will be much lower with default macos voice to text.\n\nHere is another video where I dictate the full reddit post without editing a single word \n\nhttps://www.reddit.com/r/macapps/s/6EOrL8ogsP",
              "score": 0,
              "created_utc": "2025-12-28 08:27:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwa3zy8",
          "author": "KnifeFed",
          "text": "I'm sorry, what does this have to do with OpenCode?",
          "score": 1,
          "created_utc": "2025-12-28 00:23:01",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwc10cg",
              "author": "ksanderer",
              "text": "Just wanted to show folks who haven‚Äôt tried voice-to-text that it‚Äôs actually a pretty nice way to work",
              "score": 1,
              "created_utc": "2025-12-28 08:23:16",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwdbjn0",
                  "author": "noiserr",
                  "text": "I type faster than I speak honestly. Plus how do you copy paste code or locations?",
                  "score": 2,
                  "created_utc": "2025-12-28 14:47:26",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pxziqe",
      "title": "I made opencode-telegram-notification-plugin to get notified whenever the llm finishes the task",
      "subreddit": "opencodeCLI",
      "url": "https://github.com/Davasny/opencode-telegram-notification-plugin",
      "author": "Davasny",
      "created_utc": "2025-12-28 19:07:12",
      "score": 16,
      "num_comments": 3,
      "upvote_ratio": 0.94,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pxziqe/i_made_opencodetelegramnotificationplugin_to_get/",
      "domain": "github.com",
      "is_self": false,
      "comments": [
        {
          "id": "nwg9e5o",
          "author": "Ivankax28",
          "text": "cool, goin to try",
          "score": 1,
          "created_utc": "2025-12-28 23:35:31",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwgfkfo",
          "author": "NanoCow",
          "text": "does it work on codenomad?",
          "score": 1,
          "created_utc": "2025-12-29 00:08:24",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwu1ng3",
          "author": "Any_Difference2404",
          "text": "Would be nice if i could instruct the agent to e.g. send me a telegram message when you have finished the task.\n\nIs that possible?",
          "score": 1,
          "created_utc": "2025-12-31 01:02:07",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pyxiri",
      "title": "I made openground, an opensource, on-device RAG tool that gives access to official docs to opencode (and other agents)",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pyxiri/i_made_openground_an_opensource_ondevice_rag_tool/",
      "author": "poweroutlet2",
      "created_utc": "2025-12-29 20:41:21",
      "score": 12,
      "num_comments": 4,
      "upvote_ratio": 0.94,
      "text": "Link: [https://github.com/poweroutlet2/openground](https://github.com/poweroutlet2/openground)\n\n\n\ntldr: openground lets you give controlled access to documentation to AI agents. Everything happens on-device.\n\nI'm sharing my initial release of openground, an opensource and completely on-device RAG tool that let's you give controlled documentation access to your coding agents. Solutions like and Context7 MCP provide a likely source of truth for docs, but their closed-source ingestion and querying pose security/privacy risks. openground aims to give users full control over what content is available to agents and how it is ingested. Find a documentation source (git repo or sitemap), add it to openground via the CLI, and openground will use a local embedding model and vector db (lancedb) to store your docs. You can then use the CLI to install the MCP server to your agent to allow the agent to query the docs via hybrid BM25 full-text and vector search.\n\nAgain, this is an initial release, so it is pretty barebones. Upcoming features I am working on:\n\n\\- specific library version handling (it currently only supports latest versions)\n\n\\- docs \"registry\" to allow pushing and pulling of documentation embeddings to S3\n\n\\- lighter-weight package\n\nSuggestions and PRs welcome! I'll also be around for discussion.",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pyxiri/i_made_openground_an_opensource_ondevice_rag_tool/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nwm2311",
          "author": "awfulalexey",
          "text": "Did you, by any chance, forget to drop the link here?",
          "score": 1,
          "created_utc": "2025-12-29 21:02:43",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmg44t",
              "author": "poweroutlet2",
              "text": "Oof I did... Here is the repo: [https://github.com/poweroutlet2/openground](https://github.com/poweroutlet2/openground)",
              "score": 2,
              "created_utc": "2025-12-29 22:10:52",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwm65ia",
          "author": "Potential-Leg-639",
          "text": "Github?",
          "score": 1,
          "created_utc": "2025-12-29 21:22:18",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwmg7qg",
              "author": "poweroutlet2",
              "text": "Sorry, forgot to include the link... Here you go: [https://github.com/poweroutlet2/openground](https://github.com/poweroutlet2/openground)",
              "score": 2,
              "created_utc": "2025-12-29 22:11:22",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pz1w4l",
      "title": "Building workflows in OpencodeCLI",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pz1w4l/building_workflows_in_opencodecli/",
      "author": "zashboy",
      "created_utc": "2025-12-29 23:34:43",
      "score": 10,
      "num_comments": 4,
      "upvote_ratio": 1.0,
      "text": "I've been looking for ways to build automated workflows within OpenCode, chaining multiple agents from multiple providers, but I couldn't find much information about how other people do this, or whether there are any plugins that provide better support. I've experimented with this idea and developed a command that allows me to define the type of workflow I want, as well as the prompt. Then, the supervisor agent takes over and passes the task to the planner, coder, reviewer, etc. I'm certain that I can achieve better quality code results this way. \n\nI've posted a brief explanation [here](https://zashboy.com/articles/opencode-supervisor-orchestrating-multi-agent-development-workflows).\n\nDoes anybody else do something like this? Are there currently any better ways of building workflows?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pz1w4l/building_workflows_in_opencodecli/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nwnejhx",
          "author": "robertmachine",
          "text": "AI is your friend just make sure you make a directory inside your project called .opencode and put a directory called agent, command etc and place your agents inside agent and I would create a master-agent.md which calls all your sub agents etc",
          "score": 2,
          "created_utc": "2025-12-30 01:16:19",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwni5pt",
              "author": "zashboy",
              "text": "Yes, I do something similar. I just keep the opencode folder containing the agents and commands in the \\~/.config folder, which allows me to share the same agents across all repositories.",
              "score": 2,
              "created_utc": "2025-12-30 01:36:46",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwplxh1",
          "author": "trmnl_cmdr",
          "text": "I wrote a script that runs my agent headless, I can assign different models to different stages, I don‚Äôt have an orchestration layer for it, it‚Äôs just a script I run against PRDs and come back to a finished project. Opencode has a strong SDK for this kind of thing",
          "score": 1,
          "created_utc": "2025-12-30 10:51:52",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwr8w0a",
              "author": "zashboy",
              "text": "That way, if you see that they're not doing the code exactly how you imagined, you can't interfere, right? Do you run the full process multiple times? In my experience, when an agent says the project is finished and ready for production, it's usually not the case.",
              "score": 1,
              "created_utc": "2025-12-30 16:46:59",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1py665l",
      "title": "Properly way to planning tasks?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1py665l/properly_way_to_planning_tasks/",
      "author": "awfulalexey",
      "created_utc": "2025-12-28 23:38:03",
      "score": 9,
      "num_comments": 17,
      "upvote_ratio": 1.0,
      "text": "Many people say that large tasks must first be planned with large models, for example, opus 4,5, then with small ones, for example, glm-4.7. So, my question is, how do you plan such large tasks now?\n\nYou ask first for a large model, come up with a task and create a markdown file, which will already contain a detailed description of the task and individual execution options, then drop the small model, complete, for example, tasks 1 and 2. Or How?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1py665l/properly_way_to_planning_tasks/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nwgbaso",
          "author": "ColdWeatherLion",
          "text": "My goal is to prevent the small model from ever needing to \"understand the whole project.\" It only needs to understand one atomic unit of work I call a Task. \n\nA task must touch fewer than 5 files (ideally 1) and the prompt for the executor must contain everything it needs to know, so it doesn't have to hallucinate the rest of the architecture.\n\nWe have Independent Work Trees. I don't queue tasks 1, 2, and 3. I launch them simultaneously if they don't block each other.",
          "score": 6,
          "created_utc": "2025-12-28 23:45:44",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwgbw44",
              "author": "awfulalexey",
              "text": "But technically, you asking to create md with task description?",
              "score": 3,
              "created_utc": "2025-12-28 23:48:56",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwgcia7",
                  "author": "ColdWeatherLion",
                  "text": "No it's a system prompt. The orchestrator is actually a custom agent/skill that produces these prompts. Opencode has Vibe-Kanban MCP",
                  "score": 5,
                  "created_utc": "2025-12-28 23:52:10",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            },
            {
              "id": "nwgn81z",
              "author": "trenescese",
              "text": "My goal is to prevent the intern from ever needing to \"understand the whole project.\" He only needs to understand one atomic unit of work I call a Task.\n\nA task must touch fewer than 5 files (ideally 1) and the directions given to the intern must contain everything he needs to know, so he doesn't have to hallucinate the rest of the architecture.",
              "score": 2,
              "created_utc": "2025-12-29 00:48:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nwhpfj8",
          "author": "pwarnock",
          "text": "spec-driven framework",
          "score": 2,
          "created_utc": "2025-12-29 04:33:09",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nwio8kx",
          "author": "Bob5k",
          "text": "Glm is not a small model considering the amount of parameters. Also it's quite capable model overall - and considering how hefty is opus' pricing compared to glm then the [coding plan](https://z.ai/subscribe?ic=CUEFJ9ALMX) is a no-brainer. \nHave in mind they still have the new year promo (and additional 10% on top of that with my link above)",
          "score": 1,
          "created_utc": "2025-12-29 09:21:10",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwiq219",
              "author": "awfulalexey",
              "text": "Yes, nice try sending your referral link. But no, I‚Äôve already purchased a Pro subscription for one quarter myself and actively use this model. Besides that, like many others, I also have several other subscriptions to different LLM models. I want to get the most out of this GLM, which is why I‚Äôm trying to optimize my process.",
              "score": 1,
              "created_utc": "2025-12-29 09:38:41",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwiriy7",
                  "author": "Bob5k",
                  "text": "Usually first thing when it comes to optimization would be to improve the input. People are trying to optimize LLMs while putting vague prompts and instructions into the tool. Try https://github.com/ClavixDev/Clavix and see - example excervise - put the same prompt into Clavix on glm mode and opus without Clavix and compare the end result. \nHope that helps.",
                  "score": 1,
                  "created_utc": "2025-12-29 09:52:27",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pwga4o",
      "title": "oh my opencode, Z.ai issue",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pwga4o/oh_my_opencode_zai_issue/",
      "author": "Prime_Lobrik",
      "created_utc": "2025-12-26 21:59:47",
      "score": 8,
      "num_comments": 7,
      "upvote_ratio": 0.83,
      "text": "Anyone already had this issue with [z.ai](http://z.ai) coding plan where you can auth with it in opencode but cant use it in the oh my opencode setup as a direct rooting?  \nI have tried a LOT of possibilities but each time i've hit the \"not valid configured model\" .\n\nwhat could be the fix? only an issue with [z.ai](http://z.ai) api, with others it works perfectly\n\nhttps://preview.redd.it/blvn3mmqem9g1.png?width=1270&format=png&auto=webp&s=5399e32a23722abbed71512e28e11cdd8a56b8ee\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pwga4o/oh_my_opencode_zai_issue/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nw3e9ua",
          "author": "Prime_Lobrik",
          "text": "ok update to myself and to anyone who might have the same issue, the model ID formatting when seting up agents is : \n\nzai-coding-plan/glm-4.7\n\nand if you're not sure, type \"opencode models\" in the terminal, it will show every model rooting\n\nI dont know why I did not thought of doing that earlier but hey, at least now its over :)",
          "score": 7,
          "created_utc": "2025-12-26 22:15:10",
          "is_submitter": true,
          "replies": [
            {
              "id": "nwbnnip",
              "author": "Mysterious_Ad_2326",
              "text": "Thank you very much! Very helpful!",
              "score": 1,
              "created_utc": "2025-12-28 06:20:39",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw3hvw7",
          "author": "RudyRobichaux",
          "text": "I loved this, but it also doesn't work with claude max at all, so I cant use opus.",
          "score": 3,
          "created_utc": "2025-12-26 22:35:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbni8p",
              "author": "Mysterious_Ad_2326",
              "text": "Same situation here. Claude is too much to my pocket.",
              "score": 1,
              "created_utc": "2025-12-28 06:19:25",
              "is_submitter": false,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5cnl3",
          "author": "[deleted]",
          "text": "[deleted]",
          "score": 1,
          "created_utc": "2025-12-27 05:49:37",
          "is_submitter": false,
          "replies": [
            {
              "id": "nw9txrx",
              "author": "Prime_Lobrik",
              "text": "If you are trying to setup the same file as me\n\nFirst check that you connected your api correctly \n\nAnd to get the correct opencode rooting, type : \"opencode models\" in your regular terminal\nIt will display all your models and their correct ID rooting according to opencode\n\nFor me it was zai-coding-plan/glm-4.7\n\nBecause thats how OC formats it",
              "score": 1,
              "created_utc": "2025-12-27 23:26:27",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nweilj8",
          "author": "pizza0502",
          "text": "Wats the difference of using the opencode glm-4.7-free vs the z.ai version? Is it the speed?",
          "score": 1,
          "created_utc": "2025-12-28 18:25:36",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwful0a",
              "author": "Prime_Lobrik",
              "text": "Mostly the speed yes, we dont know who is Opencode provider and since the model is free, the endpoint might get overloaded with requests\n\nOther than that, it is the exact same model ! :)",
              "score": 1,
              "created_utc": "2025-12-28 22:17:21",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pv98t4",
      "title": "How to use Sonnet 1M - with CC MAX sub, inside of OpenCode?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pv98t4/how_to_use_sonnet_1m_with_cc_max_sub_inside_of/",
      "author": "VisionaryOS",
      "created_utc": "2025-12-25 08:54:26",
      "score": 8,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "Hi\n\nI have all the other models with my CC max sub in opencode\n\nDoes anyone know how to make the 1m model available?\n\nhttps://preview.redd.it/6zupszszdb9g1.png?width=429&format=png&auto=webp&s=d0b67e565f2d018cc5d2e51926010332f02000c3\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pv98t4/how_to_use_sonnet_1m_with_cc_max_sub_inside_of/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nw3lw33",
          "author": "RudyRobichaux",
          "text": "Its only available via beta api",
          "score": 1,
          "created_utc": "2025-12-26 22:58:38",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvpfcn",
      "title": "A \"Wrapped\" CLI for OpenCode ‚Äî see your year in review",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pvpfcn/a_wrapped_cli_for_opencode_see_your_year_in_review/",
      "author": "moddi3",
      "created_utc": "2025-12-25 23:14:01",
      "score": 7,
      "num_comments": 3,
      "upvote_ratio": 0.82,
      "text": "Hey everyone,\n\nMade a small CLI tool that generates a \"Spotify Wrapped\" style summary of your OpenCode usage.\n\nShows:\n\n\\- Sessions, messages, tokens\n\n\\- Activity heatmap (GitHub-style)\n\n\\- Top models & providers\n\n\\- Longest streak\n\nnpx oc-wrapped\n\nIt's local-only ‚Äî just reads your data from \\~/.local/share/opencode and generates a shareable PNG.\n\nGitHub: [https://github.com/moddi3/opencode-wrapped](https://github.com/moddi3/opencode-wrapped)  \nX post: [https://x.com/moddi3io/status/2004215795405181325](https://x.com/moddi3io/status/2004215795405181325)\n\nShare your stats!  \nThanks and Merry Christmas to all of you and your families!\n\nhttps://preview.redd.it/fu8pqd5gmf9g1.png?width=1059&format=png&auto=webp&s=3c65fc0ecd347b037ee30ae805b412ad2031afaf\n\n",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pvpfcn/a_wrapped_cli_for_opencode_see_your_year_in_review/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nvy00oz",
          "author": "Ivankax28",
          "text": "how to use? sorry newbie here",
          "score": 1,
          "created_utc": "2025-12-25 23:50:26",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvy0wng",
              "author": "moddi3",
              "text": "npx oc-wrapped\nOr bunx \nYou should have node or bun",
              "score": 2,
              "created_utc": "2025-12-25 23:56:08",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvy2xpy",
                  "author": "Ivankax28",
                  "text": "thanks",
                  "score": 2,
                  "created_utc": "2025-12-26 00:08:52",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "1pxvynq",
      "title": "Pasted text as complete text instead of \"pasted 5 lines\"",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pxvynq/pasted_text_as_complete_text_instead_of_pasted_5/",
      "author": "EfficientHat0006",
      "created_utc": "2025-12-28 16:48:16",
      "score": 6,
      "num_comments": 8,
      "upvote_ratio": 1.0,
      "text": "Is there a way to change pasted text behavior in opencode or oh-my-opencode?\n\nBecause alot of times, i need to edit the pasted text before i hit enter and give it to my agent. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pxvynq/pasted_text_as_complete_text_instead_of_pasted_5/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nwecc8n",
          "author": "t4a8945",
          "text": "yeah this is annoying and useful at the same time, no idea if you can turn it off sorry",
          "score": 3,
          "created_utc": "2025-12-28 17:56:17",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwedldu",
              "author": "EfficientHat0006",
              "text": "I searched alot of issues and tickets on github. There are two ways to do it:\n1) use editor (which just won't open for me)\n2) add the following command in opencode config (sort of permanent way)\n// this:\n   \"experimental\": {\n    \"disable_paste_summary\": true,\n  },",
              "score": 3,
              "created_utc": "2025-12-28 18:02:12",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nwedp6b",
          "author": "FlyingDogCatcher",
          "text": "open in editor",
          "score": 1,
          "created_utc": "2025-12-28 18:02:41",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwekk1t",
              "author": "EfficientHat0006",
              "text": "How to do that? I tried ctrl p and then open editor when i am in inout field but it just won't open\nI am on latest version.\n\nTried in VS terminal and waveterm terminal",
              "score": 1,
              "created_utc": "2025-12-28 18:34:43",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nwf53hl",
                  "author": "DinoAmino",
                  "text": "Opencode uses the EDITOR environment variable. If using Linux just add it to the \\`.bashrc\\` file. I use \\`nano\\` so I have a line that just reads \\`EDITOR=nano\\`\n\nOpen a fresh terminal and use /editor on a new prompt or \\`ctrl+x e\\`  on a new or existing input prompt and the editor will open.\n\n[https://opencode.ai/docs/tui/#editor-setup](https://opencode.ai/docs/tui/#editor-setup)",
                  "score": 1,
                  "created_utc": "2025-12-28 20:11:44",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nwf6mh6",
          "author": "Recent-Success-1520",
          "text": "CodeNomad allows this\nhttps://github.com/NeuralNomadsAI/CodeNomad",
          "score": 1,
          "created_utc": "2025-12-28 20:19:15",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwf8x6i",
              "author": "EfficientHat0006",
              "text": "I tried installing codenomad on mac apple silicon. But everytime i try to launch app i get error",
              "score": 1,
              "created_utc": "2025-12-28 20:30:43",
              "is_submitter": true,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1punsc2",
      "title": "Forking OpenCode > So far ... It has these features...",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/rtz4oodkp59g1.png",
      "author": "Kitchen_Sympathy_344",
      "created_utc": "2025-12-24 13:48:35",
      "score": 6,
      "num_comments": 9,
      "upvote_ratio": 0.75,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1punsc2/forking_opencode_so_far_it_has_these_features/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nvpzpvg",
          "author": "ganadineroconalex18",
          "text": "Is this the IDE?",
          "score": 2,
          "created_utc": "2025-12-24 14:29:54",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvqymb0",
          "author": "0sko59fds24",
          "text": "What's your plan / goal?",
          "score": 1,
          "created_utc": "2025-12-24 17:40:56",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvv5lgb",
          "author": "Superb-Marketing-453",
          "text": "What does it add that Codenomad doesn't?",
          "score": 1,
          "created_utc": "2025-12-25 13:05:01",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvvbzl0",
          "author": "Kitchen_Sympathy_344",
          "text": "Autonomous APEX agent\nMulti agent and multi model in multi task (run different models and agents within same session, isolated from each other)\nAI agent generator - generate new agents using AI and use them\nMCP market installer\nAnd more",
          "score": 1,
          "created_utc": "2025-12-25 13:54:51",
          "is_submitter": true,
          "replies": []
        },
        {
          "id": "nvz6jev",
          "author": "Resident_Suit_9916",
          "text": "Where can we use it?",
          "score": 1,
          "created_utc": "2025-12-26 04:41:48",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvzolmf",
              "author": "Kitchen_Sympathy_344",
              "text": "I'm having issues upload the last version to GitHub due to some LS storage error ... Figurig out...",
              "score": 1,
              "created_utc": "2025-12-26 07:16:55",
              "is_submitter": true,
              "replies": []
            }
          ]
        },
        {
          "id": "nw5t2fa",
          "author": "formatme",
          "text": "whats the github link",
          "score": 1,
          "created_utc": "2025-12-27 08:18:47",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvq5dp7",
          "author": "Kitchen_Sympathy_344",
          "text": "Correction: Fork of CodeNomad\nTitle had a typo.\nSorry :)",
          "score": 1,
          "created_utc": "2025-12-24 15:02:49",
          "is_submitter": true,
          "replies": []
        }
      ]
    },
    {
      "id": "1punb57",
      "title": "Antigravity Subs",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1punb57/antigravity_subs/",
      "author": "Ivankax28",
      "created_utc": "2025-12-24 13:24:30",
      "score": 5,
      "num_comments": 14,
      "upvote_ratio": 0.73,
      "text": "as the title, is that possible i use my google one subs in Antigravity in opencode Connect Provider?\n\nbtw opencode is great!",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1punb57/antigravity_subs/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nvpqj8v",
          "author": "0sko59fds24",
          "text": "https://github.com/NoeFabris/opencode-antigravity-auth",
          "score": 5,
          "created_utc": "2025-12-24 13:32:53",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqiqbo",
              "author": "Ivankax28",
              "text": "is this work smooth?",
              "score": 1,
              "created_utc": "2025-12-24 16:15:03",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvu89ts",
                  "author": "james__jam",
                  "text": "Yes!",
                  "score": 1,
                  "created_utc": "2025-12-25 07:17:06",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvpxqzb",
          "author": "Ang_Drew",
          "text": "im currently using cli proxy api.. i mixed every subs i had..\nglm, minimax, 4 gemini, 12 chatgpt all of them are subs.",
          "score": 3,
          "created_utc": "2025-12-24 14:18:06",
          "is_submitter": false,
          "replies": [
            {
              "id": "nvqdn51",
              "author": "rangerrick337",
              "text": "https://github.com/router-for-me/CLIProxyAPI",
              "score": 2,
              "created_utc": "2025-12-24 15:48:10",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvpxw06",
              "author": "Recent-Success-1520",
              "text": "This",
              "score": 1,
              "created_utc": "2025-12-24 14:18:56",
              "is_submitter": false,
              "replies": []
            },
            {
              "id": "nvqd0gd",
              "author": "Ivankax28",
              "text": "any guide?",
              "score": 1,
              "created_utc": "2025-12-24 15:44:47",
              "is_submitter": true,
              "replies": [
                {
                  "id": "nvr4c73",
                  "author": "Ang_Drew",
                  "text": "very tough to explain.. there are only one docs (the web). but if you read the docs slowly you will understand eventually.",
                  "score": 1,
                  "created_utc": "2025-12-24 18:11:35",
                  "is_submitter": false,
                  "replies": []
                }
              ]
            }
          ]
        },
        {
          "id": "nvpphzq",
          "author": "VictorCTavernari",
          "text": "I am in the same boat...",
          "score": 1,
          "created_utc": "2025-12-24 13:26:07",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nvrmz35",
          "author": "FlyingDogCatcher",
          "text": "Opencode even has the ability for plugins! If only someone would make a plugin for your subscription of choice and put it on GitHub then you could finally solve this problem\n\n\\*cough\\*",
          "score": 1,
          "created_utc": "2025-12-24 19:54:37",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1pvzm2m",
      "title": "Can we anyhow use qwen code in opencode??",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1pvzm2m/can_we_anyhow_use_qwen_code_in_opencode/",
      "author": "Resident_Suit_9916",
      "created_utc": "2025-12-26 08:40:11",
      "score": 4,
      "num_comments": 3,
      "upvote_ratio": 0.84,
      "text": "Can we anyhow use qwen code in opencodex\nI wanna use qwen code cli models in opencodex is there any way from which I can do so. ",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pvzm2m/can_we_anyhow_use_qwen_code_in_opencode/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nw02la1",
          "author": "BingpotStudio",
          "text": "I haven‚Äôt done it, but you can. Hit up the discord if you‚Äôre stuck.",
          "score": 1,
          "created_utc": "2025-12-26 09:42:30",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw06b62",
          "author": "Hot_Dig8208",
          "text": "You can use [this](https://www.npmjs.com/package/opencode-alibaba-qwen3-auth). It enables you to use qern coder auth. But I don‚Äôt know is it working or not",
          "score": 1,
          "created_utc": "2025-12-26 10:20:46",
          "is_submitter": false,
          "replies": []
        },
        {
          "id": "nw37vsm",
          "author": "shikima",
          "text": "I used this guide https://medium.com/@lexy_eyn/how-to-connect-a-local-qwen3-coder-30b-to-opencode-and-create-a-self-hosted-claude-code-alternative-4f0db7f38cc2",
          "score": 1,
          "created_utc": "2025-12-26 21:40:30",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1puozpd",
      "title": "Is there a way to schedule agents/workflows in opencode?",
      "subreddit": "opencodeCLI",
      "url": "https://www.reddit.com/r/opencodeCLI/comments/1puozpd/is_there_a_way_to_schedule_agentsworkflows_in/",
      "author": "EfficientHat0006",
      "created_utc": "2025-12-24 14:46:12",
      "score": 4,
      "num_comments": 1,
      "upvote_ratio": 1.0,
      "text": "I just started using opencode and totally new to CLI based agentic approaches. I have been using n8n workflows.\n\nIs there a way to schedule certain agents and their actions? This would significantly reduce my dependence on n8n.\n\n  \nOr it's a complete different use case and no way to do it in opencode?",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1puozpd/is_there_a_way_to_schedule_agentsworkflows_in/",
      "domain": "self.opencodeCLI",
      "is_self": true,
      "comments": [
        {
          "id": "nvrtbry",
          "author": "Pleasant_Thing_2874",
          "text": "only way I've ever done it is use a cronjob to call opencode via CLI tasking a specific agent, giving it the prompt and having appropriate guardrail/instruction files to keep the agent on target.  If there is a way to directly do it in opencode I don't know it.  There might be an opencode plugin out there somewhere that'll do what you ask.",
          "score": 2,
          "created_utc": "2025-12-24 20:31:57",
          "is_submitter": false,
          "replies": []
        }
      ]
    },
    {
      "id": "1px32x8",
      "title": "Is there a way to reproduce warp terminal agentic internal workflow ?",
      "subreddit": "opencodeCLI",
      "url": "https://i.redd.it/joepb7cf2s9g1.png",
      "author": "Kisscool-citron",
      "created_utc": "2025-12-27 17:17:36",
      "score": 3,
      "num_comments": 2,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1px32x8/is_there_a_way_to_reproduce_warp_terminal_agentic/",
      "domain": "i.redd.it",
      "is_self": false,
      "comments": [
        {
          "id": "nw83x0z",
          "author": "IntrepidLawfulness42",
          "text": "I'd put a http proxy between the tool and the API they're using, and observe. \n\nOnce you know the exact warp workflow, prompts, etc. it shouldn't be difficult to replicate it in opencode.",
          "score": 2,
          "created_utc": "2025-12-27 17:56:14",
          "is_submitter": false,
          "replies": [
            {
              "id": "nwbtw5l",
              "author": "Charming_Support726",
              "text": "Great Idea. \n\nAnd please share.",
              "score": 1,
              "created_utc": "2025-12-28 07:15:54",
              "is_submitter": false,
              "replies": []
            }
          ]
        }
      ]
    },
    {
      "id": "1pumwee",
      "title": "Update: Leash now has one-liner setup and catches way more agent hallucinations",
      "subreddit": "opencodeCLI",
      "url": "/r/ClaudeAI/comments/1pumjfr/update_leash_now_has_oneliner_setup_and_catches/",
      "author": "melihmucuk",
      "created_utc": "2025-12-24 13:02:53",
      "score": 3,
      "num_comments": 0,
      "upvote_ratio": 1.0,
      "text": "[External Link]",
      "is_original_content": false,
      "link_flair_text": null,
      "permalink": "https://reddit.com/r/opencodeCLI/comments/1pumwee/update_leash_now_has_oneliner_setup_and_catches/",
      "domain": "",
      "is_self": false,
      "comments": []
    }
  ]
}